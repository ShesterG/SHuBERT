[2024-10-03 12:16:25,790][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14847', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:25,870][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10868', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:26,907][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11250', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:26,966][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12945', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:27,641][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16309', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:28,005][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11855', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:28,157][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13463', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:29,385][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12527', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-03 12:16:29,631][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:29,633][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:29,633][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:29,633][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:29,634][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:29,635][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:30,090][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:30,092][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:30,092][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:30,092][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:30,093][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:30,094][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:33,230][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:33,246][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:33,257][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:33,258][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:33,259][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:33,259][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:33,443][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:33,458][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:33,458][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:33,458][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:33,459][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:33,459][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:33,472][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:33,681][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:33,699][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:33,699][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:33,699][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:33,700][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:33,701][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:34,389][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:34,395][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:34,395][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:34,395][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:34,396][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:34,406][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:34,592][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:34,986][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:34,988][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:34,988][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:34,988][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:34,989][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:35,018][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:37,482][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:38,275][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:38,753][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:39,951][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:42,276][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-03 12:16:42,419][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-03 12:16:42,419][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-03 12:16:42,419][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-03 12:16:42,421][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-03 12:16:42,498][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-03 12:16:48,452][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:16:57,754][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:19:55,129][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:19:55,169][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:19:55,170][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:19:55,184][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:19:55,185][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:19:55,185][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:19:55,186][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:20:15,322][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:21:21,902][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:21:21,969][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:21:21,970][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:21:21,970][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:21:21,971][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:21:21,971][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:21:21,971][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:21:38,698][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:22:13,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:22:13,068][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:22:13,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:22:28,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:22:28,919][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:22:28,919][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:28:33,103][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:33,107][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:28:33,107][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:28:33,112][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:28:33,123][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:28:33,123][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:28:33,123][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:28:36,193][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:28:38,285][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:28:38,285][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,293][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,293][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,293][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,293][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,293][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,294][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,294][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:28:38,294][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:28:38,294][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:28:38,294][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:28:38,295][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:28:38,295][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:28:38,295][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:28:42,431][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,751][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,752][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:07,752][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:07,752][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:29:07,752][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:29:07,753][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:07,756][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:07,756][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:29:11,798][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:44,225][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:44,226][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:29:44,226][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:29:44,227][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:44,227][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:44,227][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:29:50,432][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,922][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,923][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,923][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:29:57,923][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:29:57,923][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:29:57,923][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:29:57,924][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:57,924][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:29:57,924][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:30:01,541][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:30:17,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:30:17,032][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:30:17,032][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:30:17,543][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:30:17,549][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-03 12:30:17,550][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-03 12:30:17,550][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-03 12:30:17,551][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-03 12:30:17,552][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:30:17,552][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-03 12:30:17,552][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-03 12:30:18,154][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:30:18,163][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:30:18,163][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:30:22,262][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-03 12:30:25,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:30:25,723][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:30:25,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:31:19,054][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:31:19,077][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:31:19,078][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:31:39,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:31:39,698][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:31:39,699][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:31:41,826][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 12:31:41,835][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-03 12:31:41,835][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 12:49:32,278][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-03 12:49:33,145][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-03 12:49:33,834][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-03 12:50:10,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-03 12:51:14,242][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-03 12:51:14,824][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-03 12:51:15,473][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-03 12:51:17,445][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-03 12:51:17,871][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-03 12:51:39,248][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-03 12:59:57,677][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.534", "ntokens": "263888", "nsentences": "1773.98", "wps": "84504.1", "ups": "0.32", "wpb": "263888", "bsz": "1774", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "732", "gb_free": "39.1", "wall": "1879"}
[2024-10-03 13:00:00,417][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.534", "ntokens": "263888", "nsentences": "1773.98", "wps": "100210", "ups": "0.38", "wpb": "263888", "bsz": "1774", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "630", "gb_free": "39.1", "wall": "1887"}
[2024-10-03 13:12:12,130][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "4.932", "ntokens": "264190", "nsentences": "1717.45", "wps": "72215.5", "ups": "0.27", "wpb": "264190", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.702", "loss_scale": "4", "train_wall": "418", "gb_free": "39.6", "wall": "2619"}
[2024-10-03 13:12:19,309][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "4.932", "ntokens": "264190", "nsentences": "1717.45", "wps": "71247.6", "ups": "0.27", "wpb": "264190", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.702", "loss_scale": "4", "train_wall": "424", "gb_free": "39.6", "wall": "2621"}
[2024-10-03 13:15:24,499][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-03 13:15:25,024][train][INFO] - {"epoch": 1, "train_loss": "5.108", "train_ntokens": "263580", "train_nsentences": "1751.41", "train_wps": "86082.7", "train_ups": "0.33", "train_wpb": "263580", "train_bsz": "1751.4", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.762", "train_loss_scale": "4", "train_train_wall": "1237", "train_gb_free": "40.1", "train_wall": "2811"}
[2024-10-03 13:15:25,719][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 13:15:25,732][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-03 13:15:25,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 13:16:13,969][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-03 13:16:14,048][train][INFO] - {"epoch": 1, "train_loss": "5.108", "train_ntokens": "263580", "train_nsentences": "1751.41", "train_wps": "78025", "train_ups": "0.3", "train_wpb": "263580", "train_bsz": "1751.4", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.762", "train_loss_scale": "4", "train_train_wall": "1388", "train_gb_free": "40.1", "train_wall": "2856"}
[2024-10-03 13:16:14,199][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 13:16:14,209][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-03 13:16:14,209][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 13:31:25,522][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.248", "ntokens": "263025", "nsentences": "1773.64", "wps": "45896.9", "ups": "0.17", "wpb": "263025", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.603", "loss_scale": "4", "train_wall": "719", "gb_free": "39.6", "wall": "3767"}
[2024-10-03 13:31:28,776][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.248", "ntokens": "263025", "nsentences": "1773.64", "wps": "45482.7", "ups": "0.17", "wpb": "263025", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.603", "loss_scale": "4", "train_wall": "664", "gb_free": "39.6", "wall": "3776"}
[2024-10-03 13:44:30,074][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "3.762", "ntokens": "264037", "nsentences": "1758.35", "wps": "67602.5", "ups": "0.26", "wpb": "264037", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.561", "loss_scale": "4", "train_wall": "603", "gb_free": "39.1", "wall": "4557"}
[2024-10-03 13:44:45,808][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "3.762", "ntokens": "264037", "nsentences": "1758.35", "wps": "65987.9", "ups": "0.25", "wpb": "264037", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.561", "loss_scale": "4", "train_wall": "624", "gb_free": "39.1", "wall": "4568"}
[2024-10-03 13:52:46,240][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-03 13:52:46,441][train][INFO] - {"epoch": 2, "train_loss": "3.749", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "56341.5", "train_ups": "0.21", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "0.604", "train_loss_scale": "4", "train_train_wall": "1570", "train_gb_free": "39.8", "train_wall": "5053"}
[2024-10-03 13:52:47,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 13:52:47,259][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-03 13:52:47,266][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 13:53:22,297][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-03 13:53:22,325][train][INFO] - {"epoch": 2, "train_loss": "3.749", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "56670.2", "train_ups": "0.21", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "0.604", "train_loss_scale": "4", "train_train_wall": "1622", "train_gb_free": "39.8", "train_wall": "5084"}
[2024-10-03 13:53:22,539][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 13:53:22,547][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-03 13:53:22,548][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 14:04:36,650][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.36", "ntokens": "262816", "nsentences": "1775.94", "wps": "43567.1", "ups": "0.17", "wpb": "262816", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.685", "loss_scale": "4", "train_wall": "766", "gb_free": "39.2", "wall": "5764"}
[2024-10-03 14:04:42,490][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.36", "ntokens": "262816", "nsentences": "1775.94", "wps": "43924.9", "ups": "0.17", "wpb": "262816", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.685", "loss_scale": "4", "train_wall": "753", "gb_free": "39.2", "wall": "5764"}
[2024-10-03 14:16:29,145][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "2.985", "ntokens": "264038", "nsentences": "1729.12", "wps": "74735.9", "ups": "0.28", "wpb": "264038", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.909", "loss_scale": "4", "train_wall": "617", "gb_free": "39.6", "wall": "6471"}
[2024-10-03 14:16:30,793][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "2.985", "ntokens": "264038", "nsentences": "1729.12", "wps": "73946.1", "ups": "0.28", "wpb": "264038", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.909", "loss_scale": "4", "train_wall": "616", "gb_free": "39.6", "wall": "6478"}
[2024-10-03 14:29:49,095][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "2.672", "ntokens": "264035", "nsentences": "1741.91", "wps": "66019.2", "ups": "0.25", "wpb": "264035", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.139", "loss_scale": "4", "train_wall": "714", "gb_free": "39.4", "wall": "7271"}
[2024-10-03 14:29:50,306][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "2.672", "ntokens": "264035", "nsentences": "1741.91", "wps": "66049.7", "ups": "0.25", "wpb": "264035", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.138", "loss_scale": "4", "train_wall": "719", "gb_free": "39.4", "wall": "7277"}
[2024-10-03 14:30:45,321][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-03 14:30:45,407][train][INFO] - {"epoch": 3, "train_loss": "2.846", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "55373.7", "train_ups": "0.21", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.002", "train_loss_scale": "4", "train_train_wall": "1662", "train_gb_free": "39.8", "train_wall": "7332"}
[2024-10-03 14:30:45,802][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 14:30:45,847][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-03 14:30:45,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 14:31:16,140][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-03 14:31:16,183][train][INFO] - {"epoch": 3, "train_loss": "2.846", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "55497.7", "train_ups": "0.21", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.002", "train_loss_scale": "4", "train_train_wall": "1659", "train_gb_free": "39.8", "train_wall": "7358"}
[2024-10-03 14:31:16,614][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 14:31:16,631][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-03 14:31:16,632][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 14:52:25,650][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "2.417", "ntokens": "262249", "nsentences": "1810.06", "wps": "38701.3", "ups": "0.15", "wpb": "262249", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.321", "loss_scale": "4", "train_wall": "776", "gb_free": "40.7", "wall": "8632"}
[2024-10-03 14:52:27,712][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "2.417", "ntokens": "262249", "nsentences": "1810.06", "wps": "38605.5", "ups": "0.15", "wpb": "262249", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.315", "loss_scale": "4", "train_wall": "819", "gb_free": "40.7", "wall": "8629"}
[2024-10-03 15:04:09,556][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "2.212", "ntokens": "264618", "nsentences": "1707.52", "wps": "75412.1", "ups": "0.28", "wpb": "264618", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.402", "loss_scale": "4", "train_wall": "421", "gb_free": "39.8", "wall": "9331"}
[2024-10-03 15:04:11,144][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "2.212", "ntokens": "264618", "nsentences": "1707.52", "wps": "75027.8", "ups": "0.28", "wpb": "264618", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.404", "loss_scale": "4", "train_wall": "400", "gb_free": "39.8", "wall": "9338"}
[2024-10-03 15:09:48,679][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-03 15:09:48,887][train][INFO] - {"epoch": 4, "train_loss": "2.247", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "53881.6", "train_ups": "0.2", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.427", "train_loss_scale": "4", "train_train_wall": "1366", "train_gb_free": "40.1", "train_wall": "9676"}
[2024-10-03 15:09:49,071][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 15:09:49,111][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-03 15:09:49,112][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 15:10:23,799][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-03 15:10:23,824][train][INFO] - {"epoch": 4, "train_loss": "2.247", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "53783.4", "train_ups": "0.2", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.387", "train_loss_scale": "4", "train_train_wall": "1443", "train_gb_free": "40.1", "train_wall": "9706"}
[2024-10-03 15:10:23,996][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 15:10:24,012][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-03 15:10:24,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 15:25:47,266][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "2.046", "ntokens": "262854", "nsentences": "1755.84", "wps": "40562.9", "ups": "0.15", "wpb": "262854", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.468", "loss_scale": "4", "train_wall": "681", "gb_free": "39.6", "wall": "10634"}
[2024-10-03 15:25:47,928][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "2.045", "ntokens": "262854", "nsentences": "1755.84", "wps": "40491.7", "ups": "0.15", "wpb": "262854", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.384", "loss_scale": "4", "train_wall": "767", "gb_free": "39.6", "wall": "10630"}
[2024-10-03 15:30:31,407][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-03 15:32:11,165][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-03 15:40:22,441][train_inner][INFO] - {"epoch": 5, "update": 4.605, "loss": "1.911", "ntokens": "263581", "nsentences": "1795.01", "wps": "60239.9", "ups": "0.23", "wpb": "263581", "bsz": "1795", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.357", "loss_scale": "4", "train_wall": "872", "gb_free": "39.2", "wall": "11509"}
[2024-10-03 15:40:23,883][train_inner][INFO] - {"epoch": 5, "update": 4.605, "loss": "1.91", "ntokens": "263602", "nsentences": "1793.82", "wps": "60188.4", "ups": "0.23", "wpb": "263602", "bsz": "1793.8", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.428", "loss_scale": "4", "train_wall": "872", "gb_free": "39.2", "wall": "11506"}
[2024-10-03 15:43:36,612][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-03 15:49:57,573][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-03 15:50:26,594][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-03 15:50:26,711][train][INFO] - {"epoch": 5, "train_loss": "1.888", "train_ntokens": "263370", "train_nsentences": "1756.38", "train_wps": "51534.8", "train_ups": "0.2", "train_wpb": "263370", "train_bsz": "1756.4", "train_num_updates": "2388", "train_lr": "3.73125e-05", "train_gnorm": "1.44", "train_loss_scale": "2", "train_train_wall": "1888", "train_gb_free": "39.2", "train_wall": "12114"}
[2024-10-03 15:50:27,040][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 15:50:27,063][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-03 15:50:27,074][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 15:50:55,271][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-03 15:50:55,288][train][INFO] - {"epoch": 5, "train_loss": "1.887", "train_ntokens": "263395", "train_nsentences": "1754.68", "train_wps": "51672.3", "train_ups": "0.2", "train_wpb": "263395", "train_bsz": "1754.7", "train_num_updates": "2388", "train_lr": "3.73125e-05", "train_gnorm": "1.43", "train_loss_scale": "2", "train_train_wall": "1952", "train_gb_free": "39.2", "train_wall": "12137"}
[2024-10-03 15:50:55,485][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 15:50:55,533][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-03 15:50:55,538][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 16:00:21,268][train_inner][INFO] - {"epoch": 6, "update": 5.025, "loss": "1.804", "ntokens": "263054", "nsentences": "1707.42", "wps": "43938.8", "ups": "0.17", "wpb": "263054", "bsz": "1707.4", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.452", "loss_scale": "2", "train_wall": "727", "gb_free": "40.3", "wall": "12703"}
[2024-10-03 16:00:24,185][train_inner][INFO] - {"epoch": 6, "update": 5.025, "loss": "1.805", "ntokens": "263016", "nsentences": "1710.27", "wps": "43772.8", "ups": "0.17", "wpb": "263016", "bsz": "1710.3", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.542", "loss_scale": "2", "train_wall": "708", "gb_free": "40.3", "wall": "12711"}
[2024-10-03 16:11:13,966][train_inner][INFO] - {"epoch": 6, "update": 5.443, "loss": "1.716", "ntokens": "263982", "nsentences": "1762.68", "wps": "81260.6", "ups": "0.31", "wpb": "263982", "bsz": "1762.7", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.459", "loss_scale": "2", "train_wall": "511", "gb_free": "40.1", "wall": "13361"}
[2024-10-03 16:11:16,127][train_inner][INFO] - {"epoch": 6, "update": 5.443, "loss": "1.716", "ntokens": "263982", "nsentences": "1762.68", "wps": "80625.1", "ups": "0.31", "wpb": "263982", "bsz": "1762.7", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.51", "loss_scale": "2", "train_wall": "514", "gb_free": "40.1", "wall": "13358"}
[2024-10-03 16:24:02,533][train_inner][INFO] - {"epoch": 6, "update": 5.86, "loss": "1.646", "ntokens": "263934", "nsentences": "1758.96", "wps": "68880.7", "ups": "0.26", "wpb": "263934", "bsz": "1759", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.342", "loss_scale": "2", "train_wall": "751", "gb_free": "39.6", "wall": "14124"}
[2024-10-03 16:24:02,969][train_inner][INFO] - {"epoch": 6, "update": 5.86, "loss": "1.646", "ntokens": "263934", "nsentences": "1758.96", "wps": "68644.7", "ups": "0.26", "wpb": "263934", "bsz": "1759", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.314", "loss_scale": "2", "train_wall": "765", "gb_free": "39.6", "wall": "14130"}
[2024-10-03 16:28:40,805][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-03 16:28:40,982][train][INFO] - {"epoch": 6, "train_loss": "1.672", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "55028.3", "train_ups": "0.21", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "2867", "train_lr": "4.47969e-05", "train_gnorm": "1.378", "train_loss_scale": "2", "train_train_wall": "1682", "train_gb_free": "39.4", "train_wall": "14408"}
[2024-10-03 16:28:41,345][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 16:28:41,368][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-03 16:28:41,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 16:29:21,402][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-03 16:29:21,414][train][INFO] - {"epoch": 6, "train_loss": "1.672", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "54742.6", "train_ups": "0.21", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "2867", "train_lr": "4.47969e-05", "train_gnorm": "1.412", "train_loss_scale": "2", "train_train_wall": "1709", "train_gb_free": "39.4", "train_wall": "14443"}
[2024-10-03 16:29:21,493][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 16:29:21,506][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-03 16:29:21,515][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 16:48:53,880][train_inner][INFO] - {"epoch": 7, "update": 6.278, "loss": "1.587", "ntokens": "263049", "nsentences": "1737.32", "wps": "35277.9", "ups": "0.13", "wpb": "263049", "bsz": "1737.3", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.338", "loss_scale": "2", "train_wall": "1017", "gb_free": "39.1", "wall": "15616"}
[2024-10-03 16:49:02,152][train_inner][INFO] - {"epoch": 7, "update": 6.278, "loss": "1.587", "ntokens": "263049", "nsentences": "1737.32", "wps": "35092.9", "ups": "0.13", "wpb": "263049", "bsz": "1737.3", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.403", "loss_scale": "2", "train_wall": "917", "gb_free": "39.1", "wall": "15629"}
[2024-10-03 17:08:40,128][train_inner][INFO] - {"epoch": 7, "update": 6.695, "loss": "1.539", "ntokens": "264285", "nsentences": "1716.78", "wps": "44560.9", "ups": "0.17", "wpb": "264285", "bsz": "1716.8", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.226", "loss_scale": "2", "train_wall": "649", "gb_free": "39.2", "wall": "16802"}
[2024-10-03 17:08:52,534][train_inner][INFO] - {"epoch": 7, "update": 6.695, "loss": "1.539", "ntokens": "264285", "nsentences": "1716.78", "wps": "44404.1", "ups": "0.17", "wpb": "264285", "bsz": "1716.8", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.191", "loss_scale": "2", "train_wall": "608", "gb_free": "39.2", "wall": "16819"}
[2024-10-03 17:18:51,471][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-03 17:18:51,633][train][INFO] - {"epoch": 7, "train_loss": "1.54", "train_ntokens": "263525", "train_nsentences": "1753.71", "train_wps": "42499.8", "train_ups": "0.16", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "3346", "train_lr": "5.22813e-05", "train_gnorm": "1.277", "train_loss_scale": "2", "train_train_wall": "1906", "train_gb_free": "39.3", "train_wall": "17413"}
[2024-10-03 17:18:52,299][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 17:18:52,416][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-03 17:18:52,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 17:18:53,699][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-03 17:18:53,754][train][INFO] - {"epoch": 7, "train_loss": "1.54", "train_ntokens": "263525", "train_nsentences": "1753.71", "train_wps": "41898.3", "train_ups": "0.16", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "3346", "train_lr": "5.22813e-05", "train_gnorm": "1.274", "train_loss_scale": "2", "train_train_wall": "1790", "train_gb_free": "39.3", "train_wall": "17421"}
[2024-10-03 17:18:54,352][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 17:18:54,407][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-03 17:18:54,409][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 17:30:03,014][train_inner][INFO] - {"epoch": 8, "update": 7.113, "loss": "1.5", "ntokens": "262663", "nsentences": "1777.61", "wps": "41351.4", "ups": "0.16", "wpb": "262663", "bsz": "1777.6", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.271", "loss_scale": "2", "train_wall": "775", "gb_free": "40.1", "wall": "18090"}
[2024-10-03 17:31:20,795][train_inner][INFO] - {"epoch": 8, "update": 7.113, "loss": "1.5", "ntokens": "262663", "nsentences": "1777.61", "wps": "38608.5", "ups": "0.15", "wpb": "262663", "bsz": "1777.6", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.319", "loss_scale": "2", "train_wall": "871", "gb_free": "40.1", "wall": "18162"}
[2024-10-03 17:44:00,779][train_inner][INFO] - {"epoch": 8, "update": 7.53, "loss": "1.464", "ntokens": "264287", "nsentences": "1741.84", "wps": "63098.8", "ups": "0.24", "wpb": "264287", "bsz": "1741.8", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.236", "loss_scale": "2", "train_wall": "771", "gb_free": "39.2", "wall": "18928"}
[2024-10-03 17:49:00,731][train_inner][INFO] - {"epoch": 8, "update": 7.53, "loss": "1.464", "ntokens": "264287", "nsentences": "1741.84", "wps": "49869.2", "ups": "0.19", "wpb": "264287", "bsz": "1741.8", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.252", "loss_scale": "2", "train_wall": "963", "gb_free": "39.2", "wall": "19222"}
[2024-10-03 18:04:32,990][train_inner][INFO] - {"epoch": 8, "update": 7.948, "loss": "1.435", "ntokens": "263959", "nsentences": "1755.26", "wps": "56630.7", "ups": "0.21", "wpb": "263959", "bsz": "1755.3", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.203", "loss_scale": "2", "train_wall": "927", "gb_free": "40.1", "wall": "20155"}
[2024-10-03 18:04:35,264][train_inner][INFO] - {"epoch": 8, "update": 7.948, "loss": "1.435", "ntokens": "263959", "nsentences": "1755.26", "wps": "42764.5", "ups": "0.16", "wpb": "263959", "bsz": "1755.3", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.204", "loss_scale": "2", "train_wall": "1195", "gb_free": "40.1", "wall": "20162"}
[2024-10-03 18:05:10,499][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-03 18:05:10,593][train][INFO] - {"epoch": 8, "train_loss": "1.453", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "45464.2", "train_ups": "0.17", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "3825", "train_lr": "5.97656e-05", "train_gnorm": "1.229", "train_loss_scale": "2", "train_train_wall": "2234", "train_gb_free": "39.3", "train_wall": "20197"}
[2024-10-03 18:05:10,998][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 18:05:11,036][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-03 18:05:11,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 18:06:26,922][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-03 18:06:26,937][train][INFO] - {"epoch": 8, "train_loss": "1.453", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "44213.5", "train_ups": "0.17", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "3825", "train_lr": "5.97656e-05", "train_gnorm": "1.247", "train_loss_scale": "2", "train_train_wall": "2315", "train_gb_free": "39.3", "train_wall": "20269"}
[2024-10-03 18:06:27,047][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 18:06:27,057][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-03 18:06:27,057][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 18:29:20,328][train_inner][INFO] - {"epoch": 9, "update": 8.365, "loss": "1.408", "ntokens": "262375", "nsentences": "1783.5", "wps": "35338.2", "ups": "0.13", "wpb": "262375", "bsz": "1783.5", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.227", "loss_scale": "2", "train_wall": "999", "gb_free": "39.1", "wall": "21647"}
[2024-10-03 18:32:05,473][train_inner][INFO] - {"epoch": 9, "update": 8.365, "loss": "1.408", "ntokens": "262375", "nsentences": "1783.5", "wps": "31756.4", "ups": "0.12", "wpb": "262375", "bsz": "1783.5", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.239", "loss_scale": "2", "train_wall": "979", "gb_free": "39.1", "wall": "21807"}
[2024-10-03 18:39:17,222][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-03 18:39:47,454][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-03 18:49:18,252][train_inner][INFO] - {"epoch": 9, "update": 8.785, "loss": "1.386", "ntokens": "264001", "nsentences": "1763.42", "wps": "44078.5", "ups": "0.17", "wpb": "264001", "bsz": "1763.4", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.246", "loss_scale": "1", "train_wall": "1147", "gb_free": "39.1", "wall": "22845"}
[2024-10-03 18:49:20,214][train_inner][INFO] - {"epoch": 9, "update": 8.785, "loss": "1.385", "ntokens": "264016", "nsentences": "1760.24", "wps": "51032.4", "ups": "0.19", "wpb": "264016", "bsz": "1760.2", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.121", "loss_scale": "1", "train_wall": "1031", "gb_free": "39.1", "wall": "22842"}
[2024-10-03 18:54:15,289][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-03 18:54:15,370][train][INFO] - {"epoch": 9, "train_loss": "1.39", "train_ntokens": "263492", "train_nsentences": "1754.31", "train_wps": "42771.2", "train_ups": "0.16", "train_wpb": "263492", "train_bsz": "1754.3", "train_num_updates": "4303", "train_lr": "6.72344e-05", "train_gnorm": "1.203", "train_loss_scale": "1", "train_train_wall": "2408", "train_gb_free": "40.1", "train_wall": "23142"}
[2024-10-03 18:54:15,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 18:54:15,755][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-03 18:54:15,756][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 18:54:43,046][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-03 18:54:43,058][train][INFO] - {"epoch": 9, "train_loss": "1.39", "train_ntokens": "263499", "train_nsentences": "1752.98", "train_wps": "43490.2", "train_ups": "0.17", "train_wpb": "263499", "train_bsz": "1753", "train_num_updates": "4303", "train_lr": "6.72344e-05", "train_gnorm": "1.205", "train_loss_scale": "1", "train_train_wall": "2175", "train_gb_free": "40.1", "train_wall": "23165"}
[2024-10-03 18:54:43,148][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 18:54:43,159][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-03 18:54:43,160][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 19:08:14,693][train_inner][INFO] - {"epoch": 10, "update": 9.203, "loss": "1.364", "ntokens": "263176", "nsentences": "1720.38", "wps": "46317.9", "ups": "0.18", "wpb": "263176", "bsz": "1720.4", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.146", "loss_scale": "1", "train_wall": "706", "gb_free": "40.5", "wall": "23982"}
[2024-10-03 19:08:22,270][train_inner][INFO] - {"epoch": 10, "update": 9.203, "loss": "1.364", "ntokens": "263176", "nsentences": "1720.38", "wps": "46089.7", "ups": "0.18", "wpb": "263176", "bsz": "1720.4", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.231", "loss_scale": "1", "train_wall": "703", "gb_free": "40.5", "wall": "23984"}
[2024-10-03 19:22:17,273][train_inner][INFO] - {"epoch": 10, "update": 9.62, "loss": "1.346", "ntokens": "264049", "nsentences": "1745.93", "wps": "62685.2", "ups": "0.24", "wpb": "264050", "bsz": "1745.9", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.106", "loss_scale": "1", "train_wall": "730", "gb_free": "39.4", "wall": "24824"}
[2024-10-03 19:22:37,935][train_inner][INFO] - {"epoch": 10, "update": 9.62, "loss": "1.345", "ntokens": "264049", "nsentences": "1745.93", "wps": "61719.2", "ups": "0.23", "wpb": "264050", "bsz": "1745.9", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.112", "loss_scale": "1", "train_wall": "753", "gb_free": "39.4", "wall": "24840"}
[2024-10-03 19:33:22,346][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-10-03 19:33:22,390][train][INFO] - {"epoch": 10, "train_loss": "1.342", "train_ntokens": "263400", "train_nsentences": "1753.71", "train_wps": "53757.9", "train_ups": "0.2", "train_wpb": "263400", "train_bsz": "1753.7", "train_num_updates": "4782", "train_lr": "7.47187e-05", "train_gnorm": "1.118", "train_loss_scale": "1", "train_train_wall": "1627", "train_gb_free": "39.6", "train_wall": "25489"}
[2024-10-03 19:33:22,464][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 19:33:22,471][fairseq.trainer][INFO] - begin training epoch 11
[2024-10-03 19:33:22,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 19:34:06,966][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-10-03 19:34:06,970][train][INFO] - {"epoch": 10, "train_loss": "1.342", "train_ntokens": "263400", "train_nsentences": "1753.71", "train_wps": "53372.9", "train_ups": "0.2", "train_wpb": "263400", "train_bsz": "1753.7", "train_num_updates": "4782", "train_lr": "7.47187e-05", "train_gnorm": "1.081", "train_loss_scale": "1", "train_train_wall": "1714", "train_gb_free": "39.6", "train_wall": "25529"}
[2024-10-03 19:34:07,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 19:34:07,027][fairseq.trainer][INFO] - begin training epoch 11
[2024-10-03 19:34:07,027][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 19:41:16,263][train_inner][INFO] - {"epoch": 11, "update": 10.038, "loss": "1.331", "ntokens": "262315", "nsentences": "1779.87", "wps": "46062.3", "ups": "0.18", "wpb": "262315", "bsz": "1779.9", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.161", "loss_scale": "1", "train_wall": "544", "gb_free": "40.1", "wall": "25963"}
[2024-10-03 19:45:46,474][train_inner][INFO] - {"epoch": 11, "update": 10.038, "loss": "1.33", "ntokens": "262315", "nsentences": "1779.87", "wps": "37784.3", "ups": "0.14", "wpb": "262315", "bsz": "1779.9", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.051", "loss_scale": "1", "train_wall": "766", "gb_free": "40.1", "wall": "26228"}
[2024-10-03 20:01:12,422][train_inner][INFO] - {"epoch": 11, "update": 10.455, "loss": "1.314", "ntokens": "263716", "nsentences": "1785.12", "wps": "44097.1", "ups": "0.17", "wpb": "263716", "bsz": "1785.1", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "0.98", "loss_scale": "1", "train_wall": "1187", "gb_free": "39.6", "wall": "27159"}
[2024-10-03 20:05:08,791][train_inner][INFO] - {"epoch": 11, "update": 10.455, "loss": "1.314", "ntokens": "263716", "nsentences": "1785.12", "wps": "45380.7", "ups": "0.17", "wpb": "263716", "bsz": "1785.1", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "1.1", "loss_scale": "1", "train_wall": "1156", "gb_free": "39.6", "wall": "27390"}
[2024-10-03 20:17:31,858][train_inner][INFO] - {"epoch": 11, "update": 10.873, "loss": "1.3", "ntokens": "264306", "nsentences": "1723.88", "wps": "53974.1", "ups": "0.2", "wpb": "264306", "bsz": "1723.9", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.054", "loss_scale": "1", "train_wall": "410", "gb_free": "40.1", "wall": "28139"}
[2024-10-03 20:17:35,839][train_inner][INFO] - {"epoch": 11, "update": 10.873, "loss": "1.3", "ntokens": "264306", "nsentences": "1723.88", "wps": "70761.7", "ups": "0.27", "wpb": "264306", "bsz": "1723.9", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.056", "loss_scale": "1", "train_wall": "619", "gb_free": "40.1", "wall": "28138"}
[2024-10-03 20:21:16,228][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-10-03 20:21:16,317][train][INFO] - {"epoch": 11, "train_loss": "1.306", "train_ntokens": "263535", "train_nsentences": "1753.71", "train_wps": "43924.7", "train_ups": "0.17", "train_wpb": "263535", "train_bsz": "1753.7", "train_num_updates": "5261", "train_lr": "8.22031e-05", "train_gnorm": "1.047", "train_loss_scale": "1", "train_train_wall": "1812", "train_gb_free": "39.3", "train_wall": "28363"}
[2024-10-03 20:21:16,561][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 20:21:16,596][fairseq.trainer][INFO] - begin training epoch 12
[2024-10-03 20:21:16,596][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 20:22:06,944][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-10-03 20:22:06,948][train][INFO] - {"epoch": 11, "train_loss": "1.306", "train_ntokens": "263535", "train_nsentences": "1753.71", "train_wps": "43831.4", "train_ups": "0.17", "train_wpb": "263535", "train_bsz": "1753.7", "train_num_updates": "5261", "train_lr": "8.22031e-05", "train_gnorm": "1.064", "train_loss_scale": "1", "train_train_wall": "2192", "train_gb_free": "39.3", "train_wall": "28409"}
[2024-10-03 20:22:06,998][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 20:22:07,002][fairseq.trainer][INFO] - begin training epoch 12
[2024-10-03 20:22:07,002][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 20:42:39,533][train_inner][INFO] - {"epoch": 12, "update": 11.29, "loss": "1.285", "ntokens": "263038", "nsentences": "1717.66", "wps": "34987.9", "ups": "0.13", "wpb": "263038", "bsz": "1717.7", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.047", "loss_scale": "1", "train_wall": "993", "gb_free": "39.1", "wall": "29641"}
[2024-10-03 20:43:46,157][train_inner][INFO] - {"epoch": 12, "update": 11.29, "loss": "1.285", "ntokens": "263038", "nsentences": "1717.66", "wps": "33418.3", "ups": "0.13", "wpb": "263038", "bsz": "1717.7", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.004", "loss_scale": "1", "train_wall": "634", "gb_free": "39.1", "wall": "29713"}
[2024-10-03 20:59:36,452][train_inner][INFO] - {"epoch": 12, "update": 11.708, "loss": "1.276", "ntokens": "264020", "nsentences": "1755.53", "wps": "55572.2", "ups": "0.21", "wpb": "264020", "bsz": "1755.5", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.053", "loss_scale": "1", "train_wall": "869", "gb_free": "39.6", "wall": "30663"}
[2024-10-03 20:59:37,677][train_inner][INFO] - {"epoch": 12, "update": 11.708, "loss": "1.276", "ntokens": "264020", "nsentences": "1755.53", "wps": "51864.1", "ups": "0.2", "wpb": "264020", "bsz": "1755.5", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.07", "loss_scale": "1", "train_wall": "892", "gb_free": "39.6", "wall": "30659"}
[2024-10-03 21:08:07,828][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-10-03 21:08:08,006][train][INFO] - {"epoch": 12, "train_loss": "1.275", "train_ntokens": "263435", "train_nsentences": "1753.71", "train_wps": "44880.7", "train_ups": "0.17", "train_wpb": "263435", "train_bsz": "1753.7", "train_num_updates": "5740", "train_lr": "8.96875e-05", "train_gnorm": "1.006", "train_loss_scale": "1", "train_train_wall": "1722", "train_gb_free": "39.3", "train_wall": "31175"}
[2024-10-03 21:08:08,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 21:08:08,487][fairseq.trainer][INFO] - begin training epoch 13
[2024-10-03 21:08:08,488][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 21:08:13,956][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-10-03 21:08:13,990][train][INFO] - {"epoch": 12, "train_loss": "1.275", "train_ntokens": "263435", "train_nsentences": "1753.71", "train_wps": "45603.2", "train_ups": "0.17", "train_wpb": "263435", "train_bsz": "1753.7", "train_num_updates": "5740", "train_lr": "8.96875e-05", "train_gnorm": "1.047", "train_loss_scale": "1", "train_train_wall": "2047", "train_gb_free": "39.3", "train_wall": "31176"}
[2024-10-03 21:08:14,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 21:08:14,379][fairseq.trainer][INFO] - begin training epoch 13
[2024-10-03 21:08:14,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 21:21:06,104][train_inner][INFO] - {"epoch": 13, "update": 12.125, "loss": "1.266", "ntokens": "262359", "nsentences": "1794.79", "wps": "40688.4", "ups": "0.16", "wpb": "262359", "bsz": "1794.8", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "0.972", "loss_scale": "1", "train_wall": "698", "gb_free": "40.1", "wall": "31953"}
[2024-10-03 21:22:29,585][train_inner][INFO] - {"epoch": 13, "update": 12.125, "loss": "1.266", "ntokens": "262359", "nsentences": "1794.79", "wps": "38249.4", "ups": "0.15", "wpb": "262359", "bsz": "1794.8", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "1.003", "loss_scale": "1", "train_wall": "790", "gb_free": "40.1", "wall": "32031"}
[2024-10-03 21:41:34,901][train_inner][INFO] - {"epoch": 13, "update": 12.543, "loss": "1.249", "ntokens": "264241", "nsentences": "1745.23", "wps": "43009.5", "ups": "0.16", "wpb": "264241", "bsz": "1745.2", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "0.986", "loss_scale": "1", "train_wall": "1222", "gb_free": "40", "wall": "33182"}
[2024-10-03 21:41:35,480][train_inner][INFO] - {"epoch": 13, "update": 12.543, "loss": "1.249", "ntokens": "264241", "nsentences": "1745.23", "wps": "46119.9", "ups": "0.17", "wpb": "264241", "bsz": "1745.2", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "0.946", "loss_scale": "1", "train_wall": "1103", "gb_free": "40", "wall": "33177"}
[2024-10-03 21:57:15,046][train_inner][INFO] - {"epoch": 13, "update": 12.96, "loss": "1.245", "ntokens": "263824", "nsentences": "1767.9", "wps": "56162.6", "ups": "0.21", "wpb": "263824", "bsz": "1767.9", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "0.94", "loss_scale": "2", "train_wall": "907", "gb_free": "39.2", "wall": "34117"}
[2024-10-03 21:57:15,050][train_inner][INFO] - {"epoch": 13, "update": 12.96, "loss": "1.244", "ntokens": "263824", "nsentences": "1767.9", "wps": "56128.4", "ups": "0.21", "wpb": "263824", "bsz": "1767.9", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "0.943", "loss_scale": "2", "train_wall": "844", "gb_free": "39.2", "wall": "34122"}
[2024-10-03 21:58:32,646][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-10-03 21:58:32,682][train][INFO] - {"epoch": 13, "train_loss": "1.249", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "41731", "train_ups": "0.16", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "6219", "train_lr": "9.71719e-05", "train_gnorm": "0.975", "train_loss_scale": "2", "train_train_wall": "2465", "train_gb_free": "39.7", "train_wall": "34200"}
[2024-10-03 21:58:32,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 21:58:33,048][fairseq.trainer][INFO] - begin training epoch 14
[2024-10-03 21:58:33,049][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 21:58:41,678][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-10-03 21:58:41,714][train][INFO] - {"epoch": 13, "train_loss": "1.249", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "41688.8", "train_ups": "0.16", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "6219", "train_lr": "9.71719e-05", "train_gnorm": "0.955", "train_loss_scale": "2", "train_train_wall": "2537", "train_gb_free": "39.7", "train_wall": "34203"}
[2024-10-03 21:58:41,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 21:58:41,876][fairseq.trainer][INFO] - begin training epoch 14
[2024-10-03 21:58:41,876][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 22:13:40,602][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-03 22:18:23,874][train_inner][INFO] - {"epoch": 14, "update": 13.38, "loss": "1.231", "ntokens": "263006", "nsentences": "1738.65", "wps": "41471.5", "ups": "0.16", "wpb": "263006", "bsz": "1738.7", "num_updates": "6400", "lr": "0.0001", "gnorm": "0.976", "loss_scale": "1", "train_wall": "770", "gb_free": "39.6", "wall": "35385"}
[2024-10-03 22:18:24,475][train_inner][INFO] - {"epoch": 14, "update": 13.378, "loss": "1.231", "ntokens": "262958", "nsentences": "1744.37", "wps": "41429.9", "ups": "0.16", "wpb": "262958", "bsz": "1744.4", "num_updates": "6400", "lr": "0.0001", "gnorm": "1.01", "loss_scale": "2", "train_wall": "765", "gb_free": "40.5", "wall": "35391"}
[2024-10-03 22:21:22,502][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-03 22:33:28,540][train_inner][INFO] - {"epoch": 14, "update": 13.797, "loss": "1.226", "ntokens": "263945", "nsentences": "1760.14", "wps": "58457.5", "ups": "0.22", "wpb": "263945", "bsz": "1760.1", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.997", "loss_scale": "1", "train_wall": "875", "gb_free": "39.6", "wall": "36294"}
[2024-10-03 22:33:29,707][train_inner][INFO] - {"epoch": 14, "update": 13.797, "loss": "1.226", "ntokens": "263877", "nsentences": "1769.07", "wps": "58262.8", "ups": "0.22", "wpb": "263877", "bsz": "1769.1", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.965", "loss_scale": "1", "train_wall": "856", "gb_free": "39.6", "wall": "36291"}
[2024-10-03 22:37:57,623][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-10-03 22:37:57,899][train][INFO] - {"epoch": 14, "train_loss": "1.227", "train_ntokens": "263524", "train_nsentences": "1750.73", "train_wps": "53262.4", "train_ups": "0.2", "train_wpb": "263524", "train_bsz": "1750.7", "train_num_updates": "6697", "train_lr": "0.000104641", "train_gnorm": "1.002", "train_loss_scale": "1", "train_train_wall": "1830", "train_gb_free": "39.1", "train_wall": "36565"}
[2024-10-03 22:37:58,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 22:37:58,203][fairseq.trainer][INFO] - begin training epoch 15
[2024-10-03 22:37:58,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-03 22:38:35,800][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-10-03 22:38:36,126][train][INFO] - {"epoch": 14, "train_loss": "1.227", "train_ntokens": "263515", "train_nsentences": "1752.07", "train_wps": "52612.4", "train_ups": "0.2", "train_wpb": "263515", "train_bsz": "1752.1", "train_num_updates": "6697", "train_lr": "0.000104641", "train_gnorm": "0.996", "train_loss_scale": "1", "train_train_wall": "1844", "train_gb_free": "39.1", "train_wall": "36598"}
[2024-10-03 22:38:36,265][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-03 22:38:36,303][fairseq.trainer][INFO] - begin training epoch 15
[2024-10-03 22:38:36,304][fairseq_cli.train][INFO] - Start iterating over samples
