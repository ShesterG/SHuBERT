[2024-10-08 16:40:35,073][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14849', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:36,437][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13114', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:36,559][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14716', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:37,308][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17682', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:37,855][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10843', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:38,339][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16172', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:38,722][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11788', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:38,944][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12071', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-08 16:40:39,221][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:39,223][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:39,223][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:39,223][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:39,224][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:39,225][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:39,510][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:40,731][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:40,740][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:40,741][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:40,741][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:40,742][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:40,747][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:41,208][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:42,072][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:42,074][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:42,074][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:42,074][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:42,075][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:42,076][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:42,549][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:42,766][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:42,776][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:42,776][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:42,776][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:42,777][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:42,783][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:42,858][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:42,872][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:42,891][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:42,891][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:42,892][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:42,903][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:43,403][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:43,434][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:43,440][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:43,440][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:43,440][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:43,441][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:43,442][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:43,924][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:44,275][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:44,520][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:44,522][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:44,522][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:44,522][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:44,531][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:44,532][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:44,788][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:40:46,066][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-08 16:40:46,107][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-08 16:40:46,107][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-08 16:40:46,107][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-08 16:40:46,108][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-08 16:40:46,108][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-08 16:40:48,372][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:41:53,640][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:41:53,647][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:41:53,648][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:41:53,648][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:41:53,655][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:42:38,739][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:42:38,750][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:42:39,485][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:42:47,432][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:42:47,456][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:42:47,457][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:42:49,344][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:42:49,345][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:42:49,346][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:42:49,346][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:42:49,347][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:43:20,491][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:43:20,493][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:43:20,935][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:43:28,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:43:28,028][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:43:28,029][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:43:31,164][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:43:31,164][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:31,165][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:43:31,165][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:43:31,165][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:43:31,178][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:43:37,396][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:43:37,396][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:43:37,397][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:43:37,397][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:43:51,916][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:43:51,996][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:43:52,701][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:43:54,089][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:43:54,097][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:43:54,508][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:44:05,374][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,375][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,376][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:05,376][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:05,376][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:44:05,376][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:44:05,378][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:44:08,269][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:44:08,284][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:44:08,285][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:11,554][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:11,554][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:44:11,555][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:44:11,556][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:44:13,429][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:44:13,459][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:44:13,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:44:42,202][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:44:42,227][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:44:42,674][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:44:42,996][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:44:43,004][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:44:43,915][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:44:52,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:44:52,703][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:44:52,703][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:44:55,369][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:55,370][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,370][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:44:55,371][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:44:55,371][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:44:55,372][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:44:55,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:44:55,382][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:44:55,412][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:44:55,417][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:45:03,072][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,073][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,074][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-08 16:45:03,074][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-08 16:45:03,074][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-08 16:45:03,074][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-08 16:45:03,075][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 16:45:24,120][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:45:24,122][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:45:24,544][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:45:25,926][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 881 @ 42219 updates)
[2024-10-08 16:45:25,928][fairseq.trainer][INFO] - loading train data for epoch 881
[2024-10-08 16:45:26,281][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-08 16:45:32,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:45:32,946][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:45:32,947][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:45:39,325][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:45:39,389][fairseq.trainer][INFO] - begin training epoch 881
[2024-10-08 16:45:39,390][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:53:59,302][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 
[2024-10-08 16:53:59,351][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3607 MiB |   3608 MiB |   4888 MiB |   1281 MiB |
|       from large pool |   3565 MiB |   3565 MiB |   4755 MiB |   1190 MiB |
|       from small pool |     41 MiB |    102 MiB |    133 MiB |     91 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3607 MiB |   3608 MiB |   4888 MiB |   1281 MiB |
|       from large pool |   3565 MiB |   3565 MiB |   4755 MiB |   1190 MiB |
|       from small pool |     41 MiB |    102 MiB |    133 MiB |     91 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3592 MiB |   3593 MiB |   4870 MiB |   1277 MiB |
|       from large pool |   3551 MiB |   3551 MiB |   4738 MiB |   1186 MiB |
|       from small pool |     41 MiB |    101 MiB |    132 MiB |     91 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   3724 MiB |   3724 MiB |   3724 MiB |      0 B   |
|       from large pool |   3620 MiB |   3620 MiB |   3620 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 119671 KiB | 288129 KiB |   1314 MiB |   1197 MiB |
|       from large pool |  55726 KiB | 223378 KiB |   1121 MiB |   1067 MiB |
|       from small pool |  63945 KiB |  69388 KiB |    192 MiB |    130 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1940    |    2633    |    2797    |     857    |
|       from large pool |     149    |     149    |     173    |      24    |
|       from small pool |    1791    |    2555    |    2624    |     833    |
|---------------------------------------------------------------------------|
| Active allocs         |    1940    |    2633    |    2797    |     857    |
|       from large pool |     149    |     149    |     173    |      24    |
|       from small pool |    1791    |    2555    |    2624    |     833    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     105    |     105    |     105    |       0    |
|       from large pool |      53    |      53    |      53    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     251    |     253    |     512    |     261    |
|       from large pool |      26    |      28    |      51    |      25    |
|       from small pool |     225    |     227    |     461    |     236    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,352][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,353][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,354][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,365][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,365][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,371][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,371][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:53:59,372][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-08 16:54:02,225][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 
[2024-10-08 16:54:02,226][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1884 MiB |   1895 MiB |   2069 MiB | 189257 KiB |
|       from large pool |   1846 MiB |   1857 MiB |   1959 MiB | 116002 KiB |
|       from small pool |     38 MiB |    102 MiB |    109 MiB |  73255 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1884 MiB |   1895 MiB |   2069 MiB | 189257 KiB |
|       from large pool |   1846 MiB |   1857 MiB |   1959 MiB | 116002 KiB |
|       from small pool |     38 MiB |    102 MiB |    109 MiB |  73255 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1876 MiB |   1887 MiB |   2061 MiB | 189165 KiB |
|       from large pool |   1838 MiB |   1849 MiB |   1952 MiB | 116002 KiB |
|       from small pool |     37 MiB |    101 MiB |    109 MiB |  73163 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   2008 MiB |   2008 MiB |   2008 MiB |      0 B   |
|       from large pool |   1904 MiB |   1904 MiB |   1904 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 114323 KiB | 115511 KiB | 413658 KiB | 299335 KiB |
|       from large pool |  46790 KiB |  47978 KiB | 236659 KiB | 189869 KiB |
|       from small pool |  67533 KiB |  69388 KiB | 176999 KiB | 109465 KiB |
|---------------------------------------------------------------------------|
| Allocations           |    1872    |    2633    |    2686    |     814    |
|       from large pool |      99    |     100    |     104    |       5    |
|       from small pool |    1773    |    2555    |    2582    |     809    |
|---------------------------------------------------------------------------|
| Active allocs         |    1872    |    2633    |    2686    |     814    |
|       from large pool |      99    |     100    |     104    |       5    |
|       from small pool |    1773    |    2555    |    2582    |     809    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      83    |      83    |      83    |       0    |
|       from large pool |      31    |      31    |      31    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     244    |     245    |     490    |     246    |
|       from large pool |      19    |      20    |      33    |      14    |
|       from small pool |     225    |     227    |     457    |     232    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,226][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,227][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,227][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,228][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,228][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,228][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,229][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:54:02,229][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-08 16:55:51,580][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 
[2024-10-08 16:55:51,590][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7050 MiB |   7410 MiB |  37997 MiB |  30947 MiB |
|       from large pool |   6996 MiB |   7356 MiB |  37623 MiB |  30627 MiB |
|       from small pool |     54 MiB |    103 MiB |    373 MiB |    319 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   7050 MiB |   7410 MiB |  37997 MiB |  30947 MiB |
|       from large pool |   6996 MiB |   7356 MiB |  37623 MiB |  30627 MiB |
|       from small pool |     54 MiB |    103 MiB |    373 MiB |    319 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7032 MiB |   7391 MiB |  37864 MiB |  30831 MiB |
|       from large pool |   6978 MiB |   7337 MiB |  37491 MiB |  30512 MiB |
|       from small pool |     53 MiB |    102 MiB |    372 MiB |    319 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   7666 MiB |   7666 MiB |  11766 MiB |   4100 MiB |
|       from large pool |   7562 MiB |   7562 MiB |  11662 MiB |   4100 MiB |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 261829 KiB |   1723 MiB |  18273 MiB |  18017 MiB |
|       from large pool | 210896 KiB |   1676 MiB |  17764 MiB |  17558 MiB |
|       from small pool |  50933 KiB |     68 MiB |    509 MiB |    459 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    3149    |    4247    |    8167    |    5018    |
|       from large pool |     239    |     241    |     936    |     697    |
|       from small pool |    2910    |    4165    |    7231    |    4321    |
|---------------------------------------------------------------------------|
| Active allocs         |    3149    |    4247    |    8167    |    5018    |
|       from large pool |     239    |     241    |     936    |     697    |
|       from small pool |    2910    |    4165    |    7231    |    4321    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     121    |     121    |     160    |      39    |
|       from large pool |      69    |      69    |     108    |      39    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     385    |     386    |    1901    |    1516    |
|       from large pool |      35    |      36    |     433    |     398    |
|       from small pool |     350    |     354    |    1468    |    1118    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,590][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,591][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,591][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,591][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,592][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,592][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,592][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-08 16:55:51,592][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-08 16:56:11,981][fairseq_cli.train][INFO] - end of epoch 881 (average epoch stats below)
[2024-10-08 16:56:12,245][train][INFO] - {"epoch": 881, "train_loss": "0.558", "train_ntokens": "260680", "train_nsentences": "1750.04", "train_wps": "42444.5", "train_ups": "0.16", "train_wpb": "260680", "train_bsz": "1750", "train_num_updates": "42267", "train_lr": "0.00048605", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "350", "train_gb_free": "40.1", "train_wall": "803"}
[2024-10-08 16:56:13,517][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 16:56:13,626][fairseq.trainer][INFO] - begin training epoch 882
[2024-10-08 16:56:13,628][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:04:14,356][fairseq_cli.train][INFO] - end of epoch 882 (average epoch stats below)
[2024-10-08 17:04:14,378][train][INFO] - {"epoch": 882, "train_loss": "0.565", "train_ntokens": "260699", "train_nsentences": "1750.04", "train_wps": "25955.2", "train_ups": "0.1", "train_wpb": "260699", "train_bsz": "1750", "train_num_updates": "42315", "train_lr": "0.000485985", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "84", "train_gb_free": "39.7", "train_wall": "1285"}
[2024-10-08 17:04:14,639][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:04:14,648][fairseq.trainer][INFO] - begin training epoch 883
[2024-10-08 17:04:14,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:07:59,925][fairseq_cli.train][INFO] - end of epoch 883 (average epoch stats below)
[2024-10-08 17:07:59,929][train][INFO] - {"epoch": 883, "train_loss": "0.553", "train_ntokens": "260755", "train_nsentences": "1750.04", "train_wps": "55493.1", "train_ups": "0.21", "train_wpb": "260755", "train_bsz": "1750", "train_num_updates": "42363", "train_lr": "0.00048592", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "39.8", "train_wall": "1511"}
[2024-10-08 17:08:00,208][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:08:00,222][fairseq.trainer][INFO] - begin training epoch 884
[2024-10-08 17:08:00,222][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:11:58,804][train_inner][INFO] - {"epoch": 884, "update": 883.771, "loss": "0.559", "ntokens": "260809", "nsentences": "1754.12", "wps": "38003.8", "ups": "0.15", "wpb": "260809", "bsz": "1754.1", "num_updates": "42400", "lr": "0.00048587", "gnorm": "0.393", "loss_scale": "2", "train_wall": "601", "gb_free": "39.3", "wall": "1749"}
[2024-10-08 17:12:11,003][fairseq_cli.train][INFO] - end of epoch 884 (average epoch stats below)
[2024-10-08 17:12:11,005][train][INFO] - {"epoch": 884, "train_loss": "0.559", "train_ntokens": "260832", "train_nsentences": "1750.04", "train_wps": "49865.5", "train_ups": "0.19", "train_wpb": "260832", "train_bsz": "1750", "train_num_updates": "42411", "train_lr": "0.000485855", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "129", "train_gb_free": "40.6", "train_wall": "1762"}
[2024-10-08 17:12:11,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:12:11,377][fairseq.trainer][INFO] - begin training epoch 885
[2024-10-08 17:12:11,377][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:16:30,904][fairseq_cli.train][INFO] - end of epoch 885 (average epoch stats below)
[2024-10-08 17:16:30,922][train][INFO] - {"epoch": 885, "train_loss": "0.567", "train_ntokens": "260638", "train_nsentences": "1750.04", "train_wps": "48133.6", "train_ups": "0.18", "train_wpb": "260638", "train_bsz": "1750", "train_num_updates": "42459", "train_lr": "0.000485789", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "2022"}
[2024-10-08 17:16:31,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:16:31,205][fairseq.trainer][INFO] - begin training epoch 886
[2024-10-08 17:16:31,206][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:20:23,728][fairseq_cli.train][INFO] - end of epoch 886 (average epoch stats below)
[2024-10-08 17:20:23,736][train][INFO] - {"epoch": 886, "train_loss": "0.564", "train_ntokens": "260799", "train_nsentences": "1750.04", "train_wps": "53770.2", "train_ups": "0.21", "train_wpb": "260799", "train_bsz": "1750", "train_num_updates": "42507", "train_lr": "0.000485724", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.7", "train_wall": "2254"}
[2024-10-08 17:20:23,944][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:20:23,975][fairseq.trainer][INFO] - begin training epoch 887
[2024-10-08 17:20:23,975][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:23:01,181][fairseq_cli.train][INFO] - end of epoch 887 (average epoch stats below)
[2024-10-08 17:23:01,195][train][INFO] - {"epoch": 887, "train_loss": "0.56", "train_ntokens": "260627", "train_nsentences": "1750.04", "train_wps": "79455.8", "train_ups": "0.3", "train_wpb": "260627", "train_bsz": "1750", "train_num_updates": "42555", "train_lr": "0.000485659", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "39.7", "train_wall": "2412"}
[2024-10-08 17:23:01,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:23:01,307][fairseq.trainer][INFO] - begin training epoch 888
[2024-10-08 17:23:01,307][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:25:09,262][train_inner][INFO] - {"epoch": 888, "update": 887.938, "loss": "0.564", "ntokens": "260629", "nsentences": "1745.67", "wps": "65944.3", "ups": "0.25", "wpb": "260629", "bsz": "1745.7", "num_updates": "42600", "lr": "0.000485598", "gnorm": "0.395", "loss_scale": "2", "train_wall": "217", "gb_free": "40.1", "wall": "2540"}
[2024-10-08 17:25:09,954][fairseq_cli.train][INFO] - end of epoch 888 (average epoch stats below)
[2024-10-08 17:25:09,960][train][INFO] - {"epoch": 888, "train_loss": "0.566", "train_ntokens": "260687", "train_nsentences": "1750.04", "train_wps": "97181", "train_ups": "0.37", "train_wpb": "260687", "train_bsz": "1750", "train_num_updates": "42603", "train_lr": "0.000485594", "train_gnorm": "0.409", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "39.7", "train_wall": "2541"}
[2024-10-08 17:25:10,095][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:25:10,099][fairseq.trainer][INFO] - begin training epoch 889
[2024-10-08 17:25:10,099][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:27:17,047][fairseq_cli.train][INFO] - end of epoch 889 (average epoch stats below)
[2024-10-08 17:27:17,055][train][INFO] - {"epoch": 889, "train_loss": "0.562", "train_ntokens": "260566", "train_nsentences": "1750.04", "train_wps": "98411.8", "train_ups": "0.38", "train_wpb": "260566", "train_bsz": "1750", "train_num_updates": "42651", "train_lr": "0.000485529", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "39.2", "train_wall": "2668"}
[2024-10-08 17:27:17,167][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:27:17,188][fairseq.trainer][INFO] - begin training epoch 890
[2024-10-08 17:27:17,189][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:31:04,995][fairseq_cli.train][INFO] - end of epoch 890 (average epoch stats below)
[2024-10-08 17:31:05,008][train][INFO] - {"epoch": 890, "train_loss": "0.551", "train_ntokens": "260907", "train_nsentences": "1750.04", "train_wps": "54941", "train_ups": "0.21", "train_wpb": "260907", "train_bsz": "1750", "train_num_updates": "42699", "train_lr": "0.000485463", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.2", "train_wall": "2896"}
[2024-10-08 17:31:05,145][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:31:05,173][fairseq.trainer][INFO] - begin training epoch 891
[2024-10-08 17:31:05,173][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:33:24,989][fairseq_cli.train][INFO] - end of epoch 891 (average epoch stats below)
[2024-10-08 17:33:24,995][train][INFO] - {"epoch": 891, "train_loss": "0.559", "train_ntokens": "260552", "train_nsentences": "1750.04", "train_wps": "89342", "train_ups": "0.34", "train_wpb": "260552", "train_bsz": "1750", "train_num_updates": "42747", "train_lr": "0.000485398", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.7", "train_wall": "3036"}
[2024-10-08 17:33:25,169][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:33:25,182][fairseq.trainer][INFO] - begin training epoch 892
[2024-10-08 17:33:25,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:35:48,189][fairseq_cli.train][INFO] - end of epoch 892 (average epoch stats below)
[2024-10-08 17:35:48,196][train][INFO] - {"epoch": 892, "train_loss": "0.558", "train_ntokens": "260816", "train_nsentences": "1750.04", "train_wps": "87425.8", "train_ups": "0.34", "train_wpb": "260816", "train_bsz": "1750", "train_num_updates": "42795", "train_lr": "0.000485333", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "30", "train_gb_free": "39.7", "train_wall": "3179"}
[2024-10-08 17:35:48,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:35:48,450][fairseq.trainer][INFO] - begin training epoch 893
[2024-10-08 17:35:48,450][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:37:35,552][train_inner][INFO] - {"epoch": 893, "update": 892.104, "loss": "0.558", "ntokens": "260714", "nsentences": "1746.98", "wps": "69870.8", "ups": "0.27", "wpb": "260714", "bsz": "1747", "num_updates": "42800", "lr": "0.000485326", "gnorm": "0.387", "loss_scale": "2", "train_wall": "206", "gb_free": "39.7", "wall": "3286"}
[2024-10-08 17:38:12,010][fairseq_cli.train][INFO] - end of epoch 893 (average epoch stats below)
[2024-10-08 17:38:12,012][train][INFO] - {"epoch": 893, "train_loss": "0.559", "train_ntokens": "260627", "train_nsentences": "1750.04", "train_wps": "86988.8", "train_ups": "0.33", "train_wpb": "260627", "train_bsz": "1750", "train_num_updates": "42843", "train_lr": "0.000485268", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "47", "train_gb_free": "39.7", "train_wall": "3323"}
[2024-10-08 17:38:12,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:38:12,183][fairseq.trainer][INFO] - begin training epoch 894
[2024-10-08 17:38:12,183][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:40:29,624][fairseq_cli.train][INFO] - end of epoch 894 (average epoch stats below)
[2024-10-08 17:40:29,627][train][INFO] - {"epoch": 894, "train_loss": "0.557", "train_ntokens": "260277", "train_nsentences": "1750.04", "train_wps": "90786.1", "train_ups": "0.35", "train_wpb": "260277", "train_bsz": "1750", "train_num_updates": "42891", "train_lr": "0.000485202", "train_gnorm": "0.404", "train_loss_scale": "2", "train_train_wall": "34", "train_gb_free": "40", "train_wall": "3460"}
[2024-10-08 17:40:29,706][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:40:29,731][fairseq.trainer][INFO] - begin training epoch 895
[2024-10-08 17:40:29,731][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:42:41,354][fairseq_cli.train][INFO] - end of epoch 895 (average epoch stats below)
[2024-10-08 17:42:41,375][train][INFO] - {"epoch": 895, "train_loss": "0.559", "train_ntokens": "260655", "train_nsentences": "1750.04", "train_wps": "94966.8", "train_ups": "0.36", "train_wpb": "260655", "train_bsz": "1750", "train_num_updates": "42939", "train_lr": "0.000485137", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.7", "train_wall": "3592"}
[2024-10-08 17:42:41,486][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:42:41,499][fairseq.trainer][INFO] - begin training epoch 896
[2024-10-08 17:42:41,500][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:44:51,762][fairseq_cli.train][INFO] - end of epoch 896 (average epoch stats below)
[2024-10-08 17:44:51,774][train][INFO] - {"epoch": 896, "train_loss": "0.554", "train_ntokens": "260335", "train_nsentences": "1750.04", "train_wps": "95831", "train_ups": "0.37", "train_wpb": "260335", "train_bsz": "1750", "train_num_updates": "42987", "train_lr": "0.000485072", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "40.3", "train_wall": "3722"}
[2024-10-08 17:44:51,889][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:44:51,919][fairseq.trainer][INFO] - begin training epoch 897
[2024-10-08 17:44:51,920][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:46:57,662][train_inner][INFO] - {"epoch": 897, "update": 896.271, "loss": "0.557", "ntokens": "260398", "nsentences": "1770.26", "wps": "92651.4", "ups": "0.36", "wpb": "260398", "bsz": "1770.3", "num_updates": "43000", "lr": "0.000485054", "gnorm": "0.394", "loss_scale": "2", "train_wall": "213", "gb_free": "39.2", "wall": "3848"}
[2024-10-08 17:47:19,170][fairseq_cli.train][INFO] - end of epoch 897 (average epoch stats below)
[2024-10-08 17:47:19,172][train][INFO] - {"epoch": 897, "train_loss": "0.551", "train_ntokens": "260750", "train_nsentences": "1750.04", "train_wps": "84914", "train_ups": "0.33", "train_wpb": "260750", "train_bsz": "1750", "train_num_updates": "43035", "train_lr": "0.000485007", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.6", "train_wall": "3870"}
[2024-10-08 17:47:19,345][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:47:19,381][fairseq.trainer][INFO] - begin training epoch 898
[2024-10-08 17:47:19,381][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:49:45,826][fairseq_cli.train][INFO] - end of epoch 898 (average epoch stats below)
[2024-10-08 17:49:45,833][train][INFO] - {"epoch": 898, "train_loss": "0.556", "train_ntokens": "260959", "train_nsentences": "1750.04", "train_wps": "85410", "train_ups": "0.33", "train_wpb": "260959", "train_bsz": "1750", "train_num_updates": "43083", "train_lr": "0.000484942", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.7", "train_wall": "4016"}
[2024-10-08 17:49:45,967][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:49:45,972][fairseq.trainer][INFO] - begin training epoch 899
[2024-10-08 17:49:45,972][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:52:15,825][fairseq_cli.train][INFO] - end of epoch 899 (average epoch stats below)
[2024-10-08 17:52:15,828][train][INFO] - {"epoch": 899, "train_loss": "0.561", "train_ntokens": "261255", "train_nsentences": "1750.04", "train_wps": "83605.1", "train_ups": "0.32", "train_wpb": "261255", "train_bsz": "1750", "train_num_updates": "43131", "train_lr": "0.000484876", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "40.1", "train_wall": "4166"}
[2024-10-08 17:52:16,119][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:52:16,139][fairseq.trainer][INFO] - begin training epoch 900
[2024-10-08 17:52:16,139][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:56:30,327][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 900 @ 43179 updates
[2024-10-08 17:56:30,328][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 17:56:35,174][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 17:56:35,177][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 900 @ 43179 updates, score None) (writing took 4.850262419320643 seconds)
[2024-10-08 17:56:35,177][fairseq_cli.train][INFO] - end of epoch 900 (average epoch stats below)
[2024-10-08 17:56:35,181][train][INFO] - {"epoch": 900, "train_loss": "0.557", "train_ntokens": "261060", "train_nsentences": "1750.04", "train_wps": "48316.7", "train_ups": "0.19", "train_wpb": "261060", "train_bsz": "1750", "train_num_updates": "43179", "train_lr": "0.000484811", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "27", "train_gb_free": "39.3", "train_wall": "4426"}
[2024-10-08 17:56:35,365][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:56:35,391][fairseq.trainer][INFO] - begin training epoch 901
[2024-10-08 17:56:35,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:59:41,938][train_inner][INFO] - {"epoch": 901, "update": 900.438, "loss": "0.556", "ntokens": "261043", "nsentences": "1736.35", "wps": "68311.7", "ups": "0.26", "wpb": "261043", "bsz": "1736.3", "num_updates": "43200", "lr": "0.000484783", "gnorm": "0.379", "loss_scale": "2", "train_wall": "224", "gb_free": "39.6", "wall": "4613"}
[2024-10-08 17:59:59,390][fairseq_cli.train][INFO] - end of epoch 901 (average epoch stats below)
[2024-10-08 17:59:59,395][train][INFO] - {"epoch": 901, "train_loss": "0.558", "train_ntokens": "260751", "train_nsentences": "1750.04", "train_wps": "61290.5", "train_ups": "0.24", "train_wpb": "260751", "train_bsz": "1750", "train_num_updates": "43227", "train_lr": "0.000484746", "train_gnorm": "0.421", "train_loss_scale": "2", "train_train_wall": "92", "train_gb_free": "40.2", "train_wall": "4630"}
[2024-10-08 17:59:59,549][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 17:59:59,553][fairseq.trainer][INFO] - begin training epoch 902
[2024-10-08 17:59:59,554][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:02:33,966][fairseq_cli.train][INFO] - end of epoch 902 (average epoch stats below)
[2024-10-08 18:02:33,984][train][INFO] - {"epoch": 902, "train_loss": "0.558", "train_ntokens": "260508", "train_nsentences": "1750.04", "train_wps": "80889.4", "train_ups": "0.31", "train_wpb": "260508", "train_bsz": "1750", "train_num_updates": "43275", "train_lr": "0.000484681", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.7", "train_wall": "4785"}
[2024-10-08 18:02:34,160][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:02:34,184][fairseq.trainer][INFO] - begin training epoch 903
[2024-10-08 18:02:34,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:05:36,334][fairseq_cli.train][INFO] - end of epoch 903 (average epoch stats below)
[2024-10-08 18:05:36,344][train][INFO] - {"epoch": 903, "train_loss": "0.555", "train_ntokens": "260772", "train_nsentences": "1750.04", "train_wps": "68642", "train_ups": "0.26", "train_wpb": "260772", "train_bsz": "1750", "train_num_updates": "43323", "train_lr": "0.000484615", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.6", "train_wall": "4967"}
[2024-10-08 18:05:36,549][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:05:36,553][fairseq.trainer][INFO] - begin training epoch 904
[2024-10-08 18:05:36,553][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:07:52,256][fairseq_cli.train][INFO] - end of epoch 904 (average epoch stats below)
[2024-10-08 18:07:52,262][train][INFO] - {"epoch": 904, "train_loss": "0.555", "train_ntokens": "260570", "train_nsentences": "1750.04", "train_wps": "92024", "train_ups": "0.35", "train_wpb": "260570", "train_bsz": "1750", "train_num_updates": "43371", "train_lr": "0.00048455", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.7", "train_wall": "5103"}
[2024-10-08 18:07:52,476][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:07:52,497][fairseq.trainer][INFO] - begin training epoch 905
[2024-10-08 18:07:52,497][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:10:33,841][train_inner][INFO] - {"epoch": 905, "update": 904.604, "loss": "0.556", "ntokens": "260840", "nsentences": "1736.91", "wps": "80024.8", "ups": "0.31", "wpb": "260840", "bsz": "1736.9", "num_updates": "43400", "lr": "0.000484511", "gnorm": "0.403", "loss_scale": "2", "train_wall": "277", "gb_free": "39.3", "wall": "5264"}
[2024-10-08 18:10:47,462][fairseq_cli.train][INFO] - end of epoch 905 (average epoch stats below)
[2024-10-08 18:10:47,478][train][INFO] - {"epoch": 905, "train_loss": "0.556", "train_ntokens": "260633", "train_nsentences": "1750.04", "train_wps": "71406.2", "train_ups": "0.27", "train_wpb": "260633", "train_bsz": "1750", "train_num_updates": "43419", "train_lr": "0.000484485", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.8", "train_wall": "5278"}
[2024-10-08 18:10:48,100][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:10:48,104][fairseq.trainer][INFO] - begin training epoch 906
[2024-10-08 18:10:48,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:15:04,507][fairseq_cli.train][INFO] - end of epoch 906 (average epoch stats below)
[2024-10-08 18:15:04,513][train][INFO] - {"epoch": 906, "train_loss": "0.551", "train_ntokens": "260656", "train_nsentences": "1750.04", "train_wps": "48676.9", "train_ups": "0.19", "train_wpb": "260656", "train_bsz": "1750", "train_num_updates": "43467", "train_lr": "0.00048442", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "39.6", "train_wall": "5535"}
[2024-10-08 18:15:04,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:15:04,693][fairseq.trainer][INFO] - begin training epoch 907
[2024-10-08 18:15:04,694][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:17:53,238][fairseq_cli.train][INFO] - end of epoch 907 (average epoch stats below)
[2024-10-08 18:17:53,244][train][INFO] - {"epoch": 907, "train_loss": "0.548", "train_ntokens": "260291", "train_nsentences": "1750.04", "train_wps": "74048", "train_ups": "0.28", "train_wpb": "260291", "train_bsz": "1750", "train_num_updates": "43515", "train_lr": "0.000484355", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "5704"}
[2024-10-08 18:17:53,424][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:17:53,444][fairseq.trainer][INFO] - begin training epoch 908
[2024-10-08 18:17:53,445][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:23:00,347][fairseq_cli.train][INFO] - end of epoch 908 (average epoch stats below)
[2024-10-08 18:23:00,354][train][INFO] - {"epoch": 908, "train_loss": "0.552", "train_ntokens": "260653", "train_nsentences": "1750.04", "train_wps": "40739.3", "train_ups": "0.16", "train_wpb": "260653", "train_bsz": "1750", "train_num_updates": "43563", "train_lr": "0.000484289", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.5", "train_wall": "6011"}
[2024-10-08 18:23:00,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:23:00,653][fairseq.trainer][INFO] - begin training epoch 909
[2024-10-08 18:23:00,653][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:25:29,960][train_inner][INFO] - {"epoch": 909, "update": 908.771, "loss": "0.553", "ntokens": "260426", "nsentences": "1769.22", "wps": "58123.4", "ups": "0.22", "wpb": "260426", "bsz": "1769.2", "num_updates": "43600", "lr": "0.000484239", "gnorm": "0.396", "loss_scale": "2", "train_wall": "243", "gb_free": "39.3", "wall": "6161"}
[2024-10-08 18:25:43,807][fairseq_cli.train][INFO] - end of epoch 909 (average epoch stats below)
[2024-10-08 18:25:43,810][train][INFO] - {"epoch": 909, "train_loss": "0.552", "train_ntokens": "261103", "train_nsentences": "1750.04", "train_wps": "76676.3", "train_ups": "0.29", "train_wpb": "261103", "train_bsz": "1750", "train_num_updates": "43611", "train_lr": "0.000484224", "train_gnorm": "0.414", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.6", "train_wall": "6174"}
[2024-10-08 18:25:43,980][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:25:44,159][fairseq.trainer][INFO] - begin training epoch 910
[2024-10-08 18:25:44,160][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:28:56,691][fairseq_cli.train][INFO] - end of epoch 910 (average epoch stats below)
[2024-10-08 18:28:56,713][train][INFO] - {"epoch": 910, "train_loss": "0.552", "train_ntokens": "260708", "train_nsentences": "1750.04", "train_wps": "64872.9", "train_ups": "0.25", "train_wpb": "260708", "train_bsz": "1750", "train_num_updates": "43659", "train_lr": "0.000484159", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "39.3", "train_wall": "6367"}
[2024-10-08 18:28:56,850][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:28:56,852][fairseq.trainer][INFO] - begin training epoch 911
[2024-10-08 18:28:56,853][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:35:10,360][fairseq_cli.train][INFO] - end of epoch 911 (average epoch stats below)
[2024-10-08 18:35:10,366][train][INFO] - {"epoch": 911, "train_loss": "0.55", "train_ntokens": "261018", "train_nsentences": "1750.04", "train_wps": "33530.9", "train_ups": "0.13", "train_wpb": "261018", "train_bsz": "1750", "train_num_updates": "43707", "train_lr": "0.000484094", "train_gnorm": "0.416", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.6", "train_wall": "6741"}
[2024-10-08 18:35:10,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:35:10,825][fairseq.trainer][INFO] - begin training epoch 912
[2024-10-08 18:35:10,826][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:39:07,705][fairseq_cli.train][INFO] - end of epoch 912 (average epoch stats below)
[2024-10-08 18:39:07,715][train][INFO] - {"epoch": 912, "train_loss": "0.553", "train_ntokens": "260733", "train_nsentences": "1750.04", "train_wps": "52730.2", "train_ups": "0.2", "train_wpb": "260733", "train_bsz": "1750", "train_num_updates": "43755", "train_lr": "0.000484029", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.3", "train_wall": "6978"}
[2024-10-08 18:39:07,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:39:07,916][fairseq.trainer][INFO] - begin training epoch 913
[2024-10-08 18:39:07,917][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:42:59,115][train_inner][INFO] - {"epoch": 913, "update": 912.938, "loss": "0.551", "ntokens": "260871", "nsentences": "1745.14", "wps": "49730.5", "ups": "0.19", "wpb": "260871", "bsz": "1745.1", "num_updates": "43800", "lr": "0.000483967", "gnorm": "0.393", "loss_scale": "2", "train_wall": "297", "gb_free": "39.8", "wall": "7210"}
[2024-10-08 18:42:59,865][fairseq_cli.train][INFO] - end of epoch 913 (average epoch stats below)
[2024-10-08 18:42:59,871][train][INFO] - {"epoch": 913, "train_loss": "0.549", "train_ntokens": "260783", "train_nsentences": "1750.04", "train_wps": "53920.3", "train_ups": "0.21", "train_wpb": "260783", "train_bsz": "1750", "train_num_updates": "43803", "train_lr": "0.000483963", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "80", "train_gb_free": "40.2", "train_wall": "7211"}
[2024-10-08 18:43:00,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:43:00,108][fairseq.trainer][INFO] - begin training epoch 914
[2024-10-08 18:43:00,109][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:48:18,708][fairseq_cli.train][INFO] - end of epoch 914 (average epoch stats below)
[2024-10-08 18:48:18,719][train][INFO] - {"epoch": 914, "train_loss": "0.547", "train_ntokens": "260665", "train_nsentences": "1750.04", "train_wps": "39242.8", "train_ups": "0.15", "train_wpb": "260665", "train_bsz": "1750", "train_num_updates": "43851", "train_lr": "0.000483898", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "40.3", "train_wall": "7529"}
[2024-10-08 18:48:18,932][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:48:18,967][fairseq.trainer][INFO] - begin training epoch 915
[2024-10-08 18:48:18,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:52:08,052][fairseq_cli.train][INFO] - end of epoch 915 (average epoch stats below)
[2024-10-08 18:52:08,066][train][INFO] - {"epoch": 915, "train_loss": "0.551", "train_ntokens": "260791", "train_nsentences": "1750.04", "train_wps": "54581.3", "train_ups": "0.21", "train_wpb": "260791", "train_bsz": "1750", "train_num_updates": "43899", "train_lr": "0.000483833", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "101", "train_gb_free": "41.2", "train_wall": "7759"}
[2024-10-08 18:52:08,426][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:52:08,431][fairseq.trainer][INFO] - begin training epoch 916
[2024-10-08 18:52:08,432][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:56:31,500][fairseq_cli.train][INFO] - end of epoch 916 (average epoch stats below)
[2024-10-08 18:56:31,506][train][INFO] - {"epoch": 916, "train_loss": "0.555", "train_ntokens": "260637", "train_nsentences": "1750.04", "train_wps": "47489.9", "train_ups": "0.18", "train_wpb": "260637", "train_bsz": "1750", "train_num_updates": "43947", "train_lr": "0.000483768", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "39.2", "train_wall": "8022"}
[2024-10-08 18:56:31,685][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 18:56:31,688][fairseq.trainer][INFO] - begin training epoch 917
[2024-10-08 18:56:31,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:00:30,550][fairseq_cli.train][INFO] - end of epoch 917 (average epoch stats below)
[2024-10-08 19:00:30,559][train][INFO] - {"epoch": 917, "train_loss": "0.551", "train_ntokens": "260587", "train_nsentences": "1750.04", "train_wps": "52324.4", "train_ups": "0.2", "train_wpb": "260587", "train_bsz": "1750", "train_num_updates": "43995", "train_lr": "0.000483702", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.2", "train_wall": "8261"}
[2024-10-08 19:00:30,780][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:00:30,794][fairseq.trainer][INFO] - begin training epoch 918
[2024-10-08 19:00:30,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:02:23,906][train_inner][INFO] - {"epoch": 918, "update": 917.104, "loss": "0.551", "ntokens": "260752", "nsentences": "1744.71", "wps": "44772.6", "ups": "0.17", "wpb": "260752", "bsz": "1744.7", "num_updates": "44000", "lr": "0.000483696", "gnorm": "0.392", "loss_scale": "2", "train_wall": "276", "gb_free": "39.6", "wall": "8375"}
[2024-10-08 19:02:58,058][fairseq_cli.train][INFO] - end of epoch 918 (average epoch stats below)
[2024-10-08 19:02:58,061][train][INFO] - {"epoch": 918, "train_loss": "0.544", "train_ntokens": "260875", "train_nsentences": "1750.04", "train_wps": "84895.7", "train_ups": "0.33", "train_wpb": "260875", "train_bsz": "1750", "train_num_updates": "44043", "train_lr": "0.000483637", "train_gnorm": "0.367", "train_loss_scale": "2", "train_train_wall": "36", "train_gb_free": "40.7", "train_wall": "8409"}
[2024-10-08 19:02:58,454][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:02:58,458][fairseq.trainer][INFO] - begin training epoch 919
[2024-10-08 19:02:58,459][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:05:31,992][fairseq_cli.train][INFO] - end of epoch 919 (average epoch stats below)
[2024-10-08 19:05:31,995][train][INFO] - {"epoch": 919, "train_loss": "0.547", "train_ntokens": "260558", "train_nsentences": "1750.04", "train_wps": "81248.8", "train_ups": "0.31", "train_wpb": "260558", "train_bsz": "1750", "train_num_updates": "44091", "train_lr": "0.000483572", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40", "train_wall": "8563"}
[2024-10-08 19:05:32,356][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:05:32,395][fairseq.trainer][INFO] - begin training epoch 920
[2024-10-08 19:05:32,399][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:11:32,267][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 920 @ 44139 updates
[2024-10-08 19:11:32,270][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 19:11:37,256][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 19:11:37,258][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 920 @ 44139 updates, score None) (writing took 4.991886477917433 seconds)
[2024-10-08 19:11:37,259][fairseq_cli.train][INFO] - end of epoch 920 (average epoch stats below)
[2024-10-08 19:11:37,262][train][INFO] - {"epoch": 920, "train_loss": "0.551", "train_ntokens": "260651", "train_nsentences": "1750.04", "train_wps": "34252.7", "train_ups": "0.13", "train_wpb": "260651", "train_bsz": "1750", "train_num_updates": "44139", "train_lr": "0.000483507", "train_gnorm": "0.412", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.7", "train_wall": "8928"}
[2024-10-08 19:11:37,479][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:11:37,503][fairseq.trainer][INFO] - begin training epoch 921
[2024-10-08 19:11:37,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:17:17,855][fairseq_cli.train][INFO] - end of epoch 921 (average epoch stats below)
[2024-10-08 19:17:17,868][train][INFO] - {"epoch": 921, "train_loss": "0.55", "train_ntokens": "260689", "train_nsentences": "1750.04", "train_wps": "36738.1", "train_ups": "0.14", "train_wpb": "260689", "train_bsz": "1750", "train_num_updates": "44187", "train_lr": "0.000483442", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "40.1", "train_wall": "9269"}
[2024-10-08 19:17:18,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:17:18,190][fairseq.trainer][INFO] - begin training epoch 922
[2024-10-08 19:17:18,191][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:21:11,222][train_inner][INFO] - {"epoch": 922, "update": 921.271, "loss": "0.548", "ntokens": "260501", "nsentences": "1758.16", "wps": "46216.4", "ups": "0.18", "wpb": "260501", "bsz": "1758.2", "num_updates": "44200", "lr": "0.000483424", "gnorm": "0.401", "loss_scale": "2", "train_wall": "265", "gb_free": "41", "wall": "9502"}
[2024-10-08 19:21:38,033][fairseq_cli.train][INFO] - end of epoch 922 (average epoch stats below)
[2024-10-08 19:21:38,035][train][INFO] - {"epoch": 922, "train_loss": "0.544", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "48117.6", "train_ups": "0.18", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "44235", "train_lr": "0.000483376", "train_gnorm": "0.424", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.6", "train_wall": "9529"}
[2024-10-08 19:21:38,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:21:38,304][fairseq.trainer][INFO] - begin training epoch 923
[2024-10-08 19:21:38,305][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:26:14,131][fairseq_cli.train][INFO] - end of epoch 923 (average epoch stats below)
[2024-10-08 19:26:14,148][train][INFO] - {"epoch": 923, "train_loss": "0.552", "train_ntokens": "260511", "train_nsentences": "1750.04", "train_wps": "45288.4", "train_ups": "0.17", "train_wpb": "260511", "train_bsz": "1750", "train_num_updates": "44283", "train_lr": "0.000483311", "train_gnorm": "0.39", "train_loss_scale": "4", "train_train_wall": "89", "train_gb_free": "39.8", "train_wall": "9805"}
[2024-10-08 19:26:14,352][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:26:14,396][fairseq.trainer][INFO] - begin training epoch 924
[2024-10-08 19:26:14,397][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:31:02,594][fairseq_cli.train][INFO] - end of epoch 924 (average epoch stats below)
[2024-10-08 19:31:02,614][train][INFO] - {"epoch": 924, "train_loss": "0.548", "train_ntokens": "260871", "train_nsentences": "1750.04", "train_wps": "43408.5", "train_ups": "0.17", "train_wpb": "260871", "train_bsz": "1750", "train_num_updates": "44331", "train_lr": "0.000483246", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "164", "train_gb_free": "40.3", "train_wall": "10093"}
[2024-10-08 19:31:02,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:31:02,943][fairseq.trainer][INFO] - begin training epoch 925
[2024-10-08 19:31:02,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:36:22,073][fairseq_cli.train][INFO] - end of epoch 925 (average epoch stats below)
[2024-10-08 19:36:22,085][train][INFO] - {"epoch": 925, "train_loss": "0.546", "train_ntokens": "260796", "train_nsentences": "1750.04", "train_wps": "39184.7", "train_ups": "0.15", "train_wpb": "260796", "train_bsz": "1750", "train_num_updates": "44379", "train_lr": "0.000483181", "train_gnorm": "0.429", "train_loss_scale": "4", "train_train_wall": "107", "train_gb_free": "39.8", "train_wall": "10413"}
[2024-10-08 19:36:22,332][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:36:22,345][fairseq.trainer][INFO] - begin training epoch 926
[2024-10-08 19:36:22,346][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:41:42,815][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 19:41:46,277][train_inner][INFO] - {"epoch": 926, "update": 925.458, "loss": "0.548", "ntokens": "260832", "nsentences": "1752.27", "wps": "42239.6", "ups": "0.16", "wpb": "260832", "bsz": "1752.3", "num_updates": "44400", "lr": "0.000483152", "gnorm": "0.406", "loss_scale": "2", "train_wall": "461", "gb_free": "39.8", "wall": "10737"}
[2024-10-08 19:42:00,992][fairseq_cli.train][INFO] - end of epoch 926 (average epoch stats below)
[2024-10-08 19:42:00,994][train][INFO] - {"epoch": 926, "train_loss": "0.546", "train_ntokens": "261043", "train_nsentences": "1767.09", "train_wps": "36201.8", "train_ups": "0.14", "train_wpb": "261043", "train_bsz": "1767.1", "train_num_updates": "44426", "train_lr": "0.000483117", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "90", "train_gb_free": "39.7", "train_wall": "10752"}
[2024-10-08 19:42:01,175][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:42:01,188][fairseq.trainer][INFO] - begin training epoch 927
[2024-10-08 19:42:01,189][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:47:24,846][fairseq_cli.train][INFO] - end of epoch 927 (average epoch stats below)
[2024-10-08 19:47:24,859][train][INFO] - {"epoch": 927, "train_loss": "0.546", "train_ntokens": "261033", "train_nsentences": "1750.04", "train_wps": "38687.9", "train_ups": "0.15", "train_wpb": "261033", "train_bsz": "1750", "train_num_updates": "44474", "train_lr": "0.000483052", "train_gnorm": "0.414", "train_loss_scale": "2", "train_train_wall": "93", "train_gb_free": "40.3", "train_wall": "11076"}
[2024-10-08 19:47:25,136][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:47:25,158][fairseq.trainer][INFO] - begin training epoch 928
[2024-10-08 19:47:25,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:52:22,370][fairseq_cli.train][INFO] - end of epoch 928 (average epoch stats below)
[2024-10-08 19:52:22,378][train][INFO] - {"epoch": 928, "train_loss": "0.551", "train_ntokens": "260824", "train_nsentences": "1750.04", "train_wps": "42080.5", "train_ups": "0.16", "train_wpb": "260824", "train_bsz": "1750", "train_num_updates": "44522", "train_lr": "0.000482986", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.3", "train_wall": "11373"}
[2024-10-08 19:52:22,605][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:52:22,614][fairseq.trainer][INFO] - begin training epoch 929
[2024-10-08 19:52:22,614][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:56:37,760][fairseq_cli.train][INFO] - end of epoch 929 (average epoch stats below)
[2024-10-08 19:56:37,776][train][INFO] - {"epoch": 929, "train_loss": "0.547", "train_ntokens": "260489", "train_nsentences": "1750.04", "train_wps": "48957.3", "train_ups": "0.19", "train_wpb": "260489", "train_bsz": "1750", "train_num_updates": "44570", "train_lr": "0.000482921", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.3", "train_wall": "11628"}
[2024-10-08 19:56:37,991][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 19:56:38,007][fairseq.trainer][INFO] - begin training epoch 930
[2024-10-08 19:56:38,008][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:59:52,199][train_inner][INFO] - {"epoch": 930, "update": 929.625, "loss": "0.547", "ntokens": "260806", "nsentences": "1747.58", "wps": "48034.2", "ups": "0.18", "wpb": "260806", "bsz": "1747.6", "num_updates": "44600", "lr": "0.00048288", "gnorm": "0.401", "loss_scale": "2", "train_wall": "286", "gb_free": "39.3", "wall": "11823"}
[2024-10-08 20:00:04,280][fairseq_cli.train][INFO] - end of epoch 930 (average epoch stats below)
[2024-10-08 20:00:04,285][train][INFO] - {"epoch": 930, "train_loss": "0.544", "train_ntokens": "260866", "train_nsentences": "1750.04", "train_wps": "60636", "train_ups": "0.23", "train_wpb": "260866", "train_bsz": "1750", "train_num_updates": "44618", "train_lr": "0.000482856", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40", "train_wall": "11835"}
[2024-10-08 20:00:04,466][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:00:04,471][fairseq.trainer][INFO] - begin training epoch 931
[2024-10-08 20:00:04,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:03:51,507][fairseq_cli.train][INFO] - end of epoch 931 (average epoch stats below)
[2024-10-08 20:03:51,515][train][INFO] - {"epoch": 931, "train_loss": "0.547", "train_ntokens": "260785", "train_nsentences": "1750.04", "train_wps": "55089.1", "train_ups": "0.21", "train_wpb": "260785", "train_bsz": "1750", "train_num_updates": "44666", "train_lr": "0.000482791", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.3", "train_wall": "12062"}
[2024-10-08 20:03:51,744][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:03:51,748][fairseq.trainer][INFO] - begin training epoch 932
[2024-10-08 20:03:51,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:07:59,870][fairseq_cli.train][INFO] - end of epoch 932 (average epoch stats below)
[2024-10-08 20:07:59,887][train][INFO] - {"epoch": 932, "train_loss": "0.554", "train_ntokens": "261033", "train_nsentences": "1750.04", "train_wps": "50447.5", "train_ups": "0.19", "train_wpb": "261033", "train_bsz": "1750", "train_num_updates": "44714", "train_lr": "0.000482726", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "113", "train_gb_free": "39.8", "train_wall": "12311"}
[2024-10-08 20:08:00,089][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:08:00,123][fairseq.trainer][INFO] - begin training epoch 933
[2024-10-08 20:08:00,124][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:12:19,049][fairseq_cli.train][INFO] - end of epoch 933 (average epoch stats below)
[2024-10-08 20:12:19,055][train][INFO] - {"epoch": 933, "train_loss": "0.541", "train_ntokens": "260586", "train_nsentences": "1750.04", "train_wps": "48263.3", "train_ups": "0.19", "train_wpb": "260586", "train_bsz": "1750", "train_num_updates": "44762", "train_lr": "0.00048266", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.1", "train_wall": "12570"}
[2024-10-08 20:12:19,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:12:19,165][fairseq.trainer][INFO] - begin training epoch 934
[2024-10-08 20:12:19,166][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:16:38,760][train_inner][INFO] - {"epoch": 934, "update": 933.792, "loss": "0.549", "ntokens": "260949", "nsentences": "1738.12", "wps": "51852.6", "ups": "0.2", "wpb": "260949", "bsz": "1738.1", "num_updates": "44800", "lr": "0.000482609", "gnorm": "0.39", "loss_scale": "2", "train_wall": "303", "gb_free": "39.6", "wall": "12829"}
[2024-10-08 20:16:47,481][fairseq_cli.train][INFO] - end of epoch 934 (average epoch stats below)
[2024-10-08 20:16:47,484][train][INFO] - {"epoch": 934, "train_loss": "0.556", "train_ntokens": "260912", "train_nsentences": "1750.04", "train_wps": "46656.3", "train_ups": "0.18", "train_wpb": "260912", "train_bsz": "1750", "train_num_updates": "44810", "train_lr": "0.000482595", "train_gnorm": "0.404", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "40", "train_wall": "12838"}
[2024-10-08 20:16:47,565][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:16:47,570][fairseq.trainer][INFO] - begin training epoch 935
[2024-10-08 20:16:47,570][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:19:20,800][fairseq_cli.train][INFO] - end of epoch 935 (average epoch stats below)
[2024-10-08 20:19:20,809][train][INFO] - {"epoch": 935, "train_loss": "0.542", "train_ntokens": "260894", "train_nsentences": "1750.04", "train_wps": "81676.9", "train_ups": "0.31", "train_wpb": "260894", "train_bsz": "1750", "train_num_updates": "44858", "train_lr": "0.00048253", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "47", "train_gb_free": "39.6", "train_wall": "12991"}
[2024-10-08 20:19:20,944][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:19:20,948][fairseq.trainer][INFO] - begin training epoch 936
[2024-10-08 20:19:20,949][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:21:34,853][fairseq_cli.train][INFO] - end of epoch 936 (average epoch stats below)
[2024-10-08 20:21:34,856][train][INFO] - {"epoch": 936, "train_loss": "0.542", "train_ntokens": "260840", "train_nsentences": "1750.04", "train_wps": "93404.8", "train_ups": "0.36", "train_wpb": "260840", "train_bsz": "1750", "train_num_updates": "44906", "train_lr": "0.000482465", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.7", "train_wall": "13126"}
[2024-10-08 20:21:35,161][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:21:35,178][fairseq.trainer][INFO] - begin training epoch 937
[2024-10-08 20:21:35,179][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:26:21,272][fairseq_cli.train][INFO] - end of epoch 937 (average epoch stats below)
[2024-10-08 20:26:21,279][train][INFO] - {"epoch": 937, "train_loss": "0.549", "train_ntokens": "260380", "train_nsentences": "1750.04", "train_wps": "43636.3", "train_ups": "0.17", "train_wpb": "260380", "train_bsz": "1750", "train_num_updates": "44954", "train_lr": "0.000482399", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40.1", "train_wall": "13412"}
[2024-10-08 20:26:21,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:26:21,561][fairseq.trainer][INFO] - begin training epoch 938
[2024-10-08 20:26:21,562][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:31:02,407][train_inner][INFO] - {"epoch": 938, "update": 937.958, "loss": "0.543", "ntokens": "260733", "nsentences": "1757.14", "wps": "60386.1", "ups": "0.23", "wpb": "260733", "bsz": "1757.1", "num_updates": "45000", "lr": "0.000482337", "gnorm": "0.377", "loss_scale": "2", "train_wall": "231", "gb_free": "39.3", "wall": "13693"}
[2024-10-08 20:31:03,109][fairseq_cli.train][INFO] - end of epoch 938 (average epoch stats below)
[2024-10-08 20:31:03,112][train][INFO] - {"epoch": 938, "train_loss": "0.541", "train_ntokens": "260793", "train_nsentences": "1750.04", "train_wps": "44417.1", "train_ups": "0.17", "train_wpb": "260793", "train_bsz": "1750", "train_num_updates": "45002", "train_lr": "0.000482334", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "72", "train_gb_free": "41", "train_wall": "13694"}
[2024-10-08 20:31:03,340][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:31:03,360][fairseq.trainer][INFO] - begin training epoch 939
[2024-10-08 20:31:03,360][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:35:18,598][fairseq_cli.train][INFO] - end of epoch 939 (average epoch stats below)
[2024-10-08 20:35:18,603][train][INFO] - {"epoch": 939, "train_loss": "0.547", "train_ntokens": "260724", "train_nsentences": "1750.04", "train_wps": "48983.5", "train_ups": "0.19", "train_wpb": "260724", "train_bsz": "1750", "train_num_updates": "45050", "train_lr": "0.000482269", "train_gnorm": "0.435", "train_loss_scale": "2", "train_train_wall": "76", "train_gb_free": "39.3", "train_wall": "13949"}
[2024-10-08 20:35:18,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:35:18,788][fairseq.trainer][INFO] - begin training epoch 940
[2024-10-08 20:35:18,788][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:39:31,912][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 940 @ 45098 updates
[2024-10-08 20:39:31,916][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 20:39:35,708][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 20:39:35,711][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 940 @ 45098 updates, score None) (writing took 3.798461831174791 seconds)
[2024-10-08 20:39:35,712][fairseq_cli.train][INFO] - end of epoch 940 (average epoch stats below)
[2024-10-08 20:39:35,715][train][INFO] - {"epoch": 940, "train_loss": "0.554", "train_ntokens": "260544", "train_nsentences": "1750.04", "train_wps": "48641.6", "train_ups": "0.19", "train_wpb": "260544", "train_bsz": "1750", "train_num_updates": "45098", "train_lr": "0.000482204", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "14206"}
[2024-10-08 20:39:36,185][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:39:36,206][fairseq.trainer][INFO] - begin training epoch 941
[2024-10-08 20:39:36,207][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:44:29,597][fairseq_cli.train][INFO] - end of epoch 941 (average epoch stats below)
[2024-10-08 20:44:29,607][train][INFO] - {"epoch": 941, "train_loss": "0.542", "train_ntokens": "260496", "train_nsentences": "1750.04", "train_wps": "42546.4", "train_ups": "0.16", "train_wpb": "260496", "train_bsz": "1750", "train_num_updates": "45146", "train_lr": "0.000482139", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "39.7", "train_wall": "14500"}
[2024-10-08 20:44:29,840][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:44:29,844][fairseq.trainer][INFO] - begin training epoch 942
[2024-10-08 20:44:29,844][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:48:53,749][fairseq_cli.train][INFO] - end of epoch 942 (average epoch stats below)
[2024-10-08 20:48:53,752][train][INFO] - {"epoch": 942, "train_loss": "0.546", "train_ntokens": "260827", "train_nsentences": "1750.04", "train_wps": "47397.5", "train_ups": "0.18", "train_wpb": "260827", "train_bsz": "1750", "train_num_updates": "45194", "train_lr": "0.000482073", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.2", "train_wall": "14764"}
[2024-10-08 20:48:53,989][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:48:53,994][fairseq.trainer][INFO] - begin training epoch 943
[2024-10-08 20:48:53,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:52:59,257][train_inner][INFO] - {"epoch": 943, "update": 942.125, "loss": "0.548", "ntokens": "260537", "nsentences": "1750.45", "wps": "39570", "ups": "0.15", "wpb": "260537", "bsz": "1750.5", "num_updates": "45200", "lr": "0.000482065", "gnorm": "0.392", "loss_scale": "2", "train_wall": "266", "gb_free": "39.6", "wall": "15010"}
[2024-10-08 20:53:25,934][fairseq_cli.train][INFO] - end of epoch 943 (average epoch stats below)
[2024-10-08 20:53:25,937][train][INFO] - {"epoch": 943, "train_loss": "0.545", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "45947", "train_ups": "0.18", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "45242", "train_lr": "0.000482008", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "31", "train_gb_free": "39.3", "train_wall": "15037"}
[2024-10-08 20:53:26,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:53:26,414][fairseq.trainer][INFO] - begin training epoch 944
[2024-10-08 20:53:26,414][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:57:25,725][fairseq_cli.train][INFO] - end of epoch 944 (average epoch stats below)
[2024-10-08 20:57:25,733][train][INFO] - {"epoch": 944, "train_loss": "0.549", "train_ntokens": "260620", "train_nsentences": "1750.04", "train_wps": "52168.9", "train_ups": "0.2", "train_wpb": "260620", "train_bsz": "1750", "train_num_updates": "45290", "train_lr": "0.000481943", "train_gnorm": "0.356", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.6", "train_wall": "15276"}
[2024-10-08 20:57:26,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 20:57:26,153][fairseq.trainer][INFO] - begin training epoch 945
[2024-10-08 20:57:26,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:02:42,374][fairseq_cli.train][INFO] - end of epoch 945 (average epoch stats below)
[2024-10-08 21:02:42,386][train][INFO] - {"epoch": 945, "train_loss": "0.544", "train_ntokens": "260675", "train_nsentences": "1750.04", "train_wps": "39515.7", "train_ups": "0.15", "train_wpb": "260675", "train_bsz": "1750", "train_num_updates": "45338", "train_lr": "0.000481878", "train_gnorm": "0.416", "train_loss_scale": "2", "train_train_wall": "111", "train_gb_free": "40.5", "train_wall": "15593"}
[2024-10-08 21:02:42,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:02:42,712][fairseq.trainer][INFO] - begin training epoch 946
[2024-10-08 21:02:42,712][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:07:39,586][fairseq_cli.train][INFO] - end of epoch 946 (average epoch stats below)
[2024-10-08 21:07:39,594][train][INFO] - {"epoch": 946, "train_loss": "0.538", "train_ntokens": "260685", "train_nsentences": "1750.04", "train_wps": "42102.1", "train_ups": "0.16", "train_wpb": "260685", "train_bsz": "1750", "train_num_updates": "45386", "train_lr": "0.000481812", "train_gnorm": "0.386", "train_loss_scale": "2", "train_train_wall": "37", "train_gb_free": "39.1", "train_wall": "15890"}
[2024-10-08 21:07:39,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:07:39,818][fairseq.trainer][INFO] - begin training epoch 947
[2024-10-08 21:07:39,819][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:11:53,538][train_inner][INFO] - {"epoch": 947, "update": 946.292, "loss": "0.544", "ntokens": "260694", "nsentences": "1765.37", "wps": "45966.9", "ups": "0.18", "wpb": "260694", "bsz": "1765.4", "num_updates": "45400", "lr": "0.000481793", "gnorm": "0.396", "loss_scale": "2", "train_wall": "279", "gb_free": "40.1", "wall": "16144"}
[2024-10-08 21:12:21,029][fairseq_cli.train][INFO] - end of epoch 947 (average epoch stats below)
[2024-10-08 21:12:21,040][train][INFO] - {"epoch": 947, "train_loss": "0.537", "train_ntokens": "260521", "train_nsentences": "1750.04", "train_wps": "44433", "train_ups": "0.17", "train_wpb": "260521", "train_bsz": "1750", "train_num_updates": "45434", "train_lr": "0.000481747", "train_gnorm": "0.45", "train_loss_scale": "2", "train_train_wall": "50", "train_gb_free": "39.3", "train_wall": "16172"}
[2024-10-08 21:12:21,243][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:12:21,250][fairseq.trainer][INFO] - begin training epoch 948
[2024-10-08 21:12:21,251][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:14:53,913][fairseq_cli.train][INFO] - end of epoch 948 (average epoch stats below)
[2024-10-08 21:14:53,926][train][INFO] - {"epoch": 948, "train_loss": "0.539", "train_ntokens": "260363", "train_nsentences": "1750.04", "train_wps": "81745.8", "train_ups": "0.31", "train_wpb": "260363", "train_bsz": "1750", "train_num_updates": "45482", "train_lr": "0.000481682", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.3", "train_wall": "16325"}
[2024-10-08 21:14:54,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:14:54,019][fairseq.trainer][INFO] - begin training epoch 949
[2024-10-08 21:14:54,020][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:17:02,908][fairseq_cli.train][INFO] - end of epoch 949 (average epoch stats below)
[2024-10-08 21:17:02,917][train][INFO] - {"epoch": 949, "train_loss": "0.544", "train_ntokens": "260617", "train_nsentences": "1750.04", "train_wps": "96983.1", "train_ups": "0.37", "train_wpb": "260617", "train_bsz": "1750", "train_num_updates": "45530", "train_lr": "0.000481617", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.4", "train_wall": "16454"}
[2024-10-08 21:17:03,078][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:17:03,082][fairseq.trainer][INFO] - begin training epoch 950
[2024-10-08 21:17:03,083][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:19:49,403][fairseq_cli.train][INFO] - end of epoch 950 (average epoch stats below)
[2024-10-08 21:19:49,418][train][INFO] - {"epoch": 950, "train_loss": "0.545", "train_ntokens": "260655", "train_nsentences": "1750.04", "train_wps": "75148.7", "train_ups": "0.29", "train_wpb": "260655", "train_bsz": "1750", "train_num_updates": "45578", "train_lr": "0.000481552", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.3", "train_wall": "16620"}
[2024-10-08 21:19:49,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:19:49,590][fairseq.trainer][INFO] - begin training epoch 951
[2024-10-08 21:19:49,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:21:49,340][train_inner][INFO] - {"epoch": 951, "update": 950.458, "loss": "0.541", "ntokens": "260676", "nsentences": "1732.01", "wps": "87505.3", "ups": "0.34", "wpb": "260676", "bsz": "1732", "num_updates": "45600", "lr": "0.000481522", "gnorm": "0.38", "loss_scale": "2", "train_wall": "247", "gb_free": "39.2", "wall": "16740"}
[2024-10-08 21:22:07,229][fairseq_cli.train][INFO] - end of epoch 951 (average epoch stats below)
[2024-10-08 21:22:07,236][train][INFO] - {"epoch": 951, "train_loss": "0.54", "train_ntokens": "260750", "train_nsentences": "1750.04", "train_wps": "90820.3", "train_ups": "0.35", "train_wpb": "260750", "train_bsz": "1750", "train_num_updates": "45626", "train_lr": "0.000481486", "train_gnorm": "0.366", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.3", "train_wall": "16758"}
[2024-10-08 21:22:07,400][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:22:07,414][fairseq.trainer][INFO] - begin training epoch 952
[2024-10-08 21:22:07,414][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:24:23,465][fairseq_cli.train][INFO] - end of epoch 952 (average epoch stats below)
[2024-10-08 21:24:23,471][train][INFO] - {"epoch": 952, "train_loss": "0.542", "train_ntokens": "260637", "train_nsentences": "1750.04", "train_wps": "91837", "train_ups": "0.35", "train_wpb": "260637", "train_bsz": "1750", "train_num_updates": "45674", "train_lr": "0.000481421", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "40.5", "train_wall": "16894"}
[2024-10-08 21:24:23,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:24:23,604][fairseq.trainer][INFO] - begin training epoch 953
[2024-10-08 21:24:23,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:26:33,628][fairseq_cli.train][INFO] - end of epoch 953 (average epoch stats below)
[2024-10-08 21:26:33,639][train][INFO] - {"epoch": 953, "train_loss": "0.545", "train_ntokens": "260767", "train_nsentences": "1750.04", "train_wps": "96166.2", "train_ups": "0.37", "train_wpb": "260768", "train_bsz": "1750", "train_num_updates": "45722", "train_lr": "0.000481356", "train_gnorm": "0.398", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "40.1", "train_wall": "17024"}
[2024-10-08 21:26:33,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:26:33,792][fairseq.trainer][INFO] - begin training epoch 954
[2024-10-08 21:26:33,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:28:48,523][fairseq_cli.train][INFO] - end of epoch 954 (average epoch stats below)
[2024-10-08 21:28:48,529][train][INFO] - {"epoch": 954, "train_loss": "0.538", "train_ntokens": "260665", "train_nsentences": "1750.04", "train_wps": "92758.2", "train_ups": "0.36", "train_wpb": "260665", "train_bsz": "1750", "train_num_updates": "45770", "train_lr": "0.000481291", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "40.3", "train_wall": "17159"}
[2024-10-08 21:28:48,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:28:48,725][fairseq.trainer][INFO] - begin training epoch 955
[2024-10-08 21:28:48,729][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:30:48,917][train_inner][INFO] - {"epoch": 955, "update": 954.625, "loss": "0.541", "ntokens": "260666", "nsentences": "1757.91", "wps": "96619.7", "ups": "0.37", "wpb": "260666", "bsz": "1757.9", "num_updates": "45800", "lr": "0.00048125", "gnorm": "0.386", "loss_scale": "2", "train_wall": "204", "gb_free": "39.8", "wall": "17280"}
[2024-10-08 21:31:03,270][fairseq_cli.train][INFO] - end of epoch 955 (average epoch stats below)
[2024-10-08 21:31:03,273][train][INFO] - {"epoch": 955, "train_loss": "0.543", "train_ntokens": "260737", "train_nsentences": "1750.04", "train_wps": "92885.1", "train_ups": "0.36", "train_wpb": "260737", "train_bsz": "1750", "train_num_updates": "45818", "train_lr": "0.000481226", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "40.1", "train_wall": "17294"}
[2024-10-08 21:31:03,403][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:31:03,416][fairseq.trainer][INFO] - begin training epoch 956
[2024-10-08 21:31:03,417][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:33:22,259][fairseq_cli.train][INFO] - end of epoch 956 (average epoch stats below)
[2024-10-08 21:33:22,264][train][INFO] - {"epoch": 956, "train_loss": "0.547", "train_ntokens": "260818", "train_nsentences": "1750.04", "train_wps": "90074.6", "train_ups": "0.35", "train_wpb": "260818", "train_bsz": "1750", "train_num_updates": "45866", "train_lr": "0.00048116", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "17433"}
[2024-10-08 21:33:22,335][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:33:22,338][fairseq.trainer][INFO] - begin training epoch 957
[2024-10-08 21:33:22,339][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:35:30,660][fairseq_cli.train][INFO] - end of epoch 957 (average epoch stats below)
[2024-10-08 21:35:30,674][train][INFO] - {"epoch": 957, "train_loss": "0.544", "train_ntokens": "260520", "train_nsentences": "1750.04", "train_wps": "97385.5", "train_ups": "0.37", "train_wpb": "260520", "train_bsz": "1750", "train_num_updates": "45914", "train_lr": "0.000481095", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.6", "train_wall": "17561"}
[2024-10-08 21:35:30,828][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:35:30,844][fairseq.trainer][INFO] - begin training epoch 958
[2024-10-08 21:35:30,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:37:42,192][fairseq_cli.train][INFO] - end of epoch 958 (average epoch stats below)
[2024-10-08 21:37:42,199][train][INFO] - {"epoch": 958, "train_loss": "0.535", "train_ntokens": "260766", "train_nsentences": "1750.04", "train_wps": "95183.7", "train_ups": "0.37", "train_wpb": "260766", "train_bsz": "1750", "train_num_updates": "45962", "train_lr": "0.00048103", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40", "train_wall": "17693"}
[2024-10-08 21:37:42,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:37:42,341][fairseq.trainer][INFO] - begin training epoch 959
[2024-10-08 21:37:42,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:39:50,554][train_inner][INFO] - {"epoch": 959, "update": 958.792, "loss": "0.541", "ntokens": "260696", "nsentences": "1753.84", "wps": "96264", "ups": "0.37", "wpb": "260696", "bsz": "1753.8", "num_updates": "46000", "lr": "0.000480978", "gnorm": "0.394", "loss_scale": "2", "train_wall": "235", "gb_free": "40.3", "wall": "17821"}
[2024-10-08 21:39:55,895][fairseq_cli.train][INFO] - end of epoch 959 (average epoch stats below)
[2024-10-08 21:39:55,898][train][INFO] - {"epoch": 959, "train_loss": "0.533", "train_ntokens": "260760", "train_nsentences": "1750.04", "train_wps": "93621.1", "train_ups": "0.36", "train_wpb": "260760", "train_bsz": "1750", "train_num_updates": "46010", "train_lr": "0.000480965", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.6", "train_wall": "17827"}
[2024-10-08 21:39:55,978][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:39:55,982][fairseq.trainer][INFO] - begin training epoch 960
[2024-10-08 21:39:55,982][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:42:03,675][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 960 @ 46058 updates
[2024-10-08 21:42:03,681][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 21:42:07,946][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 21:42:07,949][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 960 @ 46058 updates, score None) (writing took 4.273778727278113 seconds)
[2024-10-08 21:42:07,949][fairseq_cli.train][INFO] - end of epoch 960 (average epoch stats below)
[2024-10-08 21:42:07,952][train][INFO] - {"epoch": 960, "train_loss": "0.542", "train_ntokens": "260820", "train_nsentences": "1750.04", "train_wps": "94807", "train_ups": "0.36", "train_wpb": "260820", "train_bsz": "1750", "train_num_updates": "46058", "train_lr": "0.000480899", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "17959"}
[2024-10-08 21:42:08,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:42:08,133][fairseq.trainer][INFO] - begin training epoch 961
[2024-10-08 21:42:08,133][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:44:34,781][fairseq_cli.train][INFO] - end of epoch 961 (average epoch stats below)
[2024-10-08 21:44:34,784][train][INFO] - {"epoch": 961, "train_loss": "0.533", "train_ntokens": "260640", "train_nsentences": "1750.04", "train_wps": "85206.3", "train_ups": "0.33", "train_wpb": "260640", "train_bsz": "1750", "train_num_updates": "46106", "train_lr": "0.000480834", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "34", "train_gb_free": "40.5", "train_wall": "18105"}
[2024-10-08 21:44:34,861][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:44:34,885][fairseq.trainer][INFO] - begin training epoch 962
[2024-10-08 21:44:34,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:47:00,306][fairseq_cli.train][INFO] - end of epoch 962 (average epoch stats below)
[2024-10-08 21:47:00,322][train][INFO] - {"epoch": 962, "train_loss": "0.538", "train_ntokens": "261093", "train_nsentences": "1750.04", "train_wps": "86113.3", "train_ups": "0.33", "train_wpb": "261093", "train_bsz": "1750", "train_num_updates": "46154", "train_lr": "0.000480769", "train_gnorm": "0.39", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.3", "train_wall": "18251"}
[2024-10-08 21:47:00,390][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:47:00,398][fairseq.trainer][INFO] - begin training epoch 963
[2024-10-08 21:47:00,399][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:49:08,035][train_inner][INFO] - {"epoch": 963, "update": 962.958, "loss": "0.537", "ntokens": "260760", "nsentences": "1745.15", "wps": "93557.5", "ups": "0.36", "wpb": "260760", "bsz": "1745.2", "num_updates": "46200", "lr": "0.000480707", "gnorm": "0.393", "loss_scale": "2", "train_wall": "212", "gb_free": "39.2", "wall": "18379"}
[2024-10-08 21:49:08,553][fairseq_cli.train][INFO] - end of epoch 963 (average epoch stats below)
[2024-10-08 21:49:08,558][train][INFO] - {"epoch": 963, "train_loss": "0.536", "train_ntokens": "260832", "train_nsentences": "1750.04", "train_wps": "97636.5", "train_ups": "0.37", "train_wpb": "260832", "train_bsz": "1750", "train_num_updates": "46202", "train_lr": "0.000480704", "train_gnorm": "0.411", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "39.6", "train_wall": "18379"}
[2024-10-08 21:49:08,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:49:08,681][fairseq.trainer][INFO] - begin training epoch 964
[2024-10-08 21:49:08,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:51:17,000][fairseq_cli.train][INFO] - end of epoch 964 (average epoch stats below)
[2024-10-08 21:51:17,006][train][INFO] - {"epoch": 964, "train_loss": "0.544", "train_ntokens": "260789", "train_nsentences": "1750.04", "train_wps": "97457.3", "train_ups": "0.37", "train_wpb": "260789", "train_bsz": "1750", "train_num_updates": "46250", "train_lr": "0.000480639", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "40.2", "train_wall": "18508"}
[2024-10-08 21:51:17,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:51:17,207][fairseq.trainer][INFO] - begin training epoch 965
[2024-10-08 21:51:17,208][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:53:22,774][fairseq_cli.train][INFO] - end of epoch 965 (average epoch stats below)
[2024-10-08 21:53:22,780][train][INFO] - {"epoch": 965, "train_loss": "0.537", "train_ntokens": "260753", "train_nsentences": "1750.04", "train_wps": "99518.4", "train_ups": "0.38", "train_wpb": "260752", "train_bsz": "1750", "train_num_updates": "46298", "train_lr": "0.000480573", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.2", "train_wall": "18633"}
[2024-10-08 21:53:22,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:53:22,937][fairseq.trainer][INFO] - begin training epoch 966
[2024-10-08 21:53:22,938][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:55:42,464][fairseq_cli.train][INFO] - end of epoch 966 (average epoch stats below)
[2024-10-08 21:55:42,472][train][INFO] - {"epoch": 966, "train_loss": "0.534", "train_ntokens": "260689", "train_nsentences": "1750.04", "train_wps": "89580.1", "train_ups": "0.34", "train_wpb": "260689", "train_bsz": "1750", "train_num_updates": "46346", "train_lr": "0.000480508", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.8", "train_wall": "18773"}
[2024-10-08 21:55:42,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:55:42,589][fairseq.trainer][INFO] - begin training epoch 967
[2024-10-08 21:55:42,589][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:57:54,420][fairseq_cli.train][INFO] - end of epoch 967 (average epoch stats below)
[2024-10-08 21:57:54,425][train][INFO] - {"epoch": 967, "train_loss": "0.548", "train_ntokens": "261051", "train_nsentences": "1750.04", "train_wps": "94964.7", "train_ups": "0.36", "train_wpb": "261051", "train_bsz": "1750", "train_num_updates": "46394", "train_lr": "0.000480443", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "18905"}
[2024-10-08 21:57:54,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 21:57:54,563][fairseq.trainer][INFO] - begin training epoch 968
[2024-10-08 21:57:54,564][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:59:30,060][train_inner][INFO] - {"epoch": 968, "update": 967.125, "loss": "0.54", "ntokens": "260670", "nsentences": "1762.87", "wps": "83814.3", "ups": "0.32", "wpb": "260670", "bsz": "1762.9", "num_updates": "46400", "lr": "0.000480435", "gnorm": "0.375", "loss_scale": "2", "train_wall": "217", "gb_free": "39.3", "wall": "19001"}
[2024-10-08 22:00:01,163][fairseq_cli.train][INFO] - end of epoch 968 (average epoch stats below)
[2024-10-08 22:00:01,169][train][INFO] - {"epoch": 968, "train_loss": "0.538", "train_ntokens": "260405", "train_nsentences": "1750.04", "train_wps": "98624.7", "train_ups": "0.38", "train_wpb": "260405", "train_bsz": "1750", "train_num_updates": "46442", "train_lr": "0.000480378", "train_gnorm": "0.421", "train_loss_scale": "4", "train_train_wall": "41", "train_gb_free": "39.9", "train_wall": "19032"}
[2024-10-08 22:00:01,245][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:00:01,251][fairseq.trainer][INFO] - begin training epoch 969
[2024-10-08 22:00:01,251][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:01:35,142][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 22:02:09,725][fairseq_cli.train][INFO] - end of epoch 969 (average epoch stats below)
[2024-10-08 22:02:09,743][train][INFO] - {"epoch": 969, "train_loss": "0.539", "train_ntokens": "260817", "train_nsentences": "1762.17", "train_wps": "95354.7", "train_ups": "0.37", "train_wpb": "260816", "train_bsz": "1762.2", "train_num_updates": "46489", "train_lr": "0.000480314", "train_gnorm": "0.428", "train_loss_scale": "2", "train_train_wall": "30", "train_gb_free": "39.3", "train_wall": "19160"}
[2024-10-08 22:02:09,866][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:02:09,870][fairseq.trainer][INFO] - begin training epoch 970
[2024-10-08 22:02:09,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:04:19,301][fairseq_cli.train][INFO] - end of epoch 970 (average epoch stats below)
[2024-10-08 22:04:19,309][train][INFO] - {"epoch": 970, "train_loss": "0.542", "train_ntokens": "260547", "train_nsentences": "1750.04", "train_wps": "96526.9", "train_ups": "0.37", "train_wpb": "260547", "train_bsz": "1750", "train_num_updates": "46537", "train_lr": "0.000480249", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "35", "train_gb_free": "39.3", "train_wall": "19290"}
[2024-10-08 22:04:19,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:04:19,469][fairseq.trainer][INFO] - begin training epoch 971
[2024-10-08 22:04:19,470][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:06:27,325][fairseq_cli.train][INFO] - end of epoch 971 (average epoch stats below)
[2024-10-08 22:06:27,329][train][INFO] - {"epoch": 971, "train_loss": "0.533", "train_ntokens": "260595", "train_nsentences": "1750.04", "train_wps": "97710.3", "train_ups": "0.37", "train_wpb": "260595", "train_bsz": "1750", "train_num_updates": "46585", "train_lr": "0.000480183", "train_gnorm": "0.437", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "40.1", "train_wall": "19418"}
[2024-10-08 22:06:27,515][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:06:27,533][fairseq.trainer][INFO] - begin training epoch 972
[2024-10-08 22:06:27,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:08:11,298][train_inner][INFO] - {"epoch": 972, "update": 971.312, "loss": "0.538", "ntokens": "260607", "nsentences": "1741.9", "wps": "100000", "ups": "0.38", "wpb": "260607", "bsz": "1741.9", "num_updates": "46600", "lr": "0.000480163", "gnorm": "0.412", "loss_scale": "2", "train_wall": "171", "gb_free": "39.6", "wall": "19522"}
[2024-10-08 22:08:40,225][fairseq_cli.train][INFO] - end of epoch 972 (average epoch stats below)
[2024-10-08 22:08:40,227][train][INFO] - {"epoch": 972, "train_loss": "0.541", "train_ntokens": "260709", "train_nsentences": "1750.04", "train_wps": "94164.5", "train_ups": "0.36", "train_wpb": "260709", "train_bsz": "1750", "train_num_updates": "46633", "train_lr": "0.000480118", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.3", "train_wall": "19551"}
[2024-10-08 22:08:40,294][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:08:40,299][fairseq.trainer][INFO] - begin training epoch 973
[2024-10-08 22:08:40,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:10:53,738][fairseq_cli.train][INFO] - end of epoch 973 (average epoch stats below)
[2024-10-08 22:10:53,749][train][INFO] - {"epoch": 973, "train_loss": "0.533", "train_ntokens": "260808", "train_nsentences": "1750.04", "train_wps": "93760.2", "train_ups": "0.36", "train_wpb": "260808", "train_bsz": "1750", "train_num_updates": "46681", "train_lr": "0.000480053", "train_gnorm": "0.412", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "19684"}
[2024-10-08 22:10:53,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:10:53,922][fairseq.trainer][INFO] - begin training epoch 974
[2024-10-08 22:10:53,922][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:13:06,263][fairseq_cli.train][INFO] - end of epoch 974 (average epoch stats below)
[2024-10-08 22:13:06,282][train][INFO] - {"epoch": 974, "train_loss": "0.536", "train_ntokens": "261021", "train_nsentences": "1750.04", "train_wps": "94537.9", "train_ups": "0.36", "train_wpb": "261021", "train_bsz": "1750", "train_num_updates": "46729", "train_lr": "0.000479988", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.8", "train_wall": "19817"}
[2024-10-08 22:13:06,378][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:13:06,404][fairseq.trainer][INFO] - begin training epoch 975
[2024-10-08 22:13:06,405][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:15:43,373][fairseq_cli.train][INFO] - end of epoch 975 (average epoch stats below)
[2024-10-08 22:15:43,391][train][INFO] - {"epoch": 975, "train_loss": "0.534", "train_ntokens": "260732", "train_nsentences": "1750.04", "train_wps": "79666", "train_ups": "0.31", "train_wpb": "260732", "train_bsz": "1750", "train_num_updates": "46777", "train_lr": "0.000479923", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.6", "train_wall": "19974"}
[2024-10-08 22:15:43,551][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:15:43,557][fairseq.trainer][INFO] - begin training epoch 976
[2024-10-08 22:15:43,558][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:17:32,340][train_inner][INFO] - {"epoch": 976, "update": 975.479, "loss": "0.535", "ntokens": "260935", "nsentences": "1746.94", "wps": "93019", "ups": "0.36", "wpb": "260935", "bsz": "1746.9", "num_updates": "46800", "lr": "0.000479891", "gnorm": "0.388", "loss_scale": "2", "train_wall": "218", "gb_free": "39.3", "wall": "20083"}
[2024-10-08 22:17:54,634][fairseq_cli.train][INFO] - end of epoch 976 (average epoch stats below)
[2024-10-08 22:17:54,636][train][INFO] - {"epoch": 976, "train_loss": "0.534", "train_ntokens": "260553", "train_nsentences": "1750.04", "train_wps": "95293.7", "train_ups": "0.37", "train_wpb": "260553", "train_bsz": "1750", "train_num_updates": "46825", "train_lr": "0.000479857", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "20105"}
[2024-10-08 22:17:54,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:17:54,779][fairseq.trainer][INFO] - begin training epoch 977
[2024-10-08 22:17:54,780][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:20:03,120][fairseq_cli.train][INFO] - end of epoch 977 (average epoch stats below)
[2024-10-08 22:20:03,129][train][INFO] - {"epoch": 977, "train_loss": "0.539", "train_ntokens": "260430", "train_nsentences": "1750.04", "train_wps": "97289.1", "train_ups": "0.37", "train_wpb": "260430", "train_bsz": "1750", "train_num_updates": "46873", "train_lr": "0.000479792", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "47", "train_gb_free": "39.6", "train_wall": "20234"}
[2024-10-08 22:20:03,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:20:03,211][fairseq.trainer][INFO] - begin training epoch 978
[2024-10-08 22:20:03,212][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:22:10,482][fairseq_cli.train][INFO] - end of epoch 978 (average epoch stats below)
[2024-10-08 22:22:10,486][train][INFO] - {"epoch": 978, "train_loss": "0.543", "train_ntokens": "260668", "train_nsentences": "1750.04", "train_wps": "98247.1", "train_ups": "0.38", "train_wpb": "260668", "train_bsz": "1750", "train_num_updates": "46921", "train_lr": "0.000479727", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "20361"}
[2024-10-08 22:22:10,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:22:10,551][fairseq.trainer][INFO] - begin training epoch 979
[2024-10-08 22:22:10,552][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:24:19,260][fairseq_cli.train][INFO] - end of epoch 979 (average epoch stats below)
[2024-10-08 22:24:19,264][train][INFO] - {"epoch": 979, "train_loss": "0.538", "train_ntokens": "260717", "train_nsentences": "1750.04", "train_wps": "97180.7", "train_ups": "0.37", "train_wpb": "260717", "train_bsz": "1750", "train_num_updates": "46969", "train_lr": "0.000479662", "train_gnorm": "0.417", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.6", "train_wall": "20490"}
[2024-10-08 22:24:19,410][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:24:19,419][fairseq.trainer][INFO] - begin training epoch 980
[2024-10-08 22:24:19,419][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:26:13,742][train_inner][INFO] - {"epoch": 980, "update": 979.646, "loss": "0.54", "ntokens": "260730", "nsentences": "1748.33", "wps": "100012", "ups": "0.38", "wpb": "260730", "bsz": "1748.3", "num_updates": "47000", "lr": "0.00047962", "gnorm": "0.388", "loss_scale": "2", "train_wall": "214", "gb_free": "39.7", "wall": "20604"}
[2024-10-08 22:26:29,991][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 980 @ 47017 updates
[2024-10-08 22:26:29,992][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 22:26:34,108][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 22:26:34,112][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 980 @ 47017 updates, score None) (writing took 4.120428359135985 seconds)
[2024-10-08 22:26:34,112][fairseq_cli.train][INFO] - end of epoch 980 (average epoch stats below)
[2024-10-08 22:26:34,114][train][INFO] - {"epoch": 980, "train_loss": "0.539", "train_ntokens": "260717", "train_nsentences": "1750.04", "train_wps": "92805.1", "train_ups": "0.36", "train_wpb": "260717", "train_bsz": "1750", "train_num_updates": "47017", "train_lr": "0.000479596", "train_gnorm": "0.394", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "40.2", "train_wall": "20625"}
[2024-10-08 22:26:34,211][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:26:34,215][fairseq.trainer][INFO] - begin training epoch 981
[2024-10-08 22:26:34,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:28:41,888][fairseq_cli.train][INFO] - end of epoch 981 (average epoch stats below)
[2024-10-08 22:28:41,891][train][INFO] - {"epoch": 981, "train_loss": "0.532", "train_ntokens": "260867", "train_nsentences": "1750.04", "train_wps": "97998.3", "train_ups": "0.38", "train_wpb": "260867", "train_bsz": "1750", "train_num_updates": "47065", "train_lr": "0.000479531", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "30", "train_gb_free": "40.1", "train_wall": "20753"}
[2024-10-08 22:28:41,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:28:41,956][fairseq.trainer][INFO] - begin training epoch 982
[2024-10-08 22:28:41,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:30:53,016][fairseq_cli.train][INFO] - end of epoch 982 (average epoch stats below)
[2024-10-08 22:30:53,027][train][INFO] - {"epoch": 982, "train_loss": "0.535", "train_ntokens": "260463", "train_nsentences": "1750.04", "train_wps": "95340.2", "train_ups": "0.37", "train_wpb": "260463", "train_bsz": "1750", "train_num_updates": "47113", "train_lr": "0.000479466", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "40.1", "train_wall": "20884"}
[2024-10-08 22:30:53,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:30:53,152][fairseq.trainer][INFO] - begin training epoch 983
[2024-10-08 22:30:53,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:33:03,535][fairseq_cli.train][INFO] - end of epoch 983 (average epoch stats below)
[2024-10-08 22:33:03,541][train][INFO] - {"epoch": 983, "train_loss": "0.543", "train_ntokens": "260894", "train_nsentences": "1750.04", "train_wps": "95954.3", "train_ups": "0.37", "train_wpb": "260894", "train_bsz": "1750", "train_num_updates": "47161", "train_lr": "0.000479401", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.4", "train_wall": "21014"}
[2024-10-08 22:33:03,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:33:03,713][fairseq.trainer][INFO] - begin training epoch 984
[2024-10-08 22:33:03,714][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:35:08,680][train_inner][INFO] - {"epoch": 984, "update": 983.812, "loss": "0.536", "ntokens": "260843", "nsentences": "1745.47", "wps": "97538.2", "ups": "0.37", "wpb": "260843", "bsz": "1745.5", "num_updates": "47200", "lr": "0.000479348", "gnorm": "0.399", "loss_scale": "2", "train_wall": "197", "gb_free": "39.6", "wall": "21139"}
[2024-10-08 22:35:15,515][fairseq_cli.train][INFO] - end of epoch 984 (average epoch stats below)
[2024-10-08 22:35:15,517][train][INFO] - {"epoch": 984, "train_loss": "0.53", "train_ntokens": "260956", "train_nsentences": "1750.04", "train_wps": "94912.7", "train_ups": "0.36", "train_wpb": "260956", "train_bsz": "1750", "train_num_updates": "47209", "train_lr": "0.000479336", "train_gnorm": "0.412", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "21146"}
[2024-10-08 22:35:15,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:35:15,609][fairseq.trainer][INFO] - begin training epoch 985
[2024-10-08 22:35:15,609][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:37:30,516][fairseq_cli.train][INFO] - end of epoch 985 (average epoch stats below)
[2024-10-08 22:37:30,523][train][INFO] - {"epoch": 985, "train_loss": "0.529", "train_ntokens": "260439", "train_nsentences": "1750.04", "train_wps": "92599.1", "train_ups": "0.36", "train_wpb": "260440", "train_bsz": "1750", "train_num_updates": "47257", "train_lr": "0.00047927", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "32", "train_gb_free": "39.6", "train_wall": "21281"}
[2024-10-08 22:37:30,633][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:37:30,649][fairseq.trainer][INFO] - begin training epoch 986
[2024-10-08 22:37:30,650][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:39:40,928][fairseq_cli.train][INFO] - end of epoch 986 (average epoch stats below)
[2024-10-08 22:39:40,931][train][INFO] - {"epoch": 986, "train_loss": "0.528", "train_ntokens": "260988", "train_nsentences": "1750.04", "train_wps": "96065.6", "train_ups": "0.37", "train_wpb": "260988", "train_bsz": "1750", "train_num_updates": "47305", "train_lr": "0.000479205", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "21412"}
[2024-10-08 22:39:41,136][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:39:41,157][fairseq.trainer][INFO] - begin training epoch 987
[2024-10-08 22:39:41,157][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:41:55,826][fairseq_cli.train][INFO] - end of epoch 987 (average epoch stats below)
[2024-10-08 22:41:55,833][train][INFO] - {"epoch": 987, "train_loss": "0.533", "train_ntokens": "260755", "train_nsentences": "1750.04", "train_wps": "92783.3", "train_ups": "0.36", "train_wpb": "260755", "train_bsz": "1750", "train_num_updates": "47353", "train_lr": "0.00047914", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "39.2", "train_wall": "21546"}
[2024-10-08 22:41:56,049][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:41:56,070][fairseq.trainer][INFO] - begin training epoch 988
[2024-10-08 22:41:56,070][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:44:18,784][train_inner][INFO] - {"epoch": 988, "update": 987.979, "loss": "0.532", "ntokens": "260587", "nsentences": "1753.81", "wps": "94741.7", "ups": "0.36", "wpb": "260587", "bsz": "1753.8", "num_updates": "47400", "lr": "0.000479076", "gnorm": "0.398", "loss_scale": "2", "train_wall": "229", "gb_free": "39.2", "wall": "21689"}
[2024-10-08 22:44:19,173][fairseq_cli.train][INFO] - end of epoch 988 (average epoch stats below)
[2024-10-08 22:44:19,176][train][INFO] - {"epoch": 988, "train_loss": "0.535", "train_ntokens": "260648", "train_nsentences": "1750.04", "train_wps": "87283.3", "train_ups": "0.33", "train_wpb": "260648", "train_bsz": "1750", "train_num_updates": "47401", "train_lr": "0.000479075", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "39.3", "train_wall": "21690"}
[2024-10-08 22:44:19,348][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:44:19,353][fairseq.trainer][INFO] - begin training epoch 989
[2024-10-08 22:44:19,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:46:32,629][fairseq_cli.train][INFO] - end of epoch 989 (average epoch stats below)
[2024-10-08 22:46:32,647][train][INFO] - {"epoch": 989, "train_loss": "0.531", "train_ntokens": "260928", "train_nsentences": "1750.04", "train_wps": "93839.7", "train_ups": "0.36", "train_wpb": "260928", "train_bsz": "1750", "train_num_updates": "47449", "train_lr": "0.00047901", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.8", "train_wall": "21823"}
[2024-10-08 22:46:32,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:46:32,817][fairseq.trainer][INFO] - begin training epoch 990
[2024-10-08 22:46:32,827][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:48:48,619][fairseq_cli.train][INFO] - end of epoch 990 (average epoch stats below)
[2024-10-08 22:48:48,624][train][INFO] - {"epoch": 990, "train_loss": "0.534", "train_ntokens": "260951", "train_nsentences": "1750.04", "train_wps": "92118.1", "train_ups": "0.35", "train_wpb": "260951", "train_bsz": "1750", "train_num_updates": "47497", "train_lr": "0.000478944", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.3", "train_wall": "21959"}
[2024-10-08 22:48:48,743][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:48:48,755][fairseq.trainer][INFO] - begin training epoch 991
[2024-10-08 22:48:48,756][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:51:04,689][fairseq_cli.train][INFO] - end of epoch 991 (average epoch stats below)
[2024-10-08 22:51:04,707][train][INFO] - {"epoch": 991, "train_loss": "0.531", "train_ntokens": "260557", "train_nsentences": "1750.04", "train_wps": "91917.2", "train_ups": "0.35", "train_wpb": "260557", "train_bsz": "1750", "train_num_updates": "47545", "train_lr": "0.000478879", "train_gnorm": "0.439", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.3", "train_wall": "22095"}
[2024-10-08 22:51:04,819][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:51:04,836][fairseq.trainer][INFO] - begin training epoch 992
[2024-10-08 22:51:04,837][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:53:17,783][fairseq_cli.train][INFO] - end of epoch 992 (average epoch stats below)
[2024-10-08 22:53:17,786][train][INFO] - {"epoch": 992, "train_loss": "0.535", "train_ntokens": "260787", "train_nsentences": "1750.04", "train_wps": "94065.3", "train_ups": "0.36", "train_wpb": "260787", "train_bsz": "1750", "train_num_updates": "47593", "train_lr": "0.000478814", "train_gnorm": "0.43", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "22228"}
[2024-10-08 22:53:17,850][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:53:17,854][fairseq.trainer][INFO] - begin training epoch 993
[2024-10-08 22:53:17,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:54:47,089][train_inner][INFO] - {"epoch": 993, "update": 992.146, "loss": "0.532", "ntokens": "260891", "nsentences": "1741.36", "wps": "83047.1", "ups": "0.32", "wpb": "260891", "bsz": "1741.4", "num_updates": "47600", "lr": "0.000478804", "gnorm": "0.413", "loss_scale": "2", "train_wall": "201", "gb_free": "39.6", "wall": "22318"}
[2024-10-08 22:55:24,317][fairseq_cli.train][INFO] - end of epoch 993 (average epoch stats below)
[2024-10-08 22:55:24,321][train][INFO] - {"epoch": 993, "train_loss": "0.534", "train_ntokens": "261082", "train_nsentences": "1750.04", "train_wps": "99042.2", "train_ups": "0.38", "train_wpb": "261082", "train_bsz": "1750", "train_num_updates": "47641", "train_lr": "0.000478749", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "39.1", "train_wall": "22355"}
[2024-10-08 22:55:24,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:55:24,478][fairseq.trainer][INFO] - begin training epoch 994
[2024-10-08 22:55:24,479][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:57:37,653][fairseq_cli.train][INFO] - end of epoch 994 (average epoch stats below)
[2024-10-08 22:57:37,658][train][INFO] - {"epoch": 994, "train_loss": "0.535", "train_ntokens": "261243", "train_nsentences": "1750.04", "train_wps": "94048.1", "train_ups": "0.36", "train_wpb": "261243", "train_bsz": "1750", "train_num_updates": "47689", "train_lr": "0.000478683", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "39.8", "train_wall": "22488"}
[2024-10-08 22:57:37,835][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:57:37,841][fairseq.trainer][INFO] - begin training epoch 995
[2024-10-08 22:57:37,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:59:53,129][fairseq_cli.train][INFO] - end of epoch 995 (average epoch stats below)
[2024-10-08 22:59:53,138][train][INFO] - {"epoch": 995, "train_loss": "0.524", "train_ntokens": "261112", "train_nsentences": "1750.04", "train_wps": "92513.8", "train_ups": "0.35", "train_wpb": "261112", "train_bsz": "1750", "train_num_updates": "47737", "train_lr": "0.000478618", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "22624"}
[2024-10-08 22:59:53,302][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 22:59:53,320][fairseq.trainer][INFO] - begin training epoch 996
[2024-10-08 22:59:53,320][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:02:06,677][fairseq_cli.train][INFO] - end of epoch 996 (average epoch stats below)
[2024-10-08 23:02:06,682][train][INFO] - {"epoch": 996, "train_loss": "0.531", "train_ntokens": "261237", "train_nsentences": "1750.04", "train_wps": "93900.3", "train_ups": "0.36", "train_wpb": "261237", "train_bsz": "1750", "train_num_updates": "47785", "train_lr": "0.000478553", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.7", "train_wall": "22757"}
[2024-10-08 23:02:06,834][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:02:06,845][fairseq.trainer][INFO] - begin training epoch 997
[2024-10-08 23:02:06,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:03:55,316][train_inner][INFO] - {"epoch": 997, "update": 996.312, "loss": "0.53", "ntokens": "261183", "nsentences": "1757.35", "wps": "95283.7", "ups": "0.36", "wpb": "261183", "bsz": "1757.4", "num_updates": "47800", "lr": "0.000478533", "gnorm": "0.377", "loss_scale": "2", "train_wall": "215", "gb_free": "40.8", "wall": "22866"}
[2024-10-08 23:04:18,305][fairseq_cli.train][INFO] - end of epoch 997 (average epoch stats below)
[2024-10-08 23:04:18,308][train][INFO] - {"epoch": 997, "train_loss": "0.526", "train_ntokens": "260830", "train_nsentences": "1750.04", "train_wps": "95119.5", "train_ups": "0.36", "train_wpb": "260830", "train_bsz": "1750", "train_num_updates": "47833", "train_lr": "0.000478488", "train_gnorm": "0.398", "train_loss_scale": "2", "train_train_wall": "37", "train_gb_free": "40.8", "train_wall": "22889"}
[2024-10-08 23:04:18,517][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:04:18,521][fairseq.trainer][INFO] - begin training epoch 998
[2024-10-08 23:04:18,522][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:06:31,122][fairseq_cli.train][INFO] - end of epoch 998 (average epoch stats below)
[2024-10-08 23:06:31,134][train][INFO] - {"epoch": 998, "train_loss": "0.53", "train_ntokens": "260825", "train_nsentences": "1750.04", "train_wps": "94264.1", "train_ups": "0.36", "train_wpb": "260825", "train_bsz": "1750", "train_num_updates": "47881", "train_lr": "0.000478423", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.2", "train_wall": "23022"}
[2024-10-08 23:06:31,258][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:06:31,262][fairseq.trainer][INFO] - begin training epoch 999
[2024-10-08 23:06:31,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:08:47,217][fairseq_cli.train][INFO] - end of epoch 999 (average epoch stats below)
[2024-10-08 23:08:47,226][train][INFO] - {"epoch": 999, "train_loss": "0.537", "train_ntokens": "260740", "train_nsentences": "1750.04", "train_wps": "91968.3", "train_ups": "0.35", "train_wpb": "260740", "train_bsz": "1750", "train_num_updates": "47929", "train_lr": "0.000478357", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.5", "train_wall": "23158"}
[2024-10-08 23:08:47,364][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:08:47,376][fairseq.trainer][INFO] - begin training epoch 1000
[2024-10-08 23:08:47,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:11:07,258][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1000 @ 47977 updates
[2024-10-08 23:11:07,259][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 23:11:11,277][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 23:11:11,280][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1000 @ 47977 updates, score None) (writing took 4.022010854445398 seconds)
[2024-10-08 23:11:11,280][fairseq_cli.train][INFO] - end of epoch 1000 (average epoch stats below)
[2024-10-08 23:11:11,283][train][INFO] - {"epoch": 1000, "train_loss": "0.528", "train_ntokens": "260135", "train_nsentences": "1750.04", "train_wps": "86680.4", "train_ups": "0.33", "train_wpb": "260135", "train_bsz": "1750", "train_num_updates": "47977", "train_lr": "0.000478292", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.3", "train_wall": "23302"}
[2024-10-08 23:11:11,394][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:11:11,411][fairseq.trainer][INFO] - begin training epoch 1001
[2024-10-08 23:11:11,412][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:13:02,594][train_inner][INFO] - {"epoch": 1001, "update": 1000.479, "loss": "0.53", "ntokens": "260399", "nsentences": "1761.22", "wps": "95162.9", "ups": "0.37", "wpb": "260399", "bsz": "1761.2", "num_updates": "48000", "lr": "0.000478261", "gnorm": "0.392", "loss_scale": "2", "train_wall": "225", "gb_free": "39.3", "wall": "23413"}
[2024-10-08 23:13:21,664][fairseq_cli.train][INFO] - end of epoch 1001 (average epoch stats below)
[2024-10-08 23:13:21,666][train][INFO] - {"epoch": 1001, "train_loss": "0.53", "train_ntokens": "260770", "train_nsentences": "1750.04", "train_wps": "96004", "train_ups": "0.37", "train_wpb": "260770", "train_bsz": "1750", "train_num_updates": "48025", "train_lr": "0.000478227", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "26", "train_gb_free": "40.8", "train_wall": "23432"}
[2024-10-08 23:13:21,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:13:21,845][fairseq.trainer][INFO] - begin training epoch 1002
[2024-10-08 23:13:21,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:15:38,446][fairseq_cli.train][INFO] - end of epoch 1002 (average epoch stats below)
[2024-10-08 23:15:38,453][train][INFO] - {"epoch": 1002, "train_loss": "0.532", "train_ntokens": "260833", "train_nsentences": "1750.04", "train_wps": "91532", "train_ups": "0.35", "train_wpb": "260832", "train_bsz": "1750", "train_num_updates": "48073", "train_lr": "0.000478162", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.7", "train_wall": "23569"}
[2024-10-08 23:15:38,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:15:38,558][fairseq.trainer][INFO] - begin training epoch 1003
[2024-10-08 23:15:38,558][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:17:52,821][fairseq_cli.train][INFO] - end of epoch 1003 (average epoch stats below)
[2024-10-08 23:17:52,825][train][INFO] - {"epoch": 1003, "train_loss": "0.532", "train_ntokens": "260474", "train_nsentences": "1750.04", "train_wps": "93048.2", "train_ups": "0.36", "train_wpb": "260474", "train_bsz": "1750", "train_num_updates": "48121", "train_lr": "0.000478096", "train_gnorm": "0.404", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40.3", "train_wall": "23703"}
[2024-10-08 23:17:52,925][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:17:52,943][fairseq.trainer][INFO] - begin training epoch 1004
[2024-10-08 23:17:52,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:20:08,057][fairseq_cli.train][INFO] - end of epoch 1004 (average epoch stats below)
[2024-10-08 23:20:08,060][train][INFO] - {"epoch": 1004, "train_loss": "0.532", "train_ntokens": "260697", "train_nsentences": "1750.04", "train_wps": "92532.7", "train_ups": "0.35", "train_wpb": "260696", "train_bsz": "1750", "train_num_updates": "48169", "train_lr": "0.000478031", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.8", "train_wall": "23839"}
[2024-10-08 23:20:08,208][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:20:08,216][fairseq.trainer][INFO] - begin training epoch 1005
[2024-10-08 23:20:08,217][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:22:09,250][train_inner][INFO] - {"epoch": 1005, "update": 1004.646, "loss": "0.533", "ntokens": "260780", "nsentences": "1749.41", "wps": "95410.3", "ups": "0.37", "wpb": "260780", "bsz": "1749.4", "num_updates": "48200", "lr": "0.000477989", "gnorm": "0.386", "loss_scale": "2", "train_wall": "232", "gb_free": "39.7", "wall": "23960"}
[2024-10-08 23:22:21,921][fairseq_cli.train][INFO] - end of epoch 1005 (average epoch stats below)
[2024-10-08 23:22:21,926][train][INFO] - {"epoch": 1005, "train_loss": "0.532", "train_ntokens": "260845", "train_nsentences": "1750.04", "train_wps": "93535.4", "train_ups": "0.36", "train_wpb": "260845", "train_bsz": "1750", "train_num_updates": "48217", "train_lr": "0.000477966", "train_gnorm": "0.358", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.6", "train_wall": "23973"}
[2024-10-08 23:22:22,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:22:22,109][fairseq.trainer][INFO] - begin training epoch 1006
[2024-10-08 23:22:22,109][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:24:34,079][fairseq_cli.train][INFO] - end of epoch 1006 (average epoch stats below)
[2024-10-08 23:24:34,090][train][INFO] - {"epoch": 1006, "train_loss": "0.532", "train_ntokens": "260510", "train_nsentences": "1750.04", "train_wps": "94621.8", "train_ups": "0.36", "train_wpb": "260510", "train_bsz": "1750", "train_num_updates": "48265", "train_lr": "0.000477901", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40.2", "train_wall": "24105"}
[2024-10-08 23:24:34,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:24:34,244][fairseq.trainer][INFO] - begin training epoch 1007
[2024-10-08 23:24:34,244][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:26:41,381][fairseq_cli.train][INFO] - end of epoch 1007 (average epoch stats below)
[2024-10-08 23:26:41,390][train][INFO] - {"epoch": 1007, "train_loss": "0.529", "train_ntokens": "260853", "train_nsentences": "1750.04", "train_wps": "98365.5", "train_ups": "0.38", "train_wpb": "260853", "train_bsz": "1750", "train_num_updates": "48313", "train_lr": "0.000477836", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.6", "train_wall": "24232"}
[2024-10-08 23:26:41,470][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:26:41,474][fairseq.trainer][INFO] - begin training epoch 1008
[2024-10-08 23:26:41,475][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:28:50,442][fairseq_cli.train][INFO] - end of epoch 1008 (average epoch stats below)
[2024-10-08 23:28:50,457][train][INFO] - {"epoch": 1008, "train_loss": "0.525", "train_ntokens": "260909", "train_nsentences": "1750.04", "train_wps": "97043", "train_ups": "0.37", "train_wpb": "260909", "train_bsz": "1750", "train_num_updates": "48361", "train_lr": "0.00047777", "train_gnorm": "0.356", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "39.1", "train_wall": "24361"}
[2024-10-08 23:28:50,574][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:28:50,578][fairseq.trainer][INFO] - begin training epoch 1009
[2024-10-08 23:28:50,579][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:30:48,183][train_inner][INFO] - {"epoch": 1009, "update": 1008.812, "loss": "0.528", "ntokens": "260720", "nsentences": "1742.99", "wps": "100489", "ups": "0.39", "wpb": "260720", "bsz": "1743", "num_updates": "48400", "lr": "0.000477717", "gnorm": "0.383", "loss_scale": "2", "train_wall": "191", "gb_free": "39.7", "wall": "24479"}
[2024-10-08 23:30:56,770][fairseq_cli.train][INFO] - end of epoch 1009 (average epoch stats below)
[2024-10-08 23:30:56,774][train][INFO] - {"epoch": 1009, "train_loss": "0.526", "train_ntokens": "260668", "train_nsentences": "1750.04", "train_wps": "99055.7", "train_ups": "0.38", "train_wpb": "260668", "train_bsz": "1750", "train_num_updates": "48409", "train_lr": "0.000477705", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.7", "train_wall": "24487"}
[2024-10-08 23:30:56,885][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:30:56,891][fairseq.trainer][INFO] - begin training epoch 1010
[2024-10-08 23:30:56,895][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:33:06,451][fairseq_cli.train][INFO] - end of epoch 1010 (average epoch stats below)
[2024-10-08 23:33:06,475][train][INFO] - {"epoch": 1010, "train_loss": "0.533", "train_ntokens": "260550", "train_nsentences": "1750.04", "train_wps": "96437", "train_ups": "0.37", "train_wpb": "260550", "train_bsz": "1750", "train_num_updates": "48457", "train_lr": "0.00047764", "train_gnorm": "0.354", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.6", "train_wall": "24617"}
[2024-10-08 23:33:06,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:33:06,589][fairseq.trainer][INFO] - begin training epoch 1011
[2024-10-08 23:33:06,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:35:16,436][fairseq_cli.train][INFO] - end of epoch 1011 (average epoch stats below)
[2024-10-08 23:35:16,447][train][INFO] - {"epoch": 1011, "train_loss": "0.529", "train_ntokens": "260799", "train_nsentences": "1750.04", "train_wps": "96320", "train_ups": "0.37", "train_wpb": "260799", "train_bsz": "1750", "train_num_updates": "48505", "train_lr": "0.000477575", "train_gnorm": "0.355", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "39.6", "train_wall": "24747"}
[2024-10-08 23:35:16,621][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:35:16,641][fairseq.trainer][INFO] - begin training epoch 1012
[2024-10-08 23:35:16,641][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:37:26,716][fairseq_cli.train][INFO] - end of epoch 1012 (average epoch stats below)
[2024-10-08 23:37:26,740][train][INFO] - {"epoch": 1012, "train_loss": "0.523", "train_ntokens": "260821", "train_nsentences": "1750.04", "train_wps": "96089.5", "train_ups": "0.37", "train_wpb": "260821", "train_bsz": "1750", "train_num_updates": "48553", "train_lr": "0.00047751", "train_gnorm": "0.403", "train_loss_scale": "4", "train_train_wall": "51", "train_gb_free": "39.1", "train_wall": "24877"}
[2024-10-08 23:37:26,873][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:37:26,886][fairseq.trainer][INFO] - begin training epoch 1013
[2024-10-08 23:37:26,886][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:39:03,247][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 23:39:41,070][train_inner][INFO] - {"epoch": 1013, "update": 1013.0, "loss": "0.528", "ntokens": "260881", "nsentences": "1746.01", "wps": "97917.7", "ups": "0.38", "wpb": "260880", "bsz": "1746", "num_updates": "48600", "lr": "0.000477446", "gnorm": "0.38", "loss_scale": "2", "train_wall": "215", "gb_free": "40.2", "wall": "25012"}
[2024-10-08 23:39:41,075][fairseq_cli.train][INFO] - end of epoch 1013 (average epoch stats below)
[2024-10-08 23:39:41,076][train][INFO] - {"epoch": 1013, "train_loss": "0.531", "train_ntokens": "261104", "train_nsentences": "1735.06", "train_wps": "91354", "train_ups": "0.35", "train_wpb": "261104", "train_bsz": "1735.1", "train_num_updates": "48600", "train_lr": "0.000477446", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "37", "train_gb_free": "40.2", "train_wall": "25012"}
[2024-10-08 23:39:41,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:39:41,245][fairseq.trainer][INFO] - begin training epoch 1014
[2024-10-08 23:39:41,246][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:41:50,739][fairseq_cli.train][INFO] - end of epoch 1014 (average epoch stats below)
[2024-10-08 23:41:50,747][train][INFO] - {"epoch": 1014, "train_loss": "0.531", "train_ntokens": "260462", "train_nsentences": "1750.04", "train_wps": "96419.3", "train_ups": "0.37", "train_wpb": "260462", "train_bsz": "1750", "train_num_updates": "48648", "train_lr": "0.00047738", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.9", "train_wall": "25141"}
[2024-10-08 23:41:50,948][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:41:50,962][fairseq.trainer][INFO] - begin training epoch 1015
[2024-10-08 23:41:50,963][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:44:03,538][fairseq_cli.train][INFO] - end of epoch 1015 (average epoch stats below)
[2024-10-08 23:44:03,541][train][INFO] - {"epoch": 1015, "train_loss": "0.535", "train_ntokens": "260780", "train_nsentences": "1750.04", "train_wps": "94264.1", "train_ups": "0.36", "train_wpb": "260780", "train_bsz": "1750", "train_num_updates": "48696", "train_lr": "0.000477315", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "41.3", "train_wall": "25274"}
[2024-10-08 23:44:03,685][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:44:03,689][fairseq.trainer][INFO] - begin training epoch 1016
[2024-10-08 23:44:03,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:46:17,211][fairseq_cli.train][INFO] - end of epoch 1016 (average epoch stats below)
[2024-10-08 23:46:17,215][train][INFO] - {"epoch": 1016, "train_loss": "0.525", "train_ntokens": "260624", "train_nsentences": "1750.04", "train_wps": "93588.7", "train_ups": "0.36", "train_wpb": "260624", "train_bsz": "1750", "train_num_updates": "48744", "train_lr": "0.00047725", "train_gnorm": "0.356", "train_loss_scale": "2", "train_train_wall": "30", "train_gb_free": "40.7", "train_wall": "25408"}
[2024-10-08 23:46:17,354][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:46:17,361][fairseq.trainer][INFO] - begin training epoch 1017
[2024-10-08 23:46:17,362][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:48:30,493][fairseq_cli.train][INFO] - end of epoch 1017 (average epoch stats below)
[2024-10-08 23:48:30,501][train][INFO] - {"epoch": 1017, "train_loss": "0.529", "train_ntokens": "261035", "train_nsentences": "1750.04", "train_wps": "94009.3", "train_ups": "0.36", "train_wpb": "261035", "train_bsz": "1750", "train_num_updates": "48792", "train_lr": "0.000477185", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "40", "train_wall": "25541"}
[2024-10-08 23:48:30,663][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:48:30,668][fairseq.trainer][INFO] - begin training epoch 1018
[2024-10-08 23:48:30,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:50:17,132][train_inner][INFO] - {"epoch": 1018, "update": 1017.167, "loss": "0.529", "ntokens": "260500", "nsentences": "1760.41", "wps": "81911.2", "ups": "0.31", "wpb": "260500", "bsz": "1760.4", "num_updates": "48800", "lr": "0.000477174", "gnorm": "0.376", "loss_scale": "2", "train_wall": "233", "gb_free": "39.3", "wall": "25648"}
[2024-10-08 23:50:45,264][fairseq_cli.train][INFO] - end of epoch 1018 (average epoch stats below)
[2024-10-08 23:50:45,268][train][INFO] - {"epoch": 1018, "train_loss": "0.525", "train_ntokens": "260644", "train_nsentences": "1750.04", "train_wps": "92838.5", "train_ups": "0.36", "train_wpb": "260644", "train_bsz": "1750", "train_num_updates": "48840", "train_lr": "0.00047712", "train_gnorm": "0.409", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40.3", "train_wall": "25676"}
[2024-10-08 23:50:45,412][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:50:45,428][fairseq.trainer][INFO] - begin training epoch 1019
[2024-10-08 23:50:45,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:52:58,720][fairseq_cli.train][INFO] - end of epoch 1019 (average epoch stats below)
[2024-10-08 23:52:58,729][train][INFO] - {"epoch": 1019, "train_loss": "0.527", "train_ntokens": "260815", "train_nsentences": "1750.04", "train_wps": "93806.3", "train_ups": "0.36", "train_wpb": "260815", "train_bsz": "1750", "train_num_updates": "48888", "train_lr": "0.000477054", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "25809"}
[2024-10-08 23:52:58,884][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:52:58,893][fairseq.trainer][INFO] - begin training epoch 1020
[2024-10-08 23:52:58,894][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:55:08,041][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1020 @ 48936 updates
[2024-10-08 23:55:08,042][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 23:55:11,316][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-08 23:55:11,318][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1020 @ 48936 updates, score None) (writing took 3.276779701001942 seconds)
[2024-10-08 23:55:11,318][fairseq_cli.train][INFO] - end of epoch 1020 (average epoch stats below)
[2024-10-08 23:55:11,321][train][INFO] - {"epoch": 1020, "train_loss": "0.523", "train_ntokens": "260682", "train_nsentences": "1750.04", "train_wps": "94373.3", "train_ups": "0.36", "train_wpb": "260682", "train_bsz": "1750", "train_num_updates": "48936", "train_lr": "0.000476989", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "40.1", "train_wall": "25942"}
[2024-10-08 23:55:11,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:55:11,391][fairseq.trainer][INFO] - begin training epoch 1021
[2024-10-08 23:55:11,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:57:15,430][fairseq_cli.train][INFO] - end of epoch 1021 (average epoch stats below)
[2024-10-08 23:57:15,434][train][INFO] - {"epoch": 1021, "train_loss": "0.531", "train_ntokens": "260696", "train_nsentences": "1750.04", "train_wps": "100826", "train_ups": "0.39", "train_wpb": "260696", "train_bsz": "1750", "train_num_updates": "48984", "train_lr": "0.000476924", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "28", "train_gb_free": "40.1", "train_wall": "26066"}
[2024-10-08 23:57:15,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:57:15,495][fairseq.trainer][INFO] - begin training epoch 1022
[2024-10-08 23:57:15,496][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:58:54,110][train_inner][INFO] - {"epoch": 1022, "update": 1021.333, "loss": "0.527", "ntokens": "260948", "nsentences": "1734.88", "wps": "100953", "ups": "0.39", "wpb": "260948", "bsz": "1734.9", "num_updates": "49000", "lr": "0.000476902", "gnorm": "0.388", "loss_scale": "2", "train_wall": "181", "gb_free": "40", "wall": "26165"}
[2024-10-08 23:59:26,233][fairseq_cli.train][INFO] - end of epoch 1022 (average epoch stats below)
[2024-10-08 23:59:26,240][train][INFO] - {"epoch": 1022, "train_loss": "0.522", "train_ntokens": "261181", "train_nsentences": "1750.04", "train_wps": "95848.3", "train_ups": "0.37", "train_wpb": "261181", "train_bsz": "1750", "train_num_updates": "49032", "train_lr": "0.000476859", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "39.6", "train_wall": "26197"}
[2024-10-08 23:59:26,297][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-08 23:59:26,300][fairseq.trainer][INFO] - begin training epoch 1023
[2024-10-08 23:59:26,301][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:01:31,636][fairseq_cli.train][INFO] - end of epoch 1023 (average epoch stats below)
[2024-10-09 00:01:31,639][train][INFO] - {"epoch": 1023, "train_loss": "0.529", "train_ntokens": "260509", "train_nsentences": "1750.04", "train_wps": "99719.8", "train_ups": "0.38", "train_wpb": "260509", "train_bsz": "1750", "train_num_updates": "49080", "train_lr": "0.000476793", "train_gnorm": "0.418", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "40.5", "train_wall": "26322"}
[2024-10-09 00:01:31,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:01:31,732][fairseq.trainer][INFO] - begin training epoch 1024
[2024-10-09 00:01:31,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:03:41,441][fairseq_cli.train][INFO] - end of epoch 1024 (average epoch stats below)
[2024-10-09 00:03:41,447][train][INFO] - {"epoch": 1024, "train_loss": "0.524", "train_ntokens": "260589", "train_nsentences": "1750.04", "train_wps": "96365.2", "train_ups": "0.37", "train_wpb": "260589", "train_bsz": "1750", "train_num_updates": "49128", "train_lr": "0.000476728", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.7", "train_wall": "26452"}
[2024-10-09 00:03:41,506][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:03:41,519][fairseq.trainer][INFO] - begin training epoch 1025
[2024-10-09 00:03:41,520][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:05:55,104][fairseq_cli.train][INFO] - end of epoch 1025 (average epoch stats below)
[2024-10-09 00:05:55,117][train][INFO] - {"epoch": 1025, "train_loss": "0.525", "train_ntokens": "260102", "train_nsentences": "1750.04", "train_wps": "93407", "train_ups": "0.36", "train_wpb": "260102", "train_bsz": "1750", "train_num_updates": "49176", "train_lr": "0.000476663", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.7", "train_wall": "26586"}
[2024-10-09 00:05:55,265][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:05:55,268][fairseq.trainer][INFO] - begin training epoch 1026
[2024-10-09 00:05:55,269][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:07:45,574][train_inner][INFO] - {"epoch": 1026, "update": 1025.5, "loss": "0.526", "ntokens": "260683", "nsentences": "1752.6", "wps": "98101.1", "ups": "0.38", "wpb": "260683", "bsz": "1752.6", "num_updates": "49200", "lr": "0.00047663", "gnorm": "0.4", "loss_scale": "2", "train_wall": "224", "gb_free": "39.9", "wall": "26696"}
[2024-10-09 00:08:06,973][fairseq_cli.train][INFO] - end of epoch 1026 (average epoch stats below)
[2024-10-09 00:08:06,978][train][INFO] - {"epoch": 1026, "train_loss": "0.527", "train_ntokens": "260775", "train_nsentences": "1750.04", "train_wps": "94933.4", "train_ups": "0.36", "train_wpb": "260775", "train_bsz": "1750", "train_num_updates": "49224", "train_lr": "0.000476598", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.8", "train_wall": "26718"}
[2024-10-09 00:08:07,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:08:07,151][fairseq.trainer][INFO] - begin training epoch 1027
[2024-10-09 00:08:07,151][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:10:24,416][fairseq_cli.train][INFO] - end of epoch 1027 (average epoch stats below)
[2024-10-09 00:10:24,423][train][INFO] - {"epoch": 1027, "train_loss": "0.522", "train_ntokens": "260868", "train_nsentences": "1750.04", "train_wps": "91105.5", "train_ups": "0.35", "train_wpb": "260868", "train_bsz": "1750", "train_num_updates": "49272", "train_lr": "0.000476533", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.3", "train_wall": "26855"}
[2024-10-09 00:10:24,588][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:10:24,592][fairseq.trainer][INFO] - begin training epoch 1028
[2024-10-09 00:10:24,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:12:39,494][fairseq_cli.train][INFO] - end of epoch 1028 (average epoch stats below)
[2024-10-09 00:12:39,497][train][INFO] - {"epoch": 1028, "train_loss": "0.525", "train_ntokens": "261081", "train_nsentences": "1750.04", "train_wps": "92784.2", "train_ups": "0.36", "train_wpb": "261081", "train_bsz": "1750", "train_num_updates": "49320", "train_lr": "0.000476467", "train_gnorm": "0.416", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.7", "train_wall": "26990"}
[2024-10-09 00:12:39,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:12:39,585][fairseq.trainer][INFO] - begin training epoch 1029
[2024-10-09 00:12:39,585][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:14:54,805][fairseq_cli.train][INFO] - end of epoch 1029 (average epoch stats below)
[2024-10-09 00:14:54,817][train][INFO] - {"epoch": 1029, "train_loss": "0.531", "train_ntokens": "260797", "train_nsentences": "1750.04", "train_wps": "92512.8", "train_ups": "0.35", "train_wpb": "260797", "train_bsz": "1750", "train_num_updates": "49368", "train_lr": "0.000476402", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.6", "train_wall": "27125"}
[2024-10-09 00:14:54,969][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:14:54,982][fairseq.trainer][INFO] - begin training epoch 1030
[2024-10-09 00:14:54,983][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:16:52,191][train_inner][INFO] - {"epoch": 1030, "update": 1029.667, "loss": "0.524", "ntokens": "260725", "nsentences": "1750.97", "wps": "95397.1", "ups": "0.37", "wpb": "260725", "bsz": "1751", "num_updates": "49400", "lr": "0.000476359", "gnorm": "0.389", "loss_scale": "2", "train_wall": "215", "gb_free": "39.7", "wall": "27243"}
[2024-10-09 00:17:07,421][fairseq_cli.train][INFO] - end of epoch 1030 (average epoch stats below)
[2024-10-09 00:17:07,425][train][INFO] - {"epoch": 1030, "train_loss": "0.521", "train_ntokens": "260161", "train_nsentences": "1750.04", "train_wps": "94173.8", "train_ups": "0.36", "train_wpb": "260161", "train_bsz": "1750", "train_num_updates": "49416", "train_lr": "0.000476337", "train_gnorm": "0.402", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "39.3", "train_wall": "27258"}
[2024-10-09 00:17:07,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:17:07,546][fairseq.trainer][INFO] - begin training epoch 1031
[2024-10-09 00:17:07,546][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:19:23,970][fairseq_cli.train][INFO] - end of epoch 1031 (average epoch stats below)
[2024-10-09 00:19:23,973][train][INFO] - {"epoch": 1031, "train_loss": "0.518", "train_ntokens": "260893", "train_nsentences": "1750.04", "train_wps": "91712.6", "train_ups": "0.35", "train_wpb": "260893", "train_bsz": "1750", "train_num_updates": "49464", "train_lr": "0.000476272", "train_gnorm": "0.39", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.7", "train_wall": "27395"}
[2024-10-09 00:19:24,086][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:19:24,092][fairseq.trainer][INFO] - begin training epoch 1032
[2024-10-09 00:19:24,093][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:21:36,113][fairseq_cli.train][INFO] - end of epoch 1032 (average epoch stats below)
[2024-10-09 00:21:36,120][train][INFO] - {"epoch": 1032, "train_loss": "0.523", "train_ntokens": "260652", "train_nsentences": "1750.04", "train_wps": "94680.7", "train_ups": "0.36", "train_wpb": "260652", "train_bsz": "1750", "train_num_updates": "49512", "train_lr": "0.000476207", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.8", "train_wall": "27527"}
[2024-10-09 00:21:36,226][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:21:36,240][fairseq.trainer][INFO] - begin training epoch 1033
[2024-10-09 00:21:36,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:23:51,771][fairseq_cli.train][INFO] - end of epoch 1033 (average epoch stats below)
[2024-10-09 00:23:51,787][train][INFO] - {"epoch": 1033, "train_loss": "0.523", "train_ntokens": "260637", "train_nsentences": "1750.04", "train_wps": "92225.7", "train_ups": "0.35", "train_wpb": "260637", "train_bsz": "1750", "train_num_updates": "49560", "train_lr": "0.000476141", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "40.3", "train_wall": "27662"}
[2024-10-09 00:23:51,885][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:23:51,905][fairseq.trainer][INFO] - begin training epoch 1034
[2024-10-09 00:23:51,906][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:25:59,100][train_inner][INFO] - {"epoch": 1034, "update": 1033.833, "loss": "0.523", "ntokens": "260783", "nsentences": "1738.89", "wps": "95367.6", "ups": "0.37", "wpb": "260783", "bsz": "1738.9", "num_updates": "49600", "lr": "0.000476087", "gnorm": "0.382", "loss_scale": "2", "train_wall": "211", "gb_free": "40.4", "wall": "27790"}
[2024-10-09 00:26:02,529][fairseq_cli.train][INFO] - end of epoch 1034 (average epoch stats below)
[2024-10-09 00:26:02,533][train][INFO] - {"epoch": 1034, "train_loss": "0.527", "train_ntokens": "260781", "train_nsentences": "1750.04", "train_wps": "95743.2", "train_ups": "0.37", "train_wpb": "260781", "train_bsz": "1750", "train_num_updates": "49608", "train_lr": "0.000476076", "train_gnorm": "0.365", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "39.7", "train_wall": "27793"}
[2024-10-09 00:26:02,663][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:26:02,681][fairseq.trainer][INFO] - begin training epoch 1035
[2024-10-09 00:26:02,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:28:16,042][fairseq_cli.train][INFO] - end of epoch 1035 (average epoch stats below)
[2024-10-09 00:28:16,045][train][INFO] - {"epoch": 1035, "train_loss": "0.529", "train_ntokens": "260830", "train_nsentences": "1750.04", "train_wps": "93781.9", "train_ups": "0.36", "train_wpb": "260830", "train_bsz": "1750", "train_num_updates": "49656", "train_lr": "0.000476011", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.1", "train_wall": "27927"}
[2024-10-09 00:28:16,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:28:16,225][fairseq.trainer][INFO] - begin training epoch 1036
[2024-10-09 00:28:16,226][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:30:24,404][fairseq_cli.train][INFO] - end of epoch 1036 (average epoch stats below)
[2024-10-09 00:30:24,421][train][INFO] - {"epoch": 1036, "train_loss": "0.525", "train_ntokens": "260784", "train_nsentences": "1750.04", "train_wps": "97511.8", "train_ups": "0.37", "train_wpb": "260784", "train_bsz": "1750", "train_num_updates": "49704", "train_lr": "0.000475946", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "29", "train_gb_free": "39.3", "train_wall": "28055"}
[2024-10-09 00:30:24,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:30:24,495][fairseq.trainer][INFO] - begin training epoch 1037
[2024-10-09 00:30:24,495][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:32:32,743][fairseq_cli.train][INFO] - end of epoch 1037 (average epoch stats below)
[2024-10-09 00:32:32,746][train][INFO] - {"epoch": 1037, "train_loss": "0.528", "train_ntokens": "260508", "train_nsentences": "1750.04", "train_wps": "97446.6", "train_ups": "0.37", "train_wpb": "260508", "train_bsz": "1750", "train_num_updates": "49752", "train_lr": "0.00047588", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "28183"}
[2024-10-09 00:32:32,808][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:32:32,811][fairseq.trainer][INFO] - begin training epoch 1038
[2024-10-09 00:32:32,812][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:34:41,269][train_inner][INFO] - {"epoch": 1038, "update": 1038.0, "loss": "0.528", "ntokens": "260616", "nsentences": "1762.51", "wps": "99825.2", "ups": "0.38", "wpb": "260616", "bsz": "1762.5", "num_updates": "49800", "lr": "0.000475815", "gnorm": "0.4", "loss_scale": "2", "train_wall": "197", "gb_free": "40", "wall": "28312"}
[2024-10-09 00:34:41,275][fairseq_cli.train][INFO] - end of epoch 1038 (average epoch stats below)
[2024-10-09 00:34:41,276][train][INFO] - {"epoch": 1038, "train_loss": "0.531", "train_ntokens": "260848", "train_nsentences": "1750.04", "train_wps": "97417.6", "train_ups": "0.37", "train_wpb": "260848", "train_bsz": "1750", "train_num_updates": "49800", "train_lr": "0.000475815", "train_gnorm": "0.467", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "40", "train_wall": "28312"}
[2024-10-09 00:34:41,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:34:41,415][fairseq.trainer][INFO] - begin training epoch 1039
[2024-10-09 00:34:41,415][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:36:53,870][fairseq_cli.train][INFO] - end of epoch 1039 (average epoch stats below)
[2024-10-09 00:36:53,876][train][INFO] - {"epoch": 1039, "train_loss": "0.519", "train_ntokens": "260642", "train_nsentences": "1750.04", "train_wps": "94352.5", "train_ups": "0.36", "train_wpb": "260642", "train_bsz": "1750", "train_num_updates": "49848", "train_lr": "0.00047575", "train_gnorm": "0.427", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "39.6", "train_wall": "28445"}
[2024-10-09 00:36:54,056][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:36:54,061][fairseq.trainer][INFO] - begin training epoch 1040
[2024-10-09 00:36:54,061][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:39:09,347][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1040 @ 49896 updates
[2024-10-09 00:39:09,349][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 00:39:13,245][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 00:39:13,248][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1040 @ 49896 updates, score None) (writing took 3.900503725744784 seconds)
[2024-10-09 00:39:13,248][fairseq_cli.train][INFO] - end of epoch 1040 (average epoch stats below)
[2024-10-09 00:39:13,251][train][INFO] - {"epoch": 1040, "train_loss": "0.515", "train_ntokens": "260642", "train_nsentences": "1750.04", "train_wps": "89767.1", "train_ups": "0.34", "train_wpb": "260642", "train_bsz": "1750", "train_num_updates": "49896", "train_lr": "0.000475685", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "28584"}
[2024-10-09 00:39:13,390][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 00:39:13,420][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 00:39:13,420][fairseq_cli.train][INFO] - Start iterating over samples
