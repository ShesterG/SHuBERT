[2024-10-07 00:21:32,071][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18160', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:32,546][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13006', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:33,747][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14597', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:33,858][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11702', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:36,183][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18121', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:36,306][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11948', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:36,391][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:36,395][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:36,395][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:36,395][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:36,396][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:36,397][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:36,509][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10798', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:37,057][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:37,438][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16924', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 00:21:39,007][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:39,027][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:39,028][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:39,033][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:39,034][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:39,039][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:39,197][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:39,236][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:39,239][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:39,239][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:39,240][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:39,240][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:40,661][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:41,100][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:41,102][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:41,104][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:41,104][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:41,105][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:41,105][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:41,204][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:41,531][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:44,424][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:44,439][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:44,439][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:44,439][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:44,440][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:44,447][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:44,561][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:44,592][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:44,592][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:44,592][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:44,593][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:44,594][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:45,876][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:47,069][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:21:47,767][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:21:47,771][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:21:47,775][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:21:47,775][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:21:47,776][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:21:47,776][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:21:48,112][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:22:10,764][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 00:22:11,447][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 00:22:11,447][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 00:22:11,447][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 00:22:11,448][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 00:22:11,448][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 00:22:18,587][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:22:47,682][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:22:47,687][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:22:47,687][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:22:47,687][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:22:47,688][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:23:04,356][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:04,357][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:23:04,358][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:23:04,358][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:23:04,360][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:23:30,689][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:23:30,698][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:23:31,436][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:23:33,069][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:23:33,071][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:23:33,385][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:23:40,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:23:40,182][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:23:40,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:23:40,886][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:23:40,887][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:23:40,903][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:23:40,904][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:23:40,904][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:23:40,905][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:23:49,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:23:49,772][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:23:49,773][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:24:13,813][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:24:13,824][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:24:14,530][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:24:21,714][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:21,715][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:24:21,716][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:24:21,895][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:24:21,989][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:24:28,298][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:24:28,312][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:24:28,313][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:24:43,493][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:24:43,494][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:24:43,499][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:24:43,499][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:24:43,500][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:24:43,501][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:25:07,762][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:07,771][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:07,780][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:07,780][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:25:07,781][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:25:07,781][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:25:15,284][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,290][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:15,291][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:15,291][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:25:15,295][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:25:15,296][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:25:19,057][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:25:19,067][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:25:20,743][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:25:24,058][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:25:24,060][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:25:24,450][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:25:32,603][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-07 00:25:32,607][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 00:25:32,608][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 00:25:32,608][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 00:25:32,609][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 00:25:33,378][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:25:33,392][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:25:33,393][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:25:40,404][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:25:40,419][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:25:40,443][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:25:44,136][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:25:44,138][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:25:44,277][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:25:44,279][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:25:45,113][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:25:47,993][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:25:56,274][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:25:56,277][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:25:56,278][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:26:03,751][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:26:03,772][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:26:03,773][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:26:11,881][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 461 @ 22067 updates)
[2024-10-07 00:26:11,892][fairseq.trainer][INFO] - loading train data for epoch 461
[2024-10-07 00:26:12,142][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-07 00:26:18,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:26:18,214][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-07 00:26:18,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:33:14,159][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 
[2024-10-07 00:33:14,251][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1586 MiB |   1619 MiB |   1652 MiB |  67766 KiB |
|       from large pool |   1549 MiB |   1549 MiB |   1549 MiB |      0 KiB |
|       from small pool |     37 MiB |    102 MiB |    103 MiB |  67766 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1586 MiB |   1619 MiB |   1652 MiB |  67766 KiB |
|       from large pool |   1549 MiB |   1549 MiB |   1549 MiB |      0 KiB |
|       from small pool |     37 MiB |    102 MiB |    103 MiB |  67766 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1579 MiB |   1612 MiB |   1645 MiB |  67746 KiB |
|       from large pool |   1542 MiB |   1542 MiB |   1542 MiB |      0 KiB |
|       from small pool |     36 MiB |    102 MiB |    102 MiB |  67746 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1672 MiB |   1672 MiB |   1672 MiB |      0 B   |
|       from large pool |   1568 MiB |   1568 MiB |   1568 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  87375 KiB |  88248 KiB | 338546 KiB | 251171 KiB |
|       from large pool |  18835 KiB |  20224 KiB | 170771 KiB | 151936 KiB |
|       from small pool |  68540 KiB |  69413 KiB | 167775 KiB |  99235 KiB |
|---------------------------------------------------------------------------|
| Allocations           |    1129    |    1565    |    1574    |     445    |
|       from large pool |      81    |      81    |      81    |       0    |
|       from small pool |    1048    |    1487    |    1493    |     445    |
|---------------------------------------------------------------------------|
| Active allocs         |    1129    |    1565    |    1574    |     445    |
|       from large pool |      81    |      81    |      81    |       0    |
|       from small pool |    1048    |    1487    |    1493    |     445    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      68    |      68    |      68    |       0    |
|       from large pool |      16    |      16    |      16    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     175    |     175    |     264    |      89    |
|       from large pool |       8    |       8    |      16    |       8    |
|       from small pool |     167    |     167    |     248    |      81    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,271][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,272][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,272][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,272][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,273][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,273][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,273][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,273][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-07 00:33:14,420][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 
[2024-10-07 00:33:14,425][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   3139 MiB |   3313 MiB |   4268 MiB |   1129 MiB |
|       from large pool |   3098 MiB |   3273 MiB |   4142 MiB |   1043 MiB |
|       from small pool |     40 MiB |    102 MiB |    126 MiB |     85 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   3139 MiB |   3313 MiB |   4268 MiB |   1129 MiB |
|       from large pool |   3098 MiB |   3273 MiB |   4142 MiB |   1043 MiB |
|       from small pool |     40 MiB |    102 MiB |    126 MiB |     85 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   3122 MiB |   3297 MiB |   4248 MiB |   1125 MiB |
|       from large pool |   3082 MiB |   3256 MiB |   4122 MiB |   1039 MiB |
|       from small pool |     40 MiB |    102 MiB |    126 MiB |     85 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   3472 MiB |   3472 MiB |   3472 MiB |      0 B   |
|       from large pool |   3368 MiB |   3368 MiB |   3368 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 160233 KiB | 283754 KiB |   1020 MiB |    863 MiB |
|       from large pool |  95364 KiB | 218074 KiB |    836 MiB |    743 MiB |
|       from small pool |  64869 KiB |  69413 KiB |    183 MiB |    120 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1210    |    1565    |    1700    |     490    |
|       from large pool |     136    |     137    |     156    |      20    |
|       from small pool |    1074    |    1487    |    1544    |     470    |
|---------------------------------------------------------------------------|
| Active allocs         |    1210    |    1565    |    1700    |     490    |
|       from large pool |     136    |     137    |     156    |      20    |
|       from small pool |    1074    |    1487    |    1544    |     470    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     103    |     103    |     103    |       0    |
|       from large pool |      51    |      51    |      51    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     186    |     187    |     289    |     103    |
|       from large pool |      21    |      22    |      40    |      19    |
|       from small pool |     165    |     167    |     249    |      84    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,425][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,430][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,431][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,431][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,432][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,435][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,435][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:14,440][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-07 00:33:25,233][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 
[2024-10-07 00:33:25,234][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1608 MiB |   1619 MiB |   1674 MiB |  67766 KiB |
|       from large pool |   1571 MiB |   1571 MiB |   1571 MiB |      0 KiB |
|       from small pool |     37 MiB |    102 MiB |    103 MiB |  67766 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1608 MiB |   1619 MiB |   1674 MiB |  67766 KiB |
|       from large pool |   1571 MiB |   1571 MiB |   1571 MiB |      0 KiB |
|       from small pool |     37 MiB |    102 MiB |    103 MiB |  67766 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1601 MiB |   1612 MiB |   1667 MiB |  67746 KiB |
|       from large pool |   1564 MiB |   1564 MiB |   1564 MiB |      0 KiB |
|       from small pool |     37 MiB |    102 MiB |    103 MiB |  67746 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1696 MiB |   1696 MiB |   1696 MiB |      0 B   |
|       from large pool |   1592 MiB |   1592 MiB |   1592 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  89406 KiB |  89523 KiB | 340811 KiB | 251405 KiB |
|       from large pool |  21100 KiB |  21100 KiB | 173036 KiB | 151936 KiB |
|       from small pool |  68306 KiB |  69413 KiB | 167775 KiB |  99469 KiB |
|---------------------------------------------------------------------------|
| Allocations           |    1135    |    1565    |    1580    |     445    |
|       from large pool |      83    |      83    |      83    |       0    |
|       from small pool |    1052    |    1487    |    1497    |     445    |
|---------------------------------------------------------------------------|
| Active allocs         |    1135    |    1565    |    1580    |     445    |
|       from large pool |      83    |      83    |      83    |       0    |
|       from small pool |    1052    |    1487    |    1497    |     445    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      70    |      70    |      70    |       0    |
|       from large pool |      18    |      18    |      18    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     177    |     177    |     266    |      89    |
|       from large pool |      10    |      10    |      18    |       8    |
|       from small pool |     167    |     167    |     248    |      81    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,234][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,235][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,243][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,243][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,244][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,244][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,244][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:33:25,245][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-07 00:34:23,093][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 
[2024-10-07 00:34:23,095][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6028 MiB |   6029 MiB |   8983 MiB |   2954 MiB |
|       from large pool |   5982 MiB |   5982 MiB |   8815 MiB |   2832 MiB |
|       from small pool |     46 MiB |    102 MiB |    167 MiB |    121 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   6028 MiB |   6029 MiB |   8983 MiB |   2954 MiB |
|       from large pool |   5982 MiB |   5982 MiB |   8815 MiB |   2832 MiB |
|       from small pool |     46 MiB |    102 MiB |    167 MiB |    121 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6004 MiB |   6005 MiB |   8952 MiB |   2948 MiB |
|       from large pool |   5958 MiB |   5958 MiB |   8784 MiB |   2826 MiB |
|       from small pool |     45 MiB |    102 MiB |    167 MiB |    121 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   6200 MiB |   6200 MiB |   6200 MiB |      0 B   |
|       from large pool |   6096 MiB |   6096 MiB |   6096 MiB |      0 B   |
|       from small pool |    104 MiB |    104 MiB |    104 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 175476 KiB | 298997 KiB |   2852 MiB |   2680 MiB |
|       from large pool | 116196 KiB | 238906 KiB |   2632 MiB |   2519 MiB |
|       from small pool |  59280 KiB |  69413 KiB |    219 MiB |    161 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1318    |    1565    |    1879    |     561    |
|       from large pool |     214    |     214    |     263    |      49    |
|       from small pool |    1104    |    1487    |    1616    |     512    |
|---------------------------------------------------------------------------|
| Active allocs         |    1318    |    1565    |    1879    |     561    |
|       from large pool |     214    |     214    |     263    |      49    |
|       from small pool |    1104    |    1487    |    1616    |     512    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     123    |     123    |     123    |       0    |
|       from large pool |      71    |      71    |      71    |       0    |
|       from small pool |      52    |      52    |      52    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     198    |     199    |     321    |     123    |
|       from large pool |      33    |      34    |      72    |      39    |
|       from small pool |     165    |     167    |     249    |      84    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,096][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,097][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,098][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,098][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,099][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,100][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,101][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-07 00:34:23,102][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-07 00:34:45,918][fairseq_cli.train][INFO] - end of epoch 461 (average epoch stats below)
[2024-10-07 00:34:46,069][train][INFO] - {"epoch": 461, "train_loss": "0.716", "train_ntokens": "260784", "train_nsentences": "1750.04", "train_wps": "53374.2", "train_ups": "0.2", "train_wpb": "260784", "train_bsz": "1750", "train_num_updates": "22115", "train_lr": "0.000345547", "train_gnorm": "0.433", "train_loss_scale": "1", "train_train_wall": "361", "train_gb_free": "39.6", "train_wall": "702"}
[2024-10-07 00:34:46,323][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:34:46,330][fairseq.trainer][INFO] - begin training epoch 462
[2024-10-07 00:34:46,331][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:43:40,457][fairseq_cli.train][INFO] - end of epoch 462 (average epoch stats below)
[2024-10-07 00:43:40,461][train][INFO] - {"epoch": 462, "train_loss": "0.71", "train_ntokens": "260542", "train_nsentences": "1750.04", "train_wps": "23402.9", "train_ups": "0.09", "train_wpb": "260542", "train_bsz": "1750", "train_num_updates": "22163", "train_lr": "0.000346297", "train_gnorm": "0.517", "train_loss_scale": "1", "train_train_wall": "214", "train_gb_free": "39.8", "train_wall": "1236"}
[2024-10-07 00:43:40,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:43:40,525][fairseq.trainer][INFO] - begin training epoch 463
[2024-10-07 00:43:40,525][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:45:37,265][train_inner][INFO] - {"epoch": 463, "update": 462.771, "loss": "0.714", "ntokens": "260602", "nsentences": "1753.75", "wps": "39049.9", "ups": "0.15", "wpb": "260602", "bsz": "1753.8", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.501", "loss_scale": "1", "train_wall": "614", "gb_free": "39.7", "wall": "1353"}
[2024-10-07 00:45:49,265][fairseq_cli.train][INFO] - end of epoch 463 (average epoch stats below)
[2024-10-07 00:45:49,268][train][INFO] - {"epoch": 463, "train_loss": "0.715", "train_ntokens": "260702", "train_nsentences": "1750.04", "train_wps": "97152.8", "train_ups": "0.37", "train_wpb": "260702", "train_bsz": "1750", "train_num_updates": "22211", "train_lr": "0.000347047", "train_gnorm": "0.582", "train_loss_scale": "1", "train_train_wall": "50", "train_gb_free": "39.7", "train_wall": "1365"}
[2024-10-07 00:45:49,331][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:45:49,335][fairseq.trainer][INFO] - begin training epoch 464
[2024-10-07 00:45:49,336][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:47:58,785][fairseq_cli.train][INFO] - end of epoch 464 (average epoch stats below)
[2024-10-07 00:47:58,789][train][INFO] - {"epoch": 464, "train_loss": "0.712", "train_ntokens": "260821", "train_nsentences": "1750.04", "train_wps": "96660.9", "train_ups": "0.37", "train_wpb": "260821", "train_bsz": "1750", "train_num_updates": "22259", "train_lr": "0.000347797", "train_gnorm": "0.462", "train_loss_scale": "1", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "1494"}
[2024-10-07 00:47:58,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:47:58,903][fairseq.trainer][INFO] - begin training epoch 465
[2024-10-07 00:47:58,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:50:20,887][fairseq_cli.train][INFO] - end of epoch 465 (average epoch stats below)
[2024-10-07 00:50:20,890][train][INFO] - {"epoch": 465, "train_loss": "0.712", "train_ntokens": "260783", "train_nsentences": "1750.04", "train_wps": "88090.7", "train_ups": "0.34", "train_wpb": "260783", "train_bsz": "1750", "train_num_updates": "22307", "train_lr": "0.000348547", "train_gnorm": "0.521", "train_loss_scale": "1", "train_train_wall": "58", "train_gb_free": "39.6", "train_wall": "1637"}
[2024-10-07 00:50:20,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:50:20,954][fairseq.trainer][INFO] - begin training epoch 466
[2024-10-07 00:50:20,954][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:52:27,572][fairseq_cli.train][INFO] - end of epoch 466 (average epoch stats below)
[2024-10-07 00:52:27,581][train][INFO] - {"epoch": 466, "train_loss": "0.71", "train_ntokens": "260733", "train_nsentences": "1750.04", "train_wps": "98790.4", "train_ups": "0.38", "train_wpb": "260733", "train_bsz": "1750", "train_num_updates": "22355", "train_lr": "0.000349297", "train_gnorm": "0.482", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.5", "train_wall": "1763"}
[2024-10-07 00:52:27,677][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:52:27,685][fairseq.trainer][INFO] - begin training epoch 467
[2024-10-07 00:52:27,686][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:54:33,178][train_inner][INFO] - {"epoch": 467, "update": 466.938, "loss": "0.711", "ntokens": "260740", "nsentences": "1747.38", "wps": "97307.9", "ups": "0.37", "wpb": "260740", "bsz": "1747.4", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.486", "loss_scale": "1", "train_wall": "237", "gb_free": "41", "wall": "1889"}
[2024-10-07 00:54:34,053][fairseq_cli.train][INFO] - end of epoch 467 (average epoch stats below)
[2024-10-07 00:54:34,058][train][INFO] - {"epoch": 467, "train_loss": "0.71", "train_ntokens": "260516", "train_nsentences": "1750.04", "train_wps": "98874.1", "train_ups": "0.38", "train_wpb": "260516", "train_bsz": "1750", "train_num_updates": "22403", "train_lr": "0.000350047", "train_gnorm": "0.46", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.7", "train_wall": "1890"}
[2024-10-07 00:54:34,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:54:34,224][fairseq.trainer][INFO] - begin training epoch 468
[2024-10-07 00:54:34,224][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:56:40,489][fairseq_cli.train][INFO] - end of epoch 468 (average epoch stats below)
[2024-10-07 00:56:40,523][train][INFO] - {"epoch": 468, "train_loss": "0.708", "train_ntokens": "260823", "train_nsentences": "1750.04", "train_wps": "99004.6", "train_ups": "0.38", "train_wpb": "260823", "train_bsz": "1750", "train_num_updates": "22451", "train_lr": "0.000350797", "train_gnorm": "0.492", "train_loss_scale": "1", "train_train_wall": "48", "train_gb_free": "39.6", "train_wall": "2016"}
[2024-10-07 00:56:40,643][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:56:40,647][fairseq.trainer][INFO] - begin training epoch 469
[2024-10-07 00:56:40,647][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:58:55,137][fairseq_cli.train][INFO] - end of epoch 469 (average epoch stats below)
[2024-10-07 00:58:55,147][train][INFO] - {"epoch": 469, "train_loss": "0.711", "train_ntokens": "260448", "train_nsentences": "1750.04", "train_wps": "92867", "train_ups": "0.36", "train_wpb": "260448", "train_bsz": "1750", "train_num_updates": "22499", "train_lr": "0.000351547", "train_gnorm": "0.507", "train_loss_scale": "1", "train_train_wall": "49", "train_gb_free": "39.8", "train_wall": "2151"}
[2024-10-07 00:58:55,265][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 00:58:55,281][fairseq.trainer][INFO] - begin training epoch 470
[2024-10-07 00:58:55,282][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:01:09,073][fairseq_cli.train][INFO] - end of epoch 470 (average epoch stats below)
[2024-10-07 01:01:09,077][train][INFO] - {"epoch": 470, "train_loss": "0.708", "train_ntokens": "260660", "train_nsentences": "1750.04", "train_wps": "93423", "train_ups": "0.36", "train_wpb": "260660", "train_bsz": "1750", "train_num_updates": "22547", "train_lr": "0.000352297", "train_gnorm": "0.5", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.4", "train_wall": "2285"}
[2024-10-07 01:01:09,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:01:09,182][fairseq.trainer][INFO] - begin training epoch 471
[2024-10-07 01:01:09,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:03:18,363][fairseq_cli.train][INFO] - end of epoch 471 (average epoch stats below)
[2024-10-07 01:03:18,367][train][INFO] - {"epoch": 471, "train_loss": "0.705", "train_ntokens": "260524", "train_nsentences": "1750.04", "train_wps": "96723.8", "train_ups": "0.37", "train_wpb": "260524", "train_bsz": "1750", "train_num_updates": "22595", "train_lr": "0.000353047", "train_gnorm": "0.431", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "40.1", "train_wall": "2414"}
[2024-10-07 01:03:18,429][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:03:18,433][fairseq.trainer][INFO] - begin training epoch 472
[2024-10-07 01:03:18,433][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:04:46,102][train_inner][INFO] - {"epoch": 472, "update": 471.104, "loss": "0.708", "ntokens": "260585", "nsentences": "1750.73", "wps": "85032.7", "ups": "0.33", "wpb": "260585", "bsz": "1750.7", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.487", "loss_scale": "1", "train_wall": "220", "gb_free": "39.2", "wall": "2502"}
[2024-10-07 01:05:29,266][fairseq_cli.train][INFO] - end of epoch 472 (average epoch stats below)
[2024-10-07 01:05:29,269][train][INFO] - {"epoch": 472, "train_loss": "0.709", "train_ntokens": "260763", "train_nsentences": "1750.04", "train_wps": "95619.8", "train_ups": "0.37", "train_wpb": "260763", "train_bsz": "1750", "train_num_updates": "22643", "train_lr": "0.000353797", "train_gnorm": "0.443", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "40.3", "train_wall": "2545"}
[2024-10-07 01:05:29,351][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:05:29,354][fairseq.trainer][INFO] - begin training epoch 473
[2024-10-07 01:05:29,355][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:07:37,459][fairseq_cli.train][INFO] - end of epoch 473 (average epoch stats below)
[2024-10-07 01:07:37,474][train][INFO] - {"epoch": 473, "train_loss": "0.703", "train_ntokens": "260622", "train_nsentences": "1750.04", "train_wps": "97578.8", "train_ups": "0.37", "train_wpb": "260622", "train_bsz": "1750", "train_num_updates": "22691", "train_lr": "0.000354547", "train_gnorm": "0.543", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "39.2", "train_wall": "2673"}
[2024-10-07 01:07:37,570][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:07:37,577][fairseq.trainer][INFO] - begin training epoch 474
[2024-10-07 01:07:37,577][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:09:47,095][fairseq_cli.train][INFO] - end of epoch 474 (average epoch stats below)
[2024-10-07 01:09:47,100][train][INFO] - {"epoch": 474, "train_loss": "0.705", "train_ntokens": "260489", "train_nsentences": "1750.04", "train_wps": "96460.5", "train_ups": "0.37", "train_wpb": "260489", "train_bsz": "1750", "train_num_updates": "22739", "train_lr": "0.000355297", "train_gnorm": "0.44", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "2803"}
[2024-10-07 01:09:47,230][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:09:47,245][fairseq.trainer][INFO] - begin training epoch 475
[2024-10-07 01:09:47,247][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:11:53,144][fairseq_cli.train][INFO] - end of epoch 475 (average epoch stats below)
[2024-10-07 01:11:53,167][train][INFO] - {"epoch": 475, "train_loss": "0.704", "train_ntokens": "260653", "train_nsentences": "1750.04", "train_wps": "99252.9", "train_ups": "0.38", "train_wpb": "260653", "train_bsz": "1750", "train_num_updates": "22787", "train_lr": "0.000356047", "train_gnorm": "0.51", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "40", "train_wall": "2929"}
[2024-10-07 01:11:53,329][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:11:53,339][fairseq.trainer][INFO] - begin training epoch 476
[2024-10-07 01:11:53,339][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:13:24,404][train_inner][INFO] - {"epoch": 476, "update": 475.271, "loss": "0.704", "ntokens": "260761", "nsentences": "1742.6", "wps": "100622", "ups": "0.39", "wpb": "260761", "bsz": "1742.6", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.479", "loss_scale": "1", "train_wall": "224", "gb_free": "39.8", "wall": "3020"}
[2024-10-07 01:14:01,455][fairseq_cli.train][INFO] - end of epoch 476 (average epoch stats below)
[2024-10-07 01:14:01,458][train][INFO] - {"epoch": 476, "train_loss": "0.707", "train_ntokens": "260352", "train_nsentences": "1750.04", "train_wps": "97413.9", "train_ups": "0.37", "train_wpb": "260352", "train_bsz": "1750", "train_num_updates": "22835", "train_lr": "0.000356797", "train_gnorm": "0.528", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.7", "train_wall": "3057"}
[2024-10-07 01:14:04,808][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:14:04,812][fairseq.trainer][INFO] - begin training epoch 477
[2024-10-07 01:14:04,812][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:16:16,844][fairseq_cli.train][INFO] - end of epoch 477 (average epoch stats below)
[2024-10-07 01:16:16,848][train][INFO] - {"epoch": 477, "train_loss": "0.7", "train_ntokens": "260652", "train_nsentences": "1750.04", "train_wps": "92411.2", "train_ups": "0.35", "train_wpb": "260652", "train_bsz": "1750", "train_num_updates": "22883", "train_lr": "0.000357547", "train_gnorm": "0.474", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.2", "train_wall": "3192"}
[2024-10-07 01:16:16,912][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:16:16,916][fairseq.trainer][INFO] - begin training epoch 478
[2024-10-07 01:16:16,916][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:18:22,721][fairseq_cli.train][INFO] - end of epoch 478 (average epoch stats below)
[2024-10-07 01:18:22,739][train][INFO] - {"epoch": 478, "train_loss": "0.698", "train_ntokens": "260882", "train_nsentences": "1750.04", "train_wps": "99482.1", "train_ups": "0.38", "train_wpb": "260882", "train_bsz": "1750", "train_num_updates": "22931", "train_lr": "0.000358297", "train_gnorm": "0.429", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "40.1", "train_wall": "3318"}
[2024-10-07 01:18:22,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:18:22,858][fairseq.trainer][INFO] - begin training epoch 479
[2024-10-07 01:18:22,858][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:20:30,524][fairseq_cli.train][INFO] - end of epoch 479 (average epoch stats below)
[2024-10-07 01:20:30,528][train][INFO] - {"epoch": 479, "train_loss": "0.697", "train_ntokens": "260560", "train_nsentences": "1750.04", "train_wps": "97874.2", "train_ups": "0.38", "train_wpb": "260560", "train_bsz": "1750", "train_num_updates": "22979", "train_lr": "0.000359047", "train_gnorm": "0.498", "train_loss_scale": "1", "train_train_wall": "61", "train_gb_free": "39.6", "train_wall": "3446"}
[2024-10-07 01:20:30,603][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:20:30,609][fairseq.trainer][INFO] - begin training epoch 480
[2024-10-07 01:20:30,609][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:22:17,023][train_inner][INFO] - {"epoch": 480, "update": 479.438, "loss": "0.701", "ntokens": "260631", "nsentences": "1752.05", "wps": "97868.4", "ups": "0.38", "wpb": "260631", "bsz": "1752", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.483", "loss_scale": "1", "train_wall": "224", "gb_free": "39.3", "wall": "3553"}
[2024-10-07 01:22:41,215][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 480 @ 23027 updates
[2024-10-07 01:22:41,215][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 01:22:44,506][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 01:22:44,509][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 480 @ 23027 updates, score None) (writing took 3.294590757228434 seconds)
[2024-10-07 01:22:44,510][fairseq_cli.train][INFO] - end of epoch 480 (average epoch stats below)
[2024-10-07 01:22:44,512][train][INFO] - {"epoch": 480, "train_loss": "0.702", "train_ntokens": "260621", "train_nsentences": "1750.04", "train_wps": "93369.7", "train_ups": "0.36", "train_wpb": "260621", "train_bsz": "1750", "train_num_updates": "23027", "train_lr": "0.000359797", "train_gnorm": "0.429", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "39.3", "train_wall": "3580"}
[2024-10-07 01:22:44,577][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:22:44,582][fairseq.trainer][INFO] - begin training epoch 481
[2024-10-07 01:22:44,583][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:24:52,480][fairseq_cli.train][INFO] - end of epoch 481 (average epoch stats below)
[2024-10-07 01:24:52,483][train][INFO] - {"epoch": 481, "train_loss": "0.698", "train_ntokens": "260676", "train_nsentences": "1750.04", "train_wps": "97777.3", "train_ups": "0.38", "train_wpb": "260676", "train_bsz": "1750", "train_num_updates": "23075", "train_lr": "0.000360547", "train_gnorm": "0.502", "train_loss_scale": "1", "train_train_wall": "39", "train_gb_free": "39.6", "train_wall": "3708"}
[2024-10-07 01:24:52,545][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:24:52,548][fairseq.trainer][INFO] - begin training epoch 482
[2024-10-07 01:24:52,548][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:27:07,812][fairseq_cli.train][INFO] - end of epoch 482 (average epoch stats below)
[2024-10-07 01:27:07,815][train][INFO] - {"epoch": 482, "train_loss": "0.695", "train_ntokens": "260423", "train_nsentences": "1750.04", "train_wps": "92369.2", "train_ups": "0.35", "train_wpb": "260423", "train_bsz": "1750", "train_num_updates": "23123", "train_lr": "0.000361297", "train_gnorm": "0.44", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "39.6", "train_wall": "3843"}
[2024-10-07 01:27:07,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:27:07,941][fairseq.trainer][INFO] - begin training epoch 483
[2024-10-07 01:27:07,942][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:29:13,724][fairseq_cli.train][INFO] - end of epoch 483 (average epoch stats below)
[2024-10-07 01:29:13,747][train][INFO] - {"epoch": 483, "train_loss": "0.701", "train_ntokens": "260402", "train_nsentences": "1750.04", "train_wps": "99265.1", "train_ups": "0.38", "train_wpb": "260402", "train_bsz": "1750", "train_num_updates": "23171", "train_lr": "0.000362047", "train_gnorm": "0.447", "train_loss_scale": "1", "train_train_wall": "54", "train_gb_free": "39.9", "train_wall": "3969"}
[2024-10-07 01:29:13,851][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:29:13,862][fairseq.trainer][INFO] - begin training epoch 484
[2024-10-07 01:29:13,863][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:31:03,749][train_inner][INFO] - {"epoch": 484, "update": 483.604, "loss": "0.698", "ntokens": "260377", "nsentences": "1747.57", "wps": "98867.3", "ups": "0.38", "wpb": "260377", "bsz": "1747.6", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.444", "loss_scale": "1", "train_wall": "210", "gb_free": "39.1", "wall": "4079"}
[2024-10-07 01:31:18,802][fairseq_cli.train][INFO] - end of epoch 484 (average epoch stats below)
[2024-10-07 01:31:18,806][train][INFO] - {"epoch": 484, "train_loss": "0.699", "train_ntokens": "260760", "train_nsentences": "1750.04", "train_wps": "100088", "train_ups": "0.38", "train_wpb": "260760", "train_bsz": "1750", "train_num_updates": "23219", "train_lr": "0.000362797", "train_gnorm": "0.404", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.4", "train_wall": "4094"}
[2024-10-07 01:31:18,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:31:18,941][fairseq.trainer][INFO] - begin training epoch 485
[2024-10-07 01:31:18,942][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:33:25,216][fairseq_cli.train][INFO] - end of epoch 485 (average epoch stats below)
[2024-10-07 01:33:25,222][train][INFO] - {"epoch": 485, "train_loss": "0.702", "train_ntokens": "260624", "train_nsentences": "1750.04", "train_wps": "98960.7", "train_ups": "0.38", "train_wpb": "260624", "train_bsz": "1750", "train_num_updates": "23267", "train_lr": "0.000363547", "train_gnorm": "0.481", "train_loss_scale": "1", "train_train_wall": "37", "train_gb_free": "39.6", "train_wall": "4221"}
[2024-10-07 01:33:25,327][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:33:25,348][fairseq.trainer][INFO] - begin training epoch 486
[2024-10-07 01:33:25,349][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:35:36,435][fairseq_cli.train][INFO] - end of epoch 486 (average epoch stats below)
[2024-10-07 01:35:36,438][train][INFO] - {"epoch": 486, "train_loss": "0.695", "train_ntokens": "260768", "train_nsentences": "1750.04", "train_wps": "95392.7", "train_ups": "0.37", "train_wpb": "260768", "train_bsz": "1750", "train_num_updates": "23315", "train_lr": "0.000364297", "train_gnorm": "0.491", "train_loss_scale": "1", "train_train_wall": "54", "train_gb_free": "39.3", "train_wall": "4352"}
[2024-10-07 01:35:36,504][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:35:36,508][fairseq.trainer][INFO] - begin training epoch 487
[2024-10-07 01:35:36,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:37:42,772][fairseq_cli.train][INFO] - end of epoch 487 (average epoch stats below)
[2024-10-07 01:37:42,776][train][INFO] - {"epoch": 487, "train_loss": "0.697", "train_ntokens": "260709", "train_nsentences": "1750.04", "train_wps": "99056.1", "train_ups": "0.38", "train_wpb": "260709", "train_bsz": "1750", "train_num_updates": "23363", "train_lr": "0.000365047", "train_gnorm": "0.461", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "4478"}
[2024-10-07 01:37:42,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:37:42,841][fairseq.trainer][INFO] - begin training epoch 488
[2024-10-07 01:37:42,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:39:37,796][train_inner][INFO] - {"epoch": 488, "update": 487.771, "loss": "0.698", "ntokens": "260796", "nsentences": "1764.36", "wps": "101482", "ups": "0.39", "wpb": "260796", "bsz": "1764.4", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.47", "loss_scale": "1", "train_wall": "196", "gb_free": "39.9", "wall": "4593"}
[2024-10-07 01:39:48,464][fairseq_cli.train][INFO] - end of epoch 488 (average epoch stats below)
[2024-10-07 01:39:48,469][train][INFO] - {"epoch": 488, "train_loss": "0.694", "train_ntokens": "260924", "train_nsentences": "1750.04", "train_wps": "99646.3", "train_ups": "0.38", "train_wpb": "260924", "train_bsz": "1750", "train_num_updates": "23411", "train_lr": "0.000365797", "train_gnorm": "0.492", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "40.1", "train_wall": "4604"}
[2024-10-07 01:39:48,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:39:48,624][fairseq.trainer][INFO] - begin training epoch 489
[2024-10-07 01:39:48,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:41:59,659][fairseq_cli.train][INFO] - end of epoch 489 (average epoch stats below)
[2024-10-07 01:41:59,662][train][INFO] - {"epoch": 489, "train_loss": "0.698", "train_ntokens": "260632", "train_nsentences": "1750.04", "train_wps": "95378.3", "train_ups": "0.37", "train_wpb": "260632", "train_bsz": "1750", "train_num_updates": "23459", "train_lr": "0.000366547", "train_gnorm": "0.408", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "40.3", "train_wall": "4735"}
[2024-10-07 01:41:59,719][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:41:59,722][fairseq.trainer][INFO] - begin training epoch 490
[2024-10-07 01:41:59,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:44:09,901][fairseq_cli.train][INFO] - end of epoch 490 (average epoch stats below)
[2024-10-07 01:44:09,904][train][INFO] - {"epoch": 490, "train_loss": "0.694", "train_ntokens": "260583", "train_nsentences": "1750.04", "train_wps": "96039", "train_ups": "0.37", "train_wpb": "260583", "train_bsz": "1750", "train_num_updates": "23507", "train_lr": "0.000367297", "train_gnorm": "0.451", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.3", "train_wall": "4866"}
[2024-10-07 01:44:09,965][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:44:09,969][fairseq.trainer][INFO] - begin training epoch 491
[2024-10-07 01:44:09,970][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:46:16,889][fairseq_cli.train][INFO] - end of epoch 491 (average epoch stats below)
[2024-10-07 01:46:16,893][train][INFO] - {"epoch": 491, "train_loss": "0.698", "train_ntokens": "261050", "train_nsentences": "1750.04", "train_wps": "98675.9", "train_ups": "0.38", "train_wpb": "261050", "train_bsz": "1750", "train_num_updates": "23555", "train_lr": "0.000368047", "train_gnorm": "0.506", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.3", "train_wall": "4993"}
[2024-10-07 01:46:16,976][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:46:16,979][fairseq.trainer][INFO] - begin training epoch 492
[2024-10-07 01:46:16,980][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:51:25,361][train_inner][INFO] - {"epoch": 492, "update": 491.938, "loss": "0.695", "ntokens": "260942", "nsentences": "1744.07", "wps": "73760.5", "ups": "0.28", "wpb": "260942", "bsz": "1744.1", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.476", "loss_scale": "1", "train_wall": "271", "gb_free": "40.1", "wall": "5301"}
[2024-10-07 01:51:26,042][fairseq_cli.train][INFO] - end of epoch 492 (average epoch stats below)
[2024-10-07 01:51:26,044][train][INFO] - {"epoch": 492, "train_loss": "0.689", "train_ntokens": "260827", "train_nsentences": "1750.04", "train_wps": "40497.4", "train_ups": "0.16", "train_wpb": "260827", "train_bsz": "1750", "train_num_updates": "23603", "train_lr": "0.000368797", "train_gnorm": "0.509", "train_loss_scale": "1", "train_train_wall": "120", "train_gb_free": "39.7", "train_wall": "5302"}
[2024-10-07 01:51:26,349][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:51:26,362][fairseq.trainer][INFO] - begin training epoch 493
[2024-10-07 01:51:26,363][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:54:10,492][fairseq_cli.train][INFO] - end of epoch 493 (average epoch stats below)
[2024-10-07 01:54:10,515][train][INFO] - {"epoch": 493, "train_loss": "0.699", "train_ntokens": "260583", "train_nsentences": "1750.04", "train_wps": "76056.5", "train_ups": "0.29", "train_wpb": "260583", "train_bsz": "1750", "train_num_updates": "23651", "train_lr": "0.000369547", "train_gnorm": "0.446", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.8", "train_wall": "5466"}
[2024-10-07 01:54:10,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:54:10,700][fairseq.trainer][INFO] - begin training epoch 494
[2024-10-07 01:54:10,700][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:56:54,889][fairseq_cli.train][INFO] - end of epoch 494 (average epoch stats below)
[2024-10-07 01:56:54,894][train][INFO] - {"epoch": 494, "train_loss": "0.695", "train_ntokens": "260330", "train_nsentences": "1750.04", "train_wps": "76020.4", "train_ups": "0.29", "train_wpb": "260330", "train_bsz": "1750", "train_num_updates": "23699", "train_lr": "0.000370297", "train_gnorm": "0.462", "train_loss_scale": "1", "train_train_wall": "30", "train_gb_free": "39.7", "train_wall": "5631"}
[2024-10-07 01:56:55,013][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:56:55,022][fairseq.trainer][INFO] - begin training epoch 495
[2024-10-07 01:56:55,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:59:43,251][fairseq_cli.train][INFO] - end of epoch 495 (average epoch stats below)
[2024-10-07 01:59:43,258][train][INFO] - {"epoch": 495, "train_loss": "0.691", "train_ntokens": "260582", "train_nsentences": "1750.04", "train_wps": "74292.2", "train_ups": "0.29", "train_wpb": "260582", "train_bsz": "1750", "train_num_updates": "23747", "train_lr": "0.000371047", "train_gnorm": "0.468", "train_loss_scale": "1", "train_train_wall": "72", "train_gb_free": "39.9", "train_wall": "5799"}
[2024-10-07 01:59:43,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 01:59:43,428][fairseq.trainer][INFO] - begin training epoch 496
[2024-10-07 01:59:43,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:04:26,756][fairseq_cli.train][INFO] - end of epoch 496 (average epoch stats below)
[2024-10-07 02:04:26,762][train][INFO] - {"epoch": 496, "train_loss": "0.695", "train_ntokens": "260524", "train_nsentences": "1750.04", "train_wps": "44109.8", "train_ups": "0.17", "train_wpb": "260524", "train_bsz": "1750", "train_num_updates": "23795", "train_lr": "0.000371797", "train_gnorm": "0.487", "train_loss_scale": "1", "train_train_wall": "32", "train_gb_free": "39.8", "train_wall": "6082"}
[2024-10-07 02:04:26,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:04:26,973][fairseq.trainer][INFO] - begin training epoch 497
[2024-10-07 02:04:26,973][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:06:48,017][train_inner][INFO] - {"epoch": 497, "update": 496.104, "loss": "0.695", "ntokens": "260262", "nsentences": "1754.28", "wps": "56416.1", "ups": "0.22", "wpb": "260262", "bsz": "1754.3", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.465", "loss_scale": "1", "train_wall": "229", "gb_free": "39.8", "wall": "6224"}
[2024-10-07 02:07:14,936][fairseq_cli.train][INFO] - end of epoch 497 (average epoch stats below)
[2024-10-07 02:07:14,947][train][INFO] - {"epoch": 497, "train_loss": "0.69", "train_ntokens": "260425", "train_nsentences": "1750.04", "train_wps": "74330.4", "train_ups": "0.29", "train_wpb": "260425", "train_bsz": "1750", "train_num_updates": "23843", "train_lr": "0.000372547", "train_gnorm": "0.445", "train_loss_scale": "1", "train_train_wall": "61", "train_gb_free": "39.3", "train_wall": "6251"}
[2024-10-07 02:07:15,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:07:15,157][fairseq.trainer][INFO] - begin training epoch 498
[2024-10-07 02:07:15,157][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:09:46,779][fairseq_cli.train][INFO] - end of epoch 498 (average epoch stats below)
[2024-10-07 02:09:46,786][train][INFO] - {"epoch": 498, "train_loss": "0.689", "train_ntokens": "260328", "train_nsentences": "1750.04", "train_wps": "82303.7", "train_ups": "0.32", "train_wpb": "260328", "train_bsz": "1750", "train_num_updates": "23891", "train_lr": "0.000373297", "train_gnorm": "0.493", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.2", "train_wall": "6402"}
[2024-10-07 02:09:46,939][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:09:46,969][fairseq.trainer][INFO] - begin training epoch 499
[2024-10-07 02:09:46,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:12:14,551][fairseq_cli.train][INFO] - end of epoch 499 (average epoch stats below)
[2024-10-07 02:12:14,568][train][INFO] - {"epoch": 499, "train_loss": "0.688", "train_ntokens": "260735", "train_nsentences": "1750.04", "train_wps": "84689.4", "train_ups": "0.32", "train_wpb": "260735", "train_bsz": "1750", "train_num_updates": "23939", "train_lr": "0.000374047", "train_gnorm": "0.543", "train_loss_scale": "1", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "6550"}
[2024-10-07 02:12:14,889][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:12:14,909][fairseq.trainer][INFO] - begin training epoch 500
[2024-10-07 02:12:14,910][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:16:58,392][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 500 @ 23987 updates
[2024-10-07 02:16:58,394][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 02:17:02,574][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 02:17:02,577][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 500 @ 23987 updates, score None) (writing took 4.184362825006247 seconds)
[2024-10-07 02:17:02,577][fairseq_cli.train][INFO] - end of epoch 500 (average epoch stats below)
[2024-10-07 02:17:02,579][train][INFO] - {"epoch": 500, "train_loss": "0.695", "train_ntokens": "260783", "train_nsentences": "1750.04", "train_wps": "43462.5", "train_ups": "0.17", "train_wpb": "260783", "train_bsz": "1750", "train_num_updates": "23987", "train_lr": "0.000374797", "train_gnorm": "0.459", "train_loss_scale": "1", "train_train_wall": "64", "train_gb_free": "40.6", "train_wall": "6838"}
[2024-10-07 02:17:02,834][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:17:02,857][fairseq.trainer][INFO] - begin training epoch 501
[2024-10-07 02:17:02,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:19:27,971][train_inner][INFO] - {"epoch": 501, "update": 500.271, "loss": "0.691", "ntokens": "260839", "nsentences": "1737.05", "wps": "68647.7", "ups": "0.26", "wpb": "260839", "bsz": "1737", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.484", "loss_scale": "1", "train_wall": "210", "gb_free": "40.6", "wall": "6984"}
[2024-10-07 02:19:58,156][fairseq_cli.train][INFO] - end of epoch 501 (average epoch stats below)
[2024-10-07 02:19:58,158][train][INFO] - {"epoch": 501, "train_loss": "0.688", "train_ntokens": "260704", "train_nsentences": "1750.04", "train_wps": "71272.5", "train_ups": "0.27", "train_wpb": "260704", "train_bsz": "1750", "train_num_updates": "24035", "train_lr": "0.000375547", "train_gnorm": "0.451", "train_loss_scale": "1", "train_train_wall": "35", "train_gb_free": "40.8", "train_wall": "7014"}
[2024-10-07 02:19:58,307][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:19:58,318][fairseq.trainer][INFO] - begin training epoch 502
[2024-10-07 02:19:58,318][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:22:41,661][fairseq_cli.train][INFO] - end of epoch 502 (average epoch stats below)
[2024-10-07 02:22:41,676][train][INFO] - {"epoch": 502, "train_loss": "0.689", "train_ntokens": "260581", "train_nsentences": "1750.04", "train_wps": "76494", "train_ups": "0.29", "train_wpb": "260581", "train_bsz": "1750", "train_num_updates": "24083", "train_lr": "0.000376297", "train_gnorm": "0.441", "train_loss_scale": "1", "train_train_wall": "40", "train_gb_free": "39.8", "train_wall": "7177"}
[2024-10-07 02:22:41,811][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:22:41,815][fairseq.trainer][INFO] - begin training epoch 503
[2024-10-07 02:22:41,816][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:25:19,276][fairseq_cli.train][INFO] - end of epoch 503 (average epoch stats below)
[2024-10-07 02:25:19,284][train][INFO] - {"epoch": 503, "train_loss": "0.695", "train_ntokens": "261250", "train_nsentences": "1750.04", "train_wps": "79565.8", "train_ups": "0.3", "train_wpb": "261250", "train_bsz": "1750", "train_num_updates": "24131", "train_lr": "0.000377047", "train_gnorm": "0.537", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "39.6", "train_wall": "7335"}
[2024-10-07 02:25:19,503][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:25:19,510][fairseq.trainer][INFO] - begin training epoch 504
[2024-10-07 02:25:19,510][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:27:49,136][fairseq_cli.train][INFO] - end of epoch 504 (average epoch stats below)
[2024-10-07 02:27:49,142][train][INFO] - {"epoch": 504, "train_loss": "0.688", "train_ntokens": "261024", "train_nsentences": "1750.04", "train_wps": "83608.5", "train_ups": "0.32", "train_wpb": "261024", "train_bsz": "1750", "train_num_updates": "24179", "train_lr": "0.000377797", "train_gnorm": "0.437", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.7", "train_wall": "7485"}
[2024-10-07 02:27:49,234][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:27:49,244][fairseq.trainer][INFO] - begin training epoch 505
[2024-10-07 02:27:49,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:30:03,333][train_inner][INFO] - {"epoch": 505, "update": 504.438, "loss": "0.689", "ntokens": "260702", "nsentences": "1767.85", "wps": "82068.5", "ups": "0.31", "wpb": "260702", "bsz": "1767.9", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.473", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "7619"}
[2024-10-07 02:30:19,893][fairseq_cli.train][INFO] - end of epoch 505 (average epoch stats below)
[2024-10-07 02:30:19,898][train][INFO] - {"epoch": 505, "train_loss": "0.693", "train_ntokens": "261119", "train_nsentences": "1750.04", "train_wps": "83141.8", "train_ups": "0.32", "train_wpb": "261118", "train_bsz": "1750", "train_num_updates": "24227", "train_lr": "0.000378547", "train_gnorm": "0.511", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "40", "train_wall": "7636"}
[2024-10-07 02:30:20,168][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:30:20,184][fairseq.trainer][INFO] - begin training epoch 506
[2024-10-07 02:30:20,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:32:53,197][fairseq_cli.train][INFO] - end of epoch 506 (average epoch stats below)
[2024-10-07 02:32:53,209][train][INFO] - {"epoch": 506, "train_loss": "0.684", "train_ntokens": "260479", "train_nsentences": "1750.04", "train_wps": "81554.4", "train_ups": "0.31", "train_wpb": "260479", "train_bsz": "1750", "train_num_updates": "24275", "train_lr": "0.000379297", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.3", "train_wall": "7789"}
[2024-10-07 02:32:53,435][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:32:53,458][fairseq.trainer][INFO] - begin training epoch 507
[2024-10-07 02:32:53,458][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:37:57,586][fairseq_cli.train][INFO] - end of epoch 507 (average epoch stats below)
[2024-10-07 02:37:57,593][train][INFO] - {"epoch": 507, "train_loss": "0.69", "train_ntokens": "260485", "train_nsentences": "1750.04", "train_wps": "41077.6", "train_ups": "0.16", "train_wpb": "260484", "train_bsz": "1750", "train_num_updates": "24323", "train_lr": "0.000380047", "train_gnorm": "0.441", "train_loss_scale": "2", "train_train_wall": "93", "train_gb_free": "39.3", "train_wall": "8093"}
[2024-10-07 02:37:57,817][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:37:57,830][fairseq.trainer][INFO] - begin training epoch 508
[2024-10-07 02:37:57,831][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:40:59,647][fairseq_cli.train][INFO] - end of epoch 508 (average epoch stats below)
[2024-10-07 02:40:59,655][train][INFO] - {"epoch": 508, "train_loss": "0.683", "train_ntokens": "261031", "train_nsentences": "1750.04", "train_wps": "68821", "train_ups": "0.26", "train_wpb": "261031", "train_bsz": "1750", "train_num_updates": "24371", "train_lr": "0.000380797", "train_gnorm": "0.429", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.6", "train_wall": "8275"}
[2024-10-07 02:40:59,841][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:40:59,845][fairseq.trainer][INFO] - begin training epoch 509
[2024-10-07 02:40:59,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:43:23,985][train_inner][INFO] - {"epoch": 509, "update": 508.604, "loss": "0.686", "ntokens": "260597", "nsentences": "1745.12", "wps": "65096.6", "ups": "0.25", "wpb": "260597", "bsz": "1745.1", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.436", "loss_scale": "2", "train_wall": "283", "gb_free": "39.1", "wall": "8420"}
[2024-10-07 02:43:35,912][fairseq_cli.train][INFO] - end of epoch 509 (average epoch stats below)
[2024-10-07 02:43:35,914][train][INFO] - {"epoch": 509, "train_loss": "0.68", "train_ntokens": "260282", "train_nsentences": "1750.04", "train_wps": "79956.4", "train_ups": "0.31", "train_wpb": "260282", "train_bsz": "1750", "train_num_updates": "24419", "train_lr": "0.000381547", "train_gnorm": "0.434", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.7", "train_wall": "8432"}
[2024-10-07 02:43:36,248][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:43:36,262][fairseq.trainer][INFO] - begin training epoch 510
[2024-10-07 02:43:36,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:49:19,566][fairseq_cli.train][INFO] - end of epoch 510 (average epoch stats below)
[2024-10-07 02:49:19,581][train][INFO] - {"epoch": 510, "train_loss": "0.686", "train_ntokens": "260960", "train_nsentences": "1750.04", "train_wps": "36448.8", "train_ups": "0.14", "train_wpb": "260960", "train_bsz": "1750", "train_num_updates": "24467", "train_lr": "0.000382297", "train_gnorm": "0.417", "train_loss_scale": "2", "train_train_wall": "94", "train_gb_free": "39.6", "train_wall": "8775"}
[2024-10-07 02:49:19,803][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:49:19,813][fairseq.trainer][INFO] - begin training epoch 511
[2024-10-07 02:49:19,814][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:52:15,225][fairseq_cli.train][INFO] - end of epoch 511 (average epoch stats below)
[2024-10-07 02:52:15,235][train][INFO] - {"epoch": 511, "train_loss": "0.684", "train_ntokens": "260736", "train_nsentences": "1750.04", "train_wps": "71251.8", "train_ups": "0.27", "train_wpb": "260736", "train_bsz": "1750", "train_num_updates": "24515", "train_lr": "0.000383047", "train_gnorm": "0.567", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.7", "train_wall": "8951"}
[2024-10-07 02:52:15,413][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:52:15,421][fairseq.trainer][INFO] - begin training epoch 512
[2024-10-07 02:52:15,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:54:55,633][fairseq_cli.train][INFO] - end of epoch 512 (average epoch stats below)
[2024-10-07 02:54:55,638][train][INFO] - {"epoch": 512, "train_loss": "0.682", "train_ntokens": "260807", "train_nsentences": "1750.04", "train_wps": "78047", "train_ups": "0.3", "train_wpb": "260807", "train_bsz": "1750", "train_num_updates": "24563", "train_lr": "0.000383797", "train_gnorm": "0.474", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.3", "train_wall": "9111"}
[2024-10-07 02:54:55,832][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:54:55,836][fairseq.trainer][INFO] - begin training epoch 513
[2024-10-07 02:54:55,836][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:57:24,779][train_inner][INFO] - {"epoch": 513, "update": 512.771, "loss": "0.683", "ntokens": "260872", "nsentences": "1743.26", "wps": "62060.1", "ups": "0.24", "wpb": "260872", "bsz": "1743.3", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.466", "loss_scale": "2", "train_wall": "265", "gb_free": "39.3", "wall": "9260"}
[2024-10-07 02:57:38,016][fairseq_cli.train][INFO] - end of epoch 513 (average epoch stats below)
[2024-10-07 02:57:38,019][train][INFO] - {"epoch": 513, "train_loss": "0.683", "train_ntokens": "260519", "train_nsentences": "1750.04", "train_wps": "77011.7", "train_ups": "0.3", "train_wpb": "260520", "train_bsz": "1750", "train_num_updates": "24611", "train_lr": "0.000384547", "train_gnorm": "0.413", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "39.8", "train_wall": "9274"}
[2024-10-07 02:57:38,186][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 02:57:38,208][fairseq.trainer][INFO] - begin training epoch 514
[2024-10-07 02:57:38,209][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:00:24,383][fairseq_cli.train][INFO] - end of epoch 514 (average epoch stats below)
[2024-10-07 03:00:24,392][train][INFO] - {"epoch": 514, "train_loss": "0.682", "train_ntokens": "260642", "train_nsentences": "1750.04", "train_wps": "75198.4", "train_ups": "0.29", "train_wpb": "260642", "train_bsz": "1750", "train_num_updates": "24659", "train_lr": "0.000385297", "train_gnorm": "0.433", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "39.6", "train_wall": "9440"}
[2024-10-07 03:00:24,610][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:00:24,627][fairseq.trainer][INFO] - begin training epoch 515
[2024-10-07 03:00:24,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:03:00,940][fairseq_cli.train][INFO] - end of epoch 515 (average epoch stats below)
[2024-10-07 03:03:00,946][train][INFO] - {"epoch": 515, "train_loss": "0.683", "train_ntokens": "260707", "train_nsentences": "1750.04", "train_wps": "79935.2", "train_ups": "0.31", "train_wpb": "260707", "train_bsz": "1750", "train_num_updates": "24707", "train_lr": "0.000386047", "train_gnorm": "0.438", "train_loss_scale": "2", "train_train_wall": "29", "train_gb_free": "39.5", "train_wall": "9597"}
[2024-10-07 03:03:01,221][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:03:01,235][fairseq.trainer][INFO] - begin training epoch 516
[2024-10-07 03:03:01,235][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:05:33,286][fairseq_cli.train][INFO] - end of epoch 516 (average epoch stats below)
[2024-10-07 03:05:33,290][train][INFO] - {"epoch": 516, "train_loss": "0.684", "train_ntokens": "260936", "train_nsentences": "1750.04", "train_wps": "82217", "train_ups": "0.32", "train_wpb": "260936", "train_bsz": "1750", "train_num_updates": "24755", "train_lr": "0.000386797", "train_gnorm": "0.529", "train_loss_scale": "2", "train_train_wall": "63", "train_gb_free": "39.3", "train_wall": "9749"}
[2024-10-07 03:05:33,362][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:05:33,367][fairseq.trainer][INFO] - begin training epoch 517
[2024-10-07 03:05:33,368][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:08:41,087][train_inner][INFO] - {"epoch": 517, "update": 516.938, "loss": "0.683", "ntokens": "260719", "nsentences": "1755.24", "wps": "77103.8", "ups": "0.3", "wpb": "260719", "bsz": "1755.2", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.455", "loss_scale": "2", "train_wall": "245", "gb_free": "40.8", "wall": "9937"}
[2024-10-07 03:08:42,211][fairseq_cli.train][INFO] - end of epoch 517 (average epoch stats below)
[2024-10-07 03:08:42,214][train][INFO] - {"epoch": 517, "train_loss": "0.68", "train_ntokens": "260847", "train_nsentences": "1750.04", "train_wps": "66274.5", "train_ups": "0.25", "train_wpb": "260847", "train_bsz": "1750", "train_num_updates": "24803", "train_lr": "0.000387547", "train_gnorm": "0.415", "train_loss_scale": "2", "train_train_wall": "99", "train_gb_free": "39.6", "train_wall": "9938"}
[2024-10-07 03:08:42,508][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:08:42,514][fairseq.trainer][INFO] - begin training epoch 518
[2024-10-07 03:08:42,514][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:11:47,972][fairseq_cli.train][INFO] - end of epoch 518 (average epoch stats below)
[2024-10-07 03:11:47,978][train][INFO] - {"epoch": 518, "train_loss": "0.682", "train_ntokens": "260416", "train_nsentences": "1750.04", "train_wps": "67290.4", "train_ups": "0.26", "train_wpb": "260416", "train_bsz": "1750", "train_num_updates": "24851", "train_lr": "0.000388297", "train_gnorm": "0.418", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.1", "train_wall": "10124"}
[2024-10-07 03:11:48,158][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:11:48,163][fairseq.trainer][INFO] - begin training epoch 519
[2024-10-07 03:11:48,164][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:14:35,276][fairseq_cli.train][INFO] - end of epoch 519 (average epoch stats below)
[2024-10-07 03:14:35,280][train][INFO] - {"epoch": 519, "train_loss": "0.679", "train_ntokens": "260314", "train_nsentences": "1750.04", "train_wps": "74687.6", "train_ups": "0.29", "train_wpb": "260314", "train_bsz": "1750", "train_num_updates": "24899", "train_lr": "0.000389047", "train_gnorm": "0.451", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.7", "train_wall": "10291"}
[2024-10-07 03:14:35,468][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:14:35,489][fairseq.trainer][INFO] - begin training epoch 520
[2024-10-07 03:14:35,489][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:18:06,851][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 520 @ 24947 updates
[2024-10-07 03:18:06,857][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 03:18:10,928][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 03:18:10,930][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 520 @ 24947 updates, score None) (writing took 4.078672123141587 seconds)
[2024-10-07 03:18:10,930][fairseq_cli.train][INFO] - end of epoch 520 (average epoch stats below)
[2024-10-07 03:18:10,933][train][INFO] - {"epoch": 520, "train_loss": "0.683", "train_ntokens": "261102", "train_nsentences": "1750.04", "train_wps": "58116.9", "train_ups": "0.22", "train_wpb": "261102", "train_bsz": "1750", "train_num_updates": "24947", "train_lr": "0.000389797", "train_gnorm": "0.46", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "40", "train_wall": "10507"}
[2024-10-07 03:18:11,179][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:18:11,205][fairseq.trainer][INFO] - begin training epoch 521
[2024-10-07 03:18:11,205][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:21:20,090][fairseq_cli.train][INFO] - end of epoch 521 (average epoch stats below)
[2024-10-07 03:21:20,107][train][INFO] - {"epoch": 521, "train_loss": "0.677", "train_ntokens": "261044", "train_nsentences": "1750.04", "train_wps": "66240.3", "train_ups": "0.25", "train_wpb": "261044", "train_bsz": "1750", "train_num_updates": "24995", "train_lr": "0.000390547", "train_gnorm": "0.419", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40.1", "train_wall": "10696"}
[2024-10-07 03:21:20,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:21:20,307][fairseq.trainer][INFO] - begin training epoch 522
[2024-10-07 03:21:20,308][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:23:38,931][train_inner][INFO] - {"epoch": 522, "update": 521.104, "loss": "0.68", "ntokens": "260798", "nsentences": "1748.17", "wps": "58094.9", "ups": "0.22", "wpb": "260798", "bsz": "1748.2", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.437", "loss_scale": "2", "train_wall": "318", "gb_free": "39.7", "wall": "10835"}
[2024-10-07 03:24:05,005][fairseq_cli.train][INFO] - end of epoch 522 (average epoch stats below)
[2024-10-07 03:24:05,008][train][INFO] - {"epoch": 522, "train_loss": "0.68", "train_ntokens": "260729", "train_nsentences": "1750.04", "train_wps": "75895.6", "train_ups": "0.29", "train_wpb": "260729", "train_bsz": "1750", "train_num_updates": "25043", "train_lr": "0.000391297", "train_gnorm": "0.497", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "39.4", "train_wall": "10861"}
[2024-10-07 03:24:05,205][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:24:05,220][fairseq.trainer][INFO] - begin training epoch 523
[2024-10-07 03:24:05,220][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:27:06,306][fairseq_cli.train][INFO] - end of epoch 523 (average epoch stats below)
[2024-10-07 03:27:06,318][train][INFO] - {"epoch": 523, "train_loss": "0.677", "train_ntokens": "260399", "train_nsentences": "1750.04", "train_wps": "68940.6", "train_ups": "0.26", "train_wpb": "260399", "train_bsz": "1750", "train_num_updates": "25091", "train_lr": "0.000392047", "train_gnorm": "0.485", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "39.6", "train_wall": "11042"}
[2024-10-07 03:27:06,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:27:06,527][fairseq.trainer][INFO] - begin training epoch 524
[2024-10-07 03:27:06,528][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:33:33,754][fairseq_cli.train][INFO] - end of epoch 524 (average epoch stats below)
[2024-10-07 03:33:33,761][train][INFO] - {"epoch": 524, "train_loss": "0.681", "train_ntokens": "260617", "train_nsentences": "1750.04", "train_wps": "32288.9", "train_ups": "0.12", "train_wpb": "260617", "train_bsz": "1750", "train_num_updates": "25139", "train_lr": "0.000392797", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "40.1", "train_wall": "11429"}
[2024-10-07 03:33:34,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:33:34,050][fairseq.trainer][INFO] - begin training epoch 525
[2024-10-07 03:33:34,050][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:37:24,687][fairseq_cli.train][INFO] - end of epoch 525 (average epoch stats below)
[2024-10-07 03:37:24,694][train][INFO] - {"epoch": 525, "train_loss": "0.677", "train_ntokens": "260269", "train_nsentences": "1750.04", "train_wps": "54098.2", "train_ups": "0.21", "train_wpb": "260269", "train_bsz": "1750", "train_num_updates": "25187", "train_lr": "0.000393547", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "138", "train_gb_free": "39.8", "train_wall": "11660"}
[2024-10-07 03:37:24,863][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:37:24,887][fairseq.trainer][INFO] - begin training epoch 526
[2024-10-07 03:37:24,887][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:40:43,433][train_inner][INFO] - {"epoch": 526, "update": 525.271, "loss": "0.679", "ntokens": "260419", "nsentences": "1748.63", "wps": "50840.2", "ups": "0.2", "wpb": "260419", "bsz": "1748.6", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.445", "loss_scale": "2", "train_wall": "335", "gb_free": "40.7", "wall": "11859"}
[2024-10-07 03:41:13,530][fairseq_cli.train][INFO] - end of epoch 526 (average epoch stats below)
[2024-10-07 03:41:13,532][train][INFO] - {"epoch": 526, "train_loss": "0.681", "train_ntokens": "260735", "train_nsentences": "1750.04", "train_wps": "54691.2", "train_ups": "0.21", "train_wpb": "260736", "train_bsz": "1750", "train_num_updates": "25235", "train_lr": "0.000394297", "train_gnorm": "0.483", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "40.8", "train_wall": "11889"}
[2024-10-07 03:41:13,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:41:13,718][fairseq.trainer][INFO] - begin training epoch 527
[2024-10-07 03:41:13,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:43:42,109][fairseq_cli.train][INFO] - end of epoch 527 (average epoch stats below)
[2024-10-07 03:43:42,112][train][INFO] - {"epoch": 527, "train_loss": "0.681", "train_ntokens": "261039", "train_nsentences": "1750.04", "train_wps": "84332.2", "train_ups": "0.32", "train_wpb": "261039", "train_bsz": "1750", "train_num_updates": "25283", "train_lr": "0.000395047", "train_gnorm": "0.463", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.4", "train_wall": "12038"}
[2024-10-07 03:43:42,176][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:43:42,182][fairseq.trainer][INFO] - begin training epoch 528
[2024-10-07 03:43:42,183][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:45:55,411][fairseq_cli.train][INFO] - end of epoch 528 (average epoch stats below)
[2024-10-07 03:45:55,418][train][INFO] - {"epoch": 528, "train_loss": "0.672", "train_ntokens": "260695", "train_nsentences": "1750.04", "train_wps": "93871.4", "train_ups": "0.36", "train_wpb": "260695", "train_bsz": "1750", "train_num_updates": "25331", "train_lr": "0.000395797", "train_gnorm": "0.426", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.6", "train_wall": "12171"}
[2024-10-07 03:45:55,567][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:45:55,570][fairseq.trainer][INFO] - begin training epoch 529
[2024-10-07 03:45:55,570][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:48:20,948][fairseq_cli.train][INFO] - end of epoch 529 (average epoch stats below)
[2024-10-07 03:48:20,965][train][INFO] - {"epoch": 529, "train_loss": "0.68", "train_ntokens": "260502", "train_nsentences": "1750.04", "train_wps": "85913.2", "train_ups": "0.33", "train_wpb": "260502", "train_bsz": "1750", "train_num_updates": "25379", "train_lr": "0.000396547", "train_gnorm": "0.458", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.2", "train_wall": "12317"}
[2024-10-07 03:48:21,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:48:21,215][fairseq.trainer][INFO] - begin training epoch 530
[2024-10-07 03:48:21,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:50:59,714][train_inner][INFO] - {"epoch": 530, "update": 529.438, "loss": "0.677", "ntokens": "260952", "nsentences": "1735.58", "wps": "84694", "ups": "0.32", "wpb": "260952", "bsz": "1735.6", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.454", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "12475"}
[2024-10-07 03:51:31,078][fairseq_cli.train][INFO] - end of epoch 530 (average epoch stats below)
[2024-10-07 03:51:31,081][train][INFO] - {"epoch": 530, "train_loss": "0.677", "train_ntokens": "260414", "train_nsentences": "1750.04", "train_wps": "65750", "train_ups": "0.25", "train_wpb": "260414", "train_bsz": "1750", "train_num_updates": "25427", "train_lr": "0.000397297", "train_gnorm": "0.461", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.8", "train_wall": "12507"}
[2024-10-07 03:51:31,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:51:31,353][fairseq.trainer][INFO] - begin training epoch 531
[2024-10-07 03:51:31,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:55:11,835][fairseq_cli.train][INFO] - end of epoch 531 (average epoch stats below)
[2024-10-07 03:55:11,840][train][INFO] - {"epoch": 531, "train_loss": "0.677", "train_ntokens": "260725", "train_nsentences": "1750.04", "train_wps": "56690.5", "train_ups": "0.22", "train_wpb": "260725", "train_bsz": "1750", "train_num_updates": "25475", "train_lr": "0.000398047", "train_gnorm": "0.462", "train_loss_scale": "2", "train_train_wall": "112", "train_gb_free": "39.6", "train_wall": "12727"}
[2024-10-07 03:55:12,001][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:55:12,028][fairseq.trainer][INFO] - begin training epoch 532
[2024-10-07 03:55:12,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:58:12,543][fairseq_cli.train][INFO] - end of epoch 532 (average epoch stats below)
[2024-10-07 03:58:12,550][train][INFO] - {"epoch": 532, "train_loss": "0.674", "train_ntokens": "260936", "train_nsentences": "1750.04", "train_wps": "69310.8", "train_ups": "0.27", "train_wpb": "260936", "train_bsz": "1750", "train_num_updates": "25523", "train_lr": "0.000398797", "train_gnorm": "0.474", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.3", "train_wall": "12908"}
[2024-10-07 03:58:12,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 03:58:12,734][fairseq.trainer][INFO] - begin training epoch 533
[2024-10-07 03:58:12,734][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:01:23,707][fairseq_cli.train][INFO] - end of epoch 533 (average epoch stats below)
[2024-10-07 04:01:23,711][train][INFO] - {"epoch": 533, "train_loss": "0.67", "train_ntokens": "260587", "train_nsentences": "1750.04", "train_wps": "65434.1", "train_ups": "0.25", "train_wpb": "260587", "train_bsz": "1750", "train_num_updates": "25571", "train_lr": "0.000399547", "train_gnorm": "0.424", "train_loss_scale": "2", "train_train_wall": "100", "train_gb_free": "40.2", "train_wall": "13099"}
[2024-10-07 04:01:23,891][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:01:23,905][fairseq.trainer][INFO] - begin training epoch 534
[2024-10-07 04:01:23,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:04:53,105][train_inner][INFO] - {"epoch": 534, "update": 533.604, "loss": "0.675", "ntokens": "260480", "nsentences": "1762.49", "wps": "62514.4", "ups": "0.24", "wpb": "260480", "bsz": "1762.5", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.451", "loss_scale": "2", "train_wall": "397", "gb_free": "39.6", "wall": "13309"}
[2024-10-07 04:05:07,929][fairseq_cli.train][INFO] - end of epoch 534 (average epoch stats below)
[2024-10-07 04:05:07,932][train][INFO] - {"epoch": 534, "train_loss": "0.672", "train_ntokens": "260594", "train_nsentences": "1750.04", "train_wps": "55787.5", "train_ups": "0.21", "train_wpb": "260594", "train_bsz": "1750", "train_num_updates": "25619", "train_lr": "0.000400297", "train_gnorm": "0.417", "train_loss_scale": "2", "train_train_wall": "93", "train_gb_free": "39.7", "train_wall": "13324"}
[2024-10-07 04:05:08,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:05:08,151][fairseq.trainer][INFO] - begin training epoch 535
[2024-10-07 04:05:08,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:08:14,349][fairseq_cli.train][INFO] - end of epoch 535 (average epoch stats below)
[2024-10-07 04:08:14,369][train][INFO] - {"epoch": 535, "train_loss": "0.677", "train_ntokens": "260650", "train_nsentences": "1750.04", "train_wps": "67108.3", "train_ups": "0.26", "train_wpb": "260650", "train_bsz": "1750", "train_num_updates": "25667", "train_lr": "0.000401047", "train_gnorm": "0.477", "train_loss_scale": "2", "train_train_wall": "29", "train_gb_free": "39.8", "train_wall": "13510"}
[2024-10-07 04:08:14,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:08:14,583][fairseq.trainer][INFO] - begin training epoch 536
[2024-10-07 04:08:14,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:11:09,833][fairseq_cli.train][INFO] - end of epoch 536 (average epoch stats below)
[2024-10-07 04:11:09,838][train][INFO] - {"epoch": 536, "train_loss": "0.674", "train_ntokens": "260545", "train_nsentences": "1750.04", "train_wps": "71273.8", "train_ups": "0.27", "train_wpb": "260545", "train_bsz": "1750", "train_num_updates": "25715", "train_lr": "0.000401797", "train_gnorm": "0.472", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.3", "train_wall": "13685"}
[2024-10-07 04:11:10,020][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:11:10,024][fairseq.trainer][INFO] - begin training epoch 537
[2024-10-07 04:11:10,025][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:14:22,143][fairseq_cli.train][INFO] - end of epoch 537 (average epoch stats below)
[2024-10-07 04:14:22,149][train][INFO] - {"epoch": 537, "train_loss": "0.673", "train_ntokens": "260776", "train_nsentences": "1750.04", "train_wps": "65090", "train_ups": "0.25", "train_wpb": "260776", "train_bsz": "1750", "train_num_updates": "25763", "train_lr": "0.000402547", "train_gnorm": "0.428", "train_loss_scale": "2", "train_train_wall": "87", "train_gb_free": "39.6", "train_wall": "13878"}
[2024-10-07 04:14:22,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:14:22,351][fairseq.trainer][INFO] - begin training epoch 538
[2024-10-07 04:14:22,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:18:10,847][train_inner][INFO] - {"epoch": 538, "update": 537.771, "loss": "0.674", "ntokens": "260669", "nsentences": "1755.64", "wps": "65353.1", "ups": "0.25", "wpb": "260669", "bsz": "1755.6", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.457", "loss_scale": "2", "train_wall": "277", "gb_free": "40.5", "wall": "14106"}
[2024-10-07 04:18:22,786][fairseq_cli.train][INFO] - end of epoch 538 (average epoch stats below)
[2024-10-07 04:18:22,789][train][INFO] - {"epoch": 538, "train_loss": "0.676", "train_ntokens": "260659", "train_nsentences": "1750.04", "train_wps": "51994.3", "train_ups": "0.2", "train_wpb": "260659", "train_bsz": "1750", "train_num_updates": "25811", "train_lr": "0.000403297", "train_gnorm": "0.48", "train_loss_scale": "2", "train_train_wall": "84", "train_gb_free": "39.6", "train_wall": "14118"}
[2024-10-07 04:18:23,046][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:18:23,052][fairseq.trainer][INFO] - begin training epoch 539
[2024-10-07 04:18:23,052][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:22:14,192][fairseq_cli.train][INFO] - end of epoch 539 (average epoch stats below)
[2024-10-07 04:22:14,198][train][INFO] - {"epoch": 539, "train_loss": "0.672", "train_ntokens": "260622", "train_nsentences": "1750.04", "train_wps": "54060.5", "train_ups": "0.21", "train_wpb": "260622", "train_bsz": "1750", "train_num_updates": "25859", "train_lr": "0.000404047", "train_gnorm": "0.44", "train_loss_scale": "2", "train_train_wall": "101", "train_gb_free": "39.2", "train_wall": "14350"}
[2024-10-07 04:22:14,360][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:22:14,381][fairseq.trainer][INFO] - begin training epoch 540
[2024-10-07 04:22:14,382][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:25:57,156][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 540 @ 25907 updates
[2024-10-07 04:25:57,160][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 04:26:01,227][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 04:26:01,230][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 540 @ 25907 updates, score None) (writing took 4.073248960077763 seconds)
[2024-10-07 04:26:01,230][fairseq_cli.train][INFO] - end of epoch 540 (average epoch stats below)
[2024-10-07 04:26:01,232][train][INFO] - {"epoch": 540, "train_loss": "0.678", "train_ntokens": "260717", "train_nsentences": "1750.04", "train_wps": "55122.2", "train_ups": "0.21", "train_wpb": "260717", "train_bsz": "1750", "train_num_updates": "25907", "train_lr": "0.000404797", "train_gnorm": "0.443", "train_loss_scale": "2", "train_train_wall": "75", "train_gb_free": "40.7", "train_wall": "14577"}
[2024-10-07 04:26:01,462][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:26:01,484][fairseq.trainer][INFO] - begin training epoch 541
[2024-10-07 04:26:01,484][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:30:38,289][fairseq_cli.train][INFO] - end of epoch 541 (average epoch stats below)
[2024-10-07 04:30:38,299][train][INFO] - {"epoch": 541, "train_loss": "0.673", "train_ntokens": "261063", "train_nsentences": "1750.04", "train_wps": "45228.8", "train_ups": "0.17", "train_wpb": "261063", "train_bsz": "1750", "train_num_updates": "25955", "train_lr": "0.000405547", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "100", "train_gb_free": "40.6", "train_wall": "14854"}
[2024-10-07 04:30:38,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:30:38,560][fairseq.trainer][INFO] - begin training epoch 542
[2024-10-07 04:30:38,560][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:34:09,148][train_inner][INFO] - {"epoch": 542, "update": 541.938, "loss": "0.676", "ntokens": "260670", "nsentences": "1751.27", "wps": "54403.9", "ups": "0.21", "wpb": "260670", "bsz": "1751.3", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.432", "loss_scale": "2", "train_wall": "350", "gb_free": "40.3", "wall": "15065"}
[2024-10-07 04:34:09,850][fairseq_cli.train][INFO] - end of epoch 542 (average epoch stats below)
[2024-10-07 04:34:09,851][train][INFO] - {"epoch": 542, "train_loss": "0.676", "train_ntokens": "260439", "train_nsentences": "1750.04", "train_wps": "59093.1", "train_ups": "0.23", "train_wpb": "260439", "train_bsz": "1750", "train_num_updates": "26003", "train_lr": "0.000406297", "train_gnorm": "0.411", "train_loss_scale": "2", "train_train_wall": "63", "train_gb_free": "39.8", "train_wall": "15065"}
[2024-10-07 04:34:10,097][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:34:10,104][fairseq.trainer][INFO] - begin training epoch 543
[2024-10-07 04:34:10,105][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:37:28,682][fairseq_cli.train][INFO] - end of epoch 543 (average epoch stats below)
[2024-10-07 04:37:28,687][train][INFO] - {"epoch": 543, "train_loss": "0.667", "train_ntokens": "260452", "train_nsentences": "1750.04", "train_wps": "62875.6", "train_ups": "0.24", "train_wpb": "260452", "train_bsz": "1750", "train_num_updates": "26051", "train_lr": "0.000407047", "train_gnorm": "0.441", "train_loss_scale": "2", "train_train_wall": "87", "train_gb_free": "39.3", "train_wall": "15264"}
[2024-10-07 04:37:28,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:37:28,779][fairseq.trainer][INFO] - begin training epoch 544
[2024-10-07 04:37:28,779][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:40:18,499][fairseq_cli.train][INFO] - end of epoch 544 (average epoch stats below)
[2024-10-07 04:40:18,502][train][INFO] - {"epoch": 544, "train_loss": "0.678", "train_ntokens": "261042", "train_nsentences": "1750.04", "train_wps": "73787.7", "train_ups": "0.28", "train_wpb": "261042", "train_bsz": "1750", "train_num_updates": "26099", "train_lr": "0.000407797", "train_gnorm": "0.51", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "40", "train_wall": "15434"}
[2024-10-07 04:40:18,682][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:40:18,686][fairseq.trainer][INFO] - begin training epoch 545
[2024-10-07 04:40:18,687][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:42:49,919][fairseq_cli.train][INFO] - end of epoch 545 (average epoch stats below)
[2024-10-07 04:42:49,922][train][INFO] - {"epoch": 545, "train_loss": "0.668", "train_ntokens": "260607", "train_nsentences": "1750.04", "train_wps": "82614.4", "train_ups": "0.32", "train_wpb": "260607", "train_bsz": "1750", "train_num_updates": "26147", "train_lr": "0.000408547", "train_gnorm": "0.424", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.7", "train_wall": "15586"}
[2024-10-07 04:42:50,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:42:50,060][fairseq.trainer][INFO] - begin training epoch 546
[2024-10-07 04:42:50,061][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:45:22,422][fairseq_cli.train][INFO] - end of epoch 546 (average epoch stats below)
[2024-10-07 04:45:22,441][train][INFO] - {"epoch": 546, "train_loss": "0.674", "train_ntokens": "260940", "train_nsentences": "1750.04", "train_wps": "82123.6", "train_ups": "0.31", "train_wpb": "260940", "train_bsz": "1750", "train_num_updates": "26195", "train_lr": "0.000409297", "train_gnorm": "0.435", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "15738"}
[2024-10-07 04:45:22,623][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:45:22,644][fairseq.trainer][INFO] - begin training epoch 547
[2024-10-07 04:45:22,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:47:43,995][train_inner][INFO] - {"epoch": 547, "update": 546.104, "loss": "0.672", "ntokens": "260864", "nsentences": "1744.56", "wps": "64028.4", "ups": "0.25", "wpb": "260864", "bsz": "1744.6", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.453", "loss_scale": "4", "train_wall": "305", "gb_free": "39.2", "wall": "15880"}
[2024-10-07 04:48:08,094][fairseq_cli.train][INFO] - end of epoch 547 (average epoch stats below)
[2024-10-07 04:48:08,097][train][INFO] - {"epoch": 547, "train_loss": "0.67", "train_ntokens": "260875", "train_nsentences": "1750.04", "train_wps": "75592", "train_ups": "0.29", "train_wpb": "260875", "train_bsz": "1750", "train_num_updates": "26243", "train_lr": "0.000410047", "train_gnorm": "0.433", "train_loss_scale": "4", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "15904"}
[2024-10-07 04:48:08,315][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:48:08,318][fairseq.trainer][INFO] - begin training epoch 548
[2024-10-07 04:48:08,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:51:58,335][fairseq_cli.train][INFO] - end of epoch 548 (average epoch stats below)
[2024-10-07 04:51:58,349][train][INFO] - {"epoch": 548, "train_loss": "0.665", "train_ntokens": "260672", "train_nsentences": "1750.04", "train_wps": "54342.7", "train_ups": "0.21", "train_wpb": "260672", "train_bsz": "1750", "train_num_updates": "26291", "train_lr": "0.000410797", "train_gnorm": "0.402", "train_loss_scale": "4", "train_train_wall": "107", "train_gb_free": "39.3", "train_wall": "16134"}
[2024-10-07 04:51:58,592][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:51:58,612][fairseq.trainer][INFO] - begin training epoch 549
[2024-10-07 04:51:58,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:54:45,769][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 04:55:43,164][fairseq_cli.train][INFO] - end of epoch 549 (average epoch stats below)
[2024-10-07 04:55:43,168][train][INFO] - {"epoch": 549, "train_loss": "0.672", "train_ntokens": "260530", "train_nsentences": "1745.68", "train_wps": "54468", "train_ups": "0.21", "train_wpb": "260530", "train_bsz": "1745.7", "train_num_updates": "26338", "train_lr": "0.000411531", "train_gnorm": "0.467", "train_loss_scale": "2", "train_train_wall": "120", "train_gb_free": "39.8", "train_wall": "16359"}
[2024-10-07 04:55:48,643][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:55:48,653][fairseq.trainer][INFO] - begin training epoch 550
[2024-10-07 04:55:48,654][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:59:15,414][fairseq_cli.train][INFO] - end of epoch 550 (average epoch stats below)
[2024-10-07 04:59:15,422][train][INFO] - {"epoch": 550, "train_loss": "0.666", "train_ntokens": "260639", "train_nsentences": "1750.04", "train_wps": "58942.8", "train_ups": "0.23", "train_wpb": "260639", "train_bsz": "1750", "train_num_updates": "26386", "train_lr": "0.000412281", "train_gnorm": "0.452", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "39.8", "train_wall": "16571"}
[2024-10-07 04:59:15,654][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 04:59:15,664][fairseq.trainer][INFO] - begin training epoch 551
[2024-10-07 04:59:15,664][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:01:15,953][train_inner][INFO] - {"epoch": 551, "update": 550.292, "loss": "0.668", "ntokens": "260576", "nsentences": "1759.1", "wps": "64186.4", "ups": "0.25", "wpb": "260576", "bsz": "1759.1", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.437", "loss_scale": "2", "train_wall": "356", "gb_free": "39.6", "wall": "16692"}
[2024-10-07 05:01:36,481][fairseq_cli.train][INFO] - end of epoch 551 (average epoch stats below)
[2024-10-07 05:01:36,484][train][INFO] - {"epoch": 551, "train_loss": "0.664", "train_ntokens": "260711", "train_nsentences": "1750.04", "train_wps": "88716.3", "train_ups": "0.34", "train_wpb": "260711", "train_bsz": "1750", "train_num_updates": "26434", "train_lr": "0.000413031", "train_gnorm": "0.431", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "39.8", "train_wall": "16712"}
[2024-10-07 05:01:36,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:01:36,617][fairseq.trainer][INFO] - begin training epoch 552
[2024-10-07 05:01:36,617][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:03:52,426][fairseq_cli.train][INFO] - end of epoch 552 (average epoch stats below)
[2024-10-07 05:03:52,435][train][INFO] - {"epoch": 552, "train_loss": "0.673", "train_ntokens": "260679", "train_nsentences": "1750.04", "train_wps": "92040.1", "train_ups": "0.35", "train_wpb": "260679", "train_bsz": "1750", "train_num_updates": "26482", "train_lr": "0.000413781", "train_gnorm": "0.453", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "40.3", "train_wall": "16848"}
[2024-10-07 05:03:52,607][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:03:52,625][fairseq.trainer][INFO] - begin training epoch 553
[2024-10-07 05:03:52,626][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:06:07,253][fairseq_cli.train][INFO] - end of epoch 553 (average epoch stats below)
[2024-10-07 05:06:07,272][train][INFO] - {"epoch": 553, "train_loss": "0.668", "train_ntokens": "261058", "train_nsentences": "1750.04", "train_wps": "92935.8", "train_ups": "0.36", "train_wpb": "261058", "train_bsz": "1750", "train_num_updates": "26530", "train_lr": "0.000414531", "train_gnorm": "0.53", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "39.7", "train_wall": "16983"}
[2024-10-07 05:06:07,430][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:06:07,450][fairseq.trainer][INFO] - begin training epoch 554
[2024-10-07 05:06:07,450][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:09:22,737][fairseq_cli.train][INFO] - end of epoch 554 (average epoch stats below)
[2024-10-07 05:09:22,745][train][INFO] - {"epoch": 554, "train_loss": "0.66", "train_ntokens": "260378", "train_nsentences": "1750.04", "train_wps": "63939.2", "train_ups": "0.25", "train_wpb": "260378", "train_bsz": "1750", "train_num_updates": "26578", "train_lr": "0.000415281", "train_gnorm": "0.423", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "39.3", "train_wall": "17178"}
[2024-10-07 05:09:22,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:09:22,900][fairseq.trainer][INFO] - begin training epoch 555
[2024-10-07 05:09:22,900][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:12:22,888][train_inner][INFO] - {"epoch": 555, "update": 554.458, "loss": "0.666", "ntokens": "260689", "nsentences": "1741.77", "wps": "78175.9", "ups": "0.3", "wpb": "260689", "bsz": "1741.8", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.452", "loss_scale": "2", "train_wall": "256", "gb_free": "39.2", "wall": "17359"}
[2024-10-07 05:12:46,197][fairseq_cli.train][INFO] - end of epoch 555 (average epoch stats below)
[2024-10-07 05:12:46,200][train][INFO] - {"epoch": 555, "train_loss": "0.666", "train_ntokens": "260850", "train_nsentences": "1750.04", "train_wps": "61542", "train_ups": "0.24", "train_wpb": "260850", "train_bsz": "1750", "train_num_updates": "26626", "train_lr": "0.000416031", "train_gnorm": "0.403", "train_loss_scale": "2", "train_train_wall": "93", "train_gb_free": "40.2", "train_wall": "17382"}
[2024-10-07 05:12:46,449][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:12:46,469][fairseq.trainer][INFO] - begin training epoch 556
[2024-10-07 05:12:46,469][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:15:33,120][fairseq_cli.train][INFO] - end of epoch 556 (average epoch stats below)
[2024-10-07 05:15:33,125][train][INFO] - {"epoch": 556, "train_loss": "0.668", "train_ntokens": "260685", "train_nsentences": "1750.04", "train_wps": "74962.7", "train_ups": "0.29", "train_wpb": "260685", "train_bsz": "1750", "train_num_updates": "26674", "train_lr": "0.000416781", "train_gnorm": "0.411", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "40.2", "train_wall": "17549"}
[2024-10-07 05:15:33,329][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:15:33,335][fairseq.trainer][INFO] - begin training epoch 557
[2024-10-07 05:15:33,337][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:18:36,601][fairseq_cli.train][INFO] - end of epoch 557 (average epoch stats below)
[2024-10-07 05:18:36,609][train][INFO] - {"epoch": 557, "train_loss": "0.663", "train_ntokens": "260606", "train_nsentences": "1750.04", "train_wps": "68176.9", "train_ups": "0.26", "train_wpb": "260606", "train_bsz": "1750", "train_num_updates": "26722", "train_lr": "0.000417531", "train_gnorm": "0.522", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.3", "train_wall": "17732"}
[2024-10-07 05:18:36,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:18:36,840][fairseq.trainer][INFO] - begin training epoch 558
[2024-10-07 05:18:36,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:21:39,935][fairseq_cli.train][INFO] - end of epoch 558 (average epoch stats below)
[2024-10-07 05:21:39,944][train][INFO] - {"epoch": 558, "train_loss": "0.662", "train_ntokens": "260592", "train_nsentences": "1750.04", "train_wps": "68230", "train_ups": "0.26", "train_wpb": "260592", "train_bsz": "1750", "train_num_updates": "26770", "train_lr": "0.000418281", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "89", "train_gb_free": "40", "train_wall": "17916"}
[2024-10-07 05:21:40,142][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:21:40,145][fairseq.trainer][INFO] - begin training epoch 559
[2024-10-07 05:21:40,146][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:24:10,526][train_inner][INFO] - {"epoch": 559, "update": 558.625, "loss": "0.664", "ntokens": "260736", "nsentences": "1746.25", "wps": "73693.6", "ups": "0.28", "wpb": "260736", "bsz": "1746.2", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.436", "loss_scale": "2", "train_wall": "283", "gb_free": "39.6", "wall": "18066"}
[2024-10-07 05:24:23,383][fairseq_cli.train][INFO] - end of epoch 559 (average epoch stats below)
[2024-10-07 05:24:23,387][train][INFO] - {"epoch": 559, "train_loss": "0.666", "train_ntokens": "260694", "train_nsentences": "1750.04", "train_wps": "76566.2", "train_ups": "0.29", "train_wpb": "260694", "train_bsz": "1750", "train_num_updates": "26818", "train_lr": "0.000419031", "train_gnorm": "0.416", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "39.8", "train_wall": "18079"}
[2024-10-07 05:24:23,663][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:24:23,671][fairseq.trainer][INFO] - begin training epoch 560
[2024-10-07 05:24:23,672][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:27:13,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 560 @ 26866 updates
[2024-10-07 05:27:13,772][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 05:27:18,437][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 05:27:18,460][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 560 @ 26866 updates, score None) (writing took 4.691255937330425 seconds)
[2024-10-07 05:27:18,461][fairseq_cli.train][INFO] - end of epoch 560 (average epoch stats below)
[2024-10-07 05:27:18,464][train][INFO] - {"epoch": 560, "train_loss": "0.668", "train_ntokens": "260968", "train_nsentences": "1750.04", "train_wps": "71550", "train_ups": "0.27", "train_wpb": "260968", "train_bsz": "1750", "train_num_updates": "26866", "train_lr": "0.000419781", "train_gnorm": "0.46", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.6", "train_wall": "18254"}
[2024-10-07 05:27:18,665][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:27:18,671][fairseq.trainer][INFO] - begin training epoch 561
[2024-10-07 05:27:18,672][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:30:18,600][fairseq_cli.train][INFO] - end of epoch 561 (average epoch stats below)
[2024-10-07 05:30:18,603][train][INFO] - {"epoch": 561, "train_loss": "0.663", "train_ntokens": "260576", "train_nsentences": "1750.04", "train_wps": "69434.8", "train_ups": "0.27", "train_wpb": "260576", "train_bsz": "1750", "train_num_updates": "26914", "train_lr": "0.000420531", "train_gnorm": "0.467", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "39.6", "train_wall": "18434"}
[2024-10-07 05:30:18,750][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:30:18,753][fairseq.trainer][INFO] - begin training epoch 562
[2024-10-07 05:30:18,754][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:36:14,445][fairseq_cli.train][INFO] - end of epoch 562 (average epoch stats below)
[2024-10-07 05:36:14,453][train][INFO] - {"epoch": 562, "train_loss": "0.667", "train_ntokens": "260811", "train_nsentences": "1750.04", "train_wps": "35180.8", "train_ups": "0.13", "train_wpb": "260811", "train_bsz": "1750", "train_num_updates": "26962", "train_lr": "0.000421281", "train_gnorm": "0.406", "train_loss_scale": "2", "train_train_wall": "98", "train_gb_free": "39.8", "train_wall": "18790"}
[2024-10-07 05:36:14,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:36:14,642][fairseq.trainer][INFO] - begin training epoch 563
[2024-10-07 05:36:14,643][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:39:53,811][train_inner][INFO] - {"epoch": 563, "update": 562.792, "loss": "0.664", "ntokens": "260925", "nsentences": "1736.55", "wps": "55323.7", "ups": "0.21", "wpb": "260925", "bsz": "1736.5", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.443", "loss_scale": "2", "train_wall": "291", "gb_free": "39.2", "wall": "19009"}
[2024-10-07 05:40:04,563][fairseq_cli.train][INFO] - end of epoch 563 (average epoch stats below)
[2024-10-07 05:40:04,575][train][INFO] - {"epoch": 563, "train_loss": "0.66", "train_ntokens": "261089", "train_nsentences": "1750.04", "train_wps": "54462.5", "train_ups": "0.21", "train_wpb": "261089", "train_bsz": "1750", "train_num_updates": "27010", "train_lr": "0.000422031", "train_gnorm": "0.447", "train_loss_scale": "2", "train_train_wall": "115", "train_gb_free": "39.7", "train_wall": "19020"}
[2024-10-07 05:40:04,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:40:04,820][fairseq.trainer][INFO] - begin training epoch 564
[2024-10-07 05:40:04,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:44:14,969][fairseq_cli.train][INFO] - end of epoch 564 (average epoch stats below)
[2024-10-07 05:44:14,973][train][INFO] - {"epoch": 564, "train_loss": "0.659", "train_ntokens": "260694", "train_nsentences": "1750.04", "train_wps": "49974.3", "train_ups": "0.19", "train_wpb": "260694", "train_bsz": "1750", "train_num_updates": "27058", "train_lr": "0.000422781", "train_gnorm": "0.441", "train_loss_scale": "2", "train_train_wall": "106", "train_gb_free": "40.5", "train_wall": "19271"}
[2024-10-07 05:44:15,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:44:15,259][fairseq.trainer][INFO] - begin training epoch 565
[2024-10-07 05:44:15,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:48:24,401][fairseq_cli.train][INFO] - end of epoch 565 (average epoch stats below)
[2024-10-07 05:48:24,408][train][INFO] - {"epoch": 565, "train_loss": "0.659", "train_ntokens": "260775", "train_nsentences": "1750.04", "train_wps": "50183", "train_ups": "0.19", "train_wpb": "260775", "train_bsz": "1750", "train_num_updates": "27106", "train_lr": "0.000423531", "train_gnorm": "0.423", "train_loss_scale": "2", "train_train_wall": "100", "train_gb_free": "40", "train_wall": "19520"}
[2024-10-07 05:48:24,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:48:24,729][fairseq.trainer][INFO] - begin training epoch 566
[2024-10-07 05:48:24,729][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:52:27,898][fairseq_cli.train][INFO] - end of epoch 566 (average epoch stats below)
[2024-10-07 05:52:27,902][train][INFO] - {"epoch": 566, "train_loss": "0.664", "train_ntokens": "260901", "train_nsentences": "1750.04", "train_wps": "51432.1", "train_ups": "0.2", "train_wpb": "260901", "train_bsz": "1750", "train_num_updates": "27154", "train_lr": "0.000424281", "train_gnorm": "0.516", "train_loss_scale": "2", "train_train_wall": "151", "train_gb_free": "39.2", "train_wall": "19764"}
[2024-10-07 05:52:28,192][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:52:28,196][fairseq.trainer][INFO] - begin training epoch 567
[2024-10-07 05:52:28,197][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:55:50,667][train_inner][INFO] - {"epoch": 567, "update": 566.958, "loss": "0.662", "ntokens": "260583", "nsentences": "1767.9", "wps": "54467.8", "ups": "0.21", "wpb": "260583", "bsz": "1767.9", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.445", "loss_scale": "2", "train_wall": "428", "gb_free": "40.2", "wall": "19966"}
[2024-10-07 05:55:51,188][fairseq_cli.train][INFO] - end of epoch 567 (average epoch stats below)
[2024-10-07 05:55:51,191][train][INFO] - {"epoch": 567, "train_loss": "0.659", "train_ntokens": "260338", "train_nsentences": "1750.04", "train_wps": "61471.5", "train_ups": "0.24", "train_wpb": "260338", "train_bsz": "1750", "train_num_updates": "27202", "train_lr": "0.000425031", "train_gnorm": "0.386", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.6", "train_wall": "19967"}
[2024-10-07 05:55:51,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:55:51,517][fairseq.trainer][INFO] - begin training epoch 568
[2024-10-07 05:55:51,517][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:59:31,755][fairseq_cli.train][INFO] - end of epoch 568 (average epoch stats below)
[2024-10-07 05:59:31,764][train][INFO] - {"epoch": 568, "train_loss": "0.656", "train_ntokens": "260679", "train_nsentences": "1750.04", "train_wps": "56728.4", "train_ups": "0.22", "train_wpb": "260679", "train_bsz": "1750", "train_num_updates": "27250", "train_lr": "0.000425781", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "124", "train_gb_free": "40", "train_wall": "20187"}
[2024-10-07 05:59:32,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 05:59:32,072][fairseq.trainer][INFO] - begin training epoch 569
[2024-10-07 05:59:32,073][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:03:39,621][fairseq_cli.train][INFO] - end of epoch 569 (average epoch stats below)
[2024-10-07 06:03:39,628][train][INFO] - {"epoch": 569, "train_loss": "0.659", "train_ntokens": "260887", "train_nsentences": "1750.04", "train_wps": "50522.9", "train_ups": "0.19", "train_wpb": "260887", "train_bsz": "1750", "train_num_updates": "27298", "train_lr": "0.000426531", "train_gnorm": "0.44", "train_loss_scale": "2", "train_train_wall": "95", "train_gb_free": "40.3", "train_wall": "20435"}
[2024-10-07 06:03:39,918][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:03:39,938][fairseq.trainer][INFO] - begin training epoch 570
[2024-10-07 06:03:39,939][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:07:24,939][fairseq_cli.train][INFO] - end of epoch 570 (average epoch stats below)
[2024-10-07 06:07:24,954][train][INFO] - {"epoch": 570, "train_loss": "0.658", "train_ntokens": "260926", "train_nsentences": "1750.04", "train_wps": "55584.6", "train_ups": "0.21", "train_wpb": "260926", "train_bsz": "1750", "train_num_updates": "27346", "train_lr": "0.000427281", "train_gnorm": "0.438", "train_loss_scale": "2", "train_train_wall": "119", "train_gb_free": "40.2", "train_wall": "20661"}
[2024-10-07 06:07:25,825][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:07:25,831][fairseq.trainer][INFO] - begin training epoch 571
[2024-10-07 06:07:25,831][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:11:52,892][fairseq_cli.train][INFO] - end of epoch 571 (average epoch stats below)
[2024-10-07 06:11:52,903][train][INFO] - {"epoch": 571, "train_loss": "0.659", "train_ntokens": "260964", "train_nsentences": "1750.04", "train_wps": "46749.4", "train_ups": "0.18", "train_wpb": "260964", "train_bsz": "1750", "train_num_updates": "27394", "train_lr": "0.000428031", "train_gnorm": "0.461", "train_loss_scale": "2", "train_train_wall": "105", "train_gb_free": "40.1", "train_wall": "20929"}
[2024-10-07 06:11:53,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:11:53,216][fairseq.trainer][INFO] - begin training epoch 572
[2024-10-07 06:11:53,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:15:21,322][train_inner][INFO] - {"epoch": 572, "update": 571.125, "loss": "0.658", "ntokens": "260915", "nsentences": "1749.94", "wps": "44576.1", "ups": "0.17", "wpb": "260915", "bsz": "1749.9", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.433", "loss_scale": "2", "train_wall": "448", "gb_free": "39.7", "wall": "21137"}
[2024-10-07 06:16:12,376][fairseq_cli.train][INFO] - end of epoch 572 (average epoch stats below)
[2024-10-07 06:16:12,378][train][INFO] - {"epoch": 572, "train_loss": "0.665", "train_ntokens": "261022", "train_nsentences": "1750.04", "train_wps": "48286.7", "train_ups": "0.18", "train_wpb": "261022", "train_bsz": "1750", "train_num_updates": "27442", "train_lr": "0.000428781", "train_gnorm": "0.48", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "21188"}
[2024-10-07 06:16:12,632][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:16:12,646][fairseq.trainer][INFO] - begin training epoch 573
[2024-10-07 06:16:12,646][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:20:08,411][fairseq_cli.train][INFO] - end of epoch 573 (average epoch stats below)
[2024-10-07 06:20:08,433][train][INFO] - {"epoch": 573, "train_loss": "0.655", "train_ntokens": "260278", "train_nsentences": "1750.04", "train_wps": "52926.5", "train_ups": "0.2", "train_wpb": "260278", "train_bsz": "1750", "train_num_updates": "27490", "train_lr": "0.000429531", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "131", "train_gb_free": "39.9", "train_wall": "21424"}
[2024-10-07 06:20:08,812][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:20:08,823][fairseq.trainer][INFO] - begin training epoch 574
[2024-10-07 06:20:08,823][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:24:16,193][fairseq_cli.train][INFO] - end of epoch 574 (average epoch stats below)
[2024-10-07 06:24:16,200][train][INFO] - {"epoch": 574, "train_loss": "0.657", "train_ntokens": "260309", "train_nsentences": "1750.04", "train_wps": "50430.6", "train_ups": "0.19", "train_wpb": "260310", "train_bsz": "1750", "train_num_updates": "27538", "train_lr": "0.000430281", "train_gnorm": "0.423", "train_loss_scale": "2", "train_train_wall": "95", "train_gb_free": "40", "train_wall": "21672"}
[2024-10-07 06:24:16,572][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:24:16,583][fairseq.trainer][INFO] - begin training epoch 575
[2024-10-07 06:24:16,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:28:23,234][fairseq_cli.train][INFO] - end of epoch 575 (average epoch stats below)
[2024-10-07 06:28:23,242][train][INFO] - {"epoch": 575, "train_loss": "0.662", "train_ntokens": "260699", "train_nsentences": "1750.04", "train_wps": "50654.1", "train_ups": "0.19", "train_wpb": "260699", "train_bsz": "1750", "train_num_updates": "27586", "train_lr": "0.000431031", "train_gnorm": "0.505", "train_loss_scale": "2", "train_train_wall": "139", "train_gb_free": "39.8", "train_wall": "21919"}
[2024-10-07 06:28:23,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:28:23,509][fairseq.trainer][INFO] - begin training epoch 576
[2024-10-07 06:28:23,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:32:19,429][train_inner][INFO] - {"epoch": 576, "update": 575.292, "loss": "0.659", "ntokens": "260409", "nsentences": "1757.73", "wps": "51159.3", "ups": "0.2", "wpb": "260409", "bsz": "1757.7", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.456", "loss_scale": "2", "train_wall": "472", "gb_free": "39.3", "wall": "22155"}
[2024-10-07 06:32:41,760][fairseq_cli.train][INFO] - end of epoch 576 (average epoch stats below)
[2024-10-07 06:32:41,762][train][INFO] - {"epoch": 576, "train_loss": "0.662", "train_ntokens": "260600", "train_nsentences": "1750.04", "train_wps": "48386.9", "train_ups": "0.19", "train_wpb": "260600", "train_bsz": "1750", "train_num_updates": "27634", "train_lr": "0.000431781", "train_gnorm": "0.451", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "40", "train_wall": "22177"}
[2024-10-07 06:32:42,012][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:32:42,017][fairseq.trainer][INFO] - begin training epoch 577
[2024-10-07 06:32:42,017][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:35:17,492][fairseq_cli.train][INFO] - end of epoch 577 (average epoch stats below)
[2024-10-07 06:35:17,496][train][INFO] - {"epoch": 577, "train_loss": "0.662", "train_ntokens": "260507", "train_nsentences": "1750.04", "train_wps": "80294.8", "train_ups": "0.31", "train_wpb": "260507", "train_bsz": "1750", "train_num_updates": "27682", "train_lr": "0.000432531", "train_gnorm": "0.48", "train_loss_scale": "2", "train_train_wall": "34", "train_gb_free": "39.6", "train_wall": "22333"}
[2024-10-07 06:35:17,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:35:17,675][fairseq.trainer][INFO] - begin training epoch 578
[2024-10-07 06:35:17,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:37:25,708][fairseq_cli.train][INFO] - end of epoch 578 (average epoch stats below)
[2024-10-07 06:37:25,711][train][INFO] - {"epoch": 578, "train_loss": "0.659", "train_ntokens": "260640", "train_nsentences": "1750.04", "train_wps": "97579.1", "train_ups": "0.37", "train_wpb": "260640", "train_bsz": "1750", "train_num_updates": "27730", "train_lr": "0.000433281", "train_gnorm": "0.493", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.7", "train_wall": "22461"}
[2024-10-07 06:37:25,789][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:37:25,796][fairseq.trainer][INFO] - begin training epoch 579
[2024-10-07 06:37:25,796][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:39:34,004][fairseq_cli.train][INFO] - end of epoch 579 (average epoch stats below)
[2024-10-07 06:39:34,007][train][INFO] - {"epoch": 579, "train_loss": "0.658", "train_ntokens": "260706", "train_nsentences": "1750.04", "train_wps": "97541.4", "train_ups": "0.37", "train_wpb": "260706", "train_bsz": "1750", "train_num_updates": "27778", "train_lr": "0.000434031", "train_gnorm": "0.402", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.3", "train_wall": "22590"}
[2024-10-07 06:39:34,061][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:39:34,064][fairseq.trainer][INFO] - begin training epoch 580
[2024-10-07 06:39:34,065][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:41:17,031][train_inner][INFO] - {"epoch": 580, "update": 579.458, "loss": "0.661", "ntokens": "260683", "nsentences": "1742.6", "wps": "96983.5", "ups": "0.37", "wpb": "260684", "bsz": "1742.6", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.443", "loss_scale": "2", "train_wall": "177", "gb_free": "40.1", "wall": "22693"}
[2024-10-07 06:41:37,709][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 580 @ 27826 updates
[2024-10-07 06:41:37,710][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 06:41:41,721][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 06:41:41,724][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 580 @ 27826 updates, score None) (writing took 4.014956480823457 seconds)
[2024-10-07 06:41:41,725][fairseq_cli.train][INFO] - end of epoch 580 (average epoch stats below)
[2024-10-07 06:41:41,727][train][INFO] - {"epoch": 580, "train_loss": "0.657", "train_ntokens": "260495", "train_nsentences": "1750.04", "train_wps": "97902.8", "train_ups": "0.38", "train_wpb": "260495", "train_bsz": "1750", "train_num_updates": "27826", "train_lr": "0.000434781", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "46", "train_gb_free": "40.3", "train_wall": "22717"}
[2024-10-07 06:41:41,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:41:41,798][fairseq.trainer][INFO] - begin training epoch 581
[2024-10-07 06:41:41,799][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:46:29,216][fairseq_cli.train][INFO] - end of epoch 581 (average epoch stats below)
[2024-10-07 06:46:29,232][train][INFO] - {"epoch": 581, "train_loss": "0.655", "train_ntokens": "260436", "train_nsentences": "1750.04", "train_wps": "43481.3", "train_ups": "0.17", "train_wpb": "260436", "train_bsz": "1750", "train_num_updates": "27874", "train_lr": "0.000435531", "train_gnorm": "0.43", "train_loss_scale": "2", "train_train_wall": "79", "train_gb_free": "40.6", "train_wall": "23005"}
[2024-10-07 06:46:29,632][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:46:29,636][fairseq.trainer][INFO] - begin training epoch 582
[2024-10-07 06:46:29,637][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:50:47,224][fairseq_cli.train][INFO] - end of epoch 582 (average epoch stats below)
[2024-10-07 06:50:47,238][train][INFO] - {"epoch": 582, "train_loss": "0.66", "train_ntokens": "260820", "train_nsentences": "1750.04", "train_wps": "48524.4", "train_ups": "0.19", "train_wpb": "260820", "train_bsz": "1750", "train_num_updates": "27922", "train_lr": "0.000436281", "train_gnorm": "0.473", "train_loss_scale": "2", "train_train_wall": "97", "train_gb_free": "39.3", "train_wall": "23263"}
[2024-10-07 06:50:47,459][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:50:47,475][fairseq.trainer][INFO] - begin training epoch 583
[2024-10-07 06:50:47,475][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:54:35,748][fairseq_cli.train][INFO] - end of epoch 583 (average epoch stats below)
[2024-10-07 06:54:35,755][train][INFO] - {"epoch": 583, "train_loss": "0.655", "train_ntokens": "260671", "train_nsentences": "1750.04", "train_wps": "54754.7", "train_ups": "0.21", "train_wpb": "260671", "train_bsz": "1750", "train_num_updates": "27970", "train_lr": "0.000437031", "train_gnorm": "0.412", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "39.7", "train_wall": "23491"}
[2024-10-07 06:54:36,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:54:36,029][fairseq.trainer][INFO] - begin training epoch 584
[2024-10-07 06:54:36,030][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:58:15,364][train_inner][INFO] - {"epoch": 584, "update": 583.625, "loss": "0.657", "ntokens": "260738", "nsentences": "1749.39", "wps": "51209", "ups": "0.2", "wpb": "260738", "bsz": "1749.4", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.436", "loss_scale": "2", "train_wall": "315", "gb_free": "39.8", "wall": "23711"}
[2024-10-07 06:58:32,183][fairseq_cli.train][INFO] - end of epoch 584 (average epoch stats below)
[2024-10-07 06:58:32,186][train][INFO] - {"epoch": 584, "train_loss": "0.657", "train_ntokens": "260800", "train_nsentences": "1750.04", "train_wps": "52948.3", "train_ups": "0.2", "train_wpb": "260800", "train_bsz": "1750", "train_num_updates": "28018", "train_lr": "0.000437781", "train_gnorm": "0.443", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40", "train_wall": "23728"}
[2024-10-07 06:58:32,476][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 06:58:32,492][fairseq.trainer][INFO] - begin training epoch 585
[2024-10-07 06:58:32,493][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:02:50,938][fairseq_cli.train][INFO] - end of epoch 585 (average epoch stats below)
[2024-10-07 07:02:50,951][train][INFO] - {"epoch": 585, "train_loss": "0.652", "train_ntokens": "260741", "train_nsentences": "1750.04", "train_wps": "48367.2", "train_ups": "0.19", "train_wpb": "260741", "train_bsz": "1750", "train_num_updates": "28066", "train_lr": "0.000438531", "train_gnorm": "0.479", "train_loss_scale": "2", "train_train_wall": "40", "train_gb_free": "39.3", "train_wall": "23987"}
[2024-10-07 07:02:51,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:02:51,325][fairseq.trainer][INFO] - begin training epoch 586
[2024-10-07 07:02:51,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:07:10,561][fairseq_cli.train][INFO] - end of epoch 586 (average epoch stats below)
[2024-10-07 07:07:10,570][train][INFO] - {"epoch": 586, "train_loss": "0.656", "train_ntokens": "260557", "train_nsentences": "1750.04", "train_wps": "48173.8", "train_ups": "0.18", "train_wpb": "260557", "train_bsz": "1750", "train_num_updates": "28114", "train_lr": "0.000439281", "train_gnorm": "0.442", "train_loss_scale": "2", "train_train_wall": "127", "train_gb_free": "39.7", "train_wall": "24246"}
[2024-10-07 07:07:10,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:07:10,835][fairseq.trainer][INFO] - begin training epoch 587
[2024-10-07 07:07:10,836][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:11:13,108][fairseq_cli.train][INFO] - end of epoch 587 (average epoch stats below)
[2024-10-07 07:11:13,114][train][INFO] - {"epoch": 587, "train_loss": "0.662", "train_ntokens": "260456", "train_nsentences": "1750.04", "train_wps": "51545.6", "train_ups": "0.2", "train_wpb": "260456", "train_bsz": "1750", "train_num_updates": "28162", "train_lr": "0.000440031", "train_gnorm": "0.424", "train_loss_scale": "2", "train_train_wall": "25", "train_gb_free": "39.8", "train_wall": "24489"}
[2024-10-07 07:11:13,362][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:11:13,394][fairseq.trainer][INFO] - begin training epoch 588
[2024-10-07 07:11:13,395][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:15:03,827][train_inner][INFO] - {"epoch": 588, "update": 587.792, "loss": "0.657", "ntokens": "260591", "nsentences": "1752.53", "wps": "51683.1", "ups": "0.2", "wpb": "260591", "bsz": "1752.5", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.45", "loss_scale": "2", "train_wall": "333", "gb_free": "39.8", "wall": "24719"}
[2024-10-07 07:15:16,752][fairseq_cli.train][INFO] - end of epoch 588 (average epoch stats below)
[2024-10-07 07:15:16,755][train][INFO] - {"epoch": 588, "train_loss": "0.656", "train_ntokens": "260684", "train_nsentences": "1750.04", "train_wps": "51358.3", "train_ups": "0.2", "train_wpb": "260684", "train_bsz": "1750", "train_num_updates": "28210", "train_lr": "0.000440781", "train_gnorm": "0.445", "train_loss_scale": "2", "train_train_wall": "138", "train_gb_free": "40", "train_wall": "24732"}
[2024-10-07 07:15:17,072][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:15:17,078][fairseq.trainer][INFO] - begin training epoch 589
[2024-10-07 07:15:17,078][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:19:27,386][fairseq_cli.train][INFO] - end of epoch 589 (average epoch stats below)
[2024-10-07 07:19:27,397][train][INFO] - {"epoch": 589, "train_loss": "0.655", "train_ntokens": "261000", "train_nsentences": "1750.04", "train_wps": "49984.5", "train_ups": "0.19", "train_wpb": "261000", "train_bsz": "1750", "train_num_updates": "28258", "train_lr": "0.000441531", "train_gnorm": "0.459", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "40", "train_wall": "24983"}
[2024-10-07 07:19:27,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:19:27,691][fairseq.trainer][INFO] - begin training epoch 590
[2024-10-07 07:19:27,691][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:23:44,319][fairseq_cli.train][INFO] - end of epoch 590 (average epoch stats below)
[2024-10-07 07:23:44,338][train][INFO] - {"epoch": 590, "train_loss": "0.654", "train_ntokens": "260835", "train_nsentences": "1750.04", "train_wps": "48728.4", "train_ups": "0.19", "train_wpb": "260835", "train_bsz": "1750", "train_num_updates": "28306", "train_lr": "0.000442281", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "139", "train_gb_free": "39.5", "train_wall": "25240"}
[2024-10-07 07:23:44,660][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:23:44,663][fairseq.trainer][INFO] - begin training epoch 591
[2024-10-07 07:23:44,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:28:05,987][fairseq_cli.train][INFO] - end of epoch 591 (average epoch stats below)
[2024-10-07 07:28:05,999][train][INFO] - {"epoch": 591, "train_loss": "0.656", "train_ntokens": "260651", "train_nsentences": "1750.04", "train_wps": "47815.9", "train_ups": "0.18", "train_wpb": "260651", "train_bsz": "1750", "train_num_updates": "28354", "train_lr": "0.000443031", "train_gnorm": "0.451", "train_loss_scale": "4", "train_train_wall": "97", "train_gb_free": "40.3", "train_wall": "25502"}
[2024-10-07 07:28:06,283][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:28:06,292][fairseq.trainer][INFO] - begin training epoch 592
[2024-10-07 07:28:06,293][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:31:18,676][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 07:32:16,347][train_inner][INFO] - {"epoch": 592, "update": 591.979, "loss": "0.655", "ntokens": "260763", "nsentences": "1749.51", "wps": "50510.8", "ups": "0.19", "wpb": "260763", "bsz": "1749.5", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.431", "loss_scale": "2", "train_wall": "437", "gb_free": "39.7", "wall": "25752"}
[2024-10-07 07:32:16,541][fairseq_cli.train][INFO] - end of epoch 592 (average epoch stats below)
[2024-10-07 07:32:16,543][train][INFO] - {"epoch": 592, "train_loss": "0.657", "train_ntokens": "260755", "train_nsentences": "1751.98", "train_wps": "48916.5", "train_ups": "0.19", "train_wpb": "260756", "train_bsz": "1752", "train_num_updates": "28401", "train_lr": "0.000443766", "train_gnorm": "0.416", "train_loss_scale": "2", "train_train_wall": "107", "train_gb_free": "39.6", "train_wall": "25752"}
[2024-10-07 07:32:16,867][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:32:16,871][fairseq.trainer][INFO] - begin training epoch 593
[2024-10-07 07:32:16,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:35:26,284][fairseq_cli.train][INFO] - end of epoch 593 (average epoch stats below)
[2024-10-07 07:35:26,294][train][INFO] - {"epoch": 593, "train_loss": "0.658", "train_ntokens": "260699", "train_nsentences": "1750.04", "train_wps": "65948.6", "train_ups": "0.25", "train_wpb": "260699", "train_bsz": "1750", "train_num_updates": "28449", "train_lr": "0.000444516", "train_gnorm": "0.463", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.8", "train_wall": "25942"}
[2024-10-07 07:35:26,601][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:35:26,608][fairseq.trainer][INFO] - begin training epoch 594
[2024-10-07 07:35:26,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:39:22,894][fairseq_cli.train][INFO] - end of epoch 594 (average epoch stats below)
[2024-10-07 07:39:22,905][train][INFO] - {"epoch": 594, "train_loss": "0.65", "train_ntokens": "260943", "train_nsentences": "1750.04", "train_wps": "52937.3", "train_ups": "0.2", "train_wpb": "260943", "train_bsz": "1750", "train_num_updates": "28497", "train_lr": "0.000445266", "train_gnorm": "0.431", "train_loss_scale": "2", "train_train_wall": "129", "train_gb_free": "40", "train_wall": "26179"}
[2024-10-07 07:39:23,084][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:39:23,103][fairseq.trainer][INFO] - begin training epoch 595
[2024-10-07 07:39:23,103][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:43:08,976][fairseq_cli.train][INFO] - end of epoch 595 (average epoch stats below)
[2024-10-07 07:43:08,982][train][INFO] - {"epoch": 595, "train_loss": "0.661", "train_ntokens": "261081", "train_nsentences": "1750.04", "train_wps": "55432.7", "train_ups": "0.21", "train_wpb": "261081", "train_bsz": "1750", "train_num_updates": "28545", "train_lr": "0.000446016", "train_gnorm": "0.549", "train_loss_scale": "2", "train_train_wall": "99", "train_gb_free": "39.3", "train_wall": "26405"}
[2024-10-07 07:43:09,334][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:43:09,348][fairseq.trainer][INFO] - begin training epoch 596
[2024-10-07 07:43:09,349][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:48:00,374][fairseq_cli.train][INFO] - end of epoch 596 (average epoch stats below)
[2024-10-07 07:48:00,381][train][INFO] - {"epoch": 596, "train_loss": "0.647", "train_ntokens": "260923", "train_nsentences": "1750.04", "train_wps": "42980.4", "train_ups": "0.16", "train_wpb": "260922", "train_bsz": "1750", "train_num_updates": "28593", "train_lr": "0.000446766", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "188", "train_gb_free": "39.2", "train_wall": "26696"}
[2024-10-07 07:48:00,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:48:00,723][fairseq.trainer][INFO] - begin training epoch 597
[2024-10-07 07:48:00,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:52:16,718][train_inner][INFO] - {"epoch": 597, "update": 596.146, "loss": "0.653", "ntokens": "260890", "nsentences": "1757.16", "wps": "43468.5", "ups": "0.17", "wpb": "260890", "bsz": "1757.2", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.451", "loss_scale": "2", "train_wall": "565", "gb_free": "40.3", "wall": "26952"}
[2024-10-07 07:52:41,380][fairseq_cli.train][INFO] - end of epoch 597 (average epoch stats below)
[2024-10-07 07:52:41,382][train][INFO] - {"epoch": 597, "train_loss": "0.657", "train_ntokens": "260732", "train_nsentences": "1750.04", "train_wps": "44538.2", "train_ups": "0.17", "train_wpb": "260732", "train_bsz": "1750", "train_num_updates": "28641", "train_lr": "0.000447516", "train_gnorm": "0.44", "train_loss_scale": "2", "train_train_wall": "106", "train_gb_free": "40.4", "train_wall": "26977"}
[2024-10-07 07:52:41,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:52:41,808][fairseq.trainer][INFO] - begin training epoch 598
[2024-10-07 07:52:41,808][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:57:08,561][fairseq_cli.train][INFO] - end of epoch 598 (average epoch stats below)
[2024-10-07 07:57:08,588][train][INFO] - {"epoch": 598, "train_loss": "0.65", "train_ntokens": "260811", "train_nsentences": "1750.04", "train_wps": "46851.7", "train_ups": "0.18", "train_wpb": "260811", "train_bsz": "1750", "train_num_updates": "28689", "train_lr": "0.000448266", "train_gnorm": "0.431", "train_loss_scale": "2", "train_train_wall": "99", "train_gb_free": "39.6", "train_wall": "27244"}
[2024-10-07 07:57:08,814][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 07:57:08,833][fairseq.trainer][INFO] - begin training epoch 599
[2024-10-07 07:57:08,834][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:01:37,450][fairseq_cli.train][INFO] - end of epoch 599 (average epoch stats below)
[2024-10-07 08:01:37,462][train][INFO] - {"epoch": 599, "train_loss": "0.654", "train_ntokens": "260804", "train_nsentences": "1750.04", "train_wps": "46559.9", "train_ups": "0.18", "train_wpb": "260804", "train_bsz": "1750", "train_num_updates": "28737", "train_lr": "0.000449016", "train_gnorm": "0.442", "train_loss_scale": "2", "train_train_wall": "154", "train_gb_free": "39.2", "train_wall": "27513"}
[2024-10-07 08:01:37,871][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 08:01:37,895][fairseq.trainer][INFO] - begin training epoch 600
[2024-10-07 08:01:37,895][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:06:23,609][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 600 @ 28785 updates
[2024-10-07 08:06:23,610][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 08:06:27,432][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-07 08:06:27,449][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 600 @ 28785 updates, score None) (writing took 3.8397116446867585 seconds)
[2024-10-07 08:06:27,449][fairseq_cli.train][INFO] - end of epoch 600 (average epoch stats below)
[2024-10-07 08:06:27,451][train][INFO] - {"epoch": 600, "train_loss": "0.649", "train_ntokens": "260882", "train_nsentences": "1750.04", "train_wps": "43182.6", "train_ups": "0.17", "train_wpb": "260882", "train_bsz": "1750", "train_num_updates": "28785", "train_lr": "0.000449766", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "103", "train_gb_free": "39.8", "train_wall": "27803"}
[2024-10-07 08:06:27,737][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 08:06:27,765][fairseq.trainer][INFO] - begin training epoch 601
[2024-10-07 08:06:27,765][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:09:55,484][train_inner][INFO] - {"epoch": 601, "update": 600.312, "loss": "0.651", "ntokens": "261038", "nsentences": "1728.52", "wps": "49312", "ups": "0.19", "wpb": "261038", "bsz": "1728.5", "num_updates": "28800", "lr": "0.00045", "gnorm": "0.427", "loss_scale": "2", "train_wall": "441", "gb_free": "39.6", "wall": "28011"}
[2024-10-07 08:10:43,420][fairseq_cli.train][INFO] - end of epoch 601 (average epoch stats below)
[2024-10-07 08:10:43,427][train][INFO] - {"epoch": 601, "train_loss": "0.651", "train_ntokens": "260715", "train_nsentences": "1750.04", "train_wps": "48890.4", "train_ups": "0.19", "train_wpb": "260715", "train_bsz": "1750", "train_num_updates": "28833", "train_lr": "0.000450516", "train_gnorm": "0.452", "train_loss_scale": "2", "train_train_wall": "108", "train_gb_free": "39.6", "train_wall": "28059"}
[2024-10-07 08:10:43,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 08:10:43,687][fairseq.trainer][INFO] - begin training epoch 602
[2024-10-07 08:10:43,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:14:40,857][fairseq_cli.train][INFO] - end of epoch 602 (average epoch stats below)
[2024-10-07 08:14:40,862][train][INFO] - {"epoch": 602, "train_loss": "0.653", "train_ntokens": "260965", "train_nsentences": "1750.04", "train_wps": "52758.3", "train_ups": "0.2", "train_wpb": "260965", "train_bsz": "1750", "train_num_updates": "28881", "train_lr": "0.000451266", "train_gnorm": "0.493", "train_loss_scale": "2", "train_train_wall": "130", "train_gb_free": "39.9", "train_wall": "28297"}
[2024-10-07 08:14:41,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 08:14:41,036][fairseq.trainer][INFO] - begin training epoch 603
[2024-10-07 08:14:41,036][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:18:05,819][fairseq_cli.train][INFO] - end of epoch 603 (average epoch stats below)
[2024-10-07 08:18:05,823][train][INFO] - {"epoch": 603, "train_loss": "0.648", "train_ntokens": "260844", "train_nsentences": "1750.04", "train_wps": "61088.5", "train_ups": "0.23", "train_wpb": "260844", "train_bsz": "1750", "train_num_updates": "28929", "train_lr": "0.000452016", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "112", "train_gb_free": "40.5", "train_wall": "28501"}
[2024-10-07 08:18:06,017][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-07 08:18:06,031][fairseq.trainer][INFO] - begin training epoch 604
[2024-10-07 08:18:06,031][fairseq_cli.train][INFO] - Start iterating over samples
