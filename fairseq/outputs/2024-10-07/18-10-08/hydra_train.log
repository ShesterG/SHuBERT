[2024-10-07 18:10:50,093][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11340', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:51,302][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10252', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:51,418][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16410', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:51,435][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13412', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:51,806][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11631', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:52,236][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17983', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:52,332][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13812', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:52,854][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11817', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-07 18:10:52,924][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:52,925][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:52,925][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:52,925][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:52,926][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:52,951][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:54,217][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:54,219][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:54,219][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:54,219][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:54,219][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:54,220][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:54,252][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:54,254][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:54,254][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:54,254][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:54,255][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:54,255][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:55,276][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:55,278][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:55,278][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:55,278][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:55,278][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:55,279][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:55,484][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:55,485][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:55,485][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:55,485][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:55,486][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:55,490][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:58,361][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:10:58,381][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:10:59,018][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:10:59,020][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:10:59,020][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:10:59,020][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:10:59,021][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:10:59,027][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:10:59,159][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:10:59,263][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:10:59,633][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:11:00,668][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:11:00,670][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:11:00,670][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:11:00,670][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:11:00,679][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:11:00,679][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:11:04,076][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-07 18:11:04,155][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-07 18:11:04,155][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-07 18:11:04,155][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-07 18:11:04,156][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-07 18:11:04,157][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-07 18:11:04,803][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:11:10,355][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:11:41,559][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:16:14,738][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:16:14,739][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:16:14,739][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:16:14,740][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:16:14,746][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:16:43,915][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:16:43,923][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:16:48,207][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:17:11,857][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:17:11,858][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:17:11,895][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:17:11,896][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:17:38,733][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:17:38,736][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:17:38,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:19:19,066][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:19:19,139][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:19:49,416][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:25:14,938][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:25:14,954][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,954][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,956][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,956][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,956][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,957][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,957][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,957][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:25:14,957][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:25:14,957][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:25:14,967][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:25:14,973][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:25:37,905][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:25:37,906][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:25:40,178][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:26:44,117][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:26:44,138][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:26:44,138][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:28:01,576][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,577][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,578][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,578][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:01,578][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:01,578][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:28:01,578][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:28:01,579][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:28:24,727][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:28:24,732][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:28:24,732][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:28:24,863][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:24,864][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:24,864][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:28:24,864][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:28:24,865][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:28:30,729][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:30,820][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,820][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,820][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,820][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,821][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,821][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,821][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,821][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:30,821][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:30,828][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:28:30,836][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:28:30,897][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:28:33,366][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:28:33,624][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:28:33,647][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:28:33,680][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:28:33,835][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:28:34,550][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:28:34,618][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:28:37,209][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:28:39,330][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:28:39,408][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:28:41,652][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:29:04,823][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:29:04,883][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:29:06,230][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-07 18:29:06,308][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-07 18:29:06,319][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-07 18:29:06,323][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-07 18:29:06,359][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-07 18:29:07,112][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:29:31,084][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:29:31,522][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:29:38,368][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:29:40,467][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 113 @ 53623 updates)
[2024-10-07 18:29:40,468][fairseq.trainer][INFO] - loading train data for epoch 113
[2024-10-07 18:29:48,665][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-07 18:30:08,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:30:08,615][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:30:08,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:30:09,621][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:30:09,627][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:30:09,628][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:30:15,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:30:15,683][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:30:15,684][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:30:56,085][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:30:56,092][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:30:56,092][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:31:00,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:31:00,791][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-07 18:31:00,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:16:14,287][train_inner][INFO] - {"epoch": 113, "update": 112.37, "loss": "2.387", "ntokens": "358436", "nsentences": "1809.76", "wps": "64238.5", "ups": "0.18", "wpb": "358436", "bsz": "1809.8", "num_updates": "53800", "lr": "0.00047038", "gnorm": "1.571", "loss_scale": "0.0625", "train_wall": "1202", "gb_free": "39.3", "wall": "2869"}
[2024-10-07 19:16:14,287][train_inner][INFO] - {"epoch": 113, "update": 112.37, "loss": "2.385", "ntokens": "358436", "nsentences": "1809.76", "wps": "64421.1", "ups": "0.18", "wpb": "358436", "bsz": "1809.8", "num_updates": "53800", "lr": "0.00047038", "gnorm": "1.495", "loss_scale": "0.0625", "train_wall": "1189", "gb_free": "39.3", "wall": "2863"}
[2024-10-07 19:33:29,780][train_inner][INFO] - {"epoch": 113, "update": 112.787, "loss": "2.383", "ntokens": "358176", "nsentences": "1726.56", "wps": "69183.5", "ups": "0.19", "wpb": "358176", "bsz": "1726.6", "num_updates": "54000", "lr": "0.000470109", "gnorm": "1.804", "loss_scale": "0.0625", "train_wall": "1033", "gb_free": "40.1", "wall": "3899"}
[2024-10-07 19:33:30,076][train_inner][INFO] - {"epoch": 113, "update": 112.787, "loss": "2.382", "ntokens": "358176", "nsentences": "1726.56", "wps": "69163.8", "ups": "0.19", "wpb": "358176", "bsz": "1726.6", "num_updates": "54000", "lr": "0.000470109", "gnorm": "1.762", "loss_scale": "0.0625", "train_wall": "1033", "gb_free": "40.1", "wall": "3905"}
[2024-10-07 19:41:28,808][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-10-07 19:41:28,861][train][INFO] - {"epoch": 113, "train_loss": "2.385", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "68470.6", "train_ups": "0.19", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "54102", "train_lr": "0.00046997", "train_gnorm": "1.681", "train_loss_scale": "0.0625", "train_train_wall": "2554", "train_gb_free": "39.6", "train_wall": "4384"}
[2024-10-07 19:41:29,004][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-10-07 19:41:29,010][train][INFO] - {"epoch": 113, "train_loss": "2.385", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "68536", "train_ups": "0.19", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "54102", "train_lr": "0.00046997", "train_gnorm": "1.689", "train_loss_scale": "0.0625", "train_train_wall": "2549", "train_gb_free": "39.6", "train_wall": "4378"}
[2024-10-07 19:41:29,114][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:41:29,115][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:41:29,149][fairseq.trainer][INFO] - begin training epoch 114
[2024-10-07 19:41:29,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:41:29,150][fairseq.trainer][INFO] - begin training epoch 114
[2024-10-07 19:41:29,151][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:53:00,549][train_inner][INFO] - {"epoch": 114, "update": 113.205, "loss": "2.371", "ntokens": "356843", "nsentences": "1704.4", "wps": "60974.4", "ups": "0.17", "wpb": "356843", "bsz": "1704.4", "num_updates": "54200", "lr": "0.000469837", "gnorm": "1.552", "loss_scale": "0.0625", "train_wall": "615", "gb_free": "40.1", "wall": "5076"}
[2024-10-07 19:53:20,088][train_inner][INFO] - {"epoch": 114, "update": 113.205, "loss": "2.372", "ntokens": "356843", "nsentences": "1704.4", "wps": "59960", "ups": "0.17", "wpb": "356843", "bsz": "1704.4", "num_updates": "54200", "lr": "0.000469837", "gnorm": "1.708", "loss_scale": "0.0625", "train_wall": "661", "gb_free": "40.1", "wall": "5089"}
[2024-10-07 20:04:04,601][train_inner][INFO] - {"epoch": 114, "update": 113.622, "loss": "2.378", "ntokens": "358257", "nsentences": "1806.12", "wps": "111173", "ups": "0.31", "wpb": "358257", "bsz": "1806.1", "num_updates": "54400", "lr": "0.000469565", "gnorm": "1.52", "loss_scale": "0.0625", "train_wall": "640", "gb_free": "40.1", "wall": "5734"}
[2024-10-07 20:04:13,465][train_inner][INFO] - {"epoch": 114, "update": 113.622, "loss": "2.38", "ntokens": "358257", "nsentences": "1806.12", "wps": "106480", "ups": "0.3", "wpb": "358257", "bsz": "1806.1", "num_updates": "54400", "lr": "0.000469565", "gnorm": "1.635", "loss_scale": "0.0625", "train_wall": "669", "gb_free": "40.1", "wall": "5749"}
[2024-10-07 20:17:04,283][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-10-07 20:17:04,293][train][INFO] - {"epoch": 114, "train_loss": "2.379", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "80230.4", "train_ups": "0.22", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "54581", "train_lr": "0.000469319", "train_gnorm": "1.568", "train_loss_scale": "0.0625", "train_train_wall": "1677", "train_gb_free": "39.7", "train_wall": "6519"}
[2024-10-07 20:17:04,397][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:17:04,400][fairseq.trainer][INFO] - begin training epoch 115
[2024-10-07 20:17:04,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:17:07,371][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-10-07 20:17:07,373][train][INFO] - {"epoch": 114, "train_loss": "2.378", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "80120.1", "train_ups": "0.22", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "54581", "train_lr": "0.000469319", "train_gnorm": "1.564", "train_loss_scale": "0.0625", "train_train_wall": "1701", "train_gb_free": "39.7", "train_wall": "6517"}
[2024-10-07 20:17:07,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:17:07,476][fairseq.trainer][INFO] - begin training epoch 115
[2024-10-07 20:17:07,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:25:40,551][train_inner][INFO] - {"epoch": 115, "update": 114.04, "loss": "2.394", "ntokens": "356809", "nsentences": "1738.83", "wps": "55444.7", "ups": "0.16", "wpb": "356809", "bsz": "1738.8", "num_updates": "54600", "lr": "0.000469293", "gnorm": "1.621", "loss_scale": "0.0625", "train_wall": "804", "gb_free": "39.6", "wall": "7036"}
[2024-10-07 20:25:41,755][train_inner][INFO] - {"epoch": 115, "update": 114.04, "loss": "2.394", "ntokens": "356809", "nsentences": "1738.83", "wps": "55016.9", "ups": "0.15", "wpb": "356809", "bsz": "1738.8", "num_updates": "54600", "lr": "0.000469293", "gnorm": "1.606", "loss_scale": "0.0625", "train_wall": "911", "gb_free": "39.6", "wall": "7031"}
[2024-10-07 20:26:51,964][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-07 20:35:53,480][train_inner][INFO] - {"epoch": 115, "update": 114.457, "loss": "2.374", "ntokens": "358333", "nsentences": "1740.31", "wps": "117156", "ups": "0.33", "wpb": "358334", "bsz": "1740.3", "num_updates": "54800", "lr": "0.000469022", "gnorm": "1.585", "loss_scale": "0.0625", "train_wall": "525", "gb_free": "39.9", "wall": "7643"}
[2024-10-07 20:35:53,740][train_inner][INFO] - {"epoch": 115, "update": 114.459, "loss": "2.379", "ntokens": "358348", "nsentences": "1743.21", "wps": "116894", "ups": "0.33", "wpb": "358348", "bsz": "1743.2", "num_updates": "54800", "lr": "0.000469022", "gnorm": "1.779", "loss_scale": "0.0312", "train_wall": "519", "gb_free": "39.1", "wall": "7649"}
[2024-10-07 20:48:16,348][train_inner][INFO] - {"epoch": 115, "update": 114.875, "loss": "2.381", "ntokens": "358282", "nsentences": "1776.08", "wps": "96480.2", "ups": "0.27", "wpb": "358282", "bsz": "1776.1", "num_updates": "55000", "lr": "0.00046875", "gnorm": "1.51", "loss_scale": "0.0625", "train_wall": "526", "gb_free": "40.1", "wall": "8385"}
[2024-10-07 20:48:17,168][train_inner][INFO] - {"epoch": 115, "update": 114.877, "loss": "2.382", "ntokens": "358280", "nsentences": "1773.77", "wps": "96386.3", "ups": "0.27", "wpb": "358280", "bsz": "1773.8", "num_updates": "55000", "lr": "0.00046875", "gnorm": "1.576", "loss_scale": "0.0312", "train_wall": "496", "gb_free": "39.6", "wall": "8392"}
[2024-10-07 20:51:06,848][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-10-07 20:51:06,867][train][INFO] - {"epoch": 115, "train_loss": "2.384", "train_ntokens": "357678", "train_nsentences": "1754.77", "train_wps": "83703.4", "train_ups": "0.23", "train_wpb": "357678", "train_bsz": "1754.8", "train_num_updates": "55059", "train_lr": "0.00046867", "train_gnorm": "1.676", "train_loss_scale": "0.0312", "train_train_wall": "1268", "train_gb_free": "40.2", "train_wall": "8562"}
[2024-10-07 20:51:07,060][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:51:07,069][fairseq.trainer][INFO] - begin training epoch 116
[2024-10-07 20:51:07,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:51:13,570][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-10-07 20:51:13,575][train][INFO] - {"epoch": 115, "train_loss": "2.381", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "83728.8", "train_ups": "0.23", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "55060", "train_lr": "0.000468668", "train_gnorm": "1.557", "train_loss_scale": "0.0625", "train_train_wall": "1405", "train_gb_free": "40.2", "train_wall": "8563"}
[2024-10-07 20:51:13,641][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:51:13,647][fairseq.trainer][INFO] - begin training epoch 116
[2024-10-07 20:51:13,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:04:34,970][train_inner][INFO] - {"epoch": 116, "update": 115.294, "loss": "2.375", "ntokens": "356834", "nsentences": "1711.19", "wps": "72987.7", "ups": "0.2", "wpb": "356834", "bsz": "1711.2", "num_updates": "55200", "lr": "0.000468478", "gnorm": "1.689", "loss_scale": "0.0312", "train_wall": "470", "gb_free": "39.7", "wall": "9370"}
[2024-10-07 21:04:38,665][train_inner][INFO] - {"epoch": 116, "update": 115.292, "loss": "2.375", "ntokens": "356833", "nsentences": "1709.35", "wps": "72652.3", "ups": "0.2", "wpb": "356833", "bsz": "1709.3", "num_updates": "55200", "lr": "0.000468478", "gnorm": "1.719", "loss_scale": "0.0625", "train_wall": "482", "gb_free": "40.1", "wall": "9368"}
[2024-10-07 21:17:20,338][train_inner][INFO] - {"epoch": 116, "update": 115.712, "loss": "2.372", "ntokens": "358406", "nsentences": "1743.76", "wps": "93668.5", "ups": "0.26", "wpb": "358406", "bsz": "1743.8", "num_updates": "55400", "lr": "0.000468207", "gnorm": "1.556", "loss_scale": "0.0312", "train_wall": "759", "gb_free": "40.1", "wall": "10135"}
[2024-10-07 21:17:24,816][train_inner][INFO] - {"epoch": 116, "update": 115.71, "loss": "2.372", "ntokens": "358402", "nsentences": "1739.16", "wps": "93560.8", "ups": "0.26", "wpb": "358402", "bsz": "1739.2", "num_updates": "55400", "lr": "0.000468207", "gnorm": "1.505", "loss_scale": "0.0625", "train_wall": "763", "gb_free": "40.1", "wall": "10134"}
[2024-10-07 21:27:18,209][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-10-07 21:27:18,221][train][INFO] - {"epoch": 116, "train_loss": "2.376", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "78903.4", "train_ups": "0.22", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "55538", "train_lr": "0.000468019", "train_gnorm": "1.643", "train_loss_scale": "0.0312", "train_train_wall": "1648", "train_gb_free": "39.6", "train_wall": "10733"}
[2024-10-07 21:27:18,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:27:18,293][fairseq.trainer][INFO] - begin training epoch 117
[2024-10-07 21:27:18,293][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:27:24,281][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-10-07 21:27:24,284][train][INFO] - {"epoch": 116, "train_loss": "2.376", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "78926.3", "train_ups": "0.22", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "55539", "train_lr": "0.000468018", "train_gnorm": "1.65", "train_loss_scale": "0.0625", "train_train_wall": "1658", "train_gb_free": "39.6", "train_wall": "10733"}
[2024-10-07 21:27:24,352][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:27:24,354][fairseq.trainer][INFO] - begin training epoch 117
[2024-10-07 21:27:24,355][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:37:03,803][train_inner][INFO] - {"epoch": 117, "update": 116.127, "loss": "2.381", "ntokens": "356491", "nsentences": "1809.22", "wps": "60476", "ups": "0.17", "wpb": "356491", "bsz": "1809.2", "num_updates": "55600", "lr": "0.000467935", "gnorm": "1.624", "loss_scale": "0.0625", "train_wall": "825", "gb_free": "39.8", "wall": "11313"}
[2024-10-07 21:37:04,986][train_inner][INFO] - {"epoch": 117, "update": 116.129, "loss": "2.382", "ntokens": "356472", "nsentences": "1810.07", "wps": "60185.4", "ups": "0.17", "wpb": "356472", "bsz": "1810.1", "num_updates": "55600", "lr": "0.000467935", "gnorm": "1.607", "loss_scale": "0.0312", "train_wall": "824", "gb_free": "39.8", "wall": "11320"}
[2024-10-07 21:45:13,920][train_inner][INFO] - {"epoch": 117, "update": 116.545, "loss": "2.363", "ntokens": "358407", "nsentences": "1732.85", "wps": "146280", "ups": "0.41", "wpb": "358407", "bsz": "1732.9", "num_updates": "55800", "lr": "0.000467663", "gnorm": "1.604", "loss_scale": "0.125", "train_wall": "446", "gb_free": "39.4", "wall": "11803"}
[2024-10-07 21:45:15,551][train_inner][INFO] - {"epoch": 117, "update": 116.547, "loss": "2.364", "ntokens": "358391", "nsentences": "1734.22", "wps": "146120", "ups": "0.41", "wpb": "358391", "bsz": "1734.2", "num_updates": "55800", "lr": "0.000467663", "gnorm": "1.694", "loss_scale": "0.0312", "train_wall": "462", "gb_free": "39.3", "wall": "11811"}
[2024-10-07 21:58:21,743][train_inner][INFO] - {"epoch": 117, "update": 116.962, "loss": "2.377", "ntokens": "358399", "nsentences": "1760.92", "wps": "90994.9", "ups": "0.25", "wpb": "358399", "bsz": "1760.9", "num_updates": "56000", "lr": "0.000467391", "gnorm": "1.659", "loss_scale": "0.125", "train_wall": "775", "gb_free": "39.6", "wall": "12591"}
[2024-10-07 21:58:22,076][train_inner][INFO] - {"epoch": 117, "update": 116.965, "loss": "2.375", "ntokens": "358427", "nsentences": "1753.48", "wps": "91142.3", "ups": "0.25", "wpb": "358427", "bsz": "1753.5", "num_updates": "56000", "lr": "0.000467391", "gnorm": "1.571", "loss_scale": "0.0312", "train_wall": "772", "gb_free": "40.1", "wall": "12597"}
[2024-10-07 22:00:34,074][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-10-07 22:00:34,078][train][INFO] - {"epoch": 117, "train_loss": "2.369", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "86102.4", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "56018", "train_lr": "0.000467367", "train_gnorm": "1.599", "train_loss_scale": "0.125", "train_train_wall": "1595", "train_gb_free": "39.7", "train_wall": "12723"}
[2024-10-07 22:00:34,274][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-10-07 22:00:34,276][train][INFO] - {"epoch": 117, "train_loss": "2.37", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "85832.3", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "56017", "train_lr": "0.000467368", "train_gnorm": "1.608", "train_loss_scale": "0.0312", "train_train_wall": "1609", "train_gb_free": "39.7", "train_wall": "12729"}
[2024-10-07 22:00:34,645][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:00:34,646][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:00:34,657][fairseq.trainer][INFO] - begin training epoch 118
[2024-10-07 22:00:34,657][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:00:34,658][fairseq.trainer][INFO] - begin training epoch 118
[2024-10-07 22:00:34,659][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:27:26,138][train_inner][INFO] - {"epoch": 118, "update": 117.38, "loss": "2.363", "ntokens": "356790", "nsentences": "1746.08", "wps": "40907.3", "ups": "0.11", "wpb": "356790", "bsz": "1746.1", "num_updates": "56200", "lr": "0.00046712", "gnorm": "1.628", "loss_scale": "0.125", "train_wall": "1006", "gb_free": "40.6", "wall": "14335"}
[2024-10-07 22:27:26,402][train_inner][INFO] - {"epoch": 118, "update": 117.382, "loss": "2.365", "ntokens": "356796", "nsentences": "1749.37", "wps": "40909.5", "ups": "0.11", "wpb": "356796", "bsz": "1749.4", "num_updates": "56200", "lr": "0.00046712", "gnorm": "1.568", "loss_scale": "0.0312", "train_wall": "1005", "gb_free": "40.2", "wall": "14342"}
[2024-10-07 22:27:49,164][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-07 22:47:40,850][train_inner][INFO] - {"epoch": 118, "update": 117.8, "loss": "2.365", "ntokens": "358330", "nsentences": "1764.3", "wps": "58999.1", "ups": "0.16", "wpb": "358330", "bsz": "1764.3", "num_updates": "56400", "lr": "0.000466848", "gnorm": "1.39", "loss_scale": "0.0625", "train_wall": "1019", "gb_free": "40.2", "wall": "15550"}
[2024-10-07 22:47:44,963][train_inner][INFO] - {"epoch": 118, "update": 117.8, "loss": "2.366", "ntokens": "358327", "nsentences": "1759.26", "wps": "58811.9", "ups": "0.16", "wpb": "358327", "bsz": "1759.3", "num_updates": "56400", "lr": "0.000466848", "gnorm": "1.916", "loss_scale": "0.0312", "train_wall": "1026", "gb_free": "40.2", "wall": "15560"}
[2024-10-07 22:57:22,398][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-10-07 22:57:22,408][train][INFO] - {"epoch": 118, "train_loss": "2.367", "train_ntokens": "357672", "train_nsentences": "1754.74", "train_wps": "50161.7", "train_ups": "0.14", "train_wpb": "357672", "train_bsz": "1754.7", "train_num_updates": "56496", "train_lr": "0.000466717", "train_gnorm": "1.575", "train_loss_scale": "0.0625", "train_train_wall": "2473", "train_gb_free": "39.6", "train_wall": "16132"}
[2024-10-07 22:57:22,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:57:22,826][fairseq.trainer][INFO] - begin training epoch 119
[2024-10-07 22:57:22,827][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:57:32,409][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-10-07 22:57:32,413][train][INFO] - {"epoch": 118, "train_loss": "2.369", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "50122.6", "train_ups": "0.14", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "56496", "train_lr": "0.000466717", "train_gnorm": "1.672", "train_loss_scale": "0.0312", "train_train_wall": "2486", "train_gb_free": "39.6", "train_wall": "16148"}
[2024-10-07 22:57:32,484][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:57:32,488][fairseq.trainer][INFO] - begin training epoch 119
[2024-10-07 22:57:32,488][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 23:14:27,256][train_inner][INFO] - {"epoch": 119, "update": 118.217, "loss": "2.371", "ntokens": "356786", "nsentences": "1746.19", "wps": "44534.7", "ups": "0.12", "wpb": "356786", "bsz": "1746.2", "num_updates": "56600", "lr": "0.000466576", "gnorm": "1.585", "loss_scale": "0.0312", "train_wall": "1041", "gb_free": "39.6", "wall": "17162"}
[2024-10-07 23:14:27,629][train_inner][INFO] - {"epoch": 119, "update": 118.217, "loss": "2.371", "ntokens": "356786", "nsentences": "1746.19", "wps": "44411.8", "ups": "0.12", "wpb": "356786", "bsz": "1746.2", "num_updates": "56600", "lr": "0.000466576", "gnorm": "1.683", "loss_scale": "0.0625", "train_wall": "982", "gb_free": "39.6", "wall": "17157"}
[2024-10-07 23:35:55,011][train_inner][INFO] - {"epoch": 119, "update": 118.635, "loss": "2.36", "ntokens": "358134", "nsentences": "1749.49", "wps": "55639.2", "ups": "0.16", "wpb": "358134", "bsz": "1749.5", "num_updates": "56800", "lr": "0.000466304", "gnorm": "1.521", "loss_scale": "0.0625", "train_wall": "1032", "gb_free": "40.1", "wall": "18444"}
[2024-10-07 23:35:55,229][train_inner][INFO] - {"epoch": 119, "update": 118.635, "loss": "2.36", "ntokens": "358134", "nsentences": "1749.49", "wps": "55616.7", "ups": "0.16", "wpb": "358134", "bsz": "1749.5", "num_updates": "56800", "lr": "0.000466304", "gnorm": "1.579", "loss_scale": "0.0625", "train_wall": "1038", "gb_free": "40.1", "wall": "18450"}
[2024-10-07 23:55:03,539][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-10-07 23:55:03,551][train][INFO] - {"epoch": 119, "train_loss": "2.366", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "49499.9", "train_ups": "0.14", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "56975", "train_lr": "0.000466067", "train_gnorm": "1.558", "train_loss_scale": "0.0625", "train_train_wall": "2004", "train_gb_free": "39.6", "train_wall": "19593"}
[2024-10-07 23:55:03,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:55:03,844][fairseq.trainer][INFO] - begin training epoch 120
[2024-10-07 23:55:03,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 23:55:16,422][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-10-07 23:55:16,425][train][INFO] - {"epoch": 119, "train_loss": "2.365", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "49458.8", "train_ups": "0.14", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "56975", "train_lr": "0.000466067", "train_gnorm": "1.585", "train_loss_scale": "0.0625", "train_train_wall": "2077", "train_gb_free": "39.6", "train_wall": "19612"}
[2024-10-07 23:55:16,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:55:16,505][fairseq.trainer][INFO] - begin training epoch 120
[2024-10-07 23:55:16,505][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:04:45,059][train_inner][INFO] - {"epoch": 120, "update": 119.052, "loss": "2.373", "ntokens": "356923", "nsentences": "1761.84", "wps": "41263.5", "ups": "0.12", "wpb": "356923", "bsz": "1761.8", "num_updates": "57000", "lr": "0.000466033", "gnorm": "1.562", "loss_scale": "0.0625", "train_wall": "727", "gb_free": "40.2", "wall": "20174"}
[2024-10-08 00:04:45,387][train_inner][INFO] - {"epoch": 120, "update": 119.052, "loss": "2.372", "ntokens": "356923", "nsentences": "1761.84", "wps": "41259.3", "ups": "0.12", "wpb": "356923", "bsz": "1761.8", "num_updates": "57000", "lr": "0.000466033", "gnorm": "1.489", "loss_scale": "0.0625", "train_wall": "742", "gb_free": "40.2", "wall": "20181"}
[2024-10-08 00:17:32,854][train_inner][INFO] - {"epoch": 120, "update": 119.47, "loss": "2.353", "ntokens": "358172", "nsentences": "1776.08", "wps": "93344", "ups": "0.26", "wpb": "358172", "bsz": "1776.1", "num_updates": "57200", "lr": "0.000465761", "gnorm": "1.571", "loss_scale": "0.0625", "train_wall": "733", "gb_free": "40.1", "wall": "20948"}
[2024-10-08 00:17:33,057][train_inner][INFO] - {"epoch": 120, "update": 119.47, "loss": "2.356", "ntokens": "358172", "nsentences": "1776.08", "wps": "93279", "ups": "0.26", "wpb": "358172", "bsz": "1776.1", "num_updates": "57200", "lr": "0.000465761", "gnorm": "1.642", "loss_scale": "0.0625", "train_wall": "727", "gb_free": "40.1", "wall": "20942"}
[2024-10-08 00:26:42,320][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-08 00:36:22,416][train_inner][INFO] - {"epoch": 120, "update": 119.887, "loss": "2.362", "ntokens": "358452", "nsentences": "1736.34", "wps": "63479.6", "ups": "0.18", "wpb": "358452", "bsz": "1736.3", "num_updates": "57400", "lr": "0.000465489", "gnorm": "1.614", "loss_scale": "0.0625", "train_wall": "1100", "gb_free": "39.6", "wall": "22072"}
[2024-10-08 00:36:24,315][train_inner][INFO] - {"epoch": 120, "update": 119.889, "loss": "2.367", "ntokens": "358454", "nsentences": "1738.22", "wps": "63363.4", "ups": "0.18", "wpb": "358454", "bsz": "1738.2", "num_updates": "57400", "lr": "0.000465489", "gnorm": "1.588", "loss_scale": "0.0312", "train_wall": "1102", "gb_free": "39.8", "wall": "22079"}
[2024-10-08 00:40:29,412][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 57454 updates
[2024-10-08 00:40:29,413][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 00:40:32,844][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 00:40:32,848][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 120 @ 57454 updates, score None) (writing took 3.4346105037257075 seconds)
[2024-10-08 00:40:32,848][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-10-08 00:40:32,870][train][INFO] - {"epoch": 120, "train_loss": "2.361", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "62772.9", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "57454", "train_lr": "0.000465416", "train_gnorm": "1.598", "train_loss_scale": "0.0625", "train_train_wall": "2230", "train_gb_free": "39.6", "train_wall": "22322"}
[2024-10-08 00:40:33,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:40:33,051][fairseq.trainer][INFO] - begin training epoch 121
[2024-10-08 00:40:33,052][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:40:45,732][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 57453 updates
[2024-10-08 00:40:45,733][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 00:40:48,614][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 00:40:48,617][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 120 @ 57453 updates, score None) (writing took 2.8852755995467305 seconds)
[2024-10-08 00:40:48,618][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-10-08 00:40:48,620][train][INFO] - {"epoch": 120, "train_loss": "2.361", "train_ntokens": "357673", "train_nsentences": "1754.65", "train_wps": "62575.3", "train_ups": "0.17", "train_wpb": "357673", "train_bsz": "1754.7", "train_num_updates": "57453", "train_lr": "0.000465417", "train_gnorm": "1.59", "train_loss_scale": "0.0312", "train_train_wall": "2253", "train_gb_free": "39.6", "train_wall": "22344"}
[2024-10-08 00:40:48,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:40:48,677][fairseq.trainer][INFO] - begin training epoch 121
[2024-10-08 00:40:48,677][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:57:17,047][train_inner][INFO] - {"epoch": 121, "update": 120.305, "loss": "2.358", "ntokens": "356626", "nsentences": "1743.13", "wps": "56852.7", "ups": "0.16", "wpb": "356626", "bsz": "1743.1", "num_updates": "57600", "lr": "0.000465217", "gnorm": "1.544", "loss_scale": "0.0625", "train_wall": "780", "gb_free": "39.6", "wall": "23326"}
[2024-10-08 00:57:17,418][train_inner][INFO] - {"epoch": 121, "update": 120.307, "loss": "2.358", "ntokens": "356629", "nsentences": "1747.95", "wps": "56919.7", "ups": "0.16", "wpb": "356629", "bsz": "1748", "num_updates": "57600", "lr": "0.000465217", "gnorm": "1.575", "loss_scale": "0.0312", "train_wall": "837", "gb_free": "40.1", "wall": "23333"}
[2024-10-08 01:12:56,695][train_inner][INFO] - {"epoch": 121, "update": 120.722, "loss": "2.358", "ntokens": "358442", "nsentences": "1764.45", "wps": "76304.5", "ups": "0.21", "wpb": "358442", "bsz": "1764.5", "num_updates": "57800", "lr": "0.000464946", "gnorm": "1.539", "loss_scale": "0.0625", "train_wall": "819", "gb_free": "39.6", "wall": "24266"}
[2024-10-08 01:12:58,234][train_inner][INFO] - {"epoch": 121, "update": 120.724, "loss": "2.361", "ntokens": "358440", "nsentences": "1757.16", "wps": "76199.9", "ups": "0.21", "wpb": "358440", "bsz": "1757.2", "num_updates": "57800", "lr": "0.000464946", "gnorm": "1.757", "loss_scale": "0.0312", "train_wall": "821", "gb_free": "40.1", "wall": "24273"}
[2024-10-08 01:25:34,239][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-10-08 01:25:34,252][train][INFO] - {"epoch": 121, "train_loss": "2.359", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "63421.8", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "57933", "train_lr": "0.000464765", "train_gnorm": "1.591", "train_loss_scale": "0.0625", "train_train_wall": "2106", "train_gb_free": "39.1", "train_wall": "25023"}
[2024-10-08 01:25:34,442][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:25:34,463][fairseq.trainer][INFO] - begin training epoch 122
[2024-10-08 01:25:34,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:25:50,955][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-10-08 01:25:50,958][train][INFO] - {"epoch": 121, "train_loss": "2.362", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "63399.2", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "57932", "train_lr": "0.000464766", "train_gnorm": "1.625", "train_loss_scale": "0.0312", "train_train_wall": "2166", "train_gb_free": "39.1", "train_wall": "25046"}
[2024-10-08 01:25:51,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:25:51,030][fairseq.trainer][INFO] - begin training epoch 122
[2024-10-08 01:25:51,030][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:34:53,670][train_inner][INFO] - {"epoch": 122, "update": 121.14, "loss": "2.369", "ntokens": "356841", "nsentences": "1770.52", "wps": "54194", "ups": "0.15", "wpb": "356841", "bsz": "1770.5", "num_updates": "58000", "lr": "0.000464674", "gnorm": "1.661", "loss_scale": "0.0625", "train_wall": "958", "gb_free": "39.6", "wall": "25583"}
[2024-10-08 01:35:56,949][train_inner][INFO] - {"epoch": 122, "update": 121.142, "loss": "2.37", "ntokens": "356690", "nsentences": "1781.67", "wps": "51743.2", "ups": "0.15", "wpb": "356690", "bsz": "1781.7", "num_updates": "58000", "lr": "0.000464674", "gnorm": "1.51", "loss_scale": "0.0312", "train_wall": "952", "gb_free": "42.9", "wall": "25652"}
[2024-10-08 01:46:07,785][train_inner][INFO] - {"epoch": 122, "update": 121.557, "loss": "2.349", "ntokens": "358193", "nsentences": "1754.01", "wps": "106280", "ups": "0.3", "wpb": "358193", "bsz": "1754", "num_updates": "58200", "lr": "0.000464402", "gnorm": "1.402", "loss_scale": "0.0625", "train_wall": "464", "gb_free": "39.4", "wall": "26257"}
[2024-10-08 01:46:22,206][train_inner][INFO] - {"epoch": 122, "update": 121.559, "loss": "2.35", "ntokens": "358346", "nsentences": "1745.88", "wps": "114629", "ups": "0.32", "wpb": "358346", "bsz": "1745.9", "num_updates": "58200", "lr": "0.000464402", "gnorm": "1.481", "loss_scale": "0.0312", "train_wall": "476", "gb_free": "39.6", "wall": "26277"}
[2024-10-08 02:15:27,334][train_inner][INFO] - {"epoch": 122, "update": 121.975, "loss": "2.361", "ntokens": "358440", "nsentences": "1738.37", "wps": "40744.2", "ups": "0.11", "wpb": "358440", "bsz": "1738.4", "num_updates": "58400", "lr": "0.00046413", "gnorm": "1.669", "loss_scale": "0.125", "train_wall": "1645", "gb_free": "39.6", "wall": "28016"}
[2024-10-08 02:15:32,316][train_inner][INFO] - {"epoch": 122, "update": 121.977, "loss": "2.361", "ntokens": "358440", "nsentences": "1736.67", "wps": "40962.8", "ups": "0.11", "wpb": "358440", "bsz": "1736.7", "num_updates": "58400", "lr": "0.00046413", "gnorm": "1.718", "loss_scale": "0.0312", "train_wall": "1626", "gb_free": "40.1", "wall": "28027"}
[2024-10-08 02:16:53,519][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-10-08 02:16:53,529][train][INFO] - {"epoch": 122, "train_loss": "2.356", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "55638.5", "train_ups": "0.16", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "58412", "train_lr": "0.000464114", "train_gnorm": "1.539", "train_loss_scale": "0.125", "train_train_wall": "2399", "train_gb_free": "40.2", "train_wall": "28103"}
[2024-10-08 02:16:54,260][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:16:54,274][fairseq.trainer][INFO] - begin training epoch 123
[2024-10-08 02:16:54,274][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:17:04,084][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-10-08 02:17:04,085][train][INFO] - {"epoch": 122, "train_loss": "2.357", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "55749.7", "train_ups": "0.16", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "58411", "train_lr": "0.000464115", "train_gnorm": "1.581", "train_loss_scale": "0.0312", "train_train_wall": "2376", "train_gb_free": "40.2", "train_wall": "28119"}
[2024-10-08 02:17:04,253][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:17:04,259][fairseq.trainer][INFO] - begin training epoch 123
[2024-10-08 02:17:04,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:44:53,404][train_inner][INFO] - {"epoch": 123, "update": 122.392, "loss": "2.349", "ntokens": "356775", "nsentences": "1763.98", "wps": "40403.6", "ups": "0.11", "wpb": "356775", "bsz": "1764", "num_updates": "58600", "lr": "0.000463859", "gnorm": "1.517", "loss_scale": "0.125", "train_wall": "1358", "gb_free": "40.1", "wall": "29783"}
[2024-10-08 02:46:50,145][train_inner][INFO] - {"epoch": 123, "update": 122.395, "loss": "2.349", "ntokens": "356773", "nsentences": "1764.95", "wps": "37998.8", "ups": "0.11", "wpb": "356773", "bsz": "1765", "num_updates": "58600", "lr": "0.000463859", "gnorm": "1.478", "loss_scale": "0.0312", "train_wall": "1481", "gb_free": "39.6", "wall": "29905"}
[2024-10-08 03:17:02,062][train_inner][INFO] - {"epoch": 123, "update": 122.81, "loss": "2.361", "ntokens": "358280", "nsentences": "1772.69", "wps": "37156.5", "ups": "0.1", "wpb": "358280", "bsz": "1772.7", "num_updates": "58800", "lr": "0.000463587", "gnorm": "1.598", "loss_scale": "0.125", "train_wall": "1926", "gb_free": "39.6", "wall": "31711"}
[2024-10-08 03:17:08,852][train_inner][INFO] - {"epoch": 123, "update": 122.812, "loss": "2.363", "ntokens": "358282", "nsentences": "1770.79", "wps": "39401.4", "ups": "0.11", "wpb": "358282", "bsz": "1770.8", "num_updates": "58800", "lr": "0.000463587", "gnorm": "1.725", "loss_scale": "0.0312", "train_wall": "1816", "gb_free": "39.6", "wall": "31724"}
[2024-10-08 03:23:31,830][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-10-08 03:23:31,852][train][INFO] - {"epoch": 123, "train_loss": "2.355", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "42849.5", "train_ups": "0.12", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "58891", "train_lr": "0.000463463", "train_gnorm": "1.535", "train_loss_scale": "0.125", "train_train_wall": "3587", "train_gb_free": "39.8", "train_wall": "32101"}
[2024-10-08 03:23:32,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:23:32,068][fairseq.trainer][INFO] - begin training epoch 124
[2024-10-08 03:23:32,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:24:00,031][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-10-08 03:24:00,034][train][INFO] - {"epoch": 123, "train_loss": "2.357", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "42661.4", "train_ups": "0.12", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "58890", "train_lr": "0.000463465", "train_gnorm": "1.61", "train_loss_scale": "0.0312", "train_train_wall": "3614", "train_gb_free": "39.8", "train_wall": "32135"}
[2024-10-08 03:24:00,100][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:24:00,102][fairseq.trainer][INFO] - begin training epoch 124
[2024-10-08 03:24:00,103][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:45:35,569][train_inner][INFO] - {"epoch": 124, "update": 123.228, "loss": "2.347", "ntokens": "356799", "nsentences": "1706.11", "wps": "41647", "ups": "0.12", "wpb": "356799", "bsz": "1706.1", "num_updates": "59000", "lr": "0.000463315", "gnorm": "1.52", "loss_scale": "0.125", "train_wall": "1208", "gb_free": "40.1", "wall": "33425"}
[2024-10-08 03:45:36,634][train_inner][INFO] - {"epoch": 124, "update": 123.23, "loss": "2.351", "ntokens": "356802", "nsentences": "1714.28", "wps": "41785.6", "ups": "0.12", "wpb": "356802", "bsz": "1714.3", "num_updates": "59000", "lr": "0.000463315", "gnorm": "1.688", "loss_scale": "0.0312", "train_wall": "1207", "gb_free": "39.6", "wall": "33432"}
[2024-10-08 04:04:40,809][train_inner][INFO] - {"epoch": 124, "update": 123.647, "loss": "2.36", "ntokens": "358288", "nsentences": "1801.06", "wps": "62638.7", "ups": "0.17", "wpb": "358288", "bsz": "1801.1", "num_updates": "59200", "lr": "0.000463043", "gnorm": "1.636", "loss_scale": "0.0312", "train_wall": "1110", "gb_free": "39.6", "wall": "34576"}
[2024-10-08 04:04:40,851][train_inner][INFO] - {"epoch": 124, "update": 123.645, "loss": "2.358", "ntokens": "358290", "nsentences": "1808.39", "wps": "62571.9", "ups": "0.17", "wpb": "358290", "bsz": "1808.4", "num_updates": "59200", "lr": "0.000463043", "gnorm": "1.407", "loss_scale": "0.125", "train_wall": "1111", "gb_free": "40.1", "wall": "34570"}
[2024-10-08 04:25:01,627][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-10-08 04:25:01,748][train][INFO] - {"epoch": 124, "train_loss": "2.355", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "46432.4", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "59370", "train_lr": "0.000462813", "train_gnorm": "1.561", "train_loss_scale": "0.125", "train_train_wall": "2938", "train_gb_free": "39.7", "train_wall": "35791"}
[2024-10-08 04:25:01,952][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:25:01,977][fairseq.trainer][INFO] - begin training epoch 125
[2024-10-08 04:25:01,978][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:25:03,144][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-10-08 04:25:03,148][train][INFO] - {"epoch": 124, "train_loss": "2.357", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "46770.6", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "59369", "train_lr": "0.000462814", "train_gnorm": "1.646", "train_loss_scale": "0.0625", "train_train_wall": "2935", "train_gb_free": "39.7", "train_wall": "35798"}
[2024-10-08 04:25:03,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:25:03,321][fairseq.trainer][INFO] - begin training epoch 125
[2024-10-08 04:25:03,321][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:34:25,354][train_inner][INFO] - {"epoch": 125, "update": 124.063, "loss": "2.36", "ntokens": "356788", "nsentences": "1718.61", "wps": "39988.2", "ups": "0.11", "wpb": "356788", "bsz": "1718.6", "num_updates": "59400", "lr": "0.000462772", "gnorm": "1.683", "loss_scale": "0.125", "train_wall": "1120", "gb_free": "39.6", "wall": "36355"}
[2024-10-08 04:34:27,455][train_inner][INFO] - {"epoch": 125, "update": 124.065, "loss": "2.361", "ntokens": "356782", "nsentences": "1716.5", "wps": "39940.5", "ups": "0.11", "wpb": "356782", "bsz": "1716.5", "num_updates": "59400", "lr": "0.000462772", "gnorm": "1.635", "loss_scale": "0.0625", "train_wall": "1142", "gb_free": "39.3", "wall": "36363"}
[2024-10-08 04:44:59,397][train_inner][INFO] - {"epoch": 125, "update": 124.482, "loss": "2.348", "ntokens": "358211", "nsentences": "1785.13", "wps": "113376", "ups": "0.32", "wpb": "358211", "bsz": "1785.1", "num_updates": "59600", "lr": "0.0004625", "gnorm": "1.56", "loss_scale": "0.0625", "train_wall": "539", "gb_free": "39.6", "wall": "36994"}
[2024-10-08 04:44:59,558][train_inner][INFO] - {"epoch": 125, "update": 124.48, "loss": "2.345", "ntokens": "358209", "nsentences": "1782.51", "wps": "112970", "ups": "0.32", "wpb": "358210", "bsz": "1782.5", "num_updates": "59600", "lr": "0.0004625", "gnorm": "1.605", "loss_scale": "0.125", "train_wall": "540", "gb_free": "39.3", "wall": "36989"}
[2024-10-08 05:05:32,635][train_inner][INFO] - {"epoch": 125, "update": 124.898, "loss": "2.353", "ntokens": "358450", "nsentences": "1727.76", "wps": "58141", "ups": "0.16", "wpb": "358450", "bsz": "1727.8", "num_updates": "59800", "lr": "0.000462228", "gnorm": "1.621", "loss_scale": "0.125", "train_wall": "1158", "gb_free": "39.6", "wall": "38222"}
[2024-10-08 05:06:31,119][train_inner][INFO] - {"epoch": 125, "update": 124.9, "loss": "2.355", "ntokens": "358456", "nsentences": "1733.34", "wps": "55508.2", "ups": "0.15", "wpb": "358456", "bsz": "1733.3", "num_updates": "59800", "lr": "0.000462228", "gnorm": "1.604", "loss_scale": "0.0625", "train_wall": "1221", "gb_free": "40.1", "wall": "38286"}
[2024-10-08 05:09:17,052][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-10-08 05:09:17,066][train][INFO] - {"epoch": 125, "train_loss": "2.349", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "64522", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "59849", "train_lr": "0.000462162", "train_gnorm": "1.593", "train_loss_scale": "0.125", "train_train_wall": "2034", "train_gb_free": "39.8", "train_wall": "38446"}
[2024-10-08 05:09:17,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:09:17,205][fairseq.trainer][INFO] - begin training epoch 126
[2024-10-08 05:09:17,206][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:09:32,714][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-10-08 05:09:32,722][train][INFO] - {"epoch": 125, "train_loss": "2.351", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "64177.4", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "59848", "train_lr": "0.000462163", "train_gnorm": "1.612", "train_loss_scale": "0.0625", "train_train_wall": "2055", "train_gb_free": "39.8", "train_wall": "38468"}
[2024-10-08 05:09:33,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:09:33,037][fairseq.trainer][INFO] - begin training epoch 126
[2024-10-08 05:09:33,038][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:30:56,655][train_inner][INFO] - {"epoch": 126, "update": 125.315, "loss": "2.341", "ntokens": "356668", "nsentences": "1744.12", "wps": "46808.2", "ups": "0.13", "wpb": "356668", "bsz": "1744.1", "num_updates": "60000", "lr": "0.000461957", "gnorm": "1.633", "loss_scale": "0.125", "train_wall": "986", "gb_free": "40.6", "wall": "39746"}
[2024-10-08 05:31:24,558][train_inner][INFO] - {"epoch": 126, "update": 125.317, "loss": "2.341", "ntokens": "356661", "nsentences": "1741.92", "wps": "47764.2", "ups": "0.13", "wpb": "356662", "bsz": "1741.9", "num_updates": "60000", "lr": "0.000461957", "gnorm": "1.593", "loss_scale": "0.0625", "train_wall": "1007", "gb_free": "39.6", "wall": "39780"}
[2024-10-08 05:45:30,827][train_inner][INFO] - {"epoch": 126, "update": 125.733, "loss": "2.349", "ntokens": "358404", "nsentences": "1728.86", "wps": "82006.6", "ups": "0.23", "wpb": "358404", "bsz": "1728.9", "num_updates": "60200", "lr": "0.000461685", "gnorm": "1.654", "loss_scale": "0.125", "train_wall": "683", "gb_free": "39.8", "wall": "40620"}
[2024-10-08 05:45:44,350][train_inner][INFO] - {"epoch": 126, "update": 125.735, "loss": "2.351", "ntokens": "358410", "nsentences": "1727.04", "wps": "83372.7", "ups": "0.23", "wpb": "358410", "bsz": "1727", "num_updates": "60200", "lr": "0.000461685", "gnorm": "1.583", "loss_scale": "0.0625", "train_wall": "667", "gb_free": "39.7", "wall": "40639"}
[2024-10-08 06:09:28,123][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-10-08 06:09:28,136][train][INFO] - {"epoch": 126, "train_loss": "2.348", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "47444.7", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "60328", "train_lr": "0.000461511", "train_gnorm": "1.664", "train_loss_scale": "0.25", "train_train_wall": "2852", "train_gb_free": "40.4", "train_wall": "42057"}
[2024-10-08 06:09:28,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:09:28,793][fairseq.trainer][INFO] - begin training epoch 127
[2024-10-08 06:09:28,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:09:30,733][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-10-08 06:09:30,737][train][INFO] - {"epoch": 126, "train_loss": "2.35", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "47616.9", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "60327", "train_lr": "0.000461512", "train_gnorm": "1.63", "train_loss_scale": "0.0625", "train_train_wall": "2886", "train_gb_free": "40.4", "train_wall": "42066"}
[2024-10-08 06:09:30,883][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:09:30,890][fairseq.trainer][INFO] - begin training epoch 127
[2024-10-08 06:09:30,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:27:55,499][train_inner][INFO] - {"epoch": 127, "update": 126.152, "loss": "2.349", "ntokens": "356805", "nsentences": "1760.68", "wps": "28193.3", "ups": "0.08", "wpb": "356805", "bsz": "1760.7", "num_updates": "60400", "lr": "0.000461413", "gnorm": "1.622", "loss_scale": "0.0625", "train_wall": "1822", "gb_free": "39.7", "wall": "43171"}
[2024-10-08 06:27:55,694][train_inner][INFO] - {"epoch": 127, "update": 126.15, "loss": "2.349", "ntokens": "356806", "nsentences": "1763.76", "wps": "28042.2", "ups": "0.08", "wpb": "356806", "bsz": "1763.8", "num_updates": "60400", "lr": "0.000461413", "gnorm": "1.562", "loss_scale": "0.25", "train_wall": "1841", "gb_free": "39.3", "wall": "43165"}
[2024-10-08 06:52:26,402][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-08 06:58:19,892][train_inner][INFO] - {"epoch": 127, "update": 126.57, "loss": "2.337", "ntokens": "358383", "nsentences": "1725.65", "wps": "39291.4", "ups": "0.11", "wpb": "358384", "bsz": "1725.7", "num_updates": "60600", "lr": "0.000461141", "gnorm": "1.449", "loss_scale": "0.0625", "train_wall": "1597", "gb_free": "39.6", "wall": "44995"}
[2024-10-08 06:58:20,086][train_inner][INFO] - {"epoch": 127, "update": 126.57, "loss": "2.335", "ntokens": "358384", "nsentences": "1722.9", "wps": "39288.1", "ups": "0.11", "wpb": "358384", "bsz": "1722.9", "num_updates": "60600", "lr": "0.000461141", "gnorm": "1.614", "loss_scale": "0.125", "train_wall": "1589", "gb_free": "39.6", "wall": "44989"}
[2024-10-08 07:25:24,790][train_inner][INFO] - {"epoch": 127, "update": 126.987, "loss": "2.359", "ntokens": "358223", "nsentences": "1805.54", "wps": "44097.3", "ups": "0.12", "wpb": "358223", "bsz": "1805.5", "num_updates": "60800", "lr": "0.00046087", "gnorm": "1.553", "loss_scale": "0.125", "train_wall": "861", "gb_free": "39.3", "wall": "46614"}
[2024-10-08 07:25:40,672][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-10-08 07:25:40,681][train][INFO] - {"epoch": 127, "train_loss": "2.345", "train_ntokens": "357671", "train_nsentences": "1753.65", "train_wps": "37389.9", "train_ups": "0.1", "train_wpb": "357671", "train_bsz": "1753.6", "train_num_updates": "60806", "train_lr": "0.000460861", "train_gnorm": "1.548", "train_loss_scale": "0.125", "train_train_wall": "2900", "train_gb_free": "41.1", "train_wall": "46630"}
[2024-10-08 07:25:40,942][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:25:40,963][fairseq.trainer][INFO] - begin training epoch 128
[2024-10-08 07:25:40,964][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 07:25:44,923][train_inner][INFO] - {"epoch": 127, "update": 126.987, "loss": "2.36", "ntokens": "358223", "nsentences": "1805.54", "wps": "43555.7", "ups": "0.12", "wpb": "358223", "bsz": "1805.5", "num_updates": "60800", "lr": "0.00046087", "gnorm": "1.426", "loss_scale": "0.0625", "train_wall": "883", "gb_free": "39.3", "wall": "46640"}
[2024-10-08 07:25:46,593][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-10-08 07:25:46,595][train][INFO] - {"epoch": 127, "train_loss": "2.346", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "37441.3", "train_ups": "0.1", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "60806", "train_lr": "0.000460861", "train_gnorm": "1.418", "train_loss_scale": "0.0625", "train_train_wall": "2911", "train_gb_free": "41.1", "train_wall": "46642"}
[2024-10-08 07:25:46,809][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:25:46,813][fairseq.trainer][INFO] - begin training epoch 128
[2024-10-08 07:25:46,814][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 08:25:05,692][train_inner][INFO] - {"epoch": 128, "update": 127.405, "loss": "2.335", "ntokens": "356889", "nsentences": "1738.18", "wps": "19932.9", "ups": "0.06", "wpb": "356889", "bsz": "1738.2", "num_updates": "61000", "lr": "0.000460598", "gnorm": "1.558", "loss_scale": "0.125", "train_wall": "1796", "gb_free": "39.6", "wall": "50195"}
[2024-10-08 08:25:05,934][train_inner][INFO] - {"epoch": 128, "update": 127.405, "loss": "2.336", "ntokens": "356889", "nsentences": "1738.18", "wps": "20044.3", "ups": "0.06", "wpb": "356889", "bsz": "1738.2", "num_updates": "61000", "lr": "0.000460598", "gnorm": "1.551", "loss_scale": "0.0625", "train_wall": "1794", "gb_free": "39.6", "wall": "50201"}
[2024-10-08 09:04:59,041][train_inner][INFO] - {"epoch": 128, "update": 127.823, "loss": "2.345", "ntokens": "358428", "nsentences": "1760.21", "wps": "29955.1", "ups": "0.08", "wpb": "358428", "bsz": "1760.2", "num_updates": "61200", "lr": "0.000460326", "gnorm": "1.448", "loss_scale": "0.0625", "train_wall": "2389", "gb_free": "40.3", "wall": "52594"}
[2024-10-08 09:04:59,378][train_inner][INFO] - {"epoch": 128, "update": 127.823, "loss": "2.342", "ntokens": "358428", "nsentences": "1760.21", "wps": "29950.2", "ups": "0.08", "wpb": "358428", "bsz": "1760.2", "num_updates": "61200", "lr": "0.000460326", "gnorm": "1.528", "loss_scale": "0.125", "train_wall": "2390", "gb_free": "40.3", "wall": "52589"}
[2024-10-08 09:12:32,186][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-10-08 09:12:32,196][train][INFO] - {"epoch": 128, "train_loss": "2.34", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "26721.6", "train_ups": "0.07", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "61285", "train_lr": "0.000460211", "train_gnorm": "1.608", "train_loss_scale": "0.125", "train_train_wall": "4621", "train_gb_free": "40.1", "train_wall": "53041"}
[2024-10-08 09:12:32,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:12:32,258][fairseq.trainer][INFO] - begin training epoch 129
[2024-10-08 09:12:32,258][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:12:46,903][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-10-08 09:12:46,907][train][INFO] - {"epoch": 128, "train_loss": "2.341", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "26685", "train_ups": "0.07", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "61285", "train_lr": "0.000460211", "train_gnorm": "1.49", "train_loss_scale": "0.0625", "train_train_wall": "4648", "train_gb_free": "40.1", "train_wall": "53062"}
[2024-10-08 09:12:46,969][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:12:46,975][fairseq.trainer][INFO] - begin training epoch 129
[2024-10-08 09:12:46,975][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:26:35,576][train_inner][INFO] - {"epoch": 129, "update": 128.24, "loss": "2.334", "ntokens": "356571", "nsentences": "1750.65", "wps": "55018.2", "ups": "0.15", "wpb": "356571", "bsz": "1750.7", "num_updates": "61400", "lr": "0.000460054", "gnorm": "1.665", "loss_scale": "0.125", "train_wall": "781", "gb_free": "40.1", "wall": "53885"}
[2024-10-08 09:26:38,247][train_inner][INFO] - {"epoch": 129, "update": 128.24, "loss": "2.336", "ntokens": "356571", "nsentences": "1750.65", "wps": "54895.2", "ups": "0.15", "wpb": "356571", "bsz": "1750.7", "num_updates": "61400", "lr": "0.000460054", "gnorm": "1.57", "loss_scale": "0.0625", "train_wall": "788", "gb_free": "40.1", "wall": "53893"}
[2024-10-08 09:28:18,355][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-08 09:41:31,585][train_inner][INFO] - {"epoch": 129, "update": 128.66, "loss": "2.333", "ntokens": "358378", "nsentences": "1719.62", "wps": "79999", "ups": "0.22", "wpb": "358378", "bsz": "1719.6", "num_updates": "61600", "lr": "0.000459783", "gnorm": "1.607", "loss_scale": "0.0625", "train_wall": "867", "gb_free": "40.3", "wall": "54781"}
[2024-10-08 09:41:36,235][train_inner][INFO] - {"epoch": 129, "update": 128.658, "loss": "2.332", "ntokens": "358380", "nsentences": "1722.55", "wps": "79819.4", "ups": "0.22", "wpb": "358380", "bsz": "1722.5", "num_updates": "61600", "lr": "0.000459783", "gnorm": "1.483", "loss_scale": "0.125", "train_wall": "876", "gb_free": "40.6", "wall": "54791"}
[2024-10-08 09:55:03,011][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-10-08 09:55:03,028][train][INFO] - {"epoch": 129, "train_loss": "2.337", "train_ntokens": "357672", "train_nsentences": "1752.56", "train_wps": "67024.4", "train_ups": "0.19", "train_wpb": "357672", "train_bsz": "1752.6", "train_num_updates": "61763", "train_lr": "0.000459561", "train_gnorm": "1.565", "train_loss_scale": "0.0625", "train_train_wall": "1952", "train_gb_free": "39.4", "train_wall": "55592"}
[2024-10-08 09:55:03,128][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:55:03,161][fairseq.trainer][INFO] - begin training epoch 130
[2024-10-08 09:55:03,162][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:55:10,809][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-10-08 09:55:10,814][train][INFO] - {"epoch": 129, "train_loss": "2.338", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "67347.6", "train_ups": "0.19", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "61764", "train_lr": "0.00045956", "train_gnorm": "1.591", "train_loss_scale": "0.125", "train_train_wall": "1952", "train_gb_free": "39.4", "train_wall": "55606"}
[2024-10-08 09:55:10,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:55:10,879][fairseq.trainer][INFO] - begin training epoch 130
[2024-10-08 09:55:10,879][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 10:11:57,498][train_inner][INFO] - {"epoch": 130, "update": 129.075, "loss": "2.348", "ntokens": "356681", "nsentences": "1776.42", "wps": "39168.6", "ups": "0.11", "wpb": "356681", "bsz": "1776.4", "num_updates": "61800", "lr": "0.000459511", "gnorm": "1.598", "loss_scale": "0.125", "train_wall": "1353", "gb_free": "39.3", "wall": "56613"}
[2024-10-08 10:11:58,239][train_inner][INFO] - {"epoch": 130, "update": 129.077, "loss": "2.346", "ntokens": "356684", "nsentences": "1775.35", "wps": "39054.9", "ups": "0.11", "wpb": "356684", "bsz": "1775.3", "num_updates": "61800", "lr": "0.000459511", "gnorm": "1.583", "loss_scale": "0.0625", "train_wall": "1353", "gb_free": "40.6", "wall": "56607"}
[2024-10-08 10:46:20,733][train_inner][INFO] - {"epoch": 130, "update": 129.493, "loss": "2.333", "ntokens": "358311", "nsentences": "1774.06", "wps": "34734.1", "ups": "0.1", "wpb": "358311", "bsz": "1774.1", "num_updates": "62000", "lr": "0.000459239", "gnorm": "1.624", "loss_scale": "0.125", "train_wall": "1478", "gb_free": "39.3", "wall": "58676"}
[2024-10-08 10:46:20,991][train_inner][INFO] - {"epoch": 130, "update": 129.495, "loss": "2.335", "ntokens": "358307", "nsentences": "1775.52", "wps": "34740.7", "ups": "0.1", "wpb": "358307", "bsz": "1775.5", "num_updates": "62000", "lr": "0.000459239", "gnorm": "1.687", "loss_scale": "0.0625", "train_wall": "1474", "gb_free": "39.6", "wall": "58670"}
[2024-10-08 11:09:54,271][train_inner][INFO] - {"epoch": 130, "update": 129.91, "loss": "2.341", "ntokens": "358351", "nsentences": "1762.75", "wps": "50704.3", "ups": "0.14", "wpb": "358351", "bsz": "1762.8", "num_updates": "62200", "lr": "0.000458967", "gnorm": "1.538", "loss_scale": "0.125", "train_wall": "1092", "gb_free": "40.1", "wall": "60089"}
[2024-10-08 11:09:56,375][train_inner][INFO] - {"epoch": 130, "update": 129.912, "loss": "2.34", "ntokens": "358355", "nsentences": "1762.16", "wps": "50637.5", "ups": "0.14", "wpb": "358355", "bsz": "1762.2", "num_updates": "62200", "lr": "0.000458967", "gnorm": "1.508", "loss_scale": "0.0625", "train_wall": "1054", "gb_free": "39.6", "wall": "60086"}
[2024-10-08 11:13:55,366][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 62242 updates
[2024-10-08 11:13:55,368][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 11:14:00,494][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 11:14:00,496][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 130 @ 62242 updates, score None) (writing took 5.129847452044487 seconds)
[2024-10-08 11:14:00,497][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-10-08 11:14:00,499][train][INFO] - {"epoch": 130, "train_loss": "2.336", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "36164", "train_ups": "0.1", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "62242", "train_lr": "0.00045891", "train_gnorm": "1.593", "train_loss_scale": "0.0625", "train_train_wall": "3364", "train_gb_free": "39.3", "train_wall": "60330"}
[2024-10-08 11:14:00,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:14:00,627][fairseq.trainer][INFO] - begin training epoch 131
[2024-10-08 11:14:00,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:14:10,957][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 62243 updates
[2024-10-08 11:14:10,958][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 11:14:14,933][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 11:14:14,938][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 130 @ 62243 updates, score None) (writing took 3.9801331842318177 seconds)
[2024-10-08 11:14:14,938][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-10-08 11:14:14,942][train][INFO] - {"epoch": 130, "train_loss": "2.337", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "36113.3", "train_ups": "0.1", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "62243", "train_lr": "0.000458909", "train_gnorm": "1.603", "train_loss_scale": "0.125", "train_train_wall": "3421", "train_gb_free": "39.3", "train_wall": "60350"}
[2024-10-08 11:14:15,048][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:14:15,053][fairseq.trainer][INFO] - begin training epoch 131
[2024-10-08 11:14:15,054][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:28:53,011][train_inner][INFO] - {"epoch": 131, "update": 130.33, "loss": "2.328", "ntokens": "356824", "nsentences": "1721.19", "wps": "62787.1", "ups": "0.18", "wpb": "356824", "bsz": "1721.2", "num_updates": "62400", "lr": "0.000458696", "gnorm": "1.594", "loss_scale": "0.0625", "train_wall": "645", "gb_free": "39.6", "wall": "61222"}
[2024-10-08 11:28:53,093][train_inner][INFO] - {"epoch": 131, "update": 130.328, "loss": "2.33", "ntokens": "356828", "nsentences": "1722.64", "wps": "62669.4", "ups": "0.18", "wpb": "356828", "bsz": "1722.6", "num_updates": "62400", "lr": "0.000458696", "gnorm": "1.639", "loss_scale": "0.125", "train_wall": "655", "gb_free": "39.2", "wall": "61228"}
[2024-10-08 11:44:46,215][train_inner][INFO] - {"epoch": 131, "update": 130.747, "loss": "2.338", "ntokens": "358185", "nsentences": "1785.36", "wps": "75160.7", "ups": "0.21", "wpb": "358186", "bsz": "1785.4", "num_updates": "62600", "lr": "0.000458424", "gnorm": "1.664", "loss_scale": "0.0625", "train_wall": "849", "gb_free": "39.6", "wall": "62175"}
[2024-10-08 11:44:55,660][train_inner][INFO] - {"epoch": 131, "update": 130.745, "loss": "2.337", "ntokens": "358184", "nsentences": "1784.2", "wps": "74423.9", "ups": "0.21", "wpb": "358184", "bsz": "1784.2", "num_updates": "62600", "lr": "0.000458424", "gnorm": "1.571", "loss_scale": "0.125", "train_wall": "864", "gb_free": "39.6", "wall": "62191"}
[2024-10-08 11:47:04,705][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-08 11:53:40,080][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-10-08 11:53:40,095][train][INFO] - {"epoch": 131, "train_loss": "2.334", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "71998.1", "train_ups": "0.2", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "62721", "train_lr": "0.00045826", "train_gnorm": "1.617", "train_loss_scale": "0.0625", "train_train_wall": "1707", "train_gb_free": "40.1", "train_wall": "62709"}
[2024-10-08 11:53:40,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:53:40,246][fairseq.trainer][INFO] - begin training epoch 132
[2024-10-08 11:53:40,246][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:53:53,354][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-10-08 11:53:53,356][train][INFO] - {"epoch": 131, "train_loss": "2.334", "train_ntokens": "357671", "train_nsentences": "1753.4", "train_wps": "71882.7", "train_ups": "0.2", "train_wpb": "357671", "train_bsz": "1753.4", "train_num_updates": "62721", "train_lr": "0.00045826", "train_gnorm": "1.57", "train_loss_scale": "0.0625", "train_train_wall": "1733", "train_gb_free": "40.1", "train_wall": "62728"}
[2024-10-08 11:53:53,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:53:53,499][fairseq.trainer][INFO] - begin training epoch 132
[2024-10-08 11:53:53,500][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:08:47,302][train_inner][INFO] - {"epoch": 132, "update": 131.165, "loss": "2.334", "ntokens": "356817", "nsentences": "1727.62", "wps": "49847.7", "ups": "0.14", "wpb": "356817", "bsz": "1727.6", "num_updates": "62800", "lr": "0.000458152", "gnorm": "1.538", "loss_scale": "0.0625", "train_wall": "927", "gb_free": "40.6", "wall": "63622"}
[2024-10-08 12:08:51,829][train_inner][INFO] - {"epoch": 132, "update": 131.165, "loss": "2.335", "ntokens": "356822", "nsentences": "1729.04", "wps": "49369.5", "ups": "0.14", "wpb": "356822", "bsz": "1729", "num_updates": "62800", "lr": "0.000458152", "gnorm": "1.589", "loss_scale": "0.0625", "train_wall": "915", "gb_free": "40.6", "wall": "63621"}
[2024-10-08 12:10:46,839][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-08 12:18:19,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
[2024-10-08 12:19:55,559][train_inner][INFO] - {"epoch": 132, "update": 131.587, "loss": "2.337", "ntokens": "358462", "nsentences": "1746.15", "wps": "108019", "ups": "0.3", "wpb": "358462", "bsz": "1746.2", "num_updates": "63000", "lr": "0.00045788", "gnorm": "1.825", "loss_scale": "0.0156", "train_wall": "550", "gb_free": "39.7", "wall": "64285"}
[2024-10-08 12:20:29,054][train_inner][INFO] - {"epoch": 132, "update": 131.582, "loss": "2.33", "ntokens": "358467", "nsentences": "1746.76", "wps": "102170", "ups": "0.29", "wpb": "358467", "bsz": "1746.8", "num_updates": "63000", "lr": "0.00045788", "gnorm": "1.535", "loss_scale": "0.0625", "train_wall": "605", "gb_free": "41.1", "wall": "64324"}
[2024-10-08 12:38:08,142][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-10-08 12:38:08,156][train][INFO] - {"epoch": 132, "train_loss": "2.337", "train_ntokens": "357669", "train_nsentences": "1753.57", "train_wps": "63944.9", "train_ups": "0.18", "train_wpb": "357669", "train_bsz": "1753.6", "train_num_updates": "63198", "train_lr": "0.000457611", "train_gnorm": "1.646", "train_loss_scale": "0.0156", "train_train_wall": "1745", "train_gb_free": "40.1", "train_wall": "65377"}
[2024-10-08 12:38:08,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:38:08,354][fairseq.trainer][INFO] - begin training epoch 133
[2024-10-08 12:38:08,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:38:13,227][train_inner][INFO] - {"epoch": 132, "update": 132.0, "loss": "2.342", "ntokens": "356635", "nsentences": "1770.65", "wps": "67025.9", "ups": "0.19", "wpb": "356635", "bsz": "1770.7", "num_updates": "63200", "lr": "0.000457609", "gnorm": "1.774", "loss_scale": "0.0625", "train_wall": "774", "gb_free": "40.1", "wall": "65388"}
[2024-10-08 12:38:13,229][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-10-08 12:38:13,230][train][INFO] - {"epoch": 132, "train_loss": "2.334", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "64411.3", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "63200", "train_lr": "0.000457609", "train_gnorm": "1.609", "train_loss_scale": "0.0625", "train_train_wall": "1840", "train_gb_free": "40.1", "train_wall": "65388"}
[2024-10-08 12:38:13,365][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:38:13,371][fairseq.trainer][INFO] - begin training epoch 133
[2024-10-08 12:38:13,371][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:46:47,375][train_inner][INFO] - {"epoch": 133, "update": 132.004, "loss": "2.339", "ntokens": "356625", "nsentences": "1767.66", "wps": "44252", "ups": "0.12", "wpb": "356625", "bsz": "1767.7", "num_updates": "63200", "lr": "0.000457609", "gnorm": "1.462", "loss_scale": "0.0156", "train_wall": "906", "gb_free": "39.6", "wall": "65897"}
[2024-10-08 13:16:13,762][train_inner][INFO] - {"epoch": 133, "update": 132.418, "loss": "2.327", "ntokens": "358176", "nsentences": "1789.14", "wps": "31411.7", "ups": "0.09", "wpb": "358176", "bsz": "1789.1", "num_updates": "63400", "lr": "0.000457337", "gnorm": "1.587", "loss_scale": "0.0625", "train_wall": "1730", "gb_free": "39.3", "wall": "67669"}
[2024-10-08 13:16:21,172][train_inner][INFO] - {"epoch": 133, "update": 132.422, "loss": "2.329", "ntokens": "358193", "nsentences": "1797.28", "wps": "40390.6", "ups": "0.11", "wpb": "358193", "bsz": "1797.3", "num_updates": "63400", "lr": "0.000457337", "gnorm": "1.453", "loss_scale": "0.0156", "train_wall": "1545", "gb_free": "39.1", "wall": "67670"}
[2024-10-08 13:43:43,116][train_inner][INFO] - {"epoch": 133, "update": 132.835, "loss": "2.328", "ntokens": "358382", "nsentences": "1740.83", "wps": "43458.1", "ups": "0.12", "wpb": "358382", "bsz": "1740.8", "num_updates": "63600", "lr": "0.000457065", "gnorm": "1.603", "loss_scale": "0.0625", "train_wall": "1437", "gb_free": "39.8", "wall": "69318"}
[2024-10-08 13:43:43,842][train_inner][INFO] - {"epoch": 133, "update": 132.839, "loss": "2.328", "ntokens": "358376", "nsentences": "1731.07", "wps": "43633.5", "ups": "0.12", "wpb": "358376", "bsz": "1731.1", "num_updates": "63600", "lr": "0.000457065", "gnorm": "1.713", "loss_scale": "0.0156", "train_wall": "1429", "gb_free": "40.3", "wall": "69313"}
[2024-10-08 13:51:03,759][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-10-08 13:51:03,772][train][INFO] - {"epoch": 133, "train_loss": "2.33", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "39154.8", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "63677", "train_lr": "0.000456961", "train_gnorm": "1.618", "train_loss_scale": "0.0156", "train_train_wall": "3589", "train_gb_free": "40.1", "train_wall": "69753"}
[2024-10-08 13:51:03,955][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:51:03,985][fairseq.trainer][INFO] - begin training epoch 134
[2024-10-08 13:51:03,986][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 13:51:04,453][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-10-08 13:51:04,456][train][INFO] - {"epoch": 133, "train_loss": "2.33", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "39194", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "63679", "train_lr": "0.000456958", "train_gnorm": "1.577", "train_loss_scale": "0.0625", "train_train_wall": "3607", "train_gb_free": "40.1", "train_wall": "69760"}
[2024-10-08 13:51:04,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:51:04,645][fairseq.trainer][INFO] - begin training epoch 134
[2024-10-08 13:51:04,646][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:09:08,158][train_inner][INFO] - {"epoch": 134, "update": 133.257, "loss": "2.325", "ntokens": "356870", "nsentences": "1732.77", "wps": "46824.1", "ups": "0.13", "wpb": "356870", "bsz": "1732.8", "num_updates": "63800", "lr": "0.000456793", "gnorm": "1.662", "loss_scale": "0.0156", "train_wall": "1172", "gb_free": "39.6", "wall": "70837"}
[2024-10-08 14:09:08,246][train_inner][INFO] - {"epoch": 134, "update": 133.253, "loss": "2.326", "ntokens": "356874", "nsentences": "1728.16", "wps": "46800.5", "ups": "0.13", "wpb": "356874", "bsz": "1728.2", "num_updates": "63800", "lr": "0.000456793", "gnorm": "1.443", "loss_scale": "0.0625", "train_wall": "1176", "gb_free": "40.1", "wall": "70843"}
[2024-10-08 14:18:29,672][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-08 14:22:45,622][train_inner][INFO] - {"epoch": 134, "update": 133.672, "loss": "2.33", "ntokens": "358328", "nsentences": "1773.13", "wps": "87678.8", "ups": "0.24", "wpb": "358328", "bsz": "1773.1", "num_updates": "64000", "lr": "0.000456522", "gnorm": "1.481", "loss_scale": "0.0312", "train_wall": "814", "gb_free": "39.3", "wall": "71661"}
[2024-10-08 14:22:50,492][train_inner][INFO] - {"epoch": 134, "update": 133.674, "loss": "2.33", "ntokens": "358333", "nsentences": "1772.67", "wps": "87157.5", "ups": "0.24", "wpb": "358333", "bsz": "1772.7", "num_updates": "64000", "lr": "0.000456522", "gnorm": "1.609", "loss_scale": "0.0156", "train_wall": "819", "gb_free": "39.2", "wall": "71660"}
[2024-10-08 14:46:33,440][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-10-08 14:46:33,455][train][INFO] - {"epoch": 134, "train_loss": "2.328", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "51454.2", "train_ups": "0.14", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "64156", "train_lr": "0.00045631", "train_gnorm": "1.56", "train_loss_scale": "0.0156", "train_train_wall": "2847", "train_gb_free": "39.6", "train_wall": "73083"}
[2024-10-08 14:46:33,722][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:46:33,753][fairseq.trainer][INFO] - begin training epoch 135
[2024-10-08 14:46:33,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:46:42,566][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-10-08 14:46:42,569][train][INFO] - {"epoch": 134, "train_loss": "2.328", "train_ntokens": "357672", "train_nsentences": "1754.01", "train_wps": "51216.7", "train_ups": "0.14", "train_wpb": "357672", "train_bsz": "1754", "train_num_updates": "64157", "train_lr": "0.000456308", "train_gnorm": "1.495", "train_loss_scale": "0.0312", "train_train_wall": "2868", "train_gb_free": "39.6", "train_wall": "73098"}
[2024-10-08 14:46:42,840][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:46:42,853][fairseq.trainer][INFO] - begin training epoch 135
[2024-10-08 14:46:42,853][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:59:18,045][train_inner][INFO] - {"epoch": 135, "update": 134.092, "loss": "2.329", "ntokens": "356750", "nsentences": "1718.33", "wps": "32616.4", "ups": "0.09", "wpb": "356750", "bsz": "1718.3", "num_updates": "64200", "lr": "0.00045625", "gnorm": "1.682", "loss_scale": "0.0156", "train_wall": "1459", "gb_free": "40.1", "wall": "73847"}
[2024-10-08 14:59:23,789][train_inner][INFO] - {"epoch": 135, "update": 134.09, "loss": "2.328", "ntokens": "356761", "nsentences": "1722.35", "wps": "32460.2", "ups": "0.09", "wpb": "356761", "bsz": "1722.3", "num_updates": "64200", "lr": "0.00045625", "gnorm": "1.543", "loss_scale": "0.0312", "train_wall": "1490", "gb_free": "39.1", "wall": "73859"}
[2024-10-08 15:31:33,511][train_inner][INFO] - {"epoch": 135, "update": 134.507, "loss": "2.319", "ntokens": "358265", "nsentences": "1744.87", "wps": "37131.7", "ups": "0.1", "wpb": "358265", "bsz": "1744.9", "num_updates": "64400", "lr": "0.000455978", "gnorm": "1.73", "loss_scale": "0.0312", "train_wall": "1827", "gb_free": "39.6", "wall": "75789"}
[2024-10-08 15:31:33,754][train_inner][INFO] - {"epoch": 135, "update": 134.509, "loss": "2.318", "ntokens": "358279", "nsentences": "1748.12", "wps": "37019", "ups": "0.1", "wpb": "358278", "bsz": "1748.1", "num_updates": "64400", "lr": "0.000455978", "gnorm": "1.442", "loss_scale": "0.0156", "train_wall": "1822", "gb_free": "39.3", "wall": "75783"}
[2024-10-08 15:59:40,254][train_inner][INFO] - {"epoch": 135, "update": 134.927, "loss": "2.326", "ntokens": "358343", "nsentences": "1756.53", "wps": "42495.6", "ups": "0.12", "wpb": "358343", "bsz": "1756.5", "num_updates": "64600", "lr": "0.000455707", "gnorm": "1.529", "loss_scale": "0.0156", "train_wall": "1280", "gb_free": "39.3", "wall": "77469"}
[2024-10-08 15:59:40,742][train_inner][INFO] - {"epoch": 135, "update": 134.925, "loss": "2.326", "ntokens": "358342", "nsentences": "1758.28", "wps": "42477.3", "ups": "0.12", "wpb": "358342", "bsz": "1758.3", "num_updates": "64600", "lr": "0.000455707", "gnorm": "1.406", "loss_scale": "0.0312", "train_wall": "1272", "gb_free": "39.1", "wall": "77476"}
[2024-10-08 16:01:32,414][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-10-08 16:01:32,427][train][INFO] - {"epoch": 135, "train_loss": "2.323", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "38081.2", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "64635", "train_lr": "0.000455659", "train_gnorm": "1.569", "train_loss_scale": "0.0156", "train_train_wall": "3377", "train_gb_free": "39.3", "train_wall": "77582"}
[2024-10-08 16:01:37,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:01:37,487][fairseq.trainer][INFO] - begin training epoch 136
[2024-10-08 16:01:37,487][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:01:54,073][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-10-08 16:01:54,077][train][INFO] - {"epoch": 135, "train_loss": "2.324", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "37975.3", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "64636", "train_lr": "0.000455658", "train_gnorm": "1.56", "train_loss_scale": "0.0312", "train_train_wall": "3405", "train_gb_free": "39.3", "train_wall": "77609"}
[2024-10-08 16:01:54,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:01:54,662][fairseq.trainer][INFO] - begin training epoch 136
[2024-10-08 16:01:54,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:41:18,958][train_inner][INFO] - {"epoch": 136, "update": 135.342, "loss": "2.317", "ntokens": "356566", "nsentences": "1788.12", "wps": "28545.7", "ups": "0.08", "wpb": "356566", "bsz": "1788.1", "num_updates": "64800", "lr": "0.000455435", "gnorm": "1.75", "loss_scale": "0.0312", "train_wall": "1921", "gb_free": "39.3", "wall": "79974"}
[2024-10-08 16:41:19,237][train_inner][INFO] - {"epoch": 136, "update": 135.344, "loss": "2.316", "ntokens": "356559", "nsentences": "1789.04", "wps": "28536.5", "ups": "0.08", "wpb": "356559", "bsz": "1789", "num_updates": "64800", "lr": "0.000455435", "gnorm": "1.564", "loss_scale": "0.0156", "train_wall": "1901", "gb_free": "40.1", "wall": "79968"}
[2024-10-08 17:03:10,018][train_inner][INFO] - {"epoch": 136, "update": 135.76, "loss": "2.332", "ntokens": "358492", "nsentences": "1766.93", "wps": "54694.4", "ups": "0.15", "wpb": "358492", "bsz": "1766.9", "num_updates": "65000", "lr": "0.000455163", "gnorm": "1.59", "loss_scale": "0.0312", "train_wall": "1296", "gb_free": "39.2", "wall": "81285"}
[2024-10-08 17:03:10,814][train_inner][INFO] - {"epoch": 136, "update": 135.762, "loss": "2.333", "ntokens": "358493", "nsentences": "1765.92", "wps": "54666.1", "ups": "0.15", "wpb": "358493", "bsz": "1765.9", "num_updates": "65000", "lr": "0.000455163", "gnorm": "1.736", "loss_scale": "0.0156", "train_wall": "1298", "gb_free": "39.8", "wall": "81280"}
[2024-10-08 17:21:34,302][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-10-08 17:21:34,333][train][INFO] - {"epoch": 136, "train_loss": "2.322", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "35678.8", "train_ups": "0.1", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "65114", "train_lr": "0.000455008", "train_gnorm": "1.609", "train_loss_scale": "0.0312", "train_train_wall": "4189", "train_gb_free": "40.1", "train_wall": "82384"}
[2024-10-08 17:21:34,700][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 17:21:34,768][fairseq.trainer][INFO] - begin training epoch 137
[2024-10-08 17:21:34,768][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:21:57,188][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-10-08 17:21:57,193][train][INFO] - {"epoch": 136, "train_loss": "2.321", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "35669.8", "train_ups": "0.1", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "65115", "train_lr": "0.000455007", "train_gnorm": "1.613", "train_loss_scale": "0.0312", "train_train_wall": "4210", "train_gb_free": "40.1", "train_wall": "82412"}
[2024-10-08 17:21:57,260][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 17:21:57,263][fairseq.trainer][INFO] - begin training epoch 137
[2024-10-08 17:21:57,263][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:34:50,587][train_inner][INFO] - {"epoch": 137, "update": 136.177, "loss": "2.321", "ntokens": "356798", "nsentences": "1743.31", "wps": "37549.3", "ups": "0.11", "wpb": "356798", "bsz": "1743.3", "num_updates": "65200", "lr": "0.000454891", "gnorm": "1.496", "loss_scale": "0.0312", "train_wall": "1398", "gb_free": "39.4", "wall": "83186"}
[2024-10-08 17:34:50,993][train_inner][INFO] - {"epoch": 137, "update": 136.18, "loss": "2.322", "ntokens": "356801", "nsentences": "1742.6", "wps": "37554.5", "ups": "0.11", "wpb": "356801", "bsz": "1742.6", "num_updates": "65200", "lr": "0.000454891", "gnorm": "1.615", "loss_scale": "0.0312", "train_wall": "1402", "gb_free": "39.2", "wall": "83180"}
[2024-10-08 17:45:13,915][train_inner][INFO] - {"epoch": 137, "update": 136.597, "loss": "2.319", "ntokens": "358250", "nsentences": "1757.46", "wps": "115028", "ups": "0.32", "wpb": "358250", "bsz": "1757.5", "num_updates": "65400", "lr": "0.00045462", "gnorm": "1.586", "loss_scale": "0.0312", "train_wall": "608", "gb_free": "39.8", "wall": "83803"}
[2024-10-08 17:45:19,447][train_inner][INFO] - {"epoch": 137, "update": 136.595, "loss": "2.319", "ntokens": "358246", "nsentences": "1753.88", "wps": "113949", "ups": "0.32", "wpb": "358246", "bsz": "1753.9", "num_updates": "65400", "lr": "0.00045462", "gnorm": "1.486", "loss_scale": "0.0312", "train_wall": "624", "gb_free": "39.6", "wall": "83815"}
[2024-10-08 18:01:42,107][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-10-08 18:01:42,120][train][INFO] - {"epoch": 137, "train_loss": "2.323", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "71155.3", "train_ups": "0.2", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "65593", "train_lr": "0.000454357", "train_gnorm": "1.632", "train_loss_scale": "0.0312", "train_train_wall": "1765", "train_gb_free": "41.3", "train_wall": "84791"}
[2024-10-08 18:01:44,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:01:44,046][fairseq.trainer][INFO] - begin training epoch 138
[2024-10-08 18:01:44,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:02:09,309][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-10-08 18:02:09,312][train][INFO] - {"epoch": 137, "train_loss": "2.323", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "71027.2", "train_ups": "0.2", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "65594", "train_lr": "0.000454356", "train_gnorm": "1.556", "train_loss_scale": "0.0312", "train_train_wall": "1788", "train_gb_free": "41.3", "train_wall": "84824"}
[2024-10-08 18:02:09,371][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:02:09,374][fairseq.trainer][INFO] - begin training epoch 138
[2024-10-08 18:02:09,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:12:28,430][train_inner][INFO] - {"epoch": 138, "update": 137.013, "loss": "2.327", "ntokens": "356853", "nsentences": "1733.17", "wps": "43813.5", "ups": "0.12", "wpb": "356853", "bsz": "1733.2", "num_updates": "65600", "lr": "0.000454348", "gnorm": "1.637", "loss_scale": "0.0312", "train_wall": "1101", "gb_free": "39.8", "wall": "85444"}
[2024-10-08 18:12:30,382][train_inner][INFO] - {"epoch": 138, "update": 137.015, "loss": "2.327", "ntokens": "356826", "nsentences": "1729.48", "wps": "43609.7", "ups": "0.12", "wpb": "356826", "bsz": "1729.5", "num_updates": "65600", "lr": "0.000454348", "gnorm": "1.576", "loss_scale": "0.0312", "train_wall": "1109", "gb_free": "39.6", "wall": "85440"}
[2024-10-08 18:29:22,122][train_inner][INFO] - {"epoch": 138, "update": 137.43, "loss": "2.309", "ntokens": "358316", "nsentences": "1728.91", "wps": "70699", "ups": "0.2", "wpb": "358316", "bsz": "1728.9", "num_updates": "65800", "lr": "0.000454076", "gnorm": "1.523", "loss_scale": "0.0312", "train_wall": "942", "gb_free": "39.3", "wall": "86457"}
[2024-10-08 18:29:24,573][train_inner][INFO] - {"epoch": 138, "update": 137.432, "loss": "2.309", "ntokens": "358334", "nsentences": "1732.4", "wps": "70665", "ups": "0.2", "wpb": "358334", "bsz": "1732.4", "num_updates": "65800", "lr": "0.000454076", "gnorm": "1.472", "loss_scale": "0.0312", "train_wall": "941", "gb_free": "39.6", "wall": "86454"}
[2024-10-08 18:43:14,335][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
[2024-10-08 18:52:40,547][train_inner][INFO] - {"epoch": 138, "update": 137.848, "loss": "2.326", "ntokens": "358461", "nsentences": "1787.85", "wps": "51269.2", "ups": "0.14", "wpb": "358461", "bsz": "1787.8", "num_updates": "66000", "lr": "0.000453804", "gnorm": "1.452", "loss_scale": "0.0625", "train_wall": "1176", "gb_free": "40.1", "wall": "87856"}
[2024-10-08 18:52:42,459][train_inner][INFO] - {"epoch": 138, "update": 137.852, "loss": "2.338", "ntokens": "358461", "nsentences": "1786.46", "wps": "51286.7", "ups": "0.14", "wpb": "358461", "bsz": "1786.5", "num_updates": "66000", "lr": "0.000453804", "gnorm": "2.087", "loss_scale": "0.0156", "train_wall": "1162", "gb_free": "40.6", "wall": "87852"}
[2024-10-08 18:58:50,877][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-10-08 18:58:50,901][train][INFO] - {"epoch": 138, "train_loss": "2.323", "train_ntokens": "357672", "train_nsentences": "1753.8", "train_wps": "49862.6", "train_ups": "0.14", "train_wpb": "357672", "train_bsz": "1753.8", "train_num_updates": "66071", "train_lr": "0.000453708", "train_gnorm": "1.727", "train_loss_scale": "0.0156", "train_train_wall": "2723", "train_gb_free": "39.3", "train_wall": "88220"}
[2024-10-08 18:58:53,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:58:53,434][fairseq.trainer][INFO] - begin training epoch 139
[2024-10-08 18:58:53,434][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:58:59,528][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-10-08 18:58:59,531][train][INFO] - {"epoch": 138, "train_loss": "2.318", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "50239", "train_ups": "0.14", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "66073", "train_lr": "0.000453705", "train_gnorm": "1.516", "train_loss_scale": "0.0625", "train_train_wall": "2705", "train_gb_free": "39.3", "train_wall": "88235"}
[2024-10-08 18:58:59,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:58:59,616][fairseq.trainer][INFO] - begin training epoch 139
[2024-10-08 18:58:59,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:24:39,397][train_inner][INFO] - {"epoch": 139, "update": 138.265, "loss": "2.31", "ntokens": "356656", "nsentences": "1712.45", "wps": "37175.7", "ups": "0.1", "wpb": "356656", "bsz": "1712.5", "num_updates": "66200", "lr": "0.000453533", "gnorm": "1.616", "loss_scale": "0.0625", "train_wall": "1337", "gb_free": "39.4", "wall": "89775"}
[2024-10-08 19:24:40,923][train_inner][INFO] - {"epoch": 139, "update": 138.269, "loss": "2.307", "ntokens": "356658", "nsentences": "1712.47", "wps": "37181.8", "ups": "0.1", "wpb": "356658", "bsz": "1712.5", "num_updates": "66200", "lr": "0.000453533", "gnorm": "1.48", "loss_scale": "0.0156", "train_wall": "1319", "gb_free": "39.2", "wall": "89770"}
[2024-10-08 19:55:33,349][train_inner][INFO] - {"epoch": 139, "update": 138.683, "loss": "2.313", "ntokens": "358329", "nsentences": "1763.66", "wps": "38658.2", "ups": "0.11", "wpb": "358329", "bsz": "1763.7", "num_updates": "66400", "lr": "0.000453261", "gnorm": "1.525", "loss_scale": "0.0625", "train_wall": "1852", "gb_free": "39.6", "wall": "91628"}
[2024-10-08 19:55:38,896][train_inner][INFO] - {"epoch": 139, "update": 138.687, "loss": "2.312", "ntokens": "358324", "nsentences": "1764.91", "wps": "38571.9", "ups": "0.11", "wpb": "358324", "bsz": "1764.9", "num_updates": "66400", "lr": "0.000453261", "gnorm": "1.613", "loss_scale": "0.0156", "train_wall": "1855", "gb_free": "39.6", "wall": "91628"}
[2024-10-08 20:13:53,096][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-10-08 20:13:53,113][train][INFO] - {"epoch": 139, "train_loss": "2.315", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "38053.8", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "66550", "train_lr": "0.000453057", "train_gnorm": "1.655", "train_loss_scale": "0.0156", "train_train_wall": "3897", "train_gb_free": "40.1", "train_wall": "92722"}
[2024-10-08 20:13:53,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:13:53,877][fairseq.trainer][INFO] - begin training epoch 140
[2024-10-08 20:13:53,877][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:13:55,166][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-10-08 20:13:55,171][train][INFO] - {"epoch": 139, "train_loss": "2.314", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "38109.4", "train_ups": "0.11", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "66552", "train_lr": "0.000453054", "train_gnorm": "1.584", "train_loss_scale": "0.0625", "train_train_wall": "3907", "train_gb_free": "40.1", "train_wall": "92730"}
[2024-10-08 20:13:55,351][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:13:55,353][fairseq.trainer][INFO] - begin training epoch 140
[2024-10-08 20:13:55,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:29:49,192][train_inner][INFO] - {"epoch": 140, "update": 139.1, "loss": "2.323", "ntokens": "356757", "nsentences": "1800.26", "wps": "34708", "ups": "0.1", "wpb": "356757", "bsz": "1800.3", "num_updates": "66600", "lr": "0.000452989", "gnorm": "1.555", "loss_scale": "0.0625", "train_wall": "1358", "gb_free": "39.2", "wall": "93684"}
[2024-10-08 20:29:50,018][train_inner][INFO] - {"epoch": 140, "update": 139.104, "loss": "2.327", "ntokens": "356762", "nsentences": "1796.39", "wps": "34787.1", "ups": "0.1", "wpb": "356762", "bsz": "1796.4", "num_updates": "66600", "lr": "0.000452989", "gnorm": "1.742", "loss_scale": "0.0156", "train_wall": "1353", "gb_free": "39.6", "wall": "93679"}
[2024-10-08 20:48:03,369][train_inner][INFO] - {"epoch": 140, "update": 139.518, "loss": "2.31", "ntokens": "358403", "nsentences": "1708.93", "wps": "65512.4", "ups": "0.18", "wpb": "358403", "bsz": "1708.9", "num_updates": "66800", "lr": "0.000452717", "gnorm": "1.543", "loss_scale": "0.0625", "train_wall": "817", "gb_free": "39.2", "wall": "94779"}
[2024-10-08 20:48:49,690][train_inner][INFO] - {"epoch": 140, "update": 139.522, "loss": "2.305", "ntokens": "358388", "nsentences": "1716.52", "wps": "62894.2", "ups": "0.18", "wpb": "358388", "bsz": "1716.5", "num_updates": "66800", "lr": "0.000452717", "gnorm": "1.507", "loss_scale": "0.0156", "train_wall": "852", "gb_free": "39.3", "wall": "94819"}
[2024-10-08 21:12:51,104][train_inner][INFO] - {"epoch": 140, "update": 139.935, "loss": "2.32", "ntokens": "358254", "nsentences": "1790.05", "wps": "48161.9", "ups": "0.13", "wpb": "358254", "bsz": "1790", "num_updates": "67000", "lr": "0.000452446", "gnorm": "1.589", "loss_scale": "0.0625", "train_wall": "1432", "gb_free": "39.6", "wall": "96266"}
[2024-10-08 21:12:51,327][train_inner][INFO] - {"epoch": 140, "update": 139.939, "loss": "2.322", "ntokens": "358267", "nsentences": "1788.27", "wps": "49703.6", "ups": "0.14", "wpb": "358267", "bsz": "1788.3", "num_updates": "67000", "lr": "0.000452446", "gnorm": "1.633", "loss_scale": "0.0156", "train_wall": "1392", "gb_free": "39.6", "wall": "96260"}
[2024-10-08 21:14:39,002][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 67029 updates
[2024-10-08 21:14:39,003][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 21:14:42,910][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 21:14:42,914][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 140 @ 67029 updates, score None) (writing took 3.911920629441738 seconds)
[2024-10-08 21:14:42,914][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-10-08 21:14:42,932][train][INFO] - {"epoch": 140, "train_loss": "2.314", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "46941.1", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67029", "train_lr": "0.000452406", "train_gnorm": "1.546", "train_loss_scale": "0.0156", "train_train_wall": "2614", "train_gb_free": "39.6", "train_wall": "96372"}
[2024-10-08 21:14:43,209][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:14:43,231][fairseq.trainer][INFO] - begin training epoch 141
[2024-10-08 21:14:43,232][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:14:56,483][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 67031 updates
[2024-10-08 21:14:56,484][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 21:14:59,612][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-08 21:14:59,615][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 140 @ 67031 updates, score None) (writing took 3.1319267693907022 seconds)
[2024-10-08 21:14:59,616][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-10-08 21:14:59,622][train][INFO] - {"epoch": 140, "train_loss": "2.315", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "46753.6", "train_ups": "0.13", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67031", "train_lr": "0.000452404", "train_gnorm": "1.53", "train_loss_scale": "0.0625", "train_train_wall": "2634", "train_gb_free": "39.6", "train_wall": "96395"}
[2024-10-08 21:14:59,677][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:14:59,683][fairseq.trainer][INFO] - begin training epoch 141
[2024-10-08 21:14:59,683][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:30:27,565][train_inner][INFO] - {"epoch": 141, "update": 140.353, "loss": "2.302", "ntokens": "356811", "nsentences": "1733.01", "wps": "67549.9", "ups": "0.19", "wpb": "356811", "bsz": "1733", "num_updates": "67200", "lr": "0.000452174", "gnorm": "1.497", "loss_scale": "0.0625", "train_wall": "634", "gb_free": "40.1", "wall": "97323"}
[2024-10-08 21:30:28,651][train_inner][INFO] - {"epoch": 141, "update": 140.357, "loss": "2.301", "ntokens": "356809", "nsentences": "1730.15", "wps": "67493.8", "ups": "0.19", "wpb": "356809", "bsz": "1730.2", "num_updates": "67200", "lr": "0.000452174", "gnorm": "1.509", "loss_scale": "0.0156", "train_wall": "647", "gb_free": "39.3", "wall": "97318"}
[2024-10-08 21:41:01,383][train_inner][INFO] - {"epoch": 141, "update": 140.775, "loss": "2.311", "ntokens": "358285", "nsentences": "1757.93", "wps": "113253", "ups": "0.32", "wpb": "358285", "bsz": "1757.9", "num_updates": "67400", "lr": "0.000451902", "gnorm": "1.658", "loss_scale": "0.0156", "train_wall": "629", "gb_free": "40.1", "wall": "97951"}
[2024-10-08 21:41:11,968][train_inner][INFO] - {"epoch": 141, "update": 140.77, "loss": "2.308", "ntokens": "358274", "nsentences": "1757.02", "wps": "111216", "ups": "0.31", "wpb": "358274", "bsz": "1757", "num_updates": "67400", "lr": "0.000451902", "gnorm": "1.534", "loss_scale": "0.0625", "train_wall": "637", "gb_free": "40.1", "wall": "97967"}
[2024-10-08 21:48:02,494][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-10-08 21:48:02,498][train][INFO] - {"epoch": 141, "train_loss": "2.309", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "85681.6", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67508", "train_lr": "0.000451755", "train_gnorm": "1.568", "train_loss_scale": "0.0156", "train_train_wall": "1537", "train_gb_free": "39.7", "train_wall": "98372"}
[2024-10-08 21:48:03,315][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:48:03,350][fairseq.trainer][INFO] - begin training epoch 142
[2024-10-08 21:48:03,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:48:26,212][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-10-08 21:48:26,223][train][INFO] - {"epoch": 141, "train_loss": "2.308", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "85381.8", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67510", "train_lr": "0.000451753", "train_gnorm": "1.574", "train_loss_scale": "0.0625", "train_train_wall": "1526", "train_gb_free": "39.7", "train_wall": "98401"}
[2024-10-08 21:48:26,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:48:26,613][fairseq.trainer][INFO] - begin training epoch 142
[2024-10-08 21:48:26,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:59:02,697][train_inner][INFO] - {"epoch": 142, "update": 141.192, "loss": "2.305", "ntokens": "356607", "nsentences": "1737.9", "wps": "65958.7", "ups": "0.18", "wpb": "356607", "bsz": "1737.9", "num_updates": "67600", "lr": "0.00045163", "gnorm": "1.371", "loss_scale": "0.0156", "train_wall": "612", "gb_free": "39.9", "wall": "99032"}
[2024-10-08 21:59:21,480][train_inner][INFO] - {"epoch": 142, "update": 141.188, "loss": "2.307", "ntokens": "356610", "nsentences": "1738.89", "wps": "65464.3", "ups": "0.18", "wpb": "356610", "bsz": "1738.9", "num_updates": "67600", "lr": "0.00045163", "gnorm": "1.537", "loss_scale": "0.0625", "train_wall": "607", "gb_free": "39.6", "wall": "99057"}
[2024-10-08 22:07:40,439][train_inner][INFO] - {"epoch": 142, "update": 141.61, "loss": "2.309", "ntokens": "358411", "nsentences": "1799.18", "wps": "138456", "ups": "0.39", "wpb": "358411", "bsz": "1799.2", "num_updates": "67800", "lr": "0.000451359", "gnorm": "1.619", "loss_scale": "0.0156", "train_wall": "514", "gb_free": "39.7", "wall": "99550"}
[2024-10-08 22:08:37,833][train_inner][INFO] - {"epoch": 142, "update": 141.605, "loss": "2.31", "ntokens": "358417", "nsentences": "1800.62", "wps": "128853", "ups": "0.36", "wpb": "358417", "bsz": "1800.6", "num_updates": "67800", "lr": "0.000451359", "gnorm": "1.6", "loss_scale": "0.0625", "train_wall": "548", "gb_free": "39.4", "wall": "99613"}
[2024-10-08 22:18:27,874][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-10-08 22:18:27,903][train][INFO] - {"epoch": 142, "train_loss": "2.307", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "93856.6", "train_ups": "0.26", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67987", "train_lr": "0.000451105", "train_gnorm": "1.547", "train_loss_scale": "0.0312", "train_train_wall": "1354", "train_gb_free": "40.1", "train_wall": "100197"}
[2024-10-08 22:18:28,766][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:18:28,827][fairseq.trainer][INFO] - begin training epoch 143
[2024-10-08 22:18:28,828][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:19:03,391][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-10-08 22:19:03,415][train][INFO] - {"epoch": 142, "train_loss": "2.307", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "93255.4", "train_ups": "0.26", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "67989", "train_lr": "0.000451102", "train_gnorm": "1.534", "train_loss_scale": "0.0625", "train_train_wall": "1390", "train_gb_free": "40.1", "train_wall": "100239"}
[2024-10-08 22:19:03,515][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:19:03,520][fairseq.trainer][INFO] - begin training epoch 143
[2024-10-08 22:19:03,521][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:25:50,629][train_inner][INFO] - {"epoch": 143, "update": 142.023, "loss": "2.31", "ntokens": "356831", "nsentences": "1710.68", "wps": "69104.2", "ups": "0.19", "wpb": "356831", "bsz": "1710.7", "num_updates": "68000", "lr": "0.000451087", "gnorm": "1.565", "loss_scale": "0.0625", "train_wall": "638", "gb_free": "39.6", "wall": "100646"}
[2024-10-08 22:26:12,079][train_inner][INFO] - {"epoch": 143, "update": 142.027, "loss": "2.312", "ntokens": "356841", "nsentences": "1715.45", "wps": "64202.7", "ups": "0.18", "wpb": "356841", "bsz": "1715.5", "num_updates": "68000", "lr": "0.000451087", "gnorm": "1.605", "loss_scale": "0.0312", "train_wall": "686", "gb_free": "40.1", "wall": "100661"}
[2024-10-08 22:34:44,288][train_inner][INFO] - {"epoch": 143, "update": 142.445, "loss": "2.307", "ntokens": "358340", "nsentences": "1811.54", "wps": "139923", "ups": "0.39", "wpb": "358340", "bsz": "1811.5", "num_updates": "68200", "lr": "0.000450815", "gnorm": "1.55", "loss_scale": "0.0312", "train_wall": "484", "gb_free": "41", "wall": "101173"}
[2024-10-08 22:35:15,458][train_inner][INFO] - {"epoch": 143, "update": 142.441, "loss": "2.305", "ntokens": "358355", "nsentences": "1811.68", "wps": "126896", "ups": "0.35", "wpb": "358355", "bsz": "1811.7", "num_updates": "68200", "lr": "0.000450815", "gnorm": "1.458", "loss_scale": "0.125", "train_wall": "558", "gb_free": "39.3", "wall": "101211"}
[2024-10-08 22:48:36,451][train_inner][INFO] - {"epoch": 143, "update": 142.858, "loss": "2.306", "ntokens": "358270", "nsentences": "1723.26", "wps": "89458.8", "ups": "0.25", "wpb": "358270", "bsz": "1723.3", "num_updates": "68400", "lr": "0.000450543", "gnorm": "1.497", "loss_scale": "0.125", "train_wall": "724", "gb_free": "39.7", "wall": "102012"}
[2024-10-08 22:48:44,389][train_inner][INFO] - {"epoch": 143, "update": 142.862, "loss": "2.306", "ntokens": "358280", "nsentences": "1718.47", "wps": "85300", "ups": "0.24", "wpb": "358280", "bsz": "1718.5", "num_updates": "68400", "lr": "0.000450543", "gnorm": "1.546", "loss_scale": "0.0312", "train_wall": "741", "gb_free": "39.8", "wall": "102014"}
[2024-10-08 22:52:15,216][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-10-08 22:52:15,221][train][INFO] - {"epoch": 143, "train_loss": "2.307", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "84508.8", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "68466", "train_lr": "0.000450454", "train_gnorm": "1.533", "train_loss_scale": "0.0312", "train_train_wall": "1524", "train_gb_free": "39.6", "train_wall": "102224"}
[2024-10-08 22:52:15,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:52:15,303][fairseq.trainer][INFO] - begin training epoch 144
[2024-10-08 22:52:15,303][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:52:26,043][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-10-08 22:52:26,055][train][INFO] - {"epoch": 143, "train_loss": "2.306", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "85550.6", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "68468", "train_lr": "0.000450451", "train_gnorm": "1.511", "train_loss_scale": "0.125", "train_train_wall": "1529", "train_gb_free": "39.6", "train_wall": "102241"}
[2024-10-08 22:52:26,152][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:52:26,157][fairseq.trainer][INFO] - begin training epoch 144
[2024-10-08 22:52:26,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:04:44,210][train_inner][INFO] - {"epoch": 144, "update": 143.276, "loss": "2.297", "ntokens": "356686", "nsentences": "1722.17", "wps": "73717.2", "ups": "0.21", "wpb": "356686", "bsz": "1722.2", "num_updates": "68600", "lr": "0.000450272", "gnorm": "1.456", "loss_scale": "0.125", "train_wall": "544", "gb_free": "39.3", "wall": "102979"}
[2024-10-08 23:04:45,147][train_inner][INFO] - {"epoch": 144, "update": 143.28, "loss": "2.297", "ntokens": "356685", "nsentences": "1725.56", "wps": "74251.1", "ups": "0.21", "wpb": "356685", "bsz": "1725.6", "num_updates": "68600", "lr": "0.000450272", "gnorm": "1.365", "loss_scale": "0.0312", "train_wall": "556", "gb_free": "39.8", "wall": "102974"}
[2024-10-08 23:11:04,021][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-08 23:17:15,062][train_inner][INFO] - {"epoch": 144, "update": 143.697, "loss": "2.308", "ntokens": "358360", "nsentences": "1750.49", "wps": "95575.1", "ups": "0.27", "wpb": "358360", "bsz": "1750.5", "num_updates": "68800", "lr": "0.00045", "gnorm": "1.556", "loss_scale": "0.0312", "train_wall": "741", "gb_free": "40.1", "wall": "103724"}
[2024-10-08 23:17:23,045][train_inner][INFO] - {"epoch": 144, "update": 143.695, "loss": "2.304", "ntokens": "358368", "nsentences": "1745.7", "wps": "94458.5", "ups": "0.26", "wpb": "358368", "bsz": "1745.7", "num_updates": "68800", "lr": "0.00045", "gnorm": "1.623", "loss_scale": "0.0625", "train_wall": "746", "gb_free": "39.6", "wall": "103738"}
[2024-10-08 23:25:24,585][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-10-08 23:25:24,591][train][INFO] - {"epoch": 144, "train_loss": "2.308", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "86120.9", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "68945", "train_lr": "0.000449803", "train_gnorm": "1.526", "train_loss_scale": "0.0312", "train_train_wall": "1540", "train_gb_free": "39.3", "train_wall": "104214"}
[2024-10-08 23:25:24,764][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:25:24,789][fairseq.trainer][INFO] - begin training epoch 145
[2024-10-08 23:25:24,790][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:25:27,753][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-10-08 23:25:27,760][train][INFO] - {"epoch": 144, "train_loss": "2.304", "train_ntokens": "357672", "train_nsentences": "1753.16", "train_wps": "86273.1", "train_ups": "0.24", "train_wpb": "357672", "train_bsz": "1753.2", "train_num_updates": "68946", "train_lr": "0.000449802", "train_gnorm": "1.498", "train_loss_scale": "0.0625", "train_train_wall": "1543", "train_gb_free": "39.3", "train_wall": "104223"}
[2024-10-08 23:25:27,843][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:25:27,848][fairseq.trainer][INFO] - begin training epoch 145
[2024-10-08 23:25:27,850][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:34:14,134][train_inner][INFO] - {"epoch": 145, "update": 144.113, "loss": "2.31", "ntokens": "356867", "nsentences": "1764.12", "wps": "70593.5", "ups": "0.2", "wpb": "356867", "bsz": "1764.1", "num_updates": "69000", "lr": "0.000449728", "gnorm": "1.41", "loss_scale": "0.0625", "train_wall": "619", "gb_free": "40.1", "wall": "104749"}
[2024-10-08 23:34:14,280][train_inner][INFO] - {"epoch": 145, "update": 144.115, "loss": "2.316", "ntokens": "356871", "nsentences": "1756.46", "wps": "70031.2", "ups": "0.2", "wpb": "356871", "bsz": "1756.5", "num_updates": "69000", "lr": "0.000449728", "gnorm": "1.563", "loss_scale": "0.0312", "train_wall": "605", "gb_free": "39.7", "wall": "104743"}
[2024-10-08 23:42:33,711][train_inner][INFO] - {"epoch": 145, "update": 144.532, "loss": "2.296", "ntokens": "358436", "nsentences": "1730.36", "wps": "143539", "ups": "0.4", "wpb": "358436", "bsz": "1730.4", "num_updates": "69200", "lr": "0.000449457", "gnorm": "1.465", "loss_scale": "0.0312", "train_wall": "454", "gb_free": "40.1", "wall": "105243"}
[2024-10-08 23:42:44,398][train_inner][INFO] - {"epoch": 145, "update": 144.53, "loss": "2.296", "ntokens": "358430", "nsentences": "1726.77", "wps": "140496", "ups": "0.39", "wpb": "358430", "bsz": "1726.8", "num_updates": "69200", "lr": "0.000449457", "gnorm": "1.594", "loss_scale": "0.0625", "train_wall": "463", "gb_free": "39.7", "wall": "105260"}
[2024-10-08 23:54:13,007][train_inner][INFO] - {"epoch": 145, "update": 144.95, "loss": "2.318", "ntokens": "358255", "nsentences": "1817.09", "wps": "102468", "ups": "0.29", "wpb": "358255", "bsz": "1817.1", "num_updates": "69400", "lr": "0.000449185", "gnorm": "1.534", "loss_scale": "0.0312", "train_wall": "610", "gb_free": "39.7", "wall": "105942"}
[2024-10-08 23:54:14,855][train_inner][INFO] - {"epoch": 145, "update": 144.948, "loss": "2.316", "ntokens": "358253", "nsentences": "1817.09", "wps": "103774", "ups": "0.29", "wpb": "358253", "bsz": "1817.1", "num_updates": "69400", "lr": "0.000449185", "gnorm": "1.427", "loss_scale": "0.0625", "train_wall": "595", "gb_free": "39.6", "wall": "105950"}
[2024-10-08 23:55:37,370][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-10-08 23:55:37,389][train][INFO] - {"epoch": 145, "train_loss": "2.304", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "94509.7", "train_ups": "0.26", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "69424", "train_lr": "0.000449152", "train_gnorm": "1.497", "train_loss_scale": "0.0312", "train_train_wall": "1298", "train_gb_free": "39.8", "train_wall": "106027"}
[2024-10-08 23:55:37,494][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:55:37,498][fairseq.trainer][INFO] - begin training epoch 146
[2024-10-08 23:55:37,498][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:55:44,974][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-10-08 23:55:44,978][train][INFO] - {"epoch": 145, "train_loss": "2.304", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "94279.4", "train_ups": "0.26", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "69425", "train_lr": "0.000449151", "train_gnorm": "1.459", "train_loss_scale": "0.0625", "train_train_wall": "1285", "train_gb_free": "39.8", "train_wall": "106040"}
[2024-10-08 23:55:45,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:55:45,069][fairseq.trainer][INFO] - begin training epoch 146
[2024-10-08 23:55:45,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:09:05,935][train_inner][INFO] - {"epoch": 146, "update": 145.367, "loss": "2.296", "ntokens": "356753", "nsentences": "1727.96", "wps": "79907.4", "ups": "0.22", "wpb": "356753", "bsz": "1728", "num_updates": "69600", "lr": "0.000448913", "gnorm": "1.774", "loss_scale": "0.0312", "train_wall": "472", "gb_free": "40.1", "wall": "106835"}
[2024-10-09 00:09:11,149][train_inner][INFO] - {"epoch": 146, "update": 145.365, "loss": "2.29", "ntokens": "356754", "nsentences": "1728.34", "wps": "79606.7", "ups": "0.22", "wpb": "356754", "bsz": "1728.3", "num_updates": "69600", "lr": "0.000448913", "gnorm": "1.448", "loss_scale": "0.0625", "train_wall": "543", "gb_free": "39.2", "wall": "106846"}
[2024-10-09 00:21:16,073][train_inner][INFO] - {"epoch": 146, "update": 145.785, "loss": "2.303", "ntokens": "358394", "nsentences": "1762.21", "wps": "98177.8", "ups": "0.27", "wpb": "358394", "bsz": "1762.2", "num_updates": "69800", "lr": "0.000448641", "gnorm": "1.491", "loss_scale": "0.0312", "train_wall": "635", "gb_free": "40.3", "wall": "107565"}
[2024-10-09 00:21:17,111][train_inner][INFO] - {"epoch": 146, "update": 145.783, "loss": "2.303", "ntokens": "358391", "nsentences": "1760.18", "wps": "98736.6", "ups": "0.28", "wpb": "358391", "bsz": "1760.2", "num_updates": "69800", "lr": "0.000448641", "gnorm": "1.553", "loss_scale": "0.0625", "train_wall": "627", "gb_free": "40.1", "wall": "107572"}
[2024-10-09 00:28:22,636][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-10-09 00:28:22,657][train][INFO] - {"epoch": 146, "train_loss": "2.302", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "87177.4", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "69903", "train_lr": "0.000448501", "train_gnorm": "1.624", "train_loss_scale": "0.0312", "train_train_wall": "1409", "train_gb_free": "39.6", "train_wall": "107992"}
[2024-10-09 00:28:25,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:28:25,127][fairseq.trainer][INFO] - begin training epoch 147
[2024-10-09 00:28:25,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:28:26,945][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-10-09 00:28:26,996][train][INFO] - {"epoch": 146, "train_loss": "2.299", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "87321.3", "train_ups": "0.24", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "69904", "train_lr": "0.0004485", "train_gnorm": "1.561", "train_loss_scale": "0.0625", "train_train_wall": "1463", "train_gb_free": "39.6", "train_wall": "108002"}
[2024-10-09 00:28:28,137][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:28:28,212][fairseq.trainer][INFO] - begin training epoch 147
[2024-10-09 00:28:28,212][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:38:39,581][train_inner][INFO] - {"epoch": 147, "update": 146.2, "loss": "2.301", "ntokens": "356698", "nsentences": "1735.76", "wps": "68433.9", "ups": "0.19", "wpb": "356698", "bsz": "1735.8", "num_updates": "70000", "lr": "0.00044837", "gnorm": "1.727", "loss_scale": "0.0625", "train_wall": "597", "gb_free": "39.1", "wall": "108615"}
[2024-10-09 00:38:41,243][train_inner][INFO] - {"epoch": 147, "update": 146.203, "loss": "2.302", "ntokens": "356696", "nsentences": "1737.51", "wps": "68261.5", "ups": "0.19", "wpb": "356696", "bsz": "1737.5", "num_updates": "70000", "lr": "0.00044837", "gnorm": "1.692", "loss_scale": "0.0312", "train_wall": "597", "gb_free": "40.1", "wall": "108610"}
[2024-10-09 00:47:31,399][train_inner][INFO] - {"epoch": 147, "update": 146.62, "loss": "2.3", "ntokens": "358368", "nsentences": "1785.4", "wps": "135196", "ups": "0.38", "wpb": "358368", "bsz": "1785.4", "num_updates": "70200", "lr": "0.000448098", "gnorm": "1.498", "loss_scale": "0.0625", "train_wall": "526", "gb_free": "40.1", "wall": "109141"}
[2024-10-09 00:48:01,486][train_inner][INFO] - {"epoch": 147, "update": 146.618, "loss": "2.299", "ntokens": "358366", "nsentences": "1788.78", "wps": "127562", "ups": "0.36", "wpb": "358366", "bsz": "1788.8", "num_updates": "70200", "lr": "0.000448098", "gnorm": "1.595", "loss_scale": "0.0625", "train_wall": "555", "gb_free": "40.1", "wall": "109177"}
[2024-10-09 00:57:45,603][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-10-09 00:57:45,616][train][INFO] - {"epoch": 147, "train_loss": "2.299", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "97181.5", "train_ups": "0.27", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "70382", "train_lr": "0.000447851", "train_gnorm": "1.52", "train_loss_scale": "0.0625", "train_train_wall": "1251", "train_gb_free": "39.6", "train_wall": "109755"}
[2024-10-09 00:57:45,921][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-10-09 00:57:45,939][train][INFO] - {"epoch": 147, "train_loss": "2.298", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "97403.4", "train_ups": "0.27", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "70383", "train_lr": "0.000447849", "train_gnorm": "1.601", "train_loss_scale": "0.0625", "train_train_wall": "1325", "train_gb_free": "39.6", "train_wall": "109761"}
[2024-10-09 00:57:47,862][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:57:47,873][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:57:47,900][fairseq.trainer][INFO] - begin training epoch 148
[2024-10-09 00:57:47,901][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:57:47,932][fairseq.trainer][INFO] - begin training epoch 148
[2024-10-09 00:57:47,939][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:05:22,502][train_inner][INFO] - {"epoch": 148, "update": 147.038, "loss": "2.3", "ntokens": "356662", "nsentences": "1735.54", "wps": "66598.6", "ups": "0.19", "wpb": "356662", "bsz": "1735.5", "num_updates": "70400", "lr": "0.000447826", "gnorm": "1.407", "loss_scale": "0.0625", "train_wall": "563", "gb_free": "39.6", "wall": "110212"}
[2024-10-09 01:05:55,083][train_inner][INFO] - {"epoch": 148, "update": 147.035, "loss": "2.301", "ntokens": "356668", "nsentences": "1738.51", "wps": "66444.8", "ups": "0.19", "wpb": "356668", "bsz": "1738.5", "num_updates": "70400", "lr": "0.000447826", "gnorm": "1.583", "loss_scale": "0.0625", "train_wall": "600", "gb_free": "40.1", "wall": "110250"}
[2024-10-09 01:09:05,157][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 01:13:34,114][train_inner][INFO] - {"epoch": 148, "update": 147.455, "loss": "2.292", "ntokens": "358326", "nsentences": "1745.21", "wps": "145780", "ups": "0.41", "wpb": "358326", "bsz": "1745.2", "num_updates": "70600", "lr": "0.000447554", "gnorm": "1.457", "loss_scale": "0.0625", "train_wall": "487", "gb_free": "39.6", "wall": "110703"}
[2024-10-09 01:14:52,157][train_inner][INFO] - {"epoch": 148, "update": 147.455, "loss": "2.292", "ntokens": "358320", "nsentences": "1737.61", "wps": "133444", "ups": "0.37", "wpb": "358320", "bsz": "1737.6", "num_updates": "70600", "lr": "0.000447554", "gnorm": "1.681", "loss_scale": "0.0312", "train_wall": "529", "gb_free": "39.6", "wall": "110787"}
[2024-10-09 01:24:50,140][train_inner][INFO] - {"epoch": 148, "update": 147.873, "loss": "2.302", "ntokens": "358284", "nsentences": "1792.45", "wps": "106008", "ups": "0.3", "wpb": "358284", "bsz": "1792.5", "num_updates": "70800", "lr": "0.000447283", "gnorm": "1.707", "loss_scale": "0.0625", "train_wall": "672", "gb_free": "39.3", "wall": "111379"}
[2024-10-09 01:24:53,343][train_inner][INFO] - {"epoch": 148, "update": 147.873, "loss": "2.3", "ntokens": "358284", "nsentences": "1792.45", "wps": "119205", "ups": "0.33", "wpb": "358284", "bsz": "1792.5", "num_updates": "70800", "lr": "0.000447283", "gnorm": "1.578", "loss_scale": "0.0312", "train_wall": "593", "gb_free": "39.3", "wall": "111388"}
[2024-10-09 01:27:55,624][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-10-09 01:27:55,636][train][INFO] - {"epoch": 148, "train_loss": "2.296", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "94654.3", "train_ups": "0.26", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "70861", "train_lr": "0.0004472", "train_gnorm": "1.558", "train_loss_scale": "0.0625", "train_train_wall": "1394", "train_gb_free": "39.7", "train_wall": "111565"}
[2024-10-09 01:27:56,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:27:56,959][fairseq.trainer][INFO] - begin training epoch 149
[2024-10-09 01:27:56,960][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:27:59,311][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-10-09 01:27:59,352][train][INFO] - {"epoch": 148, "train_loss": "2.296", "train_ntokens": "357671", "train_nsentences": "1751.81", "train_wps": "94280.1", "train_ups": "0.26", "train_wpb": "357671", "train_bsz": "1751.8", "train_num_updates": "70861", "train_lr": "0.0004472", "train_gnorm": "1.659", "train_loss_scale": "0.0312", "train_train_wall": "1355", "train_gb_free": "39.7", "train_wall": "111574"}
[2024-10-09 01:27:59,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:27:59,751][fairseq.trainer][INFO] - begin training epoch 149
[2024-10-09 01:27:59,751][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:41:14,261][train_inner][INFO] - {"epoch": 149, "update": 148.29, "loss": "2.29", "ntokens": "356726", "nsentences": "1735.29", "wps": "72498.7", "ups": "0.2", "wpb": "356726", "bsz": "1735.3", "num_updates": "71000", "lr": "0.000447011", "gnorm": "1.556", "loss_scale": "0.0625", "train_wall": "606", "gb_free": "39.6", "wall": "112363"}
[2024-10-09 01:41:18,772][train_inner][INFO] - {"epoch": 149, "update": 148.29, "loss": "2.291", "ntokens": "356726", "nsentences": "1735.29", "wps": "72401.9", "ups": "0.2", "wpb": "356726", "bsz": "1735.3", "num_updates": "71000", "lr": "0.000447011", "gnorm": "1.653", "loss_scale": "0.0312", "train_wall": "570", "gb_free": "39.6", "wall": "112374"}
[2024-10-09 01:50:30,385][train_inner][INFO] - {"epoch": 149, "update": 148.708, "loss": "2.292", "ntokens": "358354", "nsentences": "1748.83", "wps": "128880", "ups": "0.36", "wpb": "358354", "bsz": "1748.8", "num_updates": "71200", "lr": "0.000446739", "gnorm": "1.696", "loss_scale": "0.0625", "train_wall": "552", "gb_free": "40.1", "wall": "112920"}
[2024-10-09 01:50:36,337][train_inner][INFO] - {"epoch": 149, "update": 148.708, "loss": "2.29", "ntokens": "358354", "nsentences": "1748.83", "wps": "128547", "ups": "0.36", "wpb": "358354", "bsz": "1748.8", "num_updates": "71200", "lr": "0.000446739", "gnorm": "1.529", "loss_scale": "0.0312", "train_wall": "548", "gb_free": "40.1", "wall": "112931"}
[2024-10-09 02:00:19,884][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-10-09 02:00:19,951][train][INFO] - {"epoch": 149, "train_loss": "2.293", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "88286.4", "train_ups": "0.25", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "71340", "train_lr": "0.000446549", "train_gnorm": "1.523", "train_loss_scale": "0.0312", "train_train_wall": "1461", "train_gb_free": "39.6", "train_wall": "113515"}
[2024-10-09 02:00:20,632][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-10-09 02:00:20,660][train][INFO] - {"epoch": 149, "train_loss": "2.293", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "88084.3", "train_ups": "0.25", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "71340", "train_lr": "0.000446549", "train_gnorm": "1.562", "train_loss_scale": "0.0625", "train_train_wall": "1517", "train_gb_free": "39.6", "train_wall": "113510"}
[2024-10-09 02:00:21,172][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:00:21,213][fairseq.trainer][INFO] - begin training epoch 150
[2024-10-09 02:00:21,214][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:00:21,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:00:21,828][fairseq.trainer][INFO] - begin training epoch 150
[2024-10-09 02:00:21,851][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:12:01,519][train_inner][INFO] - {"epoch": 150, "update": 149.125, "loss": "2.294", "ntokens": "356688", "nsentences": "1755.46", "wps": "55254.4", "ups": "0.15", "wpb": "356688", "bsz": "1755.5", "num_updates": "71400", "lr": "0.000446467", "gnorm": "1.444", "loss_scale": "0.0625", "train_wall": "754", "gb_free": "39.1", "wall": "114211"}
[2024-10-09 02:12:05,041][train_inner][INFO] - {"epoch": 150, "update": 149.125, "loss": "2.294", "ntokens": "356688", "nsentences": "1755.46", "wps": "55356.8", "ups": "0.16", "wpb": "356688", "bsz": "1755.5", "num_updates": "71400", "lr": "0.000446467", "gnorm": "1.42", "loss_scale": "0.0312", "train_wall": "745", "gb_free": "39.1", "wall": "114220"}
[2024-10-09 02:27:06,493][train_inner][INFO] - {"epoch": 150, "update": 149.543, "loss": "2.287", "ntokens": "358309", "nsentences": "1741.49", "wps": "79196.5", "ups": "0.22", "wpb": "358309", "bsz": "1741.5", "num_updates": "71600", "lr": "0.000446196", "gnorm": "1.723", "loss_scale": "0.0625", "train_wall": "631", "gb_free": "39.3", "wall": "115116"}
[2024-10-09 02:27:06,725][train_inner][INFO] - {"epoch": 150, "update": 149.543, "loss": "2.284", "ntokens": "358309", "nsentences": "1741.49", "wps": "79476.1", "ups": "0.22", "wpb": "358309", "bsz": "1741.5", "num_updates": "71600", "lr": "0.000446196", "gnorm": "1.599", "loss_scale": "0.0312", "train_wall": "626", "gb_free": "39.3", "wall": "115122"}
[2024-10-09 02:43:07,531][train_inner][INFO] - {"epoch": 150, "update": 149.96, "loss": "2.298", "ntokens": "358460", "nsentences": "1759.96", "wps": "74605.4", "ups": "0.21", "wpb": "358460", "bsz": "1760", "num_updates": "71800", "lr": "0.000445924", "gnorm": "1.588", "loss_scale": "0.0625", "train_wall": "728", "gb_free": "39", "wall": "116077"}
[2024-10-09 02:43:12,245][train_inner][INFO] - {"epoch": 150, "update": 149.96, "loss": "2.298", "ntokens": "358460", "nsentences": "1759.96", "wps": "74254.3", "ups": "0.21", "wpb": "358460", "bsz": "1760", "num_updates": "71800", "lr": "0.000445924", "gnorm": "1.528", "loss_scale": "0.0312", "train_wall": "750", "gb_free": "39", "wall": "116087"}
[2024-10-09 02:44:50,871][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 71819 updates
[2024-10-09 02:44:50,891][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 02:44:52,607][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 71819 updates
[2024-10-09 02:44:52,608][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 02:44:54,709][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 02:44:54,717][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 150 @ 71819 updates, score None) (writing took 3.8459010906517506 seconds)
[2024-10-09 02:44:54,723][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2024-10-09 02:44:54,729][train][INFO] - {"epoch": 150, "train_loss": "2.291", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "64052.8", "train_ups": "0.18", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "71819", "train_lr": "0.000445898", "train_gnorm": "1.57", "train_loss_scale": "0.0312", "train_train_wall": "1691", "train_gb_free": "39.2", "train_wall": "116190"}
[2024-10-09 02:44:54,863][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:44:54,883][fairseq.trainer][INFO] - begin training epoch 151
[2024-10-09 02:44:54,883][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:07:40,969][train_inner][INFO] - {"epoch": 151, "update": 150.378, "loss": "2.285", "ntokens": "356715", "nsentences": "1755.18", "wps": "48575.1", "ups": "0.14", "wpb": "356714", "bsz": "1755.2", "num_updates": "72000", "lr": "0.000445652", "gnorm": "1.609", "loss_scale": "0.0312", "train_wall": "1066", "gb_free": "40.6", "wall": "117556"}
[2024-10-09 03:27:22,998][train_inner][INFO] - {"epoch": 151, "update": 150.795, "loss": "2.284", "ntokens": "358386", "nsentences": "1749.05", "wps": "60645.9", "ups": "0.17", "wpb": "358386", "bsz": "1749", "num_updates": "72200", "lr": "0.00044538", "gnorm": "1.534", "loss_scale": "0.0312", "train_wall": "1086", "gb_free": "39.8", "wall": "118738"}
[2024-10-09 03:34:09,677][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2024-10-09 03:34:09,817][train][INFO] - {"epoch": 151, "train_loss": "2.286", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "57976.6", "train_ups": "0.16", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "72298", "train_lr": "0.000445247", "train_gnorm": "1.605", "train_loss_scale": "0.0312", "train_train_wall": "2441", "train_gb_free": "39.8", "train_wall": "119145"}
[2024-10-09 03:34:10,020][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:34:10,044][fairseq.trainer][INFO] - begin training epoch 152
[2024-10-09 03:34:10,044][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:42:04,543][train_inner][INFO] - {"epoch": 152, "update": 151.213, "loss": "2.285", "ntokens": "356811", "nsentences": "1762.51", "wps": "80956.9", "ups": "0.23", "wpb": "356811", "bsz": "1762.5", "num_updates": "72400", "lr": "0.000445109", "gnorm": "1.822", "loss_scale": "0.0312", "train_wall": "569", "gb_free": "39.6", "wall": "119620"}
[2024-10-09 03:47:07,890][train_inner][INFO] - {"epoch": 152, "update": 151.63, "loss": "2.281", "ntokens": "358319", "nsentences": "1748.01", "wps": "236276", "ups": "0.66", "wpb": "358319", "bsz": "1748", "num_updates": "72600", "lr": "0.000444837", "gnorm": "1.514", "loss_scale": "0.0625", "train_wall": "271", "gb_free": "39.2", "wall": "119923"}
[2024-10-09 03:50:35,139][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2024-10-09 03:50:35,147][train][INFO] - {"epoch": 152, "train_loss": "2.285", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "173879", "train_ups": "0.49", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "72777", "train_lr": "0.000444596", "train_gnorm": "1.576", "train_loss_scale": "0.0625", "train_train_wall": "644", "train_gb_free": "39.3", "train_wall": "120130"}
[2024-10-09 03:50:35,347][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:50:35,375][fairseq.trainer][INFO] - begin training epoch 153
[2024-10-09 03:50:35,375][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:55:45,155][train_inner][INFO] - {"epoch": 153, "update": 152.048, "loss": "2.294", "ntokens": "356693", "nsentences": "1762.89", "wps": "137929", "ups": "0.39", "wpb": "356692", "bsz": "1762.9", "num_updates": "72800", "lr": "0.000444565", "gnorm": "1.505", "loss_scale": "0.0625", "train_wall": "207", "gb_free": "39.6", "wall": "120440"}
[2024-10-09 04:00:18,106][train_inner][INFO] - {"epoch": 153, "update": 152.466, "loss": "2.281", "ntokens": "358340", "nsentences": "1753.62", "wps": "262658", "ups": "0.73", "wpb": "358340", "bsz": "1753.6", "num_updates": "73000", "lr": "0.000444293", "gnorm": "1.372", "loss_scale": "0.0625", "train_wall": "201", "gb_free": "39.3", "wall": "120713"}
[2024-10-09 04:03:32,958][train_inner][INFO] - {"epoch": 153, "update": 152.883, "loss": "2.289", "ntokens": "358251", "nsentences": "1748.7", "wps": "367726", "ups": "1.03", "wpb": "358251", "bsz": "1748.7", "num_updates": "73200", "lr": "0.000444022", "gnorm": "1.46", "loss_scale": "0.0625", "train_wall": "173", "gb_free": "40.6", "wall": "120908"}
[2024-10-09 04:04:37,613][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2024-10-09 04:04:37,619][train][INFO] - {"epoch": 153, "train_loss": "2.286", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "203362", "train_ups": "0.57", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "73256", "train_lr": "0.000443946", "train_gnorm": "1.411", "train_loss_scale": "0.0625", "train_train_wall": "456", "train_gb_free": "39.2", "train_wall": "120973"}
[2024-10-09 04:04:37,729][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:04:37,732][fairseq.trainer][INFO] - begin training epoch 154
[2024-10-09 04:04:37,732][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:19:34,640][train_inner][INFO] - {"epoch": 154, "update": 153.301, "loss": "2.275", "ntokens": "356877", "nsentences": "1701.01", "wps": "74219.7", "ups": "0.21", "wpb": "356877", "bsz": "1701", "num_updates": "73400", "lr": "0.00044375", "gnorm": "1.349", "loss_scale": "0.0625", "train_wall": "554", "gb_free": "39.6", "wall": "121870"}
[2024-10-09 04:31:34,604][train_inner][INFO] - {"epoch": 154, "update": 153.718, "loss": "2.287", "ntokens": "358256", "nsentences": "1805.08", "wps": "99553.7", "ups": "0.28", "wpb": "358256", "bsz": "1805.1", "num_updates": "73600", "lr": "0.000443478", "gnorm": "1.634", "loss_scale": "0.0625", "train_wall": "682", "gb_free": "39.3", "wall": "122590"}
[2024-10-09 04:36:37,518][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2024-10-09 04:36:37,564][train][INFO] - {"epoch": 154, "train_loss": "2.281", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "89235", "train_ups": "0.25", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "73735", "train_lr": "0.000443295", "train_gnorm": "1.506", "train_loss_scale": "0.0625", "train_train_wall": "1402", "train_gb_free": "40.6", "train_wall": "122893"}
[2024-10-09 04:36:37,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:36:37,975][fairseq.trainer][INFO] - begin training epoch 155
[2024-10-09 04:36:37,976][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:44:12,344][train_inner][INFO] - {"epoch": 155, "update": 154.136, "loss": "2.283", "ntokens": "356898", "nsentences": "1725.83", "wps": "94216.9", "ups": "0.26", "wpb": "356898", "bsz": "1725.8", "num_updates": "73800", "lr": "0.000443207", "gnorm": "1.52", "loss_scale": "0.0625", "train_wall": "356", "gb_free": "39.4", "wall": "123347"}
[2024-10-09 04:51:29,666][train_inner][INFO] - {"epoch": 155, "update": 154.553, "loss": "2.277", "ntokens": "358425", "nsentences": "1777.44", "wps": "163945", "ups": "0.46", "wpb": "358425", "bsz": "1777.4", "num_updates": "74000", "lr": "0.000442935", "gnorm": "1.601", "loss_scale": "0.0625", "train_wall": "414", "gb_free": "39.9", "wall": "123785"}
[2024-10-09 04:55:46,254][train_inner][INFO] - {"epoch": 155, "update": 154.971, "loss": "2.286", "ntokens": "358133", "nsentences": "1756.88", "wps": "279154", "ups": "0.78", "wpb": "358132", "bsz": "1756.9", "num_updates": "74200", "lr": "0.000442663", "gnorm": "1.482", "loss_scale": "0.0625", "train_wall": "254", "gb_free": "39.6", "wall": "124041"}
[2024-10-09 04:56:18,648][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2024-10-09 04:56:18,686][train][INFO] - {"epoch": 155, "train_loss": "2.281", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "145054", "train_ups": "0.41", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "74214", "train_lr": "0.000442644", "train_gnorm": "1.557", "train_loss_scale": "0.0625", "train_train_wall": "826", "train_gb_free": "39.6", "train_wall": "124074"}
[2024-10-09 04:56:18,864][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:56:18,885][fairseq.trainer][INFO] - begin training epoch 156
[2024-10-09 04:56:18,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:04:40,677][train_inner][INFO] - {"epoch": 156, "update": 155.388, "loss": "2.273", "ntokens": "356864", "nsentences": "1749.91", "wps": "133552", "ups": "0.37", "wpb": "356864", "bsz": "1749.9", "num_updates": "74400", "lr": "0.000442391", "gnorm": "1.545", "loss_scale": "0.0625", "train_wall": "257", "gb_free": "39.3", "wall": "124576"}
[2024-10-09 05:07:55,070][train_inner][INFO] - {"epoch": 156, "update": 155.806, "loss": "2.278", "ntokens": "358163", "nsentences": "1773.41", "wps": "368594", "ups": "1.03", "wpb": "358163", "bsz": "1773.4", "num_updates": "74600", "lr": "0.00044212", "gnorm": "1.493", "loss_scale": "0.125", "train_wall": "191", "gb_free": "39.6", "wall": "124770"}
[2024-10-09 05:09:39,402][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2024-10-09 05:09:39,428][train][INFO] - {"epoch": 156, "train_loss": "2.275", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "213960", "train_ups": "0.6", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "74693", "train_lr": "0.000441993", "train_gnorm": "1.473", "train_loss_scale": "0.125", "train_train_wall": "509", "train_gb_free": "39.6", "train_wall": "124875"}
[2024-10-09 05:09:39,572][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:09:39,586][fairseq.trainer][INFO] - begin training epoch 157
[2024-10-09 05:09:39,587][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:15:14,453][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-09 05:16:05,769][train_inner][INFO] - {"epoch": 157, "update": 156.225, "loss": "2.272", "ntokens": "356920", "nsentences": "1730.16", "wps": "145477", "ups": "0.41", "wpb": "356920", "bsz": "1730.2", "num_updates": "74800", "lr": "0.000441848", "gnorm": "1.501", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "40.1", "wall": "125261"}
[2024-10-09 05:17:37,033][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 05:19:15,489][train_inner][INFO] - {"epoch": 157, "update": 156.645, "loss": "2.275", "ntokens": "358440", "nsentences": "1745.96", "wps": "377884", "ups": "1.05", "wpb": "358440", "bsz": "1746", "num_updates": "75000", "lr": "0.000441576", "gnorm": "1.488", "loss_scale": "0.0312", "train_wall": "185", "gb_free": "39.4", "wall": "125451"}
[2024-10-09 05:22:29,366][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2024-10-09 05:22:29,387][train][INFO] - {"epoch": 157, "train_loss": "2.279", "train_ntokens": "357670", "train_nsentences": "1754.23", "train_wps": "221586", "train_ups": "0.62", "train_wpb": "357670", "train_bsz": "1754.2", "train_num_updates": "75170", "train_lr": "0.000441345", "train_gnorm": "1.638", "train_loss_scale": "0.0312", "train_train_wall": "477", "train_gb_free": "41", "train_wall": "125645"}
[2024-10-09 05:22:29,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:22:29,485][fairseq.trainer][INFO] - begin training epoch 158
[2024-10-09 05:22:29,485][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:28:03,631][train_inner][INFO] - {"epoch": 158, "update": 157.063, "loss": "2.289", "ntokens": "356576", "nsentences": "1768.27", "wps": "135032", "ups": "0.38", "wpb": "356576", "bsz": "1768.3", "num_updates": "75200", "lr": "0.000441304", "gnorm": "1.822", "loss_scale": "0.0312", "train_wall": "247", "gb_free": "39.2", "wall": "125979"}
[2024-10-09 05:32:12,785][train_inner][INFO] - {"epoch": 158, "update": 157.48, "loss": "2.264", "ntokens": "358297", "nsentences": "1718.85", "wps": "287675", "ups": "0.8", "wpb": "358297", "bsz": "1718.8", "num_updates": "75400", "lr": "0.000441033", "gnorm": "1.517", "loss_scale": "0.0312", "train_wall": "240", "gb_free": "39.3", "wall": "126228"}
[2024-10-09 05:35:56,457][train_inner][INFO] - {"epoch": 158, "update": 157.898, "loss": "2.292", "ntokens": "358312", "nsentences": "1801.33", "wps": "320430", "ups": "0.89", "wpb": "358312", "bsz": "1801.3", "num_updates": "75600", "lr": "0.000440761", "gnorm": "1.593", "loss_scale": "0.0312", "train_wall": "201", "gb_free": "39.9", "wall": "126452"}
[2024-10-09 05:36:42,949][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2024-10-09 05:36:42,960][train][INFO] - {"epoch": 158, "train_loss": "2.278", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "200718", "train_ups": "0.56", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "75649", "train_lr": "0.000440694", "train_gnorm": "1.53", "train_loss_scale": "0.0312", "train_train_wall": "545", "train_gb_free": "39.3", "train_wall": "126498"}
[2024-10-09 05:36:43,152][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:36:43,158][fairseq.trainer][INFO] - begin training epoch 159
[2024-10-09 05:36:43,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:45:02,268][train_inner][INFO] - {"epoch": 159, "update": 158.315, "loss": "2.271", "ntokens": "356628", "nsentences": "1757.88", "wps": "130680", "ups": "0.37", "wpb": "356628", "bsz": "1757.9", "num_updates": "75800", "lr": "0.000440489", "gnorm": "1.475", "loss_scale": "0.0312", "train_wall": "237", "gb_free": "39.4", "wall": "126997"}
[2024-10-09 05:48:14,854][train_inner][INFO] - {"epoch": 159, "update": 158.733, "loss": "2.276", "ntokens": "358495", "nsentences": "1745.98", "wps": "372368", "ups": "1.04", "wpb": "358495", "bsz": "1746", "num_updates": "76000", "lr": "0.000440217", "gnorm": "1.459", "loss_scale": "0.0312", "train_wall": "184", "gb_free": "39.3", "wall": "127190"}
[2024-10-09 05:50:18,534][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2024-10-09 05:50:18,572][train][INFO] - {"epoch": 159, "train_loss": "2.274", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "210059", "train_ups": "0.59", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "76128", "train_lr": "0.000440043", "train_gnorm": "1.56", "train_loss_scale": "0.0312", "train_train_wall": "496", "train_gb_free": "39.6", "train_wall": "127314"}
[2024-10-09 05:50:18,869][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:50:18,914][fairseq.trainer][INFO] - begin training epoch 160
[2024-10-09 05:50:18,915][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:56:15,747][train_inner][INFO] - {"epoch": 160, "update": 159.15, "loss": "2.266", "ntokens": "356710", "nsentences": "1723.6", "wps": "148355", "ups": "0.42", "wpb": "356710", "bsz": "1723.6", "num_updates": "76200", "lr": "0.000439946", "gnorm": "1.578", "loss_scale": "0.0312", "train_wall": "184", "gb_free": "39.6", "wall": "127671"}
[2024-10-09 05:59:46,752][train_inner][INFO] - {"epoch": 160, "update": 159.568, "loss": "2.264", "ntokens": "358391", "nsentences": "1765.33", "wps": "339771", "ups": "0.95", "wpb": "358391", "bsz": "1765.3", "num_updates": "76400", "lr": "0.000439674", "gnorm": "1.61", "loss_scale": "0.0312", "train_wall": "201", "gb_free": "39.6", "wall": "127882"}
[2024-10-09 06:03:07,456][train_inner][INFO] - {"epoch": 160, "update": 159.985, "loss": "2.273", "ntokens": "358314", "nsentences": "1774.01", "wps": "357116", "ups": "1", "wpb": "358314", "bsz": "1774", "num_updates": "76600", "lr": "0.000439402", "gnorm": "1.448", "loss_scale": "0.0312", "train_wall": "198", "gb_free": "39.6", "wall": "128083"}
[2024-10-09 06:03:15,521][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 76607 updates
[2024-10-09 06:03:15,521][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 06:03:23,774][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 06:03:23,817][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 160 @ 76607 updates, score None) (writing took 8.296104883775115 seconds)
[2024-10-09 06:03:23,817][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2024-10-09 06:03:23,854][train][INFO] - {"epoch": 160, "train_loss": "2.266", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "218181", "train_ups": "0.61", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "76607", "train_lr": "0.000439393", "train_gnorm": "1.514", "train_loss_scale": "0.0312", "train_train_wall": "469", "train_gb_free": "39.2", "train_wall": "128099"}
[2024-10-09 06:03:24,047][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:03:24,067][fairseq.trainer][INFO] - begin training epoch 161
[2024-10-09 06:03:24,068][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:12:40,197][train_inner][INFO] - {"epoch": 161, "update": 160.403, "loss": "2.266", "ntokens": "356715", "nsentences": "1739.19", "wps": "124568", "ups": "0.35", "wpb": "356714", "bsz": "1739.2", "num_updates": "76800", "lr": "0.00043913", "gnorm": "1.472", "loss_scale": "0.0312", "train_wall": "273", "gb_free": "39.6", "wall": "128655"}
[2024-10-09 06:15:44,068][train_inner][INFO] - {"epoch": 161, "update": 160.82, "loss": "2.271", "ntokens": "358439", "nsentences": "1757.81", "wps": "389936", "ups": "1.09", "wpb": "358439", "bsz": "1757.8", "num_updates": "77000", "lr": "0.000438859", "gnorm": "1.419", "loss_scale": "0.0625", "train_wall": "180", "gb_free": "39.9", "wall": "128839"}
[2024-10-09 06:17:13,758][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2024-10-09 06:17:13,794][train][INFO] - {"epoch": 161, "train_loss": "2.268", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "206434", "train_ups": "0.58", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "77086", "train_lr": "0.000438742", "train_gnorm": "1.479", "train_loss_scale": "0.0625", "train_train_wall": "533", "train_gb_free": "39.6", "train_wall": "128929"}
[2024-10-09 06:17:13,983][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:17:14,002][fairseq.trainer][INFO] - begin training epoch 162
[2024-10-09 06:17:14,002][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:24:49,149][train_inner][INFO] - {"epoch": 162, "update": 161.238, "loss": "2.257", "ntokens": "356564", "nsentences": "1726.36", "wps": "130833", "ups": "0.37", "wpb": "356564", "bsz": "1726.4", "num_updates": "77200", "lr": "0.000438587", "gnorm": "1.745", "loss_scale": "0.0625", "train_wall": "244", "gb_free": "39.6", "wall": "129384"}
[2024-10-09 06:29:03,785][train_inner][INFO] - {"epoch": 162, "update": 161.656, "loss": "2.264", "ntokens": "358481", "nsentences": "1741.21", "wps": "281575", "ups": "0.79", "wpb": "358481", "bsz": "1741.2", "num_updates": "77400", "lr": "0.000438315", "gnorm": "1.565", "loss_scale": "0.0625", "train_wall": "202", "gb_free": "39.8", "wall": "129639"}
[2024-10-09 06:32:01,975][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2024-10-09 06:32:02,006][train][INFO] - {"epoch": 162, "train_loss": "2.265", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "192890", "train_ups": "0.54", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "77565", "train_lr": "0.000438091", "train_gnorm": "1.59", "train_loss_scale": "0.0625", "train_train_wall": "532", "train_gb_free": "39.9", "train_wall": "129817"}
[2024-10-09 06:32:02,263][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:32:02,284][fairseq.trainer][INFO] - begin training epoch 163
[2024-10-09 06:32:02,285][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:37:40,045][train_inner][INFO] - {"epoch": 163, "update": 162.073, "loss": "2.272", "ntokens": "356710", "nsentences": "1793.15", "wps": "138197", "ups": "0.39", "wpb": "356710", "bsz": "1793.2", "num_updates": "77600", "lr": "0.000438043", "gnorm": "1.408", "loss_scale": "0.0625", "train_wall": "238", "gb_free": "39.6", "wall": "130155"}
[2024-10-09 06:40:52,860][train_inner][INFO] - {"epoch": 163, "update": 162.491, "loss": "2.259", "ntokens": "358402", "nsentences": "1755.13", "wps": "371774", "ups": "1.04", "wpb": "358402", "bsz": "1755.1", "num_updates": "77800", "lr": "0.000437772", "gnorm": "1.504", "loss_scale": "0.0625", "train_wall": "186", "gb_free": "39.7", "wall": "130348"}
[2024-10-09 06:44:25,579][train_inner][INFO] - {"epoch": 163, "update": 162.908, "loss": "2.268", "ntokens": "358251", "nsentences": "1751.2", "wps": "336873", "ups": "0.94", "wpb": "358251", "bsz": "1751.2", "num_updates": "78000", "lr": "0.0004375", "gnorm": "1.45", "loss_scale": "0.0625", "train_wall": "185", "gb_free": "40.3", "wall": "130561"}
[2024-10-09 06:45:29,769][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2024-10-09 06:45:29,780][train][INFO] - {"epoch": 163, "train_loss": "2.263", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "212097", "train_ups": "0.59", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "78044", "train_lr": "0.00043744", "train_gnorm": "1.448", "train_loss_scale": "0.0625", "train_train_wall": "493", "train_gb_free": "40.6", "train_wall": "130625"}
[2024-10-09 06:45:29,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:45:29,952][fairseq.trainer][INFO] - begin training epoch 164
[2024-10-09 06:45:29,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:53:10,200][train_inner][INFO] - {"epoch": 164, "update": 163.326, "loss": "2.268", "ntokens": "356812", "nsentences": "1793.58", "wps": "136048", "ups": "0.38", "wpb": "356812", "bsz": "1793.6", "num_updates": "78200", "lr": "0.000437228", "gnorm": "1.469", "loss_scale": "0.0625", "train_wall": "237", "gb_free": "40.6", "wall": "131085"}
[2024-10-09 06:56:30,424][train_inner][INFO] - {"epoch": 164, "update": 163.743, "loss": "2.261", "ntokens": "358320", "nsentences": "1750.61", "wps": "357931", "ups": "1", "wpb": "358320", "bsz": "1750.6", "num_updates": "78400", "lr": "0.000436957", "gnorm": "1.532", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.2", "wall": "131286"}
[2024-10-09 06:58:38,817][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2024-10-09 06:58:38,852][train][INFO] - {"epoch": 164, "train_loss": "2.261", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "217124", "train_ups": "0.61", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "78523", "train_lr": "0.000436789", "train_gnorm": "1.541", "train_loss_scale": "0.0625", "train_train_wall": "497", "train_gb_free": "39.6", "train_wall": "131414"}
[2024-10-09 06:58:39,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:58:39,140][fairseq.trainer][INFO] - begin training epoch 165
[2024-10-09 06:58:39,141][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:05:11,490][train_inner][INFO] - {"epoch": 165, "update": 164.161, "loss": "2.253", "ntokens": "356782", "nsentences": "1715.83", "wps": "136962", "ups": "0.38", "wpb": "356782", "bsz": "1715.8", "num_updates": "78600", "lr": "0.000436685", "gnorm": "1.597", "loss_scale": "0.0625", "train_wall": "215", "gb_free": "40.4", "wall": "131807"}
[2024-10-09 07:08:58,617][train_inner][INFO] - {"epoch": 165, "update": 164.578, "loss": "2.263", "ntokens": "358508", "nsentences": "1767.01", "wps": "315696", "ups": "0.88", "wpb": "358508", "bsz": "1767", "num_updates": "78800", "lr": "0.000436413", "gnorm": "1.451", "loss_scale": "0.0625", "train_wall": "187", "gb_free": "39.6", "wall": "132034"}
[2024-10-09 07:12:32,843][train_inner][INFO] - {"epoch": 165, "update": 164.996, "loss": "2.264", "ntokens": "358137", "nsentences": "1746.6", "wps": "334432", "ups": "0.93", "wpb": "358137", "bsz": "1746.6", "num_updates": "79000", "lr": "0.000436141", "gnorm": "1.522", "loss_scale": "0.125", "train_wall": "211", "gb_free": "40.1", "wall": "132248"}
[2024-10-09 07:12:38,911][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2024-10-09 07:12:38,921][train][INFO] - {"epoch": 165, "train_loss": "2.261", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "203945", "train_ups": "0.57", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "79002", "train_lr": "0.000436139", "train_gnorm": "1.493", "train_loss_scale": "0.125", "train_train_wall": "496", "train_gb_free": "39.9", "train_wall": "132254"}
[2024-10-09 07:12:39,217][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:12:39,252][fairseq.trainer][INFO] - begin training epoch 166
[2024-10-09 07:12:39,254][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:21:25,155][train_inner][INFO] - {"epoch": 166, "update": 165.413, "loss": "2.253", "ntokens": "356785", "nsentences": "1766.71", "wps": "134057", "ups": "0.38", "wpb": "356785", "bsz": "1766.7", "num_updates": "79200", "lr": "0.00043587", "gnorm": "1.56", "loss_scale": "0.125", "train_wall": "227", "gb_free": "39.8", "wall": "132780"}
[2024-10-09 07:24:33,335][train_inner][INFO] - {"epoch": 166, "update": 165.831, "loss": "2.263", "ntokens": "358264", "nsentences": "1779.62", "wps": "380790", "ups": "1.06", "wpb": "358264", "bsz": "1779.6", "num_updates": "79400", "lr": "0.000435598", "gnorm": "1.416", "loss_scale": "0.125", "train_wall": "184", "gb_free": "39.3", "wall": "132968"}
[2024-10-09 07:25:47,950][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2024-10-09 07:25:47,979][train][INFO] - {"epoch": 166, "train_loss": "2.258", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "217129", "train_ups": "0.61", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "79481", "train_lr": "0.000435488", "train_gnorm": "1.512", "train_loss_scale": "0.125", "train_train_wall": "478", "train_gb_free": "39.2", "train_wall": "133043"}
[2024-10-09 07:25:48,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:25:48,523][fairseq.trainer][INFO] - begin training epoch 167
[2024-10-09 07:25:48,524][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:33:09,732][train_inner][INFO] - {"epoch": 167, "update": 166.248, "loss": "2.255", "ntokens": "356847", "nsentences": "1736.38", "wps": "138208", "ups": "0.39", "wpb": "356847", "bsz": "1736.4", "num_updates": "79600", "lr": "0.000435326", "gnorm": "1.501", "loss_scale": "0.125", "train_wall": "235", "gb_free": "39.6", "wall": "133485"}
[2024-10-09 07:36:48,381][train_inner][INFO] - {"epoch": 167, "update": 166.666, "loss": "2.254", "ntokens": "358218", "nsentences": "1726.86", "wps": "327676", "ups": "0.91", "wpb": "358218", "bsz": "1726.9", "num_updates": "79800", "lr": "0.000435054", "gnorm": "1.519", "loss_scale": "0.125", "train_wall": "216", "gb_free": "39.3", "wall": "133704"}
[2024-10-09 07:39:46,905][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2024-10-09 07:39:46,963][train][INFO] - {"epoch": 167, "train_loss": "2.257", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "204211", "train_ups": "0.57", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "79960", "train_lr": "0.000434837", "train_gnorm": "1.47", "train_loss_scale": "0.125", "train_train_wall": "552", "train_gb_free": "39.8", "train_wall": "133882"}
[2024-10-09 07:39:47,070][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:39:47,088][fairseq.trainer][INFO] - begin training epoch 168
[2024-10-09 07:39:47,088][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:45:31,558][train_inner][INFO] - {"epoch": 168, "update": 167.084, "loss": "2.261", "ntokens": "356826", "nsentences": "1762.16", "wps": "136411", "ups": "0.38", "wpb": "356826", "bsz": "1762.2", "num_updates": "80000", "lr": "0.000434783", "gnorm": "1.499", "loss_scale": "0.125", "train_wall": "226", "gb_free": "40.1", "wall": "134227"}
[2024-10-09 07:50:57,852][train_inner][INFO] - {"epoch": 168, "update": 167.501, "loss": "2.254", "ntokens": "358252", "nsentences": "1747.94", "wps": "219592", "ups": "0.61", "wpb": "358252", "bsz": "1747.9", "num_updates": "80200", "lr": "0.000434511", "gnorm": "1.351", "loss_scale": "0.125", "train_wall": "301", "gb_free": "40.5", "wall": "134553"}
[2024-10-09 07:54:06,780][train_inner][INFO] - {"epoch": 168, "update": 167.919, "loss": "2.26", "ntokens": "358386", "nsentences": "1776.84", "wps": "379432", "ups": "1.06", "wpb": "358386", "bsz": "1776.8", "num_updates": "80400", "lr": "0.000434239", "gnorm": "1.568", "loss_scale": "0.125", "train_wall": "185", "gb_free": "39.9", "wall": "134742"}
[2024-10-09 07:57:04,342][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2024-10-09 07:57:04,491][train][INFO] - {"epoch": 168, "train_loss": "2.256", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "165131", "train_ups": "0.46", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "80439", "train_lr": "0.000434186", "train_gnorm": "1.495", "train_loss_scale": "0.125", "train_train_wall": "715", "train_gb_free": "39.2", "train_wall": "134920"}
[2024-10-09 07:57:04,573][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:57:04,596][fairseq.trainer][INFO] - begin training epoch 169
[2024-10-09 07:57:04,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:03:59,150][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-09 08:06:04,666][train_inner][INFO] - {"epoch": 169, "update": 168.338, "loss": "2.249", "ntokens": "356784", "nsentences": "1759.66", "wps": "99399.4", "ups": "0.28", "wpb": "356784", "bsz": "1759.7", "num_updates": "80600", "lr": "0.000433967", "gnorm": "1.538", "loss_scale": "0.0625", "train_wall": "341", "gb_free": "39.3", "wall": "135460"}
[2024-10-09 08:09:31,951][train_inner][INFO] - {"epoch": 169, "update": 168.756, "loss": "2.255", "ntokens": "358450", "nsentences": "1790.65", "wps": "345924", "ups": "0.97", "wpb": "358450", "bsz": "1790.7", "num_updates": "80800", "lr": "0.000433696", "gnorm": "1.428", "loss_scale": "0.0625", "train_wall": "200", "gb_free": "39.6", "wall": "135667"}
[2024-10-09 08:11:22,721][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2024-10-09 08:11:22,732][train][INFO] - {"epoch": 169, "train_loss": "2.251", "train_ntokens": "357672", "train_nsentences": "1753.86", "train_wps": "199207", "train_ups": "0.56", "train_wpb": "357672", "train_bsz": "1753.9", "train_num_updates": "80917", "train_lr": "0.000433537", "train_gnorm": "1.435", "train_loss_scale": "0.0625", "train_train_wall": "471", "train_gb_free": "39.6", "train_wall": "135778"}
[2024-10-09 08:11:22,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:11:22,873][fairseq.trainer][INFO] - begin training epoch 170
[2024-10-09 08:11:22,874][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:18:02,581][train_inner][INFO] - {"epoch": 170, "update": 169.173, "loss": "2.246", "ntokens": "356624", "nsentences": "1674.04", "wps": "139687", "ups": "0.39", "wpb": "356624", "bsz": "1674", "num_updates": "81000", "lr": "0.000433424", "gnorm": "1.464", "loss_scale": "0.0625", "train_wall": "230", "gb_free": "39.4", "wall": "136178"}
[2024-10-09 08:21:34,420][train_inner][INFO] - {"epoch": 170, "update": 169.591, "loss": "2.249", "ntokens": "358286", "nsentences": "1760.3", "wps": "338292", "ups": "0.94", "wpb": "358286", "bsz": "1760.3", "num_updates": "81200", "lr": "0.000433152", "gnorm": "1.546", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "40.1", "wall": "136390"}
[2024-10-09 08:25:21,222][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 81396 updates
[2024-10-09 08:25:21,225][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 08:25:29,383][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 08:25:29,387][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 170 @ 81396 updates, score None) (writing took 8.164977721869946 seconds)
[2024-10-09 08:25:29,387][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2024-10-09 08:25:29,403][train][INFO] - {"epoch": 170, "train_loss": "2.251", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "202356", "train_ups": "0.57", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "81396", "train_lr": "0.000432886", "train_gnorm": "1.564", "train_loss_scale": "0.0625", "train_train_wall": "514", "train_gb_free": "39.1", "train_wall": "136625"}
[2024-10-09 08:25:29,478][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:25:29,504][fairseq.trainer][INFO] - begin training epoch 171
[2024-10-09 08:25:29,505][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:30:15,534][train_inner][INFO] - {"epoch": 171, "update": 170.008, "loss": "2.256", "ntokens": "356809", "nsentences": "1758.9", "wps": "136955", "ups": "0.38", "wpb": "356809", "bsz": "1758.9", "num_updates": "81400", "lr": "0.00043288", "gnorm": "1.583", "loss_scale": "0.0625", "train_wall": "214", "gb_free": "39.6", "wall": "136911"}
[2024-10-09 08:33:08,307][train_inner][INFO] - {"epoch": 171, "update": 170.426, "loss": "2.236", "ntokens": "358425", "nsentences": "1712.64", "wps": "414918", "ups": "1.16", "wpb": "358425", "bsz": "1712.6", "num_updates": "81600", "lr": "0.000432609", "gnorm": "1.545", "loss_scale": "0.0625", "train_wall": "169", "gb_free": "39.6", "wall": "137083"}
[2024-10-09 08:36:25,934][train_inner][INFO] - {"epoch": 171, "update": 170.843, "loss": "2.261", "ntokens": "358217", "nsentences": "1812.19", "wps": "362532", "ups": "1.01", "wpb": "358217", "bsz": "1812.2", "num_updates": "81800", "lr": "0.000432337", "gnorm": "1.765", "loss_scale": "0.0625", "train_wall": "194", "gb_free": "39.3", "wall": "137281"}
[2024-10-09 08:37:36,489][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2024-10-09 08:37:36,509][train][INFO] - {"epoch": 171, "train_loss": "2.249", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "235628", "train_ups": "0.66", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "81875", "train_lr": "0.000432235", "train_gnorm": "1.657", "train_loss_scale": "0.0625", "train_train_wall": "459", "train_gb_free": "41", "train_wall": "137352"}
[2024-10-09 08:37:36,737][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:37:36,783][fairseq.trainer][INFO] - begin training epoch 172
[2024-10-09 08:37:36,783][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:44:42,135][train_inner][INFO] - {"epoch": 172, "update": 171.261, "loss": "2.246", "ntokens": "356813", "nsentences": "1720.62", "wps": "143827", "ups": "0.4", "wpb": "356813", "bsz": "1720.6", "num_updates": "82000", "lr": "0.000432065", "gnorm": "1.493", "loss_scale": "0.0625", "train_wall": "215", "gb_free": "39.2", "wall": "137777"}
[2024-10-09 08:48:49,473][train_inner][INFO] - {"epoch": 172, "update": 171.678, "loss": "2.247", "ntokens": "358310", "nsentences": "1756.62", "wps": "289833", "ups": "0.81", "wpb": "358310", "bsz": "1756.6", "num_updates": "82200", "lr": "0.000431793", "gnorm": "1.38", "loss_scale": "0.0625", "train_wall": "241", "gb_free": "40.1", "wall": "138025"}
[2024-10-09 08:52:04,228][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2024-10-09 08:52:04,319][train][INFO] - {"epoch": 172, "train_loss": "2.248", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "197428", "train_ups": "0.55", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "82354", "train_lr": "0.000431584", "train_gnorm": "1.496", "train_loss_scale": "0.0625", "train_train_wall": "551", "train_gb_free": "40.3", "train_wall": "138219"}
[2024-10-09 08:52:06,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:52:06,192][fairseq.trainer][INFO] - begin training epoch 173
[2024-10-09 08:52:06,192][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:58:02,006][train_inner][INFO] - {"epoch": 173, "update": 172.096, "loss": "2.254", "ntokens": "356799", "nsentences": "1773.27", "wps": "129154", "ups": "0.36", "wpb": "356799", "bsz": "1773.3", "num_updates": "82400", "lr": "0.000431522", "gnorm": "1.587", "loss_scale": "0.0625", "train_wall": "223", "gb_free": "40.6", "wall": "138577"}
[2024-10-09 09:00:46,079][train_inner][INFO] - {"epoch": 173, "update": 172.514, "loss": "2.242", "ntokens": "358139", "nsentences": "1770.71", "wps": "436605", "ups": "1.22", "wpb": "358139", "bsz": "1770.7", "num_updates": "82600", "lr": "0.00043125", "gnorm": "1.258", "loss_scale": "0.125", "train_wall": "159", "gb_free": "39.6", "wall": "138741"}
[2024-10-09 09:04:30,004][train_inner][INFO] - {"epoch": 173, "update": 172.931, "loss": "2.244", "ntokens": "358435", "nsentences": "1715.99", "wps": "320145", "ups": "0.89", "wpb": "358435", "bsz": "1716", "num_updates": "82800", "lr": "0.000430978", "gnorm": "1.7", "loss_scale": "0.125", "train_wall": "216", "gb_free": "40.1", "wall": "138965"}
[2024-10-09 09:05:07,138][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2024-10-09 09:05:07,153][train][INFO] - {"epoch": 173, "train_loss": "2.245", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "218855", "train_ups": "0.61", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "82833", "train_lr": "0.000430933", "train_gnorm": "1.482", "train_loss_scale": "0.125", "train_train_wall": "467", "train_gb_free": "39.8", "train_wall": "139002"}
[2024-10-09 09:05:07,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:05:07,484][fairseq.trainer][INFO] - begin training epoch 174
[2024-10-09 09:05:07,484][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:13:38,246][train_inner][INFO] - {"epoch": 174, "update": 173.349, "loss": "2.235", "ntokens": "356901", "nsentences": "1742.59", "wps": "130200", "ups": "0.36", "wpb": "356901", "bsz": "1742.6", "num_updates": "83000", "lr": "0.000430707", "gnorm": "1.647", "loss_scale": "0.125", "train_wall": "247", "gb_free": "39.6", "wall": "139513"}
[2024-10-09 09:17:29,704][train_inner][INFO] - {"epoch": 174, "update": 173.766, "loss": "2.246", "ntokens": "358339", "nsentences": "1754.01", "wps": "309702", "ups": "0.86", "wpb": "358339", "bsz": "1754", "num_updates": "83200", "lr": "0.000430435", "gnorm": "1.461", "loss_scale": "0.125", "train_wall": "221", "gb_free": "39.7", "wall": "139745"}
[2024-10-09 09:18:41,423][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-09 09:19:18,685][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2024-10-09 09:19:18,759][train][INFO] - {"epoch": 174, "train_loss": "2.243", "train_ntokens": "357672", "train_nsentences": "1753.67", "train_wps": "200761", "train_ups": "0.56", "train_wpb": "357672", "train_bsz": "1753.7", "train_num_updates": "83311", "train_lr": "0.000430284", "train_gnorm": "1.6", "train_loss_scale": "0.0625", "train_train_wall": "535", "train_gb_free": "39.7", "train_wall": "139854"}
[2024-10-09 09:19:19,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:19:19,070][fairseq.trainer][INFO] - begin training epoch 175
[2024-10-09 09:19:19,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:26:34,102][train_inner][INFO] - {"epoch": 175, "update": 174.186, "loss": "2.256", "ntokens": "356612", "nsentences": "1800.02", "wps": "131017", "ups": "0.37", "wpb": "356612", "bsz": "1800", "num_updates": "83400", "lr": "0.000430163", "gnorm": "1.59", "loss_scale": "0.0625", "train_wall": "195", "gb_free": "39.2", "wall": "140289"}
[2024-10-09 09:28:50,536][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 09:29:23,036][train_inner][INFO] - {"epoch": 175, "update": 174.605, "loss": "2.246", "ntokens": "358474", "nsentences": "1755.1", "wps": "424412", "ups": "1.18", "wpb": "358474", "bsz": "1755.1", "num_updates": "83600", "lr": "0.000429891", "gnorm": "1.707", "loss_scale": "0.0312", "train_wall": "164", "gb_free": "39.8", "wall": "140458"}
[2024-10-09 09:32:27,759][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2024-10-09 09:32:27,857][train][INFO] - {"epoch": 175, "train_loss": "2.247", "train_ntokens": "357672", "train_nsentences": "1754.31", "train_wps": "216671", "train_ups": "0.61", "train_wpb": "357672", "train_bsz": "1754.3", "train_num_updates": "83789", "train_lr": "0.000429635", "train_gnorm": "1.643", "train_loss_scale": "0.0312", "train_train_wall": "436", "train_gb_free": "39.2", "train_wall": "140643"}
[2024-10-09 09:32:28,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:32:28,208][fairseq.trainer][INFO] - begin training epoch 176
[2024-10-09 09:32:28,208][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:37:21,016][train_inner][INFO] - {"epoch": 176, "update": 175.023, "loss": "2.243", "ntokens": "356626", "nsentences": "1726.4", "wps": "149224", "ups": "0.42", "wpb": "356626", "bsz": "1726.4", "num_updates": "83800", "lr": "0.00042962", "gnorm": "1.773", "loss_scale": "0.0312", "train_wall": "183", "gb_free": "39.7", "wall": "140936"}
[2024-10-09 09:40:19,520][train_inner][INFO] - {"epoch": 176, "update": 175.441, "loss": "2.237", "ntokens": "358193", "nsentences": "1783.54", "wps": "401336", "ups": "1.12", "wpb": "358193", "bsz": "1783.5", "num_updates": "84000", "lr": "0.000429348", "gnorm": "1.497", "loss_scale": "0.0312", "train_wall": "167", "gb_free": "39.7", "wall": "141115"}
[2024-10-09 09:44:53,781][train_inner][INFO] - {"epoch": 176, "update": 175.858, "loss": "2.25", "ntokens": "358414", "nsentences": "1753.51", "wps": "261373", "ups": "0.73", "wpb": "358414", "bsz": "1753.5", "num_updates": "84200", "lr": "0.000429076", "gnorm": "1.699", "loss_scale": "0.0312", "train_wall": "271", "gb_free": "40.1", "wall": "141389"}
[2024-10-09 09:46:03,748][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2024-10-09 09:46:03,859][train][INFO] - {"epoch": 176, "train_loss": "2.244", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "209960", "train_ups": "0.59", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "84268", "train_lr": "0.000428984", "train_gnorm": "1.58", "train_loss_scale": "0.0312", "train_train_wall": "510", "train_gb_free": "40.1", "train_wall": "141459"}
[2024-10-09 09:46:05,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:46:05,519][fairseq.trainer][INFO] - begin training epoch 177
[2024-10-09 09:46:05,520][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:52:52,447][train_inner][INFO] - {"epoch": 177, "update": 176.276, "loss": "2.242", "ntokens": "356666", "nsentences": "1725.89", "wps": "149027", "ups": "0.42", "wpb": "356666", "bsz": "1725.9", "num_updates": "84400", "lr": "0.000428804", "gnorm": "1.529", "loss_scale": "0.0312", "train_wall": "195", "gb_free": "40.1", "wall": "141868"}
[2024-10-09 09:55:59,787][train_inner][INFO] - {"epoch": 177, "update": 176.693, "loss": "2.242", "ntokens": "358321", "nsentences": "1763.7", "wps": "382546", "ups": "1.07", "wpb": "358321", "bsz": "1763.7", "num_updates": "84600", "lr": "0.000428533", "gnorm": "1.528", "loss_scale": "0.0312", "train_wall": "174", "gb_free": "39.6", "wall": "142055"}
[2024-10-09 09:58:21,333][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2024-10-09 09:58:21,502][train][INFO] - {"epoch": 177, "train_loss": "2.243", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "232275", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "84747", "train_lr": "0.000428333", "train_gnorm": "1.553", "train_loss_scale": "0.0312", "train_train_wall": "412", "train_gb_free": "39.7", "train_wall": "142197"}
[2024-10-09 09:58:25,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:58:26,124][fairseq.trainer][INFO] - begin training epoch 178
[2024-10-09 09:58:26,167][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:05:32,598][train_inner][INFO] - {"epoch": 178, "update": 177.111, "loss": "2.243", "ntokens": "356890", "nsentences": "1754.31", "wps": "124611", "ups": "0.35", "wpb": "356890", "bsz": "1754.3", "num_updates": "84800", "lr": "0.000428261", "gnorm": "1.559", "loss_scale": "0.0312", "train_wall": "167", "gb_free": "39.6", "wall": "142628"}
[2024-10-09 10:10:56,915][train_inner][INFO] - {"epoch": 178, "update": 177.528, "loss": "2.228", "ntokens": "358369", "nsentences": "1745.1", "wps": "221011", "ups": "0.62", "wpb": "358369", "bsz": "1745.1", "num_updates": "85000", "lr": "0.000427989", "gnorm": "1.428", "loss_scale": "0.0312", "train_wall": "277", "gb_free": "39.8", "wall": "142952"}
[2024-10-09 10:14:18,305][train_inner][INFO] - {"epoch": 178, "update": 177.946, "loss": "2.242", "ntokens": "358248", "nsentences": "1749.55", "wps": "355832", "ups": "0.99", "wpb": "358248", "bsz": "1749.5", "num_updates": "85200", "lr": "0.000427717", "gnorm": "1.518", "loss_scale": "0.0312", "train_wall": "198", "gb_free": "39.3", "wall": "143153"}
[2024-10-09 10:14:49,942][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2024-10-09 10:14:50,178][train][INFO] - {"epoch": 178, "train_loss": "2.236", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "173330", "train_ups": "0.48", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "85226", "train_lr": "0.000427682", "train_gnorm": "1.502", "train_loss_scale": "0.0312", "train_train_wall": "564", "train_gb_free": "39.6", "train_wall": "143185"}
[2024-10-09 10:14:50,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:14:50,511][fairseq.trainer][INFO] - begin training epoch 179
[2024-10-09 10:14:50,512][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:26:06,512][train_inner][INFO] - {"epoch": 179, "update": 178.363, "loss": "2.235", "ntokens": "356762", "nsentences": "1763.4", "wps": "100752", "ups": "0.28", "wpb": "356762", "bsz": "1763.4", "num_updates": "85400", "lr": "0.000427446", "gnorm": "1.546", "loss_scale": "0.0312", "train_wall": "259", "gb_free": "39.6", "wall": "143862"}
[2024-10-09 10:31:00,033][train_inner][INFO] - {"epoch": 179, "update": 178.781, "loss": "2.242", "ntokens": "358358", "nsentences": "1775.63", "wps": "244182", "ups": "0.68", "wpb": "358358", "bsz": "1775.6", "num_updates": "85600", "lr": "0.000427174", "gnorm": "1.511", "loss_scale": "0.0312", "train_wall": "283", "gb_free": "39.6", "wall": "144155"}
[2024-10-09 10:33:17,365][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2024-10-09 10:33:17,375][train][INFO] - {"epoch": 179, "train_loss": "2.237", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "154739", "train_ups": "0.43", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "85705", "train_lr": "0.000427031", "train_gnorm": "1.507", "train_loss_scale": "0.0625", "train_train_wall": "646", "train_gb_free": "39.2", "train_wall": "144293"}
[2024-10-09 10:33:17,488][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:33:17,491][fairseq.trainer][INFO] - begin training epoch 180
[2024-10-09 10:33:17,492][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:39:31,567][train_inner][INFO] - {"epoch": 180, "update": 179.198, "loss": "2.233", "ntokens": "356830", "nsentences": "1725.06", "wps": "139518", "ups": "0.39", "wpb": "356830", "bsz": "1725.1", "num_updates": "85800", "lr": "0.000426902", "gnorm": "1.514", "loss_scale": "0.0625", "train_wall": "241", "gb_free": "40.3", "wall": "144667"}
[2024-10-09 10:43:05,508][train_inner][INFO] - {"epoch": 180, "update": 179.616, "loss": "2.231", "ntokens": "358315", "nsentences": "1760.68", "wps": "335016", "ups": "0.93", "wpb": "358315", "bsz": "1760.7", "num_updates": "86000", "lr": "0.00042663", "gnorm": "1.276", "loss_scale": "0.0625", "train_wall": "206", "gb_free": "40.1", "wall": "144881"}
[2024-10-09 10:46:24,320][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 86184 updates
[2024-10-09 10:46:24,327][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 10:46:30,392][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 10:46:30,405][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 180 @ 86184 updates, score None) (writing took 6.084743632003665 seconds)
[2024-10-09 10:46:30,411][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2024-10-09 10:46:30,430][train][INFO] - {"epoch": 180, "train_loss": "2.233", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "216039", "train_ups": "0.6", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "86184", "train_lr": "0.00042638", "train_gnorm": "1.453", "train_loss_scale": "0.0625", "train_train_wall": "485", "train_gb_free": "39.7", "train_wall": "145086"}
[2024-10-09 10:46:30,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:46:30,587][fairseq.trainer][INFO] - begin training epoch 181
[2024-10-09 10:46:30,587][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:51:26,946][train_inner][INFO] - {"epoch": 181, "update": 180.033, "loss": "2.236", "ntokens": "356777", "nsentences": "1735.31", "wps": "142306", "ups": "0.4", "wpb": "356777", "bsz": "1735.3", "num_updates": "86200", "lr": "0.000426359", "gnorm": "1.588", "loss_scale": "0.0625", "train_wall": "202", "gb_free": "40.1", "wall": "145382"}
[2024-10-09 10:54:22,506][train_inner][INFO] - {"epoch": 181, "update": 180.451, "loss": "2.229", "ntokens": "358388", "nsentences": "1746.4", "wps": "408298", "ups": "1.14", "wpb": "358388", "bsz": "1746.4", "num_updates": "86400", "lr": "0.000426087", "gnorm": "1.408", "loss_scale": "0.0625", "train_wall": "172", "gb_free": "39.6", "wall": "145558"}
[2024-10-09 10:57:42,651][train_inner][INFO] - {"epoch": 181, "update": 180.868, "loss": "2.234", "ntokens": "358256", "nsentences": "1778.12", "wps": "358011", "ups": "1", "wpb": "358256", "bsz": "1778.1", "num_updates": "86600", "lr": "0.000425815", "gnorm": "1.447", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "40.6", "wall": "145758"}
[2024-10-09 10:58:45,937][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2024-10-09 10:58:46,000][train][INFO] - {"epoch": 181, "train_loss": "2.232", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "232936", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "86663", "train_lr": "0.00042573", "train_gnorm": "1.428", "train_loss_scale": "0.0625", "train_train_wall": "458", "train_gb_free": "39.8", "train_wall": "145821"}
[2024-10-09 10:58:46,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:58:46,232][fairseq.trainer][INFO] - begin training epoch 182
[2024-10-09 10:58:46,232][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:07:13,692][train_inner][INFO] - {"epoch": 182, "update": 181.286, "loss": "2.233", "ntokens": "356808", "nsentences": "1756.67", "wps": "124969", "ups": "0.35", "wpb": "356808", "bsz": "1756.7", "num_updates": "86800", "lr": "0.000425543", "gnorm": "1.607", "loss_scale": "0.0625", "train_wall": "247", "gb_free": "39.3", "wall": "146329"}
[2024-10-09 11:11:12,814][train_inner][INFO] - {"epoch": 182, "update": 181.704, "loss": "2.229", "ntokens": "358395", "nsentences": "1786.76", "wps": "299857", "ups": "0.84", "wpb": "358394", "bsz": "1786.8", "num_updates": "87000", "lr": "0.000425272", "gnorm": "1.493", "loss_scale": "0.0625", "train_wall": "219", "gb_free": "39.1", "wall": "146568"}
[2024-10-09 11:14:11,302][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2024-10-09 11:14:11,312][train][INFO] - {"epoch": 182, "train_loss": "2.229", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "185157", "train_ups": "0.52", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "87142", "train_lr": "0.000425079", "train_gnorm": "1.514", "train_loss_scale": "0.0625", "train_train_wall": "575", "train_gb_free": "40.3", "train_wall": "146746"}
[2024-10-09 11:14:11,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:14:11,495][fairseq.trainer][INFO] - begin training epoch 183
[2024-10-09 11:14:11,495][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:20:34,832][train_inner][INFO] - {"epoch": 183, "update": 182.121, "loss": "2.227", "ntokens": "356644", "nsentences": "1719.45", "wps": "126940", "ups": "0.36", "wpb": "356644", "bsz": "1719.5", "num_updates": "87200", "lr": "0.000425", "gnorm": "1.452", "loss_scale": "0.0625", "train_wall": "265", "gb_free": "39.3", "wall": "147130"}
[2024-10-09 11:24:02,180][train_inner][INFO] - {"epoch": 183, "update": 182.539, "loss": "2.226", "ntokens": "358227", "nsentences": "1756.53", "wps": "345541", "ups": "0.96", "wpb": "358227", "bsz": "1756.5", "num_updates": "87400", "lr": "0.000424728", "gnorm": "1.614", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "39.1", "wall": "147337"}
[2024-10-09 11:27:12,546][train_inner][INFO] - {"epoch": 183, "update": 182.956, "loss": "2.234", "ntokens": "358412", "nsentences": "1746.4", "wps": "376626", "ups": "1.05", "wpb": "358412", "bsz": "1746.4", "num_updates": "87600", "lr": "0.000424457", "gnorm": "1.418", "loss_scale": "0.0625", "train_wall": "186", "gb_free": "39.3", "wall": "147528"}
[2024-10-09 11:27:56,154][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2024-10-09 11:27:56,174][train][INFO] - {"epoch": 183, "train_loss": "2.23", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "207711", "train_ups": "0.58", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "87621", "train_lr": "0.000424428", "train_gnorm": "1.527", "train_loss_scale": "0.0625", "train_train_wall": "527", "train_gb_free": "40.3", "train_wall": "147571"}
[2024-10-09 11:27:56,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:27:56,339][fairseq.trainer][INFO] - begin training epoch 184
[2024-10-09 11:27:56,340][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:35:51,733][train_inner][INFO] - {"epoch": 184, "update": 183.374, "loss": "2.224", "ntokens": "356806", "nsentences": "1756.02", "wps": "137450", "ups": "0.39", "wpb": "356806", "bsz": "1756", "num_updates": "87800", "lr": "0.000424185", "gnorm": "1.7", "loss_scale": "0.125", "train_wall": "223", "gb_free": "39.6", "wall": "148047"}
[2024-10-09 11:36:34,605][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-09 11:36:36,197][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 11:39:03,698][train_inner][INFO] - {"epoch": 184, "update": 183.795, "loss": "2.232", "ntokens": "358239", "nsentences": "1758.77", "wps": "373289", "ups": "1.04", "wpb": "358239", "bsz": "1758.8", "num_updates": "88000", "lr": "0.000423913", "gnorm": "1.609", "loss_scale": "0.0312", "train_wall": "173", "gb_free": "39.8", "wall": "148239"}
[2024-10-09 11:40:40,974][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2024-10-09 11:40:40,999][train][INFO] - {"epoch": 184, "train_loss": "2.229", "train_ntokens": "357677", "train_nsentences": "1754.49", "train_wps": "223075", "train_ups": "0.62", "train_wpb": "357677", "train_bsz": "1754.5", "train_num_updates": "88098", "train_lr": "0.00042378", "train_gnorm": "1.621", "train_loss_scale": "0.0312", "train_train_wall": "448", "train_gb_free": "40.1", "train_wall": "148336"}
[2024-10-09 11:40:41,217][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:40:41,240][fairseq.trainer][INFO] - begin training epoch 185
[2024-10-09 11:40:41,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:47:05,817][train_inner][INFO] - {"epoch": 185, "update": 184.213, "loss": "2.235", "ntokens": "356870", "nsentences": "1747.32", "wps": "148045", "ups": "0.41", "wpb": "356870", "bsz": "1747.3", "num_updates": "88200", "lr": "0.000423641", "gnorm": "1.561", "loss_scale": "0.0312", "train_wall": "207", "gb_free": "39.3", "wall": "148721"}
[2024-10-09 11:50:03,128][train_inner][INFO] - {"epoch": 185, "update": 184.63, "loss": "2.223", "ntokens": "358310", "nsentences": "1769.11", "wps": "404171", "ups": "1.13", "wpb": "358310", "bsz": "1769.1", "num_updates": "88400", "lr": "0.00042337", "gnorm": "1.666", "loss_scale": "0.0312", "train_wall": "173", "gb_free": "39.2", "wall": "148898"}
[2024-10-09 11:54:03,874][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2024-10-09 11:54:03,895][train][INFO] - {"epoch": 185, "train_loss": "2.228", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "213388", "train_ups": "0.6", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "88577", "train_lr": "0.000423129", "train_gnorm": "1.66", "train_loss_scale": "0.0312", "train_train_wall": "524", "train_gb_free": "39.6", "train_wall": "149139"}
[2024-10-09 11:54:04,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:54:04,148][fairseq.trainer][INFO] - begin training epoch 186
[2024-10-09 11:54:04,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:59:49,517][train_inner][INFO] - {"epoch": 186, "update": 185.048, "loss": "2.235", "ntokens": "356713", "nsentences": "1744.24", "wps": "121667", "ups": "0.34", "wpb": "356713", "bsz": "1744.2", "num_updates": "88600", "lr": "0.000423098", "gnorm": "1.625", "loss_scale": "0.0312", "train_wall": "284", "gb_free": "39.8", "wall": "149485"}
[2024-10-09 12:04:11,453][train_inner][INFO] - {"epoch": 186, "update": 185.466, "loss": "2.221", "ntokens": "358184", "nsentences": "1763.24", "wps": "273533", "ups": "0.76", "wpb": "358184", "bsz": "1763.2", "num_updates": "88800", "lr": "0.000422826", "gnorm": "1.511", "loss_scale": "0.0312", "train_wall": "257", "gb_free": "39.6", "wall": "149747"}
[2024-10-09 12:08:22,613][train_inner][INFO] - {"epoch": 186, "update": 185.883, "loss": "2.223", "ntokens": "358474", "nsentences": "1721.77", "wps": "285533", "ups": "0.8", "wpb": "358474", "bsz": "1721.8", "num_updates": "89000", "lr": "0.000422554", "gnorm": "1.543", "loss_scale": "0.0312", "train_wall": "247", "gb_free": "40.1", "wall": "149998"}
[2024-10-09 12:09:29,717][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2024-10-09 12:09:29,811][train][INFO] - {"epoch": 186, "train_loss": "2.226", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "185036", "train_ups": "0.52", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "89056", "train_lr": "0.000422478", "train_gnorm": "1.552", "train_loss_scale": "0.0312", "train_train_wall": "614", "train_gb_free": "39.6", "train_wall": "150065"}
[2024-10-09 12:09:29,999][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:09:30,020][fairseq.trainer][INFO] - begin training epoch 187
[2024-10-09 12:09:30,020][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:16:46,978][train_inner][INFO] - {"epoch": 187, "update": 186.301, "loss": "2.222", "ntokens": "356786", "nsentences": "1753.14", "wps": "141490", "ups": "0.4", "wpb": "356786", "bsz": "1753.1", "num_updates": "89200", "lr": "0.000422283", "gnorm": "1.414", "loss_scale": "0.0312", "train_wall": "207", "gb_free": "40.1", "wall": "150502"}
[2024-10-09 12:20:32,647][train_inner][INFO] - {"epoch": 187, "update": 186.718, "loss": "2.225", "ntokens": "358184", "nsentences": "1754.06", "wps": "317461", "ups": "0.89", "wpb": "358184", "bsz": "1754.1", "num_updates": "89400", "lr": "0.000422011", "gnorm": "1.654", "loss_scale": "0.0312", "train_wall": "222", "gb_free": "40.3", "wall": "150728"}
[2024-10-09 12:23:20,662][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2024-10-09 12:23:20,732][train][INFO] - {"epoch": 187, "train_loss": "2.223", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "206197", "train_ups": "0.58", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "89535", "train_lr": "0.000421827", "train_gnorm": "1.534", "train_loss_scale": "0.0312", "train_train_wall": "494", "train_gb_free": "39.3", "train_wall": "150896"}
[2024-10-09 12:23:22,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:23:22,859][fairseq.trainer][INFO] - begin training epoch 188
[2024-10-09 12:23:22,860][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:29:14,759][train_inner][INFO] - {"epoch": 188, "update": 187.136, "loss": "2.225", "ntokens": "356901", "nsentences": "1777.62", "wps": "136719", "ups": "0.38", "wpb": "356901", "bsz": "1777.6", "num_updates": "89600", "lr": "0.000421739", "gnorm": "1.6", "loss_scale": "0.0312", "train_wall": "196", "gb_free": "39.8", "wall": "151250"}
[2024-10-09 12:32:22,623][train_inner][INFO] - {"epoch": 188, "update": 187.553, "loss": "2.214", "ntokens": "358298", "nsentences": "1751.07", "wps": "381482", "ups": "1.06", "wpb": "358298", "bsz": "1751.1", "num_updates": "89800", "lr": "0.000421467", "gnorm": "1.55", "loss_scale": "0.0312", "train_wall": "177", "gb_free": "40.1", "wall": "151438"}
[2024-10-09 12:35:32,011][train_inner][INFO] - {"epoch": 188, "update": 187.971, "loss": "2.23", "ntokens": "358343", "nsentences": "1754.61", "wps": "378436", "ups": "1.06", "wpb": "358343", "bsz": "1754.6", "num_updates": "90000", "lr": "0.000421196", "gnorm": "1.474", "loss_scale": "0.0625", "train_wall": "184", "gb_free": "39.7", "wall": "151627"}
[2024-10-09 12:36:01,559][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2024-10-09 12:36:01,674][train][INFO] - {"epoch": 188, "train_loss": "2.222", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "225157", "train_ups": "0.63", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "90014", "train_lr": "0.000421177", "train_gnorm": "1.519", "train_loss_scale": "0.0625", "train_train_wall": "455", "train_gb_free": "39.2", "train_wall": "151657"}
[2024-10-09 12:36:03,908][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:36:03,992][fairseq.trainer][INFO] - begin training epoch 189
[2024-10-09 12:36:03,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:44:59,641][train_inner][INFO] - {"epoch": 189, "update": 188.388, "loss": "2.208", "ntokens": "356773", "nsentences": "1715.32", "wps": "125708", "ups": "0.35", "wpb": "356773", "bsz": "1715.3", "num_updates": "90200", "lr": "0.000420924", "gnorm": "1.39", "loss_scale": "0.0625", "train_wall": "264", "gb_free": "39.3", "wall": "152195"}
[2024-10-09 12:48:26,219][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 12:49:37,379][train_inner][INFO] - {"epoch": 189, "update": 188.808, "loss": "2.224", "ntokens": "358297", "nsentences": "1790.23", "wps": "258063", "ups": "0.72", "wpb": "358297", "bsz": "1790.2", "num_updates": "90400", "lr": "0.000420652", "gnorm": "1.627", "loss_scale": "0.0312", "train_wall": "226", "gb_free": "39.3", "wall": "152473"}
[2024-10-09 12:51:43,829][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2024-10-09 12:51:43,851][train][INFO] - {"epoch": 189, "train_loss": "2.217", "train_ntokens": "357672", "train_nsentences": "1753.75", "train_wps": "181460", "train_ups": "0.51", "train_wpb": "357672", "train_bsz": "1753.7", "train_num_updates": "90492", "train_lr": "0.000420527", "train_gnorm": "1.552", "train_loss_scale": "0.0312", "train_train_wall": "585", "train_gb_free": "40.1", "train_wall": "152599"}
[2024-10-09 12:51:45,537][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:51:45,687][fairseq.trainer][INFO] - begin training epoch 190
[2024-10-09 12:51:45,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:58:38,368][train_inner][INFO] - {"epoch": 190, "update": 189.225, "loss": "2.215", "ntokens": "356840", "nsentences": "1714.25", "wps": "131937", "ups": "0.37", "wpb": "356840", "bsz": "1714.2", "num_updates": "90600", "lr": "0.00042038", "gnorm": "1.599", "loss_scale": "0.0312", "train_wall": "239", "gb_free": "40.1", "wall": "153014"}
[2024-10-09 13:03:06,452][train_inner][INFO] - {"epoch": 190, "update": 189.643, "loss": "2.216", "ntokens": "358177", "nsentences": "1750.32", "wps": "267269", "ups": "0.75", "wpb": "358177", "bsz": "1750.3", "num_updates": "90800", "lr": "0.000420109", "gnorm": "1.53", "loss_scale": "0.0312", "train_wall": "231", "gb_free": "40.1", "wall": "153282"}
[2024-10-09 13:06:49,591][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 90971 updates
[2024-10-09 13:06:49,595][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 13:06:59,560][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 13:06:59,594][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 190 @ 90971 updates, score None) (writing took 10.002925775945187 seconds)
[2024-10-09 13:06:59,595][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2024-10-09 13:06:59,613][train][INFO] - {"epoch": 190, "train_loss": "2.219", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "187092", "train_ups": "0.52", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "90971", "train_lr": "0.000419876", "train_gnorm": "1.515", "train_loss_scale": "0.0312", "train_train_wall": "536", "train_gb_free": "39.8", "train_wall": "153515"}
[2024-10-09 13:06:59,797][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:06:59,820][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 13:06:59,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:12:41,973][train_inner][INFO] - {"epoch": 191, "update": 190.061, "loss": "2.229", "ntokens": "356849", "nsentences": "1793.1", "wps": "124017", "ups": "0.35", "wpb": "356849", "bsz": "1793.1", "num_updates": "91000", "lr": "0.000419837", "gnorm": "1.49", "loss_scale": "0.0312", "train_wall": "220", "gb_free": "40.6", "wall": "153857"}
[2024-10-09 13:17:36,465][train_inner][INFO] - {"epoch": 191, "update": 190.478, "loss": "2.207", "ntokens": "358417", "nsentences": "1725", "wps": "243491", "ups": "0.68", "wpb": "358417", "bsz": "1725", "num_updates": "91200", "lr": "0.000419565", "gnorm": "1.399", "loss_scale": "0.0312", "train_wall": "261", "gb_free": "39.6", "wall": "154152"}
[2024-10-09 13:21:14,159][train_inner][INFO] - {"epoch": 191, "update": 190.896, "loss": "2.219", "ntokens": "358351", "nsentences": "1765.04", "wps": "329336", "ups": "0.92", "wpb": "358351", "bsz": "1765", "num_updates": "91400", "lr": "0.000419293", "gnorm": "1.346", "loss_scale": "0.0312", "train_wall": "201", "gb_free": "39.6", "wall": "154369"}
[2024-10-09 13:23:00,966][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-09 13:23:00,969][train][INFO] - {"epoch": 191, "train_loss": "2.216", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "178214", "train_ups": "0.5", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "91450", "train_lr": "0.000419226", "train_gnorm": "1.436", "train_loss_scale": "0.0312", "train_train_wall": "565", "train_gb_free": "39.8", "train_wall": "154476"}
[2024-10-09 13:23:01,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:23:01,171][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-09 13:23:01,171][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:31:59,192][train_inner][INFO] - {"epoch": 192, "update": 191.313, "loss": "2.215", "ntokens": "356599", "nsentences": "1796.17", "wps": "110583", "ups": "0.31", "wpb": "356599", "bsz": "1796.2", "num_updates": "91600", "lr": "0.000419022", "gnorm": "1.582", "loss_scale": "0.0312", "train_wall": "317", "gb_free": "40.3", "wall": "155014"}
[2024-10-09 13:34:58,315][train_inner][INFO] - {"epoch": 192, "update": 191.731, "loss": "2.209", "ntokens": "358445", "nsentences": "1717.43", "wps": "400264", "ups": "1.12", "wpb": "358445", "bsz": "1717.4", "num_updates": "91800", "lr": "0.00041875", "gnorm": "1.562", "loss_scale": "0.0312", "train_wall": "175", "gb_free": "39.8", "wall": "155193"}
[2024-10-09 13:37:09,140][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-09 13:37:09,314][train][INFO] - {"epoch": 192, "train_loss": "2.214", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "201968", "train_ups": "0.56", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "91929", "train_lr": "0.000418575", "train_gnorm": "1.587", "train_loss_scale": "0.0312", "train_train_wall": "544", "train_gb_free": "41", "train_wall": "155324"}
[2024-10-09 13:37:10,969][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:37:11,135][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-09 13:37:11,136][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:43:59,531][train_inner][INFO] - {"epoch": 193, "update": 192.148, "loss": "2.22", "ntokens": "356717", "nsentences": "1764.52", "wps": "131824", "ups": "0.37", "wpb": "356717", "bsz": "1764.5", "num_updates": "92000", "lr": "0.000418478", "gnorm": "1.695", "loss_scale": "0.0312", "train_wall": "221", "gb_free": "39.2", "wall": "155735"}
[2024-10-09 13:48:14,146][train_inner][INFO] - {"epoch": 193, "update": 192.566, "loss": "2.203", "ntokens": "358434", "nsentences": "1705.49", "wps": "281588", "ups": "0.79", "wpb": "358434", "bsz": "1705.5", "num_updates": "92200", "lr": "0.000418207", "gnorm": "1.534", "loss_scale": "0.0312", "train_wall": "208", "gb_free": "40.1", "wall": "155989"}
[2024-10-09 13:53:05,295][train_inner][INFO] - {"epoch": 193, "update": 192.983, "loss": "2.221", "ntokens": "358182", "nsentences": "1807.38", "wps": "246108", "ups": "0.69", "wpb": "358182", "bsz": "1807.4", "num_updates": "92400", "lr": "0.000417935", "gnorm": "1.477", "loss_scale": "0.0312", "train_wall": "267", "gb_free": "41.1", "wall": "156280"}
[2024-10-09 13:53:43,215][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-09 13:53:43,221][train][INFO] - {"epoch": 193, "train_loss": "2.211", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "172379", "train_ups": "0.48", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "92408", "train_lr": "0.000417924", "train_gnorm": "1.517", "train_loss_scale": "0.0625", "train_train_wall": "608", "train_gb_free": "39.7", "train_wall": "156318"}
[2024-10-09 13:53:43,517][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:53:43,523][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-09 13:53:43,523][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:02:58,862][train_inner][INFO] - {"epoch": 194, "update": 193.401, "loss": "2.211", "ntokens": "356756", "nsentences": "1776.33", "wps": "120215", "ups": "0.34", "wpb": "356756", "bsz": "1776.3", "num_updates": "92600", "lr": "0.000417663", "gnorm": "1.775", "loss_scale": "0.0625", "train_wall": "313", "gb_free": "39.9", "wall": "156874"}
[2024-10-09 14:07:55,788][train_inner][INFO] - {"epoch": 194, "update": 193.818, "loss": "2.207", "ntokens": "358291", "nsentences": "1715.95", "wps": "241395", "ups": "0.67", "wpb": "358291", "bsz": "1716", "num_updates": "92800", "lr": "0.000417391", "gnorm": "1.605", "loss_scale": "0.0625", "train_wall": "238", "gb_free": "40.1", "wall": "157171"}
[2024-10-09 14:09:17,645][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-09 14:09:17,675][train][INFO] - {"epoch": 194, "train_loss": "2.211", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "183344", "train_ups": "0.51", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "92887", "train_lr": "0.000417273", "train_gnorm": "1.655", "train_loss_scale": "0.0625", "train_train_wall": "579", "train_gb_free": "40.6", "train_wall": "157253"}
[2024-10-09 14:09:17,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:09:17,957][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-09 14:09:17,957][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:17:32,331][train_inner][INFO] - {"epoch": 195, "update": 194.236, "loss": "2.207", "ntokens": "356875", "nsentences": "1732.02", "wps": "123803", "ups": "0.35", "wpb": "356875", "bsz": "1732", "num_updates": "93000", "lr": "0.00041712", "gnorm": "1.722", "loss_scale": "0.0625", "train_wall": "278", "gb_free": "40.1", "wall": "157747"}
[2024-10-09 14:22:04,441][train_inner][INFO] - {"epoch": 195, "update": 194.653, "loss": "2.208", "ntokens": "358379", "nsentences": "1757.65", "wps": "263414", "ups": "0.74", "wpb": "358379", "bsz": "1757.7", "num_updates": "93200", "lr": "0.000416848", "gnorm": "1.368", "loss_scale": "0.0625", "train_wall": "252", "gb_free": "39.6", "wall": "158020"}
[2024-10-09 14:25:43,068][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-09 14:25:43,116][train][INFO] - {"epoch": 195, "train_loss": "2.21", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "173858", "train_ups": "0.49", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "93366", "train_lr": "0.000416622", "train_gnorm": "1.474", "train_loss_scale": "0.0625", "train_train_wall": "681", "train_gb_free": "39.6", "train_wall": "158238"}
[2024-10-09 14:25:43,408][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:25:43,431][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-09 14:25:43,432][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:31:51,475][train_inner][INFO] - {"epoch": 196, "update": 195.071, "loss": "2.221", "ntokens": "356661", "nsentences": "1793.48", "wps": "121518", "ups": "0.34", "wpb": "356661", "bsz": "1793.5", "num_updates": "93400", "lr": "0.000416576", "gnorm": "1.379", "loss_scale": "0.0625", "train_wall": "235", "gb_free": "40.1", "wall": "158607"}
[2024-10-09 14:36:26,850][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-09 14:37:11,872][train_inner][INFO] - {"epoch": 196, "update": 195.491, "loss": "2.202", "ntokens": "358327", "nsentences": "1704.15", "wps": "223727", "ups": "0.62", "wpb": "358326", "bsz": "1704.2", "num_updates": "93600", "lr": "0.000416304", "gnorm": "1.526", "loss_scale": "0.0312", "train_wall": "318", "gb_free": "39.6", "wall": "158927"}
[2024-10-09 14:40:59,868][train_inner][INFO] - {"epoch": 196, "update": 195.908, "loss": "2.217", "ntokens": "358286", "nsentences": "1790.16", "wps": "314388", "ups": "0.88", "wpb": "358286", "bsz": "1790.2", "num_updates": "93800", "lr": "0.000416033", "gnorm": "1.768", "loss_scale": "0.0312", "train_wall": "220", "gb_free": "39.6", "wall": "159155"}
[2024-10-09 14:41:50,117][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-09 14:41:50,141][train][INFO] - {"epoch": 196, "train_loss": "2.21", "train_ntokens": "357672", "train_nsentences": "1754.37", "train_wps": "176799", "train_ups": "0.49", "train_wpb": "357672", "train_bsz": "1754.4", "train_num_updates": "93844", "train_lr": "0.000415973", "train_gnorm": "1.631", "train_loss_scale": "0.0312", "train_train_wall": "607", "train_gb_free": "40.3", "train_wall": "159205"}
[2024-10-09 14:41:50,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:41:50,639][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-09 14:41:50,640][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:49:45,534][train_inner][INFO] - {"epoch": 197, "update": 196.326, "loss": "2.208", "ntokens": "356837", "nsentences": "1773.98", "wps": "135767", "ups": "0.38", "wpb": "356837", "bsz": "1774", "num_updates": "94000", "lr": "0.000415761", "gnorm": "1.424", "loss_scale": "0.0312", "train_wall": "244", "gb_free": "41", "wall": "159681"}
[2024-10-09 14:54:44,802][train_inner][INFO] - {"epoch": 197, "update": 196.743, "loss": "2.215", "ntokens": "358346", "nsentences": "1766.21", "wps": "239545", "ups": "0.67", "wpb": "358346", "bsz": "1766.2", "num_updates": "94200", "lr": "0.000415489", "gnorm": "1.664", "loss_scale": "0.0312", "train_wall": "275", "gb_free": "40.1", "wall": "159980"}
[2024-10-09 14:56:44,353][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-09 14:56:44,370][train][INFO] - {"epoch": 197, "train_loss": "2.21", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "191591", "train_ups": "0.54", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "94323", "train_lr": "0.000415322", "train_gnorm": "1.541", "train_loss_scale": "0.0312", "train_train_wall": "586", "train_gb_free": "40.1", "train_wall": "160100"}
[2024-10-09 14:56:44,527][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:56:44,552][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-09 14:56:44,553][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:03:18,818][train_inner][INFO] - {"epoch": 198, "update": 197.161, "loss": "2.205", "ntokens": "356771", "nsentences": "1751.65", "wps": "138828", "ups": "0.39", "wpb": "356771", "bsz": "1751.7", "num_updates": "94400", "lr": "0.000415217", "gnorm": "1.566", "loss_scale": "0.0312", "train_wall": "205", "gb_free": "39.7", "wall": "160494"}
[2024-10-09 15:07:52,520][train_inner][INFO] - {"epoch": 198, "update": 197.578, "loss": "2.206", "ntokens": "358353", "nsentences": "1745.38", "wps": "261915", "ups": "0.73", "wpb": "358353", "bsz": "1745.4", "num_updates": "94600", "lr": "0.000414946", "gnorm": "1.485", "loss_scale": "0.0312", "train_wall": "237", "gb_free": "39.8", "wall": "160768"}
[2024-10-09 15:11:58,343][train_inner][INFO] - {"epoch": 198, "update": 197.996, "loss": "2.208", "ntokens": "358233", "nsentences": "1739.68", "wps": "291598", "ups": "0.81", "wpb": "358233", "bsz": "1739.7", "num_updates": "94800", "lr": "0.000414674", "gnorm": "1.386", "loss_scale": "0.0312", "train_wall": "243", "gb_free": "39.3", "wall": "161013"}
[2024-10-09 15:12:06,004][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-09 15:12:06,018][train][INFO] - {"epoch": 198, "train_loss": "2.206", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "185894", "train_ups": "0.52", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "94802", "train_lr": "0.000414671", "train_gnorm": "1.472", "train_loss_scale": "0.0312", "train_train_wall": "575", "train_gb_free": "39.6", "train_wall": "161021"}
[2024-10-09 15:12:06,236][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:12:06,240][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-09 15:12:06,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:25:26,876][train_inner][INFO] - {"epoch": 199, "update": 198.413, "loss": "2.204", "ntokens": "356757", "nsentences": "1777.72", "wps": "88249.3", "ups": "0.25", "wpb": "356757", "bsz": "1777.7", "num_updates": "95000", "lr": "0.000414402", "gnorm": "1.526", "loss_scale": "0.0312", "train_wall": "482", "gb_free": "39.8", "wall": "161822"}
[2024-10-09 15:34:19,732][train_inner][INFO] - {"epoch": 199, "update": 198.831, "loss": "2.199", "ntokens": "358231", "nsentences": "1751.93", "wps": "134482", "ups": "0.38", "wpb": "358231", "bsz": "1751.9", "num_updates": "95200", "lr": "0.00041413", "gnorm": "1.475", "loss_scale": "0.0312", "train_wall": "514", "gb_free": "39.8", "wall": "162355"}
[2024-10-09 15:36:48,169][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-09 15:36:48,203][train][INFO] - {"epoch": 199, "train_loss": "2.202", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "115590", "train_ups": "0.32", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "95281", "train_lr": "0.00041402", "train_gnorm": "1.548", "train_loss_scale": "0.0312", "train_train_wall": "1136", "train_gb_free": "39.6", "train_wall": "162503"}
[2024-10-09 15:36:48,425][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:36:48,437][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-09 15:36:48,438][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:46:01,485][train_inner][INFO] - {"epoch": 200, "update": 199.248, "loss": "2.196", "ntokens": "356939", "nsentences": "1702.06", "wps": "101735", "ups": "0.29", "wpb": "356938", "bsz": "1702.1", "num_updates": "95400", "lr": "0.000413859", "gnorm": "1.475", "loss_scale": "0.0312", "train_wall": "383", "gb_free": "40.3", "wall": "163057"}
[2024-10-09 15:53:54,972][train_inner][INFO] - {"epoch": 200, "update": 199.666, "loss": "2.203", "ntokens": "358220", "nsentences": "1777.91", "wps": "151366", "ups": "0.42", "wpb": "358220", "bsz": "1777.9", "num_updates": "95600", "lr": "0.000413587", "gnorm": "1.526", "loss_scale": "0.0625", "train_wall": "265", "gb_free": "39.6", "wall": "163530"}
[2024-10-09 15:57:40,652][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 95760 updates
[2024-10-09 15:57:40,675][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 15:57:55,358][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 15:57:55,370][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 200 @ 95760 updates, score None) (writing took 14.718314716592431 seconds)
[2024-10-09 15:57:55,371][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-09 15:57:55,375][train][INFO] - {"epoch": 200, "train_loss": "2.202", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "135204", "train_ups": "0.38", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "95760", "train_lr": "0.00041337", "train_gnorm": "1.495", "train_loss_scale": "0.0625", "train_train_wall": "636", "train_gb_free": "39.6", "train_wall": "163771"}
[2024-10-09 15:57:55,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:57:55,520][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-09 15:57:55,521][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:03:23,696][train_inner][INFO] - {"epoch": 201, "update": 200.084, "loss": "2.208", "ntokens": "356835", "nsentences": "1749.31", "wps": "125501", "ups": "0.35", "wpb": "356835", "bsz": "1749.3", "num_updates": "95800", "lr": "0.000413315", "gnorm": "1.624", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.2", "wall": "164099"}
[2024-10-09 16:08:55,212][train_inner][INFO] - {"epoch": 201, "update": 200.501, "loss": "2.187", "ntokens": "358351", "nsentences": "1706.97", "wps": "216193", "ups": "0.6", "wpb": "358351", "bsz": "1707", "num_updates": "96000", "lr": "0.000413043", "gnorm": "1.408", "loss_scale": "0.0625", "train_wall": "310", "gb_free": "39.8", "wall": "164430"}
[2024-10-09 16:15:04,515][train_inner][INFO] - {"epoch": 201, "update": 200.919, "loss": "2.209", "ntokens": "358300", "nsentences": "1789.19", "wps": "194076", "ups": "0.54", "wpb": "358300", "bsz": "1789.2", "num_updates": "96200", "lr": "0.000412772", "gnorm": "1.661", "loss_scale": "0.0625", "train_wall": "319", "gb_free": "39.3", "wall": "164800"}
[2024-10-09 16:15:59,605][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-10-09 16:15:59,703][train][INFO] - {"epoch": 201, "train_loss": "2.199", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "158003", "train_ups": "0.44", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "96239", "train_lr": "0.000412719", "train_gnorm": "1.521", "train_loss_scale": "0.0625", "train_train_wall": "744", "train_gb_free": "40.3", "train_wall": "164855"}
[2024-10-09 16:15:59,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:15:59,971][fairseq.trainer][INFO] - begin training epoch 202
[2024-10-09 16:15:59,972][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:26:09,432][train_inner][INFO] - {"epoch": 202, "update": 201.336, "loss": "2.192", "ntokens": "356610", "nsentences": "1745.32", "wps": "107268", "ups": "0.3", "wpb": "356610", "bsz": "1745.3", "num_updates": "96400", "lr": "0.0004125", "gnorm": "1.467", "loss_scale": "0.0625", "train_wall": "308", "gb_free": "39.8", "wall": "165465"}
[2024-10-09 16:30:45,196][train_inner][INFO] - {"epoch": 202, "update": 201.754, "loss": "2.194", "ntokens": "358509", "nsentences": "1741.35", "wps": "260021", "ups": "0.73", "wpb": "358509", "bsz": "1741.3", "num_updates": "96600", "lr": "0.000412228", "gnorm": "1.495", "loss_scale": "0.0625", "train_wall": "268", "gb_free": "39.8", "wall": "165740"}
[2024-10-09 16:33:31,838][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-10-09 16:33:31,854][train][INFO] - {"epoch": 202, "train_loss": "2.196", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "162835", "train_ups": "0.46", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "96718", "train_lr": "0.000412068", "train_gnorm": "1.479", "train_loss_scale": "0.0625", "train_train_wall": "684", "train_gb_free": "39.8", "train_wall": "165907"}
[2024-10-09 16:33:32,084][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:33:32,091][fairseq.trainer][INFO] - begin training epoch 203
[2024-10-09 16:33:32,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:39:37,784][train_inner][INFO] - {"epoch": 203, "update": 202.171, "loss": "2.198", "ntokens": "356676", "nsentences": "1767.7", "wps": "133952", "ups": "0.38", "wpb": "356676", "bsz": "1767.7", "num_updates": "96800", "lr": "0.000411957", "gnorm": "1.478", "loss_scale": "0.0625", "train_wall": "233", "gb_free": "39.7", "wall": "166273"}
[2024-10-09 16:44:24,449][train_inner][INFO] - {"epoch": 203, "update": 202.589, "loss": "2.194", "ntokens": "358260", "nsentences": "1764.64", "wps": "249975", "ups": "0.7", "wpb": "358260", "bsz": "1764.6", "num_updates": "97000", "lr": "0.000411685", "gnorm": "1.551", "loss_scale": "0.0625", "train_wall": "152", "gb_free": "39.3", "wall": "166560"}
[2024-10-09 16:49:31,449][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-10-09 16:49:31,463][train][INFO] - {"epoch": 203, "train_loss": "2.198", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "178540", "train_ups": "0.5", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "97197", "train_lr": "0.000411417", "train_gnorm": "1.586", "train_loss_scale": "0.0625", "train_train_wall": "517", "train_gb_free": "39.3", "train_wall": "166867"}
[2024-10-09 16:49:31,672][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:49:31,715][fairseq.trainer][INFO] - begin training epoch 204
[2024-10-09 16:49:31,716][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:55:24,950][train_inner][INFO] - {"epoch": 204, "update": 203.006, "loss": "2.209", "ntokens": "356860", "nsentences": "1762.3", "wps": "108072", "ups": "0.3", "wpb": "356860", "bsz": "1762.3", "num_updates": "97200", "lr": "0.000411413", "gnorm": "1.625", "loss_scale": "0.0625", "train_wall": "348", "gb_free": "39.6", "wall": "167220"}
[2024-10-09 17:01:53,073][train_inner][INFO] - {"epoch": 204, "update": 203.424, "loss": "2.193", "ntokens": "358144", "nsentences": "1757.96", "wps": "184566", "ups": "0.52", "wpb": "358144", "bsz": "1758", "num_updates": "97400", "lr": "0.000411141", "gnorm": "1.34", "loss_scale": "0.0625", "train_wall": "365", "gb_free": "40.3", "wall": "167608"}
[2024-10-09 17:07:06,588][train_inner][INFO] - {"epoch": 204, "update": 203.841, "loss": "2.194", "ntokens": "358437", "nsentences": "1754.69", "wps": "228687", "ups": "0.64", "wpb": "358437", "bsz": "1754.7", "num_updates": "97600", "lr": "0.00041087", "gnorm": "1.358", "loss_scale": "0.0625", "train_wall": "214", "gb_free": "38.7", "wall": "167922"}
[2024-10-09 17:08:34,041][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-10-09 17:08:34,303][train][INFO] - {"epoch": 204, "train_loss": "2.195", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "149914", "train_ups": "0.42", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "97676", "train_lr": "0.000410766", "train_gnorm": "1.368", "train_loss_scale": "0.125", "train_train_wall": "718", "train_gb_free": "39.8", "train_wall": "168009"}
[2024-10-09 17:08:34,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:08:34,512][fairseq.trainer][INFO] - begin training epoch 205
[2024-10-09 17:08:34,512][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:15:28,451][train_inner][INFO] - {"epoch": 205, "update": 204.259, "loss": "2.197", "ntokens": "356860", "nsentences": "1767.76", "wps": "142218", "ups": "0.4", "wpb": "356860", "bsz": "1767.8", "num_updates": "97800", "lr": "0.000410598", "gnorm": "1.376", "loss_scale": "0.125", "train_wall": "194", "gb_free": "39.6", "wall": "168424"}
[2024-10-09 17:18:39,966][train_inner][INFO] - {"epoch": 205, "update": 204.676, "loss": "2.19", "ntokens": "358233", "nsentences": "1751.63", "wps": "374130", "ups": "1.04", "wpb": "358233", "bsz": "1751.6", "num_updates": "98000", "lr": "0.000410326", "gnorm": "1.387", "loss_scale": "0.125", "train_wall": "147", "gb_free": "39.6", "wall": "168615"}
[2024-10-09 17:19:17,127][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-09 17:20:52,685][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-10-09 17:20:52,727][train][INFO] - {"epoch": 205, "train_loss": "2.193", "train_ntokens": "357673", "train_nsentences": "1753.73", "train_wps": "231531", "train_ups": "0.65", "train_wpb": "357673", "train_bsz": "1753.7", "train_num_updates": "98154", "train_lr": "0.000410117", "train_gnorm": "1.455", "train_loss_scale": "0.0625", "train_train_wall": "371", "train_gb_free": "39.3", "train_wall": "168748"}
[2024-10-09 17:20:53,033][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:20:53,064][fairseq.trainer][INFO] - begin training epoch 206
[2024-10-09 17:20:53,064][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:26:24,852][train_inner][INFO] - {"epoch": 206, "update": 205.096, "loss": "2.195", "ntokens": "356834", "nsentences": "1742.54", "wps": "153520", "ups": "0.43", "wpb": "356834", "bsz": "1742.5", "num_updates": "98200", "lr": "0.000410054", "gnorm": "1.574", "loss_scale": "0.0625", "train_wall": "158", "gb_free": "39.6", "wall": "169080"}
[2024-10-09 17:29:23,337][train_inner][INFO] - {"epoch": 206, "update": 205.514, "loss": "2.184", "ntokens": "358437", "nsentences": "1764.95", "wps": "401654", "ups": "1.12", "wpb": "358437", "bsz": "1765", "num_updates": "98400", "lr": "0.000409783", "gnorm": "1.638", "loss_scale": "0.0625", "train_wall": "175", "gb_free": "39.6", "wall": "169258"}
[2024-10-09 17:32:34,803][train_inner][INFO] - {"epoch": 206, "update": 205.931, "loss": "2.202", "ntokens": "358201", "nsentences": "1749.33", "wps": "374191", "ups": "1.04", "wpb": "358200", "bsz": "1749.3", "num_updates": "98600", "lr": "0.000409511", "gnorm": "1.482", "loss_scale": "0.0625", "train_wall": "188", "gb_free": "40.1", "wall": "169450"}
[2024-10-09 17:33:13,247][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-10-09 17:33:13,258][train][INFO] - {"epoch": 206, "train_loss": "2.193", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "231357", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "98633", "train_lr": "0.000409466", "train_gnorm": "1.547", "train_loss_scale": "0.0625", "train_train_wall": "447", "train_gb_free": "39.6", "train_wall": "169488"}
[2024-10-09 17:33:13,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:33:13,453][fairseq.trainer][INFO] - begin training epoch 207
[2024-10-09 17:33:13,454][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:40:39,015][train_inner][INFO] - {"epoch": 207, "update": 206.349, "loss": "2.189", "ntokens": "356753", "nsentences": "1747.09", "wps": "147356", "ups": "0.41", "wpb": "356753", "bsz": "1747.1", "num_updates": "98800", "lr": "0.000409239", "gnorm": "1.61", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "40.6", "wall": "169934"}
[2024-10-09 17:44:01,659][train_inner][INFO] - {"epoch": 207, "update": 206.766, "loss": "2.199", "ntokens": "358356", "nsentences": "1770.83", "wps": "353699", "ups": "0.99", "wpb": "358356", "bsz": "1770.8", "num_updates": "99000", "lr": "0.000408967", "gnorm": "1.236", "loss_scale": "0.0625", "train_wall": "199", "gb_free": "39.3", "wall": "170137"}
[2024-10-09 17:45:47,195][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-10-09 17:45:47,227][train][INFO] - {"epoch": 207, "train_loss": "2.193", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "227237", "train_ups": "0.64", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "99112", "train_lr": "0.000408815", "train_gnorm": "1.395", "train_loss_scale": "0.0625", "train_train_wall": "467", "train_gb_free": "39.7", "train_wall": "170242"}
[2024-10-09 17:45:47,421][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:45:47,435][fairseq.trainer][INFO] - begin training epoch 208
[2024-10-09 17:45:47,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:51:50,187][train_inner][INFO] - {"epoch": 208, "update": 207.184, "loss": "2.188", "ntokens": "356754", "nsentences": "1714.62", "wps": "152296", "ups": "0.43", "wpb": "356754", "bsz": "1714.6", "num_updates": "99200", "lr": "0.000408696", "gnorm": "1.538", "loss_scale": "0.0625", "train_wall": "194", "gb_free": "39.8", "wall": "170605"}
[2024-10-09 17:54:46,586][train_inner][INFO] - {"epoch": 208, "update": 207.601, "loss": "2.189", "ntokens": "358272", "nsentences": "1769.43", "wps": "406227", "ups": "1.13", "wpb": "358272", "bsz": "1769.4", "num_updates": "99400", "lr": "0.000408424", "gnorm": "1.366", "loss_scale": "0.0625", "train_wall": "173", "gb_free": "39.8", "wall": "170782"}
[2024-10-09 17:58:03,409][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-10-09 17:58:03,446][train][INFO] - {"epoch": 208, "train_loss": "2.189", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "232713", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "99591", "train_lr": "0.000408164", "train_gnorm": "1.452", "train_loss_scale": "0.0625", "train_train_wall": "457", "train_gb_free": "39.8", "train_wall": "170979"}
[2024-10-09 17:58:04,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:58:04,140][fairseq.trainer][INFO] - begin training epoch 209
[2024-10-09 17:58:04,147][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:03:10,887][train_inner][INFO] - {"epoch": 209, "update": 208.019, "loss": "2.191", "ntokens": "356810", "nsentences": "1749.6", "wps": "141508", "ups": "0.4", "wpb": "356810", "bsz": "1749.6", "num_updates": "99600", "lr": "0.000408152", "gnorm": "1.414", "loss_scale": "0.0625", "train_wall": "221", "gb_free": "39.6", "wall": "171286"}
[2024-10-09 18:05:49,534][train_inner][INFO] - {"epoch": 209, "update": 208.436, "loss": "2.184", "ntokens": "358288", "nsentences": "1761.77", "wps": "451692", "ups": "1.26", "wpb": "358288", "bsz": "1761.8", "num_updates": "99800", "lr": "0.00040788", "gnorm": "1.381", "loss_scale": "0.0625", "train_wall": "150", "gb_free": "40.3", "wall": "171445"}
[2024-10-09 18:09:01,967][train_inner][INFO] - {"epoch": 209, "update": 208.854, "loss": "2.189", "ntokens": "358427", "nsentences": "1755.7", "wps": "372536", "ups": "1.04", "wpb": "358427", "bsz": "1755.7", "num_updates": "100000", "lr": "0.000407609", "gnorm": "1.599", "loss_scale": "0.0625", "train_wall": "179", "gb_free": "39.3", "wall": "171637"}
[2024-10-09 18:09:01,977][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 100000 updates
[2024-10-09 18:09:01,979][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_209_100000.pt
[2024-10-09 18:09:05,022][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_209_100000.pt
[2024-10-09 18:09:09,749][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_209_100000.pt (epoch 209 @ 100000 updates, score None) (writing took 7.772450238466263 seconds)
[2024-10-09 18:10:15,061][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-10-09 18:10:15,080][train][INFO] - {"epoch": 209, "train_loss": "2.187", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "234176", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "100070", "train_lr": "0.000407514", "train_gnorm": "1.484", "train_loss_scale": "0.0625", "train_train_wall": "421", "train_gb_free": "40.8", "train_wall": "171710"}
[2024-10-09 18:10:15,234][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:10:15,248][fairseq.trainer][INFO] - begin training epoch 210
[2024-10-09 18:10:15,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:16:54,636][train_inner][INFO] - {"epoch": 210, "update": 209.271, "loss": "2.179", "ntokens": "356649", "nsentences": "1742.78", "wps": "150911", "ups": "0.42", "wpb": "356649", "bsz": "1742.8", "num_updates": "100200", "lr": "0.000407337", "gnorm": "1.384", "loss_scale": "0.125", "train_wall": "193", "gb_free": "39", "wall": "172110"}
[2024-10-09 18:19:55,272][train_inner][INFO] - {"epoch": 210, "update": 209.689, "loss": "2.184", "ntokens": "358396", "nsentences": "1718.45", "wps": "396852", "ups": "1.11", "wpb": "358396", "bsz": "1718.5", "num_updates": "100400", "lr": "0.000407065", "gnorm": "1.353", "loss_scale": "0.125", "train_wall": "177", "gb_free": "39.6", "wall": "172290"}
[2024-10-09 18:22:28,709][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 100549 updates
[2024-10-09 18:22:28,710][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 18:22:32,083][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt
[2024-10-09 18:22:32,085][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400/ckpt/checkpoint_last.pt (epoch 210 @ 100549 updates, score None) (writing took 3.376486544497311 seconds)
[2024-10-09 18:22:32,086][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-10-09 18:22:32,097][train][INFO] - {"epoch": 210, "train_loss": "2.186", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "232463", "train_ups": "0.65", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "100549", "train_lr": "0.000406863", "train_gnorm": "1.383", "train_loss_scale": "0.125", "train_train_wall": "457", "train_gb_free": "39.7", "train_wall": "172447"}
[2024-10-09 18:22:32,170][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:22:32,175][fairseq.trainer][INFO] - begin training epoch 211
[2024-10-09 18:22:32,175][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:27:50,900][train_inner][INFO] - {"epoch": 211, "update": 210.106, "loss": "2.192", "ntokens": "356755", "nsentences": "1787.29", "wps": "150017", "ups": "0.42", "wpb": "356755", "bsz": "1787.3", "num_updates": "100600", "lr": "0.000406793", "gnorm": "1.549", "loss_scale": "0.125", "train_wall": "200", "gb_free": "39.6", "wall": "172766"}
[2024-10-09 18:30:41,188][train_inner][INFO] - {"epoch": 211, "update": 210.524, "loss": "2.184", "ntokens": "358380", "nsentences": "1784.06", "wps": "420922", "ups": "1.17", "wpb": "358380", "bsz": "1784.1", "num_updates": "100800", "lr": "0.000406522", "gnorm": "1.348", "loss_scale": "0.125", "train_wall": "167", "gb_free": "40.1", "wall": "172936"}
[2024-10-09 18:33:47,693][train_inner][INFO] - {"epoch": 211, "update": 210.942, "loss": "2.187", "ntokens": "358285", "nsentences": "1754.91", "wps": "384221", "ups": "1.07", "wpb": "358285", "bsz": "1754.9", "num_updates": "101000", "lr": "0.00040625", "gnorm": "1.351", "loss_scale": "0.125", "train_wall": "183", "gb_free": "39.3", "wall": "173123"}
[2024-10-09 18:34:30,188][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-10-09 18:34:30,196][train][INFO] - {"epoch": 211, "train_loss": "2.183", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "238583", "train_ups": "0.67", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "101028", "train_lr": "0.000406212", "train_gnorm": "1.39", "train_loss_scale": "0.125", "train_train_wall": "440", "train_gb_free": "39.9", "train_wall": "173165"}
[2024-10-09 18:34:30,394][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:34:30,422][fairseq.trainer][INFO] - begin training epoch 212
[2024-10-09 18:34:30,423][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:41:51,482][train_inner][INFO] - {"epoch": 212, "update": 211.359, "loss": "2.173", "ntokens": "356861", "nsentences": "1723.19", "wps": "147529", "ups": "0.41", "wpb": "356861", "bsz": "1723.2", "num_updates": "101200", "lr": "0.000405978", "gnorm": "1.354", "loss_scale": "0.125", "train_wall": "210", "gb_free": "40.2", "wall": "173607"}
[2024-10-09 18:44:54,789][train_inner][INFO] - {"epoch": 212, "update": 211.777, "loss": "2.183", "ntokens": "358218", "nsentences": "1761.06", "wps": "390869", "ups": "1.09", "wpb": "358218", "bsz": "1761.1", "num_updates": "101400", "lr": "0.000405707", "gnorm": "1.64", "loss_scale": "0.125", "train_wall": "179", "gb_free": "39.3", "wall": "173790"}
[2024-10-09 18:46:54,318][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-10-09 18:46:54,351][train][INFO] - {"epoch": 212, "train_loss": "2.181", "train_ntokens": "357674", "train_nsentences": "1753.71", "train_wps": "230234", "train_ups": "0.64", "train_wpb": "357674", "train_bsz": "1753.7", "train_num_updates": "101507", "train_lr": "0.000405561", "train_gnorm": "1.46", "train_loss_scale": "0.125", "train_train_wall": "465", "train_gb_free": "39.2", "train_wall": "173909"}
[2024-10-09 18:46:54,573][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:46:54,599][fairseq.trainer][INFO] - begin training epoch 213
[2024-10-09 18:46:54,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:52:56,032][train_inner][INFO] - {"epoch": 213, "update": 212.194, "loss": "2.179", "ntokens": "356798", "nsentences": "1730.6", "wps": "148284", "ups": "0.42", "wpb": "356798", "bsz": "1730.6", "num_updates": "101600", "lr": "0.000405435", "gnorm": "1.372", "loss_scale": "0.125", "train_wall": "200", "gb_free": "39.1", "wall": "174271"}
[2024-10-09 18:56:01,499][train_inner][INFO] - {"epoch": 213, "update": 212.612, "loss": "2.183", "ntokens": "358410", "nsentences": "1779.09", "wps": "386531", "ups": "1.08", "wpb": "358410", "bsz": "1779.1", "num_updates": "101800", "lr": "0.000405163", "gnorm": "1.608", "loss_scale": "0.125", "train_wall": "181", "gb_free": "39.6", "wall": "174457"}
