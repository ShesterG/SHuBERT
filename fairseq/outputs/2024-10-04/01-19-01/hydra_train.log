[2024-10-04 01:19:46,995][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19285', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:47,367][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12732', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:47,715][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11132', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:48,117][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19761', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:48,765][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12773', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:49,187][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14385', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:50,245][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15352', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:50,902][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:50,904][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:50,904][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:50,904][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:50,905][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:50,918][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:51,998][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:52,007][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:52,007][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:52,007][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:52,008][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:52,009][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:52,706][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16307', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 01:19:53,248][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:53,258][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:53,258][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:53,258][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:53,259][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:53,260][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:53,648][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:53,654][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:53,654][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:53,654][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:53,655][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:53,656][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:54,703][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:54,705][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:54,705][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:54,705][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:54,730][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:54,731][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:54,774][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:54,776][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:54,776][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:54,776][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:54,781][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:54,782][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:55,916][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:19:57,034][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:19:57,036][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:19:57,036][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:19:57,036][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:19:57,037][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:19:57,065][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:19:59,127][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:19:59,738][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:20:02,920][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:20:09,206][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:20:10,700][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:20:15,115][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:20:15,215][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 01:20:15,290][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 01:20:15,291][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 01:20:15,291][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 01:20:15,292][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 01:20:15,292][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 01:20:48,972][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:24:23,539][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:24:23,541][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:24:23,541][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:24:23,565][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:24:23,589][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:24:23,590][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:24:23,590][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:24:27,265][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:25:09,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:25:09,220][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:25:09,221][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:25:12,050][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:25:12,051][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:25:12,051][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:25:12,052][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:25:12,053][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:25:12,053][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:25:12,053][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:25:52,196][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:34:56,799][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:34:56,802][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:34:56,803][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:34:56,803][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:34:56,810][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:34:56,810][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:34:56,810][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:35:07,996][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:35:11,603][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:35:11,615][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:35:11,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:35:23,888][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:35:23,921][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,921][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,921][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:23,922][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:35:23,965][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:35:23,973][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:35:24,210][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:35:24,210][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:35:24,213][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:35:31,790][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,798][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,799][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:35:31,799][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:35:31,801][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:35:31,802][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:35:31,810][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:35:31,811][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:35:31,811][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:35:33,255][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:35:39,648][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:36:11,005][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:11,281][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:11,282][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:11,333][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:36:11,353][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:36:11,586][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:11,586][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:11,586][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:36:14,424][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:36:26,548][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:26,651][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:26,677][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:36:26,677][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:36:26,736][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:26,769][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:26,769][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:36:29,909][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:30,209][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,209][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 01:36:30,210][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 01:36:30,285][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 01:36:30,293][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 01:36:30,333][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:36:30,342][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:30,342][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 01:36:30,342][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-04 01:36:30,351][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:36:30,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:36:39,758][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:36:42,463][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 01:37:15,705][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:37:15,717][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:37:15,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:37:34,390][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:37:34,402][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:37:34,403][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:37:56,306][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:37:56,319][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:37:56,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:38:05,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:38:05,792][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:38:05,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:38:07,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 01:38:07,663][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-04 01:38:07,670][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 01:56:54,303][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-04 01:56:56,463][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-04 01:56:59,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-04 01:57:00,547][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-04 01:57:04,065][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-04 01:57:22,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-04 01:57:23,372][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-04 01:57:25,880][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-04 01:58:44,952][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-04 01:58:46,508][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-04 02:11:32,452][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.534", "ntokens": "263888", "nsentences": "1773.98", "wps": "61950.9", "ups": "0.23", "wpb": "263888", "bsz": "1774", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "782", "gb_free": "39.1", "wall": "2160"}
[2024-10-04 02:11:32,956][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.534", "ntokens": "263888", "nsentences": "1773.98", "wps": "60308.5", "ups": "0.23", "wpb": "263888", "bsz": "1774", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "924", "gb_free": "39.1", "wall": "2169"}
[2024-10-04 02:25:12,255][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "4.932", "ntokens": "264190", "nsentences": "1717.45", "wps": "64505.2", "ups": "0.24", "wpb": "264190", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.702", "loss_scale": "4", "train_wall": "467", "gb_free": "39.6", "wall": "2988"}
[2024-10-04 02:25:13,654][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "4.932", "ntokens": "264190", "nsentences": "1717.45", "wps": "64342.5", "ups": "0.24", "wpb": "264190", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.702", "loss_scale": "4", "train_wall": "437", "gb_free": "39.6", "wall": "2982"}
[2024-10-04 02:27:49,370][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-04 02:27:49,710][train][INFO] - {"epoch": 1, "train_loss": "5.108", "train_ntokens": "263580", "train_nsentences": "1751.41", "train_wps": "68315.4", "train_ups": "0.26", "train_wpb": "263580", "train_bsz": "1751.4", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.762", "train_loss_scale": "4", "train_train_wall": "1372", "train_gb_free": "40.1", "train_wall": "3138"}
[2024-10-04 02:27:50,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 02:27:50,231][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-04 02:27:50,238][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 02:29:04,583][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-04 02:29:04,650][train][INFO] - {"epoch": 1, "train_loss": "5.108", "train_ntokens": "263580", "train_nsentences": "1751.41", "train_wps": "64851.6", "train_ups": "0.25", "train_wpb": "263580", "train_bsz": "1751.4", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.762", "train_loss_scale": "4", "train_train_wall": "1622", "train_gb_free": "40.1", "train_wall": "3221"}
[2024-10-04 02:29:04,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 02:29:04,734][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-04 02:29:04,734][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 02:40:27,954][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.248", "ntokens": "263025", "nsentences": "1773.64", "wps": "57539.7", "ups": "0.22", "wpb": "263025", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.603", "loss_scale": "4", "train_wall": "363", "gb_free": "39.6", "wall": "3896"}
[2024-10-04 02:51:18,653][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.248", "ntokens": "263025", "nsentences": "1773.64", "wps": "33587.3", "ups": "0.13", "wpb": "263025", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.603", "loss_scale": "4", "train_wall": "953", "gb_free": "39.6", "wall": "4555"}
[2024-10-04 02:58:53,470][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "3.762", "ntokens": "264037", "nsentences": "1758.35", "wps": "47771.8", "ups": "0.18", "wpb": "264037", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.561", "loss_scale": "4", "train_wall": "528", "gb_free": "39.1", "wall": "5002"}
[2024-10-04 03:08:17,354][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "3.762", "ntokens": "264037", "nsentences": "1758.35", "wps": "51852.8", "ups": "0.2", "wpb": "264037", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.561", "loss_scale": "4", "train_wall": "555", "gb_free": "39.1", "wall": "5573"}
[2024-10-04 03:08:25,801][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-04 03:08:25,916][train][INFO] - {"epoch": 2, "train_loss": "3.749", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "51835.2", "train_ups": "0.2", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "0.604", "train_loss_scale": "4", "train_train_wall": "1257", "train_gb_free": "39.8", "train_wall": "5574"}
[2024-10-04 03:08:28,526][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 03:08:28,584][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-04 03:08:28,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 03:12:07,298][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-04 03:12:07,349][train][INFO] - {"epoch": 2, "train_loss": "3.749", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "48893.9", "train_ups": "0.19", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "0.604", "train_loss_scale": "4", "train_train_wall": "1501", "train_gb_free": "39.8", "train_wall": "5803"}
[2024-10-04 03:12:07,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 03:12:07,935][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-04 03:12:07,946][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 03:23:51,757][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.36", "ntokens": "262816", "nsentences": "1775.94", "wps": "35087.7", "ups": "0.13", "wpb": "262816", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.685", "loss_scale": "4", "train_wall": "736", "gb_free": "39.2", "wall": "6500"}
[2024-10-04 03:26:17,043][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.36", "ntokens": "262816", "nsentences": "1775.94", "wps": "48734.1", "ups": "0.19", "wpb": "262816", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.685", "loss_scale": "4", "train_wall": "495", "gb_free": "39.2", "wall": "6652"}
[2024-10-04 03:38:25,986][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "2.985", "ntokens": "264038", "nsentences": "1729.12", "wps": "72519.5", "ups": "0.27", "wpb": "264038", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.908", "loss_scale": "4", "train_wall": "720", "gb_free": "39.6", "wall": "7381"}
[2024-10-04 03:38:26,073][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "2.985", "ntokens": "264038", "nsentences": "1729.12", "wps": "60401.1", "ups": "0.23", "wpb": "264038", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.909", "loss_scale": "4", "train_wall": "870", "gb_free": "39.6", "wall": "7374"}
[2024-10-04 03:49:29,305][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "2.672", "ntokens": "264035", "nsentences": "1741.91", "wps": "79699.6", "ups": "0.3", "wpb": "264035", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.139", "loss_scale": "4", "train_wall": "653", "gb_free": "39.4", "wall": "8037"}
[2024-10-04 03:49:29,306][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "2.672", "ntokens": "264035", "nsentences": "1741.91", "wps": "79657.9", "ups": "0.3", "wpb": "264035", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.138", "loss_scale": "4", "train_wall": "656", "gb_free": "39.4", "wall": "8045"}
[2024-10-04 03:51:09,762][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-04 03:51:09,865][train][INFO] - {"epoch": 3, "train_loss": "2.846", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "49218.6", "train_ups": "0.19", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.002", "train_loss_scale": "4", "train_train_wall": "1839", "train_gb_free": "39.8", "train_wall": "8138"}
[2024-10-04 03:51:10,881][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 03:51:10,950][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-04 03:51:10,957][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 03:51:12,903][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-04 03:51:12,954][train][INFO] - {"epoch": 3, "train_loss": "2.846", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "53799.4", "train_ups": "0.2", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.001", "train_loss_scale": "4", "train_train_wall": "1748", "train_gb_free": "39.8", "train_wall": "8149"}
[2024-10-04 03:51:13,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 03:51:13,711][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-04 03:51:13,762][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 04:11:50,721][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "2.417", "ntokens": "262249", "nsentences": "1810.06", "wps": "39115.4", "ups": "0.15", "wpb": "262249", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.316", "loss_scale": "4", "train_wall": "676", "gb_free": "40.7", "wall": "9378"}
[2024-10-04 04:11:50,723][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "2.417", "ntokens": "262249", "nsentences": "1810.06", "wps": "39114.3", "ups": "0.15", "wpb": "262249", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.316", "loss_scale": "4", "train_wall": "669", "gb_free": "40.7", "wall": "9386"}
[2024-10-04 04:23:47,006][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "2.212", "ntokens": "264618", "nsentences": "1707.52", "wps": "73954.8", "ups": "0.28", "wpb": "264618", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.399", "loss_scale": "4", "train_wall": "334", "gb_free": "39.8", "wall": "10095"}
[2024-10-04 04:23:48,187][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "2.212", "ntokens": "264618", "nsentences": "1707.52", "wps": "73772.4", "ups": "0.28", "wpb": "264618", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.404", "loss_scale": "4", "train_wall": "343", "gb_free": "39.8", "wall": "10104"}
[2024-10-04 04:29:21,853][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-04 04:29:22,210][train][INFO] - {"epoch": 4, "train_loss": "2.247", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "55088.5", "train_ups": "0.21", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.385", "train_loss_scale": "4", "train_train_wall": "1219", "train_gb_free": "40.1", "train_wall": "10430"}
[2024-10-04 04:29:22,700][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 04:29:22,819][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-04 04:29:22,819][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 04:29:27,328][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-04 04:29:27,356][train][INFO] - {"epoch": 4, "train_loss": "2.247", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "55031.3", "train_ups": "0.21", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.426", "train_loss_scale": "4", "train_train_wall": "1229", "train_gb_free": "40.1", "train_wall": "10443"}
[2024-10-04 04:29:27,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 04:29:27,971][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-04 04:29:27,982][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 04:45:08,325][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "2.045", "ntokens": "262854", "nsentences": "1755.84", "wps": "41041.6", "ups": "0.16", "wpb": "262854", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.378", "loss_scale": "4", "train_wall": "649", "gb_free": "39.6", "wall": "11376"}
[2024-10-04 04:45:08,327][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "2.046", "ntokens": "262854", "nsentences": "1755.84", "wps": "41075.9", "ups": "0.16", "wpb": "262854", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.532", "loss_scale": "4", "train_wall": "757", "gb_free": "39.6", "wall": "11384"}
[2024-10-04 04:50:03,736][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-04 04:51:30,711][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-04 04:55:14,531][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-04 04:59:58,770][train_inner][INFO] - {"epoch": 5, "update": 4.608, "loss": "1.912", "ntokens": "263591", "nsentences": "1792.53", "wps": "59228.9", "ups": "0.22", "wpb": "263591", "bsz": "1792.5", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.451", "loss_scale": "2", "train_wall": "886", "gb_free": "39.2", "wall": "12274"}
[2024-10-04 04:59:58,774][train_inner][INFO] - {"epoch": 5, "update": 4.605, "loss": "1.91", "ntokens": "263642", "nsentences": "1789.58", "wps": "59257.4", "ups": "0.22", "wpb": "263642", "bsz": "1789.6", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.423", "loss_scale": "4", "train_wall": "884", "gb_free": "39.2", "wall": "12266"}
[2024-10-04 05:00:00,934][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-04 05:10:03,779][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-04 05:10:03,855][train][INFO] - {"epoch": 5, "train_loss": "1.888", "train_ntokens": "263382", "train_nsentences": "1754.84", "train_wps": "51563.6", "train_ups": "0.2", "train_wpb": "263382", "train_bsz": "1754.8", "train_num_updates": "2388", "train_lr": "3.73125e-05", "train_gnorm": "1.405", "train_loss_scale": "2", "train_train_wall": "1884", "train_gb_free": "39.2", "train_wall": "12880"}
[2024-10-04 05:10:04,458][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 05:10:04,497][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-04 05:10:04,502][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 05:10:10,620][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-04 05:10:10,674][train][INFO] - {"epoch": 5, "train_loss": "1.887", "train_ntokens": "263404", "train_nsentences": "1754.14", "train_wps": "51316.5", "train_ups": "0.19", "train_wpb": "263404", "train_bsz": "1754.1", "train_num_updates": "2388", "train_lr": "3.73125e-05", "train_gnorm": "1.384", "train_loss_scale": "2", "train_train_wall": "1804", "train_gb_free": "39.2", "train_wall": "12879"}
[2024-10-04 05:10:11,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 05:10:11,200][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-04 05:10:11,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 05:20:03,189][train_inner][INFO] - {"epoch": 6, "update": 5.025, "loss": "1.805", "ntokens": "263035", "nsentences": "1709.1", "wps": "43681.1", "ups": "0.17", "wpb": "263035", "bsz": "1709.1", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.361", "loss_scale": "2", "train_wall": "630", "gb_free": "40.3", "wall": "13479"}
[2024-10-04 05:20:04,514][train_inner][INFO] - {"epoch": 6, "update": 5.025, "loss": "1.804", "ntokens": "263037", "nsentences": "1710.36", "wps": "43631.6", "ups": "0.17", "wpb": "263037", "bsz": "1710.4", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.4", "loss_scale": "2", "train_wall": "649", "gb_free": "40.3", "wall": "13473"}
[2024-10-04 05:32:34,505][train_inner][INFO] - {"epoch": 6, "update": 5.443, "loss": "1.716", "ntokens": "263982", "nsentences": "1762.68", "wps": "70394.2", "ups": "0.27", "wpb": "263982", "bsz": "1762.7", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.471", "loss_scale": "2", "train_wall": "745", "gb_free": "40.1", "wall": "14229"}
[2024-10-04 05:32:37,209][train_inner][INFO] - {"epoch": 6, "update": 5.443, "loss": "1.715", "ntokens": "263982", "nsentences": "1762.68", "wps": "70144.2", "ups": "0.27", "wpb": "263982", "bsz": "1762.7", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.499", "loss_scale": "2", "train_wall": "746", "gb_free": "40.1", "wall": "14225"}
[2024-10-04 05:45:18,160][train_inner][INFO] - {"epoch": 6, "update": 5.86, "loss": "1.646", "ntokens": "263934", "nsentences": "1758.96", "wps": "69146", "ups": "0.26", "wpb": "263934", "bsz": "1759", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.287", "loss_scale": "2", "train_wall": "689", "gb_free": "39.6", "wall": "14994"}
[2024-10-04 05:45:24,224][train_inner][INFO] - {"epoch": 6, "update": 5.86, "loss": "1.645", "ntokens": "263934", "nsentences": "1758.96", "wps": "68822.4", "ups": "0.26", "wpb": "263934", "bsz": "1759", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.36", "loss_scale": "2", "train_wall": "710", "gb_free": "39.6", "wall": "14992"}
[2024-10-04 05:49:26,320][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-04 05:49:26,380][train][INFO] - {"epoch": 6, "train_loss": "1.672", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "53436.5", "train_ups": "0.2", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "2867", "train_lr": "4.47969e-05", "train_gnorm": "1.429", "train_loss_scale": "2", "train_train_wall": "1751", "train_gb_free": "39.4", "train_wall": "15242"}
[2024-10-04 05:49:26,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 05:49:26,877][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-04 05:49:26,882][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 05:49:33,986][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-04 05:49:34,027][train][INFO] - {"epoch": 6, "train_loss": "1.672", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "53417.3", "train_ups": "0.2", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "2867", "train_lr": "4.47969e-05", "train_gnorm": "1.433", "train_loss_scale": "2", "train_train_wall": "1774", "train_gb_free": "39.4", "train_wall": "15242"}
[2024-10-04 05:49:34,691][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 05:49:34,729][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-04 05:49:34,758][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 06:08:00,359][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 06:10:38,579][train_inner][INFO] - {"epoch": 7, "update": 6.28, "loss": "1.587", "ntokens": "263050", "nsentences": "1738.26", "wps": "34741.5", "ups": "0.13", "wpb": "263050", "bsz": "1738.3", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.43", "loss_scale": "1", "train_wall": "1024", "gb_free": "40.3", "wall": "16507"}
[2024-10-04 06:10:40,554][train_inner][INFO] - {"epoch": 7, "update": 6.278, "loss": "1.588", "ntokens": "263049", "nsentences": "1737.32", "wps": "34557.6", "ups": "0.13", "wpb": "263049", "bsz": "1737.3", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.403", "loss_scale": "2", "train_wall": "1005", "gb_free": "39.1", "wall": "16517"}
[2024-10-04 06:23:50,676][train_inner][INFO] - {"epoch": 7, "update": 6.695, "loss": "1.54", "ntokens": "264285", "nsentences": "1716.78", "wps": "66900.5", "ups": "0.25", "wpb": "264285", "bsz": "1716.8", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.341", "loss_scale": "2", "train_wall": "371", "gb_free": "39.2", "wall": "17307"}
[2024-10-04 06:23:57,794][train_inner][INFO] - {"epoch": 7, "update": 6.697, "loss": "1.538", "ntokens": "264286", "nsentences": "1716.22", "wps": "66137.6", "ups": "0.25", "wpb": "264286", "bsz": "1716.2", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.175", "loss_scale": "1", "train_wall": "402", "gb_free": "40.1", "wall": "17306"}
[2024-10-04 06:32:07,665][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-04 06:32:07,791][train][INFO] - {"epoch": 7, "train_loss": "1.54", "train_ntokens": "263525", "train_nsentences": "1753.71", "train_wps": "49282.1", "train_ups": "0.19", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "3346", "train_lr": "5.22813e-05", "train_gnorm": "1.333", "train_loss_scale": "2", "train_train_wall": "1612", "train_gb_free": "39.3", "train_wall": "17804"}
[2024-10-04 06:32:08,294][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 06:32:08,356][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-04 06:32:08,362][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 06:32:11,848][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-04 06:32:11,902][train][INFO] - {"epoch": 7, "train_loss": "1.54", "train_ntokens": "263518", "train_nsentences": "1754.9", "train_wps": "49245.6", "train_ups": "0.19", "train_wpb": "263518", "train_bsz": "1754.9", "train_num_updates": "3345", "train_lr": "5.22656e-05", "train_gnorm": "1.311", "train_loss_scale": "1", "train_train_wall": "1669", "train_gb_free": "39.3", "train_wall": "17800"}
[2024-10-04 06:32:12,452][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 06:32:12,507][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-04 06:32:12,550][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 06:43:15,727][train_inner][INFO] - {"epoch": 8, "update": 7.113, "loss": "1.5", "ntokens": "262663", "nsentences": "1777.61", "wps": "45091.5", "ups": "0.17", "wpb": "262663", "bsz": "1777.6", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.324", "loss_scale": "2", "train_wall": "638", "gb_free": "40.1", "wall": "18472"}
[2024-10-04 06:43:17,573][train_inner][INFO] - {"epoch": 8, "update": 7.115, "loss": "1.5", "ntokens": "262654", "nsentences": "1779.12", "wps": "45294", "ups": "0.17", "wpb": "262654", "bsz": "1779.1", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.28", "loss_scale": "1", "train_wall": "703", "gb_free": "39.2", "wall": "18466"}
[2024-10-04 06:57:12,943][train_inner][INFO] - {"epoch": 8, "update": 7.53, "loss": "1.465", "ntokens": "264287", "nsentences": "1741.84", "wps": "63137.8", "ups": "0.24", "wpb": "264287", "bsz": "1741.8", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.227", "loss_scale": "2", "train_wall": "741", "gb_free": "39.2", "wall": "19309"}
[2024-10-04 06:57:16,262][train_inner][INFO] - {"epoch": 8, "update": 7.532, "loss": "1.464", "ntokens": "264281", "nsentences": "1741.72", "wps": "63023.2", "ups": "0.24", "wpb": "264281", "bsz": "1741.7", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.316", "loss_scale": "1", "train_wall": "776", "gb_free": "40.1", "wall": "19304"}
[2024-10-04 07:11:58,521][train_inner][INFO] - {"epoch": 8, "update": 7.95, "loss": "1.434", "ntokens": "263938", "nsentences": "1756.68", "wps": "59833.3", "ups": "0.23", "wpb": "263938", "bsz": "1756.7", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.139", "loss_scale": "1", "train_wall": "879", "gb_free": "39.2", "wall": "20187"}
[2024-10-04 07:12:02,438][train_inner][INFO] - {"epoch": 8, "update": 7.948, "loss": "1.435", "ntokens": "263959", "nsentences": "1755.26", "wps": "59351.6", "ups": "0.22", "wpb": "263959", "bsz": "1755.3", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.178", "loss_scale": "2", "train_wall": "886", "gb_free": "40.1", "wall": "20198"}
[2024-10-04 07:12:32,549][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-04 07:12:32,567][train][INFO] - {"epoch": 8, "train_loss": "1.453", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "52063.7", "train_ups": "0.2", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "3825", "train_lr": "5.97656e-05", "train_gnorm": "1.198", "train_loss_scale": "2", "train_train_wall": "1811", "train_gb_free": "39.3", "train_wall": "20229"}
[2024-10-04 07:12:32,645][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-04 07:12:32,699][train][INFO] - {"epoch": 8, "train_loss": "1.452", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "52149.2", "train_ups": "0.2", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "3824", "train_lr": "5.975e-05", "train_gnorm": "1.214", "train_loss_scale": "1", "train_train_wall": "1899", "train_gb_free": "39.3", "train_wall": "20221"}
[2024-10-04 07:12:32,994][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 07:12:33,027][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-04 07:12:33,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 07:12:33,216][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 07:12:33,259][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-04 07:12:33,274][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 07:34:55,788][train_inner][INFO] - {"epoch": 9, "update": 8.365, "loss": "1.409", "ntokens": "262375", "nsentences": "1783.5", "wps": "38211.4", "ups": "0.15", "wpb": "262375", "bsz": "1783.5", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.195", "loss_scale": "2", "train_wall": "911", "gb_free": "39.1", "wall": "21572"}
[2024-10-04 07:34:59,691][train_inner][INFO] - {"epoch": 9, "update": 8.367, "loss": "1.408", "ntokens": "262394", "nsentences": "1784.45", "wps": "37997.8", "ups": "0.14", "wpb": "262394", "bsz": "1784.5", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.252", "loss_scale": "1", "train_wall": "954", "gb_free": "39.6", "wall": "21568"}
[2024-10-04 07:42:14,974][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 07:52:08,071][train_inner][INFO] - {"epoch": 9, "update": 8.785, "loss": "1.386", "ntokens": "264015", "nsentences": "1761.58", "wps": "51152.8", "ups": "0.19", "wpb": "264015", "bsz": "1761.6", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.217", "loss_scale": "1", "train_wall": "1000", "gb_free": "39.1", "wall": "22604"}
[2024-10-04 07:52:08,764][train_inner][INFO] - {"epoch": 9, "update": 8.785, "loss": "1.386", "ntokens": "264011", "nsentences": "1760.65", "wps": "51311.6", "ups": "0.19", "wpb": "264011", "bsz": "1760.7", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.245", "loss_scale": "1", "train_wall": "973", "gb_free": "39.1", "wall": "22597"}
[2024-10-04 07:57:18,688][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-04 07:57:18,758][train][INFO] - {"epoch": 9, "train_loss": "1.39", "train_ntokens": "263498", "train_nsentences": "1753.54", "train_wps": "46889.3", "train_ups": "0.18", "train_wpb": "263498", "train_bsz": "1753.5", "train_num_updates": "4303", "train_lr": "6.72344e-05", "train_gnorm": "1.19", "train_loss_scale": "1", "train_train_wall": "2164", "train_gb_free": "40.1", "train_wall": "22915"}
[2024-10-04 07:57:19,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 07:57:19,087][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-04 07:57:19,102][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 07:57:50,089][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-04 07:57:50,099][train][INFO] - {"epoch": 9, "train_loss": "1.39", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "46447.2", "train_ups": "0.18", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "4303", "train_lr": "6.72344e-05", "train_gnorm": "1.238", "train_loss_scale": "1", "train_train_wall": "2211", "train_gb_free": "40.1", "train_wall": "22938"}
[2024-10-04 07:57:50,544][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 07:57:50,561][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-04 07:57:50,566][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 08:11:47,218][train_inner][INFO] - {"epoch": 10, "update": 9.203, "loss": "1.364", "ntokens": "263176", "nsentences": "1720.38", "wps": "44710.9", "ups": "0.17", "wpb": "263176", "bsz": "1720.4", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.139", "loss_scale": "1", "train_wall": "681", "gb_free": "40.5", "wall": "23781"}
[2024-10-04 08:11:55,367][train_inner][INFO] - {"epoch": 10, "update": 9.203, "loss": "1.364", "ntokens": "263176", "nsentences": "1720.38", "wps": "44389.2", "ups": "0.17", "wpb": "263176", "bsz": "1720.4", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.13", "loss_scale": "1", "train_wall": "712", "gb_free": "40.5", "wall": "23783"}
[2024-10-04 08:24:04,661][train_inner][INFO] - {"epoch": 10, "update": 9.62, "loss": "1.346", "ntokens": "264049", "nsentences": "1745.93", "wps": "71622.1", "ups": "0.27", "wpb": "264050", "bsz": "1745.9", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.133", "loss_scale": "1", "train_wall": "492", "gb_free": "39.4", "wall": "24521"}
[2024-10-04 08:24:52,856][train_inner][INFO] - {"epoch": 10, "update": 9.62, "loss": "1.346", "ntokens": "264049", "nsentences": "1745.93", "wps": "67926.4", "ups": "0.26", "wpb": "264050", "bsz": "1745.9", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.167", "loss_scale": "1", "train_wall": "553", "gb_free": "39.4", "wall": "24561"}
[2024-10-04 08:36:58,410][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 4782 updates
[2024-10-04 08:36:58,430][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 08:37:07,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 4782 updates
[2024-10-04 08:37:07,318][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 08:37:20,768][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 08:37:21,285][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 10 @ 4782 updates, score None) (writing took 22.858651656657457 seconds)
[2024-10-04 08:37:21,286][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-10-04 08:37:21,344][train][INFO] - {"epoch": 10, "train_loss": "1.342", "train_ntokens": "263400", "train_nsentences": "1753.71", "train_wps": "52514.9", "train_ups": "0.2", "train_wpb": "263400", "train_bsz": "1753.7", "train_num_updates": "4782", "train_lr": "7.47187e-05", "train_gnorm": "1.098", "train_loss_scale": "1", "train_train_wall": "1478", "train_gb_free": "39.6", "train_wall": "25317"}
[2024-10-04 08:37:21,601][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 08:37:21,654][fairseq.trainer][INFO] - begin training epoch 11
[2024-10-04 08:37:21,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 08:43:41,463][train_inner][INFO] - {"epoch": 11, "update": 10.038, "loss": "1.33", "ntokens": "262315", "nsentences": "1779.87", "wps": "44581.4", "ups": "0.17", "wpb": "262315", "bsz": "1779.9", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.054", "loss_scale": "1", "train_wall": "628", "gb_free": "40.1", "wall": "25697"}
[2024-10-04 08:47:25,778][train_inner][INFO] - {"epoch": 11, "update": 10.455, "loss": "1.314", "ntokens": "263716", "nsentences": "1785.12", "wps": "235152", "ups": "0.89", "wpb": "263716", "bsz": "1785.1", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "1.075", "loss_scale": "1", "train_wall": "220", "gb_free": "39.6", "wall": "25922"}
[2024-10-04 08:51:11,710][train_inner][INFO] - {"epoch": 11, "update": 10.873, "loss": "1.3", "ntokens": "264306", "nsentences": "1723.88", "wps": "233983", "ups": "0.89", "wpb": "264306", "bsz": "1723.9", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.112", "loss_scale": "1", "train_wall": "189", "gb_free": "40.1", "wall": "26148"}
[2024-10-04 08:52:41,140][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-10-04 08:52:41,164][train][INFO] - {"epoch": 11, "train_loss": "1.306", "train_ntokens": "263535", "train_nsentences": "1753.71", "train_wps": "137237", "train_ups": "0.52", "train_wpb": "263535", "train_bsz": "1753.7", "train_num_updates": "5261", "train_lr": "8.22031e-05", "train_gnorm": "1.083", "train_loss_scale": "1", "train_train_wall": "538", "train_gb_free": "39.3", "train_wall": "26237"}
[2024-10-04 08:52:41,341][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 08:52:41,351][fairseq.trainer][INFO] - begin training epoch 12
[2024-10-04 08:52:41,352][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 09:00:43,202][train_inner][INFO] - {"epoch": 12, "update": 11.29, "loss": "1.285", "ntokens": "263038", "nsentences": "1717.66", "wps": "92054.1", "ups": "0.35", "wpb": "263038", "bsz": "1717.7", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.05", "loss_scale": "1", "train_wall": "257", "gb_free": "39.1", "wall": "26719"}
[2024-10-04 09:04:31,043][train_inner][INFO] - {"epoch": 12, "update": 11.708, "loss": "1.276", "ntokens": "264020", "nsentences": "1755.53", "wps": "231763", "ups": "0.88", "wpb": "264020", "bsz": "1755.5", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.037", "loss_scale": "1", "train_wall": "223", "gb_free": "39.6", "wall": "26947"}
[2024-10-04 09:07:40,855][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-10-04 09:07:40,879][train][INFO] - {"epoch": 12, "train_loss": "1.275", "train_ntokens": "263435", "train_nsentences": "1753.71", "train_wps": "140251", "train_ups": "0.53", "train_wpb": "263435", "train_bsz": "1753.7", "train_num_updates": "5740", "train_lr": "8.96875e-05", "train_gnorm": "1.055", "train_loss_scale": "1", "train_train_wall": "579", "train_gb_free": "39.3", "train_wall": "27137"}
[2024-10-04 09:07:41,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 09:07:41,221][fairseq.trainer][INFO] - begin training epoch 13
[2024-10-04 09:07:41,221][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 09:14:00,695][train_inner][INFO] - {"epoch": 13, "update": 12.125, "loss": "1.266", "ntokens": "262359", "nsentences": "1794.79", "wps": "92113.5", "ups": "0.35", "wpb": "262359", "bsz": "1794.8", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "1.008", "loss_scale": "1", "train_wall": "264", "gb_free": "40.1", "wall": "27517"}
[2024-10-04 09:17:44,450][train_inner][INFO] - {"epoch": 13, "update": 12.543, "loss": "1.249", "ntokens": "264241", "nsentences": "1745.23", "wps": "236203", "ups": "0.89", "wpb": "264241", "bsz": "1745.2", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "0.99", "loss_scale": "1", "train_wall": "220", "gb_free": "40", "wall": "27740"}
[2024-10-04 09:21:36,465][train_inner][INFO] - {"epoch": 13, "update": 12.96, "loss": "1.245", "ntokens": "263824", "nsentences": "1767.9", "wps": "227434", "ups": "0.86", "wpb": "263824", "bsz": "1767.9", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "0.981", "loss_scale": "2", "train_wall": "228", "gb_free": "39.2", "wall": "27973"}
[2024-10-04 09:22:02,737][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-10-04 09:22:02,759][train][INFO] - {"epoch": 13, "train_loss": "1.249", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "146450", "train_ups": "0.56", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "6219", "train_lr": "9.71719e-05", "train_gnorm": "0.983", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.7", "train_wall": "27999"}
[2024-10-04 09:22:02,960][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 09:22:02,987][fairseq.trainer][INFO] - begin training epoch 14
[2024-10-04 09:22:02,987][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 09:28:06,472][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 09:31:16,262][train_inner][INFO] - {"epoch": 14, "update": 13.38, "loss": "1.231", "ntokens": "262987", "nsentences": "1742.56", "wps": "90718", "ups": "0.34", "wpb": "262987", "bsz": "1742.6", "num_updates": "6400", "lr": "0.0001", "gnorm": "1.009", "loss_scale": "1", "train_wall": "253", "gb_free": "39.6", "wall": "28552"}
[2024-10-04 09:35:11,175][train_inner][INFO] - {"epoch": 14, "update": 13.797, "loss": "1.226", "ntokens": "263877", "nsentences": "1769.07", "wps": "224673", "ups": "0.85", "wpb": "263877", "bsz": "1769.1", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.951", "loss_scale": "1", "train_wall": "231", "gb_free": "39.6", "wall": "28787"}
[2024-10-04 09:36:43,685][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-10-04 09:36:43,708][train][INFO] - {"epoch": 14, "train_loss": "1.227", "train_ntokens": "263508", "train_nsentences": "1753.71", "train_wps": "142979", "train_ups": "0.54", "train_wpb": "263508", "train_bsz": "1753.7", "train_num_updates": "6697", "train_lr": "0.000104641", "train_gnorm": "0.981", "train_loss_scale": "1", "train_train_wall": "549", "train_gb_free": "39.1", "train_wall": "28880"}
[2024-10-04 09:36:43,958][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 09:36:43,997][fairseq.trainer][INFO] - begin training epoch 15
[2024-10-04 09:36:43,998][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 09:44:43,882][train_inner][INFO] - {"epoch": 15, "update": 14.215, "loss": "1.215", "ntokens": "262771", "nsentences": "1725.01", "wps": "91766.7", "ups": "0.35", "wpb": "262771", "bsz": "1725", "num_updates": "6800", "lr": "0.00010625", "gnorm": "0.964", "loss_scale": "1", "train_wall": "219", "gb_free": "39.2", "wall": "29360"}
[2024-10-04 09:48:41,004][train_inner][INFO] - {"epoch": 15, "update": 14.633, "loss": "1.209", "ntokens": "263630", "nsentences": "1774.79", "wps": "222366", "ups": "0.84", "wpb": "263630", "bsz": "1774.8", "num_updates": "7000", "lr": "0.000109375", "gnorm": "1.044", "loss_scale": "1", "train_wall": "232", "gb_free": "39.8", "wall": "29597"}
[2024-10-04 09:51:58,907][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-10-04 09:51:58,934][train][INFO] - {"epoch": 15, "train_loss": "1.206", "train_ntokens": "263451", "train_nsentences": "1753.71", "train_wps": "137882", "train_ups": "0.52", "train_wpb": "263451", "train_bsz": "1753.7", "train_num_updates": "7176", "train_lr": "0.000112125", "train_gnorm": "0.957", "train_loss_scale": "1", "train_train_wall": "554", "train_gb_free": "40", "train_wall": "29795"}
[2024-10-04 09:51:59,107][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 09:51:59,122][fairseq.trainer][INFO] - begin training epoch 16
[2024-10-04 09:51:59,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 09:58:20,568][train_inner][INFO] - {"epoch": 16, "update": 15.05, "loss": "1.201", "ntokens": "263019", "nsentences": "1740.59", "wps": "90765.9", "ups": "0.35", "wpb": "263019", "bsz": "1740.6", "num_updates": "7200", "lr": "0.0001125", "gnorm": "0.952", "loss_scale": "1", "train_wall": "257", "gb_free": "39.3", "wall": "30177"}
[2024-10-04 10:02:05,180][train_inner][INFO] - {"epoch": 16, "update": 15.468, "loss": "1.19", "ntokens": "264077", "nsentences": "1743.61", "wps": "235150", "ups": "0.89", "wpb": "264077", "bsz": "1743.6", "num_updates": "7400", "lr": "0.000115625", "gnorm": "0.846", "loss_scale": "1", "train_wall": "220", "gb_free": "39.6", "wall": "30401"}
[2024-10-04 10:06:43,872][train_inner][INFO] - {"epoch": 16, "update": 15.885, "loss": "1.187", "ntokens": "263765", "nsentences": "1769.42", "wps": "189310", "ups": "0.72", "wpb": "263765", "bsz": "1769.4", "num_updates": "7600", "lr": "0.00011875", "gnorm": "0.841", "loss_scale": "1", "train_wall": "274", "gb_free": "39.6", "wall": "30680"}
[2024-10-04 10:07:33,694][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-10-04 10:07:33,718][train][INFO] - {"epoch": 16, "train_loss": "1.189", "train_ntokens": "263425", "train_nsentences": "1753.71", "train_wps": "134986", "train_ups": "0.51", "train_wpb": "263425", "train_bsz": "1753.7", "train_num_updates": "7655", "train_lr": "0.000119609", "train_gnorm": "0.899", "train_loss_scale": "1", "train_train_wall": "607", "train_gb_free": "39.2", "train_wall": "30730"}
[2024-10-04 10:07:33,924][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 10:07:33,963][fairseq.trainer][INFO] - begin training epoch 17
[2024-10-04 10:07:33,964][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 10:16:06,256][train_inner][INFO] - {"epoch": 17, "update": 16.303, "loss": "1.179", "ntokens": "262901", "nsentences": "1749.96", "wps": "93497.8", "ups": "0.36", "wpb": "262901", "bsz": "1750", "num_updates": "7800", "lr": "0.000121875", "gnorm": "0.943", "loss_scale": "1", "train_wall": "213", "gb_free": "39.6", "wall": "31242"}
[2024-10-04 10:19:44,269][train_inner][INFO] - {"epoch": 17, "update": 16.72, "loss": "1.17", "ntokens": "263977", "nsentences": "1743.18", "wps": "242170", "ups": "0.92", "wpb": "263977", "bsz": "1743.2", "num_updates": "8000", "lr": "0.000125", "gnorm": "0.895", "loss_scale": "1", "train_wall": "213", "gb_free": "39.1", "wall": "31460"}
[2024-10-04 10:22:30,475][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-10-04 10:22:30,505][train][INFO] - {"epoch": 17, "train_loss": "1.172", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "140730", "train_ups": "0.53", "train_wpb": "263475", "train_bsz": "1753.7", "train_num_updates": "8134", "train_lr": "0.000127094", "train_gnorm": "0.905", "train_loss_scale": "1", "train_train_wall": "539", "train_gb_free": "40.2", "train_wall": "31627"}
[2024-10-04 10:22:30,597][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 10:22:30,627][fairseq.trainer][INFO] - begin training epoch 18
[2024-10-04 10:22:30,628][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 10:29:20,418][train_inner][INFO] - {"epoch": 18, "update": 17.138, "loss": "1.165", "ntokens": "262908", "nsentences": "1746.17", "wps": "91265.5", "ups": "0.35", "wpb": "262908", "bsz": "1746.2", "num_updates": "8200", "lr": "0.000128125", "gnorm": "0.885", "loss_scale": "1", "train_wall": "227", "gb_free": "39.3", "wall": "32036"}
[2024-10-04 10:32:57,998][train_inner][INFO] - {"epoch": 18, "update": 17.555, "loss": "1.159", "ntokens": "263801", "nsentences": "1784", "wps": "242516", "ups": "0.92", "wpb": "263801", "bsz": "1784", "num_updates": "8400", "lr": "0.00013125", "gnorm": "0.831", "loss_scale": "2", "train_wall": "213", "gb_free": "40.3", "wall": "32254"}
[2024-10-04 10:36:48,054][train_inner][INFO] - {"epoch": 18, "update": 17.973, "loss": "1.155", "ntokens": "263977", "nsentences": "1748.78", "wps": "229497", "ups": "0.87", "wpb": "263977", "bsz": "1748.8", "num_updates": "8600", "lr": "0.000134375", "gnorm": "0.848", "loss_scale": "2", "train_wall": "152", "gb_free": "40.1", "wall": "32484"}
[2024-10-04 10:37:07,467][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-10-04 10:37:07,496][train][INFO] - {"epoch": 18, "train_loss": "1.157", "train_ntokens": "263519", "train_nsentences": "1753.71", "train_wps": "143931", "train_ups": "0.55", "train_wpb": "263519", "train_bsz": "1753.7", "train_num_updates": "8613", "train_lr": "0.000134578", "train_gnorm": "0.845", "train_loss_scale": "2", "train_train_wall": "446", "train_gb_free": "39.3", "train_wall": "32504"}
[2024-10-04 10:37:07,551][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 10:37:07,561][fairseq.trainer][INFO] - begin training epoch 19
[2024-10-04 10:37:07,561][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 10:45:01,963][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 10:46:34,369][train_inner][INFO] - {"epoch": 19, "update": 18.392, "loss": "1.146", "ntokens": "262835", "nsentences": "1750.42", "wps": "89658.1", "ups": "0.34", "wpb": "262835", "bsz": "1750.4", "num_updates": "8800", "lr": "0.0001375", "gnorm": "0.846", "loss_scale": "1", "train_wall": "259", "gb_free": "39.7", "wall": "33070"}
[2024-10-04 10:50:11,193][train_inner][INFO] - {"epoch": 19, "update": 18.81, "loss": "1.141", "ntokens": "264010", "nsentences": "1734.93", "wps": "243553", "ups": "0.92", "wpb": "264010", "bsz": "1734.9", "num_updates": "9000", "lr": "0.000140625", "gnorm": "0.934", "loss_scale": "1", "train_wall": "208", "gb_free": "39.8", "wall": "33287"}
[2024-10-04 10:51:55,575][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-10-04 10:51:55,595][train][INFO] - {"epoch": 19, "train_loss": "1.143", "train_ntokens": "263444", "train_nsentences": "1755.02", "train_wps": "141794", "train_ups": "0.54", "train_wpb": "263444", "train_bsz": "1755", "train_num_updates": "9091", "train_lr": "0.000142047", "train_gnorm": "0.854", "train_loss_scale": "1", "train_train_wall": "552", "train_gb_free": "39.1", "train_wall": "33392"}
[2024-10-04 10:51:55,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 10:51:55,732][fairseq.trainer][INFO] - begin training epoch 20
[2024-10-04 10:51:55,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 11:00:41,068][train_inner][INFO] - {"epoch": 20, "update": 19.228, "loss": "1.138", "ntokens": "262726", "nsentences": "1789.55", "wps": "83423.4", "ups": "0.32", "wpb": "262726", "bsz": "1789.5", "num_updates": "9200", "lr": "0.00014375", "gnorm": "0.784", "loss_scale": "1", "train_wall": "239", "gb_free": "39.6", "wall": "33917"}
[2024-10-04 11:04:22,310][train_inner][INFO] - {"epoch": 20, "update": 19.645, "loss": "1.133", "ntokens": "263955", "nsentences": "1743.67", "wps": "238626", "ups": "0.9", "wpb": "263954", "bsz": "1743.7", "num_updates": "9400", "lr": "0.000146875", "gnorm": "0.863", "loss_scale": "1", "train_wall": "217", "gb_free": "39.3", "wall": "34138"}
[2024-10-04 11:07:49,414][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 9570 updates
[2024-10-04 11:07:49,417][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 11:07:53,995][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 11:07:54,061][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 20 @ 9570 updates, score None) (writing took 4.6473958836868405 seconds)
[2024-10-04 11:07:54,062][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-10-04 11:07:54,087][train][INFO] - {"epoch": 20, "train_loss": "1.132", "train_ntokens": "263419", "train_nsentences": "1753.71", "train_wps": "131646", "train_ups": "0.5", "train_wpb": "263419", "train_bsz": "1753.7", "train_num_updates": "9570", "train_lr": "0.000149531", "train_gnorm": "0.866", "train_loss_scale": "1", "train_train_wall": "555", "train_gb_free": "39.7", "train_wall": "34350"}
[2024-10-04 11:07:54,274][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 11:07:54,316][fairseq.trainer][INFO] - begin training epoch 21
[2024-10-04 11:07:54,317][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 11:14:06,300][train_inner][INFO] - {"epoch": 21, "update": 20.063, "loss": "1.129", "ntokens": "262544", "nsentences": "1750.07", "wps": "89914.6", "ups": "0.34", "wpb": "262544", "bsz": "1750.1", "num_updates": "9600", "lr": "0.00015", "gnorm": "0.887", "loss_scale": "1", "train_wall": "253", "gb_free": "39.8", "wall": "34722"}
[2024-10-04 11:17:36,987][train_inner][INFO] - {"epoch": 21, "update": 20.48, "loss": "1.12", "ntokens": "263998", "nsentences": "1768.59", "wps": "250618", "ups": "0.95", "wpb": "263998", "bsz": "1768.6", "num_updates": "9800", "lr": "0.000153125", "gnorm": "0.807", "loss_scale": "1", "train_wall": "206", "gb_free": "39.6", "wall": "34933"}
[2024-10-04 11:21:35,404][train_inner][INFO] - {"epoch": 21, "update": 20.898, "loss": "1.119", "ntokens": "264400", "nsentences": "1739.66", "wps": "221809", "ups": "0.84", "wpb": "264400", "bsz": "1739.7", "num_updates": "10000", "lr": "0.00015625", "gnorm": "0.852", "loss_scale": "1", "train_wall": "234", "gb_free": "39.7", "wall": "35171"}
[2024-10-04 11:22:52,651][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-10-04 11:22:52,670][train][INFO] - {"epoch": 21, "train_loss": "1.12", "train_ntokens": "263663", "train_nsentences": "1753.71", "train_wps": "140549", "train_ups": "0.53", "train_wpb": "263663", "train_bsz": "1753.7", "train_num_updates": "10049", "train_lr": "0.000157016", "train_gnorm": "0.836", "train_loss_scale": "1", "train_train_wall": "566", "train_gb_free": "39.3", "train_wall": "35249"}
[2024-10-04 11:22:52,782][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 11:22:52,870][fairseq.trainer][INFO] - begin training epoch 22
[2024-10-04 11:22:52,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 11:31:17,226][train_inner][INFO] - {"epoch": 22, "update": 21.315, "loss": "1.113", "ntokens": "263074", "nsentences": "1752.74", "wps": "90432.2", "ups": "0.34", "wpb": "263074", "bsz": "1752.7", "num_updates": "10200", "lr": "0.000159375", "gnorm": "0.869", "loss_scale": "1", "train_wall": "234", "gb_free": "39.7", "wall": "35753"}
[2024-10-04 11:35:33,317][train_inner][INFO] - {"epoch": 22, "update": 21.733, "loss": "1.108", "ntokens": "264354", "nsentences": "1723.19", "wps": "206458", "ups": "0.78", "wpb": "264354", "bsz": "1723.2", "num_updates": "10400", "lr": "0.0001625", "gnorm": "0.817", "loss_scale": "1", "train_wall": "250", "gb_free": "40.1", "wall": "36009"}
[2024-10-04 11:37:59,618][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-10-04 11:37:59,634][train][INFO] - {"epoch": 22, "train_loss": "1.109", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "139218", "train_ups": "0.53", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "10528", "train_lr": "0.0001645", "train_gnorm": "0.821", "train_loss_scale": "1", "train_train_wall": "551", "train_gb_free": "39.3", "train_wall": "36156"}
[2024-10-04 11:37:59,716][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 11:37:59,807][fairseq.trainer][INFO] - begin training epoch 23
[2024-10-04 11:37:59,808][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 11:45:08,750][train_inner][INFO] - {"epoch": 23, "update": 22.15, "loss": "1.106", "ntokens": "262252", "nsentences": "1791.3", "wps": "91152.3", "ups": "0.35", "wpb": "262252", "bsz": "1791.3", "num_updates": "10600", "lr": "0.000165625", "gnorm": "0.812", "loss_scale": "1", "train_wall": "237", "gb_free": "39.7", "wall": "36585"}
[2024-10-04 11:47:54,825][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 11:48:41,706][train_inner][INFO] - {"epoch": 23, "update": 22.57, "loss": "1.1", "ntokens": "264245", "nsentences": "1758.66", "wps": "248191", "ups": "0.94", "wpb": "264245", "bsz": "1758.7", "num_updates": "10800", "lr": "0.00016875", "gnorm": "0.867", "loss_scale": "1", "train_wall": "208", "gb_free": "39.6", "wall": "36798"}
[2024-10-04 11:52:11,818][train_inner][INFO] - {"epoch": 23, "update": 22.987, "loss": "1.097", "ntokens": "264214", "nsentences": "1742.11", "wps": "251543", "ups": "0.95", "wpb": "264214", "bsz": "1742.1", "num_updates": "11000", "lr": "0.000171875", "gnorm": "0.759", "loss_scale": "1", "train_wall": "201", "gb_free": "40", "wall": "37008"}
[2024-10-04 11:52:17,668][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-10-04 11:52:17,694][train][INFO] - {"epoch": 23, "train_loss": "1.099", "train_ntokens": "263595", "train_nsentences": "1753.57", "train_wps": "146846", "train_ups": "0.56", "train_wpb": "263596", "train_bsz": "1753.6", "train_num_updates": "11006", "train_lr": "0.000171969", "train_gnorm": "0.82", "train_loss_scale": "1", "train_train_wall": "509", "train_gb_free": "39.6", "train_wall": "37014"}
[2024-10-04 11:52:17,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 11:52:18,020][fairseq.trainer][INFO] - begin training epoch 24
[2024-10-04 11:52:18,021][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 12:01:43,218][train_inner][INFO] - {"epoch": 24, "update": 23.405, "loss": "1.091", "ntokens": "262596", "nsentences": "1773.68", "wps": "91915.5", "ups": "0.35", "wpb": "262596", "bsz": "1773.7", "num_updates": "11200", "lr": "0.000175", "gnorm": "0.805", "loss_scale": "1", "train_wall": "223", "gb_free": "39.3", "wall": "37579"}
[2024-10-04 12:05:47,735][train_inner][INFO] - {"epoch": 24, "update": 23.823, "loss": "1.092", "ntokens": "263842", "nsentences": "1759.48", "wps": "215814", "ups": "0.82", "wpb": "263842", "bsz": "1759.5", "num_updates": "11400", "lr": "0.000178125", "gnorm": "0.798", "loss_scale": "1", "train_wall": "240", "gb_free": "39.8", "wall": "37824"}
[2024-10-04 12:07:36,926][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-10-04 12:07:36,930][train][INFO] - {"epoch": 24, "train_loss": "1.09", "train_ntokens": "263426", "train_nsentences": "1753.71", "train_wps": "137268", "train_ups": "0.52", "train_wpb": "263426", "train_bsz": "1753.7", "train_num_updates": "11485", "train_lr": "0.000179453", "train_gnorm": "0.798", "train_loss_scale": "1", "train_train_wall": "565", "train_gb_free": "39.8", "train_wall": "37933"}
[2024-10-04 12:07:37,030][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 12:07:37,074][fairseq.trainer][INFO] - begin training epoch 25
[2024-10-04 12:07:37,075][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 12:15:15,903][train_inner][INFO] - {"epoch": 25, "update": 24.24, "loss": "1.082", "ntokens": "263248", "nsentences": "1695.92", "wps": "92667.3", "ups": "0.35", "wpb": "263248", "bsz": "1695.9", "num_updates": "11600", "lr": "0.00018125", "gnorm": "0.806", "loss_scale": "1", "train_wall": "241", "gb_free": "39.6", "wall": "38392"}
[2024-10-04 12:19:01,965][train_inner][INFO] - {"epoch": 25, "update": 24.658, "loss": "1.082", "ntokens": "263971", "nsentences": "1757.78", "wps": "233543", "ups": "0.88", "wpb": "263972", "bsz": "1757.8", "num_updates": "11800", "lr": "0.000184375", "gnorm": "0.791", "loss_scale": "1", "train_wall": "222", "gb_free": "39.6", "wall": "38618"}
[2024-10-04 12:22:19,760][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-10-04 12:22:19,785][train][INFO] - {"epoch": 25, "train_loss": "1.081", "train_ntokens": "263544", "train_nsentences": "1753.71", "train_wps": "142990", "train_ups": "0.54", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "11964", "train_lr": "0.000186938", "train_gnorm": "0.803", "train_loss_scale": "1", "train_train_wall": "550", "train_gb_free": "39.6", "train_wall": "38816"}
[2024-10-04 12:22:19,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 12:22:19,983][fairseq.trainer][INFO] - begin training epoch 26
[2024-10-04 12:22:19,984][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 12:28:48,685][train_inner][INFO] - {"epoch": 26, "update": 25.075, "loss": "1.079", "ntokens": "262635", "nsentences": "1783.01", "wps": "89527.5", "ups": "0.34", "wpb": "262635", "bsz": "1783", "num_updates": "12000", "lr": "0.0001875", "gnorm": "0.79", "loss_scale": "1", "train_wall": "239", "gb_free": "40.8", "wall": "39205"}
[2024-10-04 12:32:19,768][train_inner][INFO] - {"epoch": 26, "update": 25.493, "loss": "1.07", "ntokens": "264207", "nsentences": "1737.65", "wps": "250339", "ups": "0.95", "wpb": "264207", "bsz": "1737.7", "num_updates": "12200", "lr": "0.000190625", "gnorm": "0.832", "loss_scale": "1", "train_wall": "206", "gb_free": "39.3", "wall": "39416"}
[2024-10-04 12:36:36,946][train_inner][INFO] - {"epoch": 26, "update": 25.91, "loss": "1.075", "ntokens": "263921", "nsentences": "1766.09", "wps": "205258", "ups": "0.78", "wpb": "263921", "bsz": "1766.1", "num_updates": "12400", "lr": "0.00019375", "gnorm": "0.762", "loss_scale": "1", "train_wall": "252", "gb_free": "39.6", "wall": "39673"}
[2024-10-04 12:37:06,366][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-10-04 12:37:06,390][train][INFO] - {"epoch": 26, "train_loss": "1.073", "train_ntokens": "263507", "train_nsentences": "1753.71", "train_wps": "142364", "train_ups": "0.54", "train_wpb": "263507", "train_bsz": "1753.7", "train_num_updates": "12443", "train_lr": "0.000194422", "train_gnorm": "0.794", "train_loss_scale": "1", "train_train_wall": "532", "train_gb_free": "39.3", "train_wall": "39702"}
[2024-10-04 12:37:06,602][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 12:37:06,643][fairseq.trainer][INFO] - begin training epoch 27
[2024-10-04 12:37:06,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 12:45:45,679][train_inner][INFO] - {"epoch": 27, "update": 26.328, "loss": "1.066", "ntokens": "262667", "nsentences": "1748.54", "wps": "95736.4", "ups": "0.36", "wpb": "262667", "bsz": "1748.5", "num_updates": "12600", "lr": "0.000196875", "gnorm": "0.783", "loss_scale": "1", "train_wall": "186", "gb_free": "40.1", "wall": "40222"}
[2024-10-04 12:49:50,804][train_inner][INFO] - {"epoch": 27, "update": 26.745, "loss": "1.065", "ntokens": "263995", "nsentences": "1732.54", "wps": "215403", "ups": "0.82", "wpb": "263995", "bsz": "1732.5", "num_updates": "12800", "lr": "0.0002", "gnorm": "0.807", "loss_scale": "1", "train_wall": "241", "gb_free": "39.3", "wall": "40467"}
[2024-10-04 12:51:49,508][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 12:52:02,133][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-10-04 12:52:02,165][train][INFO] - {"epoch": 27, "train_loss": "1.065", "train_ntokens": "263403", "train_nsentences": "1753.59", "train_wps": "140559", "train_ups": "0.53", "train_wpb": "263403", "train_bsz": "1753.6", "train_num_updates": "12921", "train_lr": "0.000201891", "train_gnorm": "0.778", "train_loss_scale": "1", "train_train_wall": "527", "train_gb_free": "39.6", "train_wall": "40598"}
[2024-10-04 12:52:02,330][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 12:52:02,357][fairseq.trainer][INFO] - begin training epoch 28
[2024-10-04 12:52:02,357][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 12:59:27,077][train_inner][INFO] - {"epoch": 28, "update": 27.165, "loss": "1.064", "ntokens": "262489", "nsentences": "1784.98", "wps": "91100.5", "ups": "0.35", "wpb": "262488", "bsz": "1785", "num_updates": "13000", "lr": "0.000203125", "gnorm": "0.733", "loss_scale": "1", "train_wall": "202", "gb_free": "39.2", "wall": "41043"}
[2024-10-04 13:03:01,544][train_inner][INFO] - {"epoch": 28, "update": 27.582, "loss": "1.057", "ntokens": "264304", "nsentences": "1721.28", "wps": "246482", "ups": "0.93", "wpb": "264304", "bsz": "1721.3", "num_updates": "13200", "lr": "0.00020625", "gnorm": "0.753", "loss_scale": "1", "train_wall": "159", "gb_free": "40.5", "wall": "41258"}
[2024-10-04 13:06:53,427][train_inner][INFO] - {"epoch": 28, "update": 28.0, "loss": "1.06", "ntokens": "262841", "nsentences": "1777.9", "wps": "226746", "ups": "0.86", "wpb": "262841", "bsz": "1777.9", "num_updates": "13400", "lr": "0.000209375", "gnorm": "0.797", "loss_scale": "1", "train_wall": "218", "gb_free": "39.6", "wall": "41489"}
[2024-10-04 13:06:53,442][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-10-04 13:06:53,453][train][INFO] - {"epoch": 28, "train_loss": "1.059", "train_ntokens": "263574", "train_nsentences": "1753.71", "train_wps": "141654", "train_ups": "0.54", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "13400", "train_lr": "0.000209375", "train_gnorm": "0.769", "train_loss_scale": "1", "train_train_wall": "450", "train_gb_free": "39.6", "train_wall": "41489"}
[2024-10-04 13:06:53,625][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 13:06:53,679][fairseq.trainer][INFO] - begin training epoch 29
[2024-10-04 13:06:53,680][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 13:16:11,834][train_inner][INFO] - {"epoch": 29, "update": 28.418, "loss": "1.053", "ntokens": "263778", "nsentences": "1753.37", "wps": "94479.3", "ups": "0.36", "wpb": "263778", "bsz": "1753.4", "num_updates": "13600", "lr": "0.0002125", "gnorm": "0.728", "loss_scale": "1", "train_wall": "162", "gb_free": "39.7", "wall": "42048"}
[2024-10-04 13:20:27,663][train_inner][INFO] - {"epoch": 29, "update": 28.835, "loss": "1.051", "ntokens": "263801", "nsentences": "1774.68", "wps": "206251", "ups": "0.78", "wpb": "263801", "bsz": "1774.7", "num_updates": "13800", "lr": "0.000215625", "gnorm": "0.774", "loss_scale": "1", "train_wall": "179", "gb_free": "39.8", "wall": "42304"}
[2024-10-04 13:22:07,866][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-10-04 13:22:07,891][train][INFO] - {"epoch": 29, "train_loss": "1.051", "train_ntokens": "263386", "train_nsentences": "1753.71", "train_wps": "137967", "train_ups": "0.52", "train_wpb": "263386", "train_bsz": "1753.7", "train_num_updates": "13879", "train_lr": "0.000216859", "train_gnorm": "0.725", "train_loss_scale": "1", "train_train_wall": "418", "train_gb_free": "39.6", "train_wall": "42404"}
[2024-10-04 13:22:07,980][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 13:22:08,018][fairseq.trainer][INFO] - begin training epoch 30
[2024-10-04 13:22:08,019][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 13:29:57,612][train_inner][INFO] - {"epoch": 30, "update": 29.253, "loss": "1.045", "ntokens": "263135", "nsentences": "1717.85", "wps": "92338.2", "ups": "0.35", "wpb": "263135", "bsz": "1717.9", "num_updates": "14000", "lr": "0.00021875", "gnorm": "0.699", "loss_scale": "1", "train_wall": "233", "gb_free": "39.1", "wall": "42874"}
[2024-10-04 13:33:54,938][train_inner][INFO] - {"epoch": 30, "update": 29.67, "loss": "1.046", "ntokens": "263836", "nsentences": "1794.78", "wps": "222352", "ups": "0.84", "wpb": "263836", "bsz": "1794.8", "num_updates": "14200", "lr": "0.000221875", "gnorm": "0.716", "loss_scale": "1", "train_wall": "232", "gb_free": "40.1", "wall": "43111"}
[2024-10-04 13:36:45,827][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 14358 updates
[2024-10-04 13:36:45,834][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 13:36:59,704][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 13:37:00,067][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 30 @ 14358 updates, score None) (writing took 14.240062302909791 seconds)
[2024-10-04 13:37:00,068][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-10-04 13:37:00,086][train][INFO] - {"epoch": 30, "train_loss": "1.046", "train_ntokens": "263617", "train_nsentences": "1753.71", "train_wps": "141533", "train_ups": "0.54", "train_wpb": "263617", "train_bsz": "1753.7", "train_num_updates": "14358", "train_lr": "0.000224344", "train_gnorm": "0.731", "train_loss_scale": "1", "train_train_wall": "555", "train_gb_free": "40.1", "train_wall": "43296"}
[2024-10-04 13:37:00,112][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 13:37:00,153][fairseq.trainer][INFO] - begin training epoch 31
[2024-10-04 13:37:00,154][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 13:43:22,494][train_inner][INFO] - {"epoch": 31, "update": 30.088, "loss": "1.044", "ntokens": "263119", "nsentences": "1724.24", "wps": "92720.9", "ups": "0.35", "wpb": "263120", "bsz": "1724.2", "num_updates": "14400", "lr": "0.000225", "gnorm": "0.725", "loss_scale": "1", "train_wall": "207", "gb_free": "39.7", "wall": "43679"}
[2024-10-04 13:46:58,896][train_inner][INFO] - {"epoch": 31, "update": 30.505, "loss": "1.038", "ntokens": "263925", "nsentences": "1759.33", "wps": "243926", "ups": "0.92", "wpb": "263926", "bsz": "1759.3", "num_updates": "14600", "lr": "0.000228125", "gnorm": "0.736", "loss_scale": "1", "train_wall": "198", "gb_free": "39.3", "wall": "43895"}
[2024-10-04 13:50:50,324][train_inner][INFO] - {"epoch": 31, "update": 30.923, "loss": "1.039", "ntokens": "263941", "nsentences": "1767.02", "wps": "228120", "ups": "0.86", "wpb": "263940", "bsz": "1767", "num_updates": "14800", "lr": "0.00023125", "gnorm": "0.685", "loss_scale": "1", "train_wall": "187", "gb_free": "40", "wall": "44126"}
[2024-10-04 13:51:28,976][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-10-04 13:51:29,033][train][INFO] - {"epoch": 31, "train_loss": "1.039", "train_ntokens": "263544", "train_nsentences": "1753.71", "train_wps": "145286", "train_ups": "0.55", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "14837", "train_lr": "0.000231828", "train_gnorm": "0.72", "train_loss_scale": "1", "train_train_wall": "455", "train_gb_free": "39.2", "train_wall": "44165"}
[2024-10-04 13:51:29,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 13:51:29,151][fairseq.trainer][INFO] - begin training epoch 32
[2024-10-04 13:51:29,151][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 14:00:23,989][train_inner][INFO] - {"epoch": 32, "update": 31.34, "loss": "1.035", "ntokens": "262613", "nsentences": "1777.66", "wps": "91557.5", "ups": "0.35", "wpb": "262613", "bsz": "1777.7", "num_updates": "15000", "lr": "0.000234375", "gnorm": "0.703", "loss_scale": "2", "train_wall": "212", "gb_free": "39.3", "wall": "44700"}
[2024-10-04 14:03:42,691][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 14:04:48,962][train_inner][INFO] - {"epoch": 32, "update": 31.76, "loss": "1.034", "ntokens": "264149", "nsentences": "1760.19", "wps": "199397", "ups": "0.75", "wpb": "264149", "bsz": "1760.2", "num_updates": "15200", "lr": "0.0002375", "gnorm": "0.728", "loss_scale": "1", "train_wall": "260", "gb_free": "39.3", "wall": "44965"}
[2024-10-04 14:06:55,374][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-10-04 14:06:55,425][train][INFO] - {"epoch": 32, "train_loss": "1.033", "train_ntokens": "263586", "train_nsentences": "1754.07", "train_wps": "136009", "train_ups": "0.52", "train_wpb": "263586", "train_bsz": "1754.1", "train_num_updates": "15315", "train_lr": "0.000239297", "train_gnorm": "0.698", "train_loss_scale": "1", "train_train_wall": "566", "train_gb_free": "39.2", "train_wall": "45091"}
[2024-10-04 14:06:55,570][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 14:06:55,596][fairseq.trainer][INFO] - begin training epoch 33
[2024-10-04 14:06:55,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 14:14:05,279][train_inner][INFO] - {"epoch": 33, "update": 32.177, "loss": "1.03", "ntokens": "263192", "nsentences": "1735.64", "wps": "94621.4", "ups": "0.36", "wpb": "263192", "bsz": "1735.6", "num_updates": "15400", "lr": "0.000240625", "gnorm": "0.691", "loss_scale": "1", "train_wall": "224", "gb_free": "39.6", "wall": "45521"}
[2024-10-04 14:17:34,080][train_inner][INFO] - {"epoch": 33, "update": 32.595, "loss": "1.027", "ntokens": "263922", "nsentences": "1750.18", "wps": "252804", "ups": "0.96", "wpb": "263922", "bsz": "1750.2", "num_updates": "15600", "lr": "0.00024375", "gnorm": "0.632", "loss_scale": "1", "train_wall": "158", "gb_free": "39.2", "wall": "45730"}
[2024-10-04 14:21:46,731][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-10-04 14:21:46,750][train][INFO] - {"epoch": 33, "train_loss": "1.028", "train_ntokens": "263504", "train_nsentences": "1753.71", "train_wps": "141610", "train_ups": "0.54", "train_wpb": "263504", "train_bsz": "1753.7", "train_num_updates": "15794", "train_lr": "0.000246781", "train_gnorm": "0.671", "train_loss_scale": "1", "train_train_wall": "506", "train_gb_free": "39.1", "train_wall": "45983"}
[2024-10-04 14:21:46,811][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 14:21:46,826][fairseq.trainer][INFO] - begin training epoch 34
[2024-10-04 14:21:46,827][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 14:27:32,481][train_inner][INFO] - {"epoch": 34, "update": 33.013, "loss": "1.028", "ntokens": "262991", "nsentences": "1725.52", "wps": "87899.9", "ups": "0.33", "wpb": "262991", "bsz": "1725.5", "num_updates": "15800", "lr": "0.000246875", "gnorm": "0.687", "loss_scale": "1", "train_wall": "250", "gb_free": "39.3", "wall": "46329"}
[2024-10-04 14:30:59,782][train_inner][INFO] - {"epoch": 34, "update": 33.43, "loss": "1.021", "ntokens": "263826", "nsentences": "1778.96", "wps": "254573", "ups": "0.96", "wpb": "263826", "bsz": "1779", "num_updates": "16000", "lr": "0.00025", "gnorm": "0.669", "loss_scale": "1", "train_wall": "162", "gb_free": "39.7", "wall": "46536"}
[2024-10-04 14:35:00,461][train_inner][INFO] - {"epoch": 34, "update": 33.848, "loss": "1.023", "ntokens": "264019", "nsentences": "1741.12", "wps": "219409", "ups": "0.83", "wpb": "264019", "bsz": "1741.1", "num_updates": "16200", "lr": "0.000253125", "gnorm": "0.644", "loss_scale": "1", "train_wall": "186", "gb_free": "39.2", "wall": "46776"}
[2024-10-04 14:36:26,721][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-10-04 14:36:26,750][train][INFO] - {"epoch": 34, "train_loss": "1.022", "train_ntokens": "263553", "train_nsentences": "1753.71", "train_wps": "143458", "train_ups": "0.54", "train_wpb": "263553", "train_bsz": "1753.7", "train_num_updates": "16273", "train_lr": "0.000254266", "train_gnorm": "0.658", "train_loss_scale": "1", "train_train_wall": "433", "train_gb_free": "39.3", "train_wall": "46863"}
[2024-10-04 14:36:26,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 14:36:26,953][fairseq.trainer][INFO] - begin training epoch 35
[2024-10-04 14:36:26,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 14:44:24,489][train_inner][INFO] - {"epoch": 35, "update": 34.265, "loss": "1.02", "ntokens": "262996", "nsentences": "1746.45", "wps": "93257.8", "ups": "0.35", "wpb": "262996", "bsz": "1746.5", "num_updates": "16400", "lr": "0.00025625", "gnorm": "0.713", "loss_scale": "1", "train_wall": "236", "gb_free": "39.2", "wall": "47341"}
[2024-10-04 14:48:24,934][train_inner][INFO] - {"epoch": 35, "update": 34.683, "loss": "1.018", "ntokens": "264037", "nsentences": "1755.24", "wps": "219628", "ups": "0.83", "wpb": "264037", "bsz": "1755.2", "num_updates": "16600", "lr": "0.000259375", "gnorm": "0.638", "loss_scale": "1", "train_wall": "236", "gb_free": "39.2", "wall": "47581"}
[2024-10-04 14:51:38,643][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-10-04 14:51:38,647][train][INFO] - {"epoch": 35, "train_loss": "1.017", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "138417", "train_ups": "0.53", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "16752", "train_lr": "0.00026175", "train_gnorm": "0.65", "train_loss_scale": "1", "train_train_wall": "578", "train_gb_free": "40.1", "train_wall": "47775"}
[2024-10-04 14:51:38,695][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 14:51:38,746][fairseq.trainer][INFO] - begin training epoch 36
[2024-10-04 14:51:38,747][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 14:58:28,717][train_inner][INFO] - {"epoch": 36, "update": 35.1, "loss": "1.016", "ntokens": "262927", "nsentences": "1749.15", "wps": "87094.2", "ups": "0.33", "wpb": "262927", "bsz": "1749.2", "num_updates": "16800", "lr": "0.0002625", "gnorm": "0.62", "loss_scale": "1", "train_wall": "244", "gb_free": "39.8", "wall": "48185"}
[2024-10-04 15:02:16,270][train_inner][INFO] - {"epoch": 36, "update": 35.518, "loss": "1.013", "ntokens": "263808", "nsentences": "1779.39", "wps": "231870", "ups": "0.88", "wpb": "263808", "bsz": "1779.4", "num_updates": "17000", "lr": "0.000265625", "gnorm": "0.67", "loss_scale": "1", "train_wall": "223", "gb_free": "40", "wall": "48412"}
[2024-10-04 15:05:54,752][train_inner][INFO] - {"epoch": 36, "update": 35.935, "loss": "1.014", "ntokens": "264314", "nsentences": "1732.43", "wps": "241962", "ups": "0.92", "wpb": "264314", "bsz": "1732.4", "num_updates": "17200", "lr": "0.00026875", "gnorm": "0.667", "loss_scale": "2", "train_wall": "214", "gb_free": "39.8", "wall": "48631"}
[2024-10-04 15:06:49,050][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-10-04 15:06:49,070][train][INFO] - {"epoch": 36, "train_loss": "1.014", "train_ntokens": "263609", "train_nsentences": "1753.71", "train_wps": "138695", "train_ups": "0.53", "train_wpb": "263609", "train_bsz": "1753.7", "train_num_updates": "17231", "train_lr": "0.000269234", "train_gnorm": "0.664", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "39.6", "train_wall": "48685"}
[2024-10-04 15:06:49,214][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 15:06:49,255][fairseq.trainer][INFO] - begin training epoch 37
[2024-10-04 15:06:49,256][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 15:16:12,945][train_inner][INFO] - {"epoch": 37, "update": 36.353, "loss": "1.007", "ntokens": "262718", "nsentences": "1750.46", "wps": "84996", "ups": "0.32", "wpb": "262718", "bsz": "1750.5", "num_updates": "17400", "lr": "0.000271875", "gnorm": "0.579", "loss_scale": "2", "train_wall": "238", "gb_free": "40.1", "wall": "49249"}
[2024-10-04 15:20:22,326][train_inner][INFO] - {"epoch": 37, "update": 36.77, "loss": "1.009", "ntokens": "263695", "nsentences": "1789.11", "wps": "211484", "ups": "0.8", "wpb": "263695", "bsz": "1789.1", "num_updates": "17600", "lr": "0.000275", "gnorm": "0.639", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "49498"}
[2024-10-04 15:22:16,108][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-10-04 15:22:16,150][train][INFO] - {"epoch": 37, "train_loss": "1.008", "train_ntokens": "263429", "train_nsentences": "1753.71", "train_wps": "136109", "train_ups": "0.52", "train_wpb": "263430", "train_bsz": "1753.7", "train_num_updates": "17710", "train_lr": "0.000276719", "train_gnorm": "0.62", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.1", "train_wall": "49612"}
[2024-10-04 15:22:16,358][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 15:22:16,372][fairseq.trainer][INFO] - begin training epoch 38
[2024-10-04 15:22:16,373][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 15:30:30,553][train_inner][INFO] - {"epoch": 38, "update": 37.188, "loss": "1.006", "ntokens": "263055", "nsentences": "1723.38", "wps": "86499.5", "ups": "0.33", "wpb": "263055", "bsz": "1723.4", "num_updates": "17800", "lr": "0.000278125", "gnorm": "0.62", "loss_scale": "2", "train_wall": "216", "gb_free": "40.1", "wall": "50107"}
[2024-10-04 15:34:26,201][train_inner][INFO] - {"epoch": 38, "update": 37.605, "loss": "1.002", "ntokens": "263871", "nsentences": "1758.38", "wps": "223966", "ups": "0.85", "wpb": "263871", "bsz": "1758.4", "num_updates": "18000", "lr": "0.00028125", "gnorm": "0.597", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "50342"}
[2024-10-04 15:38:38,174][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-10-04 15:38:38,194][train][INFO] - {"epoch": 38, "train_loss": "1.004", "train_ntokens": "263454", "train_nsentences": "1753.71", "train_wps": "128504", "train_ups": "0.49", "train_wpb": "263454", "train_bsz": "1753.7", "train_num_updates": "18189", "train_lr": "0.000284203", "train_gnorm": "0.609", "train_loss_scale": "2", "train_train_wall": "584", "train_gb_free": "40.1", "train_wall": "50594"}
[2024-10-04 15:38:38,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 15:38:38,339][fairseq.trainer][INFO] - begin training epoch 39
[2024-10-04 15:38:38,340][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 15:44:28,321][train_inner][INFO] - {"epoch": 39, "update": 38.023, "loss": "1.005", "ntokens": "262896", "nsentences": "1738.79", "wps": "87323.9", "ups": "0.33", "wpb": "262896", "bsz": "1738.8", "num_updates": "18200", "lr": "0.000284375", "gnorm": "0.645", "loss_scale": "2", "train_wall": "252", "gb_free": "40.1", "wall": "50944"}
[2024-10-04 15:47:45,513][train_inner][INFO] - {"epoch": 39, "update": 38.441, "loss": "0.998", "ntokens": "264052", "nsentences": "1749.36", "wps": "267818", "ups": "1.01", "wpb": "264052", "bsz": "1749.4", "num_updates": "18400", "lr": "0.0002875", "gnorm": "0.599", "loss_scale": "2", "train_wall": "153", "gb_free": "39.3", "wall": "51142"}
[2024-10-04 15:51:31,513][train_inner][INFO] - {"epoch": 39, "update": 38.858, "loss": "1", "ntokens": "263960", "nsentences": "1748.88", "wps": "233597", "ups": "0.88", "wpb": "263960", "bsz": "1748.9", "num_updates": "18600", "lr": "0.000290625", "gnorm": "0.608", "loss_scale": "2", "train_wall": "169", "gb_free": "39.1", "wall": "51368"}
[2024-10-04 15:52:54,086][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-10-04 15:52:54,132][train][INFO] - {"epoch": 39, "train_loss": "1", "train_ntokens": "263545", "train_nsentences": "1753.71", "train_wps": "147486", "train_ups": "0.56", "train_wpb": "263545", "train_bsz": "1753.7", "train_num_updates": "18668", "train_lr": "0.000291688", "train_gnorm": "0.619", "train_loss_scale": "2", "train_train_wall": "405", "train_gb_free": "39.6", "train_wall": "51450"}
[2024-10-04 15:52:54,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 15:52:54,231][fairseq.trainer][INFO] - begin training epoch 40
[2024-10-04 15:52:54,232][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 16:01:00,201][train_inner][INFO] - {"epoch": 40, "update": 39.276, "loss": "0.997", "ntokens": "263118", "nsentences": "1734.34", "wps": "92537.8", "ups": "0.35", "wpb": "263118", "bsz": "1734.3", "num_updates": "18800", "lr": "0.00029375", "gnorm": "0.6", "loss_scale": "2", "train_wall": "210", "gb_free": "39.7", "wall": "51936"}
[2024-10-04 16:05:04,315][train_inner][INFO] - {"epoch": 40, "update": 39.693, "loss": "0.997", "ntokens": "263762", "nsentences": "1779.84", "wps": "216114", "ups": "0.82", "wpb": "263762", "bsz": "1779.8", "num_updates": "19000", "lr": "0.000296875", "gnorm": "0.593", "loss_scale": "2", "train_wall": "239", "gb_free": "41.2", "wall": "52180"}
[2024-10-04 16:06:36,317][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-04 16:08:23,250][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 19146 updates
[2024-10-04 16:08:23,252][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 16:08:30,988][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 16:08:31,001][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 40 @ 19146 updates, score None) (writing took 7.750995614565909 seconds)
[2024-10-04 16:08:31,002][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-10-04 16:08:31,007][train][INFO] - {"epoch": 40, "train_loss": "0.996", "train_ntokens": "263658", "train_nsentences": "1755.11", "train_wps": "134521", "train_ups": "0.51", "train_wpb": "263658", "train_bsz": "1755.1", "train_num_updates": "19146", "train_lr": "0.000299156", "train_gnorm": "0.584", "train_loss_scale": "1", "train_train_wall": "564", "train_gb_free": "40.1", "train_wall": "52387"}
[2024-10-04 16:08:31,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 16:08:31,157][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 16:08:31,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 16:14:59,735][train_inner][INFO] - {"epoch": 41, "update": 40.113, "loss": "0.995", "ntokens": "263151", "nsentences": "1760.63", "wps": "88392.6", "ups": "0.34", "wpb": "263151", "bsz": "1760.6", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.587", "loss_scale": "1", "train_wall": "266", "gb_free": "40.5", "wall": "52776"}
[2024-10-04 16:18:55,642][train_inner][INFO] - {"epoch": 41, "update": 40.53, "loss": "0.992", "ntokens": "264000", "nsentences": "1737.4", "wps": "223823", "ups": "0.85", "wpb": "264000", "bsz": "1737.4", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.571", "loss_scale": "1", "train_wall": "231", "gb_free": "39.3", "wall": "53012"}
[2024-10-04 16:22:53,536][train_inner][INFO] - {"epoch": 41, "update": 40.948, "loss": "0.994", "ntokens": "263783", "nsentences": "1785.79", "wps": "221769", "ups": "0.84", "wpb": "263783", "bsz": "1785.8", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.578", "loss_scale": "1", "train_wall": "234", "gb_free": "39.2", "wall": "53250"}
[2024-10-04 16:23:23,315][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-10-04 16:23:23,336][train][INFO] - {"epoch": 41, "train_loss": "0.992", "train_ntokens": "263429", "train_nsentences": "1753.71", "train_wps": "141408", "train_ups": "0.54", "train_wpb": "263429", "train_bsz": "1753.7", "train_num_updates": "19625", "train_lr": "0.000306641", "train_gnorm": "0.571", "train_loss_scale": "1", "train_train_wall": "566", "train_gb_free": "39.6", "train_wall": "53279"}
[2024-10-04 16:23:23,505][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 16:23:23,521][fairseq.trainer][INFO] - begin training epoch 42
[2024-10-04 16:23:23,522][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 16:32:34,546][train_inner][INFO] - {"epoch": 42, "update": 41.365, "loss": "0.99", "ntokens": "263038", "nsentences": "1737.04", "wps": "90546.5", "ups": "0.34", "wpb": "263038", "bsz": "1737", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.536", "loss_scale": "1", "train_wall": "176", "gb_free": "41", "wall": "53831"}
[2024-10-04 16:36:11,322][train_inner][INFO] - {"epoch": 42, "update": 41.783, "loss": "0.988", "ntokens": "264097", "nsentences": "1733.09", "wps": "243666", "ups": "0.92", "wpb": "264097", "bsz": "1733.1", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.559", "loss_scale": "1", "train_wall": "209", "gb_free": "39.3", "wall": "54047"}
[2024-10-04 16:38:18,789][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-10-04 16:38:18,798][train][INFO] - {"epoch": 42, "train_loss": "0.989", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "140970", "train_ups": "0.53", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "20104", "train_lr": "0.000314125", "train_gnorm": "0.555", "train_loss_scale": "1", "train_train_wall": "446", "train_gb_free": "40.3", "train_wall": "54175"}
[2024-10-04 16:38:18,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 16:38:18,972][fairseq.trainer][INFO] - begin training epoch 43
[2024-10-04 16:38:18,973][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 16:45:49,145][train_inner][INFO] - {"epoch": 43, "update": 42.2, "loss": "0.985", "ntokens": "262641", "nsentences": "1764.89", "wps": "90908.7", "ups": "0.35", "wpb": "262641", "bsz": "1764.9", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.544", "loss_scale": "1", "train_wall": "172", "gb_free": "39.1", "wall": "54625"}
[2024-10-04 16:49:50,215][train_inner][INFO] - {"epoch": 43, "update": 42.618, "loss": "0.986", "ntokens": "263597", "nsentences": "1793.08", "wps": "218705", "ups": "0.83", "wpb": "263597", "bsz": "1793.1", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.594", "loss_scale": "1", "train_wall": "169", "gb_free": "39.7", "wall": "54866"}
[2024-10-04 16:54:01,861][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-10-04 16:54:01,878][train][INFO] - {"epoch": 43, "train_loss": "0.985", "train_ntokens": "263484", "train_nsentences": "1753.71", "train_wps": "133828", "train_ups": "0.51", "train_wpb": "263484", "train_bsz": "1753.7", "train_num_updates": "20583", "train_lr": "0.000321609", "train_gnorm": "0.582", "train_loss_scale": "1", "train_train_wall": "389", "train_gb_free": "39.3", "train_wall": "55118"}
[2024-10-04 16:54:01,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 16:54:02,065][fairseq.trainer][INFO] - begin training epoch 44
[2024-10-04 16:54:02,066][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 16:59:57,964][train_inner][INFO] - {"epoch": 44, "update": 43.035, "loss": "0.987", "ntokens": "263156", "nsentences": "1721.05", "wps": "86605.1", "ups": "0.33", "wpb": "263156", "bsz": "1721", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.584", "loss_scale": "1", "train_wall": "149", "gb_free": "39.7", "wall": "55474"}
[2024-10-04 17:03:20,092][train_inner][INFO] - {"epoch": 44, "update": 43.453, "loss": "0.981", "ntokens": "263591", "nsentences": "1773.98", "wps": "260827", "ups": "0.99", "wpb": "263591", "bsz": "1774", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.551", "loss_scale": "1", "train_wall": "153", "gb_free": "39.2", "wall": "55676"}
[2024-10-04 17:07:34,150][train_inner][INFO] - {"epoch": 44, "update": 43.871, "loss": "0.982", "ntokens": "264306", "nsentences": "1739.31", "wps": "208074", "ups": "0.79", "wpb": "264306", "bsz": "1739.3", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.555", "loss_scale": "1", "train_wall": "207", "gb_free": "39.6", "wall": "55930"}
[2024-10-04 17:09:02,915][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-10-04 17:09:02,957][train][INFO] - {"epoch": 44, "train_loss": "0.982", "train_ntokens": "263445", "train_nsentences": "1753.71", "train_wps": "140044", "train_ups": "0.53", "train_wpb": "263445", "train_bsz": "1753.7", "train_num_updates": "21062", "train_lr": "0.000329094", "train_gnorm": "0.543", "train_loss_scale": "1", "train_train_wall": "456", "train_gb_free": "39.2", "train_wall": "56019"}
[2024-10-04 17:09:03,090][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 17:09:03,127][fairseq.trainer][INFO] - begin training epoch 45
[2024-10-04 17:09:03,127][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 17:17:10,905][train_inner][INFO] - {"epoch": 45, "update": 44.288, "loss": "0.979", "ntokens": "262411", "nsentences": "1774.3", "wps": "90997.4", "ups": "0.35", "wpb": "262412", "bsz": "1774.3", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.522", "loss_scale": "2", "train_wall": "237", "gb_free": "39.9", "wall": "56507"}
[2024-10-04 17:20:49,622][train_inner][INFO] - {"epoch": 45, "update": 44.706, "loss": "0.98", "ntokens": "263753", "nsentences": "1750.91", "wps": "241187", "ups": "0.91", "wpb": "263753", "bsz": "1750.9", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.558", "loss_scale": "2", "train_wall": "213", "gb_free": "40.1", "wall": "56726"}
[2024-10-04 17:24:03,651][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-10-04 17:24:03,673][train][INFO] - {"epoch": 45, "train_loss": "0.978", "train_ntokens": "263321", "train_nsentences": "1753.71", "train_wps": "140034", "train_ups": "0.53", "train_wpb": "263321", "train_bsz": "1753.7", "train_num_updates": "21541", "train_lr": "0.000336578", "train_gnorm": "0.527", "train_loss_scale": "2", "train_train_wall": "555", "train_gb_free": "39.7", "train_wall": "56920"}
[2024-10-04 17:24:03,878][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 17:24:03,911][fairseq.trainer][INFO] - begin training epoch 46
[2024-10-04 17:24:03,912][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 17:32:56,714][train_inner][INFO] - {"epoch": 46, "update": 45.123, "loss": "0.978", "ntokens": "262971", "nsentences": "1718.47", "wps": "72336.3", "ups": "0.28", "wpb": "262971", "bsz": "1718.5", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.484", "loss_scale": "2", "train_wall": "275", "gb_free": "39.6", "wall": "57453"}
[2024-10-04 17:36:30,184][train_inner][INFO] - {"epoch": 46, "update": 45.541, "loss": "0.973", "ntokens": "264135", "nsentences": "1747.83", "wps": "247474", "ups": "0.94", "wpb": "264135", "bsz": "1747.8", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.554", "loss_scale": "2", "train_wall": "209", "gb_free": "39.6", "wall": "57666"}
[2024-10-04 17:40:32,455][train_inner][INFO] - {"epoch": 46, "update": 45.958, "loss": "0.978", "ntokens": "264061", "nsentences": "1773.97", "wps": "217998", "ups": "0.83", "wpb": "264061", "bsz": "1774", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.504", "loss_scale": "2", "train_wall": "237", "gb_free": "39.7", "wall": "57908"}
[2024-10-04 17:40:50,613][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-10-04 17:40:50,638][train][INFO] - {"epoch": 46, "train_loss": "0.976", "train_ntokens": "263592", "train_nsentences": "1753.71", "train_wps": "125389", "train_ups": "0.48", "train_wpb": "263592", "train_bsz": "1753.7", "train_num_updates": "22020", "train_lr": "0.000344063", "train_gnorm": "0.526", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.3", "train_wall": "57927"}
[2024-10-04 17:40:50,806][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 17:40:50,842][fairseq.trainer][INFO] - begin training epoch 47
[2024-10-04 17:40:50,843][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 17:50:11,511][train_inner][INFO] - {"epoch": 47, "update": 46.376, "loss": "0.973", "ntokens": "262919", "nsentences": "1745.89", "wps": "90810.4", "ups": "0.35", "wpb": "262919", "bsz": "1745.9", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.564", "loss_scale": "2", "train_wall": "224", "gb_free": "39.8", "wall": "58488"}
[2024-10-04 17:53:57,391][train_inner][INFO] - {"epoch": 47, "update": 46.793, "loss": "0.975", "ntokens": "263830", "nsentences": "1786.56", "wps": "233638", "ups": "0.89", "wpb": "263830", "bsz": "1786.6", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.493", "loss_scale": "2", "train_wall": "215", "gb_free": "39.3", "wall": "58713"}
