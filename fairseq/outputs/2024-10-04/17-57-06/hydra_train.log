[2024-10-04 17:57:47,403][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10881', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:48,094][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16719', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:50,462][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15824', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:50,493][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11213', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:50,937][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14834', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:51,049][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17158', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:51,275][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19031', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:51,609][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11186', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/scratch/shester/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/scratch/shester/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/scratch/shester/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/scratch/shester/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-04 17:57:55,273][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:55,275][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:55,276][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:55,276][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:55,277][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:55,277][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:55,394][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:55,396][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:55,396][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:55,396][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:55,397][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:55,414][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:55,451][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:55,453][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:55,461][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:55,461][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:55,462][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:55,453][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:55,466][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:55,466][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:55,466][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:55,463][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:55,467][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:55,467][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:55,560][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:55,586][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:55,586][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:55,586][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:55,587][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:55,588][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:57,005][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:57,007][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:57,013][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:57,025][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:57,026][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:57,027][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:57,758][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:57:57,760][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:57:57,761][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:57:57,761][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:57:57,762][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:57:57,762][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:57:59,389][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:01,053][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:01,043][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-04 17:58:01,082][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-04 17:58:01,082][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-04 17:58:01,082][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-04 17:58:01,083][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-04 17:58:01,084][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-04 17:58:01,255][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:03,373][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:05,647][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:07,428][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:10,136][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 17:58:12,892][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:01:23,976][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:01:23,981][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:01:23,982][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:01:23,982][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:01:23,983][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:02:08,746][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:02:08,825][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:02:15,912][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:03:25,825][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:03:25,847][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:03:25,848][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:04:45,600][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,638][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:45,639][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:04:45,639][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:04:45,639][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:04:45,640][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:04:49,331][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:04:49,331][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:04:49,338][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:04:49,338][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:05:17,568][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:05:17,984][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:05:32,436][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:06:23,569][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:06:23,571][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:06:44,141][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:06:44,152][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:06:44,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:07:01,008][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:07:53,995][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:07:53,995][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:53,995][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,007][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,007][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,007][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,008][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,008][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,008][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:07:54,008][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:07:54,009][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:07:54,010][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:07:54,012][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:08:22,564][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:08:22,616][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:08:25,766][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:09:25,172][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:09:25,187][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:09:25,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:10:07,827][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:07,827][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,827][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,827][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:07,828][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:07,828][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:10:07,828][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:10:07,836][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:10:13,615][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:13,615][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,615][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:13,616][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:13,616][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:10:13,617][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:10:13,617][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:10:19,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:10:19,175][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:10:19,176][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:23,803][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:23,804][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:10:23,804][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:10:23,805][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:10:29,664][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:29,664][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,664][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,664][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,664][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,665][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,665][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,665][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,665][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-04 18:10:29,665][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-04 18:10:29,665][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-04 18:10:29,665][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-04 18:10:29,666][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-04 18:10:42,451][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:10:42,862][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:10:47,091][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:10:54,673][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:10:54,872][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:10:59,252][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:11:04,537][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:11:04,635][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:11:08,821][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 41 @ 19146 updates)
[2024-10-04 18:11:09,024][fairseq.trainer][INFO] - loading train data for epoch 41
[2024-10-04 18:11:09,760][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:11:15,812][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-04 18:12:19,387][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:12:19,407][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:12:19,408][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:12:23,336][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:12:23,351][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:12:23,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:12:29,268][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:12:29,281][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:12:29,282][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:12:44,982][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 18:12:44,991][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-04 18:12:44,991][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 18:34:21,216][train_inner][INFO] - {"epoch": 41, "update": 40.113, "loss": "0.987", "ntokens": "264329", "nsentences": "1733.39", "wps": "160265", "ups": "0.61", "wpb": "264329", "bsz": "1733.4", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.544", "loss_scale": "1", "train_wall": "124", "gb_free": "39.6", "wall": "1453"}
[2024-10-04 18:34:23,770][train_inner][INFO] - {"epoch": 41, "update": 40.113, "loss": "0.987", "ntokens": "264329", "nsentences": "1733.39", "wps": "155694", "ups": "0.59", "wpb": "264329", "bsz": "1733.4", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.545", "loss_scale": "1", "train_wall": "185", "gb_free": "39.6", "wall": "1590"}
[2024-10-04 18:45:39,790][train_inner][INFO] - {"epoch": 41, "update": 40.53, "loss": "0.993", "ntokens": "264220", "nsentences": "1737.4", "wps": "77877.5", "ups": "0.29", "wpb": "264220", "bsz": "1737.4", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.588", "loss_scale": "1", "train_wall": "601", "gb_free": "39.8", "wall": "2132"}
[2024-10-04 18:45:51,938][train_inner][INFO] - {"epoch": 41, "update": 40.53, "loss": "0.993", "ntokens": "264220", "nsentences": "1737.4", "wps": "76789.9", "ups": "0.29", "wpb": "264220", "bsz": "1737.4", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.588", "loss_scale": "1", "train_wall": "587", "gb_free": "39.8", "wall": "2278"}
[2024-10-04 19:01:19,662][train_inner][INFO] - {"epoch": 41, "update": 40.948, "loss": "0.993", "ntokens": "263616", "nsentences": "1785.79", "wps": "56839.7", "ups": "0.22", "wpb": "263616", "bsz": "1785.8", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.55", "loss_scale": "1", "train_wall": "824", "gb_free": "39.2", "wall": "3206"}
[2024-10-04 19:01:19,681][train_inner][INFO] - {"epoch": 41, "update": 40.948, "loss": "0.993", "ntokens": "263616", "nsentences": "1785.79", "wps": "56103.3", "ups": "0.21", "wpb": "263616", "bsz": "1785.8", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.553", "loss_scale": "1", "train_wall": "928", "gb_free": "39.2", "wall": "3072"}
[2024-10-04 19:01:58,548][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-10-04 19:01:58,726][train][INFO] - {"epoch": 41, "train_loss": "0.992", "train_ntokens": "263483", "train_nsentences": "1753.71", "train_wps": "72180.5", "train_ups": "0.27", "train_wpb": "263483", "train_bsz": "1753.7", "train_num_updates": "19625", "train_lr": "0.000306641", "train_gnorm": "0.562", "train_loss_scale": "1", "train_train_wall": "1690", "train_gb_free": "40", "train_wall": "3111"}
[2024-10-04 19:01:59,248][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 19:01:59,294][fairseq.trainer][INFO] - begin training epoch 42
[2024-10-04 19:01:59,302][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 19:02:00,412][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-10-04 19:02:00,886][train][INFO] - {"epoch": 41, "train_loss": "0.992", "train_ntokens": "263483", "train_nsentences": "1753.71", "train_wps": "72103.7", "train_ups": "0.27", "train_wpb": "263483", "train_bsz": "1753.7", "train_num_updates": "19625", "train_lr": "0.000306641", "train_gnorm": "0.561", "train_loss_scale": "1", "train_train_wall": "1635", "train_gb_free": "40", "train_wall": "3246"}
[2024-10-04 19:02:01,625][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 19:02:01,651][fairseq.trainer][INFO] - begin training epoch 42
[2024-10-04 19:02:01,652][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 19:21:55,863][train_inner][INFO] - {"epoch": 42, "update": 41.365, "loss": "0.99", "ntokens": "263037", "nsentences": "1737.04", "wps": "42559", "ups": "0.16", "wpb": "263038", "bsz": "1737", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.6", "loss_scale": "1", "train_wall": "745", "gb_free": "40", "wall": "4308"}
[2024-10-04 19:21:56,531][train_inner][INFO] - {"epoch": 42, "update": 41.365, "loss": "0.99", "ntokens": "263037", "nsentences": "1737.04", "wps": "42533", "ups": "0.16", "wpb": "263038", "bsz": "1737", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.587", "loss_scale": "1", "train_wall": "776", "gb_free": "40", "wall": "4443"}
[2024-10-04 19:34:07,734][train_inner][INFO] - {"epoch": 42, "update": 41.783, "loss": "0.99", "ntokens": "264147", "nsentences": "1733.09", "wps": "72268.5", "ups": "0.27", "wpb": "264147", "bsz": "1733.1", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.612", "loss_scale": "1", "train_wall": "669", "gb_free": "39.7", "wall": "5174"}
[2024-10-04 19:34:16,532][train_inner][INFO] - {"epoch": 42, "update": 41.783, "loss": "0.989", "ntokens": "264147", "nsentences": "1733.09", "wps": "71330.7", "ups": "0.27", "wpb": "264147", "bsz": "1733.1", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.555", "loss_scale": "1", "train_wall": "609", "gb_free": "39.7", "wall": "5049"}
[2024-10-04 19:38:57,259][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-10-04 19:38:57,446][train][INFO] - {"epoch": 42, "train_loss": "0.989", "train_ntokens": "263565", "train_nsentences": "1753.71", "train_wps": "56960.6", "train_ups": "0.22", "train_wpb": "263565", "train_bsz": "1753.7", "train_num_updates": "20104", "train_lr": "0.000314125", "train_gnorm": "0.603", "train_loss_scale": "1", "train_train_wall": "1657", "train_gb_free": "40.2", "train_wall": "5463"}
[2024-10-04 19:38:58,184][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 19:38:58,263][fairseq.trainer][INFO] - begin training epoch 43
[2024-10-04 19:38:58,264][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 19:39:56,916][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-10-04 19:39:56,933][train][INFO] - {"epoch": 42, "train_loss": "0.989", "train_ntokens": "263565", "train_nsentences": "1753.71", "train_wps": "55415.5", "train_ups": "0.21", "train_wpb": "263565", "train_bsz": "1753.7", "train_num_updates": "20104", "train_lr": "0.000314125", "train_gnorm": "0.597", "train_loss_scale": "1", "train_train_wall": "1620", "train_gb_free": "40.2", "train_wall": "5389"}
[2024-10-04 19:39:57,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 19:39:57,463][fairseq.trainer][INFO] - begin training epoch 43
[2024-10-04 19:39:57,464][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 19:53:32,458][train_inner][INFO] - {"epoch": 43, "update": 42.2, "loss": "0.985", "ntokens": "262737", "nsentences": "1764.89", "wps": "45120.1", "ups": "0.17", "wpb": "262737", "bsz": "1764.9", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.594", "loss_scale": "1", "train_wall": "609", "gb_free": "39.1", "wall": "6338"}
[2024-10-04 19:53:33,034][train_inner][INFO] - {"epoch": 43, "update": 42.2, "loss": "0.985", "ntokens": "262737", "nsentences": "1764.89", "wps": "45437.6", "ups": "0.17", "wpb": "262737", "bsz": "1764.9", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.615", "loss_scale": "1", "train_wall": "624", "gb_free": "39.1", "wall": "6205"}
[2024-10-04 20:04:31,310][train_inner][INFO] - {"epoch": 43, "update": 42.618, "loss": "0.987", "ntokens": "263693", "nsentences": "1793.08", "wps": "80052", "ups": "0.3", "wpb": "263693", "bsz": "1793.1", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.548", "loss_scale": "1", "train_wall": "590", "gb_free": "39.2", "wall": "6997"}
[2024-10-04 20:04:34,918][train_inner][INFO] - {"epoch": 43, "update": 42.618, "loss": "0.988", "ntokens": "263693", "nsentences": "1793.08", "wps": "79680.3", "ups": "0.3", "wpb": "263693", "bsz": "1793.1", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.591", "loss_scale": "1", "train_wall": "597", "gb_free": "39.2", "wall": "6867"}
[2024-10-04 20:15:12,469][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-10-04 20:15:12,626][train][INFO] - {"epoch": 43, "train_loss": "0.986", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "58035.7", "train_ups": "0.22", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "20583", "train_lr": "0.000321609", "train_gnorm": "0.571", "train_loss_scale": "1", "train_train_wall": "1470", "train_gb_free": "39.7", "train_wall": "7639"}
[2024-10-04 20:15:13,069][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 20:15:13,100][fairseq.trainer][INFO] - begin training epoch 44
[2024-10-04 20:15:13,100][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 20:16:00,653][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-10-04 20:16:00,657][train][INFO] - {"epoch": 43, "train_loss": "0.986", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "58340.4", "train_ups": "0.22", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "20583", "train_lr": "0.000321609", "train_gnorm": "0.584", "train_loss_scale": "1", "train_train_wall": "1481", "train_gb_free": "39.7", "train_wall": "7553"}
[2024-10-04 20:16:00,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 20:16:00,796][fairseq.trainer][INFO] - begin training epoch 44
[2024-10-04 20:16:00,797][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 20:24:33,491][train_inner][INFO] - {"epoch": 44, "update": 43.035, "loss": "0.986", "ntokens": "263073", "nsentences": "1721.05", "wps": "43899.9", "ups": "0.17", "wpb": "263074", "bsz": "1721", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.562", "loss_scale": "1", "train_wall": "658", "gb_free": "39.7", "wall": "8066"}
[2024-10-04 20:25:22,884][train_inner][INFO] - {"epoch": 44, "update": 43.035, "loss": "0.986", "ntokens": "263073", "nsentences": "1721.05", "wps": "42039.8", "ups": "0.16", "wpb": "263074", "bsz": "1721", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.571", "loss_scale": "1", "train_wall": "674", "gb_free": "39.7", "wall": "8249"}
[2024-10-04 20:36:08,770][train_inner][INFO] - {"epoch": 44, "update": 43.453, "loss": "0.981", "ntokens": "263745", "nsentences": "1773.98", "wps": "75881.5", "ups": "0.29", "wpb": "263745", "bsz": "1774", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.526", "loss_scale": "1", "train_wall": "638", "gb_free": "39.7", "wall": "8761"}
[2024-10-04 20:36:09,690][train_inner][INFO] - {"epoch": 44, "update": 43.453, "loss": "0.981", "ntokens": "263745", "nsentences": "1773.98", "wps": "81553.8", "ups": "0.31", "wpb": "263745", "bsz": "1774", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.514", "loss_scale": "1", "train_wall": "597", "gb_free": "39.7", "wall": "8896"}
[2024-10-04 20:51:04,090][train_inner][INFO] - {"epoch": 44, "update": 43.871, "loss": "0.982", "ntokens": "264278", "nsentences": "1739.31", "wps": "59098.7", "ups": "0.22", "wpb": "264278", "bsz": "1739.3", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.551", "loss_scale": "1", "train_wall": "866", "gb_free": "40.1", "wall": "9790"}
[2024-10-04 20:51:12,216][train_inner][INFO] - {"epoch": 44, "update": 43.871, "loss": "0.982", "ntokens": "264278", "nsentences": "1739.31", "wps": "58505.6", "ups": "0.22", "wpb": "264278", "bsz": "1739.3", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.566", "loss_scale": "1", "train_wall": "874", "gb_free": "40.1", "wall": "9664"}
[2024-10-04 20:54:30,930][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-10-04 20:54:30,982][train][INFO] - {"epoch": 44, "train_loss": "0.982", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "54627.9", "train_ups": "0.21", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "21062", "train_lr": "0.000329094", "train_gnorm": "0.532", "train_loss_scale": "1", "train_train_wall": "1797", "train_gb_free": "40.2", "train_wall": "9863"}
[2024-10-04 20:54:31,000][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-10-04 20:54:31,003][train][INFO] - {"epoch": 44, "train_loss": "0.982", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "53514.5", "train_ups": "0.2", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "21062", "train_lr": "0.000329094", "train_gnorm": "0.527", "train_loss_scale": "1", "train_train_wall": "1816", "train_gb_free": "40.2", "train_wall": "9997"}
[2024-10-04 20:54:31,176][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 20:54:31,213][fairseq.trainer][INFO] - begin training epoch 45
[2024-10-04 20:54:31,222][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 20:54:31,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 20:54:31,443][fairseq.trainer][INFO] - begin training epoch 45
[2024-10-04 20:54:31,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 21:11:23,079][train_inner][INFO] - {"epoch": 45, "update": 44.288, "loss": "0.98", "ntokens": "262629", "nsentences": "1774.3", "wps": "43379.7", "ups": "0.17", "wpb": "262629", "bsz": "1774.3", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.532", "loss_scale": "2", "train_wall": "780", "gb_free": "39.9", "wall": "10875"}
[2024-10-04 21:11:23,092][train_inner][INFO] - {"epoch": 45, "update": 44.288, "loss": "0.979", "ntokens": "262629", "nsentences": "1774.3", "wps": "43090.8", "ups": "0.16", "wpb": "262629", "bsz": "1774.3", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.526", "loss_scale": "2", "train_wall": "780", "gb_free": "39.9", "wall": "11009"}
[2024-10-04 21:23:54,180][train_inner][INFO] - {"epoch": 45, "update": 44.706, "loss": "0.98", "ntokens": "264213", "nsentences": "1750.91", "wps": "70360.2", "ups": "0.27", "wpb": "264213", "bsz": "1750.9", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.577", "loss_scale": "2", "train_wall": "719", "gb_free": "40", "wall": "11626"}
[2024-10-04 21:23:54,719][train_inner][INFO] - {"epoch": 45, "update": 44.706, "loss": "0.98", "ntokens": "264213", "nsentences": "1750.91", "wps": "70308.2", "ups": "0.27", "wpb": "264213", "bsz": "1750.9", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.566", "loss_scale": "2", "train_wall": "719", "gb_free": "40", "wall": "11761"}
[2024-10-04 21:31:49,289][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-10-04 21:31:49,535][train][INFO] - {"epoch": 45, "train_loss": "0.979", "train_ntokens": "263585", "train_nsentences": "1753.71", "train_wps": "56407.4", "train_ups": "0.21", "train_wpb": "263585", "train_bsz": "1753.7", "train_num_updates": "21541", "train_lr": "0.000336578", "train_gnorm": "0.539", "train_loss_scale": "2", "train_train_wall": "1681", "train_gb_free": "39.2", "train_wall": "12235"}
[2024-10-04 21:31:49,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 21:31:49,951][fairseq.trainer][INFO] - begin training epoch 46
[2024-10-04 21:31:49,952][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 21:32:42,225][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-10-04 21:32:42,266][train][INFO] - {"epoch": 45, "train_loss": "0.979", "train_ntokens": "263585", "train_nsentences": "1753.71", "train_wps": "55103.8", "train_ups": "0.21", "train_wpb": "263585", "train_bsz": "1753.7", "train_num_updates": "21541", "train_lr": "0.000336578", "train_gnorm": "0.556", "train_loss_scale": "2", "train_train_wall": "1748", "train_gb_free": "39.2", "train_wall": "12154"}
[2024-10-04 21:32:42,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 21:32:42,520][fairseq.trainer][INFO] - begin training epoch 46
[2024-10-04 21:32:42,526][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 21:43:42,802][train_inner][INFO] - {"epoch": 46, "update": 45.123, "loss": "0.978", "ntokens": "263028", "nsentences": "1718.47", "wps": "44279.3", "ups": "0.17", "wpb": "263028", "bsz": "1718.5", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.501", "loss_scale": "2", "train_wall": "619", "gb_free": "39.6", "wall": "12949"}
[2024-10-04 21:43:42,817][train_inner][INFO] - {"epoch": 46, "update": 45.123, "loss": "0.978", "ntokens": "263028", "nsentences": "1718.47", "wps": "44258.3", "ups": "0.17", "wpb": "263028", "bsz": "1718.5", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.516", "loss_scale": "2", "train_wall": "676", "gb_free": "39.6", "wall": "12815"}
[2024-10-04 21:55:14,461][train_inner][INFO] - {"epoch": 46, "update": 45.541, "loss": "0.973", "ntokens": "263980", "nsentences": "1747.83", "wps": "76340.6", "ups": "0.29", "wpb": "263980", "bsz": "1747.8", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.53", "loss_scale": "2", "train_wall": "666", "gb_free": "40.5", "wall": "13640"}
[2024-10-04 21:55:17,925][train_inner][INFO] - {"epoch": 46, "update": 45.541, "loss": "0.973", "ntokens": "263980", "nsentences": "1747.83", "wps": "75954.3", "ups": "0.29", "wpb": "263980", "bsz": "1747.8", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.508", "loss_scale": "2", "train_wall": "673", "gb_free": "40.5", "wall": "13510"}
[2024-10-04 22:08:30,076][train_inner][INFO] - {"epoch": 46, "update": 45.958, "loss": "0.978", "ntokens": "263963", "nsentences": "1773.97", "wps": "66650", "ups": "0.25", "wpb": "263963", "bsz": "1774", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.507", "loss_scale": "2", "train_wall": "718", "gb_free": "39.7", "wall": "14302"}
[2024-10-04 22:08:30,529][train_inner][INFO] - {"epoch": 46, "update": 45.958, "loss": "0.978", "ntokens": "263963", "nsentences": "1773.97", "wps": "66317.9", "ups": "0.25", "wpb": "263963", "bsz": "1774", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.53", "loss_scale": "2", "train_wall": "766", "gb_free": "39.7", "wall": "14437"}
[2024-10-04 22:09:38,177][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-10-04 22:09:38,195][train][INFO] - {"epoch": 46, "train_loss": "0.976", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "56961.5", "train_ups": "0.22", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "22020", "train_lr": "0.000344063", "train_gnorm": "0.508", "train_loss_scale": "2", "train_train_wall": "1695", "train_gb_free": "39.8", "train_wall": "14370"}
[2024-10-04 22:09:38,459][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 22:09:38,508][fairseq.trainer][INFO] - begin training epoch 47
[2024-10-04 22:09:38,518][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 22:10:02,418][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-10-04 22:10:02,429][train][INFO] - {"epoch": 46, "train_loss": "0.976", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "55049.4", "train_ups": "0.21", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "22020", "train_lr": "0.000344063", "train_gnorm": "0.527", "train_loss_scale": "2", "train_train_wall": "1760", "train_gb_free": "39.7", "train_wall": "14528"}
[2024-10-04 22:10:02,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 22:10:02,542][fairseq.trainer][INFO] - begin training epoch 47
[2024-10-04 22:10:02,542][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 22:29:05,291][train_inner][INFO] - {"epoch": 47, "update": 46.376, "loss": "0.973", "ntokens": "263002", "nsentences": "1745.89", "wps": "42585.9", "ups": "0.16", "wpb": "263002", "bsz": "1745.9", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.512", "loss_scale": "2", "train_wall": "794", "gb_free": "40.3", "wall": "15537"}
[2024-10-04 22:29:09,025][train_inner][INFO] - {"epoch": 47, "update": 46.376, "loss": "0.973", "ntokens": "263002", "nsentences": "1745.89", "wps": "42471.7", "ups": "0.16", "wpb": "263002", "bsz": "1745.9", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.519", "loss_scale": "2", "train_wall": "817", "gb_free": "40.3", "wall": "15675"}
[2024-10-04 22:41:46,230][train_inner][INFO] - {"epoch": 47, "update": 46.793, "loss": "0.974", "ntokens": "263722", "nsentences": "1786.56", "wps": "69337.6", "ups": "0.26", "wpb": "263722", "bsz": "1786.6", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.509", "loss_scale": "2", "train_wall": "757", "gb_free": "39.3", "wall": "16298"}
[2024-10-04 22:41:49,760][train_inner][INFO] - {"epoch": 47, "update": 46.793, "loss": "0.974", "ntokens": "263722", "nsentences": "1786.56", "wps": "69333.9", "ups": "0.26", "wpb": "263722", "bsz": "1786.6", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.526", "loss_scale": "2", "train_wall": "756", "gb_free": "39.2", "wall": "16436"}
[2024-10-04 22:46:13,725][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-10-04 22:46:13,926][train][INFO] - {"epoch": 47, "train_loss": "0.973", "train_ntokens": "263578", "train_nsentences": "1753.71", "train_wps": "58144.8", "train_ups": "0.22", "train_wpb": "263578", "train_bsz": "1753.7", "train_num_updates": "22499", "train_lr": "0.000351547", "train_gnorm": "0.516", "train_loss_scale": "2", "train_train_wall": "1709", "train_gb_free": "39.1", "train_wall": "16700"}
[2024-10-04 22:46:14,453][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 22:46:14,583][fairseq.trainer][INFO] - begin training epoch 48
[2024-10-04 22:46:14,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 22:47:35,115][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-10-04 22:47:35,134][train][INFO] - {"epoch": 47, "train_loss": "0.973", "train_ntokens": "263578", "train_nsentences": "1753.71", "train_wps": "55449.2", "train_ups": "0.21", "train_wpb": "263578", "train_bsz": "1753.7", "train_num_updates": "22499", "train_lr": "0.000351547", "train_gnorm": "0.503", "train_loss_scale": "2", "train_train_wall": "1807", "train_gb_free": "39.1", "train_wall": "16647"}
[2024-10-04 22:47:35,219][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 22:47:35,227][fairseq.trainer][INFO] - begin training epoch 48
[2024-10-04 22:47:35,228][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 23:02:48,510][train_inner][INFO] - {"epoch": 48, "update": 47.211, "loss": "0.972", "ntokens": "263166", "nsentences": "1733.87", "wps": "41815", "ups": "0.16", "wpb": "263166", "bsz": "1733.9", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.522", "loss_scale": "2", "train_wall": "758", "gb_free": "39.6", "wall": "17694"}
[2024-10-04 23:05:44,232][train_inner][INFO] - {"epoch": 48, "update": 47.211, "loss": "0.972", "ntokens": "263166", "nsentences": "1733.87", "wps": "36602.5", "ups": "0.14", "wpb": "263166", "bsz": "1733.9", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.502", "loss_scale": "2", "train_wall": "997", "gb_free": "39.6", "wall": "17736"}
[2024-10-04 23:19:20,601][train_inner][INFO] - {"epoch": 48, "update": 47.628, "loss": "0.969", "ntokens": "264140", "nsentences": "1758.98", "wps": "53254.7", "ups": "0.2", "wpb": "264140", "bsz": "1759", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.508", "loss_scale": "2", "train_wall": "989", "gb_free": "39.6", "wall": "18686"}
[2024-10-04 23:24:32,142][train_inner][INFO] - {"epoch": 48, "update": 47.628, "loss": "0.969", "ntokens": "264140", "nsentences": "1758.98", "wps": "46841.1", "ups": "0.18", "wpb": "264140", "bsz": "1759", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.506", "loss_scale": "2", "train_wall": "1122", "gb_free": "39.6", "wall": "18864"}
[2024-10-04 23:34:23,921][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-10-04 23:34:24,070][train][INFO] - {"epoch": 48, "train_loss": "0.971", "train_ntokens": "263670", "train_nsentences": "1753.71", "train_wps": "43701.2", "train_ups": "0.17", "train_wpb": "263670", "train_bsz": "1753.7", "train_num_updates": "22978", "train_lr": "0.000359031", "train_gnorm": "0.523", "train_loss_scale": "2", "train_train_wall": "2420", "train_gb_free": "39.3", "train_wall": "19590"}
[2024-10-04 23:34:24,966][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 23:34:24,986][fairseq.trainer][INFO] - begin training epoch 49
[2024-10-04 23:34:24,987][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 23:36:08,372][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-10-04 23:36:08,430][train][INFO] - {"epoch": 48, "train_loss": "0.971", "train_ntokens": "263670", "train_nsentences": "1753.71", "train_wps": "43352.5", "train_ups": "0.16", "train_wpb": "263670", "train_bsz": "1753.7", "train_num_updates": "22978", "train_lr": "0.000359031", "train_gnorm": "0.509", "train_loss_scale": "2", "train_train_wall": "2405", "train_gb_free": "39.3", "train_wall": "19561"}
[2024-10-04 23:36:08,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-04 23:36:08,827][fairseq.trainer][INFO] - begin training epoch 49
[2024-10-04 23:36:08,828][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-04 23:43:38,032][train_inner][INFO] - {"epoch": 49, "update": 48.046, "loss": "0.972", "ntokens": "262916", "nsentences": "1753.06", "wps": "36081", "ups": "0.14", "wpb": "262916", "bsz": "1753.1", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.522", "loss_scale": "2", "train_wall": "909", "gb_free": "39.7", "wall": "20144"}
[2024-10-04 23:48:03,714][train_inner][INFO] - {"epoch": 49, "update": 48.046, "loss": "0.972", "ntokens": "262916", "nsentences": "1753.06", "wps": "37255.6", "ups": "0.14", "wpb": "262916", "bsz": "1753.1", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.498", "loss_scale": "2", "train_wall": "872", "gb_free": "39.7", "wall": "20276"}
[2024-10-05 00:01:42,134][train_inner][INFO] - {"epoch": 49, "update": 48.463, "loss": "0.966", "ntokens": "264063", "nsentences": "1760.23", "wps": "48718.4", "ups": "0.18", "wpb": "264063", "bsz": "1760.2", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.489", "loss_scale": "2", "train_wall": "695", "gb_free": "39.6", "wall": "21228"}
[2024-10-05 00:05:46,428][train_inner][INFO] - {"epoch": 49, "update": 48.463, "loss": "0.966", "ntokens": "264063", "nsentences": "1760.23", "wps": "49698.6", "ups": "0.19", "wpb": "264063", "bsz": "1760.2", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.508", "loss_scale": "2", "train_wall": "772", "gb_free": "39.6", "wall": "21339"}
[2024-10-05 00:06:13,390][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 00:09:52,284][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 00:19:43,246][train_inner][INFO] - {"epoch": 49, "update": 48.883, "loss": "0.969", "ntokens": "264107", "nsentences": "1759.87", "wps": "48859.6", "ups": "0.18", "wpb": "264107", "bsz": "1759.9", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.502", "loss_scale": "2", "train_wall": "928", "gb_free": "39.3", "wall": "22309"}
[2024-10-05 00:23:32,173][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-10-05 00:23:32,223][train][INFO] - {"epoch": 49, "train_loss": "0.968", "train_ntokens": "263628", "train_nsentences": "1754.11", "train_wps": "42743.5", "train_ups": "0.16", "train_wpb": "263628", "train_bsz": "1754.1", "train_num_updates": "23456", "train_lr": "0.0003665", "train_gnorm": "0.494", "train_loss_scale": "2", "train_train_wall": "1851", "train_gb_free": "40.5", "train_wall": "22538"}
[2024-10-05 00:23:34,695][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 00:23:34,731][fairseq.trainer][INFO] - begin training epoch 50
[2024-10-05 00:23:34,732][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 00:24:14,217][train_inner][INFO] - {"epoch": 49, "update": 48.883, "loss": "0.969", "ntokens": "264080", "nsentences": "1761.27", "wps": "47677.5", "ups": "0.18", "wpb": "264080", "bsz": "1761.3", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.495", "loss_scale": "2", "train_wall": "943", "gb_free": "39.3", "wall": "22446"}
[2024-10-05 00:25:51,757][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-10-05 00:25:51,776][train][INFO] - {"epoch": 49, "train_loss": "0.968", "train_ntokens": "263616", "train_nsentences": "1754.7", "train_wps": "42237.4", "train_ups": "0.16", "train_wpb": "263616", "train_bsz": "1754.7", "train_num_updates": "23456", "train_lr": "0.0003665", "train_gnorm": "0.5", "train_loss_scale": "2", "train_train_wall": "2067", "train_gb_free": "40.5", "train_wall": "22544"}
[2024-10-05 00:25:51,996][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 00:25:52,035][fairseq.trainer][INFO] - begin training epoch 50
[2024-10-05 00:25:52,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 00:45:24,009][train_inner][INFO] - {"epoch": 50, "update": 49.301, "loss": "0.966", "ntokens": "262636", "nsentences": "1780.12", "wps": "34093", "ups": "0.13", "wpb": "262636", "bsz": "1780.1", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.477", "loss_scale": "2", "train_wall": "878", "gb_free": "39.2", "wall": "23850"}
[2024-10-05 00:50:40,737][train_inner][INFO] - {"epoch": 50, "update": 49.301, "loss": "0.966", "ntokens": "262636", "nsentences": "1780.12", "wps": "33109.1", "ups": "0.13", "wpb": "262636", "bsz": "1780.1", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.497", "loss_scale": "2", "train_wall": "1176", "gb_free": "39.2", "wall": "24033"}
[2024-10-05 01:02:46,355][train_inner][INFO] - {"epoch": 50, "update": 49.718, "loss": "0.966", "ntokens": "264146", "nsentences": "1747.28", "wps": "50686.6", "ups": "0.19", "wpb": "264146", "bsz": "1747.3", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.499", "loss_scale": "2", "train_wall": "995", "gb_free": "39.6", "wall": "24892"}
[2024-10-05 01:08:17,028][train_inner][INFO] - {"epoch": 50, "update": 49.718, "loss": "0.966", "ntokens": "264146", "nsentences": "1747.28", "wps": "50014.7", "ups": "0.19", "wpb": "264146", "bsz": "1747.3", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.497", "loss_scale": "2", "train_wall": "982", "gb_free": "39.6", "wall": "25089"}
[2024-10-05 01:11:56,201][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 23935 updates
[2024-10-05 01:11:56,202][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 01:12:05,316][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 01:12:05,327][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 50 @ 23935 updates, score None) (writing took 9.125347146764398 seconds)
[2024-10-05 01:12:05,327][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-10-05 01:12:05,382][train][INFO] - {"epoch": 50, "train_loss": "0.966", "train_ntokens": "263615", "train_nsentences": "1753.71", "train_wps": "43346", "train_ups": "0.16", "train_wpb": "263614", "train_bsz": "1753.7", "train_num_updates": "23935", "train_lr": "0.000373984", "train_gnorm": "0.497", "train_loss_scale": "2", "train_train_wall": "2158", "train_gb_free": "39.2", "train_wall": "25451"}
[2024-10-05 01:12:05,552][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 01:12:05,578][fairseq.trainer][INFO] - begin training epoch 51
[2024-10-05 01:12:05,578][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 01:14:32,058][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 23935 updates
[2024-10-05 01:14:32,074][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 01:15:04,258][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 01:15:04,382][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 50 @ 23935 updates, score None) (writing took 32.323703452944756 seconds)
[2024-10-05 01:15:04,383][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-10-05 01:15:04,410][train][INFO] - {"epoch": 50, "train_loss": "0.966", "train_ntokens": "263615", "train_nsentences": "1753.71", "train_wps": "42766.2", "train_ups": "0.16", "train_wpb": "263614", "train_bsz": "1753.7", "train_num_updates": "23935", "train_lr": "0.000373984", "train_gnorm": "0.499", "train_loss_scale": "2", "train_train_wall": "2412", "train_gb_free": "39.2", "train_wall": "25497"}
[2024-10-05 01:15:04,515][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 01:15:04,553][fairseq.trainer][INFO] - begin training epoch 51
[2024-10-05 01:15:04,554][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 01:22:16,262][train_inner][INFO] - {"epoch": 51, "update": 50.136, "loss": "0.965", "ntokens": "263152", "nsentences": "1712.71", "wps": "44987.4", "ups": "0.17", "wpb": "263152", "bsz": "1712.7", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.504", "loss_scale": "2", "train_wall": "665", "gb_free": "40.5", "wall": "26062"}
[2024-10-05 01:31:05,733][train_inner][INFO] - {"epoch": 51, "update": 50.136, "loss": "0.965", "ntokens": "263152", "nsentences": "1712.71", "wps": "38453.7", "ups": "0.15", "wpb": "263152", "bsz": "1712.7", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.499", "loss_scale": "2", "train_wall": "796", "gb_free": "40.5", "wall": "26458"}
[2024-10-05 01:39:33,489][train_inner][INFO] - {"epoch": 51, "update": 50.553, "loss": "0.963", "ntokens": "264255", "nsentences": "1747.31", "wps": "50956.8", "ups": "0.19", "wpb": "264254", "bsz": "1747.3", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.462", "loss_scale": "2", "train_wall": "905", "gb_free": "39.3", "wall": "27099"}
[2024-10-05 01:51:15,443][train_inner][INFO] - {"epoch": 51, "update": 50.553, "loss": "0.963", "ntokens": "264255", "nsentences": "1747.31", "wps": "43691", "ups": "0.17", "wpb": "264254", "bsz": "1747.3", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.466", "loss_scale": "2", "train_wall": "1114", "gb_free": "39.3", "wall": "27668"}
[2024-10-05 01:59:57,434][train_inner][INFO] - {"epoch": 51, "update": 50.971, "loss": "0.966", "ntokens": "263864", "nsentences": "1769.48", "wps": "43122", "ups": "0.16", "wpb": "263864", "bsz": "1769.5", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.485", "loss_scale": "2", "train_wall": "1221", "gb_free": "39.2", "wall": "28323"}
[2024-10-05 02:00:33,247][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-10-05 02:00:33,271][train][INFO] - {"epoch": 51, "train_loss": "0.964", "train_ntokens": "263532", "train_nsentences": "1753.71", "train_wps": "43410.3", "train_ups": "0.16", "train_wpb": "263532", "train_bsz": "1753.7", "train_num_updates": "24414", "train_lr": "0.000381469", "train_gnorm": "0.474", "train_loss_scale": "2", "train_train_wall": "2320", "train_gb_free": "40", "train_wall": "28359"}
[2024-10-05 02:00:35,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 02:00:35,781][fairseq.trainer][INFO] - begin training epoch 52
[2024-10-05 02:00:35,782][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 02:02:26,758][train_inner][INFO] - {"epoch": 51, "update": 50.971, "loss": "0.966", "ntokens": "263864", "nsentences": "1769.48", "wps": "78612.2", "ups": "0.3", "wpb": "263864", "bsz": "1769.5", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.509", "loss_scale": "2", "train_wall": "664", "gb_free": "39.3", "wall": "28339"}
[2024-10-05 02:02:49,727][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-10-05 02:02:49,747][train][INFO] - {"epoch": 51, "train_loss": "0.964", "train_ntokens": "263532", "train_nsentences": "1753.71", "train_wps": "44055.1", "train_ups": "0.17", "train_wpb": "263532", "train_bsz": "1753.7", "train_num_updates": "24414", "train_lr": "0.000381469", "train_gnorm": "0.489", "train_loss_scale": "2", "train_train_wall": "2253", "train_gb_free": "40", "train_wall": "28362"}
[2024-10-05 02:02:50,158][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 02:02:50,175][fairseq.trainer][INFO] - begin training epoch 52
[2024-10-05 02:02:50,176][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 02:26:01,743][train_inner][INFO] - {"epoch": 52, "update": 51.388, "loss": "0.96", "ntokens": "262984", "nsentences": "1723.41", "wps": "33624.3", "ups": "0.13", "wpb": "262984", "bsz": "1723.4", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.495", "loss_scale": "2", "train_wall": "934", "gb_free": "39.3", "wall": "29888"}
[2024-10-05 02:30:43,594][train_inner][INFO] - {"epoch": 52, "update": 51.388, "loss": "0.96", "ntokens": "262984", "nsentences": "1723.41", "wps": "30997.4", "ups": "0.12", "wpb": "262984", "bsz": "1723.4", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.5", "loss_scale": "2", "train_wall": "1026", "gb_free": "39.3", "wall": "30036"}
[2024-10-05 02:41:52,322][train_inner][INFO] - {"epoch": 52, "update": 51.806, "loss": "0.965", "ntokens": "263837", "nsentences": "1807.09", "wps": "55514.5", "ups": "0.21", "wpb": "263837", "bsz": "1807.1", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.471", "loss_scale": "2", "train_wall": "538", "gb_free": "39.6", "wall": "30838"}
[2024-10-05 02:50:03,161][train_inner][INFO] - {"epoch": 52, "update": 51.806, "loss": "0.965", "ntokens": "263837", "nsentences": "1807.09", "wps": "45509.9", "ups": "0.17", "wpb": "263837", "bsz": "1807.1", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.475", "loss_scale": "2", "train_wall": "508", "gb_free": "39.6", "wall": "31195"}
[2024-10-05 02:50:27,280][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-10-05 02:50:27,404][train][INFO] - {"epoch": 52, "train_loss": "0.962", "train_ntokens": "263507", "train_nsentences": "1753.71", "train_wps": "42156.8", "train_ups": "0.16", "train_wpb": "263507", "train_bsz": "1753.7", "train_num_updates": "24893", "train_lr": "0.000388953", "train_gnorm": "0.487", "train_loss_scale": "2", "train_train_wall": "1925", "train_gb_free": "39.1", "train_wall": "31353"}
[2024-10-05 02:50:29,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 02:50:29,184][fairseq.trainer][INFO] - begin training epoch 53
[2024-10-05 02:50:29,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 02:52:53,164][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-10-05 02:52:53,197][train][INFO] - {"epoch": 52, "train_loss": "0.962", "train_ntokens": "263507", "train_nsentences": "1753.71", "train_wps": "42025", "train_ups": "0.16", "train_wpb": "263507", "train_bsz": "1753.7", "train_num_updates": "24893", "train_lr": "0.000388953", "train_gnorm": "0.486", "train_loss_scale": "2", "train_train_wall": "1672", "train_gb_free": "39.1", "train_wall": "31365"}
[2024-10-05 02:52:53,781][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 02:52:53,839][fairseq.trainer][INFO] - begin training epoch 53
[2024-10-05 02:52:53,867][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 03:07:02,953][train_inner][INFO] - {"epoch": 53, "update": 52.223, "loss": "0.958", "ntokens": "262894", "nsentences": "1722.63", "wps": "34807.2", "ups": "0.13", "wpb": "262894", "bsz": "1722.6", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.478", "loss_scale": "2", "train_wall": "993", "gb_free": "40", "wall": "32349"}
[2024-10-05 03:12:27,696][train_inner][INFO] - {"epoch": 53, "update": 52.223, "loss": "0.959", "ntokens": "262894", "nsentences": "1722.63", "wps": "39108.5", "ups": "0.15", "wpb": "262894", "bsz": "1722.6", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.498", "loss_scale": "2", "train_wall": "364", "gb_free": "40", "wall": "32540"}
[2024-10-05 03:27:13,000][train_inner][INFO] - {"epoch": 53, "update": 52.641, "loss": "0.959", "ntokens": "264038", "nsentences": "1750.95", "wps": "43645.4", "ups": "0.17", "wpb": "264038", "bsz": "1751", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.483", "loss_scale": "2", "train_wall": "1053", "gb_free": "39.6", "wall": "33559"}
[2024-10-05 03:32:28,273][train_inner][INFO] - {"epoch": 53, "update": 52.641, "loss": "0.959", "ntokens": "264038", "nsentences": "1750.95", "wps": "43994.7", "ups": "0.17", "wpb": "264038", "bsz": "1751", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.462", "loss_scale": "2", "train_wall": "1023", "gb_free": "39.6", "wall": "33740"}
[2024-10-05 03:36:51,681][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 03:39:29,742][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-10-05 03:39:29,784][train][INFO] - {"epoch": 53, "train_loss": "0.959", "train_ntokens": "263533", "train_nsentences": "1752.87", "train_wps": "42812.3", "train_ups": "0.16", "train_wpb": "263532", "train_bsz": "1752.9", "train_num_updates": "25371", "train_lr": "0.000396422", "train_gnorm": "0.483", "train_loss_scale": "2", "train_train_wall": "2060", "train_gb_free": "39.6", "train_wall": "34296"}
[2024-10-05 03:39:30,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 03:39:30,607][fairseq.trainer][INFO] - begin training epoch 54
[2024-10-05 03:39:30,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 03:40:16,960][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 03:41:40,436][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-10-05 03:41:40,506][train][INFO] - {"epoch": 53, "train_loss": "0.959", "train_ntokens": "263528", "train_nsentences": "1753.94", "train_wps": "43031.7", "train_ups": "0.16", "train_wpb": "263528", "train_bsz": "1753.9", "train_num_updates": "25371", "train_lr": "0.000396422", "train_gnorm": "0.475", "train_loss_scale": "2", "train_train_wall": "1460", "train_gb_free": "39.6", "train_wall": "34293"}
[2024-10-05 03:41:41,135][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 03:41:41,175][fairseq.trainer][INFO] - begin training epoch 54
[2024-10-05 03:41:41,190][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 03:48:52,301][train_inner][INFO] - {"epoch": 54, "update": 53.061, "loss": "0.962", "ntokens": "262689", "nsentences": "1761.78", "wps": "40436.6", "ups": "0.15", "wpb": "262689", "bsz": "1761.8", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.483", "loss_scale": "2", "train_wall": "563", "gb_free": "39.7", "wall": "34858"}
[2024-10-05 03:54:38,598][train_inner][INFO] - {"epoch": 54, "update": 53.061, "loss": "0.962", "ntokens": "262677", "nsentences": "1764.35", "wps": "39493.3", "ups": "0.15", "wpb": "262677", "bsz": "1764.4", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.459", "loss_scale": "2", "train_wall": "556", "gb_free": "39.7", "wall": "35071"}
[2024-10-05 04:05:39,403][train_inner][INFO] - {"epoch": 54, "update": 53.478, "loss": "0.954", "ntokens": "264281", "nsentences": "1729.11", "wps": "52484.5", "ups": "0.2", "wpb": "264281", "bsz": "1729.1", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.488", "loss_scale": "2", "train_wall": "858", "gb_free": "39.6", "wall": "35865"}
[2024-10-05 04:11:43,411][train_inner][INFO] - {"epoch": 54, "update": 53.478, "loss": "0.954", "ntokens": "264281", "nsentences": "1729.11", "wps": "51578.7", "ups": "0.2", "wpb": "264281", "bsz": "1729.1", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.481", "loss_scale": "2", "train_wall": "1021", "gb_free": "39.6", "wall": "36096"}
[2024-10-05 04:23:52,879][train_inner][INFO] - {"epoch": 54, "update": 53.896, "loss": "0.959", "ntokens": "263793", "nsentences": "1782.35", "wps": "48250", "ups": "0.18", "wpb": "263792", "bsz": "1782.4", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.47", "loss_scale": "2", "train_wall": "915", "gb_free": "39.6", "wall": "36959"}
[2024-10-05 04:27:42,924][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-10-05 04:27:43,102][train][INFO] - {"epoch": 54, "train_loss": "0.958", "train_ntokens": "263482", "train_nsentences": "1753.71", "train_wps": "43622.9", "train_ups": "0.17", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "25850", "train_lr": "0.000403906", "train_gnorm": "0.47", "train_loss_scale": "2", "train_train_wall": "2064", "train_gb_free": "39.8", "train_wall": "37189"}
[2024-10-05 04:27:44,046][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 04:27:44,087][fairseq.trainer][INFO] - begin training epoch 55
[2024-10-05 04:27:44,094][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 04:28:49,519][train_inner][INFO] - {"epoch": 54, "update": 53.896, "loss": "0.959", "ntokens": "263793", "nsentences": "1782.35", "wps": "51416.9", "ups": "0.19", "wpb": "263792", "bsz": "1782.4", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.443", "loss_scale": "2", "train_wall": "930", "gb_free": "39.6", "wall": "37122"}
[2024-10-05 04:30:10,668][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-10-05 04:30:10,692][train][INFO] - {"epoch": 54, "train_loss": "0.957", "train_ntokens": "263482", "train_nsentences": "1753.71", "train_wps": "43367.7", "train_ups": "0.16", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "25850", "train_lr": "0.000403906", "train_gnorm": "0.45", "train_loss_scale": "2", "train_train_wall": "2343", "train_gb_free": "39.8", "train_wall": "37203"}
[2024-10-05 04:30:10,864][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 04:30:10,885][fairseq.trainer][INFO] - begin training epoch 55
[2024-10-05 04:30:10,886][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 04:42:53,161][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-05 04:49:14,622][train_inner][INFO] - {"epoch": 55, "update": 54.313, "loss": "0.956", "ntokens": "262807", "nsentences": "1751.24", "wps": "34541.8", "ups": "0.13", "wpb": "262807", "bsz": "1751.2", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.473", "loss_scale": "2", "train_wall": "992", "gb_free": "39.6", "wall": "38481"}
[2024-10-05 04:54:25,460][train_inner][INFO] - {"epoch": 55, "update": 54.315, "loss": "0.955", "ntokens": "262845", "nsentences": "1745.6", "wps": "34226.5", "ups": "0.13", "wpb": "262845", "bsz": "1745.6", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.455", "loss_scale": "1", "train_wall": "1077", "gb_free": "39.6", "wall": "38658"}
[2024-10-05 05:09:34,292][train_inner][INFO] - {"epoch": 55, "update": 54.731, "loss": "0.956", "ntokens": "263867", "nsentences": "1767.84", "wps": "43270.8", "ups": "0.16", "wpb": "263867", "bsz": "1767.8", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.485", "loss_scale": "2", "train_wall": "894", "gb_free": "40", "wall": "39700"}
[2024-10-05 05:14:19,237][train_inner][INFO] - {"epoch": 55, "update": 54.733, "loss": "0.956", "ntokens": "263846", "nsentences": "1770.21", "wps": "44208.3", "ups": "0.17", "wpb": "263846", "bsz": "1770.2", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.472", "loss_scale": "1", "train_wall": "1002", "gb_free": "40.1", "wall": "39851"}
[2024-10-05 05:18:34,370][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-10-05 05:18:34,492][train][INFO] - {"epoch": 55, "train_loss": "0.956", "train_ntokens": "263519", "train_nsentences": "1753.71", "train_wps": "41367.5", "train_ups": "0.16", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "26329", "train_lr": "0.000411391", "train_gnorm": "0.475", "train_loss_scale": "2", "train_train_wall": "2194", "train_gb_free": "39.7", "train_wall": "40240"}
[2024-10-05 05:18:36,603][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 05:18:36,666][fairseq.trainer][INFO] - begin training epoch 56
[2024-10-05 05:18:36,669][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 05:19:54,338][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-10-05 05:19:54,368][train][INFO] - {"epoch": 55, "train_loss": "0.956", "train_ntokens": "263522", "train_nsentences": "1752.49", "train_wps": "42217.6", "train_ups": "0.16", "train_wpb": "263522", "train_bsz": "1752.5", "train_num_updates": "26328", "train_lr": "0.000411375", "train_gnorm": "0.481", "train_loss_scale": "1", "train_train_wall": "2341", "train_gb_free": "39.7", "train_wall": "40187"}
[2024-10-05 05:19:54,952][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 05:19:54,999][fairseq.trainer][INFO] - begin training epoch 56
[2024-10-05 05:19:55,015][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 05:32:16,052][train_inner][INFO] - {"epoch": 56, "update": 55.148, "loss": "0.956", "ntokens": "263091", "nsentences": "1731.02", "wps": "38641.2", "ups": "0.15", "wpb": "263091", "bsz": "1731", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.454", "loss_scale": "2", "train_wall": "653", "gb_free": "39.3", "wall": "41062"}
[2024-10-05 05:36:40,936][train_inner][INFO] - {"epoch": 56, "update": 55.15, "loss": "0.956", "ntokens": "263084", "nsentences": "1731.7", "wps": "39217.7", "ups": "0.15", "wpb": "263084", "bsz": "1731.7", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.483", "loss_scale": "1", "train_wall": "840", "gb_free": "40", "wall": "41193"}
[2024-10-05 05:52:12,594][train_inner][INFO] - {"epoch": 56, "update": 55.566, "loss": "0.953", "ntokens": "264108", "nsentences": "1755.14", "wps": "44146.9", "ups": "0.17", "wpb": "264108", "bsz": "1755.1", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.492", "loss_scale": "2", "train_wall": "1016", "gb_free": "39.6", "wall": "42259"}
[2024-10-05 05:53:46,524][train_inner][INFO] - {"epoch": 56, "update": 55.568, "loss": "0.953", "ntokens": "264098", "nsentences": "1757.28", "wps": "51502.1", "ups": "0.2", "wpb": "264098", "bsz": "1757.3", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.448", "loss_scale": "1", "train_wall": "864", "gb_free": "40", "wall": "42219"}
[2024-10-05 06:05:33,067][train_inner][INFO] - {"epoch": 56, "update": 55.985, "loss": "0.958", "ntokens": "264147", "nsentences": "1745.89", "wps": "74781.2", "ups": "0.28", "wpb": "264147", "bsz": "1745.9", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.428", "loss_scale": "1", "train_wall": "663", "gb_free": "39.3", "wall": "42925"}
[2024-10-05 06:05:36,858][train_inner][INFO] - {"epoch": 56, "update": 55.983, "loss": "0.958", "ntokens": "264162", "nsentences": "1747.32", "wps": "65693.3", "ups": "0.25", "wpb": "264162", "bsz": "1747.3", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.435", "loss_scale": "2", "train_wall": "576", "gb_free": "40", "wall": "43063"}
[2024-10-05 06:05:54,900][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-10-05 06:05:54,986][train][INFO] - {"epoch": 56, "train_loss": "0.955", "train_ntokens": "263633", "train_nsentences": "1753.71", "train_wps": "44458", "train_ups": "0.17", "train_wpb": "263633", "train_bsz": "1753.7", "train_num_updates": "26808", "train_lr": "0.000418875", "train_gnorm": "0.462", "train_loss_scale": "2", "train_train_wall": "1725", "train_gb_free": "39.2", "train_wall": "43081"}
[2024-10-05 06:05:55,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 06:05:55,403][fairseq.trainer][INFO] - begin training epoch 57
[2024-10-05 06:05:55,410][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 06:05:57,783][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-10-05 06:05:57,811][train][INFO] - {"epoch": 56, "train_loss": "0.955", "train_ntokens": "263633", "train_nsentences": "1753.71", "train_wps": "45697.2", "train_ups": "0.17", "train_wpb": "263633", "train_bsz": "1753.7", "train_num_updates": "26807", "train_lr": "0.000418859", "train_gnorm": "0.439", "train_loss_scale": "1", "train_train_wall": "2059", "train_gb_free": "39.2", "train_wall": "42950"}
[2024-10-05 06:05:58,022][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 06:05:58,043][fairseq.trainer][INFO] - begin training epoch 57
[2024-10-05 06:05:58,054][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 06:26:14,899][train_inner][INFO] - {"epoch": 57, "update": 56.401, "loss": "0.952", "ntokens": "262857", "nsentences": "1773.13", "wps": "42463.5", "ups": "0.16", "wpb": "262857", "bsz": "1773.1", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.422", "loss_scale": "2", "train_wall": "805", "gb_free": "39.4", "wall": "44301"}
[2024-10-05 06:26:14,899][train_inner][INFO] - {"epoch": 57, "update": 56.403, "loss": "0.952", "ntokens": "262894", "nsentences": "1769.58", "wps": "42341.8", "ups": "0.16", "wpb": "262894", "bsz": "1769.6", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.445", "loss_scale": "1", "train_wall": "817", "gb_free": "39.6", "wall": "44167"}
[2024-10-05 06:39:13,525][train_inner][INFO] - {"epoch": 57, "update": 56.82, "loss": "0.953", "ntokens": "263855", "nsentences": "1766.37", "wps": "67780.5", "ups": "0.26", "wpb": "263855", "bsz": "1766.4", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.42", "loss_scale": "1", "train_wall": "774", "gb_free": "39.3", "wall": "44946"}
[2024-10-05 06:39:17,265][train_inner][INFO] - {"epoch": 57, "update": 56.818, "loss": "0.954", "ntokens": "263851", "nsentences": "1766.56", "wps": "67451", "ups": "0.26", "wpb": "263852", "bsz": "1766.6", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.452", "loss_scale": "2", "train_wall": "778", "gb_free": "40.1", "wall": "45083"}
[2024-10-05 06:44:46,935][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-10-05 06:44:47,256][train][INFO] - {"epoch": 57, "train_loss": "0.952", "train_ntokens": "263558", "train_nsentences": "1753.71", "train_wps": "54201.1", "train_ups": "0.21", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "27286", "train_lr": "0.000426344", "train_gnorm": "0.434", "train_loss_scale": "1", "train_train_wall": "1889", "train_gb_free": "39.7", "train_wall": "45279"}
[2024-10-05 06:44:47,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 06:44:47,544][fairseq.trainer][INFO] - begin training epoch 58
[2024-10-05 06:44:47,545][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 06:45:44,993][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-10-05 06:45:44,996][train][INFO] - {"epoch": 57, "train_loss": "0.952", "train_ntokens": "263558", "train_nsentences": "1753.71", "train_wps": "52821.8", "train_ups": "0.2", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "27287", "train_lr": "0.000426359", "train_gnorm": "0.443", "train_loss_scale": "2", "train_train_wall": "1943", "train_gb_free": "39.7", "train_wall": "45471"}
[2024-10-05 06:45:45,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 06:45:45,046][fairseq.trainer][INFO] - begin training epoch 58
[2024-10-05 06:45:45,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 07:01:08,014][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 07:02:16,500][train_inner][INFO] - {"epoch": 58, "update": 57.238, "loss": "0.95", "ntokens": "263048", "nsentences": "1719.23", "wps": "38047.5", "ups": "0.14", "wpb": "263048", "bsz": "1719.2", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.447", "loss_scale": "1", "train_wall": "890", "gb_free": "40.1", "wall": "46328"}
[2024-10-05 07:04:43,878][train_inner][INFO] - {"epoch": 58, "update": 57.238, "loss": "0.95", "ntokens": "263050", "nsentences": "1718.67", "wps": "34462.8", "ups": "0.13", "wpb": "263050", "bsz": "1718.7", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.443", "loss_scale": "2", "train_wall": "1074", "gb_free": "40.1", "wall": "46610"}
[2024-10-05 07:17:51,395][train_inner][INFO] - {"epoch": 58, "update": 57.656, "loss": "0.951", "ntokens": "263907", "nsentences": "1755.69", "wps": "56459.1", "ups": "0.21", "wpb": "263907", "bsz": "1755.7", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.442", "loss_scale": "1", "train_wall": "749", "gb_free": "39.6", "wall": "47264"}
[2024-10-05 07:17:52,062][train_inner][INFO] - {"epoch": 58, "update": 57.656, "loss": "0.951", "ntokens": "263907", "nsentences": "1755.69", "wps": "66966.5", "ups": "0.25", "wpb": "263907", "bsz": "1755.7", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.49", "loss_scale": "2", "train_wall": "582", "gb_free": "39.6", "wall": "47398"}
[2024-10-05 07:28:26,282][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-10-05 07:28:26,383][train][INFO] - {"epoch": 58, "train_loss": "0.951", "train_ntokens": "263445", "train_nsentences": "1753.71", "train_wps": "48181.5", "train_ups": "0.18", "train_wpb": "263444", "train_bsz": "1753.7", "train_num_updates": "27765", "train_lr": "0.000433828", "train_gnorm": "0.45", "train_loss_scale": "1", "train_train_wall": "1839", "train_gb_free": "41.1", "train_wall": "47899"}
[2024-10-05 07:28:26,792][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 07:28:26,855][fairseq.trainer][INFO] - begin training epoch 59
[2024-10-05 07:28:26,862][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 07:28:34,060][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-10-05 07:28:34,106][train][INFO] - {"epoch": 58, "train_loss": "0.951", "train_ntokens": "263437", "train_nsentences": "1754.61", "train_wps": "49015.1", "train_ups": "0.19", "train_wpb": "263437", "train_bsz": "1754.6", "train_num_updates": "27765", "train_lr": "0.000433828", "train_gnorm": "0.452", "train_loss_scale": "2", "train_train_wall": "1842", "train_gb_free": "41.1", "train_wall": "48040"}
[2024-10-05 07:28:34,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 07:28:34,580][fairseq.trainer][INFO] - begin training epoch 59
[2024-10-05 07:28:34,580][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 07:38:03,128][train_inner][INFO] - {"epoch": 59, "update": 58.073, "loss": "0.954", "ntokens": "262649", "nsentences": "1767.66", "wps": "43376.9", "ups": "0.17", "wpb": "262649", "bsz": "1767.7", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.439", "loss_scale": "2", "train_wall": "706", "gb_free": "40.3", "wall": "48609"}
[2024-10-05 07:38:08,307][train_inner][INFO] - {"epoch": 59, "update": 58.073, "loss": "0.954", "ntokens": "262649", "nsentences": "1767.66", "wps": "43167.3", "ups": "0.16", "wpb": "262649", "bsz": "1767.7", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.463", "loss_scale": "1", "train_wall": "687", "gb_free": "40.3", "wall": "48480"}
[2024-10-05 07:52:04,388][train_inner][INFO] - {"epoch": 59, "update": 58.491, "loss": "0.948", "ntokens": "263760", "nsentences": "1774.18", "wps": "63097.5", "ups": "0.24", "wpb": "263760", "bsz": "1774.2", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.406", "loss_scale": "2", "train_wall": "795", "gb_free": "39.3", "wall": "49317"}
[2024-10-05 07:52:07,206][train_inner][INFO] - {"epoch": 59, "update": 58.491, "loss": "0.948", "ntokens": "263760", "nsentences": "1774.18", "wps": "62497.8", "ups": "0.24", "wpb": "263760", "bsz": "1774.2", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.414", "loss_scale": "2", "train_wall": "785", "gb_free": "39.3", "wall": "49453"}
[2024-10-05 08:08:28,453][train_inner][INFO] - {"epoch": 59, "update": 58.908, "loss": "0.95", "ntokens": "264050", "nsentences": "1758.65", "wps": "53670", "ups": "0.2", "wpb": "264050", "bsz": "1758.7", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.428", "loss_scale": "2", "train_wall": "735", "gb_free": "39.8", "wall": "50301"}
[2024-10-05 08:08:30,707][train_inner][INFO] - {"epoch": 59, "update": 58.908, "loss": "0.95", "ntokens": "264050", "nsentences": "1758.65", "wps": "53696.4", "ups": "0.2", "wpb": "264050", "bsz": "1758.7", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.448", "loss_scale": "2", "train_wall": "614", "gb_free": "39.7", "wall": "50437"}
[2024-10-05 08:10:28,535][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-10-05 08:10:28,555][train][INFO] - {"epoch": 59, "train_loss": "0.95", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "50046.2", "train_ups": "0.19", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "28244", "train_lr": "0.000441313", "train_gnorm": "0.431", "train_loss_scale": "2", "train_train_wall": "1813", "train_gb_free": "40", "train_wall": "50421"}
[2024-10-05 08:10:28,853][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 08:10:28,872][fairseq.trainer][INFO] - begin training epoch 60
[2024-10-05 08:10:28,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 08:10:29,329][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-10-05 08:10:29,342][train][INFO] - {"epoch": 59, "train_loss": "0.95", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "50184.1", "train_ups": "0.19", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "28244", "train_lr": "0.000441313", "train_gnorm": "0.434", "train_loss_scale": "2", "train_train_wall": "1659", "train_gb_free": "40", "train_wall": "50555"}
[2024-10-05 08:10:29,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 08:10:29,663][fairseq.trainer][INFO] - begin training epoch 60
[2024-10-05 08:10:29,686][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 08:19:13,792][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-05 08:28:52,328][train_inner][INFO] - {"epoch": 60, "update": 59.328, "loss": "0.947", "ntokens": "263013", "nsentences": "1733.55", "wps": "42982.6", "ups": "0.16", "wpb": "263012", "bsz": "1733.5", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.477", "loss_scale": "1", "train_wall": "566", "gb_free": "40.5", "wall": "51524"}
[2024-10-05 08:28:52,353][train_inner][INFO] - {"epoch": 60, "update": 59.326, "loss": "0.947", "ntokens": "262981", "nsentences": "1734.95", "wps": "43054.6", "ups": "0.16", "wpb": "262981", "bsz": "1735", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.415", "loss_scale": "2", "train_wall": "573", "gb_free": "40.5", "wall": "51658"}
[2024-10-05 08:45:23,531][train_inner][INFO] - {"epoch": 60, "update": 59.743, "loss": "0.948", "ntokens": "263814", "nsentences": "1775.97", "wps": "53235.7", "ups": "0.2", "wpb": "263814", "bsz": "1776", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.416", "loss_scale": "2", "train_wall": "811", "gb_free": "39.6", "wall": "52649"}
[2024-10-05 08:45:23,538][train_inner][INFO] - {"epoch": 60, "update": 59.745, "loss": "0.948", "ntokens": "263793", "nsentences": "1775.17", "wps": "53227", "ups": "0.2", "wpb": "263793", "bsz": "1775.2", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.422", "loss_scale": "1", "train_wall": "944", "gb_free": "39.7", "wall": "52516"}
[2024-10-05 08:51:57,057][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 28722 updates
[2024-10-05 08:51:57,063][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 08:52:05,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 28723 updates
[2024-10-05 08:52:05,061][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 08:52:06,493][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 08:52:06,497][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 60 @ 28722 updates, score None) (writing took 9.439360408112407 seconds)
[2024-10-05 08:52:06,497][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-10-05 08:52:06,538][train][INFO] - {"epoch": 60, "train_loss": "0.948", "train_ntokens": "263492", "train_nsentences": "1752.74", "train_wps": "50421.2", "train_ups": "0.19", "train_wpb": "263492", "train_bsz": "1752.7", "train_num_updates": "28722", "train_lr": "0.000448781", "train_gnorm": "0.442", "train_loss_scale": "1", "train_train_wall": "1543", "train_gb_free": "39.1", "train_wall": "52919"}
[2024-10-05 08:52:06,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 08:52:06,660][fairseq.trainer][INFO] - begin training epoch 61
[2024-10-05 08:52:06,666][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 08:59:04,781][train_inner][INFO] - {"epoch": 61, "update": 60.163, "loss": "0.946", "ntokens": "263250", "nsentences": "1683.19", "wps": "64110.8", "ups": "0.24", "wpb": "263250", "bsz": "1683.2", "num_updates": "28800", "lr": "0.00045", "gnorm": "0.434", "loss_scale": "1", "train_wall": "257", "gb_free": "39.3", "wall": "53337"}
[2024-10-05 09:02:44,915][train_inner][INFO] - {"epoch": 61, "update": 60.58, "loss": "0.945", "ntokens": "264296", "nsentences": "1739.48", "wps": "240136", "ups": "0.91", "wpb": "264296", "bsz": "1739.5", "num_updates": "29000", "lr": "0.000453125", "gnorm": "0.428", "loss_scale": "1", "train_wall": "215", "gb_free": "40", "wall": "53557"}
[2024-10-05 09:07:03,342][train_inner][INFO] - {"epoch": 61, "update": 60.998, "loss": "0.951", "ntokens": "263405", "nsentences": "1815.64", "wps": "203864", "ups": "0.77", "wpb": "263405", "bsz": "1815.6", "num_updates": "29200", "lr": "0.00045625", "gnorm": "0.406", "loss_scale": "1", "train_wall": "253", "gb_free": "39.2", "wall": "53816"}
[2024-10-05 09:07:04,738][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-10-05 09:07:04,762][train][INFO] - {"epoch": 61, "train_loss": "0.947", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "140517", "train_ups": "0.53", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "29201", "train_lr": "0.000456266", "train_gnorm": "0.419", "train_loss_scale": "1", "train_train_wall": "574", "train_gb_free": "39.6", "train_wall": "53817"}
[2024-10-05 09:07:04,831][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 09:07:04,853][fairseq.trainer][INFO] - begin training epoch 62
[2024-10-05 09:07:04,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 09:15:50,529][train_inner][INFO] - {"epoch": 62, "update": 61.415, "loss": "0.944", "ntokens": "263020", "nsentences": "1721.83", "wps": "99783.6", "ups": "0.38", "wpb": "263020", "bsz": "1721.8", "num_updates": "29400", "lr": "0.000459375", "gnorm": "0.407", "loss_scale": "1", "train_wall": "219", "gb_free": "39.3", "wall": "54343"}
[2024-10-05 09:20:18,037][train_inner][INFO] - {"epoch": 62, "update": 61.833, "loss": "0.947", "ntokens": "263827", "nsentences": "1769.89", "wps": "197252", "ups": "0.75", "wpb": "263827", "bsz": "1769.9", "num_updates": "29600", "lr": "0.0004625", "gnorm": "0.435", "loss_scale": "1", "train_wall": "263", "gb_free": "39.6", "wall": "54610"}
[2024-10-05 09:22:08,203][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-10-05 09:22:08,209][train][INFO] - {"epoch": 62, "train_loss": "0.946", "train_ntokens": "263476", "train_nsentences": "1753.71", "train_wps": "139693", "train_ups": "0.53", "train_wpb": "263476", "train_bsz": "1753.7", "train_num_updates": "29680", "train_lr": "0.00046375", "train_gnorm": "0.417", "train_loss_scale": "1", "train_train_wall": "588", "train_gb_free": "39.3", "train_wall": "54720"}
[2024-10-05 09:22:08,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 09:22:08,559][fairseq.trainer][INFO] - begin training epoch 63
[2024-10-05 09:22:08,560][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 09:29:32,666][train_inner][INFO] - {"epoch": 63, "update": 62.251, "loss": "0.943", "ntokens": "262939", "nsentences": "1736.69", "wps": "94817.3", "ups": "0.36", "wpb": "262939", "bsz": "1736.7", "num_updates": "29800", "lr": "0.000465625", "gnorm": "0.398", "loss_scale": "1", "train_wall": "252", "gb_free": "39.6", "wall": "55165"}
[2024-10-05 09:33:20,314][train_inner][INFO] - {"epoch": 63, "update": 62.668, "loss": "0.947", "ntokens": "263835", "nsentences": "1787.78", "wps": "231798", "ups": "0.88", "wpb": "263835", "bsz": "1787.8", "num_updates": "30000", "lr": "0.00046875", "gnorm": "0.404", "loss_scale": "1", "train_wall": "223", "gb_free": "39.2", "wall": "55392"}
[2024-10-05 09:36:24,239][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-10-05 09:36:24,256][train][INFO] - {"epoch": 63, "train_loss": "0.945", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "147446", "train_ups": "0.56", "train_wpb": "263509", "train_bsz": "1753.7", "train_num_updates": "30159", "train_lr": "0.000471234", "train_gnorm": "0.408", "train_loss_scale": "1", "train_train_wall": "546", "train_gb_free": "40", "train_wall": "55576"}
[2024-10-05 09:36:24,477][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 09:36:24,523][fairseq.trainer][INFO] - begin training epoch 64
[2024-10-05 09:36:24,524][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 09:42:59,246][train_inner][INFO] - {"epoch": 64, "update": 63.086, "loss": "0.945", "ntokens": "262878", "nsentences": "1740.43", "wps": "90816.7", "ups": "0.35", "wpb": "262878", "bsz": "1740.4", "num_updates": "30200", "lr": "0.000471875", "gnorm": "0.429", "loss_scale": "1", "train_wall": "258", "gb_free": "39.2", "wall": "55971"}
[2024-10-05 09:46:35,283][train_inner][INFO] - {"epoch": 64, "update": 63.503, "loss": "0.941", "ntokens": "264107", "nsentences": "1744.73", "wps": "244508", "ups": "0.93", "wpb": "264107", "bsz": "1744.7", "num_updates": "30400", "lr": "0.000475", "gnorm": "0.401", "loss_scale": "2", "train_wall": "211", "gb_free": "39.3", "wall": "56187"}
[2024-10-05 09:50:56,395][train_inner][INFO] - {"epoch": 64, "update": 63.921, "loss": "0.946", "ntokens": "263535", "nsentences": "1783.13", "wps": "201869", "ups": "0.77", "wpb": "263535", "bsz": "1783.1", "num_updates": "30600", "lr": "0.000478125", "gnorm": "0.384", "loss_scale": "2", "train_wall": "256", "gb_free": "39.6", "wall": "56449"}
[2024-10-05 09:51:35,122][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-10-05 09:51:35,147][train][INFO] - {"epoch": 64, "train_loss": "0.944", "train_ntokens": "263428", "train_nsentences": "1753.71", "train_wps": "138530", "train_ups": "0.53", "train_wpb": "263428", "train_bsz": "1753.7", "train_num_updates": "30638", "train_lr": "0.000478719", "train_gnorm": "0.403", "train_loss_scale": "2", "train_train_wall": "582", "train_gb_free": "39.6", "train_wall": "56487"}
[2024-10-05 09:51:35,410][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 09:51:35,455][fairseq.trainer][INFO] - begin training epoch 65
[2024-10-05 09:51:35,456][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 10:00:08,898][train_inner][INFO] - {"epoch": 65, "update": 64.338, "loss": "0.943", "ntokens": "262775", "nsentences": "1757.81", "wps": "95123", "ups": "0.36", "wpb": "262775", "bsz": "1757.8", "num_updates": "30800", "lr": "0.00048125", "gnorm": "0.433", "loss_scale": "2", "train_wall": "210", "gb_free": "39.6", "wall": "57001"}
[2024-10-05 10:04:35,510][train_inner][INFO] - {"epoch": 65, "update": 64.756, "loss": "0.942", "ntokens": "264064", "nsentences": "1734.7", "wps": "198096", "ups": "0.75", "wpb": "264064", "bsz": "1734.7", "num_updates": "31000", "lr": "0.000484375", "gnorm": "0.384", "loss_scale": "2", "train_wall": "262", "gb_free": "39.1", "wall": "57268"}
[2024-10-05 10:07:06,696][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-10-05 10:07:06,702][train][INFO] - {"epoch": 65, "train_loss": "0.943", "train_ntokens": "263458", "train_nsentences": "1753.71", "train_wps": "135469", "train_ups": "0.51", "train_wpb": "263458", "train_bsz": "1753.7", "train_num_updates": "31117", "train_lr": "0.000486203", "train_gnorm": "0.403", "train_loss_scale": "2", "train_train_wall": "583", "train_gb_free": "39.3", "train_wall": "57419"}
[2024-10-05 10:07:06,826][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 10:07:06,845][fairseq.trainer][INFO] - begin training epoch 66
[2024-10-05 10:07:06,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 10:14:13,327][train_inner][INFO] - {"epoch": 66, "update": 65.173, "loss": "0.945", "ntokens": "262392", "nsentences": "1803.17", "wps": "90823.7", "ups": "0.35", "wpb": "262392", "bsz": "1803.2", "num_updates": "31200", "lr": "0.0004875", "gnorm": "0.392", "loss_scale": "2", "train_wall": "258", "gb_free": "39.3", "wall": "57845"}
[2024-10-05 10:17:36,678][train_inner][INFO] - {"epoch": 66, "update": 65.591, "loss": "0.939", "ntokens": "264303", "nsentences": "1730.94", "wps": "259985", "ups": "0.98", "wpb": "264303", "bsz": "1730.9", "num_updates": "31400", "lr": "0.000490625", "gnorm": "0.406", "loss_scale": "2", "train_wall": "199", "gb_free": "40.3", "wall": "58049"}
[2024-10-05 10:21:29,153][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-10-05 10:21:29,170][train][INFO] - {"epoch": 66, "train_loss": "0.942", "train_ntokens": "263583", "train_nsentences": "1753.71", "train_wps": "146390", "train_ups": "0.56", "train_wpb": "263583", "train_bsz": "1753.7", "train_num_updates": "31596", "train_lr": "0.000493687", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.7", "train_wall": "58281"}
[2024-10-05 10:21:29,347][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 10:21:29,353][fairseq.trainer][INFO] - begin training epoch 67
[2024-10-05 10:21:29,354][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 10:27:20,917][train_inner][INFO] - {"epoch": 67, "update": 66.008, "loss": "0.944", "ntokens": "263112", "nsentences": "1718.95", "wps": "90070.6", "ups": "0.34", "wpb": "263112", "bsz": "1719", "num_updates": "31600", "lr": "0.00049375", "gnorm": "0.41", "loss_scale": "2", "train_wall": "259", "gb_free": "40", "wall": "58633"}
[2024-10-05 10:30:44,335][train_inner][INFO] - {"epoch": 67, "update": 66.426, "loss": "0.94", "ntokens": "263829", "nsentences": "1764.92", "wps": "259401", "ups": "0.98", "wpb": "263829", "bsz": "1764.9", "num_updates": "31800", "lr": "0.000496875", "gnorm": "0.385", "loss_scale": "2", "train_wall": "198", "gb_free": "39.6", "wall": "58837"}
[2024-10-05 10:34:57,868][train_inner][INFO] - {"epoch": 67, "update": 66.843, "loss": "0.943", "ntokens": "263832", "nsentences": "1761.82", "wps": "208136", "ups": "0.79", "wpb": "263832", "bsz": "1761.8", "num_updates": "32000", "lr": "0.0005", "gnorm": "0.429", "loss_scale": "2", "train_wall": "248", "gb_free": "40.2", "wall": "59090"}
[2024-10-05 10:36:16,174][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-10-05 10:36:16,217][train][INFO] - {"epoch": 67, "train_loss": "0.941", "train_ntokens": "263420", "train_nsentences": "1753.71", "train_wps": "142248", "train_ups": "0.54", "train_wpb": "263420", "train_bsz": "1753.7", "train_num_updates": "32075", "train_lr": "0.000499898", "train_gnorm": "0.407", "train_loss_scale": "2", "train_train_wall": "555", "train_gb_free": "40.2", "train_wall": "59168"}
[2024-10-05 10:36:16,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 10:36:16,519][fairseq.trainer][INFO] - begin training epoch 68
[2024-10-05 10:36:16,519][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 10:44:07,071][train_inner][INFO] - {"epoch": 68, "update": 67.261, "loss": "0.938", "ntokens": "263249", "nsentences": "1717.45", "wps": "95866.7", "ups": "0.36", "wpb": "263249", "bsz": "1717.5", "num_updates": "32200", "lr": "0.000499728", "gnorm": "0.391", "loss_scale": "2", "train_wall": "220", "gb_free": "39.8", "wall": "59639"}
[2024-10-05 10:47:15,192][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 10:47:56,923][train_inner][INFO] - {"epoch": 68, "update": 67.681, "loss": "0.94", "ntokens": "263615", "nsentences": "1769.41", "wps": "229388", "ups": "0.87", "wpb": "263615", "bsz": "1769.4", "num_updates": "32400", "lr": "0.000499457", "gnorm": "0.405", "loss_scale": "2", "train_wall": "224", "gb_free": "39.8", "wall": "59869"}
[2024-10-05 10:50:47,856][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-10-05 10:50:47,898][train][INFO] - {"epoch": 68, "train_loss": "0.94", "train_ntokens": "263434", "train_nsentences": "1754.08", "train_wps": "144463", "train_ups": "0.55", "train_wpb": "263434", "train_bsz": "1754.1", "train_num_updates": "32553", "train_lr": "0.000499249", "train_gnorm": "0.394", "train_loss_scale": "2", "train_train_wall": "536", "train_gb_free": "39.2", "train_wall": "60040"}
[2024-10-05 10:50:48,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 10:50:48,089][fairseq.trainer][INFO] - begin training epoch 69
[2024-10-05 10:50:48,089][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 10:57:30,117][train_inner][INFO] - {"epoch": 69, "update": 68.098, "loss": "0.942", "ntokens": "262673", "nsentences": "1767.11", "wps": "91653.4", "ups": "0.35", "wpb": "262673", "bsz": "1767.1", "num_updates": "32600", "lr": "0.000499185", "gnorm": "0.38", "loss_scale": "2", "train_wall": "232", "gb_free": "40", "wall": "60442"}
[2024-10-05 11:01:10,544][train_inner][INFO] - {"epoch": 69, "update": 68.516, "loss": "0.937", "ntokens": "263900", "nsentences": "1771.89", "wps": "239449", "ups": "0.91", "wpb": "263900", "bsz": "1771.9", "num_updates": "32800", "lr": "0.000498913", "gnorm": "0.371", "loss_scale": "2", "train_wall": "216", "gb_free": "39.1", "wall": "60663"}
[2024-10-05 11:04:53,964][train_inner][INFO] - {"epoch": 69, "update": 68.933, "loss": "0.938", "ntokens": "264341", "nsentences": "1728.84", "wps": "236642", "ups": "0.9", "wpb": "264341", "bsz": "1728.8", "num_updates": "33000", "lr": "0.000498641", "gnorm": "0.386", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "60886"}
[2024-10-05 11:05:43,004][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-10-05 11:05:43,021][train][INFO] - {"epoch": 69, "train_loss": "0.938", "train_ntokens": "263603", "train_nsentences": "1753.71", "train_wps": "141062", "train_ups": "0.54", "train_wpb": "263603", "train_bsz": "1753.7", "train_num_updates": "33032", "train_lr": "0.000498598", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "40", "train_wall": "60935"}
[2024-10-05 11:05:43,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 11:05:43,251][fairseq.trainer][INFO] - begin training epoch 70
[2024-10-05 11:05:43,252][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 11:14:27,155][train_inner][INFO] - {"epoch": 70, "update": 69.351, "loss": "0.934", "ntokens": "262895", "nsentences": "1759.71", "wps": "91732.6", "ups": "0.35", "wpb": "262895", "bsz": "1759.7", "num_updates": "33200", "lr": "0.00049837", "gnorm": "0.367", "loss_scale": "2", "train_wall": "186", "gb_free": "40.1", "wall": "61459"}
[2024-10-05 11:18:29,113][train_inner][INFO] - {"epoch": 70, "update": 69.768, "loss": "0.936", "ntokens": "264126", "nsentences": "1750.12", "wps": "218338", "ups": "0.83", "wpb": "264126", "bsz": "1750.1", "num_updates": "33400", "lr": "0.000498098", "gnorm": "0.383", "loss_scale": "2", "train_wall": "147", "gb_free": "40.7", "wall": "61701"}
[2024-10-05 11:21:05,178][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 33511 updates
[2024-10-05 11:21:05,180][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 11:21:09,471][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 11:21:09,474][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 70 @ 33511 updates, score None) (writing took 4.295760135166347 seconds)
[2024-10-05 11:21:09,474][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2024-10-05 11:21:09,477][train][INFO] - {"epoch": 70, "train_loss": "0.936", "train_ntokens": "263457", "train_nsentences": "1753.71", "train_wps": "136214", "train_ups": "0.52", "train_wpb": "263457", "train_bsz": "1753.7", "train_num_updates": "33511", "train_lr": "0.000497947", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "336", "train_gb_free": "39.6", "train_wall": "61862"}
[2024-10-05 11:21:09,503][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 11:21:09,538][fairseq.trainer][INFO] - begin training epoch 71
[2024-10-05 11:21:09,539][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 11:28:00,940][train_inner][INFO] - {"epoch": 71, "update": 70.186, "loss": "0.935", "ntokens": "262867", "nsentences": "1724.28", "wps": "91940.9", "ups": "0.35", "wpb": "262867", "bsz": "1724.3", "num_updates": "33600", "lr": "0.000497826", "gnorm": "0.353", "loss_scale": "2", "train_wall": "143", "gb_free": "39.3", "wall": "62273"}
[2024-10-05 11:31:31,798][train_inner][INFO] - {"epoch": 71, "update": 70.603, "loss": "0.934", "ntokens": "263811", "nsentences": "1765.84", "wps": "250242", "ups": "0.95", "wpb": "263811", "bsz": "1765.8", "num_updates": "33800", "lr": "0.000497554", "gnorm": "0.395", "loss_scale": "2", "train_wall": "205", "gb_free": "39.3", "wall": "62484"}
[2024-10-05 11:35:17,527][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2024-10-05 11:35:17,538][train][INFO] - {"epoch": 71, "train_loss": "0.934", "train_ntokens": "263455", "train_nsentences": "1753.71", "train_wps": "148804", "train_ups": "0.56", "train_wpb": "263455", "train_bsz": "1753.7", "train_num_updates": "33990", "train_lr": "0.000497296", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "517", "train_gb_free": "39.8", "train_wall": "62710"}
[2024-10-05 11:35:17,721][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 11:35:17,752][fairseq.trainer][INFO] - begin training epoch 72
[2024-10-05 11:35:17,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 11:41:14,486][train_inner][INFO] - {"epoch": 72, "update": 71.021, "loss": "0.936", "ntokens": "262545", "nsentences": "1766.53", "wps": "90116.1", "ups": "0.34", "wpb": "262544", "bsz": "1766.5", "num_updates": "34000", "lr": "0.000497283", "gnorm": "0.364", "loss_scale": "2", "train_wall": "239", "gb_free": "39.3", "wall": "63067"}
[2024-10-05 11:44:48,984][train_inner][INFO] - {"epoch": 72, "update": 71.438, "loss": "0.931", "ntokens": "263795", "nsentences": "1776.05", "wps": "245979", "ups": "0.93", "wpb": "263795", "bsz": "1776", "num_updates": "34200", "lr": "0.000497011", "gnorm": "0.353", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "63281"}
[2024-10-05 11:48:44,163][train_inner][INFO] - {"epoch": 72, "update": 71.856, "loss": "0.932", "ntokens": "264201", "nsentences": "1755.86", "wps": "224704", "ups": "0.85", "wpb": "264201", "bsz": "1755.9", "num_updates": "34400", "lr": "0.000496739", "gnorm": "0.384", "loss_scale": "2", "train_wall": "227", "gb_free": "40.5", "wall": "63516"}
[2024-10-05 11:50:07,990][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2024-10-05 11:50:08,034][train][INFO] - {"epoch": 72, "train_loss": "0.932", "train_ntokens": "263615", "train_nsentences": "1753.71", "train_wps": "141802", "train_ups": "0.54", "train_wpb": "263615", "train_bsz": "1753.7", "train_num_updates": "34469", "train_lr": "0.000496645", "train_gnorm": "0.366", "train_loss_scale": "4", "train_train_wall": "529", "train_gb_free": "39.8", "train_wall": "63600"}
[2024-10-05 11:50:08,375][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 11:50:08,407][fairseq.trainer][INFO] - begin training epoch 73
[2024-10-05 11:50:08,408][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 11:56:17,687][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 11:58:15,159][train_inner][INFO] - {"epoch": 73, "update": 72.276, "loss": "0.931", "ntokens": "263117", "nsentences": "1729.38", "wps": "92163.8", "ups": "0.35", "wpb": "263117", "bsz": "1729.4", "num_updates": "34600", "lr": "0.000496467", "gnorm": "0.356", "loss_scale": "2", "train_wall": "223", "gb_free": "39.3", "wall": "64087"}
[2024-10-05 12:02:01,277][train_inner][INFO] - {"epoch": 73, "update": 72.693, "loss": "0.931", "ntokens": "263922", "nsentences": "1755.92", "wps": "233443", "ups": "0.88", "wpb": "263922", "bsz": "1755.9", "num_updates": "34800", "lr": "0.000496196", "gnorm": "0.359", "loss_scale": "2", "train_wall": "221", "gb_free": "39.7", "wall": "64313"}
[2024-10-05 12:04:56,441][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2024-10-05 12:04:56,466][train][INFO] - {"epoch": 73, "train_loss": "0.93", "train_ntokens": "263514", "train_nsentences": "1754.59", "train_wps": "141780", "train_ups": "0.54", "train_wpb": "263514", "train_bsz": "1754.6", "train_num_updates": "34947", "train_lr": "0.000495996", "train_gnorm": "0.36", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.3", "train_wall": "64489"}
[2024-10-05 12:04:56,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 12:04:56,637][fairseq.trainer][INFO] - begin training epoch 74
[2024-10-05 12:04:56,638][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 12:11:34,275][train_inner][INFO] - {"epoch": 74, "update": 73.111, "loss": "0.93", "ntokens": "262922", "nsentences": "1746.32", "wps": "91773.6", "ups": "0.35", "wpb": "262922", "bsz": "1746.3", "num_updates": "35000", "lr": "0.000495924", "gnorm": "0.353", "loss_scale": "2", "train_wall": "236", "gb_free": "39.2", "wall": "64886"}
[2024-10-05 12:15:15,480][train_inner][INFO] - {"epoch": 74, "update": 73.528, "loss": "0.926", "ntokens": "263924", "nsentences": "1758.14", "wps": "238644", "ups": "0.9", "wpb": "263924", "bsz": "1758.1", "num_updates": "35200", "lr": "0.000495652", "gnorm": "0.348", "loss_scale": "2", "train_wall": "216", "gb_free": "39.7", "wall": "65108"}
[2024-10-05 12:18:57,649][train_inner][INFO] - {"epoch": 74, "update": 73.946, "loss": "0.931", "ntokens": "263900", "nsentences": "1766.98", "wps": "237574", "ups": "0.9", "wpb": "263900", "bsz": "1767", "num_updates": "35400", "lr": "0.00049538", "gnorm": "0.349", "loss_scale": "2", "train_wall": "216", "gb_free": "39.7", "wall": "65330"}
[2024-10-05 12:19:37,832][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2024-10-05 12:19:37,842][train][INFO] - {"epoch": 74, "train_loss": "0.929", "train_ntokens": "263460", "train_nsentences": "1753.71", "train_wps": "143184", "train_ups": "0.54", "train_wpb": "263460", "train_bsz": "1753.7", "train_num_updates": "35426", "train_lr": "0.000495345", "train_gnorm": "0.343", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "39.8", "train_wall": "65370"}
[2024-10-05 12:19:37,933][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 12:19:37,956][fairseq.trainer][INFO] - begin training epoch 75
[2024-10-05 12:19:37,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 12:28:28,210][train_inner][INFO] - {"epoch": 75, "update": 74.363, "loss": "0.927", "ntokens": "262396", "nsentences": "1774.62", "wps": "91980.4", "ups": "0.35", "wpb": "262396", "bsz": "1774.6", "num_updates": "35600", "lr": "0.000495109", "gnorm": "0.343", "loss_scale": "2", "train_wall": "238", "gb_free": "40.5", "wall": "65900"}
[2024-10-05 12:32:49,126][train_inner][INFO] - {"epoch": 75, "update": 74.781, "loss": "0.926", "ntokens": "264241", "nsentences": "1739.04", "wps": "202583", "ups": "0.77", "wpb": "264241", "bsz": "1739", "num_updates": "35800", "lr": "0.000494837", "gnorm": "0.356", "loss_scale": "2", "train_wall": "256", "gb_free": "39.3", "wall": "66161"}
[2024-10-05 12:34:48,761][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2024-10-05 12:34:48,787][train][INFO] - {"epoch": 75, "train_loss": "0.927", "train_ntokens": "263473", "train_nsentences": "1753.71", "train_wps": "138542", "train_ups": "0.53", "train_wpb": "263473", "train_bsz": "1753.7", "train_num_updates": "35905", "train_lr": "0.000494694", "train_gnorm": "0.35", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "40", "train_wall": "66281"}
[2024-10-05 12:34:48,891][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 12:34:48,909][fairseq.trainer][INFO] - begin training epoch 76
[2024-10-05 12:34:48,910][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 12:42:15,600][train_inner][INFO] - {"epoch": 76, "update": 75.198, "loss": "0.927", "ntokens": "263184", "nsentences": "1710.57", "wps": "92922.2", "ups": "0.35", "wpb": "263184", "bsz": "1710.6", "num_updates": "36000", "lr": "0.000494565", "gnorm": "0.358", "loss_scale": "2", "train_wall": "238", "gb_free": "39.2", "wall": "66728"}
[2024-10-05 12:45:40,397][train_inner][INFO] - {"epoch": 76, "update": 75.616, "loss": "0.921", "ntokens": "264292", "nsentences": "1721.79", "wps": "258119", "ups": "0.98", "wpb": "264292", "bsz": "1721.8", "num_updates": "36200", "lr": "0.000494293", "gnorm": "0.334", "loss_scale": "2", "train_wall": "200", "gb_free": "39.6", "wall": "66933"}
[2024-10-05 12:49:30,151][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2024-10-05 12:49:30,164][train][INFO] - {"epoch": 76, "train_loss": "0.925", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "143212", "train_ups": "0.54", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "36384", "train_lr": "0.000494043", "train_gnorm": "0.347", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "39.2", "train_wall": "67162"}
[2024-10-05 12:49:30,264][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 12:49:30,280][fairseq.trainer][INFO] - begin training epoch 77
[2024-10-05 12:49:30,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 12:55:31,443][train_inner][INFO] - {"epoch": 77, "update": 76.033, "loss": "0.928", "ntokens": "262360", "nsentences": "1805.56", "wps": "88780", "ups": "0.34", "wpb": "262360", "bsz": "1805.6", "num_updates": "36400", "lr": "0.000494022", "gnorm": "0.345", "loss_scale": "2", "train_wall": "272", "gb_free": "39.3", "wall": "67524"}
[2024-10-05 12:58:01,408][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 12:59:04,816][train_inner][INFO] - {"epoch": 77, "update": 76.453, "loss": "0.921", "ntokens": "263801", "nsentences": "1774.53", "wps": "247281", "ups": "0.94", "wpb": "263801", "bsz": "1774.5", "num_updates": "36600", "lr": "0.00049375", "gnorm": "0.351", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "67737"}
[2024-10-05 13:02:47,259][train_inner][INFO] - {"epoch": 77, "update": 76.871, "loss": "0.926", "ntokens": "264060", "nsentences": "1775.74", "wps": "237429", "ups": "0.9", "wpb": "264060", "bsz": "1775.7", "num_updates": "36800", "lr": "0.000493478", "gnorm": "0.334", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "67959"}
[2024-10-05 13:04:14,008][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2024-10-05 13:04:14,041][train][INFO] - {"epoch": 77, "train_loss": "0.924", "train_ntokens": "263596", "train_nsentences": "1753.53", "train_wps": "142553", "train_ups": "0.54", "train_wpb": "263596", "train_bsz": "1753.5", "train_num_updates": "36862", "train_lr": "0.000493394", "train_gnorm": "0.349", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "40.2", "train_wall": "68046"}
[2024-10-05 13:04:14,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 13:04:14,261][fairseq.trainer][INFO] - begin training epoch 78
[2024-10-05 13:04:14,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 13:12:37,933][train_inner][INFO] - {"epoch": 78, "update": 77.288, "loss": "0.921", "ntokens": "263087", "nsentences": "1726.87", "wps": "89081.2", "ups": "0.34", "wpb": "263087", "bsz": "1726.9", "num_updates": "37000", "lr": "0.000493207", "gnorm": "0.36", "loss_scale": "2", "train_wall": "251", "gb_free": "39.3", "wall": "68550"}
[2024-10-05 13:16:38,036][train_inner][INFO] - {"epoch": 78, "update": 77.706, "loss": "0.921", "ntokens": "264028", "nsentences": "1762.9", "wps": "219933", "ups": "0.83", "wpb": "264028", "bsz": "1762.9", "num_updates": "37200", "lr": "0.000492935", "gnorm": "0.346", "loss_scale": "2", "train_wall": "234", "gb_free": "39.3", "wall": "68790"}
[2024-10-05 13:19:26,878][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2024-10-05 13:19:26,900][train][INFO] - {"epoch": 78, "train_loss": "0.921", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "138271", "train_ups": "0.52", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "37341", "train_lr": "0.000492743", "train_gnorm": "0.337", "train_loss_scale": "2", "train_train_wall": "568", "train_gb_free": "39.2", "train_wall": "68959"}
[2024-10-05 13:19:27,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 13:19:27,055][fairseq.trainer][INFO] - begin training epoch 79
[2024-10-05 13:19:27,056][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 13:26:03,625][train_inner][INFO] - {"epoch": 79, "update": 78.123, "loss": "0.921", "ntokens": "262779", "nsentences": "1750.42", "wps": "92924.6", "ups": "0.35", "wpb": "262779", "bsz": "1750.4", "num_updates": "37400", "lr": "0.000492663", "gnorm": "0.322", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "69356"}
[2024-10-05 13:29:41,831][train_inner][INFO] - {"epoch": 79, "update": 78.541, "loss": "0.919", "ntokens": "264231", "nsentences": "1745.87", "wps": "242194", "ups": "0.92", "wpb": "264231", "bsz": "1745.9", "num_updates": "37600", "lr": "0.000492391", "gnorm": "0.324", "loss_scale": "2", "train_wall": "171", "gb_free": "40", "wall": "69574"}
[2024-10-05 13:33:48,056][train_inner][INFO] - {"epoch": 79, "update": 78.958, "loss": "0.922", "ntokens": "263996", "nsentences": "1758.96", "wps": "214440", "ups": "0.81", "wpb": "263996", "bsz": "1759", "num_updates": "37800", "lr": "0.00049212", "gnorm": "0.329", "loss_scale": "2", "train_wall": "241", "gb_free": "40.2", "wall": "69820"}
[2024-10-05 13:34:31,329][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2024-10-05 13:34:31,356][train][INFO] - {"epoch": 79, "train_loss": "0.921", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "139603", "train_ups": "0.53", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "37820", "train_lr": "0.000492092", "train_gnorm": "0.329", "train_loss_scale": "2", "train_train_wall": "504", "train_gb_free": "39.3", "train_wall": "69864"}
[2024-10-05 13:34:31,499][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 13:34:31,531][fairseq.trainer][INFO] - begin training epoch 80
[2024-10-05 13:34:31,532][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 13:43:28,826][train_inner][INFO] - {"epoch": 80, "update": 79.376, "loss": "0.917", "ntokens": "262711", "nsentences": "1753.27", "wps": "90472.3", "ups": "0.34", "wpb": "262712", "bsz": "1753.3", "num_updates": "38000", "lr": "0.000491848", "gnorm": "0.343", "loss_scale": "2", "train_wall": "259", "gb_free": "39.3", "wall": "70401"}
[2024-10-05 13:47:25,346][train_inner][INFO] - {"epoch": 80, "update": 79.793, "loss": "0.919", "ntokens": "263943", "nsentences": "1753.89", "wps": "223198", "ups": "0.85", "wpb": "263943", "bsz": "1753.9", "num_updates": "38200", "lr": "0.000491576", "gnorm": "0.323", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "70638"}
[2024-10-05 13:49:49,881][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 38299 updates
[2024-10-05 13:49:49,884][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 13:49:54,753][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 13:49:54,758][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 80 @ 38299 updates, score None) (writing took 4.876368093304336 seconds)
[2024-10-05 13:49:54,758][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2024-10-05 13:49:54,761][train][INFO] - {"epoch": 80, "train_loss": "0.919", "train_ntokens": "263424", "train_nsentences": "1753.71", "train_wps": "136647", "train_ups": "0.52", "train_wpb": "263424", "train_bsz": "1753.7", "train_num_updates": "38299", "train_lr": "0.000491442", "train_gnorm": "0.336", "train_loss_scale": "2", "train_train_wall": "590", "train_gb_free": "39.3", "train_wall": "70787"}
[2024-10-05 13:49:54,850][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 13:49:54,873][fairseq.trainer][INFO] - begin training epoch 81
[2024-10-05 13:49:54,873][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 13:57:11,183][train_inner][INFO] - {"epoch": 81, "update": 80.211, "loss": "0.919", "ntokens": "262985", "nsentences": "1736.75", "wps": "89781.9", "ups": "0.34", "wpb": "262985", "bsz": "1736.8", "num_updates": "38400", "lr": "0.000491304", "gnorm": "0.344", "loss_scale": "2", "train_wall": "253", "gb_free": "39.6", "wall": "71223"}
[2024-10-05 14:00:55,510][train_inner][INFO] - {"epoch": 81, "update": 80.628, "loss": "0.918", "ntokens": "263884", "nsentences": "1761.96", "wps": "235280", "ups": "0.89", "wpb": "263884", "bsz": "1762", "num_updates": "38600", "lr": "0.000491033", "gnorm": "0.335", "loss_scale": "4", "train_wall": "186", "gb_free": "39.3", "wall": "71448"}
[2024-10-05 14:02:20,442][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 14:04:15,396][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2024-10-05 14:04:15,418][train][INFO] - {"epoch": 81, "train_loss": "0.918", "train_ntokens": "263564", "train_nsentences": "1752.9", "train_wps": "146383", "train_ups": "0.56", "train_wpb": "263564", "train_bsz": "1752.9", "train_num_updates": "38777", "train_lr": "0.000490792", "train_gnorm": "0.335", "train_loss_scale": "2", "train_train_wall": "475", "train_gb_free": "39.9", "train_wall": "71648"}
[2024-10-05 14:04:15,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 14:04:15,618][fairseq.trainer][INFO] - begin training epoch 82
[2024-10-05 14:04:15,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 14:10:29,594][train_inner][INFO] - {"epoch": 82, "update": 81.048, "loss": "0.918", "ntokens": "263012", "nsentences": "1734.53", "wps": "91629.7", "ups": "0.35", "wpb": "263012", "bsz": "1734.5", "num_updates": "38800", "lr": "0.000490761", "gnorm": "0.339", "loss_scale": "2", "train_wall": "214", "gb_free": "40.5", "wall": "72022"}
[2024-10-05 14:14:52,627][train_inner][INFO] - {"epoch": 82, "update": 81.466, "loss": "0.918", "ntokens": "263591", "nsentences": "1811.53", "wps": "200432", "ups": "0.76", "wpb": "263591", "bsz": "1811.5", "num_updates": "39000", "lr": "0.000490489", "gnorm": "0.333", "loss_scale": "2", "train_wall": "258", "gb_free": "40.5", "wall": "72285"}
[2024-10-05 14:19:07,550][train_inner][INFO] - {"epoch": 82, "update": 81.883, "loss": "0.915", "ntokens": "263966", "nsentences": "1749.76", "wps": "207102", "ups": "0.78", "wpb": "263966", "bsz": "1749.8", "num_updates": "39200", "lr": "0.000490217", "gnorm": "0.317", "loss_scale": "2", "train_wall": "249", "gb_free": "39.8", "wall": "72540"}
[2024-10-05 14:20:34,654][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2024-10-05 14:20:34,667][train][INFO] - {"epoch": 82, "train_loss": "0.916", "train_ntokens": "263450", "train_nsentences": "1753.71", "train_wps": "128867", "train_ups": "0.49", "train_wpb": "263450", "train_bsz": "1753.7", "train_num_updates": "39256", "train_lr": "0.000490141", "train_gnorm": "0.328", "train_loss_scale": "2", "train_train_wall": "629", "train_gb_free": "39.3", "train_wall": "72627"}
[2024-10-05 14:20:34,806][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 14:20:34,816][fairseq.trainer][INFO] - begin training epoch 83
[2024-10-05 14:20:34,817][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 14:28:39,393][train_inner][INFO] - {"epoch": 83, "update": 82.301, "loss": "0.913", "ntokens": "262831", "nsentences": "1736.81", "wps": "91925.6", "ups": "0.35", "wpb": "262831", "bsz": "1736.8", "num_updates": "39400", "lr": "0.000489946", "gnorm": "0.339", "loss_scale": "2", "train_wall": "252", "gb_free": "40", "wall": "73112"}
[2024-10-05 14:32:42,437][train_inner][INFO] - {"epoch": 83, "update": 82.718, "loss": "0.914", "ntokens": "264072", "nsentences": "1752.64", "wps": "217332", "ups": "0.82", "wpb": "264072", "bsz": "1752.6", "num_updates": "39600", "lr": "0.000489674", "gnorm": "0.314", "loss_scale": "2", "train_wall": "238", "gb_free": "39.3", "wall": "73355"}
[2024-10-05 14:35:10,105][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2024-10-05 14:35:10,133][train][INFO] - {"epoch": 83, "train_loss": "0.914", "train_ntokens": "263499", "train_nsentences": "1753.71", "train_wps": "144171", "train_ups": "0.55", "train_wpb": "263499", "train_bsz": "1753.7", "train_num_updates": "39735", "train_lr": "0.00048949", "train_gnorm": "0.332", "train_loss_scale": "2", "train_train_wall": "548", "train_gb_free": "39.3", "train_wall": "73502"}
[2024-10-05 14:35:10,304][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 14:35:10,350][fairseq.trainer][INFO] - begin training epoch 84
[2024-10-05 14:35:10,351][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 14:42:38,014][train_inner][INFO] - {"epoch": 84, "update": 83.136, "loss": "0.913", "ntokens": "262943", "nsentences": "1737.82", "wps": "88299.6", "ups": "0.34", "wpb": "262943", "bsz": "1737.8", "num_updates": "39800", "lr": "0.000489402", "gnorm": "0.335", "loss_scale": "2", "train_wall": "233", "gb_free": "39.3", "wall": "73950"}
[2024-10-05 14:46:23,324][train_inner][INFO] - {"epoch": 84, "update": 83.553, "loss": "0.912", "ntokens": "263922", "nsentences": "1773.69", "wps": "234283", "ups": "0.89", "wpb": "263922", "bsz": "1773.7", "num_updates": "40000", "lr": "0.00048913", "gnorm": "0.333", "loss_scale": "2", "train_wall": "220", "gb_free": "39.3", "wall": "74175"}
[2024-10-05 14:50:27,024][train_inner][INFO] - {"epoch": 84, "update": 83.971, "loss": "0.914", "ntokens": "264016", "nsentences": "1749.24", "wps": "216702", "ups": "0.82", "wpb": "264016", "bsz": "1749.2", "num_updates": "40200", "lr": "0.000488859", "gnorm": "0.312", "loss_scale": "2", "train_wall": "239", "gb_free": "39.3", "wall": "74419"}
[2024-10-05 14:51:02,273][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2024-10-05 14:51:02,275][train][INFO] - {"epoch": 84, "train_loss": "0.913", "train_ntokens": "263551", "train_nsentences": "1753.71", "train_wps": "132587", "train_ups": "0.5", "train_wpb": "263551", "train_bsz": "1753.7", "train_num_updates": "40214", "train_lr": "0.00048884", "train_gnorm": "0.323", "train_loss_scale": "2", "train_train_wall": "583", "train_gb_free": "40.1", "train_wall": "74454"}
[2024-10-05 14:51:02,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 14:51:02,338][fairseq.trainer][INFO] - begin training epoch 85
[2024-10-05 14:51:02,339][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 14:59:42,559][train_inner][INFO] - {"epoch": 85, "update": 84.388, "loss": "0.909", "ntokens": "263410", "nsentences": "1700.5", "wps": "94833.4", "ups": "0.36", "wpb": "263410", "bsz": "1700.5", "num_updates": "40400", "lr": "0.000488587", "gnorm": "0.334", "loss_scale": "2", "train_wall": "236", "gb_free": "39.8", "wall": "74975"}
[2024-10-05 15:03:47,121][train_inner][INFO] - {"epoch": 85, "update": 84.806, "loss": "0.912", "ntokens": "263670", "nsentences": "1788.18", "wps": "215643", "ups": "0.82", "wpb": "263670", "bsz": "1788.2", "num_updates": "40600", "lr": "0.000488315", "gnorm": "0.331", "loss_scale": "2", "train_wall": "240", "gb_free": "39.1", "wall": "75219"}
[2024-10-05 15:05:25,055][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2024-10-05 15:05:25,089][train][INFO] - {"epoch": 85, "train_loss": "0.911", "train_ntokens": "263557", "train_nsentences": "1753.71", "train_wps": "146317", "train_ups": "0.56", "train_wpb": "263557", "train_bsz": "1753.7", "train_num_updates": "40693", "train_lr": "0.000488189", "train_gnorm": "0.325", "train_loss_scale": "2", "train_train_wall": "537", "train_gb_free": "39.7", "train_wall": "75317"}
[2024-10-05 15:05:25,252][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 15:05:25,280][fairseq.trainer][INFO] - begin training epoch 86
[2024-10-05 15:05:25,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 15:13:18,468][train_inner][INFO] - {"epoch": 86, "update": 85.223, "loss": "0.909", "ntokens": "262841", "nsentences": "1764.98", "wps": "92009.1", "ups": "0.35", "wpb": "262841", "bsz": "1765", "num_updates": "40800", "lr": "0.000488043", "gnorm": "0.301", "loss_scale": "4", "train_wall": "227", "gb_free": "40.1", "wall": "75791"}
[2024-10-05 15:15:10,992][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 15:17:10,972][train_inner][INFO] - {"epoch": 86, "update": 85.643, "loss": "0.913", "ntokens": "264015", "nsentences": "1776.75", "wps": "227121", "ups": "0.86", "wpb": "264015", "bsz": "1776.8", "num_updates": "41000", "lr": "0.000487772", "gnorm": "0.342", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "76023"}
[2024-10-05 15:20:32,349][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2024-10-05 15:20:32,400][train][INFO] - {"epoch": 86, "train_loss": "0.91", "train_ntokens": "263518", "train_nsentences": "1753.74", "train_wps": "138830", "train_ups": "0.53", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "41171", "train_lr": "0.000487539", "train_gnorm": "0.32", "train_loss_scale": "2", "train_train_wall": "555", "train_gb_free": "39.1", "train_wall": "76225"}
[2024-10-05 15:20:32,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 15:20:32,654][fairseq.trainer][INFO] - begin training epoch 87
[2024-10-05 15:20:32,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 15:26:48,346][train_inner][INFO] - {"epoch": 87, "update": 86.061, "loss": "0.911", "ntokens": "262676", "nsentences": "1723.92", "wps": "90991.2", "ups": "0.35", "wpb": "262676", "bsz": "1723.9", "num_updates": "41200", "lr": "0.0004875", "gnorm": "0.311", "loss_scale": "2", "train_wall": "236", "gb_free": "39.2", "wall": "76601"}
[2024-10-05 15:30:20,282][train_inner][INFO] - {"epoch": 87, "update": 86.478, "loss": "0.909", "ntokens": "264026", "nsentences": "1767.65", "wps": "249169", "ups": "0.94", "wpb": "264026", "bsz": "1767.7", "num_updates": "41400", "lr": "0.000487228", "gnorm": "0.319", "loss_scale": "2", "train_wall": "207", "gb_free": "40.2", "wall": "76812"}
[2024-10-05 15:34:27,651][train_inner][INFO] - {"epoch": 87, "update": 86.896, "loss": "0.911", "ntokens": "263809", "nsentences": "1773.54", "wps": "213307", "ups": "0.81", "wpb": "263809", "bsz": "1773.5", "num_updates": "41600", "lr": "0.000486957", "gnorm": "0.326", "loss_scale": "2", "train_wall": "242", "gb_free": "39.6", "wall": "77060"}
[2024-10-05 15:35:31,495][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2024-10-05 15:35:31,518][train][INFO] - {"epoch": 87, "train_loss": "0.909", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "140387", "train_ups": "0.53", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "41650", "train_lr": "0.000486889", "train_gnorm": "0.322", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.6", "train_wall": "77124"}
[2024-10-05 15:35:31,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 15:35:31,670][fairseq.trainer][INFO] - begin training epoch 88
[2024-10-05 15:35:31,671][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 15:44:09,536][train_inner][INFO] - {"epoch": 88, "update": 87.313, "loss": "0.905", "ntokens": "263360", "nsentences": "1689.38", "wps": "90521.5", "ups": "0.34", "wpb": "263360", "bsz": "1689.4", "num_updates": "41800", "lr": "0.000486685", "gnorm": "0.301", "loss_scale": "2", "train_wall": "252", "gb_free": "39.6", "wall": "77642"}
[2024-10-05 15:48:13,158][train_inner][INFO] - {"epoch": 88, "update": 87.731, "loss": "0.909", "ntokens": "263730", "nsentences": "1788.49", "wps": "216513", "ups": "0.82", "wpb": "263730", "bsz": "1788.5", "num_updates": "42000", "lr": "0.000486413", "gnorm": "0.296", "loss_scale": "2", "train_wall": "238", "gb_free": "39.6", "wall": "77885"}
[2024-10-05 15:51:00,342][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2024-10-05 15:51:00,369][train][INFO] - {"epoch": 88, "train_loss": "0.908", "train_ntokens": "263556", "train_nsentences": "1753.71", "train_wps": "135914", "train_ups": "0.52", "train_wpb": "263556", "train_bsz": "1753.7", "train_num_updates": "42129", "train_lr": "0.000486238", "train_gnorm": "0.302", "train_loss_scale": "2", "train_train_wall": "591", "train_gb_free": "40", "train_wall": "78053"}
[2024-10-05 15:51:00,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 15:51:00,513][fairseq.trainer][INFO] - begin training epoch 89
[2024-10-05 15:51:00,513][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 15:57:44,361][train_inner][INFO] - {"epoch": 89, "update": 88.148, "loss": "0.909", "ntokens": "263017", "nsentences": "1737.46", "wps": "92094.7", "ups": "0.35", "wpb": "263017", "bsz": "1737.5", "num_updates": "42200", "lr": "0.000486141", "gnorm": "0.308", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "78457"}
[2024-10-05 16:01:12,297][train_inner][INFO] - {"epoch": 89, "update": 88.566, "loss": "0.904", "ntokens": "264254", "nsentences": "1719.56", "wps": "254176", "ups": "0.96", "wpb": "264254", "bsz": "1719.6", "num_updates": "42400", "lr": "0.00048587", "gnorm": "0.31", "loss_scale": "2", "train_wall": "203", "gb_free": "39.8", "wall": "78664"}
[2024-10-05 16:05:27,454][train_inner][INFO] - {"epoch": 89, "update": 88.983, "loss": "0.909", "ntokens": "263457", "nsentences": "1808.82", "wps": "206546", "ups": "0.78", "wpb": "263457", "bsz": "1808.8", "num_updates": "42600", "lr": "0.000485598", "gnorm": "0.303", "loss_scale": "2", "train_wall": "250", "gb_free": "39.2", "wall": "78920"}
[2024-10-05 16:06:01,550][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2024-10-05 16:06:01,586][train][INFO] - {"epoch": 89, "train_loss": "0.906", "train_ntokens": "263420", "train_nsentences": "1753.71", "train_wps": "140014", "train_ups": "0.53", "train_wpb": "263420", "train_bsz": "1753.7", "train_num_updates": "42608", "train_lr": "0.000485587", "train_gnorm": "0.307", "train_loss_scale": "2", "train_train_wall": "565", "train_gb_free": "40", "train_wall": "78954"}
[2024-10-05 16:06:01,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 16:06:01,833][fairseq.trainer][INFO] - begin training epoch 90
[2024-10-05 16:06:01,834][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 16:15:08,246][train_inner][INFO] - {"epoch": 90, "update": 89.401, "loss": "0.906", "ntokens": "262199", "nsentences": "1798.3", "wps": "90291", "ups": "0.34", "wpb": "262199", "bsz": "1798.3", "num_updates": "42800", "lr": "0.000485326", "gnorm": "0.311", "loss_scale": "2", "train_wall": "180", "gb_free": "39.7", "wall": "79500"}
[2024-10-05 16:19:01,587][train_inner][INFO] - {"epoch": 90, "update": 89.818, "loss": "0.907", "ntokens": "264125", "nsentences": "1738.4", "wps": "226391", "ups": "0.86", "wpb": "264125", "bsz": "1738.4", "num_updates": "43000", "lr": "0.000485054", "gnorm": "0.322", "loss_scale": "4", "train_wall": "175", "gb_free": "39.3", "wall": "79734"}
[2024-10-05 16:20:44,005][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 43087 updates
[2024-10-05 16:20:44,007][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 16:20:52,839][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 16:20:52,858][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 90 @ 43087 updates, score None) (writing took 8.853879714384675 seconds)
[2024-10-05 16:20:52,859][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2024-10-05 16:20:52,868][train][INFO] - {"epoch": 90, "train_loss": "0.906", "train_ntokens": "263422", "train_nsentences": "1753.71", "train_wps": "141572", "train_ups": "0.54", "train_wpb": "263422", "train_bsz": "1753.7", "train_num_updates": "43087", "train_lr": "0.000484936", "train_gnorm": "0.32", "train_loss_scale": "4", "train_train_wall": "422", "train_gb_free": "39.2", "train_wall": "79845"}
[2024-10-05 16:20:52,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 16:20:52,996][fairseq.trainer][INFO] - begin training epoch 91
[2024-10-05 16:20:52,997][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 16:28:12,597][train_inner][INFO] - {"epoch": 91, "update": 90.236, "loss": "0.903", "ntokens": "263152", "nsentences": "1712.92", "wps": "95517.4", "ups": "0.36", "wpb": "263152", "bsz": "1712.9", "num_updates": "43200", "lr": "0.000484783", "gnorm": "0.331", "loss_scale": "4", "train_wall": "231", "gb_free": "41", "wall": "80285"}
[2024-10-05 16:28:32,122][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 16:31:52,458][train_inner][INFO] - {"epoch": 91, "update": 90.656, "loss": "0.903", "ntokens": "264030", "nsentences": "1738.06", "wps": "240187", "ups": "0.91", "wpb": "264030", "bsz": "1738.1", "num_updates": "43400", "lr": "0.000484511", "gnorm": "0.323", "loss_scale": "2", "train_wall": "213", "gb_free": "39.3", "wall": "80505"}
[2024-10-05 16:35:21,016][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2024-10-05 16:35:21,024][train][INFO] - {"epoch": 91, "train_loss": "0.904", "train_ntokens": "263460", "train_nsentences": "1753.93", "train_wps": "145060", "train_ups": "0.55", "train_wpb": "263460", "train_bsz": "1753.9", "train_num_updates": "43565", "train_lr": "0.000484287", "train_gnorm": "0.314", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "40.1", "train_wall": "80713"}
[2024-10-05 16:35:21,212][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 16:35:21,248][fairseq.trainer][INFO] - begin training epoch 92
[2024-10-05 16:35:21,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 16:41:41,562][train_inner][INFO] - {"epoch": 92, "update": 91.073, "loss": "0.905", "ntokens": "262706", "nsentences": "1769.15", "wps": "89189.5", "ups": "0.34", "wpb": "262706", "bsz": "1769.2", "num_updates": "43600", "lr": "0.000484239", "gnorm": "0.302", "loss_scale": "2", "train_wall": "267", "gb_free": "39.6", "wall": "81094"}
[2024-10-05 16:45:35,747][train_inner][INFO] - {"epoch": 92, "update": 91.491, "loss": "0.902", "ntokens": "263836", "nsentences": "1761.93", "wps": "225331", "ups": "0.85", "wpb": "263836", "bsz": "1761.9", "num_updates": "43800", "lr": "0.000483967", "gnorm": "0.331", "loss_scale": "2", "train_wall": "229", "gb_free": "40.2", "wall": "81328"}
[2024-10-05 16:50:07,097][train_inner][INFO] - {"epoch": 92, "update": 91.908, "loss": "0.903", "ntokens": "264232", "nsentences": "1733.91", "wps": "194762", "ups": "0.74", "wpb": "264232", "bsz": "1733.9", "num_updates": "44000", "lr": "0.000483696", "gnorm": "0.302", "loss_scale": "2", "train_wall": "266", "gb_free": "39.7", "wall": "81599"}
[2024-10-05 16:51:12,653][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2024-10-05 16:51:12,664][train][INFO] - {"epoch": 92, "train_loss": "0.903", "train_ntokens": "263513", "train_nsentences": "1753.71", "train_wps": "132638", "train_ups": "0.5", "train_wpb": "263513", "train_bsz": "1753.7", "train_num_updates": "44044", "train_lr": "0.000483636", "train_gnorm": "0.317", "train_loss_scale": "2", "train_train_wall": "623", "train_gb_free": "39.7", "train_wall": "81665"}
[2024-10-05 16:51:12,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 16:51:12,777][fairseq.trainer][INFO] - begin training epoch 93
[2024-10-05 16:51:12,778][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 16:59:33,966][train_inner][INFO] - {"epoch": 93, "update": 92.326, "loss": "0.902", "ntokens": "262931", "nsentences": "1752.31", "wps": "92767.7", "ups": "0.35", "wpb": "262931", "bsz": "1752.3", "num_updates": "44200", "lr": "0.000483424", "gnorm": "0.307", "loss_scale": "2", "train_wall": "237", "gb_free": "39.6", "wall": "82166"}
[2024-10-05 17:03:41,926][train_inner][INFO] - {"epoch": 93, "update": 92.743, "loss": "0.899", "ntokens": "263971", "nsentences": "1756.08", "wps": "212925", "ups": "0.81", "wpb": "263971", "bsz": "1756.1", "num_updates": "44400", "lr": "0.000483152", "gnorm": "0.299", "loss_scale": "2", "train_wall": "242", "gb_free": "40.8", "wall": "82414"}
[2024-10-05 17:06:21,642][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2024-10-05 17:06:21,714][train][INFO] - {"epoch": 93, "train_loss": "0.902", "train_ntokens": "263507", "train_nsentences": "1753.71", "train_wps": "138850", "train_ups": "0.53", "train_wpb": "263507", "train_bsz": "1753.7", "train_num_updates": "44523", "train_lr": "0.000482985", "train_gnorm": "0.309", "train_loss_scale": "2", "train_train_wall": "572", "train_gb_free": "39.6", "train_wall": "82574"}
[2024-10-05 17:06:21,784][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 17:06:21,791][fairseq.trainer][INFO] - begin training epoch 94
[2024-10-05 17:06:21,791][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 17:13:31,589][train_inner][INFO] - {"epoch": 94, "update": 93.161, "loss": "0.903", "ntokens": "262734", "nsentences": "1760.04", "wps": "89114.6", "ups": "0.34", "wpb": "262734", "bsz": "1760", "num_updates": "44600", "lr": "0.00048288", "gnorm": "0.336", "loss_scale": "2", "train_wall": "272", "gb_free": "40", "wall": "83004"}
[2024-10-05 17:17:05,871][train_inner][INFO] - {"epoch": 94, "update": 93.578, "loss": "0.9", "ntokens": "263899", "nsentences": "1757.73", "wps": "246330", "ups": "0.93", "wpb": "263899", "bsz": "1757.7", "num_updates": "44800", "lr": "0.000482609", "gnorm": "0.29", "loss_scale": "2", "train_wall": "209", "gb_free": "39.8", "wall": "83218"}
[2024-10-05 17:21:44,538][train_inner][INFO] - {"epoch": 94, "update": 93.996, "loss": "0.902", "ntokens": "263832", "nsentences": "1756.81", "wps": "189371", "ups": "0.72", "wpb": "263832", "bsz": "1756.8", "num_updates": "45000", "lr": "0.000482337", "gnorm": "0.293", "loss_scale": "2", "train_wall": "274", "gb_free": "39.3", "wall": "83497"}
[2024-10-05 17:21:45,659][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2024-10-05 17:21:45,663][train][INFO] - {"epoch": 94, "train_loss": "0.9", "train_ntokens": "263427", "train_nsentences": "1753.71", "train_wps": "136568", "train_ups": "0.52", "train_wpb": "263427", "train_bsz": "1753.7", "train_num_updates": "45002", "train_lr": "0.000482334", "train_gnorm": "0.301", "train_loss_scale": "2", "train_train_wall": "601", "train_gb_free": "39.6", "train_wall": "83498"}
[2024-10-05 17:21:45,741][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 17:21:45,749][fairseq.trainer][INFO] - begin training epoch 95
[2024-10-05 17:21:45,750][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 17:30:47,008][train_inner][INFO] - {"epoch": 95, "update": 94.413, "loss": "0.899", "ntokens": "262746", "nsentences": "1761.25", "wps": "96871.8", "ups": "0.37", "wpb": "262746", "bsz": "1761.2", "num_updates": "45200", "lr": "0.000482065", "gnorm": "0.292", "loss_scale": "2", "train_wall": "204", "gb_free": "39.8", "wall": "84039"}
[2024-10-05 17:34:38,415][train_inner][INFO] - {"epoch": 95, "update": 94.831, "loss": "0.901", "ntokens": "263684", "nsentences": "1793.85", "wps": "227906", "ups": "0.86", "wpb": "263684", "bsz": "1793.9", "num_updates": "45400", "lr": "0.000481793", "gnorm": "0.303", "loss_scale": "4", "train_wall": "215", "gb_free": "39.8", "wall": "84271"}
[2024-10-05 17:35:57,713][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2024-10-05 17:35:57,729][train][INFO] - {"epoch": 95, "train_loss": "0.9", "train_ntokens": "263443", "train_nsentences": "1753.71", "train_wps": "148098", "train_ups": "0.56", "train_wpb": "263443", "train_bsz": "1753.7", "train_num_updates": "45481", "train_lr": "0.000481683", "train_gnorm": "0.302", "train_loss_scale": "4", "train_train_wall": "493", "train_gb_free": "40.7", "train_wall": "84350"}
[2024-10-05 17:35:57,801][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 17:35:57,819][fairseq.trainer][INFO] - begin training epoch 96
[2024-10-05 17:35:57,820][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 17:41:51,761][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 17:43:45,647][train_inner][INFO] - {"epoch": 96, "update": 95.251, "loss": "0.897", "ntokens": "263129", "nsentences": "1686.05", "wps": "96170.5", "ups": "0.37", "wpb": "263130", "bsz": "1686", "num_updates": "45600", "lr": "0.000481522", "gnorm": "0.32", "loss_scale": "2", "train_wall": "171", "gb_free": "39.2", "wall": "84818"}
[2024-10-05 17:47:33,165][train_inner][INFO] - {"epoch": 96, "update": 95.668, "loss": "0.898", "ntokens": "264005", "nsentences": "1771.17", "wps": "232086", "ups": "0.88", "wpb": "264005", "bsz": "1771.2", "num_updates": "45800", "lr": "0.00048125", "gnorm": "0.306", "loss_scale": "2", "train_wall": "153", "gb_free": "39.3", "wall": "85045"}
[2024-10-05 17:51:00,588][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2024-10-05 17:51:00,722][train][INFO] - {"epoch": 96, "train_loss": "0.899", "train_ntokens": "263538", "train_nsentences": "1754.31", "train_wps": "139511", "train_ups": "0.53", "train_wpb": "263538", "train_bsz": "1754.3", "train_num_updates": "45959", "train_lr": "0.000481034", "train_gnorm": "0.305", "train_loss_scale": "2", "train_train_wall": "362", "train_gb_free": "39.7", "train_wall": "85253"}
[2024-10-05 17:51:00,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 17:51:01,043][fairseq.trainer][INFO] - begin training epoch 97
[2024-10-05 17:51:01,043][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 17:57:19,429][train_inner][INFO] - {"epoch": 97, "update": 96.086, "loss": "0.901", "ntokens": "262726", "nsentences": "1754.96", "wps": "89630.4", "ups": "0.34", "wpb": "262726", "bsz": "1755", "num_updates": "46000", "lr": "0.000480978", "gnorm": "0.299", "loss_scale": "2", "train_wall": "160", "gb_free": "39.1", "wall": "85632"}
[2024-10-05 18:00:29,888][train_inner][INFO] - {"epoch": 97, "update": 96.503, "loss": "0.895", "ntokens": "264256", "nsentences": "1743.82", "wps": "277507", "ups": "1.05", "wpb": "264256", "bsz": "1743.8", "num_updates": "46200", "lr": "0.000480707", "gnorm": "0.314", "loss_scale": "2", "train_wall": "154", "gb_free": "39.3", "wall": "85822"}
[2024-10-05 18:04:45,073][train_inner][INFO] - {"epoch": 97, "update": 96.921, "loss": "0.901", "ntokens": "263840", "nsentences": "1767.34", "wps": "206804", "ups": "0.78", "wpb": "263840", "bsz": "1767.3", "num_updates": "46400", "lr": "0.000480435", "gnorm": "0.282", "loss_scale": "2", "train_wall": "182", "gb_free": "39.6", "wall": "86077"}
[2024-10-05 18:05:36,947][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2024-10-05 18:05:37,078][train][INFO] - {"epoch": 97, "train_loss": "0.898", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "144058", "train_ups": "0.55", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "46438", "train_lr": "0.000480383", "train_gnorm": "0.298", "train_loss_scale": "2", "train_train_wall": "427", "train_gb_free": "39.6", "train_wall": "86129"}
[2024-10-05 18:05:38,287][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 18:05:38,320][fairseq.trainer][INFO] - begin training epoch 98
[2024-10-05 18:05:38,320][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 18:14:13,214][train_inner][INFO] - {"epoch": 98, "update": 97.338, "loss": "0.893", "ntokens": "262344", "nsentences": "1762.51", "wps": "92352.8", "ups": "0.35", "wpb": "262344", "bsz": "1762.5", "num_updates": "46600", "lr": "0.000480163", "gnorm": "0.31", "loss_scale": "2", "train_wall": "232", "gb_free": "40", "wall": "86645"}
[2024-10-05 18:17:58,570][train_inner][INFO] - {"epoch": 98, "update": 97.756, "loss": "0.897", "ntokens": "264184", "nsentences": "1716.2", "wps": "234480", "ups": "0.89", "wpb": "264184", "bsz": "1716.2", "num_updates": "46800", "lr": "0.000479891", "gnorm": "0.32", "loss_scale": "2", "train_wall": "220", "gb_free": "39.6", "wall": "86871"}
[2024-10-05 18:20:14,616][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2024-10-05 18:20:14,642][train][INFO] - {"epoch": 98, "train_loss": "0.896", "train_ntokens": "263313", "train_nsentences": "1753.71", "train_wps": "143725", "train_ups": "0.55", "train_wpb": "263313", "train_bsz": "1753.7", "train_num_updates": "46917", "train_lr": "0.000479732", "train_gnorm": "0.317", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.6", "train_wall": "87007"}
[2024-10-05 18:20:14,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 18:20:14,804][fairseq.trainer][INFO] - begin training epoch 99
[2024-10-05 18:20:14,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 18:27:30,558][train_inner][INFO] - {"epoch": 99, "update": 98.173, "loss": "0.897", "ntokens": "262785", "nsentences": "1761.65", "wps": "91889.5", "ups": "0.35", "wpb": "262785", "bsz": "1761.7", "num_updates": "47000", "lr": "0.00047962", "gnorm": "0.301", "loss_scale": "2", "train_wall": "178", "gb_free": "39.7", "wall": "87443"}
[2024-10-05 18:31:04,045][train_inner][INFO] - {"epoch": 99, "update": 98.591, "loss": "0.894", "ntokens": "264430", "nsentences": "1729.57", "wps": "247748", "ups": "0.94", "wpb": "264430", "bsz": "1729.6", "num_updates": "47200", "lr": "0.000479348", "gnorm": "0.318", "loss_scale": "2", "train_wall": "204", "gb_free": "40", "wall": "87656"}
[2024-10-05 18:35:11,336][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2024-10-05 18:35:11,374][train][INFO] - {"epoch": 99, "train_loss": "0.895", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "140792", "train_ups": "0.53", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "47396", "train_lr": "0.000479082", "train_gnorm": "0.3", "train_loss_scale": "2", "train_train_wall": "491", "train_gb_free": "40.3", "train_wall": "87904"}
[2024-10-05 18:35:11,487][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 18:35:11,504][fairseq.trainer][INFO] - begin training epoch 100
[2024-10-05 18:35:11,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 18:41:06,474][train_inner][INFO] - {"epoch": 100, "update": 99.008, "loss": "0.898", "ntokens": "262395", "nsentences": "1793.34", "wps": "87114.4", "ups": "0.33", "wpb": "262395", "bsz": "1793.3", "num_updates": "47400", "lr": "0.000479076", "gnorm": "0.29", "loss_scale": "2", "train_wall": "263", "gb_free": "39.2", "wall": "88259"}
[2024-10-05 18:44:39,192][train_inner][INFO] - {"epoch": 100, "update": 99.426, "loss": "0.892", "ntokens": "264154", "nsentences": "1737.87", "wps": "248391", "ups": "0.94", "wpb": "264154", "bsz": "1737.9", "num_updates": "47600", "lr": "0.000478804", "gnorm": "0.309", "loss_scale": "4", "train_wall": "207", "gb_free": "39.6", "wall": "88471"}
[2024-10-05 18:48:33,621][train_inner][INFO] - {"epoch": 100, "update": 99.843, "loss": "0.896", "ntokens": "263529", "nsentences": "1796.23", "wps": "224849", "ups": "0.85", "wpb": "263529", "bsz": "1796.2", "num_updates": "47800", "lr": "0.000478533", "gnorm": "0.286", "loss_scale": "4", "train_wall": "229", "gb_free": "40.2", "wall": "88706"}
[2024-10-05 18:50:14,187][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 47875 updates
[2024-10-05 18:50:14,189][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 18:50:18,864][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 18:50:18,906][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 100 @ 47875 updates, score None) (writing took 4.719099543988705 seconds)
[2024-10-05 18:50:18,907][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2024-10-05 18:50:18,910][train][INFO] - {"epoch": 100, "train_loss": "0.894", "train_ntokens": "263437", "train_nsentences": "1753.71", "train_wps": "139043", "train_ups": "0.53", "train_wpb": "263437", "train_bsz": "1753.7", "train_num_updates": "47875", "train_lr": "0.000478431", "train_gnorm": "0.297", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "40.3", "train_wall": "88811"}
[2024-10-05 18:50:19,002][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 18:50:19,036][fairseq.trainer][INFO] - begin training epoch 101
[2024-10-05 18:50:19,036][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 18:58:14,418][train_inner][INFO] - {"epoch": 101, "update": 100.261, "loss": "0.894", "ntokens": "262969", "nsentences": "1750.87", "wps": "90556", "ups": "0.34", "wpb": "262969", "bsz": "1750.9", "num_updates": "48000", "lr": "0.000478261", "gnorm": "0.303", "loss_scale": "4", "train_wall": "266", "gb_free": "40", "wall": "89287"}
[2024-10-05 19:00:07,946][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 19:01:34,088][train_inner][INFO] - {"epoch": 101, "update": 100.681, "loss": "0.893", "ntokens": "264024", "nsentences": "1736.23", "wps": "264478", "ups": "1", "wpb": "264024", "bsz": "1736.2", "num_updates": "48200", "lr": "0.000477989", "gnorm": "0.293", "loss_scale": "2", "train_wall": "194", "gb_free": "39.6", "wall": "89486"}
[2024-10-05 19:04:37,227][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2024-10-05 19:04:37,246][train][INFO] - {"epoch": 101, "train_loss": "0.894", "train_ntokens": "263579", "train_nsentences": "1751.37", "train_wps": "146786", "train_ups": "0.56", "train_wpb": "263579", "train_bsz": "1751.4", "train_num_updates": "48353", "train_lr": "0.000477781", "train_gnorm": "0.296", "train_loss_scale": "2", "train_train_wall": "538", "train_gb_free": "39.6", "train_wall": "89669"}
[2024-10-05 19:04:37,349][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 19:04:37,373][fairseq.trainer][INFO] - begin training epoch 102
[2024-10-05 19:04:37,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 19:11:21,104][train_inner][INFO] - {"epoch": 102, "update": 101.098, "loss": "0.897", "ntokens": "262874", "nsentences": "1759.83", "wps": "89563.8", "ups": "0.34", "wpb": "262874", "bsz": "1759.8", "num_updates": "48400", "lr": "0.000477717", "gnorm": "0.304", "loss_scale": "2", "train_wall": "257", "gb_free": "40", "wall": "90073"}
[2024-10-05 19:15:10,180][train_inner][INFO] - {"epoch": 102, "update": 101.516, "loss": "0.891", "ntokens": "263995", "nsentences": "1761.04", "wps": "230495", "ups": "0.87", "wpb": "263995", "bsz": "1761", "num_updates": "48600", "lr": "0.000477446", "gnorm": "0.292", "loss_scale": "2", "train_wall": "223", "gb_free": "39.7", "wall": "90302"}
[2024-10-05 19:19:19,848][train_inner][INFO] - {"epoch": 102, "update": 101.933, "loss": "0.894", "ntokens": "264082", "nsentences": "1752.44", "wps": "211551", "ups": "0.8", "wpb": "264082", "bsz": "1752.4", "num_updates": "48800", "lr": "0.000477174", "gnorm": "0.316", "loss_scale": "2", "train_wall": "245", "gb_free": "39.8", "wall": "90552"}
[2024-10-05 19:20:01,201][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2024-10-05 19:20:01,235][train][INFO] - {"epoch": 102, "train_loss": "0.893", "train_ntokens": "263559", "train_nsentences": "1753.71", "train_wps": "136630", "train_ups": "0.52", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "48832", "train_lr": "0.00047713", "train_gnorm": "0.309", "train_loss_scale": "2", "train_train_wall": "589", "train_gb_free": "39.3", "train_wall": "90593"}
[2024-10-05 19:20:01,283][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 19:20:01,310][fairseq.trainer][INFO] - begin training epoch 103
[2024-10-05 19:20:01,311][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 19:28:27,451][train_inner][INFO] - {"epoch": 103, "update": 102.351, "loss": "0.89", "ntokens": "263088", "nsentences": "1729.06", "wps": "96090.5", "ups": "0.37", "wpb": "263088", "bsz": "1729.1", "num_updates": "49000", "lr": "0.000476902", "gnorm": "0.289", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "91100"}
[2024-10-05 19:32:23,074][train_inner][INFO] - {"epoch": 103, "update": 102.768, "loss": "0.893", "ntokens": "263744", "nsentences": "1761.89", "wps": "223891", "ups": "0.85", "wpb": "263744", "bsz": "1761.9", "num_updates": "49200", "lr": "0.00047663", "gnorm": "0.295", "loss_scale": "2", "train_wall": "230", "gb_free": "39.7", "wall": "91335"}
[2024-10-05 19:34:55,560][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2024-10-05 19:34:55,563][train][INFO] - {"epoch": 103, "train_loss": "0.892", "train_ntokens": "263468", "train_nsentences": "1753.71", "train_wps": "141113", "train_ups": "0.54", "train_wpb": "263468", "train_bsz": "1753.7", "train_num_updates": "49311", "train_lr": "0.00047648", "train_gnorm": "0.293", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "39.4", "train_wall": "91488"}
[2024-10-05 19:34:55,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 19:34:55,616][fairseq.trainer][INFO] - begin training epoch 104
[2024-10-05 19:34:55,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 19:42:03,284][train_inner][INFO] - {"epoch": 104, "update": 103.186, "loss": "0.892", "ntokens": "262680", "nsentences": "1770.91", "wps": "90549.5", "ups": "0.34", "wpb": "262680", "bsz": "1770.9", "num_updates": "49400", "lr": "0.000476359", "gnorm": "0.295", "loss_scale": "2", "train_wall": "250", "gb_free": "40.3", "wall": "91915"}
[2024-10-05 19:45:46,275][train_inner][INFO] - {"epoch": 104, "update": 103.603, "loss": "0.889", "ntokens": "264121", "nsentences": "1756.1", "wps": "236901", "ups": "0.9", "wpb": "264120", "bsz": "1756.1", "num_updates": "49600", "lr": "0.000476087", "gnorm": "0.299", "loss_scale": "2", "train_wall": "218", "gb_free": "39.3", "wall": "92138"}
[2024-10-05 19:49:34,559][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2024-10-05 19:49:34,571][train][INFO] - {"epoch": 104, "train_loss": "0.891", "train_ntokens": "263608", "train_nsentences": "1753.71", "train_wps": "143649", "train_ups": "0.54", "train_wpb": "263608", "train_bsz": "1753.7", "train_num_updates": "49790", "train_lr": "0.000475829", "train_gnorm": "0.293", "train_loss_scale": "2", "train_train_wall": "540", "train_gb_free": "39.7", "train_wall": "92367"}
[2024-10-05 19:49:34,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 19:49:34,730][fairseq.trainer][INFO] - begin training epoch 105
[2024-10-05 19:49:34,731][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 19:55:43,327][train_inner][INFO] - {"epoch": 105, "update": 104.021, "loss": "0.891", "ntokens": "263225", "nsentences": "1719.26", "wps": "88177.4", "ups": "0.33", "wpb": "263225", "bsz": "1719.3", "num_updates": "49800", "lr": "0.000475815", "gnorm": "0.292", "loss_scale": "2", "train_wall": "246", "gb_free": "40", "wall": "92735"}
[2024-10-05 19:59:12,569][train_inner][INFO] - {"epoch": 105, "update": 104.438, "loss": "0.888", "ntokens": "264174", "nsentences": "1732.9", "wps": "252563", "ups": "0.96", "wpb": "264174", "bsz": "1732.9", "num_updates": "50000", "lr": "0.000475543", "gnorm": "0.285", "loss_scale": "2", "train_wall": "205", "gb_free": "39.6", "wall": "92945"}
[2024-10-05 19:59:12,582][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 50000 updates
[2024-10-05 19:59:12,583][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_105_50000.pt
[2024-10-05 19:59:17,421][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_105_50000.pt
[2024-10-05 19:59:28,222][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_105_50000.pt (epoch 105 @ 50000 updates, score None) (writing took 15.639982657507062 seconds)
[2024-10-05 20:03:11,614][train_inner][INFO] - {"epoch": 105, "update": 104.856, "loss": "0.891", "ntokens": "263712", "nsentences": "1791.65", "wps": "220645", "ups": "0.84", "wpb": "263712", "bsz": "1791.7", "num_updates": "50200", "lr": "0.000475272", "gnorm": "0.292", "loss_scale": "4", "train_wall": "218", "gb_free": "39.6", "wall": "93184"}
[2024-10-05 20:04:34,569][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2024-10-05 20:04:34,592][train][INFO] - {"epoch": 105, "train_loss": "0.89", "train_ntokens": "263538", "train_nsentences": "1753.71", "train_wps": "140258", "train_ups": "0.53", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "50269", "train_lr": "0.000475178", "train_gnorm": "0.293", "train_loss_scale": "4", "train_train_wall": "528", "train_gb_free": "39.1", "train_wall": "93267"}
[2024-10-05 20:04:34,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 20:04:34,738][fairseq.trainer][INFO] - begin training epoch 106
[2024-10-05 20:04:34,739][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 20:11:52,391][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 20:12:52,076][train_inner][INFO] - {"epoch": 106, "update": 105.276, "loss": "0.891", "ntokens": "263015", "nsentences": "1742.24", "wps": "90626.1", "ups": "0.34", "wpb": "263015", "bsz": "1742.2", "num_updates": "50400", "lr": "0.000475", "gnorm": "0.3", "loss_scale": "2", "train_wall": "257", "gb_free": "39.6", "wall": "93764"}
[2024-10-05 20:16:33,044][train_inner][INFO] - {"epoch": 106, "update": 105.693, "loss": "0.888", "ntokens": "263874", "nsentences": "1774.84", "wps": "238840", "ups": "0.91", "wpb": "263874", "bsz": "1774.8", "num_updates": "50600", "lr": "0.000474728", "gnorm": "0.289", "loss_scale": "2", "train_wall": "212", "gb_free": "39.6", "wall": "93985"}
[2024-10-05 20:19:29,933][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2024-10-05 20:19:29,951][train][INFO] - {"epoch": 106, "train_loss": "0.889", "train_ntokens": "263562", "train_nsentences": "1753.65", "train_wps": "140707", "train_ups": "0.53", "train_wpb": "263562", "train_bsz": "1753.7", "train_num_updates": "50747", "train_lr": "0.000474529", "train_gnorm": "0.287", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "39.6", "train_wall": "94162"}
[2024-10-05 20:19:30,080][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 20:19:30,112][fairseq.trainer][INFO] - begin training epoch 107
[2024-10-05 20:19:30,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 20:26:20,459][train_inner][INFO] - {"epoch": 107, "update": 106.111, "loss": "0.888", "ntokens": "263061", "nsentences": "1730.67", "wps": "89569.8", "ups": "0.34", "wpb": "263061", "bsz": "1730.7", "num_updates": "50800", "lr": "0.000474457", "gnorm": "0.278", "loss_scale": "2", "train_wall": "254", "gb_free": "39.8", "wall": "94573"}
[2024-10-05 20:29:44,962][train_inner][INFO] - {"epoch": 107, "update": 106.528, "loss": "0.887", "ntokens": "263687", "nsentences": "1791.04", "wps": "257905", "ups": "0.98", "wpb": "263687", "bsz": "1791", "num_updates": "51000", "lr": "0.000474185", "gnorm": "0.293", "loss_scale": "2", "train_wall": "199", "gb_free": "39.6", "wall": "94777"}
[2024-10-05 20:33:39,967][train_inner][INFO] - {"epoch": 107, "update": 106.946, "loss": "0.889", "ntokens": "264018", "nsentences": "1736.38", "wps": "224703", "ups": "0.85", "wpb": "264018", "bsz": "1736.4", "num_updates": "51200", "lr": "0.000473913", "gnorm": "0.277", "loss_scale": "2", "train_wall": "230", "gb_free": "39.8", "wall": "95012"}
[2024-10-05 20:34:09,098][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2024-10-05 20:34:09,123][train][INFO] - {"epoch": 107, "train_loss": "0.887", "train_ntokens": "263456", "train_nsentences": "1753.71", "train_wps": "143543", "train_ups": "0.54", "train_wpb": "263456", "train_bsz": "1753.7", "train_num_updates": "51226", "train_lr": "0.000473878", "train_gnorm": "0.286", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.7", "train_wall": "95041"}
[2024-10-05 20:34:09,299][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 20:34:09,327][fairseq.trainer][INFO] - begin training epoch 108
[2024-10-05 20:34:09,328][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 20:43:24,145][train_inner][INFO] - {"epoch": 108, "update": 107.363, "loss": "0.888", "ntokens": "262579", "nsentences": "1792.27", "wps": "89897.5", "ups": "0.34", "wpb": "262579", "bsz": "1792.3", "num_updates": "51400", "lr": "0.000473641", "gnorm": "0.286", "loss_scale": "2", "train_wall": "202", "gb_free": "39.6", "wall": "95596"}
[2024-10-05 20:47:10,890][train_inner][INFO] - {"epoch": 108, "update": 107.781, "loss": "0.886", "ntokens": "264118", "nsentences": "1742.1", "wps": "232988", "ups": "0.88", "wpb": "264118", "bsz": "1742.1", "num_updates": "51600", "lr": "0.00047337", "gnorm": "0.297", "loss_scale": "2", "train_wall": "221", "gb_free": "39.7", "wall": "95823"}
[2024-10-05 20:48:59,815][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2024-10-05 20:48:59,842][train][INFO] - {"epoch": 108, "train_loss": "0.887", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "141709", "train_ups": "0.54", "train_wpb": "263508", "train_bsz": "1753.7", "train_num_updates": "51705", "train_lr": "0.000473227", "train_gnorm": "0.291", "train_loss_scale": "2", "train_train_wall": "502", "train_gb_free": "39.2", "train_wall": "95932"}
[2024-10-05 20:49:00,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 20:49:00,042][fairseq.trainer][INFO] - begin training epoch 109
[2024-10-05 20:49:00,043][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 20:56:42,451][train_inner][INFO] - {"epoch": 109, "update": 108.198, "loss": "0.886", "ntokens": "263036", "nsentences": "1719.19", "wps": "92042.9", "ups": "0.35", "wpb": "263036", "bsz": "1719.2", "num_updates": "51800", "lr": "0.000473098", "gnorm": "0.291", "loss_scale": "2", "train_wall": "221", "gb_free": "40", "wall": "96395"}
[2024-10-05 21:00:29,738][train_inner][INFO] - {"epoch": 109, "update": 108.616, "loss": "0.883", "ntokens": "264213", "nsentences": "1734.98", "wps": "232510", "ups": "0.88", "wpb": "264213", "bsz": "1735", "num_updates": "52000", "lr": "0.000472826", "gnorm": "0.272", "loss_scale": "2", "train_wall": "222", "gb_free": "39.1", "wall": "96622"}
[2024-10-05 21:04:43,647][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2024-10-05 21:04:43,653][train][INFO] - {"epoch": 109, "train_loss": "0.886", "train_ntokens": "263531", "train_nsentences": "1753.71", "train_wps": "133747", "train_ups": "0.51", "train_wpb": "263531", "train_bsz": "1753.7", "train_num_updates": "52184", "train_lr": "0.000472576", "train_gnorm": "0.29", "train_loss_scale": "2", "train_train_wall": "586", "train_gb_free": "39.6", "train_wall": "96876"}
[2024-10-05 21:04:43,724][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 21:04:43,776][fairseq.trainer][INFO] - begin training epoch 110
[2024-10-05 21:04:43,776][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 21:10:59,892][train_inner][INFO] - {"epoch": 110, "update": 109.033, "loss": "0.89", "ntokens": "262617", "nsentences": "1773.83", "wps": "83353.9", "ups": "0.32", "wpb": "262617", "bsz": "1773.8", "num_updates": "52200", "lr": "0.000472554", "gnorm": "0.314", "loss_scale": "2", "train_wall": "275", "gb_free": "39.6", "wall": "97252"}
[2024-10-05 21:14:46,034][train_inner][INFO] - {"epoch": 110, "update": 109.451, "loss": "0.882", "ntokens": "264001", "nsentences": "1760.99", "wps": "233495", "ups": "0.88", "wpb": "264001", "bsz": "1761", "num_updates": "52400", "lr": "0.000472283", "gnorm": "0.311", "loss_scale": "4", "train_wall": "221", "gb_free": "39.3", "wall": "97478"}
[2024-10-05 21:18:58,031][train_inner][INFO] - {"epoch": 110, "update": 109.868, "loss": "0.887", "ntokens": "264061", "nsentences": "1752.12", "wps": "209588", "ups": "0.79", "wpb": "264061", "bsz": "1752.1", "num_updates": "52600", "lr": "0.000472011", "gnorm": "0.282", "loss_scale": "4", "train_wall": "247", "gb_free": "40.5", "wall": "97730"}
[2024-10-05 21:20:21,350][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 52663 updates
[2024-10-05 21:20:21,358][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 21:20:26,190][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 21:20:26,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 110 @ 52663 updates, score None) (writing took 4.843230183236301 seconds)
[2024-10-05 21:20:26,193][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2024-10-05 21:20:26,203][train][INFO] - {"epoch": 110, "train_loss": "0.885", "train_ntokens": "263545", "train_nsentences": "1753.71", "train_wps": "133934", "train_ups": "0.51", "train_wpb": "263545", "train_bsz": "1753.7", "train_num_updates": "52663", "train_lr": "0.000471925", "train_gnorm": "0.299", "train_loss_scale": "4", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "97818"}
[2024-10-05 21:20:26,270][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 21:20:26,307][fairseq.trainer][INFO] - begin training epoch 111
[2024-10-05 21:20:26,307][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 21:28:21,898][train_inner][INFO] - {"epoch": 111, "update": 110.286, "loss": "0.884", "ntokens": "262592", "nsentences": "1773.02", "wps": "93145.5", "ups": "0.35", "wpb": "262592", "bsz": "1773", "num_updates": "52800", "lr": "0.000471739", "gnorm": "0.294", "loss_scale": "4", "train_wall": "224", "gb_free": "39.7", "wall": "98294"}
[2024-10-05 21:32:28,732][train_inner][INFO] - {"epoch": 111, "update": 110.704, "loss": "0.883", "ntokens": "264253", "nsentences": "1729.83", "wps": "214119", "ups": "0.81", "wpb": "264253", "bsz": "1729.8", "num_updates": "53000", "lr": "0.000471467", "gnorm": "0.286", "loss_scale": "4", "train_wall": "241", "gb_free": "39.6", "wall": "98541"}
[2024-10-05 21:35:39,861][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2024-10-05 21:35:39,894][train][INFO] - {"epoch": 111, "train_loss": "0.885", "train_ntokens": "263523", "train_nsentences": "1753.71", "train_wps": "138153", "train_ups": "0.52", "train_wpb": "263523", "train_bsz": "1753.7", "train_num_updates": "53142", "train_lr": "0.000471274", "train_gnorm": "0.291", "train_loss_scale": "4", "train_train_wall": "569", "train_gb_free": "41", "train_wall": "98732"}
[2024-10-05 21:35:40,089][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 21:35:40,141][fairseq.trainer][INFO] - begin training epoch 112
[2024-10-05 21:35:40,142][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 21:42:28,851][train_inner][INFO] - {"epoch": 112, "update": 111.121, "loss": "0.886", "ntokens": "262831", "nsentences": "1749.86", "wps": "87593.7", "ups": "0.33", "wpb": "262831", "bsz": "1749.9", "num_updates": "53200", "lr": "0.000471196", "gnorm": "0.3", "loss_scale": "4", "train_wall": "283", "gb_free": "39.7", "wall": "99141"}
[2024-10-05 21:46:16,315][train_inner][INFO] - {"epoch": 112, "update": 111.539, "loss": "0.884", "ntokens": "264018", "nsentences": "1762.88", "wps": "232149", "ups": "0.88", "wpb": "264018", "bsz": "1762.9", "num_updates": "53400", "lr": "0.000470924", "gnorm": "0.286", "loss_scale": "4", "train_wall": "222", "gb_free": "40.5", "wall": "99368"}
[2024-10-05 21:46:50,494][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 21:50:18,295][train_inner][INFO] - {"epoch": 112, "update": 111.958, "loss": "0.884", "ntokens": "264050", "nsentences": "1732.88", "wps": "218251", "ups": "0.83", "wpb": "264050", "bsz": "1732.9", "num_updates": "53600", "lr": "0.000470652", "gnorm": "0.281", "loss_scale": "2", "train_wall": "237", "gb_free": "39.3", "wall": "99610"}
[2024-10-05 21:50:55,262][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2024-10-05 21:50:55,277][train][INFO] - {"epoch": 112, "train_loss": "0.884", "train_ntokens": "263485", "train_nsentences": "1755.1", "train_wps": "137591", "train_ups": "0.52", "train_wpb": "263485", "train_bsz": "1755.1", "train_num_updates": "53620", "train_lr": "0.000470625", "train_gnorm": "0.287", "train_loss_scale": "2", "train_train_wall": "590", "train_gb_free": "39.2", "train_wall": "99647"}
[2024-10-05 21:50:55,334][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 21:50:55,348][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-05 21:50:55,349][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 22:00:01,900][train_inner][INFO] - {"epoch": 113, "update": 112.376, "loss": "0.883", "ntokens": "262292", "nsentences": "1808.2", "wps": "89888.1", "ups": "0.34", "wpb": "262292", "bsz": "1808.2", "num_updates": "53800", "lr": "0.00047038", "gnorm": "0.278", "loss_scale": "2", "train_wall": "242", "gb_free": "39.3", "wall": "100194"}
[2024-10-05 22:03:52,020][train_inner][INFO] - {"epoch": 113, "update": 112.793, "loss": "0.882", "ntokens": "264343", "nsentences": "1731.79", "wps": "229770", "ups": "0.87", "wpb": "264343", "bsz": "1731.8", "num_updates": "54000", "lr": "0.000470109", "gnorm": "0.281", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "100424"}
[2024-10-05 22:06:07,771][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-10-05 22:06:07,806][train][INFO] - {"epoch": 113, "train_loss": "0.882", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "138335", "train_ups": "0.52", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "54099", "train_lr": "0.000469974", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "40", "train_wall": "100560"}
[2024-10-05 22:06:08,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 22:06:08,037][fairseq.trainer][INFO] - begin training epoch 114
[2024-10-05 22:06:08,038][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 22:13:38,895][train_inner][INFO] - {"epoch": 114, "update": 113.211, "loss": "0.879", "ntokens": "263415", "nsentences": "1697.18", "wps": "89770.6", "ups": "0.34", "wpb": "263415", "bsz": "1697.2", "num_updates": "54200", "lr": "0.000469837", "gnorm": "0.288", "loss_scale": "2", "train_wall": "259", "gb_free": "39.3", "wall": "101011"}
[2024-10-05 22:17:29,902][train_inner][INFO] - {"epoch": 114, "update": 113.628, "loss": "0.883", "ntokens": "263520", "nsentences": "1810.26", "wps": "228160", "ups": "0.87", "wpb": "263520", "bsz": "1810.3", "num_updates": "54400", "lr": "0.000469565", "gnorm": "0.271", "loss_scale": "2", "train_wall": "226", "gb_free": "39.6", "wall": "101242"}
[2024-10-05 22:21:04,854][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-10-05 22:21:04,880][train][INFO] - {"epoch": 114, "train_loss": "0.882", "train_ntokens": "263543", "train_nsentences": "1753.71", "train_wps": "140724", "train_ups": "0.53", "train_wpb": "263543", "train_bsz": "1753.7", "train_num_updates": "54578", "train_lr": "0.000469323", "train_gnorm": "0.282", "train_loss_scale": "2", "train_train_wall": "562", "train_gb_free": "40.2", "train_wall": "101457"}
[2024-10-05 22:21:04,998][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 22:21:05,044][fairseq.trainer][INFO] - begin training epoch 115
[2024-10-05 22:21:05,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 22:27:04,640][train_inner][INFO] - {"epoch": 115, "update": 114.046, "loss": "0.885", "ntokens": "262963", "nsentences": "1738.72", "wps": "91509.7", "ups": "0.35", "wpb": "262963", "bsz": "1738.7", "num_updates": "54600", "lr": "0.000469293", "gnorm": "0.289", "loss_scale": "2", "train_wall": "245", "gb_free": "39.7", "wall": "101817"}
[2024-10-05 22:30:25,509][train_inner][INFO] - {"epoch": 115, "update": 114.463, "loss": "0.878", "ntokens": "264154", "nsentences": "1740.72", "wps": "263021", "ups": "1", "wpb": "264154", "bsz": "1740.7", "num_updates": "54800", "lr": "0.000469022", "gnorm": "0.283", "loss_scale": "2", "train_wall": "196", "gb_free": "40", "wall": "102018"}
[2024-10-05 22:34:19,721][train_inner][INFO] - {"epoch": 115, "update": 114.881, "loss": "0.882", "ntokens": "263866", "nsentences": "1776.82", "wps": "225336", "ups": "0.85", "wpb": "263866", "bsz": "1776.8", "num_updates": "55000", "lr": "0.00046875", "gnorm": "0.277", "loss_scale": "2", "train_wall": "226", "gb_free": "39.3", "wall": "102252"}
[2024-10-05 22:35:18,975][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-10-05 22:35:19,000][train][INFO] - {"epoch": 115, "train_loss": "0.881", "train_ntokens": "263542", "train_nsentences": "1753.71", "train_wps": "147802", "train_ups": "0.56", "train_wpb": "263542", "train_bsz": "1753.7", "train_num_updates": "55057", "train_lr": "0.000468673", "train_gnorm": "0.284", "train_loss_scale": "2", "train_train_wall": "514", "train_gb_free": "40.2", "train_wall": "102311"}
[2024-10-05 22:35:19,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 22:35:19,179][fairseq.trainer][INFO] - begin training epoch 116
[2024-10-05 22:35:19,180][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 22:43:30,245][train_inner][INFO] - {"epoch": 116, "update": 115.299, "loss": "0.88", "ntokens": "263248", "nsentences": "1711.24", "wps": "95637.7", "ups": "0.36", "wpb": "263248", "bsz": "1711.2", "num_updates": "55200", "lr": "0.000468478", "gnorm": "0.3", "loss_scale": "2", "train_wall": "181", "gb_free": "39.8", "wall": "102802"}
[2024-10-05 22:47:46,954][train_inner][INFO] - {"epoch": 116, "update": 115.716, "loss": "0.88", "ntokens": "264153", "nsentences": "1739.61", "wps": "205807", "ups": "0.78", "wpb": "264153", "bsz": "1739.6", "num_updates": "55400", "lr": "0.000468207", "gnorm": "0.299", "loss_scale": "2", "train_wall": "141", "gb_free": "40.3", "wall": "103059"}
[2024-10-05 22:50:43,631][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-10-05 22:50:43,666][train][INFO] - {"epoch": 116, "train_loss": "0.88", "train_ntokens": "263556", "train_nsentences": "1753.71", "train_wps": "136530", "train_ups": "0.52", "train_wpb": "263556", "train_bsz": "1753.7", "train_num_updates": "55536", "train_lr": "0.000468022", "train_gnorm": "0.295", "train_loss_scale": "4", "train_train_wall": "385", "train_gb_free": "39.1", "train_wall": "103236"}
[2024-10-05 22:50:43,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 22:50:44,019][fairseq.trainer][INFO] - begin training epoch 117
[2024-10-05 22:50:44,019][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 22:57:36,555][train_inner][INFO] - {"epoch": 117, "update": 116.134, "loss": "0.883", "ntokens": "262597", "nsentences": "1808.06", "wps": "89077.8", "ups": "0.34", "wpb": "262597", "bsz": "1808.1", "num_updates": "55600", "lr": "0.000467935", "gnorm": "0.278", "loss_scale": "4", "train_wall": "198", "gb_free": "39.6", "wall": "103649"}
[2024-10-05 23:01:20,852][train_inner][INFO] - {"epoch": 117, "update": 116.551, "loss": "0.878", "ntokens": "264282", "nsentences": "1733.92", "wps": "235668", "ups": "0.89", "wpb": "264282", "bsz": "1733.9", "num_updates": "55800", "lr": "0.000467663", "gnorm": "0.283", "loss_scale": "4", "train_wall": "218", "gb_free": "39.6", "wall": "103873"}
[2024-10-05 23:04:49,424][train_inner][INFO] - {"epoch": 117, "update": 116.969, "loss": "0.883", "ntokens": "264075", "nsentences": "1757.87", "wps": "253254", "ups": "0.96", "wpb": "264075", "bsz": "1757.9", "num_updates": "56000", "lr": "0.000467391", "gnorm": "0.28", "loss_scale": "4", "train_wall": "202", "gb_free": "39.6", "wall": "104082"}
[2024-10-05 23:05:23,300][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-10-05 23:05:23,362][train][INFO] - {"epoch": 117, "train_loss": "0.88", "train_ntokens": "263683", "train_nsentences": "1753.71", "train_wps": "143580", "train_ups": "0.54", "train_wpb": "263683", "train_bsz": "1753.7", "train_num_updates": "56015", "train_lr": "0.000467371", "train_gnorm": "0.279", "train_loss_scale": "4", "train_train_wall": "530", "train_gb_free": "39.7", "train_wall": "104116"}
[2024-10-05 23:05:23,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 23:05:23,560][fairseq.trainer][INFO] - begin training epoch 118
[2024-10-05 23:05:23,561][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:14:16,315][train_inner][INFO] - {"epoch": 118, "update": 117.386, "loss": "0.879", "ntokens": "262714", "nsentences": "1749.84", "wps": "92689.5", "ups": "0.35", "wpb": "262714", "bsz": "1749.8", "num_updates": "56200", "lr": "0.00046712", "gnorm": "0.284", "loss_scale": "4", "train_wall": "219", "gb_free": "40", "wall": "104648"}
[2024-10-05 23:18:07,162][train_inner][INFO] - {"epoch": 118, "update": 117.804, "loss": "0.877", "ntokens": "264074", "nsentences": "1754.21", "wps": "228813", "ups": "0.87", "wpb": "264074", "bsz": "1754.2", "num_updates": "56400", "lr": "0.000466848", "gnorm": "0.281", "loss_scale": "4", "train_wall": "210", "gb_free": "40.3", "wall": "104879"}
[2024-10-05 23:19:53,865][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-10-05 23:19:53,900][train][INFO] - {"epoch": 118, "train_loss": "0.879", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "145027", "train_ups": "0.55", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "56494", "train_lr": "0.00046672", "train_gnorm": "0.286", "train_loss_scale": "4", "train_train_wall": "486", "train_gb_free": "39.6", "train_wall": "104986"}
[2024-10-05 23:19:54,082][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 23:19:54,111][fairseq.trainer][INFO] - begin training epoch 119
[2024-10-05 23:19:54,112][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:27:39,236][train_inner][INFO] - {"epoch": 119, "update": 118.221, "loss": "0.878", "ntokens": "262866", "nsentences": "1757.97", "wps": "91901.4", "ups": "0.35", "wpb": "262866", "bsz": "1758", "num_updates": "56600", "lr": "0.000466576", "gnorm": "0.284", "loss_scale": "4", "train_wall": "223", "gb_free": "40.2", "wall": "105451"}
[2024-10-05 23:31:43,244][train_inner][INFO] - {"epoch": 119, "update": 118.639, "loss": "0.876", "ntokens": "264086", "nsentences": "1742.55", "wps": "216464", "ups": "0.82", "wpb": "264086", "bsz": "1742.5", "num_updates": "56800", "lr": "0.000466304", "gnorm": "0.285", "loss_scale": "4", "train_wall": "239", "gb_free": "39.6", "wall": "105695"}
[2024-10-05 23:35:24,586][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-10-05 23:35:24,624][train][INFO] - {"epoch": 119, "train_loss": "0.877", "train_ntokens": "263536", "train_nsentences": "1753.71", "train_wps": "135630", "train_ups": "0.51", "train_wpb": "263536", "train_bsz": "1753.7", "train_num_updates": "56973", "train_lr": "0.000466069", "train_gnorm": "0.282", "train_loss_scale": "4", "train_train_wall": "590", "train_gb_free": "40", "train_wall": "105917"}
[2024-10-05 23:35:24,731][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 23:35:24,778][fairseq.trainer][INFO] - begin training epoch 120
[2024-10-05 23:35:24,778][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:41:34,487][train_inner][INFO] - {"epoch": 120, "update": 119.056, "loss": "0.88", "ntokens": "262919", "nsentences": "1757.89", "wps": "88940.9", "ups": "0.34", "wpb": "262919", "bsz": "1757.9", "num_updates": "57000", "lr": "0.000466033", "gnorm": "0.284", "loss_scale": "4", "train_wall": "255", "gb_free": "40", "wall": "106287"}
[2024-10-05 23:45:16,944][train_inner][INFO] - {"epoch": 120, "update": 119.474, "loss": "0.876", "ntokens": "263785", "nsentences": "1781.94", "wps": "237167", "ups": "0.9", "wpb": "263785", "bsz": "1781.9", "num_updates": "57200", "lr": "0.000465761", "gnorm": "0.303", "loss_scale": "4", "train_wall": "217", "gb_free": "39.1", "wall": "106509"}
[2024-10-05 23:49:13,309][train_inner][INFO] - {"epoch": 120, "update": 119.891, "loss": "0.877", "ntokens": "264193", "nsentences": "1732.44", "wps": "223552", "ups": "0.85", "wpb": "264193", "bsz": "1732.4", "num_updates": "57400", "lr": "0.000465489", "gnorm": "0.286", "loss_scale": "4", "train_wall": "231", "gb_free": "39.6", "wall": "106745"}
[2024-10-05 23:50:18,974][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 57452 updates
[2024-10-05 23:50:18,975][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 23:50:28,770][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-05 23:50:29,014][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 120 @ 57452 updates, score None) (writing took 10.04020840022713 seconds)
[2024-10-05 23:50:29,020][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-10-05 23:50:29,022][train][INFO] - {"epoch": 120, "train_loss": "0.877", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "139559", "train_ups": "0.53", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "57452", "train_lr": "0.000465418", "train_gnorm": "0.291", "train_loss_scale": "4", "train_train_wall": "550", "train_gb_free": "39.6", "train_wall": "106821"}
[2024-10-05 23:50:29,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-05 23:50:29,103][fairseq.trainer][INFO] - begin training epoch 121
[2024-10-05 23:50:29,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:57:24,994][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-05 23:58:37,293][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-05 23:58:38,406][train_inner][INFO] - {"epoch": 121, "update": 120.313, "loss": "0.876", "ntokens": "262656", "nsentences": "1754.65", "wps": "92960.6", "ups": "0.35", "wpb": "262656", "bsz": "1754.7", "num_updates": "57600", "lr": "0.000465217", "gnorm": "0.292", "loss_scale": "2", "train_wall": "241", "gb_free": "39.6", "wall": "107311"}
[2024-10-06 00:02:24,862][train_inner][INFO] - {"epoch": 121, "update": 120.731, "loss": "0.876", "ntokens": "264113", "nsentences": "1751.65", "wps": "233262", "ups": "0.88", "wpb": "264113", "bsz": "1751.7", "num_updates": "57800", "lr": "0.000464946", "gnorm": "0.28", "loss_scale": "2", "train_wall": "221", "gb_free": "40.5", "wall": "107537"}
[2024-10-06 00:05:01,877][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-10-06 00:05:01,926][train][INFO] - {"epoch": 121, "train_loss": "0.876", "train_ntokens": "263550", "train_nsentences": "1753.84", "train_wps": "144021", "train_ups": "0.55", "train_wpb": "263550", "train_bsz": "1753.8", "train_num_updates": "57929", "train_lr": "0.00046477", "train_gnorm": "0.283", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.1", "train_wall": "107694"}
[2024-10-06 00:05:02,144][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 00:05:02,180][fairseq.trainer][INFO] - begin training epoch 122
[2024-10-06 00:05:02,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:12:13,642][train_inner][INFO] - {"epoch": 122, "update": 121.148, "loss": "0.879", "ntokens": "262557", "nsentences": "1779.75", "wps": "89189.3", "ups": "0.34", "wpb": "262557", "bsz": "1779.8", "num_updates": "58000", "lr": "0.000464674", "gnorm": "0.274", "loss_scale": "2", "train_wall": "209", "gb_free": "39.8", "wall": "108126"}
[2024-10-06 00:15:56,424][train_inner][INFO] - {"epoch": 122, "update": 121.566, "loss": "0.873", "ntokens": "264245", "nsentences": "1756.17", "wps": "237236", "ups": "0.9", "wpb": "264244", "bsz": "1756.2", "num_updates": "58200", "lr": "0.000464402", "gnorm": "0.276", "loss_scale": "2", "train_wall": "150", "gb_free": "39.7", "wall": "108349"}
[2024-10-06 00:19:43,857][train_inner][INFO] - {"epoch": 122, "update": 121.983, "loss": "0.879", "ntokens": "264174", "nsentences": "1728.3", "wps": "232324", "ups": "0.88", "wpb": "264174", "bsz": "1728.3", "num_updates": "58400", "lr": "0.00046413", "gnorm": "0.3", "loss_scale": "2", "train_wall": "150", "gb_free": "39.2", "wall": "108576"}
[2024-10-06 00:20:03,624][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-10-06 00:20:03,651][train][INFO] - {"epoch": 122, "train_loss": "0.876", "train_ntokens": "263532", "train_nsentences": "1753.71", "train_wps": "139990", "train_ups": "0.53", "train_wpb": "263532", "train_bsz": "1753.7", "train_num_updates": "58408", "train_lr": "0.00046412", "train_gnorm": "0.287", "train_loss_scale": "2", "train_train_wall": "376", "train_gb_free": "39.1", "train_wall": "108596"}
[2024-10-06 00:20:03,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 00:20:03,788][fairseq.trainer][INFO] - begin training epoch 123
[2024-10-06 00:20:03,788][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:29:04,697][train_inner][INFO] - {"epoch": 123, "update": 122.401, "loss": "0.875", "ntokens": "262914", "nsentences": "1760.17", "wps": "93766.1", "ups": "0.36", "wpb": "262914", "bsz": "1760.2", "num_updates": "58600", "lr": "0.000463859", "gnorm": "0.274", "loss_scale": "2", "train_wall": "206", "gb_free": "39.3", "wall": "109137"}
[2024-10-06 00:33:07,728][train_inner][INFO] - {"epoch": 123, "update": 122.818, "loss": "0.876", "ntokens": "263780", "nsentences": "1775.39", "wps": "217082", "ups": "0.82", "wpb": "263780", "bsz": "1775.4", "num_updates": "58800", "lr": "0.000463587", "gnorm": "0.296", "loss_scale": "2", "train_wall": "165", "gb_free": "39.8", "wall": "109380"}
[2024-10-06 00:34:44,884][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-10-06 00:34:44,899][train][INFO] - {"epoch": 123, "train_loss": "0.876", "train_ntokens": "263542", "train_nsentences": "1753.71", "train_wps": "143248", "train_ups": "0.54", "train_wpb": "263542", "train_bsz": "1753.7", "train_num_updates": "58887", "train_lr": "0.000463469", "train_gnorm": "0.285", "train_loss_scale": "2", "train_train_wall": "424", "train_gb_free": "39.8", "train_wall": "109477"}
[2024-10-06 00:34:45,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 00:34:45,051][fairseq.trainer][INFO] - begin training epoch 124
[2024-10-06 00:34:45,052][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:42:22,092][train_inner][INFO] - {"epoch": 124, "update": 123.236, "loss": "0.873", "ntokens": "263010", "nsentences": "1720.98", "wps": "94888.4", "ups": "0.36", "wpb": "263010", "bsz": "1721", "num_updates": "59000", "lr": "0.000463315", "gnorm": "0.282", "loss_scale": "2", "train_wall": "208", "gb_free": "39.6", "wall": "109934"}
[2024-10-06 00:46:29,566][train_inner][INFO] - {"epoch": 124, "update": 123.653, "loss": "0.876", "ntokens": "263816", "nsentences": "1795.82", "wps": "213217", "ups": "0.81", "wpb": "263816", "bsz": "1795.8", "num_updates": "59200", "lr": "0.000463043", "gnorm": "0.269", "loss_scale": "2", "train_wall": "242", "gb_free": "39.3", "wall": "110182"}
[2024-10-06 00:49:35,030][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-10-06 00:49:35,179][train][INFO] - {"epoch": 124, "train_loss": "0.875", "train_ntokens": "263601", "train_nsentences": "1753.71", "train_wps": "141832", "train_ups": "0.54", "train_wpb": "263601", "train_bsz": "1753.7", "train_num_updates": "59366", "train_lr": "0.000462818", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "559", "train_gb_free": "39.2", "train_wall": "110367"}
[2024-10-06 00:49:35,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 00:49:35,409][fairseq.trainer][INFO] - begin training epoch 125
[2024-10-06 00:49:35,410][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:55:54,036][train_inner][INFO] - {"epoch": 125, "update": 124.071, "loss": "0.876", "ntokens": "263294", "nsentences": "1711.08", "wps": "93290.1", "ups": "0.35", "wpb": "263294", "bsz": "1711.1", "num_updates": "59400", "lr": "0.000462772", "gnorm": "0.276", "loss_scale": "2", "train_wall": "227", "gb_free": "39.8", "wall": "110746"}
[2024-10-06 00:59:22,479][train_inner][INFO] - {"epoch": 125, "update": 124.489, "loss": "0.873", "ntokens": "263446", "nsentences": "1790.29", "wps": "252782", "ups": "0.96", "wpb": "263446", "bsz": "1790.3", "num_updates": "59600", "lr": "0.0004625", "gnorm": "0.289", "loss_scale": "2", "train_wall": "203", "gb_free": "39.3", "wall": "110955"}
[2024-10-06 01:03:31,572][train_inner][INFO] - {"epoch": 125, "update": 124.906, "loss": "0.876", "ntokens": "264284", "nsentences": "1734.78", "wps": "212212", "ups": "0.8", "wpb": "264284", "bsz": "1734.8", "num_updates": "59800", "lr": "0.000462228", "gnorm": "0.263", "loss_scale": "4", "train_wall": "244", "gb_free": "39.1", "wall": "111204"}
[2024-10-06 01:04:16,061][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-10-06 01:04:16,083][train][INFO] - {"epoch": 125, "train_loss": "0.874", "train_ntokens": "263447", "train_nsentences": "1753.71", "train_wps": "143254", "train_ups": "0.54", "train_wpb": "263447", "train_bsz": "1753.7", "train_num_updates": "59845", "train_lr": "0.000462167", "train_gnorm": "0.285", "train_loss_scale": "4", "train_train_wall": "537", "train_gb_free": "39.7", "train_wall": "111248"}
[2024-10-06 01:04:16,218][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 01:04:16,240][fairseq.trainer][INFO] - begin training epoch 126
[2024-10-06 01:04:16,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:12:51,989][train_inner][INFO] - {"epoch": 126, "update": 125.324, "loss": "0.872", "ntokens": "262921", "nsentences": "1740.24", "wps": "93834.1", "ups": "0.36", "wpb": "262921", "bsz": "1740.2", "num_updates": "60000", "lr": "0.000461957", "gnorm": "0.289", "loss_scale": "4", "train_wall": "212", "gb_free": "39.8", "wall": "111764"}
[2024-10-06 01:16:35,044][train_inner][INFO] - {"epoch": 126, "update": 125.741, "loss": "0.873", "ntokens": "264158", "nsentences": "1728.67", "wps": "236875", "ups": "0.9", "wpb": "264158", "bsz": "1728.7", "num_updates": "60200", "lr": "0.000461685", "gnorm": "0.274", "loss_scale": "4", "train_wall": "217", "gb_free": "39.6", "wall": "111987"}
[2024-10-06 01:18:45,408][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-10-06 01:18:45,444][train][INFO] - {"epoch": 126, "train_loss": "0.873", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "145173", "train_ups": "0.55", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "60324", "train_lr": "0.000461516", "train_gnorm": "0.272", "train_loss_scale": "4", "train_train_wall": "512", "train_gb_free": "39.4", "train_wall": "112118"}
[2024-10-06 01:18:45,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 01:18:45,734][fairseq.trainer][INFO] - begin training epoch 127
[2024-10-06 01:18:45,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:25:59,775][train_inner][INFO] - {"epoch": 127, "update": 126.159, "loss": "0.873", "ntokens": "262737", "nsentences": "1754.38", "wps": "93050.4", "ups": "0.35", "wpb": "262738", "bsz": "1754.4", "num_updates": "60400", "lr": "0.000461413", "gnorm": "0.277", "loss_scale": "4", "train_wall": "226", "gb_free": "39.6", "wall": "112552"}
[2024-10-06 01:29:34,735][train_inner][INFO] - {"epoch": 127, "update": 126.576, "loss": "0.87", "ntokens": "264157", "nsentences": "1731.7", "wps": "245783", "ups": "0.93", "wpb": "264157", "bsz": "1731.7", "num_updates": "60600", "lr": "0.000461141", "gnorm": "0.289", "loss_scale": "4", "train_wall": "210", "gb_free": "39.3", "wall": "112767"}
[2024-10-06 01:33:17,214][train_inner][INFO] - {"epoch": 127, "update": 126.994, "loss": "0.877", "ntokens": "263637", "nsentences": "1801.88", "wps": "237046", "ups": "0.9", "wpb": "263637", "bsz": "1801.9", "num_updates": "60800", "lr": "0.00046087", "gnorm": "0.278", "loss_scale": "4", "train_wall": "217", "gb_free": "39.2", "wall": "112989"}
[2024-10-06 01:33:23,122][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-10-06 01:33:23,160][train][INFO] - {"epoch": 127, "train_loss": "0.873", "train_ntokens": "263489", "train_nsentences": "1753.71", "train_wps": "143797", "train_ups": "0.55", "train_wpb": "263490", "train_bsz": "1753.7", "train_num_updates": "60803", "train_lr": "0.000460865", "train_gnorm": "0.284", "train_loss_scale": "4", "train_train_wall": "532", "train_gb_free": "39.7", "train_wall": "112995"}
[2024-10-06 01:33:23,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 01:33:23,319][fairseq.trainer][INFO] - begin training epoch 128
[2024-10-06 01:33:23,319][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:42:56,370][train_inner][INFO] - {"epoch": 128, "update": 127.411, "loss": "0.869", "ntokens": "262736", "nsentences": "1744.18", "wps": "90734.7", "ups": "0.35", "wpb": "262736", "bsz": "1744.2", "num_updates": "61000", "lr": "0.000460598", "gnorm": "0.283", "loss_scale": "4", "train_wall": "232", "gb_free": "39.7", "wall": "113569"}
[2024-10-06 01:46:58,455][train_inner][INFO] - {"epoch": 128, "update": 127.829, "loss": "0.873", "ntokens": "263793", "nsentences": "1752.79", "wps": "217944", "ups": "0.83", "wpb": "263793", "bsz": "1752.8", "num_updates": "61200", "lr": "0.000460326", "gnorm": "0.28", "loss_scale": "4", "train_wall": "237", "gb_free": "39.6", "wall": "113811"}
[2024-10-06 01:48:45,291][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-10-06 01:48:45,310][train][INFO] - {"epoch": 128, "train_loss": "0.871", "train_ntokens": "263310", "train_nsentences": "1753.71", "train_wps": "136775", "train_ups": "0.52", "train_wpb": "263310", "train_bsz": "1753.7", "train_num_updates": "61282", "train_lr": "0.000460215", "train_gnorm": "0.278", "train_loss_scale": "4", "train_train_wall": "568", "train_gb_free": "39.6", "train_wall": "113917"}
[2024-10-06 01:48:45,469][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 01:48:45,491][fairseq.trainer][INFO] - begin training epoch 129
[2024-10-06 01:48:45,491][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:56:37,129][train_inner][INFO] - {"epoch": 129, "update": 128.246, "loss": "0.87", "ntokens": "262713", "nsentences": "1753.19", "wps": "90802.2", "ups": "0.35", "wpb": "262713", "bsz": "1753.2", "num_updates": "61400", "lr": "0.000460054", "gnorm": "0.271", "loss_scale": "4", "train_wall": "261", "gb_free": "39.6", "wall": "114389"}
[2024-10-06 02:00:28,608][train_inner][INFO] - {"epoch": 129, "update": 128.664, "loss": "0.871", "ntokens": "264356", "nsentences": "1719.19", "wps": "228430", "ups": "0.86", "wpb": "264356", "bsz": "1719.2", "num_updates": "61600", "lr": "0.000459783", "gnorm": "0.268", "loss_scale": "4", "train_wall": "227", "gb_free": "39.6", "wall": "114621"}
[2024-10-06 02:02:18,969][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-06 02:03:48,730][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-10-06 02:03:48,746][train][INFO] - {"epoch": 129, "train_loss": "0.871", "train_ntokens": "263538", "train_nsentences": "1753.72", "train_wps": "139436", "train_ups": "0.53", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "61760", "train_lr": "0.000459565", "train_gnorm": "0.276", "train_loss_scale": "4", "train_train_wall": "578", "train_gb_free": "39.8", "train_wall": "114821"}
[2024-10-06 02:03:48,895][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 02:03:48,931][fairseq.trainer][INFO] - begin training epoch 130
[2024-10-06 02:03:48,932][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:10:14,169][train_inner][INFO] - {"epoch": 130, "update": 129.084, "loss": "0.873", "ntokens": "262639", "nsentences": "1774.13", "wps": "89706.1", "ups": "0.34", "wpb": "262639", "bsz": "1774.1", "num_updates": "61800", "lr": "0.000459511", "gnorm": "0.291", "loss_scale": "4", "train_wall": "255", "gb_free": "40.1", "wall": "115206"}
[2024-10-06 02:13:44,452][train_inner][INFO] - {"epoch": 130, "update": 129.501, "loss": "0.868", "ntokens": "263717", "nsentences": "1782.06", "wps": "250829", "ups": "0.95", "wpb": "263718", "bsz": "1782.1", "num_updates": "62000", "lr": "0.000459239", "gnorm": "0.275", "loss_scale": "4", "train_wall": "205", "gb_free": "39.3", "wall": "115417"}
[2024-10-06 02:17:51,854][train_inner][INFO] - {"epoch": 130, "update": 129.919, "loss": "0.873", "ntokens": "264095", "nsentences": "1759.57", "wps": "213500", "ups": "0.81", "wpb": "264095", "bsz": "1759.6", "num_updates": "62200", "lr": "0.000458967", "gnorm": "0.274", "loss_scale": "4", "train_wall": "243", "gb_free": "39.7", "wall": "115664"}
[2024-10-06 02:18:39,566][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 62239 updates
[2024-10-06 02:18:39,567][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 02:18:48,640][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 02:18:48,725][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 130 @ 62239 updates, score None) (writing took 9.158932832069695 seconds)
[2024-10-06 02:18:48,726][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-10-06 02:18:48,730][train][INFO] - {"epoch": 130, "train_loss": "0.87", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "140262", "train_ups": "0.53", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "62239", "train_lr": "0.000458914", "train_gnorm": "0.278", "train_loss_scale": "4", "train_train_wall": "553", "train_gb_free": "39.3", "train_wall": "115721"}
[2024-10-06 02:18:48,787][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 02:18:48,800][fairseq.trainer][INFO] - begin training epoch 131
[2024-10-06 02:18:48,801][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:27:17,085][train_inner][INFO] - {"epoch": 131, "update": 130.336, "loss": "0.868", "ntokens": "262907", "nsentences": "1724.21", "wps": "93029.3", "ups": "0.35", "wpb": "262907", "bsz": "1724.2", "num_updates": "62400", "lr": "0.000458696", "gnorm": "0.275", "loss_scale": "4", "train_wall": "216", "gb_free": "39.6", "wall": "116229"}
[2024-10-06 02:31:19,699][train_inner][INFO] - {"epoch": 131, "update": 130.754, "loss": "0.87", "ntokens": "263767", "nsentences": "1780.51", "wps": "217445", "ups": "0.82", "wpb": "263767", "bsz": "1780.5", "num_updates": "62600", "lr": "0.000458424", "gnorm": "0.282", "loss_scale": "4", "train_wall": "157", "gb_free": "40", "wall": "116472"}
[2024-10-06 02:33:55,290][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-10-06 02:33:55,310][train][INFO] - {"epoch": 131, "train_loss": "0.869", "train_ntokens": "263445", "train_nsentences": "1753.71", "train_wps": "139195", "train_ups": "0.53", "train_wpb": "263445", "train_bsz": "1753.7", "train_num_updates": "62718", "train_lr": "0.000458264", "train_gnorm": "0.274", "train_loss_scale": "4", "train_train_wall": "420", "train_gb_free": "39.6", "train_wall": "116627"}
[2024-10-06 02:33:55,386][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 02:33:55,418][fairseq.trainer][INFO] - begin training epoch 132
[2024-10-06 02:33:55,418][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:40:07,408][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 02:40:57,311][train_inner][INFO] - {"epoch": 132, "update": 131.173, "loss": "0.87", "ntokens": "263195", "nsentences": "1728.69", "wps": "91133.6", "ups": "0.35", "wpb": "263195", "bsz": "1728.7", "num_updates": "62800", "lr": "0.000458152", "gnorm": "0.278", "loss_scale": "2", "train_wall": "190", "gb_free": "39.6", "wall": "117049"}
[2024-10-06 02:44:23,994][train_inner][INFO] - {"epoch": 132, "update": 131.591, "loss": "0.869", "ntokens": "264142", "nsentences": "1753.08", "wps": "255615", "ups": "0.97", "wpb": "264142", "bsz": "1753.1", "num_updates": "63000", "lr": "0.00045788", "gnorm": "0.279", "loss_scale": "2", "train_wall": "201", "gb_free": "39.6", "wall": "117256"}
[2024-10-06 02:48:44,176][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-10-06 02:48:44,209][train][INFO] - {"epoch": 132, "train_loss": "0.87", "train_ntokens": "263659", "train_nsentences": "1754.45", "train_wps": "141782", "train_ups": "0.54", "train_wpb": "263659", "train_bsz": "1754.4", "train_num_updates": "63196", "train_lr": "0.000457614", "train_gnorm": "0.286", "train_loss_scale": "2", "train_train_wall": "504", "train_gb_free": "39.6", "train_wall": "117516"}
[2024-10-06 02:48:44,364][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 02:48:44,382][fairseq.trainer][INFO] - begin training epoch 133
[2024-10-06 02:48:44,383][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:54:20,137][train_inner][INFO] - {"epoch": 133, "update": 132.008, "loss": "0.871", "ntokens": "262786", "nsentences": "1764.35", "wps": "88165.1", "ups": "0.34", "wpb": "262786", "bsz": "1764.4", "num_updates": "63200", "lr": "0.000457609", "gnorm": "0.29", "loss_scale": "2", "train_wall": "219", "gb_free": "39.8", "wall": "117852"}
[2024-10-06 02:58:00,292][train_inner][INFO] - {"epoch": 133, "update": 132.426, "loss": "0.867", "ntokens": "263533", "nsentences": "1799.24", "wps": "239417", "ups": "0.91", "wpb": "263533", "bsz": "1799.2", "num_updates": "63400", "lr": "0.000457337", "gnorm": "0.27", "loss_scale": "2", "train_wall": "202", "gb_free": "40", "wall": "118072"}
[2024-10-06 03:01:39,075][train_inner][INFO] - {"epoch": 133, "update": 132.843, "loss": "0.87", "ntokens": "264325", "nsentences": "1732.63", "wps": "241641", "ups": "0.91", "wpb": "264325", "bsz": "1732.6", "num_updates": "63600", "lr": "0.000457065", "gnorm": "0.271", "loss_scale": "2", "train_wall": "164", "gb_free": "39.3", "wall": "118291"}
[2024-10-06 03:03:22,215][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-10-06 03:03:22,220][train][INFO] - {"epoch": 133, "train_loss": "0.868", "train_ntokens": "263548", "train_nsentences": "1753.71", "train_wps": "143780", "train_ups": "0.55", "train_wpb": "263548", "train_bsz": "1753.7", "train_num_updates": "63675", "train_lr": "0.000456963", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "450", "train_gb_free": "40", "train_wall": "118394"}
[2024-10-06 03:03:22,325][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 03:03:22,341][fairseq.trainer][INFO] - begin training epoch 134
[2024-10-06 03:03:22,342][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:11:03,378][train_inner][INFO] - {"epoch": 134, "update": 133.261, "loss": "0.866", "ntokens": "263110", "nsentences": "1728.38", "wps": "93254.6", "ups": "0.35", "wpb": "263110", "bsz": "1728.4", "num_updates": "63800", "lr": "0.000456793", "gnorm": "0.272", "loss_scale": "2", "train_wall": "210", "gb_free": "39.8", "wall": "118856"}
[2024-10-06 03:14:55,549][train_inner][INFO] - {"epoch": 134, "update": 133.678, "loss": "0.869", "ntokens": "263827", "nsentences": "1776.79", "wps": "227277", "ups": "0.86", "wpb": "263827", "bsz": "1776.8", "num_updates": "64000", "lr": "0.000456522", "gnorm": "0.268", "loss_scale": "2", "train_wall": "227", "gb_free": "39.6", "wall": "119088"}
[2024-10-06 03:17:57,036][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-10-06 03:17:57,058][train][INFO] - {"epoch": 134, "train_loss": "0.868", "train_ntokens": "263478", "train_nsentences": "1753.71", "train_wps": "144263", "train_ups": "0.55", "train_wpb": "263478", "train_bsz": "1753.7", "train_num_updates": "64154", "train_lr": "0.000456313", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "540", "train_gb_free": "40.5", "train_wall": "119269"}
[2024-10-06 03:17:57,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 03:17:57,174][fairseq.trainer][INFO] - begin training epoch 135
[2024-10-06 03:17:57,175][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:24:34,546][train_inner][INFO] - {"epoch": 135, "update": 134.096, "loss": "0.868", "ntokens": "262995", "nsentences": "1720.78", "wps": "90846.5", "ups": "0.35", "wpb": "262995", "bsz": "1720.8", "num_updates": "64200", "lr": "0.00045625", "gnorm": "0.289", "loss_scale": "2", "train_wall": "246", "gb_free": "39.6", "wall": "119667"}
[2024-10-06 03:28:00,550][train_inner][INFO] - {"epoch": 135, "update": 134.514, "loss": "0.865", "ntokens": "263861", "nsentences": "1748.8", "wps": "256185", "ups": "0.97", "wpb": "263861", "bsz": "1748.8", "num_updates": "64400", "lr": "0.000455978", "gnorm": "0.258", "loss_scale": "2", "train_wall": "200", "gb_free": "39.6", "wall": "119873"}
[2024-10-06 03:31:58,740][train_inner][INFO] - {"epoch": 135, "update": 134.931, "loss": "0.867", "ntokens": "264108", "nsentences": "1751.23", "wps": "221770", "ups": "0.84", "wpb": "264108", "bsz": "1751.2", "num_updates": "64600", "lr": "0.000455707", "gnorm": "0.266", "loss_scale": "2", "train_wall": "232", "gb_free": "40.5", "wall": "120111"}
[2024-10-06 03:32:49,721][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-10-06 03:32:49,759][train][INFO] - {"epoch": 135, "train_loss": "0.866", "train_ntokens": "263476", "train_nsentences": "1753.71", "train_wps": "141381", "train_ups": "0.54", "train_wpb": "263476", "train_bsz": "1753.7", "train_num_updates": "64633", "train_lr": "0.000455662", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "39.7", "train_wall": "120162"}
[2024-10-06 03:32:49,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 03:32:49,968][fairseq.trainer][INFO] - begin training epoch 136
[2024-10-06 03:32:49,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:41:14,360][train_inner][INFO] - {"epoch": 136, "update": 135.349, "loss": "0.865", "ntokens": "262495", "nsentences": "1789.12", "wps": "94489.5", "ups": "0.36", "wpb": "262495", "bsz": "1789.1", "num_updates": "64800", "lr": "0.000455435", "gnorm": "0.275", "loss_scale": "2", "train_wall": "220", "gb_free": "39.6", "wall": "120667"}
[2024-10-06 03:45:14,674][train_inner][INFO] - {"epoch": 136, "update": 135.766, "loss": "0.869", "ntokens": "264032", "nsentences": "1763.11", "wps": "219777", "ups": "0.83", "wpb": "264032", "bsz": "1763.1", "num_updates": "65000", "lr": "0.000455163", "gnorm": "0.282", "loss_scale": "4", "train_wall": "235", "gb_free": "39.2", "wall": "120907"}
[2024-10-06 03:47:38,183][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-10-06 03:47:38,224][train][INFO] - {"epoch": 136, "train_loss": "0.866", "train_ntokens": "263524", "train_nsentences": "1753.71", "train_wps": "142075", "train_ups": "0.54", "train_wpb": "263524", "train_bsz": "1753.7", "train_num_updates": "65112", "train_lr": "0.000455011", "train_gnorm": "0.276", "train_loss_scale": "4", "train_train_wall": "544", "train_gb_free": "40", "train_wall": "121050"}
[2024-10-06 03:47:38,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 03:47:38,411][fairseq.trainer][INFO] - begin training epoch 137
[2024-10-06 03:47:38,411][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:54:51,858][train_inner][INFO] - {"epoch": 137, "update": 136.184, "loss": "0.866", "ntokens": "262879", "nsentences": "1745.28", "wps": "91091.6", "ups": "0.35", "wpb": "262879", "bsz": "1745.3", "num_updates": "65200", "lr": "0.000454891", "gnorm": "0.262", "loss_scale": "4", "train_wall": "211", "gb_free": "39.6", "wall": "121484"}
[2024-10-06 03:58:28,897][train_inner][INFO] - {"epoch": 137, "update": 136.601, "loss": "0.864", "ntokens": "263904", "nsentences": "1756.76", "wps": "243196", "ups": "0.92", "wpb": "263904", "bsz": "1756.8", "num_updates": "65400", "lr": "0.00045462", "gnorm": "0.264", "loss_scale": "4", "train_wall": "136", "gb_free": "39.6", "wall": "121701"}
[2024-10-06 04:02:20,971][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-10-06 04:02:20,988][train][INFO] - {"epoch": 137, "train_loss": "0.866", "train_ntokens": "263427", "train_nsentences": "1753.71", "train_wps": "142940", "train_ups": "0.54", "train_wpb": "263427", "train_bsz": "1753.7", "train_num_updates": "65591", "train_lr": "0.00045436", "train_gnorm": "0.274", "train_loss_scale": "4", "train_train_wall": "355", "train_gb_free": "39.8", "train_wall": "121933"}
[2024-10-06 04:02:21,056][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 04:02:21,084][fairseq.trainer][INFO] - begin training epoch 138
[2024-10-06 04:02:21,085][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:08:09,406][train_inner][INFO] - {"epoch": 138, "update": 137.019, "loss": "0.868", "ntokens": "262841", "nsentences": "1728.36", "wps": "90558.2", "ups": "0.34", "wpb": "262841", "bsz": "1728.4", "num_updates": "65600", "lr": "0.000454348", "gnorm": "0.296", "loss_scale": "4", "train_wall": "168", "gb_free": "39.8", "wall": "122282"}
[2024-10-06 04:11:36,960][train_inner][INFO] - {"epoch": 138, "update": 137.436, "loss": "0.863", "ntokens": "264228", "nsentences": "1733.01", "wps": "254622", "ups": "0.96", "wpb": "264228", "bsz": "1733", "num_updates": "65800", "lr": "0.000454076", "gnorm": "0.267", "loss_scale": "4", "train_wall": "187", "gb_free": "39.2", "wall": "122489"}
[2024-10-06 04:15:31,693][train_inner][INFO] - {"epoch": 138, "update": 137.854, "loss": "0.868", "ntokens": "263845", "nsentences": "1789.83", "wps": "224827", "ups": "0.85", "wpb": "263845", "bsz": "1789.8", "num_updates": "66000", "lr": "0.000453804", "gnorm": "0.261", "loss_scale": "4", "train_wall": "229", "gb_free": "41", "wall": "122724"}
[2024-10-06 04:16:07,116][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 04:17:06,607][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-10-06 04:17:06,611][train][INFO] - {"epoch": 138, "train_loss": "0.865", "train_ntokens": "263506", "train_nsentences": "1755.34", "train_wps": "142223", "train_ups": "0.54", "train_wpb": "263506", "train_bsz": "1755.3", "train_num_updates": "66069", "train_lr": "0.000453711", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "529", "train_gb_free": "39.8", "train_wall": "122819"}
[2024-10-06 04:17:06,712][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 04:17:06,740][fairseq.trainer][INFO] - begin training epoch 139
[2024-10-06 04:17:06,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:24:58,320][train_inner][INFO] - {"epoch": 139, "update": 138.273, "loss": "0.862", "ntokens": "263043", "nsentences": "1715.8", "wps": "92849.7", "ups": "0.35", "wpb": "263043", "bsz": "1715.8", "num_updates": "66200", "lr": "0.000453533", "gnorm": "0.274", "loss_scale": "2", "train_wall": "244", "gb_free": "40", "wall": "123290"}
[2024-10-06 04:29:07,127][train_inner][INFO] - {"epoch": 139, "update": 138.691, "loss": "0.865", "ntokens": "264003", "nsentences": "1768.15", "wps": "212221", "ups": "0.8", "wpb": "264003", "bsz": "1768.2", "num_updates": "66400", "lr": "0.000453261", "gnorm": "0.275", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "123539"}
[2024-10-06 04:32:04,371][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-10-06 04:32:04,393][train][INFO] - {"epoch": 139, "train_loss": "0.864", "train_ntokens": "263668", "train_nsentences": "1753.71", "train_wps": "140678", "train_ups": "0.53", "train_wpb": "263668", "train_bsz": "1753.7", "train_num_updates": "66548", "train_lr": "0.00045306", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "567", "train_gb_free": "39.6", "train_wall": "123717"}
[2024-10-06 04:32:04,446][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 04:32:04,464][fairseq.trainer][INFO] - begin training epoch 140
[2024-10-06 04:32:04,464][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:38:58,338][train_inner][INFO] - {"epoch": 140, "update": 139.109, "loss": "0.867", "ntokens": "262699", "nsentences": "1794.42", "wps": "88869.4", "ups": "0.34", "wpb": "262699", "bsz": "1794.4", "num_updates": "66600", "lr": "0.000452989", "gnorm": "0.277", "loss_scale": "2", "train_wall": "257", "gb_free": "41", "wall": "124131"}
[2024-10-06 04:42:20,672][train_inner][INFO] - {"epoch": 140, "update": 139.526, "loss": "0.862", "ntokens": "264409", "nsentences": "1715.55", "wps": "261400", "ups": "0.99", "wpb": "264409", "bsz": "1715.5", "num_updates": "66800", "lr": "0.000452717", "gnorm": "0.266", "loss_scale": "2", "train_wall": "197", "gb_free": "40", "wall": "124333"}
[2024-10-06 04:46:25,900][train_inner][INFO] - {"epoch": 140, "update": 139.944, "loss": "0.867", "ntokens": "263697", "nsentences": "1786.34", "wps": "215072", "ups": "0.82", "wpb": "263697", "bsz": "1786.3", "num_updates": "67000", "lr": "0.000452446", "gnorm": "0.29", "loss_scale": "2", "train_wall": "240", "gb_free": "39.3", "wall": "124578"}
[2024-10-06 04:47:01,744][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 67027 updates
[2024-10-06 04:47:01,745][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 04:47:18,226][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 04:47:18,442][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 140 @ 67027 updates, score None) (writing took 16.6977875540033 seconds)
[2024-10-06 04:47:18,443][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-10-06 04:47:18,458][train][INFO] - {"epoch": 140, "train_loss": "0.864", "train_ntokens": "263467", "train_nsentences": "1753.71", "train_wps": "138068", "train_ups": "0.52", "train_wpb": "263467", "train_bsz": "1753.7", "train_num_updates": "67027", "train_lr": "0.000452409", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "40", "train_wall": "124631"}
[2024-10-06 04:47:18,530][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 04:47:18,549][fairseq.trainer][INFO] - begin training epoch 141
[2024-10-06 04:47:18,550][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:55:42,142][train_inner][INFO] - {"epoch": 141, "update": 140.361, "loss": "0.86", "ntokens": "263065", "nsentences": "1730.41", "wps": "94587.3", "ups": "0.36", "wpb": "263065", "bsz": "1730.4", "num_updates": "67200", "lr": "0.000452174", "gnorm": "0.276", "loss_scale": "2", "train_wall": "221", "gb_free": "39.3", "wall": "125134"}
[2024-10-06 04:59:54,587][train_inner][INFO] - {"epoch": 141, "update": 140.779, "loss": "0.865", "ntokens": "263841", "nsentences": "1760.91", "wps": "209034", "ups": "0.79", "wpb": "263841", "bsz": "1760.9", "num_updates": "67400", "lr": "0.000451902", "gnorm": "0.268", "loss_scale": "2", "train_wall": "248", "gb_free": "40.2", "wall": "125387"}
[2024-10-06 05:02:08,127][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-10-06 05:02:08,140][train][INFO] - {"epoch": 141, "train_loss": "0.863", "train_ntokens": "263527", "train_nsentences": "1753.71", "train_wps": "141882", "train_ups": "0.54", "train_wpb": "263527", "train_bsz": "1753.7", "train_num_updates": "67506", "train_lr": "0.000451758", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "565", "train_gb_free": "40.1", "train_wall": "125520"}
[2024-10-06 05:02:08,320][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 05:02:08,326][fairseq.trainer][INFO] - begin training epoch 142
[2024-10-06 05:02:08,326][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:09:22,038][train_inner][INFO] - {"epoch": 142, "update": 141.196, "loss": "0.861", "ntokens": "262773", "nsentences": "1735.65", "wps": "92618.5", "ups": "0.35", "wpb": "262773", "bsz": "1735.7", "num_updates": "67600", "lr": "0.00045163", "gnorm": "0.269", "loss_scale": "2", "train_wall": "243", "gb_free": "39.3", "wall": "125954"}
[2024-10-06 05:13:06,793][train_inner][INFO] - {"epoch": 142, "update": 141.614, "loss": "0.864", "ntokens": "263438", "nsentences": "1793.78", "wps": "234428", "ups": "0.89", "wpb": "263438", "bsz": "1793.8", "num_updates": "67800", "lr": "0.000451359", "gnorm": "0.271", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "126179"}
[2024-10-06 05:16:55,901][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-10-06 05:16:55,920][train][INFO] - {"epoch": 142, "train_loss": "0.862", "train_ntokens": "263365", "train_nsentences": "1753.71", "train_wps": "142099", "train_ups": "0.54", "train_wpb": "263365", "train_bsz": "1753.7", "train_num_updates": "67985", "train_lr": "0.000451107", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "40.1", "train_wall": "126408"}
[2024-10-06 05:16:56,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 05:16:56,104][fairseq.trainer][INFO] - begin training epoch 143
[2024-10-06 05:16:56,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:23:01,339][train_inner][INFO] - {"epoch": 143, "update": 142.031, "loss": "0.863", "ntokens": "263164", "nsentences": "1718.18", "wps": "88526.7", "ups": "0.34", "wpb": "263164", "bsz": "1718.2", "num_updates": "68000", "lr": "0.000451087", "gnorm": "0.284", "loss_scale": "2", "train_wall": "274", "gb_free": "39.6", "wall": "126774"}
[2024-10-06 05:26:37,269][train_inner][INFO] - {"epoch": 143, "update": 142.449, "loss": "0.863", "ntokens": "263653", "nsentences": "1809.42", "wps": "244210", "ups": "0.93", "wpb": "263653", "bsz": "1809.4", "num_updates": "68200", "lr": "0.000450815", "gnorm": "0.257", "loss_scale": "4", "train_wall": "210", "gb_free": "39.4", "wall": "126989"}
[2024-10-06 05:30:41,035][train_inner][INFO] - {"epoch": 143, "update": 142.866, "loss": "0.861", "ntokens": "264163", "nsentences": "1727.51", "wps": "216742", "ups": "0.82", "wpb": "264163", "bsz": "1727.5", "num_updates": "68400", "lr": "0.000450543", "gnorm": "0.276", "loss_scale": "4", "train_wall": "238", "gb_free": "39.3", "wall": "127233"}
[2024-10-06 05:32:05,081][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-10-06 05:32:05,106][train][INFO] - {"epoch": 143, "train_loss": "0.862", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "138836", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "68464", "train_lr": "0.000450457", "train_gnorm": "0.27", "train_loss_scale": "4", "train_train_wall": "583", "train_gb_free": "40.5", "train_wall": "127317"}
[2024-10-06 05:32:05,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 05:32:05,298][fairseq.trainer][INFO] - begin training epoch 144
[2024-10-06 05:32:05,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:40:03,016][train_inner][INFO] - {"epoch": 144, "update": 143.284, "loss": "0.859", "ntokens": "262957", "nsentences": "1718.77", "wps": "93589.2", "ups": "0.36", "wpb": "262957", "bsz": "1718.8", "num_updates": "68600", "lr": "0.000450272", "gnorm": "0.258", "loss_scale": "4", "train_wall": "249", "gb_free": "40.2", "wall": "127795"}
[2024-10-06 05:43:58,208][train_inner][INFO] - {"epoch": 144, "update": 143.701, "loss": "0.863", "ntokens": "264107", "nsentences": "1749.86", "wps": "224594", "ups": "0.85", "wpb": "264107", "bsz": "1749.9", "num_updates": "68800", "lr": "0.00045", "gnorm": "0.271", "loss_scale": "4", "train_wall": "230", "gb_free": "39.7", "wall": "128030"}
[2024-10-06 05:46:56,074][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-10-06 05:46:56,078][train][INFO] - {"epoch": 144, "train_loss": "0.862", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "141669", "train_ups": "0.54", "train_wpb": "263509", "train_bsz": "1753.7", "train_num_updates": "68943", "train_lr": "0.000449806", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "569", "train_gb_free": "39.8", "train_wall": "128208"}
[2024-10-06 05:46:56,130][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 05:46:56,149][fairseq.trainer][INFO] - begin training epoch 145
[2024-10-06 05:46:56,150][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:53:32,063][train_inner][INFO] - {"epoch": 145, "update": 144.119, "loss": "0.863", "ntokens": "262826", "nsentences": "1762.7", "wps": "91601", "ups": "0.35", "wpb": "262826", "bsz": "1762.7", "num_updates": "69000", "lr": "0.000449728", "gnorm": "0.287", "loss_scale": "4", "train_wall": "250", "gb_free": "39.6", "wall": "128604"}
[2024-10-06 05:56:55,005][train_inner][INFO] - {"epoch": 145, "update": 144.537, "loss": "0.86", "ntokens": "264185", "nsentences": "1725.99", "wps": "260363", "ups": "0.99", "wpb": "264185", "bsz": "1726", "num_updates": "69200", "lr": "0.000449457", "gnorm": "0.266", "loss_scale": "4", "train_wall": "198", "gb_free": "40.6", "wall": "128807"}
[2024-10-06 06:00:47,434][train_inner][INFO] - {"epoch": 145, "update": 144.954, "loss": "0.865", "ntokens": "263508", "nsentences": "1811.15", "wps": "226751", "ups": "0.86", "wpb": "263508", "bsz": "1811.2", "num_updates": "69400", "lr": "0.000449185", "gnorm": "0.281", "loss_scale": "4", "train_wall": "227", "gb_free": "39.8", "wall": "129040"}
[2024-10-06 06:01:26,750][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-10-06 06:01:26,773][train][INFO] - {"epoch": 145, "train_loss": "0.861", "train_ntokens": "263500", "train_nsentences": "1753.71", "train_wps": "144962", "train_ups": "0.55", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "69422", "train_lr": "0.000449155", "train_gnorm": "0.275", "train_loss_scale": "4", "train_train_wall": "536", "train_gb_free": "39.2", "train_wall": "129079"}
[2024-10-06 06:01:26,904][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 06:01:26,923][fairseq.trainer][INFO] - begin training epoch 146
[2024-10-06 06:01:26,924][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:10:04,443][train_inner][INFO] - {"epoch": 146, "update": 145.372, "loss": "0.859", "ntokens": "263173", "nsentences": "1731.38", "wps": "94500.7", "ups": "0.36", "wpb": "263173", "bsz": "1731.4", "num_updates": "69600", "lr": "0.000448913", "gnorm": "0.277", "loss_scale": "4", "train_wall": "240", "gb_free": "39.7", "wall": "129597"}
[2024-10-06 06:14:16,216][train_inner][INFO] - {"epoch": 146, "update": 145.789, "loss": "0.862", "ntokens": "263953", "nsentences": "1767.09", "wps": "209683", "ups": "0.79", "wpb": "263953", "bsz": "1767.1", "num_updates": "69800", "lr": "0.000448641", "gnorm": "0.277", "loss_scale": "4", "train_wall": "246", "gb_free": "39.2", "wall": "129848"}
[2024-10-06 06:16:29,764][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-10-06 06:16:29,769][train][INFO] - {"epoch": 146, "train_loss": "0.861", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "139808", "train_ups": "0.53", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "69901", "train_lr": "0.000448504", "train_gnorm": "0.279", "train_loss_scale": "4", "train_train_wall": "582", "train_gb_free": "39.6", "train_wall": "129982"}
[2024-10-06 06:16:29,860][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 06:16:29,899][fairseq.trainer][INFO] - begin training epoch 147
[2024-10-06 06:16:29,900][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:23:42,955][train_inner][INFO] - {"epoch": 147, "update": 146.207, "loss": "0.861", "ntokens": "262958", "nsentences": "1734.45", "wps": "92798", "ups": "0.35", "wpb": "262958", "bsz": "1734.5", "num_updates": "70000", "lr": "0.00044837", "gnorm": "0.285", "loss_scale": "4", "train_wall": "256", "gb_free": "40", "wall": "130415"}
[2024-10-06 06:26:38,244][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-06 06:27:34,470][train_inner][INFO] - {"epoch": 147, "update": 146.626, "loss": "0.861", "ntokens": "263685", "nsentences": "1797.66", "wps": "227798", "ups": "0.86", "wpb": "263686", "bsz": "1797.7", "num_updates": "70200", "lr": "0.000448098", "gnorm": "0.27", "loss_scale": "4", "train_wall": "227", "gb_free": "40.5", "wall": "130647"}
[2024-10-06 06:31:34,091][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-10-06 06:31:34,128][train][INFO] - {"epoch": 147, "train_loss": "0.861", "train_ntokens": "263571", "train_nsentences": "1754.44", "train_wps": "139314", "train_ups": "0.53", "train_wpb": "263571", "train_bsz": "1754.4", "train_num_updates": "70379", "train_lr": "0.000447855", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "587", "train_gb_free": "39.6", "train_wall": "130886"}
[2024-10-06 06:31:34,318][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 06:31:34,363][fairseq.trainer][INFO] - begin training epoch 148
[2024-10-06 06:31:34,364][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:37:30,921][train_inner][INFO] - {"epoch": 148, "update": 147.044, "loss": "0.861", "ntokens": "263060", "nsentences": "1725.75", "wps": "88210.8", "ups": "0.34", "wpb": "263060", "bsz": "1725.8", "num_updates": "70400", "lr": "0.000447826", "gnorm": "0.272", "loss_scale": "4", "train_wall": "259", "gb_free": "39.1", "wall": "131243"}
[2024-10-06 06:41:14,990][train_inner][INFO] - {"epoch": 148, "update": 147.461, "loss": "0.859", "ntokens": "264023", "nsentences": "1743.2", "wps": "235673", "ups": "0.89", "wpb": "264023", "bsz": "1743.2", "num_updates": "70600", "lr": "0.000447554", "gnorm": "0.278", "loss_scale": "4", "train_wall": "162", "gb_free": "40.3", "wall": "131467"}
[2024-10-06 06:45:10,993][train_inner][INFO] - {"epoch": 148, "update": 147.879, "loss": "0.861", "ntokens": "263896", "nsentences": "1789.49", "wps": "223644", "ups": "0.85", "wpb": "263896", "bsz": "1789.5", "num_updates": "70800", "lr": "0.000447283", "gnorm": "0.271", "loss_scale": "4", "train_wall": "170", "gb_free": "39.6", "wall": "131703"}
[2024-10-06 06:46:18,319][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-10-06 06:46:18,343][train][INFO] - {"epoch": 148, "train_loss": "0.86", "train_ntokens": "263528", "train_nsentences": "1753.71", "train_wps": "142760", "train_ups": "0.54", "train_wpb": "263528", "train_bsz": "1753.7", "train_num_updates": "70858", "train_lr": "0.000447204", "train_gnorm": "0.273", "train_loss_scale": "4", "train_train_wall": "386", "train_gb_free": "39.2", "train_wall": "131771"}
[2024-10-06 06:46:18,759][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 06:46:18,815][fairseq.trainer][INFO] - begin training epoch 149
[2024-10-06 06:46:18,816][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:54:34,115][train_inner][INFO] - {"epoch": 149, "update": 148.296, "loss": "0.858", "ntokens": "262890", "nsentences": "1750.19", "wps": "93369.6", "ups": "0.36", "wpb": "262890", "bsz": "1750.2", "num_updates": "71000", "lr": "0.000447011", "gnorm": "0.26", "loss_scale": "4", "train_wall": "197", "gb_free": "39.6", "wall": "132266"}
[2024-10-06 06:58:30,946][train_inner][INFO] - {"epoch": 149, "update": 148.714, "loss": "0.859", "ntokens": "264226", "nsentences": "1737.52", "wps": "223164", "ups": "0.84", "wpb": "264226", "bsz": "1737.5", "num_updates": "71200", "lr": "0.000446739", "gnorm": "0.262", "loss_scale": "4", "train_wall": "230", "gb_free": "39.6", "wall": "132503"}
[2024-10-06 07:01:19,655][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-10-06 07:01:19,726][train][INFO] - {"epoch": 149, "train_loss": "0.859", "train_ntokens": "263623", "train_nsentences": "1753.71", "train_wps": "140094", "train_ups": "0.53", "train_wpb": "263623", "train_bsz": "1753.7", "train_num_updates": "71337", "train_lr": "0.000446553", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "40.1", "train_wall": "132672"}
[2024-10-06 07:01:21,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 07:01:21,859][fairseq.trainer][INFO] - begin training epoch 150
[2024-10-06 07:01:21,860][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:08:06,081][train_inner][INFO] - {"epoch": 150, "update": 149.132, "loss": "0.861", "ntokens": "262795", "nsentences": "1756.07", "wps": "91387.3", "ups": "0.35", "wpb": "262795", "bsz": "1756.1", "num_updates": "71400", "lr": "0.000446467", "gnorm": "0.271", "loss_scale": "4", "train_wall": "218", "gb_free": "39.7", "wall": "133078"}
[2024-10-06 07:11:59,277][train_inner][INFO] - {"epoch": 150, "update": 149.549, "loss": "0.855", "ntokens": "264210", "nsentences": "1742.32", "wps": "226611", "ups": "0.86", "wpb": "264210", "bsz": "1742.3", "num_updates": "71600", "lr": "0.000446196", "gnorm": "0.288", "loss_scale": "4", "train_wall": "160", "gb_free": "39.8", "wall": "133311"}
[2024-10-06 07:15:59,462][train_inner][INFO] - {"epoch": 150, "update": 149.967, "loss": "0.861", "ntokens": "264040", "nsentences": "1759.95", "wps": "219878", "ups": "0.83", "wpb": "264040", "bsz": "1760", "num_updates": "71800", "lr": "0.000445924", "gnorm": "0.267", "loss_scale": "4", "train_wall": "144", "gb_free": "40", "wall": "133552"}
[2024-10-06 07:16:47,928][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 71816 updates
[2024-10-06 07:16:47,928][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 07:16:59,127][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 07:16:59,148][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 150 @ 71816 updates, score None) (writing took 11.22011807654053 seconds)
[2024-10-06 07:16:59,149][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2024-10-06 07:16:59,154][train][INFO] - {"epoch": 150, "train_loss": "0.858", "train_ntokens": "263549", "train_nsentences": "1753.71", "train_wps": "134382", "train_ups": "0.51", "train_wpb": "263549", "train_bsz": "1753.7", "train_num_updates": "71816", "train_lr": "0.000445902", "train_gnorm": "0.278", "train_loss_scale": "4", "train_train_wall": "400", "train_gb_free": "40.1", "train_wall": "133611"}
[2024-10-06 07:16:59,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 07:16:59,217][fairseq.trainer][INFO] - begin training epoch 151
[2024-10-06 07:16:59,217][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:25:40,331][train_inner][INFO] - {"epoch": 151, "update": 150.384, "loss": "0.858", "ntokens": "262834", "nsentences": "1752.23", "wps": "90497.9", "ups": "0.34", "wpb": "262834", "bsz": "1752.2", "num_updates": "72000", "lr": "0.000445652", "gnorm": "0.265", "loss_scale": "4", "train_wall": "182", "gb_free": "39.3", "wall": "134133"}
[2024-10-06 07:29:56,517][train_inner][INFO] - {"epoch": 151, "update": 150.802, "loss": "0.86", "ntokens": "264127", "nsentences": "1758.47", "wps": "206216", "ups": "0.78", "wpb": "264127", "bsz": "1758.5", "num_updates": "72200", "lr": "0.00044538", "gnorm": "0.276", "loss_scale": "8", "train_wall": "186", "gb_free": "40.7", "wall": "134389"}
[2024-10-06 07:29:59,565][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-06 07:31:35,456][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2024-10-06 07:31:35,468][train][INFO] - {"epoch": 151, "train_loss": "0.859", "train_ntokens": "263588", "train_nsentences": "1753.58", "train_wps": "143779", "train_ups": "0.55", "train_wpb": "263588", "train_bsz": "1753.6", "train_num_updates": "72294", "train_lr": "0.000445253", "train_gnorm": "0.272", "train_loss_scale": "4", "train_train_wall": "424", "train_gb_free": "39.8", "train_wall": "134488"}
[2024-10-06 07:31:35,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 07:31:35,604][fairseq.trainer][INFO] - begin training epoch 152
[2024-10-06 07:31:35,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:38:58,061][train_inner][INFO] - {"epoch": 152, "update": 151.221, "loss": "0.858", "ntokens": "262882", "nsentences": "1756.63", "wps": "97089.9", "ups": "0.37", "wpb": "262882", "bsz": "1756.6", "num_updates": "72400", "lr": "0.000445109", "gnorm": "0.279", "loss_scale": "4", "train_wall": "208", "gb_free": "40", "wall": "134930"}
[2024-10-06 07:42:33,721][train_inner][INFO] - {"epoch": 152, "update": 151.639, "loss": "0.856", "ntokens": "264070", "nsentences": "1750.35", "wps": "244918", "ups": "0.93", "wpb": "264070", "bsz": "1750.3", "num_updates": "72600", "lr": "0.000444837", "gnorm": "0.27", "loss_scale": "4", "train_wall": "210", "gb_free": "39.6", "wall": "135146"}
[2024-10-06 07:43:14,533][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 07:45:46,602][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2024-10-06 07:45:46,647][train][INFO] - {"epoch": 152, "train_loss": "0.858", "train_ntokens": "263506", "train_nsentences": "1754.39", "train_wps": "147979", "train_ups": "0.56", "train_wpb": "263506", "train_bsz": "1754.4", "train_num_updates": "72772", "train_lr": "0.000444603", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "509", "train_gb_free": "39.3", "train_wall": "135339"}
[2024-10-06 07:45:46,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 07:45:46,926][fairseq.trainer][INFO] - begin training epoch 153
[2024-10-06 07:45:46,926][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:52:13,243][train_inner][INFO] - {"epoch": 153, "update": 152.058, "loss": "0.86", "ntokens": "262708", "nsentences": "1755.74", "wps": "90665.9", "ups": "0.35", "wpb": "262708", "bsz": "1755.7", "num_updates": "72800", "lr": "0.000444565", "gnorm": "0.265", "loss_scale": "2", "train_wall": "227", "gb_free": "40.1", "wall": "135725"}
[2024-10-06 07:56:01,981][train_inner][INFO] - {"epoch": 153, "update": 152.476, "loss": "0.855", "ntokens": "263799", "nsentences": "1757.26", "wps": "230684", "ups": "0.87", "wpb": "263799", "bsz": "1757.3", "num_updates": "73000", "lr": "0.000444293", "gnorm": "0.272", "loss_scale": "2", "train_wall": "219", "gb_free": "40", "wall": "135954"}
[2024-10-06 08:00:07,448][train_inner][INFO] - {"epoch": 153, "update": 152.894, "loss": "0.859", "ntokens": "264056", "nsentences": "1754.61", "wps": "215150", "ups": "0.81", "wpb": "264056", "bsz": "1754.6", "num_updates": "73200", "lr": "0.000444022", "gnorm": "0.268", "loss_scale": "2", "train_wall": "240", "gb_free": "39.3", "wall": "136200"}
[2024-10-06 08:01:07,071][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2024-10-06 08:01:07,108][train][INFO] - {"epoch": 153, "train_loss": "0.857", "train_ntokens": "263425", "train_nsentences": "1753.71", "train_wps": "137092", "train_ups": "0.52", "train_wpb": "263425", "train_bsz": "1753.7", "train_num_updates": "73251", "train_lr": "0.000443952", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.2", "train_wall": "136259"}
[2024-10-06 08:01:07,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 08:01:07,403][fairseq.trainer][INFO] - begin training epoch 154
[2024-10-06 08:01:07,403][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 08:09:11,216][train_inner][INFO] - {"epoch": 154, "update": 153.311, "loss": "0.853", "ntokens": "263102", "nsentences": "1693.44", "wps": "96770.8", "ups": "0.37", "wpb": "263102", "bsz": "1693.4", "num_updates": "73400", "lr": "0.00044375", "gnorm": "0.262", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "136743"}
[2024-10-06 08:13:11,903][train_inner][INFO] - {"epoch": 154, "update": 153.729, "loss": "0.858", "ntokens": "263472", "nsentences": "1804.68", "wps": "218940", "ups": "0.83", "wpb": "263472", "bsz": "1804.7", "num_updates": "73600", "lr": "0.000443478", "gnorm": "0.281", "loss_scale": "2", "train_wall": "235", "gb_free": "40", "wall": "136984"}
[2024-10-06 08:15:38,915][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2024-10-06 08:15:38,970][train][INFO] - {"epoch": 154, "train_loss": "0.856", "train_ntokens": "263427", "train_nsentences": "1753.71", "train_wps": "144729", "train_ups": "0.55", "train_wpb": "263427", "train_bsz": "1753.7", "train_num_updates": "73730", "train_lr": "0.000443302", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "540", "train_gb_free": "39.6", "train_wall": "137131"}
[2024-10-06 08:15:39,290][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 08:15:39,321][fairseq.trainer][INFO] - begin training epoch 155
[2024-10-06 08:15:39,321][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 08:22:30,963][train_inner][INFO] - {"epoch": 155, "update": 154.146, "loss": "0.858", "ntokens": "263118", "nsentences": "1734.64", "wps": "94136.6", "ups": "0.36", "wpb": "263118", "bsz": "1734.6", "num_updates": "73800", "lr": "0.000443207", "gnorm": "0.276", "loss_scale": "2", "train_wall": "221", "gb_free": "39.8", "wall": "137543"}
[2024-10-06 08:26:19,498][train_inner][INFO] - {"epoch": 155, "update": 154.564, "loss": "0.856", "ntokens": "264067", "nsentences": "1769.63", "wps": "231102", "ups": "0.88", "wpb": "264067", "bsz": "1769.6", "num_updates": "74000", "lr": "0.000442935", "gnorm": "0.273", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "137772"}
[2024-10-06 08:29:58,707][train_inner][INFO] - {"epoch": 155, "update": 154.981, "loss": "0.856", "ntokens": "263723", "nsentences": "1757.12", "wps": "240645", "ups": "0.91", "wpb": "263723", "bsz": "1757.1", "num_updates": "74200", "lr": "0.000442663", "gnorm": "0.266", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "137991"}
[2024-10-06 08:30:20,404][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2024-10-06 08:30:20,408][train][INFO] - {"epoch": 155, "train_loss": "0.856", "train_ntokens": "263513", "train_nsentences": "1753.71", "train_wps": "143202", "train_ups": "0.54", "train_wpb": "263513", "train_bsz": "1753.7", "train_num_updates": "74209", "train_lr": "0.000442651", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "536", "train_gb_free": "40", "train_wall": "138013"}
[2024-10-06 08:30:20,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 08:30:20,528][fairseq.trainer][INFO] - begin training epoch 156
[2024-10-06 08:30:20,529][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 08:39:50,755][train_inner][INFO] - {"epoch": 156, "update": 155.399, "loss": "0.854", "ntokens": "262683", "nsentences": "1761.24", "wps": "88742.8", "ups": "0.34", "wpb": "262683", "bsz": "1761.2", "num_updates": "74400", "lr": "0.000442391", "gnorm": "0.274", "loss_scale": "2", "train_wall": "258", "gb_free": "39.8", "wall": "138583"}
[2024-10-06 08:44:04,689][train_inner][INFO] - {"epoch": 156, "update": 155.816, "loss": "0.856", "ntokens": "264112", "nsentences": "1763.57", "wps": "208022", "ups": "0.79", "wpb": "264112", "bsz": "1763.6", "num_updates": "74600", "lr": "0.00044212", "gnorm": "0.282", "loss_scale": "2", "train_wall": "249", "gb_free": "39.3", "wall": "138837"}
[2024-10-06 08:45:57,662][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2024-10-06 08:45:57,667][train][INFO] - {"epoch": 156, "train_loss": "0.855", "train_ntokens": "263631", "train_nsentences": "1753.71", "train_wps": "134735", "train_ups": "0.51", "train_wpb": "263631", "train_bsz": "1753.7", "train_num_updates": "74688", "train_lr": "0.000442", "train_gnorm": "0.277", "train_loss_scale": "4", "train_train_wall": "596", "train_gb_free": "39.6", "train_wall": "138950"}
[2024-10-06 08:45:57,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 08:45:57,729][fairseq.trainer][INFO] - begin training epoch 157
[2024-10-06 08:45:57,730][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 08:53:13,583][train_inner][INFO] - {"epoch": 157, "update": 156.234, "loss": "0.856", "ntokens": "263222", "nsentences": "1729.34", "wps": "95911", "ups": "0.36", "wpb": "263222", "bsz": "1729.3", "num_updates": "74800", "lr": "0.000441848", "gnorm": "0.282", "loss_scale": "4", "train_wall": "238", "gb_free": "39.6", "wall": "139386"}
[2024-10-06 08:57:20,758][train_inner][INFO] - {"epoch": 157, "update": 156.651, "loss": "0.854", "ntokens": "264100", "nsentences": "1743.72", "wps": "213716", "ups": "0.81", "wpb": "264100", "bsz": "1743.7", "num_updates": "75000", "lr": "0.000441576", "gnorm": "0.266", "loss_scale": "4", "train_wall": "242", "gb_free": "39.4", "wall": "139633"}
[2024-10-06 09:00:23,218][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 09:01:13,946][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2024-10-06 09:01:13,951][train][INFO] - {"epoch": 157, "train_loss": "0.855", "train_ntokens": "263491", "train_nsentences": "1752.94", "train_wps": "137457", "train_ups": "0.52", "train_wpb": "263491", "train_bsz": "1752.9", "train_num_updates": "75166", "train_lr": "0.000441351", "train_gnorm": "0.277", "train_loss_scale": "2", "train_train_wall": "597", "train_gb_free": "40", "train_wall": "139866"}
[2024-10-06 09:01:14,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 09:01:14,048][fairseq.trainer][INFO] - begin training epoch 158
[2024-10-06 09:01:14,048][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 09:07:41,488][train_inner][INFO] - {"epoch": 158, "update": 157.071, "loss": "0.856", "ntokens": "262611", "nsentences": "1765.99", "wps": "84614.8", "ups": "0.32", "wpb": "262611", "bsz": "1766", "num_updates": "75200", "lr": "0.000441304", "gnorm": "0.286", "loss_scale": "2", "train_wall": "291", "gb_free": "39.6", "wall": "140254"}
[2024-10-06 09:10:52,470][train_inner][INFO] - {"epoch": 158, "update": 157.489, "loss": "0.852", "ntokens": "264162", "nsentences": "1718.6", "wps": "276664", "ups": "1.05", "wpb": "264162", "bsz": "1718.6", "num_updates": "75400", "lr": "0.000441033", "gnorm": "0.261", "loss_scale": "2", "train_wall": "186", "gb_free": "39.6", "wall": "140445"}
[2024-10-06 09:15:19,660][train_inner][INFO] - {"epoch": 158, "update": 157.906, "loss": "0.859", "ntokens": "263620", "nsentences": "1807.14", "wps": "197343", "ups": "0.75", "wpb": "263620", "bsz": "1807.1", "num_updates": "75600", "lr": "0.000440761", "gnorm": "0.274", "loss_scale": "2", "train_wall": "262", "gb_free": "41", "wall": "140712"}
[2024-10-06 09:16:39,908][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2024-10-06 09:16:39,938][train][INFO] - {"epoch": 158, "train_loss": "0.855", "train_ntokens": "263464", "train_nsentences": "1753.71", "train_wps": "136287", "train_ups": "0.52", "train_wpb": "263464", "train_bsz": "1753.7", "train_num_updates": "75645", "train_lr": "0.0004407", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "591", "train_gb_free": "39.3", "train_wall": "140792"}
[2024-10-06 09:16:40,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 09:16:40,046][fairseq.trainer][INFO] - begin training epoch 159
[2024-10-06 09:16:40,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 09:24:51,647][train_inner][INFO] - {"epoch": 159, "update": 158.324, "loss": "0.852", "ntokens": "262607", "nsentences": "1757.05", "wps": "91824.3", "ups": "0.35", "wpb": "262607", "bsz": "1757", "num_updates": "75800", "lr": "0.000440489", "gnorm": "0.27", "loss_scale": "2", "train_wall": "252", "gb_free": "39.9", "wall": "141284"}
[2024-10-06 09:28:37,905][train_inner][INFO] - {"epoch": 159, "update": 158.741, "loss": "0.856", "ntokens": "264030", "nsentences": "1739.67", "wps": "233399", "ups": "0.88", "wpb": "264030", "bsz": "1739.7", "num_updates": "76000", "lr": "0.000440217", "gnorm": "0.263", "loss_scale": "2", "train_wall": "212", "gb_free": "39.8", "wall": "141510"}
[2024-10-06 09:31:17,985][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2024-10-06 09:31:18,001][train][INFO] - {"epoch": 159, "train_loss": "0.854", "train_ntokens": "263417", "train_nsentences": "1753.71", "train_wps": "143700", "train_ups": "0.55", "train_wpb": "263417", "train_bsz": "1753.7", "train_num_updates": "76124", "train_lr": "0.000440049", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "40", "train_wall": "141670"}
[2024-10-06 09:31:18,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 09:31:18,130][fairseq.trainer][INFO] - begin training epoch 160
[2024-10-06 09:31:18,131][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 09:38:17,614][train_inner][INFO] - {"epoch": 160, "update": 159.159, "loss": "0.852", "ntokens": "262883", "nsentences": "1729.55", "wps": "90700", "ups": "0.35", "wpb": "262883", "bsz": "1729.5", "num_updates": "76200", "lr": "0.000439946", "gnorm": "0.273", "loss_scale": "2", "train_wall": "240", "gb_free": "39.7", "wall": "142090"}
[2024-10-06 09:42:04,518][train_inner][INFO] - {"epoch": 160, "update": 159.576, "loss": "0.855", "ntokens": "263938", "nsentences": "1767.12", "wps": "232654", "ups": "0.88", "wpb": "263938", "bsz": "1767.1", "num_updates": "76400", "lr": "0.000439674", "gnorm": "0.266", "loss_scale": "2", "train_wall": "221", "gb_free": "39.6", "wall": "142317"}
[2024-10-06 09:46:01,849][train_inner][INFO] - {"epoch": 160, "update": 159.994, "loss": "0.856", "ntokens": "263951", "nsentences": "1769.01", "wps": "222478", "ups": "0.84", "wpb": "263952", "bsz": "1769", "num_updates": "76600", "lr": "0.000439402", "gnorm": "0.286", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "142554"}
[2024-10-06 09:46:05,107][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 76603 updates
[2024-10-06 09:46:05,130][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 09:46:19,613][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 09:46:19,765][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 160 @ 76603 updates, score None) (writing took 14.657605363056064 seconds)
[2024-10-06 09:46:19,766][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2024-10-06 09:46:19,768][train][INFO] - {"epoch": 160, "train_loss": "0.854", "train_ntokens": "263494", "train_nsentences": "1753.71", "train_wps": "139963", "train_ups": "0.53", "train_wpb": "263494", "train_bsz": "1753.7", "train_num_updates": "76603", "train_lr": "0.000439398", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.2", "train_wall": "142572"}
[2024-10-06 09:46:19,817][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 09:46:19,839][fairseq.trainer][INFO] - begin training epoch 161
[2024-10-06 09:46:19,840][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 09:54:55,060][train_inner][INFO] - {"epoch": 161, "update": 160.411, "loss": "0.852", "ntokens": "262857", "nsentences": "1739.54", "wps": "98596.7", "ups": "0.38", "wpb": "262857", "bsz": "1739.5", "num_updates": "76800", "lr": "0.00043913", "gnorm": "0.268", "loss_scale": "2", "train_wall": "205", "gb_free": "39.6", "wall": "143087"}
[2024-10-06 09:59:08,218][train_inner][INFO] - {"epoch": 161, "update": 160.829, "loss": "0.855", "ntokens": "264026", "nsentences": "1755.66", "wps": "208591", "ups": "0.79", "wpb": "264026", "bsz": "1755.7", "num_updates": "77000", "lr": "0.000438859", "gnorm": "0.258", "loss_scale": "2", "train_wall": "247", "gb_free": "39.3", "wall": "143340"}
[2024-10-06 10:01:03,577][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2024-10-06 10:01:03,596][train][INFO] - {"epoch": 161, "train_loss": "0.854", "train_ntokens": "263489", "train_nsentences": "1753.71", "train_wps": "142801", "train_ups": "0.54", "train_wpb": "263489", "train_bsz": "1753.7", "train_num_updates": "77082", "train_lr": "0.000438747", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "562", "train_gb_free": "40.5", "train_wall": "143456"}
[2024-10-06 10:01:03,797][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 10:01:03,850][fairseq.trainer][INFO] - begin training epoch 162
[2024-10-06 10:01:03,851][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 10:08:33,638][train_inner][INFO] - {"epoch": 162, "update": 161.246, "loss": "0.851", "ntokens": "263016", "nsentences": "1723.27", "wps": "93034.7", "ups": "0.35", "wpb": "263016", "bsz": "1723.3", "num_updates": "77200", "lr": "0.000438587", "gnorm": "0.283", "loss_scale": "4", "train_wall": "227", "gb_free": "39.6", "wall": "143906"}
[2024-10-06 10:11:59,762][train_inner][INFO] - {"epoch": 162, "update": 161.664, "loss": "0.854", "ntokens": "264170", "nsentences": "1749.25", "wps": "256337", "ups": "0.97", "wpb": "264170", "bsz": "1749.2", "num_updates": "77400", "lr": "0.000438315", "gnorm": "0.258", "loss_scale": "4", "train_wall": "184", "gb_free": "39.6", "wall": "144112"}
[2024-10-06 10:15:44,000][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2024-10-06 10:15:44,051][train][INFO] - {"epoch": 162, "train_loss": "0.853", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "143394", "train_ups": "0.54", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "77561", "train_lr": "0.000438096", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "512", "train_gb_free": "39.4", "train_wall": "144336"}
[2024-10-06 10:15:44,263][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 10:15:44,295][fairseq.trainer][INFO] - begin training epoch 163
[2024-10-06 10:15:44,296][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 10:22:02,494][train_inner][INFO] - {"epoch": 163, "update": 162.081, "loss": "0.855", "ntokens": "262504", "nsentences": "1793.33", "wps": "87108.3", "ups": "0.33", "wpb": "262504", "bsz": "1793.3", "num_updates": "77600", "lr": "0.000438043", "gnorm": "0.271", "loss_scale": "4", "train_wall": "283", "gb_free": "39.7", "wall": "144715"}
[2024-10-06 10:22:55,037][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 10:25:41,487][train_inner][INFO] - {"epoch": 163, "update": 162.501, "loss": "0.851", "ntokens": "264111", "nsentences": "1749.8", "wps": "241215", "ups": "0.91", "wpb": "264110", "bsz": "1749.8", "num_updates": "77800", "lr": "0.000437772", "gnorm": "0.258", "loss_scale": "2", "train_wall": "214", "gb_free": "40.5", "wall": "144934"}
[2024-10-06 10:29:53,360][train_inner][INFO] - {"epoch": 163, "update": 162.919, "loss": "0.853", "ntokens": "264068", "nsentences": "1757.59", "wps": "209692", "ups": "0.79", "wpb": "264068", "bsz": "1757.6", "num_updates": "78000", "lr": "0.0004375", "gnorm": "0.271", "loss_scale": "2", "train_wall": "246", "gb_free": "39.2", "wall": "145186"}
[2024-10-06 10:30:55,531][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2024-10-06 10:30:55,534][train][INFO] - {"epoch": 163, "train_loss": "0.853", "train_ntokens": "263532", "train_nsentences": "1753.24", "train_wps": "138202", "train_ups": "0.52", "train_wpb": "263532", "train_bsz": "1753.2", "train_num_updates": "78039", "train_lr": "0.000437447", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "590", "train_gb_free": "40.5", "train_wall": "145248"}
[2024-10-06 10:30:55,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 10:30:55,605][fairseq.trainer][INFO] - begin training epoch 164
[2024-10-06 10:30:55,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 10:39:02,365][train_inner][INFO] - {"epoch": 164, "update": 163.336, "loss": "0.855", "ntokens": "262276", "nsentences": "1799.5", "wps": "95548.8", "ups": "0.36", "wpb": "262276", "bsz": "1799.5", "num_updates": "78200", "lr": "0.000437228", "gnorm": "0.266", "loss_scale": "2", "train_wall": "232", "gb_free": "40.1", "wall": "145735"}
[2024-10-06 10:42:42,684][train_inner][INFO] - {"epoch": 164, "update": 163.754, "loss": "0.851", "ntokens": "264062", "nsentences": "1736.56", "wps": "239734", "ups": "0.91", "wpb": "264062", "bsz": "1736.6", "num_updates": "78400", "lr": "0.000436957", "gnorm": "0.255", "loss_scale": "2", "train_wall": "215", "gb_free": "39.3", "wall": "145955"}
[2024-10-06 10:45:07,217][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2024-10-06 10:45:07,232][train][INFO] - {"epoch": 164, "train_loss": "0.852", "train_ntokens": "263394", "train_nsentences": "1753.71", "train_wps": "148135", "train_ups": "0.56", "train_wpb": "263394", "train_bsz": "1753.7", "train_num_updates": "78518", "train_lr": "0.000436796", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "527", "train_gb_free": "39.6", "train_wall": "146099"}
[2024-10-06 10:45:07,311][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 10:45:07,334][fairseq.trainer][INFO] - begin training epoch 165
[2024-10-06 10:45:07,335][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 10:51:58,461][train_inner][INFO] - {"epoch": 165, "update": 164.171, "loss": "0.85", "ntokens": "262857", "nsentences": "1727.25", "wps": "94592.3", "ups": "0.36", "wpb": "262857", "bsz": "1727.2", "num_updates": "78600", "lr": "0.000436685", "gnorm": "0.261", "loss_scale": "2", "train_wall": "230", "gb_free": "39.7", "wall": "146511"}
[2024-10-06 10:55:52,858][train_inner][INFO] - {"epoch": 165, "update": 164.589, "loss": "0.852", "ntokens": "263949", "nsentences": "1761.41", "wps": "225230", "ups": "0.85", "wpb": "263949", "bsz": "1761.4", "num_updates": "78800", "lr": "0.000436413", "gnorm": "0.264", "loss_scale": "2", "train_wall": "229", "gb_free": "39.7", "wall": "146745"}
[2024-10-06 10:59:56,812][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2024-10-06 10:59:56,815][train][INFO] - {"epoch": 165, "train_loss": "0.851", "train_ntokens": "263416", "train_nsentences": "1753.71", "train_wps": "141838", "train_ups": "0.54", "train_wpb": "263416", "train_bsz": "1753.7", "train_num_updates": "78997", "train_lr": "0.000436145", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.9", "train_wall": "146989"}
[2024-10-06 10:59:56,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 10:59:57,011][fairseq.trainer][INFO] - begin training epoch 166
[2024-10-06 10:59:57,012][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 11:05:41,902][train_inner][INFO] - {"epoch": 166, "update": 165.006, "loss": "0.851", "ntokens": "262789", "nsentences": "1737.58", "wps": "89228.5", "ups": "0.34", "wpb": "262789", "bsz": "1737.6", "num_updates": "79000", "lr": "0.000436141", "gnorm": "0.284", "loss_scale": "2", "train_wall": "266", "gb_free": "39.6", "wall": "147334"}
[2024-10-06 11:09:20,004][train_inner][INFO] - {"epoch": 166, "update": 165.424, "loss": "0.85", "ntokens": "263973", "nsentences": "1773.15", "wps": "242071", "ups": "0.92", "wpb": "263973", "bsz": "1773.2", "num_updates": "79200", "lr": "0.00043587", "gnorm": "0.279", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "147552"}
[2024-10-06 11:13:35,250][train_inner][INFO] - {"epoch": 166, "update": 165.841, "loss": "0.855", "ntokens": "263639", "nsentences": "1785.17", "wps": "206581", "ups": "0.78", "wpb": "263639", "bsz": "1785.2", "num_updates": "79400", "lr": "0.000435598", "gnorm": "0.269", "loss_scale": "2", "train_wall": "250", "gb_free": "39.6", "wall": "147807"}
[2024-10-06 11:14:56,526][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2024-10-06 11:14:56,553][train][INFO] - {"epoch": 166, "train_loss": "0.852", "train_ntokens": "263527", "train_nsentences": "1753.71", "train_wps": "140296", "train_ups": "0.53", "train_wpb": "263527", "train_bsz": "1753.7", "train_num_updates": "79476", "train_lr": "0.000435495", "train_gnorm": "0.281", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.7", "train_wall": "147889"}
[2024-10-06 11:14:56,889][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 11:14:56,967][fairseq.trainer][INFO] - begin training epoch 167
[2024-10-06 11:14:56,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 11:22:57,289][train_inner][INFO] - {"epoch": 167, "update": 166.259, "loss": "0.849", "ntokens": "263027", "nsentences": "1734.47", "wps": "93598.6", "ups": "0.36", "wpb": "263027", "bsz": "1734.5", "num_updates": "79600", "lr": "0.000435326", "gnorm": "0.282", "loss_scale": "2", "train_wall": "190", "gb_free": "40", "wall": "148369"}
[2024-10-06 11:26:31,869][train_inner][INFO] - {"epoch": 167, "update": 166.676, "loss": "0.848", "ntokens": "264009", "nsentences": "1714.87", "wps": "246092", "ups": "0.93", "wpb": "264009", "bsz": "1714.9", "num_updates": "79800", "lr": "0.000435054", "gnorm": "0.264", "loss_scale": "4", "train_wall": "156", "gb_free": "39.6", "wall": "148584"}
[2024-10-06 11:29:32,706][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2024-10-06 11:29:32,715][train][INFO] - {"epoch": 167, "train_loss": "0.85", "train_ntokens": "263414", "train_nsentences": "1753.71", "train_wps": "144010", "train_ups": "0.55", "train_wpb": "263414", "train_bsz": "1753.7", "train_num_updates": "79955", "train_lr": "0.000434844", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "407", "train_gb_free": "39.3", "train_wall": "148765"}
[2024-10-06 11:29:32,912][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 11:29:32,942][fairseq.trainer][INFO] - begin training epoch 168
[2024-10-06 11:29:32,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 11:36:10,896][train_inner][INFO] - {"epoch": 168, "update": 167.094, "loss": "0.852", "ntokens": "262752", "nsentences": "1776.37", "wps": "90758.9", "ups": "0.35", "wpb": "262752", "bsz": "1776.4", "num_updates": "80000", "lr": "0.000434783", "gnorm": "0.275", "loss_scale": "4", "train_wall": "194", "gb_free": "39.6", "wall": "149163"}
[2024-10-06 11:39:47,273][train_inner][INFO] - {"epoch": 168, "update": 167.511, "loss": "0.848", "ntokens": "264098", "nsentences": "1744.34", "wps": "244122", "ups": "0.92", "wpb": "264098", "bsz": "1744.3", "num_updates": "80200", "lr": "0.000434511", "gnorm": "0.265", "loss_scale": "4", "train_wall": "174", "gb_free": "40.7", "wall": "149379"}
[2024-10-06 11:43:51,673][train_inner][INFO] - {"epoch": 168, "update": 167.929, "loss": "0.853", "ntokens": "263943", "nsentences": "1780.05", "wps": "216006", "ups": "0.82", "wpb": "263943", "bsz": "1780", "num_updates": "80400", "lr": "0.000434239", "gnorm": "0.261", "loss_scale": "4", "train_wall": "153", "gb_free": "39.3", "wall": "149624"}
[2024-10-06 11:44:23,345][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2024-10-06 11:44:23,421][train][INFO] - {"epoch": 168, "train_loss": "0.85", "train_ntokens": "263596", "train_nsentences": "1753.71", "train_wps": "141760", "train_ups": "0.54", "train_wpb": "263596", "train_bsz": "1753.7", "train_num_updates": "80434", "train_lr": "0.000434193", "train_gnorm": "0.267", "train_loss_scale": "4", "train_train_wall": "402", "train_gb_free": "39.7", "train_wall": "149656"}
[2024-10-06 11:44:23,586][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 11:44:23,615][fairseq.trainer][INFO] - begin training epoch 169
[2024-10-06 11:44:23,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 11:53:20,268][train_inner][INFO] - {"epoch": 169, "update": 168.347, "loss": "0.85", "ntokens": "262761", "nsentences": "1761.82", "wps": "92425.5", "ups": "0.35", "wpb": "262760", "bsz": "1761.8", "num_updates": "80600", "lr": "0.000433967", "gnorm": "0.269", "loss_scale": "4", "train_wall": "203", "gb_free": "40.5", "wall": "150192"}
[2024-10-06 11:57:15,112][train_inner][INFO] - {"epoch": 169, "update": 168.764, "loss": "0.851", "ntokens": "263936", "nsentences": "1781.2", "wps": "224806", "ups": "0.85", "wpb": "263936", "bsz": "1781.2", "num_updates": "80800", "lr": "0.000433696", "gnorm": "0.274", "loss_scale": "4", "train_wall": "228", "gb_free": "40.2", "wall": "150427"}
[2024-10-06 11:59:10,665][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2024-10-06 11:59:10,786][train][INFO] - {"epoch": 169, "train_loss": "0.85", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "142248", "train_ups": "0.54", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "80913", "train_lr": "0.000433542", "train_gnorm": "0.274", "train_loss_scale": "4", "train_train_wall": "518", "train_gb_free": "39.6", "train_wall": "150543"}
[2024-10-06 11:59:12,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 11:59:13,059][fairseq.trainer][INFO] - begin training epoch 170
[2024-10-06 11:59:13,059][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 12:05:42,749][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 12:06:11,477][train_inner][INFO] - {"epoch": 170, "update": 169.184, "loss": "0.848", "ntokens": "263337", "nsentences": "1678.38", "wps": "98197.2", "ups": "0.37", "wpb": "263337", "bsz": "1678.4", "num_updates": "81000", "lr": "0.000433424", "gnorm": "0.277", "loss_scale": "2", "train_wall": "205", "gb_free": "39.6", "wall": "150964"}
[2024-10-06 12:10:02,681][train_inner][INFO] - {"epoch": 170, "update": 169.601, "loss": "0.849", "ntokens": "264143", "nsentences": "1756.92", "wps": "228517", "ups": "0.87", "wpb": "264143", "bsz": "1756.9", "num_updates": "81200", "lr": "0.000433152", "gnorm": "0.263", "loss_scale": "2", "train_wall": "174", "gb_free": "39.3", "wall": "151195"}
[2024-10-06 12:14:02,869][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 81391 updates
[2024-10-06 12:14:02,946][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 12:14:11,134][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 12:14:11,200][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 170 @ 81391 updates, score None) (writing took 8.330696183256805 seconds)
[2024-10-06 12:14:11,201][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2024-10-06 12:14:11,214][train][INFO] - {"epoch": 170, "train_loss": "0.849", "train_ntokens": "263627", "train_nsentences": "1753.54", "train_wps": "139953", "train_ups": "0.53", "train_wpb": "263627", "train_bsz": "1753.5", "train_num_updates": "81391", "train_lr": "0.000432893", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "441", "train_gb_free": "39.1", "train_wall": "151443"}
[2024-10-06 12:14:11,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 12:14:11,310][fairseq.trainer][INFO] - begin training epoch 171
[2024-10-06 12:14:11,311][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 12:19:48,998][train_inner][INFO] - {"epoch": 171, "update": 170.019, "loss": "0.851", "ntokens": "262787", "nsentences": "1761.23", "wps": "89643.3", "ups": "0.34", "wpb": "262788", "bsz": "1761.2", "num_updates": "81400", "lr": "0.00043288", "gnorm": "0.252", "loss_scale": "2", "train_wall": "178", "gb_free": "39.6", "wall": "151781"}
[2024-10-06 12:23:19,530][train_inner][INFO] - {"epoch": 171, "update": 170.436, "loss": "0.846", "ntokens": "264350", "nsentences": "1725.17", "wps": "251144", "ups": "0.95", "wpb": "264350", "bsz": "1725.2", "num_updates": "81600", "lr": "0.000432609", "gnorm": "0.262", "loss_scale": "2", "train_wall": "197", "gb_free": "39.3", "wall": "151992"}
[2024-10-06 12:27:02,321][train_inner][INFO] - {"epoch": 171, "update": 170.854, "loss": "0.851", "ntokens": "263545", "nsentences": "1797.16", "wps": "236608", "ups": "0.9", "wpb": "263545", "bsz": "1797.2", "num_updates": "81800", "lr": "0.000432337", "gnorm": "0.254", "loss_scale": "2", "train_wall": "176", "gb_free": "40.5", "wall": "152214"}
[2024-10-06 12:28:37,361][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2024-10-06 12:28:37,398][train][INFO] - {"epoch": 171, "train_loss": "0.849", "train_ntokens": "263477", "train_nsentences": "1753.71", "train_wps": "145706", "train_ups": "0.55", "train_wpb": "263477", "train_bsz": "1753.7", "train_num_updates": "81870", "train_lr": "0.000432242", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "435", "train_gb_free": "40", "train_wall": "152310"}
[2024-10-06 12:28:37,623][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 12:28:37,639][fairseq.trainer][INFO] - begin training epoch 172
[2024-10-06 12:28:37,640][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 12:36:35,894][train_inner][INFO] - {"epoch": 172, "update": 171.271, "loss": "0.849", "ntokens": "262837", "nsentences": "1729.43", "wps": "91653.6", "ups": "0.35", "wpb": "262837", "bsz": "1729.4", "num_updates": "82000", "lr": "0.000432065", "gnorm": "0.258", "loss_scale": "2", "train_wall": "165", "gb_free": "39.9", "wall": "152788"}
[2024-10-06 12:40:37,298][train_inner][INFO] - {"epoch": 172, "update": 171.689, "loss": "0.848", "ntokens": "264115", "nsentences": "1746.09", "wps": "218823", "ups": "0.83", "wpb": "264114", "bsz": "1746.1", "num_updates": "82200", "lr": "0.000431793", "gnorm": "0.264", "loss_scale": "2", "train_wall": "164", "gb_free": "39.6", "wall": "153029"}
[2024-10-06 12:42:53,184][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-06 12:44:02,316][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2024-10-06 12:44:02,330][train][INFO] - {"epoch": 172, "train_loss": "0.849", "train_ntokens": "263434", "train_nsentences": "1754.08", "train_wps": "136143", "train_ups": "0.52", "train_wpb": "263434", "train_bsz": "1754.1", "train_num_updates": "82348", "train_lr": "0.000431592", "train_gnorm": "0.263", "train_loss_scale": "1", "train_train_wall": "413", "train_gb_free": "40.2", "train_wall": "153234"}
[2024-10-06 12:44:02,416][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 12:44:02,434][fairseq.trainer][INFO] - begin training epoch 173
[2024-10-06 12:44:02,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 12:50:33,202][train_inner][INFO] - {"epoch": 173, "update": 172.109, "loss": "0.85", "ntokens": "262507", "nsentences": "1780.94", "wps": "88108.6", "ups": "0.34", "wpb": "262507", "bsz": "1780.9", "num_updates": "82400", "lr": "0.000431522", "gnorm": "0.274", "loss_scale": "1", "train_wall": "213", "gb_free": "39.8", "wall": "153625"}
[2024-10-06 12:54:08,675][train_inner][INFO] - {"epoch": 173, "update": 172.526, "loss": "0.848", "ntokens": "263724", "nsentences": "1766.76", "wps": "244799", "ups": "0.93", "wpb": "263724", "bsz": "1766.8", "num_updates": "82600", "lr": "0.00043125", "gnorm": "0.259", "loss_scale": "1", "train_wall": "210", "gb_free": "39.2", "wall": "153841"}
[2024-10-06 12:57:53,216][train_inner][INFO] - {"epoch": 173, "update": 172.944, "loss": "0.849", "ntokens": "264400", "nsentences": "1724.83", "wps": "235515", "ups": "0.89", "wpb": "264400", "bsz": "1724.8", "num_updates": "82800", "lr": "0.000430978", "gnorm": "0.27", "loss_scale": "1", "train_wall": "219", "gb_free": "39.3", "wall": "154065"}
[2024-10-06 12:58:25,010][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2024-10-06 12:58:25,050][train][INFO] - {"epoch": 173, "train_loss": "0.848", "train_ntokens": "263491", "train_nsentences": "1753.71", "train_wps": "146300", "train_ups": "0.56", "train_wpb": "263491", "train_bsz": "1753.7", "train_num_updates": "82827", "train_lr": "0.000430942", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "535", "train_gb_free": "39.7", "train_wall": "154097"}
[2024-10-06 12:58:25,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 12:58:25,433][fairseq.trainer][INFO] - begin training epoch 174
[2024-10-06 12:58:25,434][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 13:07:27,076][train_inner][INFO] - {"epoch": 174, "update": 173.361, "loss": "0.847", "ntokens": "263018", "nsentences": "1728.81", "wps": "91667.7", "ups": "0.35", "wpb": "263018", "bsz": "1728.8", "num_updates": "83000", "lr": "0.000430707", "gnorm": "0.251", "loss_scale": "1", "train_wall": "215", "gb_free": "39.8", "wall": "154639"}
[2024-10-06 13:11:25,463][train_inner][INFO] - {"epoch": 174, "update": 173.779, "loss": "0.849", "ntokens": "263882", "nsentences": "1770.38", "wps": "221395", "ups": "0.84", "wpb": "263882", "bsz": "1770.4", "num_updates": "83200", "lr": "0.000430435", "gnorm": "0.265", "loss_scale": "1", "train_wall": "196", "gb_free": "39.3", "wall": "154878"}
[2024-10-06 13:13:16,126][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2024-10-06 13:13:16,158][train][INFO] - {"epoch": 174, "train_loss": "0.848", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "141656", "train_ups": "0.54", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "83306", "train_lr": "0.000430291", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "451", "train_gb_free": "40.1", "train_wall": "154988"}
[2024-10-06 13:13:16,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 13:13:16,499][fairseq.trainer][INFO] - begin training epoch 175
[2024-10-06 13:13:16,500][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 13:20:56,338][train_inner][INFO] - {"epoch": 175, "update": 174.196, "loss": "0.85", "ntokens": "262521", "nsentences": "1790.11", "wps": "91973.5", "ups": "0.35", "wpb": "262520", "bsz": "1790.1", "num_updates": "83400", "lr": "0.000430163", "gnorm": "0.271", "loss_scale": "1", "train_wall": "187", "gb_free": "40", "wall": "155449"}
[2024-10-06 13:24:39,917][train_inner][INFO] - {"epoch": 175, "update": 174.614, "loss": "0.849", "ntokens": "264055", "nsentences": "1748.33", "wps": "236217", "ups": "0.89", "wpb": "264055", "bsz": "1748.3", "num_updates": "83600", "lr": "0.000429891", "gnorm": "0.264", "loss_scale": "1", "train_wall": "218", "gb_free": "39.6", "wall": "155672"}
[2024-10-06 13:28:22,469][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2024-10-06 13:28:22,484][train][INFO] - {"epoch": 175, "train_loss": "0.848", "train_ntokens": "263548", "train_nsentences": "1753.71", "train_wps": "139288", "train_ups": "0.53", "train_wpb": "263548", "train_bsz": "1753.7", "train_num_updates": "83785", "train_lr": "0.00042964", "train_gnorm": "0.263", "train_loss_scale": "1", "train_train_wall": "553", "train_gb_free": "39.2", "train_wall": "155895"}
[2024-10-06 13:28:22,620][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 13:28:22,635][fairseq.trainer][INFO] - begin training epoch 176
[2024-10-06 13:28:22,635][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 13:34:22,675][train_inner][INFO] - {"epoch": 176, "update": 175.031, "loss": "0.845", "ntokens": "263035", "nsentences": "1733.9", "wps": "90274", "ups": "0.34", "wpb": "263035", "bsz": "1733.9", "num_updates": "83800", "lr": "0.00042962", "gnorm": "0.269", "loss_scale": "1", "train_wall": "258", "gb_free": "39.6", "wall": "156255"}
[2024-10-06 13:38:10,301][train_inner][INFO] - {"epoch": 176, "update": 175.449, "loss": "0.847", "ntokens": "263764", "nsentences": "1783.3", "wps": "231786", "ups": "0.88", "wpb": "263764", "bsz": "1783.3", "num_updates": "84000", "lr": "0.000429348", "gnorm": "0.266", "loss_scale": "1", "train_wall": "222", "gb_free": "39.9", "wall": "156482"}
[2024-10-06 13:42:14,985][train_inner][INFO] - {"epoch": 176, "update": 175.866, "loss": "0.849", "ntokens": "264092", "nsentences": "1750.21", "wps": "215871", "ups": "0.82", "wpb": "264092", "bsz": "1750.2", "num_updates": "84200", "lr": "0.000429076", "gnorm": "0.261", "loss_scale": "1", "train_wall": "240", "gb_free": "40", "wall": "156727"}
[2024-10-06 13:43:29,524][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2024-10-06 13:43:29,555][train][INFO] - {"epoch": 176, "train_loss": "0.848", "train_ntokens": "263537", "train_nsentences": "1753.71", "train_wps": "139168", "train_ups": "0.53", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "84264", "train_lr": "0.000428989", "train_gnorm": "0.263", "train_loss_scale": "1", "train_train_wall": "575", "train_gb_free": "40", "train_wall": "156802"}
[2024-10-06 13:43:29,702][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 13:43:29,715][fairseq.trainer][INFO] - begin training epoch 177
[2024-10-06 13:43:29,716][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 13:51:35,438][train_inner][INFO] - {"epoch": 177, "update": 176.284, "loss": "0.848", "ntokens": "262844", "nsentences": "1736.44", "wps": "93799.1", "ups": "0.36", "wpb": "262844", "bsz": "1736.4", "num_updates": "84400", "lr": "0.000428804", "gnorm": "0.253", "loss_scale": "2", "train_wall": "216", "gb_free": "40", "wall": "157288"}
[2024-10-06 13:55:16,328][train_inner][INFO] - {"epoch": 177, "update": 176.701, "loss": "0.845", "ntokens": "264094", "nsentences": "1763.55", "wps": "239125", "ups": "0.91", "wpb": "264094", "bsz": "1763.5", "num_updates": "84600", "lr": "0.000428533", "gnorm": "0.261", "loss_scale": "2", "train_wall": "216", "gb_free": "40", "wall": "157508"}
[2024-10-06 13:57:54,680][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2024-10-06 13:57:54,700][train][INFO] - {"epoch": 177, "train_loss": "0.847", "train_ntokens": "263538", "train_nsentences": "1753.71", "train_wps": "145913", "train_ups": "0.55", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "84743", "train_lr": "0.000428338", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "512", "train_gb_free": "39.6", "train_wall": "157667"}
[2024-10-06 13:57:54,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 13:57:54,840][fairseq.trainer][INFO] - begin training epoch 178
[2024-10-06 13:57:54,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 14:05:00,121][train_inner][INFO] - {"epoch": 178, "update": 177.119, "loss": "0.849", "ntokens": "262970", "nsentences": "1749.8", "wps": "90091", "ups": "0.34", "wpb": "262970", "bsz": "1749.8", "num_updates": "84800", "lr": "0.000428261", "gnorm": "0.263", "loss_scale": "2", "train_wall": "194", "gb_free": "40", "wall": "158092"}
[2024-10-06 14:08:49,065][train_inner][INFO] - {"epoch": 178, "update": 177.537, "loss": "0.844", "ntokens": "264239", "nsentences": "1743.23", "wps": "230842", "ups": "0.87", "wpb": "264239", "bsz": "1743.2", "num_updates": "85000", "lr": "0.000427989", "gnorm": "0.267", "loss_scale": "2", "train_wall": "160", "gb_free": "39.7", "wall": "158321"}
[2024-10-06 14:12:29,027][train_inner][INFO] - {"epoch": 178, "update": 177.954, "loss": "0.848", "ntokens": "263849", "nsentences": "1748.51", "wps": "239923", "ups": "0.91", "wpb": "263849", "bsz": "1748.5", "num_updates": "85200", "lr": "0.000427717", "gnorm": "0.251", "loss_scale": "2", "train_wall": "138", "gb_free": "39.3", "wall": "158541"}
[2024-10-06 14:13:06,687][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2024-10-06 14:13:06,730][train][INFO] - {"epoch": 178, "train_loss": "0.847", "train_ntokens": "263539", "train_nsentences": "1753.71", "train_wps": "138414", "train_ups": "0.53", "train_wpb": "263539", "train_bsz": "1753.7", "train_num_updates": "85222", "train_lr": "0.000427688", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "369", "train_gb_free": "39.6", "train_wall": "158579"}
[2024-10-06 14:13:06,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 14:13:06,908][fairseq.trainer][INFO] - begin training epoch 179
[2024-10-06 14:13:06,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 14:22:03,655][train_inner][INFO] - {"epoch": 179, "update": 178.372, "loss": "0.847", "ntokens": "262705", "nsentences": "1769.9", "wps": "91435.9", "ups": "0.35", "wpb": "262705", "bsz": "1769.9", "num_updates": "85400", "lr": "0.000427446", "gnorm": "0.263", "loss_scale": "2", "train_wall": "226", "gb_free": "39.3", "wall": "159116"}
[2024-10-06 14:25:58,729][train_inner][INFO] - {"epoch": 179, "update": 178.789, "loss": "0.846", "ntokens": "263978", "nsentences": "1769.06", "wps": "224597", "ups": "0.85", "wpb": "263978", "bsz": "1769.1", "num_updates": "85600", "lr": "0.000427174", "gnorm": "0.257", "loss_scale": "2", "train_wall": "230", "gb_free": "39.2", "wall": "159351"}
[2024-10-06 14:27:56,886][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2024-10-06 14:27:56,904][train][INFO] - {"epoch": 179, "train_loss": "0.846", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "141803", "train_ups": "0.54", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "85701", "train_lr": "0.000427037", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.2", "train_wall": "159469"}
[2024-10-06 14:27:57,082][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 14:27:57,108][fairseq.trainer][INFO] - begin training epoch 180
[2024-10-06 14:27:57,108][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 14:35:30,784][train_inner][INFO] - {"epoch": 180, "update": 179.207, "loss": "0.845", "ntokens": "262981", "nsentences": "1737.44", "wps": "91944", "ups": "0.35", "wpb": "262981", "bsz": "1737.4", "num_updates": "85800", "lr": "0.000426902", "gnorm": "0.269", "loss_scale": "2", "train_wall": "205", "gb_free": "39.7", "wall": "159923"}
[2024-10-06 14:39:20,287][train_inner][INFO] - {"epoch": 180, "update": 179.624, "loss": "0.846", "ntokens": "264128", "nsentences": "1746.24", "wps": "230194", "ups": "0.87", "wpb": "264128", "bsz": "1746.2", "num_updates": "86000", "lr": "0.00042663", "gnorm": "0.262", "loss_scale": "2", "train_wall": "156", "gb_free": "39.6", "wall": "160152"}
[2024-10-06 14:42:53,695][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 86180 updates
[2024-10-06 14:42:53,701][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 14:43:04,090][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 14:43:04,263][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 180 @ 86180 updates, score None) (writing took 10.567819467745721 seconds)
[2024-10-06 14:43:04,279][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2024-10-06 14:43:04,281][train][INFO] - {"epoch": 180, "train_loss": "0.846", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "139115", "train_ups": "0.53", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "86180", "train_lr": "0.000426386", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "398", "train_gb_free": "40.1", "train_wall": "160376"}
[2024-10-06 14:43:04,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 14:43:04,423][fairseq.trainer][INFO] - begin training epoch 181
[2024-10-06 14:43:04,424][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 14:49:47,849][train_inner][INFO] - {"epoch": 181, "update": 180.042, "loss": "0.847", "ntokens": "262801", "nsentences": "1739.7", "wps": "83756.1", "ups": "0.32", "wpb": "262801", "bsz": "1739.7", "num_updates": "86200", "lr": "0.000426359", "gnorm": "0.261", "loss_scale": "2", "train_wall": "189", "gb_free": "39.6", "wall": "160780"}
[2024-10-06 14:53:25,938][train_inner][INFO] - {"epoch": 181, "update": 180.459, "loss": "0.843", "ntokens": "264296", "nsentences": "1736.5", "wps": "242406", "ups": "0.92", "wpb": "264296", "bsz": "1736.5", "num_updates": "86400", "lr": "0.000426087", "gnorm": "0.261", "loss_scale": "2", "train_wall": "213", "gb_free": "39.2", "wall": "160998"}
[2024-10-06 14:57:47,682][train_inner][INFO] - {"epoch": 181, "update": 180.877, "loss": "0.848", "ntokens": "263798", "nsentences": "1787.36", "wps": "201584", "ups": "0.76", "wpb": "263798", "bsz": "1787.4", "num_updates": "86600", "lr": "0.000425815", "gnorm": "0.282", "loss_scale": "4", "train_wall": "256", "gb_free": "40.9", "wall": "161260"}
[2024-10-06 14:58:52,754][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2024-10-06 14:58:52,786][train][INFO] - {"epoch": 181, "train_loss": "0.846", "train_ntokens": "263623", "train_nsentences": "1753.71", "train_wps": "133133", "train_ups": "0.51", "train_wpb": "263623", "train_bsz": "1753.7", "train_num_updates": "86659", "train_lr": "0.000425735", "train_gnorm": "0.268", "train_loss_scale": "4", "train_train_wall": "571", "train_gb_free": "39.8", "train_wall": "161325"}
[2024-10-06 14:58:53,015][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 14:58:53,053][fairseq.trainer][INFO] - begin training epoch 182
[2024-10-06 14:58:53,054][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 15:06:07,080][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 15:07:36,607][train_inner][INFO] - {"epoch": 182, "update": 181.296, "loss": "0.847", "ntokens": "262954", "nsentences": "1756.2", "wps": "89300.5", "ups": "0.34", "wpb": "262954", "bsz": "1756.2", "num_updates": "86800", "lr": "0.000425543", "gnorm": "0.265", "loss_scale": "2", "train_wall": "234", "gb_free": "40.7", "wall": "161849"}
[2024-10-06 15:11:24,288][train_inner][INFO] - {"epoch": 182, "update": 181.714, "loss": "0.846", "ntokens": "263828", "nsentences": "1799.4", "wps": "231766", "ups": "0.88", "wpb": "263828", "bsz": "1799.4", "num_updates": "87000", "lr": "0.000425272", "gnorm": "0.265", "loss_scale": "2", "train_wall": "221", "gb_free": "39.2", "wall": "162076"}
[2024-10-06 15:14:00,564][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2024-10-06 15:14:00,619][train][INFO] - {"epoch": 182, "train_loss": "0.845", "train_ntokens": "263610", "train_nsentences": "1754.78", "train_wps": "138802", "train_ups": "0.53", "train_wpb": "263610", "train_bsz": "1754.8", "train_num_updates": "87137", "train_lr": "0.000425086", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.2", "train_wall": "162233"}
[2024-10-06 15:14:00,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 15:14:00,858][fairseq.trainer][INFO] - begin training epoch 183
[2024-10-06 15:14:00,859][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 15:21:30,057][train_inner][INFO] - {"epoch": 183, "update": 182.132, "loss": "0.842", "ntokens": "263251", "nsentences": "1696.45", "wps": "86916.9", "ups": "0.33", "wpb": "263251", "bsz": "1696.5", "num_updates": "87200", "lr": "0.000425", "gnorm": "0.268", "loss_scale": "2", "train_wall": "234", "gb_free": "39.2", "wall": "162682"}
[2024-10-06 15:25:08,643][train_inner][INFO] - {"epoch": 183, "update": 182.549, "loss": "0.844", "ntokens": "263730", "nsentences": "1766.96", "wps": "241326", "ups": "0.92", "wpb": "263730", "bsz": "1767", "num_updates": "87400", "lr": "0.000424728", "gnorm": "0.256", "loss_scale": "2", "train_wall": "213", "gb_free": "40.3", "wall": "162901"}
[2024-10-06 15:28:53,970][train_inner][INFO] - {"epoch": 183, "update": 182.967, "loss": "0.846", "ntokens": "263927", "nsentences": "1751.4", "wps": "234271", "ups": "0.89", "wpb": "263927", "bsz": "1751.4", "num_updates": "87600", "lr": "0.000424457", "gnorm": "0.268", "loss_scale": "2", "train_wall": "221", "gb_free": "40", "wall": "163126"}
[2024-10-06 15:29:26,354][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2024-10-06 15:29:26,357][train][INFO] - {"epoch": 183, "train_loss": "0.845", "train_ntokens": "263410", "train_nsentences": "1753.71", "train_wps": "136298", "train_ups": "0.52", "train_wpb": "263410", "train_bsz": "1753.7", "train_num_updates": "87616", "train_lr": "0.000424435", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.8", "train_wall": "163159"}
[2024-10-06 15:29:26,470][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 15:29:26,475][fairseq.trainer][INFO] - begin training epoch 184
[2024-10-06 15:29:26,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 15:39:24,742][train_inner][INFO] - {"epoch": 184, "update": 183.384, "loss": "0.844", "ntokens": "262840", "nsentences": "1757.18", "wps": "83340", "ups": "0.32", "wpb": "262840", "bsz": "1757.2", "num_updates": "87800", "lr": "0.000424185", "gnorm": "0.278", "loss_scale": "2", "train_wall": "249", "gb_free": "39.1", "wall": "163757"}
[2024-10-06 15:43:14,412][train_inner][INFO] - {"epoch": 184, "update": 183.802, "loss": "0.843", "ntokens": "264039", "nsentences": "1747.3", "wps": "229946", "ups": "0.87", "wpb": "264039", "bsz": "1747.3", "num_updates": "88000", "lr": "0.000423913", "gnorm": "0.275", "loss_scale": "2", "train_wall": "225", "gb_free": "39.3", "wall": "163987"}
[2024-10-06 15:44:55,031][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2024-10-06 15:44:55,048][train][INFO] - {"epoch": 184, "train_loss": "0.845", "train_ntokens": "263517", "train_nsentences": "1753.71", "train_wps": "135920", "train_ups": "0.52", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "88095", "train_lr": "0.000423784", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "540", "train_gb_free": "39.6", "train_wall": "164087"}
[2024-10-06 15:44:55,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 15:44:55,179][fairseq.trainer][INFO] - begin training epoch 185
[2024-10-06 15:44:55,180][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 15:53:24,015][train_inner][INFO] - {"epoch": 185, "update": 184.219, "loss": "0.848", "ntokens": "262701", "nsentences": "1761.52", "wps": "86190.8", "ups": "0.33", "wpb": "262701", "bsz": "1761.5", "num_updates": "88200", "lr": "0.000423641", "gnorm": "0.269", "loss_scale": "2", "train_wall": "221", "gb_free": "39.1", "wall": "164596"}
[2024-10-06 15:57:08,794][train_inner][INFO] - {"epoch": 185, "update": 184.637, "loss": "0.841", "ntokens": "263952", "nsentences": "1763.57", "wps": "234863", "ups": "0.89", "wpb": "263952", "bsz": "1763.6", "num_updates": "88400", "lr": "0.00042337", "gnorm": "0.289", "loss_scale": "2", "train_wall": "220", "gb_free": "39.2", "wall": "164821"}
[2024-10-06 16:00:25,022][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2024-10-06 16:00:25,037][train][INFO] - {"epoch": 185, "train_loss": "0.844", "train_ntokens": "263461", "train_nsentences": "1753.71", "train_wps": "135700", "train_ups": "0.52", "train_wpb": "263461", "train_bsz": "1753.7", "train_num_updates": "88574", "train_lr": "0.000423133", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "534", "train_gb_free": "39.6", "train_wall": "165017"}
[2024-10-06 16:00:25,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 16:00:25,277][fairseq.trainer][INFO] - begin training epoch 186
[2024-10-06 16:00:25,278][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 16:06:46,199][train_inner][INFO] - {"epoch": 186, "update": 185.054, "loss": "0.846", "ntokens": "262874", "nsentences": "1740.99", "wps": "91055.2", "ups": "0.35", "wpb": "262874", "bsz": "1741", "num_updates": "88600", "lr": "0.000423098", "gnorm": "0.267", "loss_scale": "2", "train_wall": "245", "gb_free": "40.1", "wall": "165398"}
[2024-10-06 16:10:35,622][train_inner][INFO] - {"epoch": 186, "update": 185.472, "loss": "0.842", "ntokens": "263988", "nsentences": "1765.38", "wps": "230152", "ups": "0.87", "wpb": "263988", "bsz": "1765.4", "num_updates": "88800", "lr": "0.000422826", "gnorm": "0.247", "loss_scale": "4", "train_wall": "224", "gb_free": "39.2", "wall": "165628"}
[2024-10-06 16:14:58,792][train_inner][INFO] - {"epoch": 186, "update": 185.889, "loss": "0.842", "ntokens": "264435", "nsentences": "1716.59", "wps": "200966", "ups": "0.76", "wpb": "264435", "bsz": "1716.6", "num_updates": "89000", "lr": "0.000422554", "gnorm": "0.269", "loss_scale": "4", "train_wall": "258", "gb_free": "39.7", "wall": "165891"}
[2024-10-06 16:15:59,227][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2024-10-06 16:15:59,256][train][INFO] - {"epoch": 186, "train_loss": "0.843", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "135156", "train_ups": "0.51", "train_wpb": "263599", "train_bsz": "1753.7", "train_num_updates": "89053", "train_lr": "0.000422482", "train_gnorm": "0.257", "train_loss_scale": "4", "train_train_wall": "595", "train_gb_free": "40.5", "train_wall": "165951"}
[2024-10-06 16:15:59,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 16:15:59,386][fairseq.trainer][INFO] - begin training epoch 187
[2024-10-06 16:15:59,386][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 16:24:12,424][train_inner][INFO] - {"epoch": 187, "update": 186.307, "loss": "0.843", "ntokens": "262805", "nsentences": "1752.96", "wps": "94940.9", "ups": "0.36", "wpb": "262805", "bsz": "1753", "num_updates": "89200", "lr": "0.000422283", "gnorm": "0.269", "loss_scale": "4", "train_wall": "218", "gb_free": "39.2", "wall": "166445"}
[2024-10-06 16:27:48,138][train_inner][INFO] - {"epoch": 187, "update": 186.724, "loss": "0.843", "ntokens": "263959", "nsentences": "1754.28", "wps": "244764", "ups": "0.93", "wpb": "263959", "bsz": "1754.3", "num_updates": "89400", "lr": "0.000422011", "gnorm": "0.268", "loss_scale": "4", "train_wall": "210", "gb_free": "39.6", "wall": "166660"}
[2024-10-06 16:30:12,371][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2024-10-06 16:30:12,412][train][INFO] - {"epoch": 187, "train_loss": "0.843", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "147954", "train_ups": "0.56", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "89532", "train_lr": "0.000421832", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "510", "train_gb_free": "39.3", "train_wall": "166805"}
[2024-10-06 16:30:12,598][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 16:30:12,629][fairseq.trainer][INFO] - begin training epoch 188
[2024-10-06 16:30:12,630][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 16:37:10,602][train_inner][INFO] - {"epoch": 188, "update": 187.142, "loss": "0.846", "ntokens": "262779", "nsentences": "1777.85", "wps": "93439.7", "ups": "0.36", "wpb": "262779", "bsz": "1777.9", "num_updates": "89600", "lr": "0.000421739", "gnorm": "0.279", "loss_scale": "4", "train_wall": "235", "gb_free": "39.6", "wall": "167223"}
[2024-10-06 16:40:54,822][train_inner][INFO] - {"epoch": 188, "update": 187.559, "loss": "0.84", "ntokens": "264127", "nsentences": "1751.48", "wps": "235611", "ups": "0.89", "wpb": "264127", "bsz": "1751.5", "num_updates": "89800", "lr": "0.000421467", "gnorm": "0.255", "loss_scale": "4", "train_wall": "219", "gb_free": "40.1", "wall": "167447"}
[2024-10-06 16:44:27,542][train_inner][INFO] - {"epoch": 188, "update": 187.977, "loss": "0.845", "ntokens": "263915", "nsentences": "1750.34", "wps": "248174", "ups": "0.94", "wpb": "263915", "bsz": "1750.3", "num_updates": "90000", "lr": "0.000421196", "gnorm": "0.278", "loss_scale": "4", "train_wall": "208", "gb_free": "39.2", "wall": "167660"}
[2024-10-06 16:45:09,695][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2024-10-06 16:45:09,699][train][INFO] - {"epoch": 188, "train_loss": "0.843", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "140677", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "90011", "train_lr": "0.000421181", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "563", "train_gb_free": "39.7", "train_wall": "167702"}
[2024-10-06 16:45:09,761][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 16:45:09,768][fairseq.trainer][INFO] - begin training epoch 189
[2024-10-06 16:45:09,768][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 16:54:08,417][train_inner][INFO] - {"epoch": 189, "update": 188.395, "loss": "0.84", "ntokens": "263235", "nsentences": "1721.29", "wps": "90636.9", "ups": "0.34", "wpb": "263235", "bsz": "1721.3", "num_updates": "90200", "lr": "0.000420924", "gnorm": "0.26", "loss_scale": "4", "train_wall": "243", "gb_free": "40.1", "wall": "168241"}
[2024-10-06 16:58:20,265][train_inner][INFO] - {"epoch": 189, "update": 188.812, "loss": "0.845", "ntokens": "263753", "nsentences": "1788.36", "wps": "209462", "ups": "0.79", "wpb": "263753", "bsz": "1788.4", "num_updates": "90400", "lr": "0.000420652", "gnorm": "0.286", "loss_scale": "4", "train_wall": "246", "gb_free": "39.3", "wall": "168492"}
[2024-10-06 16:59:53,571][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2024-10-06 16:59:53,589][train][INFO] - {"epoch": 189, "train_loss": "0.843", "train_ntokens": "263625", "train_nsentences": "1753.71", "train_wps": "142868", "train_ups": "0.54", "train_wpb": "263625", "train_bsz": "1753.7", "train_num_updates": "90490", "train_lr": "0.00042053", "train_gnorm": "0.268", "train_loss_scale": "4", "train_train_wall": "539", "train_gb_free": "40.1", "train_wall": "168586"}
[2024-10-06 16:59:53,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 16:59:53,725][fairseq.trainer][INFO] - begin training epoch 190
[2024-10-06 16:59:53,726][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 17:07:26,463][train_inner][INFO] - {"epoch": 190, "update": 189.23, "loss": "0.842", "ntokens": "263135", "nsentences": "1719.48", "wps": "96352.5", "ups": "0.37", "wpb": "263135", "bsz": "1719.5", "num_updates": "90600", "lr": "0.00042038", "gnorm": "0.257", "loss_scale": "4", "train_wall": "194", "gb_free": "39.7", "wall": "169039"}
[2024-10-06 17:10:31,581][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 17:11:13,945][train_inner][INFO] - {"epoch": 190, "update": 189.649, "loss": "0.841", "ntokens": "263841", "nsentences": "1754.06", "wps": "231972", "ups": "0.88", "wpb": "263841", "bsz": "1754.1", "num_updates": "90800", "lr": "0.000420109", "gnorm": "0.271", "loss_scale": "2", "train_wall": "222", "gb_free": "40.8", "wall": "169266"}
[2024-10-06 17:14:35,007][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 90968 updates
[2024-10-06 17:14:35,008][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 17:14:45,842][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 17:14:45,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 190 @ 90968 updates, score None) (writing took 10.966861716471612 seconds)
[2024-10-06 17:14:45,975][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2024-10-06 17:14:45,979][train][INFO] - {"epoch": 190, "train_loss": "0.842", "train_ntokens": "263549", "train_nsentences": "1753.81", "train_wps": "141168", "train_ups": "0.54", "train_wpb": "263549", "train_bsz": "1753.8", "train_num_updates": "90968", "train_lr": "0.00041988", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "519", "train_gb_free": "39.7", "train_wall": "169478"}
[2024-10-06 17:14:46,048][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 17:14:46,109][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-06 17:14:46,110][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 17:20:50,088][train_inner][INFO] - {"epoch": 191, "update": 190.067, "loss": "0.846", "ntokens": "262887", "nsentences": "1782.15", "wps": "91258.8", "ups": "0.35", "wpb": "262887", "bsz": "1782.2", "num_updates": "91000", "lr": "0.000419837", "gnorm": "0.263", "loss_scale": "2", "train_wall": "240", "gb_free": "39.6", "wall": "169842"}
[2024-10-06 17:24:31,459][train_inner][INFO] - {"epoch": 191, "update": 190.484, "loss": "0.837", "ntokens": "264333", "nsentences": "1723.68", "wps": "238821", "ups": "0.9", "wpb": "264333", "bsz": "1723.7", "num_updates": "91200", "lr": "0.000419565", "gnorm": "0.276", "loss_scale": "2", "train_wall": "216", "gb_free": "39.6", "wall": "170064"}
[2024-10-06 17:28:18,085][train_inner][INFO] - {"epoch": 191, "update": 190.902, "loss": "0.846", "ntokens": "263929", "nsentences": "1767.36", "wps": "232935", "ups": "0.88", "wpb": "263929", "bsz": "1767.4", "num_updates": "91400", "lr": "0.000419293", "gnorm": "0.262", "loss_scale": "2", "train_wall": "221", "gb_free": "39.3", "wall": "170290"}
[2024-10-06 17:29:35,584][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-06 17:29:35,590][train][INFO] - {"epoch": 191, "train_loss": "0.842", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "141890", "train_ups": "0.54", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "91447", "train_lr": "0.00041923", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "39.8", "train_wall": "170368"}
[2024-10-06 17:29:35,717][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 17:29:35,750][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-06 17:29:35,751][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 17:37:45,763][train_inner][INFO] - {"epoch": 192, "update": 191.319, "loss": "0.842", "ntokens": "262236", "nsentences": "1800.74", "wps": "92394.1", "ups": "0.35", "wpb": "262236", "bsz": "1800.7", "num_updates": "91600", "lr": "0.000419022", "gnorm": "0.273", "loss_scale": "2", "train_wall": "240", "gb_free": "40", "wall": "170858"}
[2024-10-06 17:41:36,558][train_inner][INFO] - {"epoch": 192, "update": 191.737, "loss": "0.838", "ntokens": "264254", "nsentences": "1714.78", "wps": "229000", "ups": "0.87", "wpb": "264254", "bsz": "1714.8", "num_updates": "91800", "lr": "0.00041875", "gnorm": "0.26", "loss_scale": "2", "train_wall": "225", "gb_free": "40.3", "wall": "171089"}
[2024-10-06 17:44:22,430][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-06 17:44:22,470][train][INFO] - {"epoch": 192, "train_loss": "0.841", "train_ntokens": "263387", "train_nsentences": "1753.71", "train_wps": "142257", "train_ups": "0.54", "train_wpb": "263387", "train_bsz": "1753.7", "train_num_updates": "91926", "train_lr": "0.000418579", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "40.5", "train_wall": "171255"}
[2024-10-06 17:44:22,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 17:44:22,665][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-06 17:44:22,666][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 17:51:11,554][train_inner][INFO] - {"epoch": 193, "update": 192.154, "loss": "0.842", "ntokens": "262793", "nsentences": "1759.91", "wps": "91408.2", "ups": "0.35", "wpb": "262793", "bsz": "1759.9", "num_updates": "92000", "lr": "0.000418478", "gnorm": "0.259", "loss_scale": "2", "train_wall": "255", "gb_free": "39.2", "wall": "171664"}
[2024-10-06 17:54:39,234][train_inner][INFO] - {"epoch": 193, "update": 192.572, "loss": "0.841", "ntokens": "264413", "nsentences": "1709.97", "wps": "254651", "ups": "0.96", "wpb": "264413", "bsz": "1710", "num_updates": "92200", "lr": "0.000418207", "gnorm": "0.259", "loss_scale": "2", "train_wall": "202", "gb_free": "40.5", "wall": "171871"}
[2024-10-06 17:58:27,822][train_inner][INFO] - {"epoch": 193, "update": 192.99, "loss": "0.844", "ntokens": "263577", "nsentences": "1807.41", "wps": "230671", "ups": "0.88", "wpb": "263577", "bsz": "1807.4", "num_updates": "92400", "lr": "0.000417935", "gnorm": "0.286", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "172100"}
[2024-10-06 17:58:49,618][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-06 17:58:49,634][train][INFO] - {"epoch": 193, "train_loss": "0.842", "train_ntokens": "263575", "train_nsentences": "1753.71", "train_wps": "145595", "train_ups": "0.55", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "92405", "train_lr": "0.000417928", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "538", "train_gb_free": "39.7", "train_wall": "172122"}
[2024-10-06 17:58:49,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 17:58:49,743][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-06 17:58:49,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 18:08:06,606][train_inner][INFO] - {"epoch": 194, "update": 193.407, "loss": "0.84", "ntokens": "262576", "nsentences": "1779.97", "wps": "90749.5", "ups": "0.35", "wpb": "262576", "bsz": "1780", "num_updates": "92600", "lr": "0.000417663", "gnorm": "0.278", "loss_scale": "2", "train_wall": "177", "gb_free": "39.7", "wall": "172679"}
[2024-10-06 18:12:00,529][train_inner][INFO] - {"epoch": 194, "update": 193.825, "loss": "0.84", "ntokens": "264536", "nsentences": "1710.41", "wps": "226184", "ups": "0.86", "wpb": "264536", "bsz": "1710.4", "num_updates": "92800", "lr": "0.000417391", "gnorm": "0.236", "loss_scale": "2", "train_wall": "229", "gb_free": "39.3", "wall": "172913"}
[2024-10-06 18:13:41,460][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-06 18:13:41,477][train][INFO] - {"epoch": 194, "train_loss": "0.841", "train_ntokens": "263593", "train_nsentences": "1753.71", "train_wps": "141574", "train_ups": "0.54", "train_wpb": "263593", "train_bsz": "1753.7", "train_num_updates": "92884", "train_lr": "0.000417277", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "484", "train_gb_free": "39.6", "train_wall": "173014"}
[2024-10-06 18:13:41,607][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 18:13:41,621][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-06 18:13:41,622][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 18:21:44,129][train_inner][INFO] - {"epoch": 195, "update": 194.242, "loss": "0.839", "ntokens": "263115", "nsentences": "1730.16", "wps": "90171.1", "ups": "0.34", "wpb": "263115", "bsz": "1730.2", "num_updates": "93000", "lr": "0.00041712", "gnorm": "0.255", "loss_scale": "4", "train_wall": "249", "gb_free": "39.6", "wall": "173496"}
[2024-10-06 18:25:42,045][train_inner][INFO] - {"epoch": 195, "update": 194.66, "loss": "0.841", "ntokens": "263783", "nsentences": "1770.55", "wps": "221758", "ups": "0.84", "wpb": "263783", "bsz": "1770.5", "num_updates": "93200", "lr": "0.000416848", "gnorm": "0.26", "loss_scale": "4", "train_wall": "232", "gb_free": "39.6", "wall": "173734"}
[2024-10-06 18:29:14,644][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-06 18:29:14,694][train][INFO] - {"epoch": 195, "train_loss": "0.84", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "135260", "train_ups": "0.51", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "93363", "train_lr": "0.000416626", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "590", "train_gb_free": "39.6", "train_wall": "173947"}
[2024-10-06 18:29:14,871][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 18:29:14,891][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-06 18:29:14,891][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 18:35:55,215][train_inner][INFO] - {"epoch": 196, "update": 195.077, "loss": "0.842", "ntokens": "262625", "nsentences": "1778.09", "wps": "85662.9", "ups": "0.33", "wpb": "262625", "bsz": "1778.1", "num_updates": "93400", "lr": "0.000416576", "gnorm": "0.269", "loss_scale": "4", "train_wall": "260", "gb_free": "39.6", "wall": "174347"}
[2024-10-06 18:39:17,767][train_inner][INFO] - {"epoch": 196, "update": 195.495, "loss": "0.837", "ntokens": "264444", "nsentences": "1707.37", "wps": "261126", "ups": "0.99", "wpb": "264444", "bsz": "1707.4", "num_updates": "93600", "lr": "0.000416304", "gnorm": "0.274", "loss_scale": "4", "train_wall": "196", "gb_free": "40", "wall": "174550"}
[2024-10-06 18:43:29,499][train_inner][INFO] - {"epoch": 196, "update": 195.912, "loss": "0.843", "ntokens": "263753", "nsentences": "1794.82", "wps": "209574", "ups": "0.79", "wpb": "263753", "bsz": "1794.8", "num_updates": "93800", "lr": "0.000416033", "gnorm": "0.255", "loss_scale": "4", "train_wall": "245", "gb_free": "39.2", "wall": "174802"}
[2024-10-06 18:44:30,644][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-06 18:44:30,670][train][INFO] - {"epoch": 196, "train_loss": "0.84", "train_ntokens": "263613", "train_nsentences": "1753.71", "train_wps": "137856", "train_ups": "0.52", "train_wpb": "263613", "train_bsz": "1753.7", "train_num_updates": "93842", "train_lr": "0.000415976", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "554", "train_gb_free": "39.3", "train_wall": "174863"}
[2024-10-06 18:44:30,760][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 18:44:30,784][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-06 18:44:30,785][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 18:54:06,596][train_inner][INFO] - {"epoch": 197, "update": 196.33, "loss": "0.839", "ntokens": "262800", "nsentences": "1772.49", "wps": "82501.1", "ups": "0.31", "wpb": "262800", "bsz": "1772.5", "num_updates": "94000", "lr": "0.000415761", "gnorm": "0.256", "loss_scale": "4", "train_wall": "209", "gb_free": "39.2", "wall": "175439"}
[2024-10-06 18:58:06,264][train_inner][INFO] - {"epoch": 197, "update": 196.747, "loss": "0.842", "ntokens": "263788", "nsentences": "1778.89", "wps": "220146", "ups": "0.83", "wpb": "263788", "bsz": "1778.9", "num_updates": "94200", "lr": "0.000415489", "gnorm": "0.259", "loss_scale": "4", "train_wall": "234", "gb_free": "39.3", "wall": "175678"}
[2024-10-06 19:00:11,350][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-06 19:00:11,367][train][INFO] - {"epoch": 197, "train_loss": "0.84", "train_ntokens": "263549", "train_nsentences": "1753.71", "train_wps": "134199", "train_ups": "0.51", "train_wpb": "263549", "train_bsz": "1753.7", "train_num_updates": "94321", "train_lr": "0.000415325", "train_gnorm": "0.257", "train_loss_scale": "4", "train_train_wall": "504", "train_gb_free": "39.6", "train_wall": "175804"}
[2024-10-06 19:00:11,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 19:00:11,615][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-06 19:00:11,616][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 19:08:03,786][train_inner][INFO] - {"epoch": 198, "update": 197.165, "loss": "0.84", "ntokens": "263079", "nsentences": "1734.48", "wps": "88060.3", "ups": "0.33", "wpb": "263079", "bsz": "1734.5", "num_updates": "94400", "lr": "0.000415217", "gnorm": "0.265", "loss_scale": "4", "train_wall": "239", "gb_free": "39.3", "wall": "176276"}
[2024-10-06 19:12:03,174][train_inner][INFO] - {"epoch": 198, "update": 197.582, "loss": "0.838", "ntokens": "263966", "nsentences": "1745.46", "wps": "220545", "ups": "0.84", "wpb": "263966", "bsz": "1745.5", "num_updates": "94600", "lr": "0.000414946", "gnorm": "0.268", "loss_scale": "4", "train_wall": "234", "gb_free": "40.3", "wall": "176515"}
[2024-10-06 19:12:06,572][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 19:15:47,678][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-06 19:15:47,711][train][INFO] - {"epoch": 198, "train_loss": "0.839", "train_ntokens": "263381", "train_nsentences": "1754.47", "train_wps": "134456", "train_ups": "0.51", "train_wpb": "263381", "train_bsz": "1754.5", "train_num_updates": "94799", "train_lr": "0.000414675", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.6", "train_wall": "176740"}
[2024-10-06 19:15:47,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 19:15:47,826][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-06 19:15:47,826][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 19:21:53,835][train_inner][INFO] - {"epoch": 199, "update": 198.002, "loss": "0.839", "ntokens": "262726", "nsentences": "1736.2", "wps": "88961.7", "ups": "0.34", "wpb": "262726", "bsz": "1736.2", "num_updates": "94800", "lr": "0.000414674", "gnorm": "0.269", "loss_scale": "2", "train_wall": "224", "gb_free": "39.6", "wall": "177106"}
[2024-10-06 19:25:29,789][train_inner][INFO] - {"epoch": 199, "update": 198.42, "loss": "0.838", "ntokens": "263795", "nsentences": "1788.93", "wps": "244337", "ups": "0.93", "wpb": "263795", "bsz": "1788.9", "num_updates": "95000", "lr": "0.000414402", "gnorm": "0.261", "loss_scale": "2", "train_wall": "209", "gb_free": "39.6", "wall": "177322"}
[2024-10-06 19:29:18,407][train_inner][INFO] - {"epoch": 199, "update": 198.837, "loss": "0.839", "ntokens": "264097", "nsentences": "1748.18", "wps": "231050", "ups": "0.87", "wpb": "264097", "bsz": "1748.2", "num_updates": "95200", "lr": "0.00041413", "gnorm": "0.265", "loss_scale": "2", "train_wall": "223", "gb_free": "39.7", "wall": "177551"}
[2024-10-06 19:30:57,857][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-06 19:30:57,893][train][INFO] - {"epoch": 199, "train_loss": "0.839", "train_ntokens": "263574", "train_nsentences": "1753.71", "train_wps": "138712", "train_ups": "0.53", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "95278", "train_lr": "0.000414024", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "40", "train_wall": "177650"}
[2024-10-06 19:30:58,036][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 19:30:58,043][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-06 19:30:58,044][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 19:39:03,045][train_inner][INFO] - {"epoch": 200, "update": 199.255, "loss": "0.838", "ntokens": "263244", "nsentences": "1706.69", "wps": "90057.3", "ups": "0.34", "wpb": "263244", "bsz": "1706.7", "num_updates": "95400", "lr": "0.000413859", "gnorm": "0.255", "loss_scale": "2", "train_wall": "226", "gb_free": "39.6", "wall": "178135"}
[2024-10-06 19:43:00,957][train_inner][INFO] - {"epoch": 200, "update": 199.672, "loss": "0.838", "ntokens": "263715", "nsentences": "1770.91", "wps": "221704", "ups": "0.84", "wpb": "263716", "bsz": "1770.9", "num_updates": "95600", "lr": "0.000413587", "gnorm": "0.264", "loss_scale": "2", "train_wall": "232", "gb_free": "39.7", "wall": "178373"}
[2024-10-06 19:45:43,012][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 95757 updates
[2024-10-06 19:45:43,015][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 19:45:59,215][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 19:45:59,553][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 200 @ 95757 updates, score None) (writing took 16.54036288615316 seconds)
[2024-10-06 19:45:59,587][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-06 19:45:59,599][train][INFO] - {"epoch": 200, "train_loss": "0.839", "train_ntokens": "263396", "train_nsentences": "1753.71", "train_wps": "139922", "train_ups": "0.53", "train_wpb": "263396", "train_bsz": "1753.7", "train_num_updates": "95757", "train_lr": "0.000413374", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "521", "train_gb_free": "39.6", "train_wall": "178552"}
[2024-10-06 19:45:59,745][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 19:45:59,784][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-06 19:45:59,785][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 19:52:59,686][train_inner][INFO] - {"epoch": 201, "update": 200.09, "loss": "0.843", "ntokens": "262622", "nsentences": "1754.87", "wps": "87727.9", "ups": "0.33", "wpb": "262622", "bsz": "1754.9", "num_updates": "95800", "lr": "0.000413315", "gnorm": "0.25", "loss_scale": "2", "train_wall": "222", "gb_free": "39.6", "wall": "178972"}
[2024-10-06 19:56:20,310][train_inner][INFO] - {"epoch": 201, "update": 200.507, "loss": "0.834", "ntokens": "264184", "nsentences": "1709.76", "wps": "263402", "ups": "1", "wpb": "264184", "bsz": "1709.8", "num_updates": "96000", "lr": "0.000413043", "gnorm": "0.266", "loss_scale": "2", "train_wall": "195", "gb_free": "39.3", "wall": "179172"}
[2024-10-06 20:00:28,634][train_inner][INFO] - {"epoch": 201, "update": 200.925, "loss": "0.842", "ntokens": "263702", "nsentences": "1795.27", "wps": "212392", "ups": "0.81", "wpb": "263702", "bsz": "1795.3", "num_updates": "96200", "lr": "0.000412772", "gnorm": "0.266", "loss_scale": "2", "train_wall": "243", "gb_free": "39.6", "wall": "179421"}
[2024-10-06 20:01:02,616][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-10-06 20:01:02,622][train][INFO] - {"epoch": 201, "train_loss": "0.838", "train_ntokens": "263389", "train_nsentences": "1753.71", "train_wps": "139716", "train_ups": "0.53", "train_wpb": "263389", "train_bsz": "1753.7", "train_num_updates": "96236", "train_lr": "0.000412723", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.3", "train_wall": "179455"}
[2024-10-06 20:01:02,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 20:01:02,951][fairseq.trainer][INFO] - begin training epoch 202
[2024-10-06 20:01:02,952][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 20:09:42,216][train_inner][INFO] - {"epoch": 202, "update": 201.342, "loss": "0.836", "ntokens": "262809", "nsentences": "1734.06", "wps": "94950.1", "ups": "0.36", "wpb": "262809", "bsz": "1734.1", "num_updates": "96400", "lr": "0.0004125", "gnorm": "0.268", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "179974"}
[2024-10-06 20:13:32,126][train_inner][INFO] - {"epoch": 202, "update": 201.76, "loss": "0.839", "ntokens": "263934", "nsentences": "1740.59", "wps": "229608", "ups": "0.87", "wpb": "263934", "bsz": "1740.6", "num_updates": "96600", "lr": "0.000412228", "gnorm": "0.269", "loss_scale": "2", "train_wall": "224", "gb_free": "40.1", "wall": "180204"}
[2024-10-06 20:15:58,721][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-10-06 20:15:58,757][train][INFO] - {"epoch": 202, "train_loss": "0.838", "train_ntokens": "263414", "train_nsentences": "1753.71", "train_wps": "140800", "train_ups": "0.53", "train_wpb": "263414", "train_bsz": "1753.7", "train_num_updates": "96715", "train_lr": "0.000412072", "train_gnorm": "0.275", "train_loss_scale": "4", "train_train_wall": "547", "train_gb_free": "39.2", "train_wall": "180351"}
[2024-10-06 20:15:58,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 20:15:58,925][fairseq.trainer][INFO] - begin training epoch 203
[2024-10-06 20:15:58,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 20:23:03,461][train_inner][INFO] - {"epoch": 203, "update": 202.177, "loss": "0.836", "ntokens": "262807", "nsentences": "1773.2", "wps": "91998.6", "ups": "0.35", "wpb": "262807", "bsz": "1773.2", "num_updates": "96800", "lr": "0.000411957", "gnorm": "0.276", "loss_scale": "4", "train_wall": "236", "gb_free": "39.8", "wall": "180776"}
[2024-10-06 20:26:43,098][train_inner][INFO] - {"epoch": 203, "update": 202.595, "loss": "0.838", "ntokens": "263982", "nsentences": "1756.31", "wps": "240389", "ups": "0.91", "wpb": "263982", "bsz": "1756.3", "num_updates": "97000", "lr": "0.000411685", "gnorm": "0.274", "loss_scale": "4", "train_wall": "214", "gb_free": "40.2", "wall": "180995"}
[2024-10-06 20:30:16,524][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-10-06 20:30:16,555][train][INFO] - {"epoch": 203, "train_loss": "0.838", "train_ntokens": "263619", "train_nsentences": "1753.71", "train_wps": "147209", "train_ups": "0.56", "train_wpb": "263619", "train_bsz": "1753.7", "train_num_updates": "97194", "train_lr": "0.000411421", "train_gnorm": "0.268", "train_loss_scale": "4", "train_train_wall": "520", "train_gb_free": "40.3", "train_wall": "181209"}
[2024-10-06 20:30:16,605][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 20:30:16,625][fairseq.trainer][INFO] - begin training epoch 204
[2024-10-06 20:30:16,626][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 20:36:13,870][train_inner][INFO] - {"epoch": 204, "update": 203.013, "loss": "0.842", "ntokens": "262908", "nsentences": "1761.24", "wps": "92125.4", "ups": "0.35", "wpb": "262908", "bsz": "1761.2", "num_updates": "97200", "lr": "0.000411413", "gnorm": "0.27", "loss_scale": "4", "train_wall": "249", "gb_free": "39.3", "wall": "181566"}
[2024-10-06 20:39:39,904][train_inner][INFO] - {"epoch": 204, "update": 203.43, "loss": "0.836", "ntokens": "263872", "nsentences": "1765.71", "wps": "256164", "ups": "0.97", "wpb": "263872", "bsz": "1765.7", "num_updates": "97400", "lr": "0.000411141", "gnorm": "0.266", "loss_scale": "4", "train_wall": "197", "gb_free": "39.6", "wall": "181772"}
[2024-10-06 20:41:52,293][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 20:43:44,085][train_inner][INFO] - {"epoch": 204, "update": 203.85, "loss": "0.837", "ntokens": "263996", "nsentences": "1750.1", "wps": "216237", "ups": "0.82", "wpb": "263996", "bsz": "1750.1", "num_updates": "97600", "lr": "0.00041087", "gnorm": "0.252", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "182016"}
[2024-10-06 20:44:45,253][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-10-06 20:44:45,288][train][INFO] - {"epoch": 204, "train_loss": "0.837", "train_ntokens": "263476", "train_nsentences": "1754.23", "train_wps": "144972", "train_ups": "0.55", "train_wpb": "263476", "train_bsz": "1754.2", "train_num_updates": "97672", "train_lr": "0.000410772", "train_gnorm": "0.256", "train_loss_scale": "2", "train_train_wall": "536", "train_gb_free": "39.3", "train_wall": "182077"}
[2024-10-06 20:44:45,569][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 20:44:45,635][fairseq.trainer][INFO] - begin training epoch 205
[2024-10-06 20:44:45,636][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 20:53:14,462][train_inner][INFO] - {"epoch": 205, "update": 204.267, "loss": "0.839", "ntokens": "262629", "nsentences": "1764.98", "wps": "92092.5", "ups": "0.35", "wpb": "262629", "bsz": "1765", "num_updates": "97800", "lr": "0.000410598", "gnorm": "0.264", "loss_scale": "2", "train_wall": "203", "gb_free": "39.8", "wall": "182587"}
[2024-10-06 20:57:03,823][train_inner][INFO] - {"epoch": 205, "update": 204.685, "loss": "0.838", "ntokens": "263998", "nsentences": "1757.56", "wps": "230208", "ups": "0.87", "wpb": "263998", "bsz": "1757.6", "num_updates": "98000", "lr": "0.000410326", "gnorm": "0.253", "loss_scale": "2", "train_wall": "170", "gb_free": "39.6", "wall": "182816"}
[2024-10-06 21:00:00,345][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-10-06 21:00:00,362][train][INFO] - {"epoch": 205, "train_loss": "0.837", "train_ntokens": "263486", "train_nsentences": "1753.71", "train_wps": "137926", "train_ups": "0.52", "train_wpb": "263486", "train_bsz": "1753.7", "train_num_updates": "98151", "train_lr": "0.000410121", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "456", "train_gb_free": "39.7", "train_wall": "182993"}
[2024-10-06 21:00:00,413][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 21:00:00,425][fairseq.trainer][INFO] - begin training epoch 206
[2024-10-06 21:00:00,426][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 21:06:48,123][train_inner][INFO] - {"epoch": 206, "update": 205.102, "loss": "0.837", "ntokens": "262976", "nsentences": "1741.14", "wps": "90015.8", "ups": "0.34", "wpb": "262976", "bsz": "1741.1", "num_updates": "98200", "lr": "0.000410054", "gnorm": "0.269", "loss_scale": "2", "train_wall": "200", "gb_free": "40", "wall": "183400"}
[2024-10-06 21:10:19,746][train_inner][INFO] - {"epoch": 206, "update": 205.52, "loss": "0.835", "ntokens": "264094", "nsentences": "1768.02", "wps": "249597", "ups": "0.95", "wpb": "264094", "bsz": "1768", "num_updates": "98400", "lr": "0.000409783", "gnorm": "0.243", "loss_scale": "2", "train_wall": "207", "gb_free": "39.2", "wall": "183612"}
[2024-10-06 21:13:56,159][train_inner][INFO] - {"epoch": 206, "update": 205.937, "loss": "0.839", "ntokens": "263947", "nsentences": "1745.94", "wps": "243941", "ups": "0.92", "wpb": "263947", "bsz": "1745.9", "num_updates": "98600", "lr": "0.000409511", "gnorm": "0.251", "loss_scale": "2", "train_wall": "211", "gb_free": "41.2", "wall": "183828"}
[2024-10-06 21:15:01,673][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-10-06 21:15:01,703][train][INFO] - {"epoch": 206, "train_loss": "0.837", "train_ntokens": "263537", "train_nsentences": "1753.71", "train_wps": "140052", "train_ups": "0.53", "train_wpb": "263537", "train_bsz": "1753.7", "train_num_updates": "98630", "train_lr": "0.00040947", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.6", "train_wall": "183894"}
[2024-10-06 21:15:01,938][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 21:15:01,976][fairseq.trainer][INFO] - begin training epoch 207
[2024-10-06 21:15:01,977][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 21:24:18,081][train_inner][INFO] - {"epoch": 207, "update": 206.355, "loss": "0.836", "ntokens": "262640", "nsentences": "1750.56", "wps": "84462", "ups": "0.32", "wpb": "262640", "bsz": "1750.6", "num_updates": "98800", "lr": "0.000409239", "gnorm": "0.271", "loss_scale": "2", "train_wall": "255", "gb_free": "39.7", "wall": "184450"}
[2024-10-06 21:28:16,145][train_inner][INFO] - {"epoch": 207, "update": 206.772, "loss": "0.838", "ntokens": "263997", "nsentences": "1771.25", "wps": "221802", "ups": "0.84", "wpb": "263997", "bsz": "1771.2", "num_updates": "99000", "lr": "0.000408967", "gnorm": "0.268", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "184688"}
[2024-10-06 21:30:32,919][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-10-06 21:30:32,939][train][INFO] - {"epoch": 207, "train_loss": "0.837", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "135546", "train_ups": "0.51", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "99109", "train_lr": "0.000408819", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.1", "train_wall": "184825"}
[2024-10-06 21:30:33,003][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 21:30:33,103][fairseq.trainer][INFO] - begin training epoch 208
[2024-10-06 21:30:33,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 21:38:58,567][train_inner][INFO] - {"epoch": 208, "update": 207.19, "loss": "0.837", "ntokens": "263186", "nsentences": "1707.07", "wps": "81938", "ups": "0.31", "wpb": "263186", "bsz": "1707.1", "num_updates": "99200", "lr": "0.000408696", "gnorm": "0.26", "loss_scale": "2", "train_wall": "242", "gb_free": "39.2", "wall": "185331"}
[2024-10-06 21:42:38,176][train_inner][INFO] - {"epoch": 208, "update": 207.608, "loss": "0.837", "ntokens": "263934", "nsentences": "1775.44", "wps": "240391", "ups": "0.91", "wpb": "263934", "bsz": "1775.4", "num_updates": "99400", "lr": "0.000408424", "gnorm": "0.258", "loss_scale": "2", "train_wall": "214", "gb_free": "40.1", "wall": "185550"}
[2024-10-06 21:46:55,549][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-10-06 21:46:55,583][train][INFO] - {"epoch": 208, "train_loss": "0.837", "train_ntokens": "263591", "train_nsentences": "1753.71", "train_wps": "128493", "train_ups": "0.49", "train_wpb": "263592", "train_bsz": "1753.7", "train_num_updates": "99588", "train_lr": "0.000408168", "train_gnorm": "0.27", "train_loss_scale": "4", "train_train_wall": "575", "train_gb_free": "39.3", "train_wall": "185808"}
[2024-10-06 21:46:55,752][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 21:46:55,791][fairseq.trainer][INFO] - begin training epoch 209
[2024-10-06 21:46:55,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 21:53:10,588][train_inner][INFO] - {"epoch": 209, "update": 208.025, "loss": "0.837", "ntokens": "262956", "nsentences": "1756.68", "wps": "83160.5", "ups": "0.32", "wpb": "262956", "bsz": "1756.7", "num_updates": "99600", "lr": "0.000408152", "gnorm": "0.293", "loss_scale": "4", "train_wall": "271", "gb_free": "40.5", "wall": "186183"}
[2024-10-06 21:56:45,191][train_inner][INFO] - {"epoch": 209, "update": 208.443, "loss": "0.836", "ntokens": "263973", "nsentences": "1753.48", "wps": "246021", "ups": "0.93", "wpb": "263973", "bsz": "1753.5", "num_updates": "99800", "lr": "0.00040788", "gnorm": "0.266", "loss_scale": "4", "train_wall": "209", "gb_free": "39.8", "wall": "186397"}
[2024-10-06 22:00:56,389][train_inner][INFO] - {"epoch": 209, "update": 208.86, "loss": "0.838", "ntokens": "264212", "nsentences": "1755.63", "wps": "210377", "ups": "0.8", "wpb": "264212", "bsz": "1755.6", "num_updates": "100000", "lr": "0.000407609", "gnorm": "0.263", "loss_scale": "4", "train_wall": "246", "gb_free": "39.4", "wall": "186649"}
[2024-10-06 22:00:56,401][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 100000 updates
[2024-10-06 22:00:56,402][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_209_100000.pt
[2024-10-06 22:01:00,307][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_209_100000.pt
[2024-10-06 22:01:07,501][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_209_100000.pt (epoch 209 @ 100000 updates, score None) (writing took 11.099934604018927 seconds)
[2024-10-06 22:02:32,339][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-10-06 22:02:32,364][train][INFO] - {"epoch": 209, "train_loss": "0.837", "train_ntokens": "263621", "train_nsentences": "1753.71", "train_wps": "134800", "train_ups": "0.51", "train_wpb": "263621", "train_bsz": "1753.7", "train_num_updates": "100067", "train_lr": "0.000407518", "train_gnorm": "0.27", "train_loss_scale": "4", "train_train_wall": "556", "train_gb_free": "39.3", "train_wall": "186745"}
[2024-10-06 22:02:32,495][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 22:02:32,517][fairseq.trainer][INFO] - begin training epoch 210
[2024-10-06 22:02:32,518][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 22:10:53,938][train_inner][INFO] - {"epoch": 210, "update": 209.278, "loss": "0.835", "ntokens": "263042", "nsentences": "1747.47", "wps": "88041.4", "ups": "0.33", "wpb": "263042", "bsz": "1747.5", "num_updates": "100200", "lr": "0.000407337", "gnorm": "0.27", "loss_scale": "4", "train_wall": "242", "gb_free": "39.1", "wall": "187246"}
[2024-10-06 22:14:45,712][train_inner][INFO] - {"epoch": 210, "update": 209.695, "loss": "0.835", "ntokens": "264387", "nsentences": "1721.35", "wps": "228171", "ups": "0.86", "wpb": "264388", "bsz": "1721.3", "num_updates": "100400", "lr": "0.000407065", "gnorm": "0.248", "loss_scale": "4", "train_wall": "227", "gb_free": "40.3", "wall": "187478"}
[2024-10-06 22:17:42,866][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 100546 updates
[2024-10-06 22:17:42,868][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 22:17:49,286][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-06 22:17:49,342][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 210 @ 100546 updates, score None) (writing took 6.475917010568082 seconds)
[2024-10-06 22:17:49,343][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-10-06 22:17:49,353][train][INFO] - {"epoch": 210, "train_loss": "0.836", "train_ntokens": "263569", "train_nsentences": "1753.71", "train_wps": "137680", "train_ups": "0.52", "train_wpb": "263569", "train_bsz": "1753.7", "train_num_updates": "100546", "train_lr": "0.000406867", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "39.2", "train_wall": "187662"}
[2024-10-06 22:17:49,425][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 22:17:49,463][fairseq.trainer][INFO] - begin training epoch 211
[2024-10-06 22:17:49,464][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 22:24:33,164][train_inner][INFO] - {"epoch": 211, "update": 210.113, "loss": "0.835", "ntokens": "262516", "nsentences": "1779.7", "wps": "89375.3", "ups": "0.34", "wpb": "262516", "bsz": "1779.7", "num_updates": "100600", "lr": "0.000406793", "gnorm": "0.262", "loss_scale": "4", "train_wall": "216", "gb_free": "39.8", "wall": "188065"}
[2024-10-06 22:28:30,919][train_inner][INFO] - {"epoch": 211, "update": 210.53, "loss": "0.836", "ntokens": "263671", "nsentences": "1787.25", "wps": "221806", "ups": "0.84", "wpb": "263671", "bsz": "1787.2", "num_updates": "100800", "lr": "0.000406522", "gnorm": "0.258", "loss_scale": "4", "train_wall": "217", "gb_free": "39.3", "wall": "188303"}
[2024-10-06 22:31:30,536][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 22:32:28,795][train_inner][INFO] - {"epoch": 211, "update": 210.95, "loss": "0.837", "ntokens": "264012", "nsentences": "1751.74", "wps": "221985", "ups": "0.84", "wpb": "264012", "bsz": "1751.7", "num_updates": "101000", "lr": "0.00040625", "gnorm": "0.257", "loss_scale": "2", "train_wall": "232", "gb_free": "39.7", "wall": "188541"}
[2024-10-06 22:33:19,237][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-10-06 22:33:19,240][train][INFO] - {"epoch": 211, "train_loss": "0.835", "train_ntokens": "263467", "train_nsentences": "1754.26", "train_wps": "135433", "train_ups": "0.51", "train_wpb": "263467", "train_bsz": "1754.3", "train_num_updates": "101024", "train_lr": "0.000406217", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.4", "train_wall": "188591"}
[2024-10-06 22:33:19,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 22:33:19,320][fairseq.trainer][INFO] - begin training epoch 212
[2024-10-06 22:33:19,321][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 22:41:53,744][train_inner][INFO] - {"epoch": 212, "update": 211.367, "loss": "0.834", "ntokens": "263013", "nsentences": "1724.76", "wps": "93112.7", "ups": "0.35", "wpb": "263013", "bsz": "1724.8", "num_updates": "101200", "lr": "0.000405978", "gnorm": "0.271", "loss_scale": "2", "train_wall": "249", "gb_free": "40", "wall": "189106"}
[2024-10-06 22:45:45,255][train_inner][INFO] - {"epoch": 212, "update": 211.785, "loss": "0.835", "ntokens": "263965", "nsentences": "1759.22", "wps": "228045", "ups": "0.86", "wpb": "263965", "bsz": "1759.2", "num_updates": "101400", "lr": "0.000405707", "gnorm": "0.275", "loss_scale": "2", "train_wall": "222", "gb_free": "40.1", "wall": "189337"}
[2024-10-06 22:47:54,479][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-10-06 22:47:54,512][train][INFO] - {"epoch": 212, "train_loss": "0.835", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "144234", "train_ups": "0.55", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "101503", "train_lr": "0.000405567", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "548", "train_gb_free": "39.1", "train_wall": "189467"}
[2024-10-06 22:47:54,649][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 22:47:54,656][fairseq.trainer][INFO] - begin training epoch 213
[2024-10-06 22:47:54,656][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 22:55:26,269][train_inner][INFO] - {"epoch": 213, "update": 212.203, "loss": "0.834", "ntokens": "263079", "nsentences": "1730.76", "wps": "90561.2", "ups": "0.34", "wpb": "263079", "bsz": "1730.8", "num_updates": "101600", "lr": "0.000405435", "gnorm": "0.258", "loss_scale": "2", "train_wall": "250", "gb_free": "39.3", "wall": "189918"}
[2024-10-06 22:59:21,435][train_inner][INFO] - {"epoch": 213, "update": 212.62, "loss": "0.835", "ntokens": "263814", "nsentences": "1774.59", "wps": "224390", "ups": "0.85", "wpb": "263814", "bsz": "1774.6", "num_updates": "101800", "lr": "0.000405163", "gnorm": "0.261", "loss_scale": "2", "train_wall": "223", "gb_free": "39.3", "wall": "190154"}
[2024-10-06 23:03:19,193][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2024-10-06 23:03:19,210][train][INFO] - {"epoch": 213, "train_loss": "0.835", "train_ntokens": "263420", "train_nsentences": "1753.71", "train_wps": "136457", "train_ups": "0.52", "train_wpb": "263420", "train_bsz": "1753.7", "train_num_updates": "101982", "train_lr": "0.000404916", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "574", "train_gb_free": "39.6", "train_wall": "190391"}
[2024-10-06 23:03:19,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 23:03:19,300][fairseq.trainer][INFO] - begin training epoch 214
[2024-10-06 23:03:19,300][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 23:09:32,300][train_inner][INFO] - {"epoch": 214, "update": 213.038, "loss": "0.836", "ntokens": "262597", "nsentences": "1759.78", "wps": "85976.4", "ups": "0.33", "wpb": "262597", "bsz": "1759.8", "num_updates": "102000", "lr": "0.000404891", "gnorm": "0.271", "loss_scale": "2", "train_wall": "280", "gb_free": "39.2", "wall": "190764"}
[2024-10-06 23:12:56,427][train_inner][INFO] - {"epoch": 214, "update": 213.455, "loss": "0.832", "ntokens": "264220", "nsentences": "1763.94", "wps": "258895", "ups": "0.98", "wpb": "264220", "bsz": "1763.9", "num_updates": "102200", "lr": "0.00040462", "gnorm": "0.277", "loss_scale": "2", "train_wall": "196", "gb_free": "39.6", "wall": "190969"}
[2024-10-06 23:16:55,668][train_inner][INFO] - {"epoch": 214, "update": 213.873, "loss": "0.835", "ntokens": "264146", "nsentences": "1741.21", "wps": "220834", "ups": "0.84", "wpb": "264146", "bsz": "1741.2", "num_updates": "102400", "lr": "0.000404348", "gnorm": "0.258", "loss_scale": "2", "train_wall": "234", "gb_free": "39.6", "wall": "191208"}
[2024-10-06 23:18:15,872][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2024-10-06 23:18:15,884][train][INFO] - {"epoch": 214, "train_loss": "0.835", "train_ntokens": "263645", "train_nsentences": "1753.71", "train_wps": "140839", "train_ups": "0.53", "train_wpb": "263645", "train_bsz": "1753.7", "train_num_updates": "102461", "train_lr": "0.000404265", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "559", "train_gb_free": "39.6", "train_wall": "191288"}
[2024-10-06 23:18:15,965][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 23:18:15,991][fairseq.trainer][INFO] - begin training epoch 215
[2024-10-06 23:18:15,991][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 23:26:49,562][train_inner][INFO] - {"epoch": 215, "update": 214.29, "loss": "0.834", "ntokens": "262694", "nsentences": "1756.09", "wps": "88467.9", "ups": "0.34", "wpb": "262694", "bsz": "1756.1", "num_updates": "102600", "lr": "0.000404076", "gnorm": "0.27", "loss_scale": "2", "train_wall": "261", "gb_free": "39.2", "wall": "191802"}
[2024-10-06 23:30:45,608][train_inner][INFO] - {"epoch": 215, "update": 214.708, "loss": "0.838", "ntokens": "263727", "nsentences": "1783.11", "wps": "223459", "ups": "0.85", "wpb": "263727", "bsz": "1783.1", "num_updates": "102800", "lr": "0.000403804", "gnorm": "0.27", "loss_scale": "2", "train_wall": "230", "gb_free": "40", "wall": "192038"}
[2024-10-06 23:33:45,056][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2024-10-06 23:33:45,074][train][INFO] - {"epoch": 215, "train_loss": "0.834", "train_ntokens": "263460", "train_nsentences": "1753.71", "train_wps": "135817", "train_ups": "0.52", "train_wpb": "263460", "train_bsz": "1753.7", "train_num_updates": "102940", "train_lr": "0.000403614", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "588", "train_gb_free": "39.2", "train_wall": "192217"}
[2024-10-06 23:33:45,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 23:33:45,241][fairseq.trainer][INFO] - begin training epoch 216
[2024-10-06 23:33:45,242][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 23:40:11,152][train_inner][INFO] - {"epoch": 216, "update": 215.125, "loss": "0.833", "ntokens": "262975", "nsentences": "1728.66", "wps": "93000.8", "ups": "0.35", "wpb": "262975", "bsz": "1728.7", "num_updates": "103000", "lr": "0.000403533", "gnorm": "0.254", "loss_scale": "4", "train_wall": "245", "gb_free": "39.6", "wall": "192603"}
[2024-10-06 23:44:12,344][train_inner][INFO] - {"epoch": 216, "update": 215.543, "loss": "0.832", "ntokens": "263820", "nsentences": "1771.11", "wps": "218771", "ups": "0.83", "wpb": "263820", "bsz": "1771.1", "num_updates": "103200", "lr": "0.000403261", "gnorm": "0.262", "loss_scale": "4", "train_wall": "179", "gb_free": "39.8", "wall": "192845"}
[2024-10-06 23:47:59,743][train_inner][INFO] - {"epoch": 216, "update": 215.96, "loss": "0.836", "ntokens": "264107", "nsentences": "1738.61", "wps": "232296", "ups": "0.88", "wpb": "264107", "bsz": "1738.6", "num_updates": "103400", "lr": "0.000402989", "gnorm": "0.262", "loss_scale": "4", "train_wall": "137", "gb_free": "39.8", "wall": "193072"}
[2024-10-06 23:48:44,385][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2024-10-06 23:48:44,402][train][INFO] - {"epoch": 216, "train_loss": "0.834", "train_ntokens": "263431", "train_nsentences": "1753.71", "train_wps": "140310", "train_ups": "0.53", "train_wpb": "263430", "train_bsz": "1753.7", "train_num_updates": "103419", "train_lr": "0.000402963", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "411", "train_gb_free": "39.3", "train_wall": "193117"}
[2024-10-06 23:48:44,526][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-06 23:48:44,551][fairseq.trainer][INFO] - begin training epoch 217
[2024-10-06 23:48:44,552][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 23:57:41,158][train_inner][INFO] - {"epoch": 217, "update": 216.378, "loss": "0.833", "ntokens": "262692", "nsentences": "1772.42", "wps": "90364.1", "ups": "0.34", "wpb": "262692", "bsz": "1772.4", "num_updates": "103600", "lr": "0.000402717", "gnorm": "0.274", "loss_scale": "4", "train_wall": "240", "gb_free": "40.1", "wall": "193653"}
[2024-10-07 00:01:48,479][train_inner][INFO] - {"epoch": 217, "update": 216.795, "loss": "0.834", "ntokens": "263914", "nsentences": "1754.97", "wps": "213426", "ups": "0.81", "wpb": "263914", "bsz": "1755", "num_updates": "103800", "lr": "0.000402446", "gnorm": "0.279", "loss_scale": "4", "train_wall": "242", "gb_free": "39.6", "wall": "193901"}
[2024-10-07 00:03:36,919][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2024-10-07 00:03:36,948][train][INFO] - {"epoch": 217, "train_loss": "0.834", "train_ntokens": "263504", "train_nsentences": "1753.71", "train_wps": "141415", "train_ups": "0.54", "train_wpb": "263504", "train_bsz": "1753.7", "train_num_updates": "103898", "train_lr": "0.000402313", "train_gnorm": "0.276", "train_loss_scale": "4", "train_train_wall": "565", "train_gb_free": "39.6", "train_wall": "194009"}
[2024-10-07 00:03:37,039][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 00:03:37,048][fairseq.trainer][INFO] - begin training epoch 218
[2024-10-07 00:03:37,049][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:10:59,160][train_inner][INFO] - {"epoch": 218, "update": 217.213, "loss": "0.832", "ntokens": "263265", "nsentences": "1700.82", "wps": "95616.3", "ups": "0.36", "wpb": "263266", "bsz": "1700.8", "num_updates": "104000", "lr": "0.000402174", "gnorm": "0.264", "loss_scale": "4", "train_wall": "231", "gb_free": "39.8", "wall": "194451"}
[2024-10-07 00:14:42,295][train_inner][INFO] - {"epoch": 218, "update": 217.63, "loss": "0.832", "ntokens": "263877", "nsentences": "1768.12", "wps": "236526", "ups": "0.9", "wpb": "263877", "bsz": "1768.1", "num_updates": "104200", "lr": "0.000401902", "gnorm": "0.255", "loss_scale": "4", "train_wall": "218", "gb_free": "40", "wall": "194674"}
[2024-10-07 00:18:25,659][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2024-10-07 00:18:25,714][train][INFO] - {"epoch": 218, "train_loss": "0.833", "train_ntokens": "263502", "train_nsentences": "1753.71", "train_wps": "142017", "train_ups": "0.54", "train_wpb": "263502", "train_bsz": "1753.7", "train_num_updates": "104377", "train_lr": "0.000401662", "train_gnorm": "0.259", "train_loss_scale": "4", "train_train_wall": "561", "train_gb_free": "40.6", "train_wall": "194898"}
[2024-10-07 00:18:26,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 00:18:26,772][fairseq.trainer][INFO] - begin training epoch 219
[2024-10-07 00:18:26,773][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:24:35,036][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 00:24:55,110][train_inner][INFO] - {"epoch": 219, "update": 218.05, "loss": "0.837", "ntokens": "262539", "nsentences": "1774.16", "wps": "85684.4", "ups": "0.33", "wpb": "262538", "bsz": "1774.2", "num_updates": "104400", "lr": "0.00040163", "gnorm": "0.278", "loss_scale": "2", "train_wall": "282", "gb_free": "40", "wall": "195287"}
[2024-10-07 00:28:25,612][train_inner][INFO] - {"epoch": 219, "update": 218.468, "loss": "0.832", "ntokens": "263693", "nsentences": "1765.41", "wps": "250556", "ups": "0.95", "wpb": "263693", "bsz": "1765.4", "num_updates": "104600", "lr": "0.000401359", "gnorm": "0.258", "loss_scale": "2", "train_wall": "205", "gb_free": "39.8", "wall": "195498"}
[2024-10-07 00:32:27,847][train_inner][INFO] - {"epoch": 219, "update": 218.885, "loss": "0.832", "ntokens": "264271", "nsentences": "1743.98", "wps": "218204", "ups": "0.83", "wpb": "264271", "bsz": "1744", "num_updates": "104800", "lr": "0.000401087", "gnorm": "0.265", "loss_scale": "2", "train_wall": "236", "gb_free": "39.3", "wall": "195740"}
[2024-10-07 00:33:50,996][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2024-10-07 00:33:51,030][train][INFO] - {"epoch": 219, "train_loss": "0.833", "train_ntokens": "263445", "train_nsentences": "1753.91", "train_wps": "136092", "train_ups": "0.52", "train_wpb": "263445", "train_bsz": "1753.9", "train_num_updates": "104855", "train_lr": "0.000401012", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "586", "train_gb_free": "39.6", "train_wall": "195823"}
[2024-10-07 00:33:51,212][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 00:33:51,225][fairseq.trainer][INFO] - begin training epoch 220
[2024-10-07 00:33:51,226][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:42:38,343][train_inner][INFO] - {"epoch": 220, "update": 219.303, "loss": "0.831", "ntokens": "262842", "nsentences": "1729.99", "wps": "86108.6", "ups": "0.33", "wpb": "262842", "bsz": "1730", "num_updates": "105000", "lr": "0.000400815", "gnorm": "0.25", "loss_scale": "2", "train_wall": "295", "gb_free": "39.6", "wall": "196351"}
[2024-10-07 00:47:06,270][train_inner][INFO] - {"epoch": 220, "update": 219.72, "loss": "0.834", "ntokens": "264046", "nsentences": "1752.71", "wps": "197117", "ups": "0.75", "wpb": "264046", "bsz": "1752.7", "num_updates": "105200", "lr": "0.000400543", "gnorm": "0.263", "loss_scale": "2", "train_wall": "262", "gb_free": "39.3", "wall": "196618"}
[2024-10-07 00:50:02,065][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 105334 updates
[2024-10-07 00:50:02,074][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 00:50:11,364][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 00:50:11,531][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 220 @ 105334 updates, score None) (writing took 9.466228847391903 seconds)
[2024-10-07 00:50:11,532][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2024-10-07 00:50:11,534][train][INFO] - {"epoch": 220, "train_loss": "0.833", "train_ntokens": "263487", "train_nsentences": "1753.71", "train_wps": "128720", "train_ups": "0.49", "train_wpb": "263487", "train_bsz": "1753.7", "train_num_updates": "105334", "train_lr": "0.000400361", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "645", "train_gb_free": "39.3", "train_wall": "196804"}
[2024-10-07 00:50:11,617][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 00:50:11,634][fairseq.trainer][INFO] - begin training epoch 221
[2024-10-07 00:50:11,635][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 00:56:45,414][train_inner][INFO] - {"epoch": 221, "update": 220.138, "loss": "0.833", "ntokens": "262783", "nsentences": "1751.22", "wps": "90750.8", "ups": "0.35", "wpb": "262783", "bsz": "1751.2", "num_updates": "105400", "lr": "0.000400272", "gnorm": "0.251", "loss_scale": "2", "train_wall": "250", "gb_free": "39.7", "wall": "197198"}
[2024-10-07 01:00:25,270][train_inner][INFO] - {"epoch": 221, "update": 220.555, "loss": "0.833", "ntokens": "263588", "nsentences": "1802.65", "wps": "239792", "ups": "0.91", "wpb": "263588", "bsz": "1802.7", "num_updates": "105600", "lr": "0.0004", "gnorm": "0.268", "loss_scale": "2", "train_wall": "212", "gb_free": "39.1", "wall": "197417"}
[2024-10-07 01:04:05,735][train_inner][INFO] - {"epoch": 221, "update": 220.973, "loss": "0.833", "ntokens": "264290", "nsentences": "1726.4", "wps": "239764", "ups": "0.91", "wpb": "264290", "bsz": "1726.4", "num_updates": "105800", "lr": "0.000399728", "gnorm": "0.253", "loss_scale": "2", "train_wall": "215", "gb_free": "39.2", "wall": "197638"}
[2024-10-07 01:04:39,114][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2024-10-07 01:04:39,128][train][INFO] - {"epoch": 221, "train_loss": "0.833", "train_ntokens": "263466", "train_nsentences": "1753.71", "train_wps": "145461", "train_ups": "0.55", "train_wpb": "263466", "train_bsz": "1753.7", "train_num_updates": "105813", "train_lr": "0.000399711", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "540", "train_gb_free": "39.2", "train_wall": "197671"}
[2024-10-07 01:04:39,271][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 01:04:39,297][fairseq.trainer][INFO] - begin training epoch 222
[2024-10-07 01:04:39,298][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:13:42,642][train_inner][INFO] - {"epoch": 222, "update": 221.39, "loss": "0.832", "ntokens": "262898", "nsentences": "1734.48", "wps": "91141.5", "ups": "0.35", "wpb": "262898", "bsz": "1734.5", "num_updates": "106000", "lr": "0.000399457", "gnorm": "0.252", "loss_scale": "2", "train_wall": "258", "gb_free": "39.2", "wall": "198215"}
[2024-10-07 01:17:28,782][train_inner][INFO] - {"epoch": 222, "update": 221.808, "loss": "0.831", "ntokens": "264161", "nsentences": "1737.81", "wps": "233660", "ups": "0.88", "wpb": "264161", "bsz": "1737.8", "num_updates": "106200", "lr": "0.000399185", "gnorm": "0.285", "loss_scale": "2", "train_wall": "221", "gb_free": "39.6", "wall": "198441"}
[2024-10-07 01:19:35,270][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2024-10-07 01:19:35,278][train][INFO] - {"epoch": 222, "train_loss": "0.832", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "140852", "train_ups": "0.53", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "106292", "train_lr": "0.00039906", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "570", "train_gb_free": "39.2", "train_wall": "198567"}
[2024-10-07 01:19:35,361][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 01:19:35,400][fairseq.trainer][INFO] - begin training epoch 223
[2024-10-07 01:19:35,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:27:02,335][train_inner][INFO] - {"epoch": 223, "update": 222.225, "loss": "0.833", "ntokens": "262632", "nsentences": "1803.15", "wps": "91582.6", "ups": "0.35", "wpb": "262632", "bsz": "1803.2", "num_updates": "106400", "lr": "0.000398913", "gnorm": "0.263", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "199015"}
[2024-10-07 01:28:35,753][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 01:31:03,185][train_inner][INFO] - {"epoch": 223, "update": 222.645, "loss": "0.83", "ntokens": "264135", "nsentences": "1727.73", "wps": "219349", "ups": "0.83", "wpb": "264136", "bsz": "1727.7", "num_updates": "106600", "lr": "0.000398641", "gnorm": "0.261", "loss_scale": "2", "train_wall": "235", "gb_free": "39.7", "wall": "199255"}
[2024-10-07 01:34:37,557][fairseq_cli.train][INFO] - end of epoch 223 (average epoch stats below)
[2024-10-07 01:34:37,568][train][INFO] - {"epoch": 223, "train_loss": "0.832", "train_ntokens": "263551", "train_nsentences": "1753.9", "train_wps": "139621", "train_ups": "0.53", "train_wpb": "263551", "train_bsz": "1753.9", "train_num_updates": "106770", "train_lr": "0.00039841", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.3", "train_wall": "199470"}
[2024-10-07 01:34:37,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 01:34:37,709][fairseq.trainer][INFO] - begin training epoch 224
[2024-10-07 01:34:37,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:40:53,921][train_inner][INFO] - {"epoch": 224, "update": 223.063, "loss": "0.835", "ntokens": "262654", "nsentences": "1763.69", "wps": "88925.3", "ups": "0.34", "wpb": "262654", "bsz": "1763.7", "num_updates": "106800", "lr": "0.00039837", "gnorm": "0.251", "loss_scale": "2", "train_wall": "274", "gb_free": "39.6", "wall": "199846"}
[2024-10-07 01:44:09,015][train_inner][INFO] - {"epoch": 224, "update": 223.48, "loss": "0.833", "ntokens": "263885", "nsentences": "1764.41", "wps": "270531", "ups": "1.03", "wpb": "263885", "bsz": "1764.4", "num_updates": "107000", "lr": "0.000398098", "gnorm": "0.26", "loss_scale": "2", "train_wall": "190", "gb_free": "40", "wall": "200041"}
[2024-10-07 01:48:21,304][train_inner][INFO] - {"epoch": 224, "update": 223.898, "loss": "0.83", "ntokens": "264261", "nsentences": "1745.06", "wps": "209501", "ups": "0.79", "wpb": "264261", "bsz": "1745.1", "num_updates": "107200", "lr": "0.000397826", "gnorm": "0.251", "loss_scale": "2", "train_wall": "247", "gb_free": "39.6", "wall": "200293"}
[2024-10-07 01:49:29,853][fairseq_cli.train][INFO] - end of epoch 224 (average epoch stats below)
[2024-10-07 01:49:29,868][train][INFO] - {"epoch": 224, "train_loss": "0.832", "train_ntokens": "263518", "train_nsentences": "1753.71", "train_wps": "141461", "train_ups": "0.54", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "107249", "train_lr": "0.00039776", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.6", "train_wall": "200362"}
[2024-10-07 01:49:29,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 01:49:30,018][fairseq.trainer][INFO] - begin training epoch 225
[2024-10-07 01:49:30,019][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 01:58:27,621][train_inner][INFO] - {"epoch": 225, "update": 224.315, "loss": "0.832", "ntokens": "262370", "nsentences": "1808.57", "wps": "86548.6", "ups": "0.33", "wpb": "262370", "bsz": "1808.6", "num_updates": "107400", "lr": "0.000397554", "gnorm": "0.266", "loss_scale": "2", "train_wall": "277", "gb_free": "39.2", "wall": "200900"}
[2024-10-07 02:02:42,274][train_inner][INFO] - {"epoch": 225, "update": 224.733, "loss": "0.83", "ntokens": "264397", "nsentences": "1709.69", "wps": "207671", "ups": "0.79", "wpb": "264397", "bsz": "1709.7", "num_updates": "107600", "lr": "0.000397283", "gnorm": "0.26", "loss_scale": "2", "train_wall": "249", "gb_free": "40.3", "wall": "201154"}
[2024-10-07 02:05:13,649][fairseq_cli.train][INFO] - end of epoch 225 (average epoch stats below)
[2024-10-07 02:05:13,670][train][INFO] - {"epoch": 225, "train_loss": "0.831", "train_ntokens": "263554", "train_nsentences": "1753.71", "train_wps": "133761", "train_ups": "0.51", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "107728", "train_lr": "0.000397109", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "606", "train_gb_free": "39.2", "train_wall": "201306"}
[2024-10-07 02:05:13,728][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 02:05:13,737][fairseq.trainer][INFO] - begin training epoch 226
[2024-10-07 02:05:13,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:12:29,089][train_inner][INFO] - {"epoch": 226, "update": 225.15, "loss": "0.832", "ntokens": "262940", "nsentences": "1755.92", "wps": "89619.8", "ups": "0.34", "wpb": "262940", "bsz": "1755.9", "num_updates": "107800", "lr": "0.000397011", "gnorm": "0.263", "loss_scale": "2", "train_wall": "248", "gb_free": "39.6", "wall": "201741"}
[2024-10-07 02:15:54,647][train_inner][INFO] - {"epoch": 226, "update": 225.568, "loss": "0.831", "ntokens": "263940", "nsentences": "1752.21", "wps": "256810", "ups": "0.97", "wpb": "263940", "bsz": "1752.2", "num_updates": "108000", "lr": "0.000396739", "gnorm": "0.258", "loss_scale": "2", "train_wall": "200", "gb_free": "39.5", "wall": "201947"}
[2024-10-07 02:19:45,622][train_inner][INFO] - {"epoch": 226, "update": 225.985, "loss": "0.832", "ntokens": "264296", "nsentences": "1740.83", "wps": "228860", "ups": "0.87", "wpb": "264296", "bsz": "1740.8", "num_updates": "108200", "lr": "0.000396467", "gnorm": "0.261", "loss_scale": "2", "train_wall": "226", "gb_free": "40", "wall": "202178"}
[2024-10-07 02:20:02,925][fairseq_cli.train][INFO] - end of epoch 226 (average epoch stats below)
[2024-10-07 02:20:02,949][train][INFO] - {"epoch": 226, "train_loss": "0.831", "train_ntokens": "263611", "train_nsentences": "1753.71", "train_wps": "141993", "train_ups": "0.54", "train_wpb": "263611", "train_bsz": "1753.7", "train_num_updates": "108207", "train_lr": "0.000396458", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "39.8", "train_wall": "202195"}
[2024-10-07 02:20:03,106][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 02:20:03,127][fairseq.trainer][INFO] - begin training epoch 227
[2024-10-07 02:20:03,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:29:41,638][train_inner][INFO] - {"epoch": 227, "update": 226.403, "loss": "0.831", "ntokens": "262775", "nsentences": "1778.24", "wps": "88180.4", "ups": "0.34", "wpb": "262775", "bsz": "1778.2", "num_updates": "108400", "lr": "0.000396196", "gnorm": "0.274", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "202774"}
[2024-10-07 02:34:12,846][train_inner][INFO] - {"epoch": 227, "update": 226.82, "loss": "0.831", "ntokens": "264183", "nsentences": "1738.01", "wps": "194832", "ups": "0.74", "wpb": "264183", "bsz": "1738", "num_updates": "108600", "lr": "0.000395924", "gnorm": "0.263", "loss_scale": "4", "train_wall": "265", "gb_free": "40", "wall": "203045"}
[2024-10-07 02:35:59,364][fairseq_cli.train][INFO] - end of epoch 227 (average epoch stats below)
[2024-10-07 02:35:59,416][train][INFO] - {"epoch": 227, "train_loss": "0.831", "train_ntokens": "263600", "train_nsentences": "1753.71", "train_wps": "132013", "train_ups": "0.5", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "108686", "train_lr": "0.000395807", "train_gnorm": "0.267", "train_loss_scale": "4", "train_train_wall": "581", "train_gb_free": "40", "train_wall": "203152"}
[2024-10-07 02:35:59,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 02:35:59,547][fairseq.trainer][INFO] - begin training epoch 228
[2024-10-07 02:35:59,548][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:43:58,920][train_inner][INFO] - {"epoch": 228, "update": 227.238, "loss": "0.828", "ntokens": "263228", "nsentences": "1725.26", "wps": "89828.8", "ups": "0.34", "wpb": "263228", "bsz": "1725.3", "num_updates": "108800", "lr": "0.000395652", "gnorm": "0.255", "loss_scale": "4", "train_wall": "250", "gb_free": "40", "wall": "203631"}
[2024-10-07 02:47:54,642][train_inner][INFO] - {"epoch": 228, "update": 227.656, "loss": "0.832", "ntokens": "263582", "nsentences": "1787.54", "wps": "223652", "ups": "0.85", "wpb": "263582", "bsz": "1787.5", "num_updates": "109000", "lr": "0.00039538", "gnorm": "0.281", "loss_scale": "4", "train_wall": "231", "gb_free": "40", "wall": "203867"}
[2024-10-07 02:51:16,120][fairseq_cli.train][INFO] - end of epoch 228 (average epoch stats below)
[2024-10-07 02:51:16,136][train][INFO] - {"epoch": 228, "train_loss": "0.83", "train_ntokens": "263579", "train_nsentences": "1753.71", "train_wps": "137725", "train_ups": "0.52", "train_wpb": "263579", "train_bsz": "1753.7", "train_num_updates": "109165", "train_lr": "0.000395156", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "575", "train_gb_free": "40", "train_wall": "204068"}
[2024-10-07 02:51:16,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 02:51:16,307][fairseq.trainer][INFO] - begin training epoch 229
[2024-10-07 02:51:16,308][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 02:57:54,183][train_inner][INFO] - {"epoch": 229, "update": 228.073, "loss": "0.833", "ntokens": "263127", "nsentences": "1733.33", "wps": "87778.5", "ups": "0.33", "wpb": "263127", "bsz": "1733.3", "num_updates": "109200", "lr": "0.000395109", "gnorm": "0.264", "loss_scale": "4", "train_wall": "238", "gb_free": "39.6", "wall": "204466"}
[2024-10-07 02:58:13,534][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 03:01:18,374][train_inner][INFO] - {"epoch": 229, "update": 228.493, "loss": "0.829", "ntokens": "263664", "nsentences": "1804.19", "wps": "258283", "ups": "0.98", "wpb": "263664", "bsz": "1804.2", "num_updates": "109400", "lr": "0.000394837", "gnorm": "0.271", "loss_scale": "2", "train_wall": "198", "gb_free": "40.3", "wall": "204671"}
[2024-10-07 03:05:09,274][train_inner][INFO] - {"epoch": 229, "update": 228.91, "loss": "0.831", "ntokens": "264100", "nsentences": "1719.32", "wps": "228768", "ups": "0.87", "wpb": "264100", "bsz": "1719.3", "num_updates": "109600", "lr": "0.000394565", "gnorm": "0.272", "loss_scale": "2", "train_wall": "158", "gb_free": "39.2", "wall": "204901"}
[2024-10-07 03:06:16,322][fairseq_cli.train][INFO] - end of epoch 229 (average epoch stats below)
[2024-10-07 03:06:16,354][train][INFO] - {"epoch": 229, "train_loss": "0.83", "train_ntokens": "263431", "train_nsentences": "1753.53", "train_wps": "139879", "train_ups": "0.53", "train_wpb": "263431", "train_bsz": "1753.5", "train_num_updates": "109643", "train_lr": "0.000394507", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "439", "train_gb_free": "39.8", "train_wall": "204969"}
[2024-10-07 03:06:16,487][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 03:06:16,497][fairseq.trainer][INFO] - begin training epoch 230
[2024-10-07 03:06:16,498][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:14:55,335][train_inner][INFO] - {"epoch": 230, "update": 229.328, "loss": "0.828", "ntokens": "263123", "nsentences": "1712.21", "wps": "89795.9", "ups": "0.34", "wpb": "263122", "bsz": "1712.2", "num_updates": "109800", "lr": "0.000394293", "gnorm": "0.265", "loss_scale": "2", "train_wall": "207", "gb_free": "39.6", "wall": "205488"}
[2024-10-07 03:19:04,532][train_inner][INFO] - {"epoch": 230, "update": 229.745, "loss": "0.83", "ntokens": "263888", "nsentences": "1773.98", "wps": "211798", "ups": "0.8", "wpb": "263888", "bsz": "1774", "num_updates": "110000", "lr": "0.000394022", "gnorm": "0.268", "loss_scale": "2", "train_wall": "159", "gb_free": "39.2", "wall": "205737"}
[2024-10-07 03:21:44,397][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 230 @ 110122 updates
[2024-10-07 03:21:44,398][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 03:21:56,404][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 03:21:56,408][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 230 @ 110122 updates, score None) (writing took 12.010863173753023 seconds)
[2024-10-07 03:21:56,408][fairseq_cli.train][INFO] - end of epoch 230 (average epoch stats below)
[2024-10-07 03:21:56,411][train][INFO] - {"epoch": 230, "train_loss": "0.83", "train_ntokens": "263457", "train_nsentences": "1753.71", "train_wps": "134244", "train_ups": "0.51", "train_wpb": "263457", "train_bsz": "1753.7", "train_num_updates": "110122", "train_lr": "0.000393856", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "205909"}
[2024-10-07 03:21:56,443][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 03:21:56,462][fairseq.trainer][INFO] - begin training epoch 231
[2024-10-07 03:21:56,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:28:41,874][train_inner][INFO] - {"epoch": 231, "update": 230.163, "loss": "0.83", "ntokens": "262499", "nsentences": "1767.29", "wps": "90936.8", "ups": "0.35", "wpb": "262499", "bsz": "1767.3", "num_updates": "110200", "lr": "0.00039375", "gnorm": "0.266", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "206314"}
[2024-10-07 03:32:21,506][train_inner][INFO] - {"epoch": 231, "update": 230.58, "loss": "0.828", "ntokens": "263878", "nsentences": "1756.58", "wps": "240315", "ups": "0.91", "wpb": "263878", "bsz": "1756.6", "num_updates": "110400", "lr": "0.000393478", "gnorm": "0.253", "loss_scale": "2", "train_wall": "213", "gb_free": "40.5", "wall": "206534"}
[2024-10-07 03:36:42,726][train_inner][INFO] - {"epoch": 231, "update": 230.998, "loss": "0.832", "ntokens": "264112", "nsentences": "1750.57", "wps": "202242", "ups": "0.77", "wpb": "264112", "bsz": "1750.6", "num_updates": "110600", "lr": "0.000393207", "gnorm": "0.254", "loss_scale": "2", "train_wall": "253", "gb_free": "39.2", "wall": "206795"}
[2024-10-07 03:36:43,836][fairseq_cli.train][INFO] - end of epoch 231 (average epoch stats below)
[2024-10-07 03:36:43,850][train][INFO] - {"epoch": 231, "train_loss": "0.83", "train_ntokens": "263484", "train_nsentences": "1753.71", "train_wps": "142220", "train_ups": "0.54", "train_wpb": "263484", "train_bsz": "1753.7", "train_num_updates": "110601", "train_lr": "0.000393205", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "561", "train_gb_free": "39.6", "train_wall": "206796"}
[2024-10-07 03:36:43,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 03:36:43,905][fairseq.trainer][INFO] - begin training epoch 232
[2024-10-07 03:36:43,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:46:13,471][train_inner][INFO] - {"epoch": 232, "update": 231.415, "loss": "0.827", "ntokens": "263417", "nsentences": "1713.78", "wps": "92307.7", "ups": "0.35", "wpb": "263417", "bsz": "1713.8", "num_updates": "110800", "lr": "0.000392935", "gnorm": "0.256", "loss_scale": "2", "train_wall": "239", "gb_free": "39.3", "wall": "207366"}
[2024-10-07 03:50:12,526][train_inner][INFO] - {"epoch": 232, "update": 231.833, "loss": "0.832", "ntokens": "263497", "nsentences": "1800.89", "wps": "220457", "ups": "0.84", "wpb": "263497", "bsz": "1800.9", "num_updates": "111000", "lr": "0.000392663", "gnorm": "0.256", "loss_scale": "2", "train_wall": "233", "gb_free": "39.6", "wall": "207605"}
[2024-10-07 03:51:56,258][fairseq_cli.train][INFO] - end of epoch 232 (average epoch stats below)
[2024-10-07 03:51:56,291][train][INFO] - {"epoch": 232, "train_loss": "0.83", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "138359", "train_ups": "0.52", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "111080", "train_lr": "0.000392554", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "40.5", "train_wall": "207708"}
[2024-10-07 03:51:56,430][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 03:51:56,449][fairseq.trainer][INFO] - begin training epoch 233
[2024-10-07 03:51:56,449][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 03:59:47,652][train_inner][INFO] - {"epoch": 233, "update": 232.251, "loss": "0.829", "ntokens": "262968", "nsentences": "1735.54", "wps": "91449.6", "ups": "0.35", "wpb": "262968", "bsz": "1735.5", "num_updates": "111200", "lr": "0.000392391", "gnorm": "0.268", "loss_scale": "2", "train_wall": "227", "gb_free": "40", "wall": "208180"}
[2024-10-07 04:03:37,560][train_inner][INFO] - {"epoch": 233, "update": 232.668, "loss": "0.829", "ntokens": "264040", "nsentences": "1751.96", "wps": "229709", "ups": "0.87", "wpb": "264040", "bsz": "1752", "num_updates": "111400", "lr": "0.00039212", "gnorm": "0.255", "loss_scale": "4", "train_wall": "221", "gb_free": "39.3", "wall": "208410"}
[2024-10-07 04:06:44,371][fairseq_cli.train][INFO] - end of epoch 233 (average epoch stats below)
[2024-10-07 04:06:44,406][train][INFO] - {"epoch": 233, "train_loss": "0.83", "train_ntokens": "263528", "train_nsentences": "1753.71", "train_wps": "142137", "train_ups": "0.54", "train_wpb": "263528", "train_bsz": "1753.7", "train_num_updates": "111559", "train_lr": "0.000391904", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "528", "train_gb_free": "40", "train_wall": "208597"}
[2024-10-07 04:06:44,488][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 04:06:44,501][fairseq.trainer][INFO] - begin training epoch 234
[2024-10-07 04:06:44,502][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:13:27,205][train_inner][INFO] - {"epoch": 234, "update": 233.086, "loss": "0.83", "ntokens": "262704", "nsentences": "1753.04", "wps": "89109.1", "ups": "0.34", "wpb": "262704", "bsz": "1753", "num_updates": "111600", "lr": "0.000391848", "gnorm": "0.263", "loss_scale": "4", "train_wall": "248", "gb_free": "39.2", "wall": "208999"}
[2024-10-07 04:16:55,342][train_inner][INFO] - {"epoch": 234, "update": 233.503, "loss": "0.827", "ntokens": "264020", "nsentences": "1734.48", "wps": "253756", "ups": "0.96", "wpb": "264020", "bsz": "1734.5", "num_updates": "111800", "lr": "0.000391576", "gnorm": "0.263", "loss_scale": "4", "train_wall": "202", "gb_free": "39.6", "wall": "209208"}
[2024-10-07 04:20:48,547][train_inner][INFO] - {"epoch": 234, "update": 233.921, "loss": "0.831", "ntokens": "263449", "nsentences": "1790.88", "wps": "225959", "ups": "0.86", "wpb": "263449", "bsz": "1790.9", "num_updates": "112000", "lr": "0.000391304", "gnorm": "0.266", "loss_scale": "4", "train_wall": "228", "gb_free": "39.2", "wall": "209441"}
[2024-10-07 04:21:39,753][fairseq_cli.train][INFO] - end of epoch 234 (average epoch stats below)
[2024-10-07 04:21:39,778][train][INFO] - {"epoch": 234, "train_loss": "0.829", "train_ntokens": "263306", "train_nsentences": "1753.71", "train_wps": "140864", "train_ups": "0.53", "train_wpb": "263306", "train_bsz": "1753.7", "train_num_updates": "112038", "train_lr": "0.000391253", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "547", "train_gb_free": "39.6", "train_wall": "209492"}
[2024-10-07 04:21:40,013][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 04:21:40,030][fairseq.trainer][INFO] - begin training epoch 235
[2024-10-07 04:21:40,031][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:31:16,508][train_inner][INFO] - {"epoch": 235, "update": 234.338, "loss": "0.829", "ntokens": "262856", "nsentences": "1751.08", "wps": "83719.5", "ups": "0.32", "wpb": "262856", "bsz": "1751.1", "num_updates": "112200", "lr": "0.000391033", "gnorm": "0.257", "loss_scale": "4", "train_wall": "250", "gb_free": "39.3", "wall": "210069"}
[2024-10-07 04:31:21,253][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 04:35:31,208][train_inner][INFO] - {"epoch": 235, "update": 234.758, "loss": "0.829", "ntokens": "263967", "nsentences": "1766.13", "wps": "207289", "ups": "0.79", "wpb": "263967", "bsz": "1766.1", "num_updates": "112400", "lr": "0.000390761", "gnorm": "0.249", "loss_scale": "2", "train_wall": "249", "gb_free": "40.2", "wall": "210323"}
[2024-10-07 04:37:34,101][fairseq_cli.train][INFO] - end of epoch 235 (average epoch stats below)
[2024-10-07 04:37:34,123][train][INFO] - {"epoch": 235, "train_loss": "0.829", "train_ntokens": "263536", "train_nsentences": "1754.38", "train_wps": "131997", "train_ups": "0.5", "train_wpb": "263536", "train_bsz": "1754.4", "train_num_updates": "112516", "train_lr": "0.000390603", "train_gnorm": "0.254", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.8", "train_wall": "210446"}
[2024-10-07 04:37:34,388][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 04:37:34,427][fairseq.trainer][INFO] - begin training epoch 236
[2024-10-07 04:37:34,427][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:45:32,410][train_inner][INFO] - {"epoch": 236, "update": 235.175, "loss": "0.827", "ntokens": "263359", "nsentences": "1687.74", "wps": "87614.3", "ups": "0.33", "wpb": "263359", "bsz": "1687.7", "num_updates": "112600", "lr": "0.000390489", "gnorm": "0.274", "loss_scale": "2", "train_wall": "235", "gb_free": "39.6", "wall": "210925"}
[2024-10-07 04:49:26,637][train_inner][INFO] - {"epoch": 236, "update": 235.593, "loss": "0.833", "ntokens": "263324", "nsentences": "1836.32", "wps": "224858", "ups": "0.85", "wpb": "263324", "bsz": "1836.3", "num_updates": "112800", "lr": "0.000390217", "gnorm": "0.267", "loss_scale": "2", "train_wall": "229", "gb_free": "40", "wall": "211159"}
[2024-10-07 04:53:42,870][fairseq_cli.train][INFO] - end of epoch 236 (average epoch stats below)
[2024-10-07 04:53:42,891][train][INFO] - {"epoch": 236, "train_loss": "0.829", "train_ntokens": "263554", "train_nsentences": "1753.71", "train_wps": "130313", "train_ups": "0.49", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "112995", "train_lr": "0.000389952", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "596", "train_gb_free": "39.2", "train_wall": "211415"}
[2024-10-07 04:53:42,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 04:53:42,968][fairseq.trainer][INFO] - begin training epoch 237
[2024-10-07 04:53:42,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 04:59:45,062][train_inner][INFO] - {"epoch": 237, "update": 236.01, "loss": "0.828", "ntokens": "263190", "nsentences": "1716.93", "wps": "85117.9", "ups": "0.32", "wpb": "263190", "bsz": "1716.9", "num_updates": "113000", "lr": "0.000389946", "gnorm": "0.263", "loss_scale": "2", "train_wall": "274", "gb_free": "39.8", "wall": "211777"}
[2024-10-07 05:02:48,512][train_inner][INFO] - {"epoch": 237, "update": 236.428, "loss": "0.826", "ntokens": "263986", "nsentences": "1742.49", "wps": "287821", "ups": "1.09", "wpb": "263986", "bsz": "1742.5", "num_updates": "113200", "lr": "0.000389674", "gnorm": "0.264", "loss_scale": "2", "train_wall": "165", "gb_free": "39.6", "wall": "211961"}
[2024-10-07 05:07:08,856][train_inner][INFO] - {"epoch": 237, "update": 236.846, "loss": "0.831", "ntokens": "263958", "nsentences": "1762.5", "wps": "202786", "ups": "0.77", "wpb": "263958", "bsz": "1762.5", "num_updates": "113400", "lr": "0.000389402", "gnorm": "0.254", "loss_scale": "2", "train_wall": "255", "gb_free": "40.2", "wall": "212221"}
[2024-10-07 05:08:53,760][fairseq_cli.train][INFO] - end of epoch 237 (average epoch stats below)
[2024-10-07 05:08:53,782][train][INFO] - {"epoch": 237, "train_loss": "0.829", "train_ntokens": "263486", "train_nsentences": "1753.71", "train_wps": "138558", "train_ups": "0.53", "train_wpb": "263486", "train_bsz": "1753.7", "train_num_updates": "113474", "train_lr": "0.000389302", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "39.6", "train_wall": "212326"}
[2024-10-07 05:08:53,888][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 05:08:53,924][fairseq.trainer][INFO] - begin training epoch 238
[2024-10-07 05:08:53,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:16:41,064][train_inner][INFO] - {"epoch": 238, "update": 237.263, "loss": "0.827", "ntokens": "263033", "nsentences": "1728.2", "wps": "91939.4", "ups": "0.35", "wpb": "263033", "bsz": "1728.2", "num_updates": "113600", "lr": "0.00038913", "gnorm": "0.251", "loss_scale": "2", "train_wall": "238", "gb_free": "39.6", "wall": "212793"}
[2024-10-07 05:20:24,898][train_inner][INFO] - {"epoch": 238, "update": 237.681, "loss": "0.829", "ntokens": "264000", "nsentences": "1758.3", "wps": "235902", "ups": "0.89", "wpb": "264000", "bsz": "1758.3", "num_updates": "113800", "lr": "0.000388859", "gnorm": "0.264", "loss_scale": "2", "train_wall": "218", "gb_free": "39.6", "wall": "213017"}
[2024-10-07 05:23:23,260][fairseq_cli.train][INFO] - end of epoch 238 (average epoch stats below)
[2024-10-07 05:23:23,268][train][INFO] - {"epoch": 238, "train_loss": "0.828", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "145168", "train_ups": "0.55", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "113953", "train_lr": "0.000388651", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "526", "train_gb_free": "40.2", "train_wall": "213195"}
[2024-10-07 05:23:23,375][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 05:23:23,401][fairseq.trainer][INFO] - begin training epoch 239
[2024-10-07 05:23:23,402][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:30:08,407][train_inner][INFO] - {"epoch": 239, "update": 238.098, "loss": "0.83", "ntokens": "262548", "nsentences": "1774.6", "wps": "89993", "ups": "0.34", "wpb": "262548", "bsz": "1774.6", "num_updates": "114000", "lr": "0.000388587", "gnorm": "0.258", "loss_scale": "2", "train_wall": "247", "gb_free": "40.1", "wall": "213601"}
[2024-10-07 05:33:47,250][train_inner][INFO] - {"epoch": 239, "update": 238.516, "loss": "0.825", "ntokens": "264099", "nsentences": "1741.09", "wps": "241368", "ups": "0.91", "wpb": "264099", "bsz": "1741.1", "num_updates": "114200", "lr": "0.000388315", "gnorm": "0.253", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "213819"}
[2024-10-07 05:38:02,267][train_inner][INFO] - {"epoch": 239, "update": 238.933, "loss": "0.831", "ntokens": "263892", "nsentences": "1785.19", "wps": "206976", "ups": "0.78", "wpb": "263892", "bsz": "1785.2", "num_updates": "114400", "lr": "0.000388043", "gnorm": "0.276", "loss_scale": "4", "train_wall": "250", "gb_free": "39.3", "wall": "214074"}
[2024-10-07 05:38:56,725][fairseq_cli.train][INFO] - end of epoch 239 (average epoch stats below)
[2024-10-07 05:38:56,778][train][INFO] - {"epoch": 239, "train_loss": "0.828", "train_ntokens": "263520", "train_nsentences": "1753.71", "train_wps": "135220", "train_ups": "0.51", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "114432", "train_lr": "0.000388", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "585", "train_gb_free": "41", "train_wall": "214129"}
[2024-10-07 05:38:56,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 05:38:56,982][fairseq.trainer][INFO] - begin training epoch 240
[2024-10-07 05:38:56,982][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 05:47:44,629][train_inner][INFO] - {"epoch": 240, "update": 239.351, "loss": "0.825", "ntokens": "263039", "nsentences": "1746.01", "wps": "90336.4", "ups": "0.34", "wpb": "263039", "bsz": "1746", "num_updates": "114600", "lr": "0.000387772", "gnorm": "0.264", "loss_scale": "4", "train_wall": "224", "gb_free": "39.6", "wall": "214657"}
[2024-10-07 05:51:51,595][train_inner][INFO] - {"epoch": 240, "update": 239.768, "loss": "0.828", "ntokens": "263777", "nsentences": "1777.61", "wps": "213626", "ups": "0.81", "wpb": "263777", "bsz": "1777.6", "num_updates": "114800", "lr": "0.0003875", "gnorm": "0.262", "loss_scale": "4", "train_wall": "242", "gb_free": "39.3", "wall": "214904"}
[2024-10-07 05:54:11,559][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 240 @ 114911 updates
[2024-10-07 05:54:11,562][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 05:54:21,259][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 05:54:21,593][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 240 @ 114911 updates, score None) (writing took 10.034528429619968 seconds)
[2024-10-07 05:54:21,610][fairseq_cli.train][INFO] - end of epoch 240 (average epoch stats below)
[2024-10-07 05:54:21,618][train][INFO] - {"epoch": 240, "train_loss": "0.827", "train_ntokens": "263520", "train_nsentences": "1753.71", "train_wps": "136486", "train_ups": "0.52", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "114911", "train_lr": "0.000387349", "train_gnorm": "0.267", "train_loss_scale": "4", "train_train_wall": "550", "train_gb_free": "40", "train_wall": "215054"}
[2024-10-07 05:54:21,723][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 05:54:21,739][fairseq.trainer][INFO] - begin training epoch 241
[2024-10-07 05:54:21,739][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:01:51,432][train_inner][INFO] - {"epoch": 241, "update": 240.186, "loss": "0.829", "ntokens": "262678", "nsentences": "1764.31", "wps": "87586", "ups": "0.33", "wpb": "262678", "bsz": "1764.3", "num_updates": "115000", "lr": "0.000387228", "gnorm": "0.296", "loss_scale": "4", "train_wall": "255", "gb_free": "39.6", "wall": "215504"}
[2024-10-07 06:05:17,854][train_inner][INFO] - {"epoch": 241, "update": 240.603, "loss": "0.825", "ntokens": "264460", "nsentences": "1708.35", "wps": "256251", "ups": "0.97", "wpb": "264460", "bsz": "1708.3", "num_updates": "115200", "lr": "0.000386957", "gnorm": "0.264", "loss_scale": "4", "train_wall": "201", "gb_free": "40", "wall": "215710"}
[2024-10-07 06:09:00,173][fairseq_cli.train][INFO] - end of epoch 241 (average epoch stats below)
[2024-10-07 06:09:00,186][train][INFO] - {"epoch": 241, "train_loss": "0.827", "train_ntokens": "263554", "train_nsentences": "1753.71", "train_wps": "143692", "train_ups": "0.55", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "115390", "train_lr": "0.000386698", "train_gnorm": "0.277", "train_loss_scale": "4", "train_train_wall": "532", "train_gb_free": "39.7", "train_wall": "215932"}
[2024-10-07 06:09:00,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 06:09:00,319][fairseq.trainer][INFO] - begin training epoch 242
[2024-10-07 06:09:00,320][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:15:02,771][train_inner][INFO] - {"epoch": 242, "update": 241.021, "loss": "0.83", "ntokens": "262718", "nsentences": "1757.16", "wps": "89834.4", "ups": "0.34", "wpb": "262718", "bsz": "1757.2", "num_updates": "115400", "lr": "0.000386685", "gnorm": "0.276", "loss_scale": "4", "train_wall": "229", "gb_free": "39.3", "wall": "216295"}
[2024-10-07 06:19:08,386][train_inner][INFO] - {"epoch": 242, "update": 241.438, "loss": "0.828", "ntokens": "263677", "nsentences": "1782.73", "wps": "214726", "ups": "0.81", "wpb": "263677", "bsz": "1782.7", "num_updates": "115600", "lr": "0.000386413", "gnorm": "0.248", "loss_scale": "4", "train_wall": "240", "gb_free": "39.7", "wall": "216541"}
[2024-10-07 06:23:23,226][train_inner][INFO] - {"epoch": 242, "update": 241.856, "loss": "0.825", "ntokens": "264148", "nsentences": "1729.33", "wps": "207316", "ups": "0.78", "wpb": "264148", "bsz": "1729.3", "num_updates": "115800", "lr": "0.000386141", "gnorm": "0.255", "loss_scale": "4", "train_wall": "249", "gb_free": "39.6", "wall": "216795"}
[2024-10-07 06:24:40,482][fairseq_cli.train][INFO] - end of epoch 242 (average epoch stats below)
[2024-10-07 06:24:40,558][train][INFO] - {"epoch": 242, "train_loss": "0.827", "train_ntokens": "263351", "train_nsentences": "1753.71", "train_wps": "134147", "train_ups": "0.51", "train_wpb": "263351", "train_bsz": "1753.7", "train_num_updates": "115869", "train_lr": "0.000386048", "train_gnorm": "0.253", "train_loss_scale": "4", "train_train_wall": "579", "train_gb_free": "39.3", "train_wall": "216873"}
[2024-10-07 06:24:40,741][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 06:24:40,774][fairseq.trainer][INFO] - begin training epoch 243
[2024-10-07 06:24:40,775][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:33:04,261][train_inner][INFO] - {"epoch": 243, "update": 242.273, "loss": "0.823", "ntokens": "263015", "nsentences": "1713.67", "wps": "90535.3", "ups": "0.34", "wpb": "263015", "bsz": "1713.7", "num_updates": "116000", "lr": "0.00038587", "gnorm": "0.271", "loss_scale": "4", "train_wall": "192", "gb_free": "40.1", "wall": "217376"}
[2024-10-07 06:37:05,450][train_inner][INFO] - {"epoch": 243, "update": 242.691, "loss": "0.829", "ntokens": "263454", "nsentences": "1813.91", "wps": "218486", "ups": "0.83", "wpb": "263454", "bsz": "1813.9", "num_updates": "116200", "lr": "0.000385598", "gnorm": "0.272", "loss_scale": "4", "train_wall": "164", "gb_free": "40", "wall": "217618"}
[2024-10-07 06:38:56,896][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-07 06:39:56,436][fairseq_cli.train][INFO] - end of epoch 243 (average epoch stats below)
[2024-10-07 06:39:56,482][train][INFO] - {"epoch": 243, "train_loss": "0.827", "train_ntokens": "263472", "train_nsentences": "1753.65", "train_wps": "137503", "train_ups": "0.52", "train_wpb": "263472", "train_bsz": "1753.7", "train_num_updates": "116347", "train_lr": "0.000385398", "train_gnorm": "0.268", "train_loss_scale": "4", "train_train_wall": "403", "train_gb_free": "39.7", "train_wall": "217789"}
[2024-10-07 06:39:56,668][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 06:39:56,704][fairseq.trainer][INFO] - begin training epoch 244
[2024-10-07 06:39:56,704][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 06:47:58,539][train_inner][INFO] - {"epoch": 244, "update": 243.111, "loss": "0.83", "ntokens": "262875", "nsentences": "1733.57", "wps": "80503.2", "ups": "0.31", "wpb": "262875", "bsz": "1733.6", "num_updates": "116400", "lr": "0.000385326", "gnorm": "0.253", "loss_scale": "4", "train_wall": "178", "gb_free": "39.2", "wall": "218271"}
[2024-10-07 06:51:25,766][train_inner][INFO] - {"epoch": 244, "update": 243.528, "loss": "0.823", "ntokens": "264454", "nsentences": "1710.99", "wps": "255341", "ups": "0.97", "wpb": "264454", "bsz": "1711", "num_updates": "116600", "lr": "0.000385054", "gnorm": "0.257", "loss_scale": "4", "train_wall": "158", "gb_free": "40.2", "wall": "218478"}
[2024-10-07 06:55:28,318][train_inner][INFO] - {"epoch": 244, "update": 243.946, "loss": "0.83", "ntokens": "263796", "nsentences": "1778.88", "wps": "217612", "ups": "0.82", "wpb": "263796", "bsz": "1778.9", "num_updates": "116800", "lr": "0.000384783", "gnorm": "0.254", "loss_scale": "4", "train_wall": "165", "gb_free": "39.6", "wall": "218720"}
[2024-10-07 06:56:13,641][fairseq_cli.train][INFO] - end of epoch 244 (average epoch stats below)
[2024-10-07 06:56:13,659][train][INFO] - {"epoch": 244, "train_loss": "0.827", "train_ntokens": "263528", "train_nsentences": "1753.71", "train_wps": "129179", "train_ups": "0.49", "train_wpb": "263528", "train_bsz": "1753.7", "train_num_updates": "116826", "train_lr": "0.000384747", "train_gnorm": "0.256", "train_loss_scale": "4", "train_train_wall": "419", "train_gb_free": "39.6", "train_wall": "218766"}
[2024-10-07 06:56:13,866][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 06:56:13,920][fairseq.trainer][INFO] - begin training epoch 245
[2024-10-07 06:56:13,921][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:05:09,653][train_inner][INFO] - {"epoch": 245, "update": 244.363, "loss": "0.825", "ntokens": "262819", "nsentences": "1754.31", "wps": "90420.6", "ups": "0.34", "wpb": "262819", "bsz": "1754.3", "num_updates": "117000", "lr": "0.000384511", "gnorm": "0.267", "loss_scale": "4", "train_wall": "212", "gb_free": "39.8", "wall": "219302"}
[2024-10-07 07:07:05,924][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 07:09:07,826][train_inner][INFO] - {"epoch": 245, "update": 244.783, "loss": "0.827", "ntokens": "263964", "nsentences": "1742.53", "wps": "221671", "ups": "0.84", "wpb": "263964", "bsz": "1742.5", "num_updates": "117200", "lr": "0.000384239", "gnorm": "0.274", "loss_scale": "2", "train_wall": "194", "gb_free": "40.5", "wall": "219540"}
[2024-10-07 07:11:24,330][fairseq_cli.train][INFO] - end of epoch 245 (average epoch stats below)
[2024-10-07 07:11:24,352][train][INFO] - {"epoch": 245, "train_loss": "0.826", "train_ntokens": "263414", "train_nsentences": "1752.93", "train_wps": "138266", "train_ups": "0.52", "train_wpb": "263414", "train_bsz": "1752.9", "train_num_updates": "117304", "train_lr": "0.000384098", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "478", "train_gb_free": "39.6", "train_wall": "219677"}
[2024-10-07 07:11:24,535][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 07:11:24,567][fairseq.trainer][INFO] - begin training epoch 246
[2024-10-07 07:11:24,568][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:19:09,886][train_inner][INFO] - {"epoch": 246, "update": 245.2, "loss": "0.826", "ntokens": "262180", "nsentences": "1811.65", "wps": "87099.5", "ups": "0.33", "wpb": "262180", "bsz": "1811.7", "num_updates": "117400", "lr": "0.000383967", "gnorm": "0.248", "loss_scale": "2", "train_wall": "249", "gb_free": "39.4", "wall": "220142"}
[2024-10-07 07:22:44,802][train_inner][INFO] - {"epoch": 246, "update": 245.618, "loss": "0.825", "ntokens": "264207", "nsentences": "1746.78", "wps": "245894", "ups": "0.93", "wpb": "264207", "bsz": "1746.8", "num_updates": "117600", "lr": "0.000383696", "gnorm": "0.258", "loss_scale": "2", "train_wall": "208", "gb_free": "40", "wall": "220357"}
[2024-10-07 07:26:21,856][fairseq_cli.train][INFO] - end of epoch 246 (average epoch stats below)
[2024-10-07 07:26:21,892][train][INFO] - {"epoch": 246, "train_loss": "0.826", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "140693", "train_ups": "0.53", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "117783", "train_lr": "0.000383447", "train_gnorm": "0.254", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "40.1", "train_wall": "220574"}
[2024-10-07 07:26:22,019][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 07:26:22,049][fairseq.trainer][INFO] - begin training epoch 247
[2024-10-07 07:26:22,051][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:32:35,040][train_inner][INFO] - {"epoch": 247, "update": 246.035, "loss": "0.828", "ntokens": "263182", "nsentences": "1731.88", "wps": "89184.2", "ups": "0.34", "wpb": "263182", "bsz": "1731.9", "num_updates": "117800", "lr": "0.000383424", "gnorm": "0.253", "loss_scale": "2", "train_wall": "254", "gb_free": "40", "wall": "220947"}
[2024-10-07 07:36:21,840][train_inner][INFO] - {"epoch": 247, "update": 246.453, "loss": "0.825", "ntokens": "263871", "nsentences": "1755.16", "wps": "232726", "ups": "0.88", "wpb": "263871", "bsz": "1755.2", "num_updates": "118000", "lr": "0.000383152", "gnorm": "0.278", "loss_scale": "2", "train_wall": "222", "gb_free": "40", "wall": "221174"}
[2024-10-07 07:40:30,688][train_inner][INFO] - {"epoch": 247, "update": 246.871, "loss": "0.826", "ntokens": "264109", "nsentences": "1759.89", "wps": "212290", "ups": "0.8", "wpb": "264109", "bsz": "1759.9", "num_updates": "118200", "lr": "0.00038288", "gnorm": "0.255", "loss_scale": "2", "train_wall": "243", "gb_free": "39.6", "wall": "221423"}
[2024-10-07 07:42:03,785][fairseq_cli.train][INFO] - end of epoch 247 (average epoch stats below)
[2024-10-07 07:42:03,807][train][INFO] - {"epoch": 247, "train_loss": "0.825", "train_ntokens": "263489", "train_nsentences": "1753.71", "train_wps": "133996", "train_ups": "0.51", "train_wpb": "263489", "train_bsz": "1753.7", "train_num_updates": "118262", "train_lr": "0.000382796", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "601", "train_gb_free": "39.6", "train_wall": "221516"}
[2024-10-07 07:42:03,908][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 07:42:03,933][fairseq.trainer][INFO] - begin training epoch 248
[2024-10-07 07:42:03,933][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 07:50:59,276][train_inner][INFO] - {"epoch": 248, "update": 247.288, "loss": "0.826", "ntokens": "262701", "nsentences": "1763.36", "wps": "83586.4", "ups": "0.32", "wpb": "262701", "bsz": "1763.4", "num_updates": "118400", "lr": "0.000382609", "gnorm": "0.261", "loss_scale": "2", "train_wall": "238", "gb_free": "39.6", "wall": "222051"}
[2024-10-07 07:54:53,407][train_inner][INFO] - {"epoch": 248, "update": 247.706, "loss": "0.825", "ntokens": "263576", "nsentences": "1788.39", "wps": "225171", "ups": "0.85", "wpb": "263576", "bsz": "1788.4", "num_updates": "118600", "lr": "0.000382337", "gnorm": "0.245", "loss_scale": "2", "train_wall": "181", "gb_free": "39.2", "wall": "222286"}
[2024-10-07 07:57:44,785][fairseq_cli.train][INFO] - end of epoch 248 (average epoch stats below)
[2024-10-07 07:57:44,790][train][INFO] - {"epoch": 248, "train_loss": "0.825", "train_ntokens": "263434", "train_nsentences": "1753.71", "train_wps": "134100", "train_ups": "0.51", "train_wpb": "263434", "train_bsz": "1753.7", "train_num_updates": "118741", "train_lr": "0.000382145", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "497", "train_gb_free": "39.8", "train_wall": "222457"}
[2024-10-07 07:57:44,926][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 07:57:44,952][fairseq.trainer][INFO] - begin training epoch 249
[2024-10-07 07:57:44,952][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:04:32,899][train_inner][INFO] - {"epoch": 249, "update": 248.123, "loss": "0.823", "ntokens": "263147", "nsentences": "1700.45", "wps": "90823.5", "ups": "0.35", "wpb": "263147", "bsz": "1700.5", "num_updates": "118800", "lr": "0.000382065", "gnorm": "0.264", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "222865"}
[2024-10-07 08:08:11,314][train_inner][INFO] - {"epoch": 249, "update": 248.541, "loss": "0.825", "ntokens": "264174", "nsentences": "1742.42", "wps": "241909", "ups": "0.92", "wpb": "264174", "bsz": "1742.4", "num_updates": "119000", "lr": "0.000381793", "gnorm": "0.256", "loss_scale": "2", "train_wall": "212", "gb_free": "39.6", "wall": "223083"}
[2024-10-07 08:11:58,767][train_inner][INFO] - {"epoch": 249, "update": 248.958, "loss": "0.826", "ntokens": "264025", "nsentences": "1756.88", "wps": "232170", "ups": "0.88", "wpb": "264025", "bsz": "1756.9", "num_updates": "119200", "lr": "0.000381522", "gnorm": "0.273", "loss_scale": "4", "train_wall": "222", "gb_free": "39.6", "wall": "223311"}
[2024-10-07 08:12:40,577][fairseq_cli.train][INFO] - end of epoch 249 (average epoch stats below)
[2024-10-07 08:12:40,585][train][INFO] - {"epoch": 249, "train_loss": "0.825", "train_ntokens": "263564", "train_nsentences": "1753.71", "train_wps": "140933", "train_ups": "0.53", "train_wpb": "263564", "train_bsz": "1753.7", "train_num_updates": "119220", "train_lr": "0.000381495", "train_gnorm": "0.261", "train_loss_scale": "4", "train_train_wall": "551", "train_gb_free": "39.7", "train_wall": "223353"}
[2024-10-07 08:12:40,748][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 08:12:40,784][fairseq.trainer][INFO] - begin training epoch 250
[2024-10-07 08:12:40,785][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:20:22,266][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 08:22:03,571][train_inner][INFO] - {"epoch": 250, "update": 249.378, "loss": "0.823", "ntokens": "263197", "nsentences": "1740.73", "wps": "87036.8", "ups": "0.33", "wpb": "263197", "bsz": "1740.7", "num_updates": "119400", "lr": "0.00038125", "gnorm": "0.255", "loss_scale": "2", "train_wall": "281", "gb_free": "39.1", "wall": "223916"}
[2024-10-07 08:26:00,473][train_inner][INFO] - {"epoch": 250, "update": 249.795, "loss": "0.826", "ntokens": "264274", "nsentences": "1747.11", "wps": "223119", "ups": "0.84", "wpb": "264274", "bsz": "1747.1", "num_updates": "119600", "lr": "0.000380978", "gnorm": "0.265", "loss_scale": "2", "train_wall": "231", "gb_free": "40", "wall": "224153"}
[2024-10-07 08:28:11,988][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 250 @ 119698 updates
[2024-10-07 08:28:11,998][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 08:28:21,022][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 08:28:21,095][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 250 @ 119698 updates, score None) (writing took 9.10681554954499 seconds)
[2024-10-07 08:28:21,098][fairseq_cli.train][INFO] - end of epoch 250 (average epoch stats below)
[2024-10-07 08:28:21,114][train][INFO] - {"epoch": 250, "train_loss": "0.826", "train_ntokens": "263716", "train_nsentences": "1751.89", "train_wps": "134032", "train_ups": "0.51", "train_wpb": "263716", "train_bsz": "1751.9", "train_num_updates": "119698", "train_lr": "0.000380845", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "600", "train_gb_free": "40", "train_wall": "224293"}
[2024-10-07 08:28:21,208][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 08:28:21,250][fairseq.trainer][INFO] - begin training epoch 251
[2024-10-07 08:28:21,251][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:35:41,908][train_inner][INFO] - {"epoch": 251, "update": 250.213, "loss": "0.827", "ntokens": "262282", "nsentences": "1804.4", "wps": "90221.8", "ups": "0.34", "wpb": "262282", "bsz": "1804.4", "num_updates": "119800", "lr": "0.000380707", "gnorm": "0.259", "loss_scale": "2", "train_wall": "243", "gb_free": "39.6", "wall": "224734"}
[2024-10-07 08:39:11,627][train_inner][INFO] - {"epoch": 251, "update": 250.63, "loss": "0.826", "ntokens": "264111", "nsentences": "1742.78", "wps": "251883", "ups": "0.95", "wpb": "264111", "bsz": "1742.8", "num_updates": "120000", "lr": "0.000380435", "gnorm": "0.25", "loss_scale": "2", "train_wall": "204", "gb_free": "39.8", "wall": "224944"}
[2024-10-07 08:43:03,461][fairseq_cli.train][INFO] - end of epoch 251 (average epoch stats below)
[2024-10-07 08:43:03,469][train][INFO] - {"epoch": 251, "train_loss": "0.825", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "143045", "train_ups": "0.54", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "120177", "train_lr": "0.000380194", "train_gnorm": "0.256", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "40", "train_wall": "225176"}
[2024-10-07 08:43:03,555][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 08:43:03,584][fairseq.trainer][INFO] - begin training epoch 252
[2024-10-07 08:43:03,585][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 08:49:18,287][train_inner][INFO] - {"epoch": 252, "update": 251.048, "loss": "0.825", "ntokens": "262886", "nsentences": "1743.06", "wps": "86669.1", "ups": "0.33", "wpb": "262886", "bsz": "1743.1", "num_updates": "120200", "lr": "0.000380163", "gnorm": "0.261", "loss_scale": "2", "train_wall": "292", "gb_free": "39.2", "wall": "225550"}
[2024-10-07 08:52:37,257][train_inner][INFO] - {"epoch": 252, "update": 251.466, "loss": "0.825", "ntokens": "263695", "nsentences": "1781.67", "wps": "265092", "ups": "1.01", "wpb": "263695", "bsz": "1781.7", "num_updates": "120400", "lr": "0.000379891", "gnorm": "0.269", "loss_scale": "2", "train_wall": "194", "gb_free": "40", "wall": "225749"}
[2024-10-07 08:56:49,129][train_inner][INFO] - {"epoch": 252, "update": 251.883, "loss": "0.825", "ntokens": "264265", "nsentences": "1752.8", "wps": "209860", "ups": "0.79", "wpb": "264265", "bsz": "1752.8", "num_updates": "120600", "lr": "0.00037962", "gnorm": "0.271", "loss_scale": "2", "train_wall": "246", "gb_free": "39.7", "wall": "226001"}
[2024-10-07 08:58:05,491][fairseq_cli.train][INFO] - end of epoch 252 (average epoch stats below)
[2024-10-07 08:58:05,505][train][INFO] - {"epoch": 252, "train_loss": "0.825", "train_ntokens": "263547", "train_nsentences": "1753.71", "train_wps": "139950", "train_ups": "0.53", "train_wpb": "263546", "train_bsz": "1753.7", "train_num_updates": "120656", "train_lr": "0.000379543", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "582", "train_gb_free": "39.2", "train_wall": "226078"}
[2024-10-07 08:58:05,599][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 08:58:05,623][fairseq.trainer][INFO] - begin training epoch 253
[2024-10-07 08:58:05,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 09:06:10,685][train_inner][INFO] - {"epoch": 253, "update": 252.301, "loss": "0.824", "ntokens": "262776", "nsentences": "1751.71", "wps": "93590.7", "ups": "0.36", "wpb": "262776", "bsz": "1751.7", "num_updates": "120800", "lr": "0.000379348", "gnorm": "0.254", "loss_scale": "2", "train_wall": "245", "gb_free": "39.7", "wall": "226563"}
[2024-10-07 09:09:54,317][train_inner][INFO] - {"epoch": 253, "update": 252.718, "loss": "0.823", "ntokens": "264313", "nsentences": "1722.38", "wps": "236394", "ups": "0.89", "wpb": "264313", "bsz": "1722.4", "num_updates": "121000", "lr": "0.000379076", "gnorm": "0.272", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "226786"}
[2024-10-07 09:12:24,880][fairseq_cli.train][INFO] - end of epoch 253 (average epoch stats below)
[2024-10-07 09:12:24,940][train][INFO] - {"epoch": 253, "train_loss": "0.824", "train_ntokens": "263530", "train_nsentences": "1753.71", "train_wps": "146877", "train_ups": "0.56", "train_wpb": "263530", "train_bsz": "1753.7", "train_num_updates": "121135", "train_lr": "0.000378893", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.2", "train_wall": "226937"}
[2024-10-07 09:12:25,076][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 09:12:25,104][fairseq.trainer][INFO] - begin training epoch 254
[2024-10-07 09:12:25,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 09:19:34,170][train_inner][INFO] - {"epoch": 254, "update": 253.136, "loss": "0.825", "ntokens": "262552", "nsentences": "1771.83", "wps": "90561.4", "ups": "0.34", "wpb": "262552", "bsz": "1771.8", "num_updates": "121200", "lr": "0.000378804", "gnorm": "0.244", "loss_scale": "2", "train_wall": "246", "gb_free": "39.1", "wall": "227366"}
[2024-10-07 09:22:46,860][train_inner][INFO] - {"epoch": 254, "update": 253.553, "loss": "0.82", "ntokens": "264669", "nsentences": "1683.08", "wps": "274736", "ups": "1.04", "wpb": "264669", "bsz": "1683.1", "num_updates": "121400", "lr": "0.000378533", "gnorm": "0.283", "loss_scale": "4", "train_wall": "188", "gb_free": "39.6", "wall": "227559"}
[2024-10-07 09:26:44,641][train_inner][INFO] - {"epoch": 254, "update": 253.971, "loss": "0.828", "ntokens": "264097", "nsentences": "1794.11", "wps": "222141", "ups": "0.84", "wpb": "264097", "bsz": "1794.1", "num_updates": "121600", "lr": "0.000378261", "gnorm": "0.286", "loss_scale": "4", "train_wall": "233", "gb_free": "39.6", "wall": "227797"}
[2024-10-07 09:27:31,631][fairseq_cli.train][INFO] - end of epoch 254 (average epoch stats below)
[2024-10-07 09:27:31,640][train][INFO] - {"epoch": 254, "train_loss": "0.825", "train_ntokens": "263642", "train_nsentences": "1753.71", "train_wps": "139283", "train_ups": "0.53", "train_wpb": "263642", "train_bsz": "1753.7", "train_num_updates": "121614", "train_lr": "0.000378242", "train_gnorm": "0.278", "train_loss_scale": "4", "train_train_wall": "565", "train_gb_free": "39.6", "train_wall": "227844"}
[2024-10-07 09:27:31,724][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 09:27:31,754][fairseq.trainer][INFO] - begin training epoch 255
[2024-10-07 09:27:31,755][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 09:36:43,909][train_inner][INFO] - {"epoch": 255, "update": 254.388, "loss": "0.822", "ntokens": "262971", "nsentences": "1726.48", "wps": "87766.9", "ups": "0.33", "wpb": "262971", "bsz": "1726.5", "num_updates": "121800", "lr": "0.000377989", "gnorm": "0.257", "loss_scale": "4", "train_wall": "280", "gb_free": "39.3", "wall": "228396"}
[2024-10-07 09:40:58,111][train_inner][INFO] - {"epoch": 255, "update": 254.806, "loss": "0.826", "ntokens": "263828", "nsentences": "1790.73", "wps": "207612", "ups": "0.79", "wpb": "263828", "bsz": "1790.7", "num_updates": "122000", "lr": "0.000377717", "gnorm": "0.255", "loss_scale": "4", "train_wall": "248", "gb_free": "40.1", "wall": "228650"}
[2024-10-07 09:42:19,156][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 09:43:11,950][fairseq_cli.train][INFO] - end of epoch 255 (average epoch stats below)
[2024-10-07 09:43:11,954][train][INFO] - {"epoch": 255, "train_loss": "0.824", "train_ntokens": "263528", "train_nsentences": "1752.01", "train_wps": "133962", "train_ups": "0.51", "train_wpb": "263528", "train_bsz": "1752", "train_num_updates": "122092", "train_lr": "0.000377592", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "614", "train_gb_free": "39.6", "train_wall": "228784"}
[2024-10-07 09:43:12,004][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 09:43:12,023][fairseq.trainer][INFO] - begin training epoch 256
[2024-10-07 09:43:12,024][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 09:51:28,858][train_inner][INFO] - {"epoch": 256, "update": 255.225, "loss": "0.824", "ntokens": "262707", "nsentences": "1760.2", "wps": "83301.7", "ups": "0.32", "wpb": "262707", "bsz": "1760.2", "num_updates": "122200", "lr": "0.000377446", "gnorm": "0.278", "loss_scale": "2", "train_wall": "258", "gb_free": "40", "wall": "229281"}
[2024-10-07 09:55:22,806][train_inner][INFO] - {"epoch": 256, "update": 255.643, "loss": "0.823", "ntokens": "263885", "nsentences": "1759.69", "wps": "225615", "ups": "0.85", "wpb": "263885", "bsz": "1759.7", "num_updates": "122400", "lr": "0.000377174", "gnorm": "0.244", "loss_scale": "2", "train_wall": "229", "gb_free": "39.2", "wall": "229515"}
[2024-10-07 09:58:01,294][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-07 09:59:12,626][fairseq_cli.train][INFO] - end of epoch 256 (average epoch stats below)
[2024-10-07 09:59:12,646][train][INFO] - {"epoch": 256, "train_loss": "0.824", "train_ntokens": "263400", "train_nsentences": "1754.02", "train_wps": "131058", "train_ups": "0.5", "train_wpb": "263400", "train_bsz": "1754", "train_num_updates": "122570", "train_lr": "0.000376943", "train_gnorm": "0.255", "train_loss_scale": "1", "train_train_wall": "582", "train_gb_free": "39.2", "train_wall": "229745"}
[2024-10-07 09:59:12,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 09:59:12,760][fairseq.trainer][INFO] - begin training epoch 257
[2024-10-07 09:59:12,761][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 10:05:26,038][train_inner][INFO] - {"epoch": 257, "update": 256.063, "loss": "0.825", "ntokens": "262798", "nsentences": "1730.78", "wps": "87132", "ups": "0.33", "wpb": "262798", "bsz": "1730.8", "num_updates": "122600", "lr": "0.000376902", "gnorm": "0.263", "loss_scale": "1", "train_wall": "283", "gb_free": "39.2", "wall": "230118"}
[2024-10-07 10:09:09,962][train_inner][INFO] - {"epoch": 257, "update": 256.48, "loss": "0.821", "ntokens": "264210", "nsentences": "1744.64", "wps": "236021", "ups": "0.89", "wpb": "264210", "bsz": "1744.6", "num_updates": "122800", "lr": "0.00037663", "gnorm": "0.258", "loss_scale": "1", "train_wall": "218", "gb_free": "40.1", "wall": "230342"}
[2024-10-07 10:13:24,786][train_inner][INFO] - {"epoch": 257, "update": 256.898, "loss": "0.825", "ntokens": "264073", "nsentences": "1752.6", "wps": "207267", "ups": "0.78", "wpb": "264073", "bsz": "1752.6", "num_updates": "123000", "lr": "0.000376359", "gnorm": "0.254", "loss_scale": "1", "train_wall": "249", "gb_free": "39.3", "wall": "230597"}
[2024-10-07 10:14:49,774][fairseq_cli.train][INFO] - end of epoch 257 (average epoch stats below)
[2024-10-07 10:14:49,781][train][INFO] - {"epoch": 257, "train_loss": "0.824", "train_ntokens": "263615", "train_nsentences": "1753.71", "train_wps": "134743", "train_ups": "0.51", "train_wpb": "263615", "train_bsz": "1753.7", "train_num_updates": "123049", "train_lr": "0.000376292", "train_gnorm": "0.26", "train_loss_scale": "1", "train_train_wall": "608", "train_gb_free": "39.6", "train_wall": "230682"}
[2024-10-07 10:14:49,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 10:14:49,924][fairseq.trainer][INFO] - begin training epoch 258
[2024-10-07 10:14:49,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 10:23:13,464][train_inner][INFO] - {"epoch": 258, "update": 257.315, "loss": "0.824", "ntokens": "262729", "nsentences": "1782.06", "wps": "89264.3", "ups": "0.34", "wpb": "262729", "bsz": "1782.1", "num_updates": "123200", "lr": "0.000376087", "gnorm": "0.282", "loss_scale": "1", "train_wall": "270", "gb_free": "40.6", "wall": "231186"}
[2024-10-07 10:27:29,259][train_inner][INFO] - {"epoch": 258, "update": 257.733, "loss": "0.824", "ntokens": "263981", "nsentences": "1764.61", "wps": "206411", "ups": "0.78", "wpb": "263981", "bsz": "1764.6", "num_updates": "123400", "lr": "0.000375815", "gnorm": "0.255", "loss_scale": "1", "train_wall": "250", "gb_free": "39.7", "wall": "231441"}
[2024-10-07 10:30:09,532][fairseq_cli.train][INFO] - end of epoch 258 (average epoch stats below)
[2024-10-07 10:30:09,536][train][INFO] - {"epoch": 258, "train_loss": "0.824", "train_ntokens": "263597", "train_nsentences": "1753.71", "train_wps": "137280", "train_ups": "0.52", "train_wpb": "263597", "train_bsz": "1753.7", "train_num_updates": "123528", "train_lr": "0.000375641", "train_gnorm": "0.273", "train_loss_scale": "1", "train_train_wall": "592", "train_gb_free": "39.7", "train_wall": "231602"}
[2024-10-07 10:30:09,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 10:30:09,633][fairseq.trainer][INFO] - begin training epoch 259
[2024-10-07 10:30:09,634][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 10:37:04,974][train_inner][INFO] - {"epoch": 259, "update": 258.15, "loss": "0.823", "ntokens": "263307", "nsentences": "1699.59", "wps": "91472.9", "ups": "0.35", "wpb": "263307", "bsz": "1699.6", "num_updates": "123600", "lr": "0.000375543", "gnorm": "0.29", "loss_scale": "1", "train_wall": "239", "gb_free": "39.3", "wall": "232017"}
[2024-10-07 10:41:08,738][train_inner][INFO] - {"epoch": 259, "update": 258.568, "loss": "0.823", "ntokens": "263893", "nsentences": "1790.64", "wps": "216532", "ups": "0.82", "wpb": "263893", "bsz": "1790.6", "num_updates": "123800", "lr": "0.000375272", "gnorm": "0.253", "loss_scale": "1", "train_wall": "235", "gb_free": "40", "wall": "232261"}
[2024-10-07 10:45:30,182][train_inner][INFO] - {"epoch": 259, "update": 258.985, "loss": "0.824", "ntokens": "263932", "nsentences": "1746.87", "wps": "201914", "ups": "0.77", "wpb": "263932", "bsz": "1746.9", "num_updates": "124000", "lr": "0.000375", "gnorm": "0.254", "loss_scale": "1", "train_wall": "255", "gb_free": "39.7", "wall": "232522"}
[2024-10-07 10:45:50,539][fairseq_cli.train][INFO] - end of epoch 259 (average epoch stats below)
[2024-10-07 10:45:50,542][train][INFO] - {"epoch": 259, "train_loss": "0.823", "train_ntokens": "263500", "train_nsentences": "1753.71", "train_wps": "134130", "train_ups": "0.51", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "124007", "train_lr": "0.00037499", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "592", "train_gb_free": "39.7", "train_wall": "232543"}
[2024-10-07 10:45:50,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 10:45:50,637][fairseq.trainer][INFO] - begin training epoch 260
[2024-10-07 10:45:50,638][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 10:55:16,804][train_inner][INFO] - {"epoch": 260, "update": 259.403, "loss": "0.821", "ntokens": "262568", "nsentences": "1782.22", "wps": "89524", "ups": "0.34", "wpb": "262568", "bsz": "1782.2", "num_updates": "124200", "lr": "0.000374728", "gnorm": "0.273", "loss_scale": "1", "train_wall": "247", "gb_free": "39.7", "wall": "233109"}
[2024-10-07 10:58:56,621][train_inner][INFO] - {"epoch": 260, "update": 259.82, "loss": "0.821", "ntokens": "264031", "nsentences": "1743.72", "wps": "240264", "ups": "0.91", "wpb": "264031", "bsz": "1743.7", "num_updates": "124400", "lr": "0.000374457", "gnorm": "0.261", "loss_scale": "1", "train_wall": "214", "gb_free": "39.6", "wall": "233329"}
[2024-10-07 11:00:37,183][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 260 @ 124486 updates
[2024-10-07 11:00:37,185][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 11:00:43,148][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 11:00:43,318][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 260 @ 124486 updates, score None) (writing took 6.13515002746135 seconds)
[2024-10-07 11:00:43,319][fairseq_cli.train][INFO] - end of epoch 260 (average epoch stats below)
[2024-10-07 11:00:43,322][train][INFO] - {"epoch": 260, "train_loss": "0.822", "train_ntokens": "263558", "train_nsentences": "1753.71", "train_wps": "141406", "train_ups": "0.54", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "124486", "train_lr": "0.00037434", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "540", "train_gb_free": "40.3", "train_wall": "233435"}
[2024-10-07 11:00:43,400][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 11:00:43,420][fairseq.trainer][INFO] - begin training epoch 261
[2024-10-07 11:00:43,420][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 11:08:20,516][train_inner][INFO] - {"epoch": 261, "update": 260.238, "loss": "0.822", "ntokens": "263187", "nsentences": "1722.93", "wps": "93348.5", "ups": "0.35", "wpb": "263187", "bsz": "1722.9", "num_updates": "124600", "lr": "0.000374185", "gnorm": "0.281", "loss_scale": "2", "train_wall": "224", "gb_free": "39.3", "wall": "233893"}
[2024-10-07 11:11:49,518][train_inner][INFO] - {"epoch": 261, "update": 260.656, "loss": "0.823", "ntokens": "263893", "nsentences": "1782.22", "wps": "252538", "ups": "0.96", "wpb": "263893", "bsz": "1782.2", "num_updates": "124800", "lr": "0.000373913", "gnorm": "0.257", "loss_scale": "2", "train_wall": "203", "gb_free": "40", "wall": "234102"}
[2024-10-07 11:15:22,155][fairseq_cli.train][INFO] - end of epoch 261 (average epoch stats below)
[2024-10-07 11:15:22,185][train][INFO] - {"epoch": 261, "train_loss": "0.822", "train_ntokens": "263492", "train_nsentences": "1753.71", "train_wps": "143610", "train_ups": "0.55", "train_wpb": "263492", "train_bsz": "1753.7", "train_num_updates": "124965", "train_lr": "0.000373689", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "39.6", "train_wall": "234314"}
[2024-10-07 11:15:22,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 11:15:22,340][fairseq.trainer][INFO] - begin training epoch 262
[2024-10-07 11:15:22,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 11:21:43,898][train_inner][INFO] - {"epoch": 262, "update": 261.073, "loss": "0.823", "ntokens": "262606", "nsentences": "1757.46", "wps": "88364.4", "ups": "0.34", "wpb": "262606", "bsz": "1757.5", "num_updates": "125000", "lr": "0.000373641", "gnorm": "0.261", "loss_scale": "2", "train_wall": "240", "gb_free": "40.2", "wall": "234696"}
[2024-10-07 11:24:56,590][train_inner][INFO] - {"epoch": 262, "update": 261.491, "loss": "0.818", "ntokens": "264366", "nsentences": "1711.08", "wps": "274449", "ups": "1.04", "wpb": "264366", "bsz": "1711.1", "num_updates": "125200", "lr": "0.00037337", "gnorm": "0.274", "loss_scale": "2", "train_wall": "159", "gb_free": "39.6", "wall": "234889"}
[2024-10-07 11:28:40,995][train_inner][INFO] - {"epoch": 262, "update": 261.908, "loss": "0.825", "ntokens": "263531", "nsentences": "1789.15", "wps": "234898", "ups": "0.89", "wpb": "263531", "bsz": "1789.2", "num_updates": "125400", "lr": "0.000373098", "gnorm": "0.282", "loss_scale": "2", "train_wall": "216", "gb_free": "39.6", "wall": "235113"}
[2024-10-07 11:29:58,863][fairseq_cli.train][INFO] - end of epoch 262 (average epoch stats below)
[2024-10-07 11:29:58,867][train][INFO] - {"epoch": 262, "train_loss": "0.822", "train_ntokens": "263408", "train_nsentences": "1753.71", "train_wps": "143921", "train_ups": "0.55", "train_wpb": "263408", "train_bsz": "1753.7", "train_num_updates": "125444", "train_lr": "0.000373038", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "487", "train_gb_free": "39.7", "train_wall": "235191"}
[2024-10-07 11:29:58,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 11:29:58,931][fairseq.trainer][INFO] - begin training epoch 263
[2024-10-07 11:29:58,932][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 11:38:31,938][train_inner][INFO] - {"epoch": 263, "update": 262.326, "loss": "0.821", "ntokens": "263228", "nsentences": "1726.77", "wps": "89090.2", "ups": "0.34", "wpb": "263228", "bsz": "1726.8", "num_updates": "125600", "lr": "0.000372826", "gnorm": "0.251", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "235704"}
[2024-10-07 11:41:11,398][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-07 11:42:24,345][train_inner][INFO] - {"epoch": 263, "update": 262.745, "loss": "0.823", "ntokens": "263701", "nsentences": "1776.33", "wps": "226942", "ups": "0.86", "wpb": "263701", "bsz": "1776.3", "num_updates": "125800", "lr": "0.000372554", "gnorm": "0.263", "loss_scale": "1", "train_wall": "164", "gb_free": "40", "wall": "235937"}
[2024-10-07 11:44:58,101][fairseq_cli.train][INFO] - end of epoch 263 (average epoch stats below)
[2024-10-07 11:44:58,170][train][INFO] - {"epoch": 263, "train_loss": "0.822", "train_ntokens": "263596", "train_nsentences": "1754.58", "train_wps": "140110", "train_ups": "0.53", "train_wpb": "263596", "train_bsz": "1754.6", "train_num_updates": "125922", "train_lr": "0.000372389", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "420", "train_gb_free": "39.7", "train_wall": "236090"}
[2024-10-07 11:44:58,808][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 11:44:58,872][fairseq.trainer][INFO] - begin training epoch 264
[2024-10-07 11:44:58,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 11:52:01,349][train_inner][INFO] - {"epoch": 264, "update": 263.163, "loss": "0.821", "ntokens": "263166", "nsentences": "1744.64", "wps": "91222.5", "ups": "0.35", "wpb": "263166", "bsz": "1744.6", "num_updates": "126000", "lr": "0.000372283", "gnorm": "0.265", "loss_scale": "1", "train_wall": "188", "gb_free": "39.8", "wall": "236514"}
[2024-10-07 11:55:40,068][train_inner][INFO] - {"epoch": 264, "update": 263.58, "loss": "0.821", "ntokens": "263823", "nsentences": "1769.33", "wps": "241267", "ups": "0.91", "wpb": "263823", "bsz": "1769.3", "num_updates": "126200", "lr": "0.000372011", "gnorm": "0.271", "loss_scale": "1", "train_wall": "192", "gb_free": "40", "wall": "236732"}
[2024-10-07 11:59:55,455][train_inner][INFO] - {"epoch": 264, "update": 263.998, "loss": "0.823", "ntokens": "264207", "nsentences": "1744.71", "wps": "206935", "ups": "0.78", "wpb": "264207", "bsz": "1744.7", "num_updates": "126400", "lr": "0.000371739", "gnorm": "0.269", "loss_scale": "1", "train_wall": "208", "gb_free": "39.2", "wall": "236988"}
[2024-10-07 11:59:56,003][fairseq_cli.train][INFO] - end of epoch 264 (average epoch stats below)
[2024-10-07 11:59:56,024][train][INFO] - {"epoch": 264, "train_loss": "0.822", "train_ntokens": "263593", "train_nsentences": "1753.71", "train_wps": "140629", "train_ups": "0.53", "train_wpb": "263593", "train_bsz": "1753.7", "train_num_updates": "126401", "train_lr": "0.000371738", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "476", "train_gb_free": "39.2", "train_wall": "236988"}
[2024-10-07 11:59:56,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 11:59:56,178][fairseq.trainer][INFO] - begin training epoch 265
[2024-10-07 11:59:56,178][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 12:09:35,524][train_inner][INFO] - {"epoch": 265, "update": 264.415, "loss": "0.82", "ntokens": "262932", "nsentences": "1739.36", "wps": "90662", "ups": "0.34", "wpb": "262932", "bsz": "1739.4", "num_updates": "126600", "lr": "0.000371467", "gnorm": "0.272", "loss_scale": "1", "train_wall": "173", "gb_free": "40.2", "wall": "237568"}
[2024-10-07 12:14:02,157][train_inner][INFO] - {"epoch": 265, "update": 264.833, "loss": "0.823", "ntokens": "263691", "nsentences": "1768.3", "wps": "197801", "ups": "0.75", "wpb": "263691", "bsz": "1768.3", "num_updates": "126800", "lr": "0.000371196", "gnorm": "0.268", "loss_scale": "1", "train_wall": "134", "gb_free": "39.6", "wall": "237834"}
[2024-10-07 12:15:46,303][fairseq_cli.train][INFO] - end of epoch 265 (average epoch stats below)
[2024-10-07 12:15:46,418][train][INFO] - {"epoch": 265, "train_loss": "0.822", "train_ntokens": "263472", "train_nsentences": "1753.71", "train_wps": "132792", "train_ups": "0.5", "train_wpb": "263472", "train_bsz": "1753.7", "train_num_updates": "126880", "train_lr": "0.000371087", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "388", "train_gb_free": "39.1", "train_wall": "237939"}
[2024-10-07 12:15:48,516][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 12:15:48,603][fairseq.trainer][INFO] - begin training epoch 266
[2024-10-07 12:15:48,604][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 12:23:25,360][train_inner][INFO] - {"epoch": 266, "update": 265.251, "loss": "0.818", "ntokens": "263553", "nsentences": "1676.53", "wps": "93593.8", "ups": "0.36", "wpb": "263553", "bsz": "1676.5", "num_updates": "127000", "lr": "0.000370924", "gnorm": "0.261", "loss_scale": "1", "train_wall": "203", "gb_free": "39.6", "wall": "238398"}
[2024-10-07 12:27:03,132][train_inner][INFO] - {"epoch": 266, "update": 265.668, "loss": "0.825", "ntokens": "263485", "nsentences": "1828.27", "wps": "241998", "ups": "0.92", "wpb": "263485", "bsz": "1828.3", "num_updates": "127200", "lr": "0.000370652", "gnorm": "0.284", "loss_scale": "1", "train_wall": "198", "gb_free": "39.3", "wall": "238615"}
[2024-10-07 12:30:30,962][fairseq_cli.train][INFO] - end of epoch 266 (average epoch stats below)
[2024-10-07 12:30:30,978][train][INFO] - {"epoch": 266, "train_loss": "0.822", "train_ntokens": "263600", "train_nsentences": "1753.71", "train_wps": "142744", "train_ups": "0.54", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "127359", "train_lr": "0.000370436", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "430", "train_gb_free": "39.6", "train_wall": "238823"}
[2024-10-07 12:30:31,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 12:30:31,063][fairseq.trainer][INFO] - begin training epoch 267
[2024-10-07 12:30:31,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 12:36:58,493][train_inner][INFO] - {"epoch": 267, "update": 266.086, "loss": "0.824", "ntokens": "263037", "nsentences": "1748.54", "wps": "88366.6", "ups": "0.34", "wpb": "263037", "bsz": "1748.5", "num_updates": "127400", "lr": "0.00037038", "gnorm": "0.263", "loss_scale": "1", "train_wall": "153", "gb_free": "39.6", "wall": "239211"}
[2024-10-07 12:40:47,082][train_inner][INFO] - {"epoch": 267, "update": 266.503, "loss": "0.821", "ntokens": "263635", "nsentences": "1788.15", "wps": "230688", "ups": "0.88", "wpb": "263635", "bsz": "1788.2", "num_updates": "127600", "lr": "0.000370109", "gnorm": "0.249", "loss_scale": "1", "train_wall": "169", "gb_free": "39.3", "wall": "239439"}
[2024-10-07 12:44:34,835][train_inner][INFO] - {"epoch": 267, "update": 266.921, "loss": "0.822", "ntokens": "264388", "nsentences": "1724.4", "wps": "232182", "ups": "0.88", "wpb": "264388", "bsz": "1724.4", "num_updates": "127800", "lr": "0.000369837", "gnorm": "0.261", "loss_scale": "2", "train_wall": "129", "gb_free": "39.6", "wall": "239667"}
[2024-10-07 12:45:33,795][fairseq_cli.train][INFO] - end of epoch 267 (average epoch stats below)
[2024-10-07 12:45:33,822][train][INFO] - {"epoch": 267, "train_loss": "0.821", "train_ntokens": "263576", "train_nsentences": "1753.71", "train_wps": "139844", "train_ups": "0.53", "train_wpb": "263576", "train_bsz": "1753.7", "train_num_updates": "127838", "train_lr": "0.000369785", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "383", "train_gb_free": "39.6", "train_wall": "239726"}
[2024-10-07 12:45:34,026][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 12:45:34,043][fairseq.trainer][INFO] - begin training epoch 268
[2024-10-07 12:45:34,044][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 12:54:27,812][train_inner][INFO] - {"epoch": 268, "update": 267.338, "loss": "0.818", "ntokens": "262942", "nsentences": "1735.94", "wps": "88686.8", "ups": "0.34", "wpb": "262942", "bsz": "1735.9", "num_updates": "128000", "lr": "0.000369565", "gnorm": "0.26", "loss_scale": "2", "train_wall": "182", "gb_free": "39.6", "wall": "240260"}
[2024-10-07 12:58:36,191][train_inner][INFO] - {"epoch": 268, "update": 267.756, "loss": "0.821", "ntokens": "264142", "nsentences": "1749.68", "wps": "212710", "ups": "0.81", "wpb": "264142", "bsz": "1749.7", "num_updates": "128200", "lr": "0.000369293", "gnorm": "0.273", "loss_scale": "2", "train_wall": "148", "gb_free": "40.1", "wall": "240508"}
[2024-10-07 13:01:08,305][fairseq_cli.train][INFO] - end of epoch 268 (average epoch stats below)
[2024-10-07 13:01:08,348][train][INFO] - {"epoch": 268, "train_loss": "0.821", "train_ntokens": "263501", "train_nsentences": "1753.71", "train_wps": "135061", "train_ups": "0.51", "train_wpb": "263501", "train_bsz": "1753.7", "train_num_updates": "128317", "train_lr": "0.000369135", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "393", "train_gb_free": "39.3", "train_wall": "240661"}
[2024-10-07 13:01:08,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 13:01:08,569][fairseq.trainer][INFO] - begin training epoch 269
[2024-10-07 13:01:08,570][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 13:08:24,519][train_inner][INFO] - {"epoch": 269, "update": 268.173, "loss": "0.824", "ntokens": "262612", "nsentences": "1778.58", "wps": "89275.8", "ups": "0.34", "wpb": "262612", "bsz": "1778.6", "num_updates": "128400", "lr": "0.000369022", "gnorm": "0.251", "loss_scale": "2", "train_wall": "192", "gb_free": "39.7", "wall": "241097"}
[2024-10-07 13:12:04,942][train_inner][INFO] - {"epoch": 269, "update": 268.591, "loss": "0.82", "ntokens": "264008", "nsentences": "1746.58", "wps": "239565", "ups": "0.91", "wpb": "264008", "bsz": "1746.6", "num_updates": "128600", "lr": "0.00036875", "gnorm": "0.264", "loss_scale": "2", "train_wall": "140", "gb_free": "40.2", "wall": "241317"}
[2024-10-07 13:16:27,822][fairseq_cli.train][INFO] - end of epoch 269 (average epoch stats below)
[2024-10-07 13:16:27,843][train][INFO] - {"epoch": 269, "train_loss": "0.821", "train_ntokens": "263593", "train_nsentences": "1753.71", "train_wps": "137317", "train_ups": "0.52", "train_wpb": "263593", "train_bsz": "1753.7", "train_num_updates": "128796", "train_lr": "0.000368484", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "357", "train_gb_free": "39.6", "train_wall": "241580"}
[2024-10-07 13:16:27,950][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 13:16:27,979][fairseq.trainer][INFO] - begin training epoch 270
[2024-10-07 13:16:27,980][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 13:21:58,450][train_inner][INFO] - {"epoch": 270, "update": 269.008, "loss": "0.821", "ntokens": "263026", "nsentences": "1750.04", "wps": "88637.1", "ups": "0.34", "wpb": "263026", "bsz": "1750", "num_updates": "128800", "lr": "0.000368478", "gnorm": "0.252", "loss_scale": "2", "train_wall": "137", "gb_free": "39.6", "wall": "241911"}
[2024-10-07 13:25:39,502][train_inner][INFO] - {"epoch": 270, "update": 269.426, "loss": "0.818", "ntokens": "263601", "nsentences": "1782.08", "wps": "238523", "ups": "0.9", "wpb": "263601", "bsz": "1782.1", "num_updates": "129000", "lr": "0.000368207", "gnorm": "0.259", "loss_scale": "2", "train_wall": "166", "gb_free": "39.3", "wall": "242132"}
[2024-10-07 13:29:41,615][train_inner][INFO] - {"epoch": 270, "update": 269.843, "loss": "0.822", "ntokens": "264256", "nsentences": "1746.55", "wps": "218305", "ups": "0.83", "wpb": "264256", "bsz": "1746.5", "num_updates": "129200", "lr": "0.000367935", "gnorm": "0.26", "loss_scale": "2", "train_wall": "169", "gb_free": "39.6", "wall": "242374"}
[2024-10-07 13:31:11,760][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 270 @ 129275 updates
[2024-10-07 13:31:11,842][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 13:31:31,708][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 13:31:31,773][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 270 @ 129275 updates, score None) (writing took 20.01313391327858 seconds)
[2024-10-07 13:31:31,774][fairseq_cli.train][INFO] - end of epoch 270 (average epoch stats below)
[2024-10-07 13:31:31,778][train][INFO] - {"epoch": 270, "train_loss": "0.82", "train_ntokens": "263519", "train_nsentences": "1753.71", "train_wps": "139642", "train_ups": "0.53", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "129275", "train_lr": "0.000367833", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "405", "train_gb_free": "39.6", "train_wall": "242484"}
[2024-10-07 13:31:31,829][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 13:31:31,852][fairseq.trainer][INFO] - begin training epoch 271
[2024-10-07 13:31:31,853][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 13:39:09,504][train_inner][INFO] - {"epoch": 271, "update": 270.261, "loss": "0.818", "ntokens": "263470", "nsentences": "1689.92", "wps": "92793.7", "ups": "0.35", "wpb": "263470", "bsz": "1689.9", "num_updates": "129400", "lr": "0.000367663", "gnorm": "0.267", "loss_scale": "2", "train_wall": "162", "gb_free": "39.3", "wall": "242942"}
[2024-10-07 13:43:02,549][train_inner][INFO] - {"epoch": 271, "update": 270.678, "loss": "0.824", "ntokens": "263717", "nsentences": "1797.46", "wps": "226351", "ups": "0.86", "wpb": "263717", "bsz": "1797.5", "num_updates": "129600", "lr": "0.000367391", "gnorm": "0.276", "loss_scale": "2", "train_wall": "155", "gb_free": "39.1", "wall": "243175"}
[2024-10-07 13:46:09,382][fairseq_cli.train][INFO] - end of epoch 271 (average epoch stats below)
[2024-10-07 13:46:09,410][train][INFO] - {"epoch": 271, "train_loss": "0.821", "train_ntokens": "263618", "train_nsentences": "1753.71", "train_wps": "143882", "train_ups": "0.55", "train_wpb": "263618", "train_bsz": "1753.7", "train_num_updates": "129754", "train_lr": "0.000367182", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "382", "train_gb_free": "39.2", "train_wall": "243362"}
[2024-10-07 13:46:09,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 13:46:09,805][fairseq.trainer][INFO] - begin training epoch 272
[2024-10-07 13:46:09,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 13:52:29,979][train_inner][INFO] - {"epoch": 272, "update": 271.096, "loss": "0.819", "ntokens": "262908", "nsentences": "1737.5", "wps": "92669.1", "ups": "0.35", "wpb": "262908", "bsz": "1737.5", "num_updates": "129800", "lr": "0.00036712", "gnorm": "0.28", "loss_scale": "2", "train_wall": "183", "gb_free": "39.3", "wall": "243742"}
[2024-10-07 13:56:11,210][train_inner][INFO] - {"epoch": 272, "update": 271.514, "loss": "0.819", "ntokens": "264093", "nsentences": "1758.3", "wps": "238792", "ups": "0.9", "wpb": "264093", "bsz": "1758.3", "num_updates": "130000", "lr": "0.000366848", "gnorm": "0.253", "loss_scale": "4", "train_wall": "216", "gb_free": "39.8", "wall": "243963"}
[2024-10-07 14:00:33,963][train_inner][INFO] - {"epoch": 272, "update": 271.931, "loss": "0.822", "ntokens": "263647", "nsentences": "1788.87", "wps": "200691", "ups": "0.76", "wpb": "263647", "bsz": "1788.9", "num_updates": "130200", "lr": "0.000366576", "gnorm": "0.265", "loss_scale": "4", "train_wall": "257", "gb_free": "40", "wall": "244226"}
[2024-10-07 14:01:09,086][fairseq_cli.train][INFO] - end of epoch 272 (average epoch stats below)
[2024-10-07 14:01:09,110][train][INFO] - {"epoch": 272, "train_loss": "0.82", "train_ntokens": "263456", "train_nsentences": "1753.71", "train_wps": "140269", "train_ups": "0.53", "train_wpb": "263456", "train_bsz": "1753.7", "train_num_updates": "130233", "train_lr": "0.000366531", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "561", "train_gb_free": "39.6", "train_wall": "244261"}
[2024-10-07 14:01:09,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 14:01:09,715][fairseq.trainer][INFO] - begin training epoch 273
[2024-10-07 14:01:09,715][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 14:10:09,943][train_inner][INFO] - {"epoch": 273, "update": 272.349, "loss": "0.818", "ntokens": "263018", "nsentences": "1735.34", "wps": "91331.3", "ups": "0.35", "wpb": "263018", "bsz": "1735.3", "num_updates": "130400", "lr": "0.000366304", "gnorm": "0.274", "loss_scale": "4", "train_wall": "233", "gb_free": "40", "wall": "244802"}
[2024-10-07 14:13:49,577][train_inner][INFO] - {"epoch": 273, "update": 272.766, "loss": "0.82", "ntokens": "263996", "nsentences": "1765.48", "wps": "240420", "ups": "0.91", "wpb": "263996", "bsz": "1765.5", "num_updates": "130600", "lr": "0.000366033", "gnorm": "0.269", "loss_scale": "4", "train_wall": "214", "gb_free": "40", "wall": "245022"}
[2024-10-07 14:16:01,075][fairseq_cli.train][INFO] - end of epoch 273 (average epoch stats below)
[2024-10-07 14:16:01,092][train][INFO] - {"epoch": 273, "train_loss": "0.82", "train_ntokens": "263579", "train_nsentences": "1753.71", "train_wps": "141546", "train_ups": "0.54", "train_wpb": "263579", "train_bsz": "1753.7", "train_num_updates": "130712", "train_lr": "0.00036588", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "541", "train_gb_free": "40", "train_wall": "245153"}
[2024-10-07 14:16:01,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 14:16:01,215][fairseq.trainer][INFO] - begin training epoch 274
[2024-10-07 14:16:01,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 14:23:07,526][train_inner][INFO] - {"epoch": 274, "update": 273.184, "loss": "0.821", "ntokens": "262884", "nsentences": "1734.41", "wps": "94234.6", "ups": "0.36", "wpb": "262884", "bsz": "1734.4", "num_updates": "130800", "lr": "0.000365761", "gnorm": "0.266", "loss_scale": "4", "train_wall": "234", "gb_free": "40.5", "wall": "245580"}
[2024-10-07 14:26:47,720][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 14:27:02,936][train_inner][INFO] - {"epoch": 274, "update": 273.603, "loss": "0.818", "ntokens": "263843", "nsentences": "1765.1", "wps": "224179", "ups": "0.85", "wpb": "263843", "bsz": "1765.1", "num_updates": "131000", "lr": "0.000365489", "gnorm": "0.256", "loss_scale": "2", "train_wall": "230", "gb_free": "40.1", "wall": "245815"}
[2024-10-07 14:30:48,462][fairseq_cli.train][INFO] - end of epoch 274 (average epoch stats below)
[2024-10-07 14:30:48,510][train][INFO] - {"epoch": 274, "train_loss": "0.819", "train_ntokens": "263360", "train_nsentences": "1754.57", "train_wps": "141859", "train_ups": "0.54", "train_wpb": "263360", "train_bsz": "1754.6", "train_num_updates": "131190", "train_lr": "0.000365231", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "40.5", "train_wall": "246041"}
[2024-10-07 14:30:48,705][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 14:30:48,755][fairseq.trainer][INFO] - begin training epoch 275
[2024-10-07 14:30:48,755][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 14:36:54,527][train_inner][INFO] - {"epoch": 275, "update": 274.021, "loss": "0.821", "ntokens": "262570", "nsentences": "1748.86", "wps": "88769.6", "ups": "0.34", "wpb": "262570", "bsz": "1748.9", "num_updates": "131200", "lr": "0.000365217", "gnorm": "0.247", "loss_scale": "2", "train_wall": "237", "gb_free": "39.3", "wall": "246407"}
[2024-10-07 14:40:07,217][train_inner][INFO] - {"epoch": 275, "update": 274.438, "loss": "0.817", "ntokens": "264021", "nsentences": "1752.18", "wps": "274082", "ups": "1.04", "wpb": "264021", "bsz": "1752.2", "num_updates": "131400", "lr": "0.000364946", "gnorm": "0.258", "loss_scale": "2", "train_wall": "137", "gb_free": "39.8", "wall": "246599"}
[2024-10-07 14:44:06,274][train_inner][INFO] - {"epoch": 275, "update": 274.856, "loss": "0.82", "ntokens": "263929", "nsentences": "1777.21", "wps": "220816", "ups": "0.84", "wpb": "263929", "bsz": "1777.2", "num_updates": "131600", "lr": "0.000364674", "gnorm": "0.25", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "246838"}
[2024-10-07 14:45:32,001][fairseq_cli.train][INFO] - end of epoch 275 (average epoch stats below)
[2024-10-07 14:45:32,062][train][INFO] - {"epoch": 275, "train_loss": "0.819", "train_ntokens": "263502", "train_nsentences": "1753.71", "train_wps": "142856", "train_ups": "0.54", "train_wpb": "263502", "train_bsz": "1753.7", "train_num_updates": "131669", "train_lr": "0.00036458", "train_gnorm": "0.256", "train_loss_scale": "2", "train_train_wall": "463", "train_gb_free": "39.3", "train_wall": "246924"}
[2024-10-07 14:45:32,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 14:45:32,216][fairseq.trainer][INFO] - begin training epoch 276
[2024-10-07 14:45:32,217][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 14:53:41,568][train_inner][INFO] - {"epoch": 276, "update": 275.273, "loss": "0.819", "ntokens": "262923", "nsentences": "1735.95", "wps": "91406.5", "ups": "0.35", "wpb": "262923", "bsz": "1736", "num_updates": "131800", "lr": "0.000364402", "gnorm": "0.25", "loss_scale": "2", "train_wall": "242", "gb_free": "40", "wall": "247414"}
[2024-10-07 14:57:35,654][train_inner][INFO] - {"epoch": 276, "update": 275.691, "loss": "0.818", "ntokens": "263915", "nsentences": "1755.59", "wps": "225506", "ups": "0.85", "wpb": "263915", "bsz": "1755.6", "num_updates": "132000", "lr": "0.00036413", "gnorm": "0.265", "loss_scale": "2", "train_wall": "229", "gb_free": "39.6", "wall": "247648"}
[2024-10-07 15:00:47,636][fairseq_cli.train][INFO] - end of epoch 276 (average epoch stats below)
[2024-10-07 15:00:47,656][train][INFO] - {"epoch": 276, "train_loss": "0.819", "train_ntokens": "263471", "train_nsentences": "1753.71", "train_wps": "137839", "train_ups": "0.52", "train_wpb": "263470", "train_bsz": "1753.7", "train_num_updates": "132148", "train_lr": "0.000363929", "train_gnorm": "0.253", "train_loss_scale": "2", "train_train_wall": "575", "train_gb_free": "39.1", "train_wall": "247840"}
[2024-10-07 15:00:47,731][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 15:00:47,750][fairseq.trainer][INFO] - begin training epoch 277
[2024-10-07 15:00:47,751][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 15:07:25,304][train_inner][INFO] - {"epoch": 277, "update": 276.109, "loss": "0.819", "ntokens": "262872", "nsentences": "1752.47", "wps": "89164.2", "ups": "0.34", "wpb": "262872", "bsz": "1752.5", "num_updates": "132200", "lr": "0.000363859", "gnorm": "0.253", "loss_scale": "2", "train_wall": "266", "gb_free": "39.3", "wall": "248237"}
[2024-10-07 15:11:06,119][train_inner][INFO] - {"epoch": 277, "update": 276.526, "loss": "0.815", "ntokens": "264253", "nsentences": "1736.42", "wps": "239371", "ups": "0.91", "wpb": "264253", "bsz": "1736.4", "num_updates": "132400", "lr": "0.000363587", "gnorm": "0.264", "loss_scale": "2", "train_wall": "216", "gb_free": "39.6", "wall": "248458"}
[2024-10-07 15:15:08,008][train_inner][INFO] - {"epoch": 277, "update": 276.944, "loss": "0.823", "ntokens": "263651", "nsentences": "1780.96", "wps": "218008", "ups": "0.83", "wpb": "263651", "bsz": "1781", "num_updates": "132600", "lr": "0.000363315", "gnorm": "0.259", "loss_scale": "2", "train_wall": "236", "gb_free": "40", "wall": "248700"}
[2024-10-07 15:15:45,083][fairseq_cli.train][INFO] - end of epoch 277 (average epoch stats below)
[2024-10-07 15:15:45,085][train][INFO] - {"epoch": 277, "train_loss": "0.818", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "140652", "train_ups": "0.53", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "132627", "train_lr": "0.000363279", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "40.3", "train_wall": "248737"}
[2024-10-07 15:15:45,159][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 15:15:45,179][fairseq.trainer][INFO] - begin training epoch 278
[2024-10-07 15:15:45,179][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 15:24:33,354][train_inner][INFO] - {"epoch": 278, "update": 277.361, "loss": "0.819", "ntokens": "262932", "nsentences": "1756.01", "wps": "93020.4", "ups": "0.35", "wpb": "262932", "bsz": "1756", "num_updates": "132800", "lr": "0.000363043", "gnorm": "0.27", "loss_scale": "2", "train_wall": "241", "gb_free": "39.8", "wall": "249266"}
[2024-10-07 15:28:19,062][train_inner][INFO] - {"epoch": 278, "update": 277.779, "loss": "0.816", "ntokens": "264384", "nsentences": "1698.82", "wps": "234286", "ups": "0.89", "wpb": "264384", "bsz": "1698.8", "num_updates": "133000", "lr": "0.000362772", "gnorm": "0.257", "loss_scale": "2", "train_wall": "220", "gb_free": "39.8", "wall": "249491"}
[2024-10-07 15:30:51,017][fairseq_cli.train][INFO] - end of epoch 278 (average epoch stats below)
[2024-10-07 15:30:51,036][train][INFO] - {"epoch": 278, "train_loss": "0.819", "train_ntokens": "263525", "train_nsentences": "1753.71", "train_wps": "139333", "train_ups": "0.53", "train_wpb": "263525", "train_bsz": "1753.7", "train_num_updates": "133106", "train_lr": "0.000362628", "train_gnorm": "0.262", "train_loss_scale": "4", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "249643"}
[2024-10-07 15:30:51,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 15:30:51,149][fairseq.trainer][INFO] - begin training epoch 279
[2024-10-07 15:30:51,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 15:38:40,724][train_inner][INFO] - {"epoch": 279, "update": 278.196, "loss": "0.823", "ntokens": "262162", "nsentences": "1823.32", "wps": "84343.3", "ups": "0.32", "wpb": "262162", "bsz": "1823.3", "num_updates": "133200", "lr": "0.0003625", "gnorm": "0.26", "loss_scale": "4", "train_wall": "275", "gb_free": "39.4", "wall": "250113"}
[2024-10-07 15:42:37,267][train_inner][INFO] - {"epoch": 279, "update": 278.614, "loss": "0.816", "ntokens": "264123", "nsentences": "1742.29", "wps": "223342", "ups": "0.85", "wpb": "264123", "bsz": "1742.3", "num_updates": "133400", "lr": "0.000362228", "gnorm": "0.281", "loss_scale": "4", "train_wall": "231", "gb_free": "39.8", "wall": "250349"}
[2024-10-07 15:42:41,368][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 15:46:27,269][fairseq_cli.train][INFO] - end of epoch 279 (average epoch stats below)
[2024-10-07 15:46:27,292][train][INFO] - {"epoch": 279, "train_loss": "0.818", "train_ntokens": "263473", "train_nsentences": "1753.69", "train_wps": "134515", "train_ups": "0.51", "train_wpb": "263473", "train_bsz": "1753.7", "train_num_updates": "133584", "train_lr": "0.000361978", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "581", "train_gb_free": "39.8", "train_wall": "250579"}
[2024-10-07 15:46:27,382][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 15:46:27,454][fairseq.trainer][INFO] - begin training epoch 280
[2024-10-07 15:46:27,455][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 15:52:48,810][train_inner][INFO] - {"epoch": 280, "update": 279.033, "loss": "0.818", "ntokens": "262881", "nsentences": "1733.57", "wps": "85974.6", "ups": "0.33", "wpb": "262881", "bsz": "1733.6", "num_updates": "133600", "lr": "0.000361957", "gnorm": "0.265", "loss_scale": "2", "train_wall": "256", "gb_free": "39.6", "wall": "250961"}
[2024-10-07 15:56:27,862][train_inner][INFO] - {"epoch": 280, "update": 279.451, "loss": "0.816", "ntokens": "264279", "nsentences": "1736.85", "wps": "241303", "ups": "0.91", "wpb": "264279", "bsz": "1736.8", "num_updates": "133800", "lr": "0.000361685", "gnorm": "0.25", "loss_scale": "2", "train_wall": "214", "gb_free": "39.2", "wall": "251180"}
[2024-10-07 16:00:27,376][train_inner][INFO] - {"epoch": 280, "update": 279.868, "loss": "0.821", "ntokens": "263581", "nsentences": "1795.11", "wps": "220105", "ups": "0.84", "wpb": "263581", "bsz": "1795.1", "num_updates": "134000", "lr": "0.000361413", "gnorm": "0.271", "loss_scale": "2", "train_wall": "235", "gb_free": "39.2", "wall": "251420"}
[2024-10-07 16:01:49,642][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 280 @ 134063 updates
[2024-10-07 16:01:49,645][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 16:01:54,969][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 16:01:55,005][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 280 @ 134063 updates, score None) (writing took 5.362251995131373 seconds)
[2024-10-07 16:01:55,005][fairseq_cli.train][INFO] - end of epoch 280 (average epoch stats below)
[2024-10-07 16:01:55,014][train][INFO] - {"epoch": 280, "train_loss": "0.818", "train_ntokens": "263544", "train_nsentences": "1753.71", "train_wps": "136074", "train_ups": "0.52", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "134063", "train_lr": "0.000361327", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "39.6", "train_wall": "251507"}
[2024-10-07 16:01:55,084][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 16:01:55,114][fairseq.trainer][INFO] - begin training epoch 281
[2024-10-07 16:01:55,115][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 16:09:59,960][train_inner][INFO] - {"epoch": 281, "update": 280.286, "loss": "0.817", "ntokens": "263100", "nsentences": "1731.24", "wps": "91904.8", "ups": "0.35", "wpb": "263100", "bsz": "1731.2", "num_updates": "134200", "lr": "0.000361141", "gnorm": "0.251", "loss_scale": "2", "train_wall": "238", "gb_free": "39.8", "wall": "251992"}
[2024-10-07 16:13:50,062][train_inner][INFO] - {"epoch": 281, "update": 280.704, "loss": "0.817", "ntokens": "264217", "nsentences": "1724.49", "wps": "229660", "ups": "0.87", "wpb": "264217", "bsz": "1724.5", "num_updates": "134400", "lr": "0.00036087", "gnorm": "0.26", "loss_scale": "2", "train_wall": "225", "gb_free": "39.7", "wall": "252222"}
[2024-10-07 16:17:07,823][fairseq_cli.train][INFO] - end of epoch 281 (average epoch stats below)
[2024-10-07 16:17:07,848][train][INFO] - {"epoch": 281, "train_loss": "0.818", "train_ntokens": "263474", "train_nsentences": "1753.71", "train_wps": "138256", "train_ups": "0.52", "train_wpb": "263474", "train_bsz": "1753.7", "train_num_updates": "134542", "train_lr": "0.000360677", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "252420"}
[2024-10-07 16:17:07,926][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 16:17:07,945][fairseq.trainer][INFO] - begin training epoch 282
[2024-10-07 16:17:07,945][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 16:23:59,953][train_inner][INFO] - {"epoch": 282, "update": 281.121, "loss": "0.82", "ntokens": "262685", "nsentences": "1758.61", "wps": "86146.1", "ups": "0.33", "wpb": "262685", "bsz": "1758.6", "num_updates": "134600", "lr": "0.000360598", "gnorm": "0.267", "loss_scale": "2", "train_wall": "286", "gb_free": "39.7", "wall": "252832"}
[2024-10-07 16:27:49,956][train_inner][INFO] - {"epoch": 282, "update": 281.539, "loss": "0.818", "ntokens": "263932", "nsentences": "1772.97", "wps": "229529", "ups": "0.87", "wpb": "263932", "bsz": "1773", "num_updates": "134800", "lr": "0.000360326", "gnorm": "0.26", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "253062"}
[2024-10-07 16:31:59,518][train_inner][INFO] - {"epoch": 282, "update": 281.956, "loss": "0.818", "ntokens": "263872", "nsentences": "1771.38", "wps": "211475", "ups": "0.8", "wpb": "263872", "bsz": "1771.4", "num_updates": "135000", "lr": "0.000360054", "gnorm": "0.26", "loss_scale": "2", "train_wall": "245", "gb_free": "39.6", "wall": "253312"}
[2024-10-07 16:32:34,413][fairseq_cli.train][INFO] - end of epoch 282 (average epoch stats below)
[2024-10-07 16:32:34,437][train][INFO] - {"epoch": 282, "train_loss": "0.818", "train_ntokens": "263529", "train_nsentences": "1753.71", "train_wps": "136233", "train_ups": "0.52", "train_wpb": "263529", "train_bsz": "1753.7", "train_num_updates": "135021", "train_lr": "0.000360026", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "594", "train_gb_free": "39.8", "train_wall": "253347"}
[2024-10-07 16:32:34,563][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 16:32:34,599][fairseq.trainer][INFO] - begin training epoch 283
[2024-10-07 16:32:34,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 16:41:39,507][train_inner][INFO] - {"epoch": 283, "update": 282.374, "loss": "0.818", "ntokens": "262738", "nsentences": "1743.38", "wps": "90602.6", "ups": "0.34", "wpb": "262738", "bsz": "1743.4", "num_updates": "135200", "lr": "0.000359783", "gnorm": "0.268", "loss_scale": "2", "train_wall": "250", "gb_free": "39.6", "wall": "253892"}
[2024-10-07 16:45:43,611][train_inner][INFO] - {"epoch": 283, "update": 282.791, "loss": "0.818", "ntokens": "263657", "nsentences": "1797.8", "wps": "216034", "ups": "0.82", "wpb": "263657", "bsz": "1797.8", "num_updates": "135400", "lr": "0.000359511", "gnorm": "0.265", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "254136"}
[2024-10-07 16:47:22,937][fairseq_cli.train][INFO] - end of epoch 283 (average epoch stats below)
[2024-10-07 16:47:22,963][train][INFO] - {"epoch": 283, "train_loss": "0.818", "train_ntokens": "263471", "train_nsentences": "1753.71", "train_wps": "142036", "train_ups": "0.54", "train_wpb": "263471", "train_bsz": "1753.7", "train_num_updates": "135500", "train_lr": "0.000359375", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "552", "train_gb_free": "39.6", "train_wall": "254235"}
[2024-10-07 16:47:23,345][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 16:47:23,396][fairseq.trainer][INFO] - begin training epoch 284
[2024-10-07 16:47:23,402][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 16:56:23,226][train_inner][INFO] - {"epoch": 284, "update": 283.209, "loss": "0.816", "ntokens": "263264", "nsentences": "1707.82", "wps": "82320.6", "ups": "0.31", "wpb": "263264", "bsz": "1707.8", "num_updates": "135600", "lr": "0.000359239", "gnorm": "0.258", "loss_scale": "4", "train_wall": "168", "gb_free": "39.1", "wall": "254775"}
[2024-10-07 16:58:34,416][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 17:00:18,487][train_inner][INFO] - {"epoch": 284, "update": 283.628, "loss": "0.818", "ntokens": "263897", "nsentences": "1771.49", "wps": "224368", "ups": "0.85", "wpb": "263897", "bsz": "1771.5", "num_updates": "135800", "lr": "0.000358967", "gnorm": "0.257", "loss_scale": "2", "train_wall": "143", "gb_free": "39.7", "wall": "255011"}
[2024-10-07 17:03:53,631][fairseq_cli.train][INFO] - end of epoch 284 (average epoch stats below)
[2024-10-07 17:03:53,676][train][INFO] - {"epoch": 284, "train_loss": "0.817", "train_ntokens": "263592", "train_nsentences": "1753.01", "train_wps": "127182", "train_ups": "0.48", "train_wpb": "263592", "train_bsz": "1753", "train_num_updates": "135978", "train_lr": "0.000358726", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "343", "train_gb_free": "39.6", "train_wall": "255226"}
[2024-10-07 17:03:53,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 17:03:53,852][fairseq.trainer][INFO] - begin training epoch 285
[2024-10-07 17:03:53,852][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 17:12:26,574][train_inner][INFO] - {"epoch": 285, "update": 284.046, "loss": "0.818", "ntokens": "263025", "nsentences": "1731.96", "wps": "72254.8", "ups": "0.27", "wpb": "263025", "bsz": "1732", "num_updates": "136000", "lr": "0.000358696", "gnorm": "0.277", "loss_scale": "2", "train_wall": "168", "gb_free": "39.2", "wall": "255739"}
[2024-10-07 17:15:39,585][train_inner][INFO] - {"epoch": 285, "update": 284.463, "loss": "0.816", "ntokens": "263912", "nsentences": "1784.58", "wps": "273525", "ups": "1.04", "wpb": "263912", "bsz": "1784.6", "num_updates": "136200", "lr": "0.000358424", "gnorm": "0.259", "loss_scale": "2", "train_wall": "187", "gb_free": "40", "wall": "255932"}
[2024-10-07 17:19:48,084][train_inner][INFO] - {"epoch": 285, "update": 284.881, "loss": "0.818", "ntokens": "263881", "nsentences": "1748.25", "wps": "212392", "ups": "0.8", "wpb": "263881", "bsz": "1748.2", "num_updates": "136400", "lr": "0.000358152", "gnorm": "0.26", "loss_scale": "2", "train_wall": "193", "gb_free": "39.3", "wall": "256180"}
[2024-10-07 17:21:14,034][fairseq_cli.train][INFO] - end of epoch 285 (average epoch stats below)
[2024-10-07 17:21:14,087][train][INFO] - {"epoch": 285, "train_loss": "0.816", "train_ntokens": "263460", "train_nsentences": "1753.71", "train_wps": "121298", "train_ups": "0.46", "train_wpb": "263460", "train_bsz": "1753.7", "train_num_updates": "136457", "train_lr": "0.000358075", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "455", "train_gb_free": "39.2", "train_wall": "256266"}
[2024-10-07 17:21:14,594][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 17:21:14,623][fairseq.trainer][INFO] - begin training epoch 286
[2024-10-07 17:21:14,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 17:31:07,002][train_inner][INFO] - {"epoch": 286, "update": 285.299, "loss": "0.813", "ntokens": "263159", "nsentences": "1717.46", "wps": "77524.2", "ups": "0.29", "wpb": "263159", "bsz": "1717.5", "num_updates": "136600", "lr": "0.00035788", "gnorm": "0.254", "loss_scale": "2", "train_wall": "156", "gb_free": "40.8", "wall": "256859"}
[2024-10-07 17:35:03,983][train_inner][INFO] - {"epoch": 286, "update": 285.716, "loss": "0.817", "ntokens": "263905", "nsentences": "1759.99", "wps": "222732", "ups": "0.84", "wpb": "263905", "bsz": "1760", "num_updates": "136800", "lr": "0.000357609", "gnorm": "0.27", "loss_scale": "2", "train_wall": "155", "gb_free": "39.6", "wall": "257096"}
[2024-10-07 17:38:09,491][fairseq_cli.train][INFO] - end of epoch 286 (average epoch stats below)
[2024-10-07 17:38:09,710][train][INFO] - {"epoch": 286, "train_loss": "0.817", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "124293", "train_ups": "0.47", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "136936", "train_lr": "0.000357424", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "406", "train_gb_free": "39.3", "train_wall": "257282"}
[2024-10-07 17:38:11,570][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 17:38:11,715][fairseq.trainer][INFO] - begin training epoch 287
[2024-10-07 17:38:11,715][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 17:47:50,418][train_inner][INFO] - {"epoch": 287, "update": 286.134, "loss": "0.82", "ntokens": "262850", "nsentences": "1758.99", "wps": "68592", "ups": "0.26", "wpb": "262850", "bsz": "1759", "num_updates": "137000", "lr": "0.000357337", "gnorm": "0.268", "loss_scale": "2", "train_wall": "183", "gb_free": "39.1", "wall": "257863"}
[2024-10-07 17:51:19,326][train_inner][INFO] - {"epoch": 287, "update": 286.551, "loss": "0.814", "ntokens": "264166", "nsentences": "1738.03", "wps": "252948", "ups": "0.96", "wpb": "264166", "bsz": "1738", "num_updates": "137200", "lr": "0.000357065", "gnorm": "0.258", "loss_scale": "2", "train_wall": "171", "gb_free": "39.6", "wall": "258071"}
[2024-10-07 17:55:22,197][train_inner][INFO] - {"epoch": 287, "update": 286.969, "loss": "0.818", "ntokens": "263876", "nsentences": "1771.97", "wps": "217316", "ups": "0.82", "wpb": "263876", "bsz": "1772", "num_updates": "137400", "lr": "0.000356793", "gnorm": "0.264", "loss_scale": "2", "train_wall": "151", "gb_free": "39.3", "wall": "258314"}
[2024-10-07 17:56:09,853][fairseq_cli.train][INFO] - end of epoch 287 (average epoch stats below)
[2024-10-07 17:56:09,886][train][INFO] - {"epoch": 287, "train_loss": "0.816", "train_ntokens": "263562", "train_nsentences": "1753.71", "train_wps": "116878", "train_ups": "0.44", "train_wpb": "263562", "train_bsz": "1753.7", "train_num_updates": "137415", "train_lr": "0.000356773", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "415", "train_gb_free": "39.8", "train_wall": "258362"}
[2024-10-07 17:56:10,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 17:56:10,133][fairseq.trainer][INFO] - begin training epoch 288
[2024-10-07 17:56:10,134][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:06:10,491][train_inner][INFO] - {"epoch": 288, "update": 287.386, "loss": "0.815", "ntokens": "262968", "nsentences": "1742.52", "wps": "81127.8", "ups": "0.31", "wpb": "262968", "bsz": "1742.5", "num_updates": "137600", "lr": "0.000356522", "gnorm": "0.265", "loss_scale": "2", "train_wall": "284", "gb_free": "39.6", "wall": "258963"}
[2024-10-07 18:10:07,528][train_inner][INFO] - {"epoch": 288, "update": 287.804, "loss": "0.818", "ntokens": "263669", "nsentences": "1775.6", "wps": "222502", "ups": "0.84", "wpb": "263669", "bsz": "1775.6", "num_updates": "137800", "lr": "0.00035625", "gnorm": "0.254", "loss_scale": "4", "train_wall": "232", "gb_free": "40", "wall": "259200"}
[2024-10-07 18:11:53,927][fairseq_cli.train][INFO] - end of epoch 288 (average epoch stats below)
[2024-10-07 18:11:53,941][train][INFO] - {"epoch": 288, "train_loss": "0.817", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "133671", "train_ups": "0.51", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "137894", "train_lr": "0.000356122", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "579", "train_gb_free": "39.6", "train_wall": "259306"}
[2024-10-07 18:11:54,046][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:11:54,064][fairseq.trainer][INFO] - begin training epoch 289
[2024-10-07 18:11:54,065][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:19:41,115][train_inner][INFO] - {"epoch": 289, "update": 288.221, "loss": "0.817", "ntokens": "262634", "nsentences": "1758.41", "wps": "91578.7", "ups": "0.35", "wpb": "262634", "bsz": "1758.4", "num_updates": "138000", "lr": "0.000355978", "gnorm": "0.274", "loss_scale": "4", "train_wall": "217", "gb_free": "39.7", "wall": "259773"}
[2024-10-07 18:23:50,410][train_inner][INFO] - {"epoch": 289, "update": 288.639, "loss": "0.817", "ntokens": "263674", "nsentences": "1788.08", "wps": "211560", "ups": "0.8", "wpb": "263674", "bsz": "1788.1", "num_updates": "138200", "lr": "0.000355707", "gnorm": "0.271", "loss_scale": "4", "train_wall": "244", "gb_free": "39.7", "wall": "260023"}
[2024-10-07 18:27:11,788][fairseq_cli.train][INFO] - end of epoch 289 (average epoch stats below)
[2024-10-07 18:27:11,823][train][INFO] - {"epoch": 289, "train_loss": "0.816", "train_ntokens": "263430", "train_nsentences": "1753.71", "train_wps": "137472", "train_ups": "0.52", "train_wpb": "263430", "train_bsz": "1753.7", "train_num_updates": "138373", "train_lr": "0.000355471", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "553", "train_gb_free": "39.6", "train_wall": "260224"}
[2024-10-07 18:27:12,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:27:12,039][fairseq.trainer][INFO] - begin training epoch 290
[2024-10-07 18:27:12,040][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:34:15,741][train_inner][INFO] - {"epoch": 290, "update": 289.056, "loss": "0.817", "ntokens": "262846", "nsentences": "1728.34", "wps": "84067.1", "ups": "0.32", "wpb": "262846", "bsz": "1728.3", "num_updates": "138400", "lr": "0.000355435", "gnorm": "0.267", "loss_scale": "4", "train_wall": "240", "gb_free": "40.3", "wall": "260648"}
[2024-10-07 18:37:43,387][train_inner][INFO] - {"epoch": 290, "update": 289.474, "loss": "0.814", "ntokens": "264248", "nsentences": "1736.59", "wps": "254525", "ups": "0.96", "wpb": "264248", "bsz": "1736.6", "num_updates": "138600", "lr": "0.000355163", "gnorm": "0.257", "loss_scale": "4", "train_wall": "191", "gb_free": "39.2", "wall": "260856"}
[2024-10-07 18:41:30,074][train_inner][INFO] - {"epoch": 290, "update": 289.891, "loss": "0.816", "ntokens": "263930", "nsentences": "1761.79", "wps": "232889", "ups": "0.88", "wpb": "263930", "bsz": "1761.8", "num_updates": "138800", "lr": "0.000354891", "gnorm": "0.244", "loss_scale": "4", "train_wall": "199", "gb_free": "39.6", "wall": "261082"}
[2024-10-07 18:42:38,220][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 290 @ 138852 updates
[2024-10-07 18:42:38,221][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 18:42:46,148][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 18:42:46,335][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 290 @ 138852 updates, score None) (writing took 8.115510049276054 seconds)
[2024-10-07 18:42:46,346][fairseq_cli.train][INFO] - end of epoch 290 (average epoch stats below)
[2024-10-07 18:42:46,356][train][INFO] - {"epoch": 290, "train_loss": "0.816", "train_ntokens": "263462", "train_nsentences": "1753.71", "train_wps": "135042", "train_ups": "0.51", "train_wpb": "263462", "train_bsz": "1753.7", "train_num_updates": "138852", "train_lr": "0.000354821", "train_gnorm": "0.259", "train_loss_scale": "4", "train_train_wall": "498", "train_gb_free": "39.7", "train_wall": "261159"}
[2024-10-07 18:42:46,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:42:46,492][fairseq.trainer][INFO] - begin training epoch 291
[2024-10-07 18:42:46,493][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 18:48:20,202][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 18:50:58,578][train_inner][INFO] - {"epoch": 291, "update": 290.311, "loss": "0.816", "ntokens": "262857", "nsentences": "1734.9", "wps": "92474.2", "ups": "0.35", "wpb": "262856", "bsz": "1734.9", "num_updates": "139000", "lr": "0.00035462", "gnorm": "0.276", "loss_scale": "2", "train_wall": "245", "gb_free": "40.2", "wall": "261651"}
[2024-10-07 18:54:50,538][train_inner][INFO] - {"epoch": 291, "update": 290.729, "loss": "0.815", "ntokens": "264023", "nsentences": "1754.97", "wps": "227658", "ups": "0.86", "wpb": "264023", "bsz": "1755", "num_updates": "139200", "lr": "0.000354348", "gnorm": "0.254", "loss_scale": "2", "train_wall": "227", "gb_free": "39.2", "wall": "261883"}
[2024-10-07 18:57:04,418][fairseq_cli.train][INFO] - end of epoch 291 (average epoch stats below)
[2024-10-07 18:57:04,458][train][INFO] - {"epoch": 291, "train_loss": "0.815", "train_ntokens": "263481", "train_nsentences": "1754.95", "train_wps": "146773", "train_ups": "0.56", "train_wpb": "263481", "train_bsz": "1754.9", "train_num_updates": "139330", "train_lr": "0.000354171", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "536", "train_gb_free": "39.8", "train_wall": "262017"}
[2024-10-07 18:57:04,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 18:57:04,712][fairseq.trainer][INFO] - begin training epoch 292
[2024-10-07 18:57:04,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:04:50,780][train_inner][INFO] - {"epoch": 292, "update": 291.146, "loss": "0.816", "ntokens": "262569", "nsentences": "1775.28", "wps": "87489", "ups": "0.33", "wpb": "262570", "bsz": "1775.3", "num_updates": "139400", "lr": "0.000354076", "gnorm": "0.265", "loss_scale": "2", "train_wall": "235", "gb_free": "40", "wall": "262483"}
[2024-10-07 19:08:35,110][train_inner][INFO] - {"epoch": 292, "update": 291.564, "loss": "0.813", "ntokens": "264180", "nsentences": "1756.55", "wps": "235541", "ups": "0.89", "wpb": "264180", "bsz": "1756.5", "num_updates": "139600", "lr": "0.000353804", "gnorm": "0.262", "loss_scale": "2", "train_wall": "218", "gb_free": "39.6", "wall": "262707"}
[2024-10-07 19:12:24,944][train_inner][INFO] - {"epoch": 292, "update": 291.981, "loss": "0.816", "ntokens": "264100", "nsentences": "1742.8", "wps": "229830", "ups": "0.87", "wpb": "264100", "bsz": "1742.8", "num_updates": "139800", "lr": "0.000353533", "gnorm": "0.257", "loss_scale": "2", "train_wall": "225", "gb_free": "39.7", "wall": "262937"}
[2024-10-07 19:12:47,913][fairseq_cli.train][INFO] - end of epoch 292 (average epoch stats below)
[2024-10-07 19:12:47,933][train][INFO] - {"epoch": 292, "train_loss": "0.815", "train_ntokens": "263585", "train_nsentences": "1753.71", "train_wps": "133824", "train_ups": "0.51", "train_wpb": "263585", "train_bsz": "1753.7", "train_num_updates": "139809", "train_lr": "0.00035352", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "570", "train_gb_free": "39.3", "train_wall": "262960"}
[2024-10-07 19:12:48,072][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:12:48,111][fairseq.trainer][INFO] - begin training epoch 293
[2024-10-07 19:12:48,111][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:22:16,357][train_inner][INFO] - {"epoch": 293, "update": 292.399, "loss": "0.814", "ntokens": "263165", "nsentences": "1731.06", "wps": "89002.5", "ups": "0.34", "wpb": "263165", "bsz": "1731.1", "num_updates": "140000", "lr": "0.000353261", "gnorm": "0.266", "loss_scale": "2", "train_wall": "244", "gb_free": "40", "wall": "263529"}
[2024-10-07 19:26:21,392][train_inner][INFO] - {"epoch": 293, "update": 292.816, "loss": "0.816", "ntokens": "263938", "nsentences": "1766.14", "wps": "215437", "ups": "0.82", "wpb": "263938", "bsz": "1766.1", "num_updates": "140200", "lr": "0.000352989", "gnorm": "0.261", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "263774"}
[2024-10-07 19:27:58,678][fairseq_cli.train][INFO] - end of epoch 293 (average epoch stats below)
[2024-10-07 19:27:58,714][train][INFO] - {"epoch": 293, "train_loss": "0.815", "train_ntokens": "263586", "train_nsentences": "1753.71", "train_wps": "138629", "train_ups": "0.53", "train_wpb": "263586", "train_bsz": "1753.7", "train_num_updates": "140288", "train_lr": "0.00035287", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.3", "train_wall": "263871"}
[2024-10-07 19:27:58,941][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:27:58,996][fairseq.trainer][INFO] - begin training epoch 294
[2024-10-07 19:27:58,996][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:36:12,535][train_inner][INFO] - {"epoch": 294, "update": 293.234, "loss": "0.814", "ntokens": "262716", "nsentences": "1751.34", "wps": "88885.6", "ups": "0.34", "wpb": "262716", "bsz": "1751.3", "num_updates": "140400", "lr": "0.000352717", "gnorm": "0.271", "loss_scale": "2", "train_wall": "220", "gb_free": "39.6", "wall": "264365"}
[2024-10-07 19:40:00,377][train_inner][INFO] - {"epoch": 294, "update": 293.651, "loss": "0.813", "ntokens": "264410", "nsentences": "1728.53", "wps": "232109", "ups": "0.88", "wpb": "264410", "bsz": "1728.5", "num_updates": "140600", "lr": "0.000352446", "gnorm": "0.265", "loss_scale": "2", "train_wall": "223", "gb_free": "40", "wall": "264593"}
[2024-10-07 19:43:18,561][fairseq_cli.train][INFO] - end of epoch 294 (average epoch stats below)
[2024-10-07 19:43:18,578][train][INFO] - {"epoch": 294, "train_loss": "0.815", "train_ntokens": "263462", "train_nsentences": "1753.71", "train_wps": "137197", "train_ups": "0.52", "train_wpb": "263462", "train_bsz": "1753.7", "train_num_updates": "140767", "train_lr": "0.000352219", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "39.8", "train_wall": "264791"}
[2024-10-07 19:43:18,656][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:43:18,678][fairseq.trainer][INFO] - begin training epoch 295
[2024-10-07 19:43:18,679][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 19:49:39,314][train_inner][INFO] - {"epoch": 295, "update": 294.069, "loss": "0.818", "ntokens": "262376", "nsentences": "1778.54", "wps": "90642.4", "ups": "0.35", "wpb": "262376", "bsz": "1778.5", "num_updates": "140800", "lr": "0.000352174", "gnorm": "0.272", "loss_scale": "2", "train_wall": "251", "gb_free": "39.2", "wall": "265171"}
[2024-10-07 19:53:22,196][train_inner][INFO] - {"epoch": 295, "update": 294.486, "loss": "0.814", "ntokens": "263638", "nsentences": "1800.67", "wps": "236599", "ups": "0.9", "wpb": "263638", "bsz": "1800.7", "num_updates": "141000", "lr": "0.000351902", "gnorm": "0.266", "loss_scale": "4", "train_wall": "217", "gb_free": "40", "wall": "265394"}
[2024-10-07 19:57:08,877][train_inner][INFO] - {"epoch": 295, "update": 294.904, "loss": "0.815", "ntokens": "264166", "nsentences": "1724.43", "wps": "233081", "ups": "0.88", "wpb": "264166", "bsz": "1724.4", "num_updates": "141200", "lr": "0.00035163", "gnorm": "0.259", "loss_scale": "4", "train_wall": "221", "gb_free": "39.3", "wall": "265621"}
[2024-10-07 19:57:58,708][fairseq_cli.train][INFO] - end of epoch 295 (average epoch stats below)
[2024-10-07 19:57:58,752][train][INFO] - {"epoch": 295, "train_loss": "0.815", "train_ntokens": "263457", "train_nsentences": "1753.71", "train_wps": "143377", "train_ups": "0.54", "train_wpb": "263457", "train_bsz": "1753.7", "train_num_updates": "141246", "train_lr": "0.000351568", "train_gnorm": "0.265", "train_loss_scale": "4", "train_train_wall": "544", "train_gb_free": "40", "train_wall": "265671"}
[2024-10-07 19:57:59,033][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 19:57:59,046][fairseq.trainer][INFO] - begin training epoch 296
[2024-10-07 19:57:59,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:06:40,502][train_inner][INFO] - {"epoch": 296, "update": 295.322, "loss": "0.812", "ntokens": "263102", "nsentences": "1721.61", "wps": "92057", "ups": "0.35", "wpb": "263102", "bsz": "1721.6", "num_updates": "141400", "lr": "0.000351359", "gnorm": "0.263", "loss_scale": "4", "train_wall": "206", "gb_free": "39.2", "wall": "266193"}
[2024-10-07 20:10:17,463][train_inner][INFO] - {"epoch": 296, "update": 295.739, "loss": "0.816", "ntokens": "264160", "nsentences": "1752.72", "wps": "243531", "ups": "0.92", "wpb": "264160", "bsz": "1752.7", "num_updates": "141600", "lr": "0.000351087", "gnorm": "0.262", "loss_scale": "4", "train_wall": "128", "gb_free": "39.6", "wall": "266410"}
[2024-10-07 20:12:40,350][fairseq_cli.train][INFO] - end of epoch 296 (average epoch stats below)
[2024-10-07 20:12:40,355][train][INFO] - {"epoch": 296, "train_loss": "0.815", "train_ntokens": "263634", "train_nsentences": "1753.71", "train_wps": "143247", "train_ups": "0.54", "train_wpb": "263634", "train_bsz": "1753.7", "train_num_updates": "141725", "train_lr": "0.000350917", "train_gnorm": "0.275", "train_loss_scale": "4", "train_train_wall": "378", "train_gb_free": "39.8", "train_wall": "266553"}
[2024-10-07 20:12:40,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:12:40,470][fairseq.trainer][INFO] - begin training epoch 297
[2024-10-07 20:12:40,470][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:19:42,537][train_inner][INFO] - {"epoch": 297, "update": 296.157, "loss": "0.816", "ntokens": "262784", "nsentences": "1767.08", "wps": "93015.4", "ups": "0.35", "wpb": "262784", "bsz": "1767.1", "num_updates": "141800", "lr": "0.000350815", "gnorm": "0.292", "loss_scale": "4", "train_wall": "185", "gb_free": "39.6", "wall": "266975"}
[2024-10-07 20:23:24,134][train_inner][INFO] - {"epoch": 297, "update": 296.574, "loss": "0.813", "ntokens": "263774", "nsentences": "1764.57", "wps": "238075", "ups": "0.9", "wpb": "263774", "bsz": "1764.6", "num_updates": "142000", "lr": "0.000350543", "gnorm": "0.267", "loss_scale": "4", "train_wall": "216", "gb_free": "39.2", "wall": "267196"}
[2024-10-07 20:23:50,420][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 20:27:22,970][train_inner][INFO] - {"epoch": 297, "update": 296.994, "loss": "0.817", "ntokens": "263844", "nsentences": "1760.89", "wps": "220979", "ups": "0.84", "wpb": "263844", "bsz": "1760.9", "num_updates": "142200", "lr": "0.000350272", "gnorm": "0.27", "loss_scale": "2", "train_wall": "234", "gb_free": "40", "wall": "267435"}
[2024-10-07 20:27:23,907][fairseq_cli.train][INFO] - end of epoch 297 (average epoch stats below)
[2024-10-07 20:27:23,927][train][INFO] - {"epoch": 297, "train_loss": "0.814", "train_ntokens": "263374", "train_nsentences": "1754.85", "train_wps": "142483", "train_ups": "0.54", "train_wpb": "263374", "train_bsz": "1754.8", "train_num_updates": "142203", "train_lr": "0.000350268", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "39.8", "train_wall": "267436"}
[2024-10-07 20:27:23,985][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:27:24,027][fairseq.trainer][INFO] - begin training epoch 298
[2024-10-07 20:27:24,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:36:44,810][train_inner][INFO] - {"epoch": 298, "update": 297.411, "loss": "0.812", "ntokens": "262480", "nsentences": "1784.37", "wps": "93442", "ups": "0.36", "wpb": "262480", "bsz": "1784.4", "num_updates": "142400", "lr": "0.00035", "gnorm": "0.274", "loss_scale": "2", "train_wall": "185", "gb_free": "39.6", "wall": "267997"}
[2024-10-07 20:40:36,931][train_inner][INFO] - {"epoch": 298, "update": 297.829, "loss": "0.815", "ntokens": "263981", "nsentences": "1748.91", "wps": "227473", "ups": "0.86", "wpb": "263981", "bsz": "1748.9", "num_updates": "142600", "lr": "0.000349728", "gnorm": "0.266", "loss_scale": "2", "train_wall": "160", "gb_free": "39.7", "wall": "268229"}
[2024-10-07 20:42:08,305][fairseq_cli.train][INFO] - end of epoch 298 (average epoch stats below)
[2024-10-07 20:42:08,354][train][INFO] - {"epoch": 298, "train_loss": "0.813", "train_ntokens": "263437", "train_nsentences": "1753.71", "train_wps": "142679", "train_ups": "0.54", "train_wpb": "263437", "train_bsz": "1753.7", "train_num_updates": "142682", "train_lr": "0.000349617", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "390", "train_gb_free": "39.3", "train_wall": "268321"}
[2024-10-07 20:42:08,742][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:42:08,787][fairseq.trainer][INFO] - begin training epoch 299
[2024-10-07 20:42:08,794][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 20:50:06,725][train_inner][INFO] - {"epoch": 299, "update": 298.246, "loss": "0.811", "ntokens": "263350", "nsentences": "1682.83", "wps": "92439.2", "ups": "0.35", "wpb": "263350", "bsz": "1682.8", "num_updates": "142800", "lr": "0.000349457", "gnorm": "0.271", "loss_scale": "2", "train_wall": "184", "gb_free": "39.3", "wall": "268799"}
[2024-10-07 20:53:51,993][train_inner][INFO] - {"epoch": 299, "update": 298.664, "loss": "0.815", "ntokens": "263548", "nsentences": "1805.51", "wps": "233997", "ups": "0.89", "wpb": "263548", "bsz": "1805.5", "num_updates": "143000", "lr": "0.000349185", "gnorm": "0.256", "loss_scale": "2", "train_wall": "217", "gb_free": "40", "wall": "269024"}
[2024-10-07 20:57:23,177][fairseq_cli.train][INFO] - end of epoch 299 (average epoch stats below)
[2024-10-07 20:57:23,242][train][INFO] - {"epoch": 299, "train_loss": "0.813", "train_ntokens": "263461", "train_nsentences": "1753.71", "train_wps": "137941", "train_ups": "0.52", "train_wpb": "263461", "train_bsz": "1753.7", "train_num_updates": "143161", "train_lr": "0.000348966", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.3", "train_wall": "269235"}
[2024-10-07 20:57:23,964][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 20:57:24,027][fairseq.trainer][INFO] - begin training epoch 300
[2024-10-07 20:57:24,027][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:03:29,397][train_inner][INFO] - {"epoch": 300, "update": 299.081, "loss": "0.814", "ntokens": "262848", "nsentences": "1739.05", "wps": "91046.1", "ups": "0.35", "wpb": "262848", "bsz": "1739", "num_updates": "143200", "lr": "0.000348913", "gnorm": "0.272", "loss_scale": "2", "train_wall": "256", "gb_free": "39.6", "wall": "269602"}
[2024-10-07 21:07:14,583][train_inner][INFO] - {"epoch": 300, "update": 299.499, "loss": "0.812", "ntokens": "263996", "nsentences": "1760.26", "wps": "234487", "ups": "0.89", "wpb": "263996", "bsz": "1760.3", "num_updates": "143400", "lr": "0.000348641", "gnorm": "0.255", "loss_scale": "2", "train_wall": "143", "gb_free": "39.6", "wall": "269827"}
[2024-10-07 21:11:22,335][train_inner][INFO] - {"epoch": 300, "update": 299.916, "loss": "0.816", "ntokens": "264213", "nsentences": "1747.37", "wps": "213300", "ups": "0.81", "wpb": "264213", "bsz": "1747.4", "num_updates": "143600", "lr": "0.00034837", "gnorm": "0.27", "loss_scale": "2", "train_wall": "157", "gb_free": "39.1", "wall": "270075"}
[2024-10-07 21:12:16,537][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 300 @ 143640 updates
[2024-10-07 21:12:16,538][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 21:12:23,069][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 21:12:23,092][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 300 @ 143640 updates, score None) (writing took 6.554987404495478 seconds)
[2024-10-07 21:12:23,093][fairseq_cli.train][INFO] - end of epoch 300 (average epoch stats below)
[2024-10-07 21:12:23,097][train][INFO] - {"epoch": 300, "train_loss": "0.814", "train_ntokens": "263570", "train_nsentences": "1753.71", "train_wps": "140303", "train_ups": "0.53", "train_wpb": "263570", "train_bsz": "1753.7", "train_num_updates": "143640", "train_lr": "0.000348315", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "400", "train_gb_free": "39.3", "train_wall": "270135"}
[2024-10-07 21:12:23,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:12:23,200][fairseq.trainer][INFO] - begin training epoch 301
[2024-10-07 21:12:23,201][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:20:51,572][train_inner][INFO] - {"epoch": 301, "update": 300.334, "loss": "0.813", "ntokens": "262690", "nsentences": "1768.33", "wps": "92300.7", "ups": "0.35", "wpb": "262690", "bsz": "1768.3", "num_updates": "143800", "lr": "0.000348098", "gnorm": "0.275", "loss_scale": "2", "train_wall": "217", "gb_free": "39.8", "wall": "270644"}
[2024-10-07 21:24:38,363][train_inner][INFO] - {"epoch": 301, "update": 300.752, "loss": "0.812", "ntokens": "264182", "nsentences": "1730.82", "wps": "232996", "ups": "0.88", "wpb": "264182", "bsz": "1730.8", "num_updates": "144000", "lr": "0.000347826", "gnorm": "0.254", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "270871"}
[2024-10-07 21:26:47,605][fairseq_cli.train][INFO] - end of epoch 301 (average epoch stats below)
[2024-10-07 21:26:47,634][train][INFO] - {"epoch": 301, "train_loss": "0.813", "train_ntokens": "263480", "train_nsentences": "1753.71", "train_wps": "145985", "train_ups": "0.55", "train_wpb": "263480", "train_bsz": "1753.7", "train_num_updates": "144119", "train_lr": "0.000347664", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "514", "train_gb_free": "39.3", "train_wall": "271000"}
[2024-10-07 21:26:47,754][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:26:47,820][fairseq.trainer][INFO] - begin training epoch 302
[2024-10-07 21:26:47,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:33:51,976][train_inner][INFO] - {"epoch": 302, "update": 301.169, "loss": "0.816", "ntokens": "262603", "nsentences": "1777.9", "wps": "94870.8", "ups": "0.36", "wpb": "262603", "bsz": "1777.9", "num_updates": "144200", "lr": "0.000347554", "gnorm": "0.26", "loss_scale": "4", "train_wall": "233", "gb_free": "40", "wall": "271424"}
[2024-10-07 21:37:31,001][train_inner][INFO] - {"epoch": 302, "update": 301.587, "loss": "0.811", "ntokens": "263712", "nsentences": "1760.67", "wps": "240826", "ups": "0.91", "wpb": "263712", "bsz": "1760.7", "num_updates": "144400", "lr": "0.000347283", "gnorm": "0.286", "loss_scale": "4", "train_wall": "213", "gb_free": "39.8", "wall": "271643"}
[2024-10-07 21:41:39,516][fairseq_cli.train][INFO] - end of epoch 302 (average epoch stats below)
[2024-10-07 21:41:39,548][train][INFO] - {"epoch": 302, "train_loss": "0.814", "train_ntokens": "263489", "train_nsentences": "1753.71", "train_wps": "141510", "train_ups": "0.54", "train_wpb": "263489", "train_bsz": "1753.7", "train_num_updates": "144598", "train_lr": "0.000347014", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "564", "train_gb_free": "40", "train_wall": "271892"}
[2024-10-07 21:41:39,743][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:41:39,748][fairseq.trainer][INFO] - begin training epoch 303
[2024-10-07 21:41:39,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 21:47:25,632][train_inner][INFO] - {"epoch": 303, "update": 302.004, "loss": "0.816", "ntokens": "263128", "nsentences": "1728.18", "wps": "88502.7", "ups": "0.34", "wpb": "263128", "bsz": "1728.2", "num_updates": "144600", "lr": "0.000347011", "gnorm": "0.249", "loss_scale": "4", "train_wall": "269", "gb_free": "39.1", "wall": "272238"}
[2024-10-07 21:50:50,743][train_inner][INFO] - {"epoch": 303, "update": 302.422, "loss": "0.811", "ntokens": "264005", "nsentences": "1776.6", "wps": "257438", "ups": "0.98", "wpb": "264005", "bsz": "1776.6", "num_updates": "144800", "lr": "0.000346739", "gnorm": "0.27", "loss_scale": "4", "train_wall": "200", "gb_free": "40.8", "wall": "272443"}
[2024-10-07 21:55:27,081][train_inner][INFO] - {"epoch": 303, "update": 302.839, "loss": "0.816", "ntokens": "264252", "nsentences": "1750.49", "wps": "191263", "ups": "0.72", "wpb": "264252", "bsz": "1750.5", "num_updates": "145000", "lr": "0.000346467", "gnorm": "0.257", "loss_scale": "4", "train_wall": "270", "gb_free": "39.6", "wall": "272719"}
[2024-10-07 21:57:11,794][fairseq_cli.train][INFO] - end of epoch 303 (average epoch stats below)
[2024-10-07 21:57:11,810][train][INFO] - {"epoch": 303, "train_loss": "0.813", "train_ntokens": "263672", "train_nsentences": "1753.71", "train_wps": "135478", "train_ups": "0.51", "train_wpb": "263672", "train_bsz": "1753.7", "train_num_updates": "145077", "train_lr": "0.000346363", "train_gnorm": "0.262", "train_loss_scale": "4", "train_train_wall": "599", "train_gb_free": "39.6", "train_wall": "272824"}
[2024-10-07 21:57:11,905][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 21:57:11,921][fairseq.trainer][INFO] - begin training epoch 304
[2024-10-07 21:57:11,922][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:05:16,625][train_inner][INFO] - {"epoch": 304, "update": 303.257, "loss": "0.813", "ntokens": "262918", "nsentences": "1745.29", "wps": "89196.1", "ups": "0.34", "wpb": "262918", "bsz": "1745.3", "num_updates": "145200", "lr": "0.000346196", "gnorm": "0.258", "loss_scale": "4", "train_wall": "247", "gb_free": "39.3", "wall": "273309"}
[2024-10-07 22:05:47,106][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-07 22:09:41,050][train_inner][INFO] - {"epoch": 304, "update": 303.676, "loss": "0.81", "ntokens": "264044", "nsentences": "1759.33", "wps": "199726", "ups": "0.76", "wpb": "264044", "bsz": "1759.3", "num_updates": "145400", "lr": "0.000345924", "gnorm": "0.269", "loss_scale": "2", "train_wall": "259", "gb_free": "39.2", "wall": "273573"}
[2024-10-07 22:13:07,920][fairseq_cli.train][INFO] - end of epoch 304 (average epoch stats below)
[2024-10-07 22:13:07,940][train][INFO] - {"epoch": 304, "train_loss": "0.813", "train_ntokens": "263537", "train_nsentences": "1753.66", "train_wps": "131751", "train_ups": "0.5", "train_wpb": "263537", "train_bsz": "1753.7", "train_num_updates": "145555", "train_lr": "0.000345713", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "607", "train_gb_free": "39.6", "train_wall": "273780"}
[2024-10-07 22:13:08,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:13:08,272][fairseq.trainer][INFO] - begin training epoch 305
[2024-10-07 22:13:08,273][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:22:20,351][train_inner][INFO] - {"epoch": 305, "update": 304.094, "loss": "0.816", "ntokens": "262875", "nsentences": "1741.06", "wps": "69242.3", "ups": "0.26", "wpb": "262875", "bsz": "1741.1", "num_updates": "145600", "lr": "0.000345652", "gnorm": "0.266", "loss_scale": "2", "train_wall": "281", "gb_free": "39.3", "wall": "274333"}
[2024-10-07 22:25:52,323][train_inner][INFO] - {"epoch": 305, "update": 304.511, "loss": "0.811", "ntokens": "263981", "nsentences": "1762.34", "wps": "249094", "ups": "0.94", "wpb": "263981", "bsz": "1762.3", "num_updates": "145800", "lr": "0.00034538", "gnorm": "0.263", "loss_scale": "2", "train_wall": "207", "gb_free": "39.8", "wall": "274544"}
[2024-10-07 22:29:42,541][train_inner][INFO] - {"epoch": 305, "update": 304.929, "loss": "0.813", "ntokens": "264091", "nsentences": "1731.55", "wps": "229442", "ups": "0.87", "wpb": "264090", "bsz": "1731.5", "num_updates": "146000", "lr": "0.000345109", "gnorm": "0.27", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "274775"}
[2024-10-07 22:30:28,069][fairseq_cli.train][INFO] - end of epoch 305 (average epoch stats below)
[2024-10-07 22:30:28,090][train][INFO] - {"epoch": 305, "train_loss": "0.813", "train_ntokens": "263454", "train_nsentences": "1753.71", "train_wps": "121326", "train_ups": "0.46", "train_wpb": "263454", "train_bsz": "1753.7", "train_num_updates": "146034", "train_lr": "0.000345062", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "555", "train_gb_free": "40", "train_wall": "274820"}
[2024-10-07 22:30:28,179][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:30:28,252][fairseq.trainer][INFO] - begin training epoch 306
[2024-10-07 22:30:28,253][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:40:53,973][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-07 22:42:36,220][train_inner][INFO] - {"epoch": 306, "update": 305.349, "loss": "0.813", "ntokens": "262948", "nsentences": "1734.74", "wps": "67973.9", "ups": "0.26", "wpb": "262948", "bsz": "1734.7", "num_updates": "146200", "lr": "0.000344837", "gnorm": "0.266", "loss_scale": "1", "train_wall": "238", "gb_free": "39.6", "wall": "275548"}
[2024-10-07 22:46:28,749][train_inner][INFO] - {"epoch": 306, "update": 305.766, "loss": "0.814", "ntokens": "263758", "nsentences": "1785.22", "wps": "226872", "ups": "0.86", "wpb": "263758", "bsz": "1785.2", "num_updates": "146400", "lr": "0.000344565", "gnorm": "0.28", "loss_scale": "1", "train_wall": "227", "gb_free": "39.8", "wall": "275781"}
[2024-10-07 22:48:54,073][fairseq_cli.train][INFO] - end of epoch 306 (average epoch stats below)
[2024-10-07 22:48:54,102][train][INFO] - {"epoch": 306, "train_loss": "0.813", "train_ntokens": "263500", "train_nsentences": "1754.77", "train_wps": "113882", "train_ups": "0.43", "train_wpb": "263500", "train_bsz": "1754.8", "train_num_updates": "146512", "train_lr": "0.000344413", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "562", "train_gb_free": "39.6", "train_wall": "275926"}
[2024-10-07 22:48:54,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 22:48:54,192][fairseq.trainer][INFO] - begin training epoch 307
[2024-10-07 22:48:54,192][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 22:56:12,537][train_inner][INFO] - {"epoch": 307, "update": 306.184, "loss": "0.814", "ntokens": "262580", "nsentences": "1777.18", "wps": "89960.3", "ups": "0.34", "wpb": "262580", "bsz": "1777.2", "num_updates": "146600", "lr": "0.000344293", "gnorm": "0.258", "loss_scale": "1", "train_wall": "248", "gb_free": "39.1", "wall": "276365"}
[2024-10-07 22:59:42,495][train_inner][INFO] - {"epoch": 307, "update": 306.601, "loss": "0.812", "ntokens": "264141", "nsentences": "1743.36", "wps": "251639", "ups": "0.95", "wpb": "264141", "bsz": "1743.4", "num_updates": "146800", "lr": "0.000344022", "gnorm": "0.265", "loss_scale": "1", "train_wall": "153", "gb_free": "40.3", "wall": "276575"}
[2024-10-07 23:03:57,821][fairseq_cli.train][INFO] - end of epoch 307 (average epoch stats below)
[2024-10-07 23:03:57,946][train][INFO] - {"epoch": 307, "train_loss": "0.813", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "139660", "train_ups": "0.53", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "146991", "train_lr": "0.000343762", "train_gnorm": "0.262", "train_loss_scale": "1", "train_train_wall": "393", "train_gb_free": "39.3", "train_wall": "276830"}
[2024-10-07 23:03:59,483][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:03:59,583][fairseq.trainer][INFO] - begin training epoch 308
[2024-10-07 23:03:59,583][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 23:10:30,016][train_inner][INFO] - {"epoch": 308, "update": 307.019, "loss": "0.814", "ntokens": "262893", "nsentences": "1740.96", "wps": "81201.8", "ups": "0.31", "wpb": "262893", "bsz": "1741", "num_updates": "147000", "lr": "0.00034375", "gnorm": "0.266", "loss_scale": "1", "train_wall": "144", "gb_free": "39.6", "wall": "277222"}
[2024-10-07 23:14:07,395][train_inner][INFO] - {"epoch": 308, "update": 307.436, "loss": "0.812", "ntokens": "263945", "nsentences": "1775", "wps": "242867", "ups": "0.92", "wpb": "263945", "bsz": "1775", "num_updates": "147200", "lr": "0.000343478", "gnorm": "0.263", "loss_scale": "1", "train_wall": "153", "gb_free": "39.6", "wall": "277440"}
[2024-10-07 23:18:40,382][train_inner][INFO] - {"epoch": 308, "update": 307.854, "loss": "0.811", "ntokens": "264284", "nsentences": "1725.98", "wps": "193637", "ups": "0.73", "wpb": "264284", "bsz": "1726", "num_updates": "147400", "lr": "0.000343207", "gnorm": "0.264", "loss_scale": "1", "train_wall": "147", "gb_free": "39.6", "wall": "277713"}
[2024-10-07 23:20:13,123][fairseq_cli.train][INFO] - end of epoch 308 (average epoch stats below)
[2024-10-07 23:20:13,143][train][INFO] - {"epoch": 308, "train_loss": "0.812", "train_ntokens": "263596", "train_nsentences": "1753.71", "train_wps": "129474", "train_ups": "0.49", "train_wpb": "263596", "train_bsz": "1753.7", "train_num_updates": "147470", "train_lr": "0.000343111", "train_gnorm": "0.266", "train_loss_scale": "1", "train_train_wall": "377", "train_gb_free": "39.3", "train_wall": "277805"}
[2024-10-07 23:20:13,223][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:20:13,397][fairseq.trainer][INFO] - begin training epoch 309
[2024-10-07 23:20:13,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 23:30:17,798][train_inner][INFO] - {"epoch": 309, "update": 308.271, "loss": "0.814", "ntokens": "262663", "nsentences": "1772.02", "wps": "75331.7", "ups": "0.29", "wpb": "262663", "bsz": "1772", "num_updates": "147600", "lr": "0.000342935", "gnorm": "0.257", "loss_scale": "1", "train_wall": "193", "gb_free": "39.8", "wall": "278410"}
[2024-10-07 23:33:59,729][train_inner][INFO] - {"epoch": 309, "update": 308.689, "loss": "0.812", "ntokens": "264123", "nsentences": "1762.83", "wps": "238068", "ups": "0.9", "wpb": "264123", "bsz": "1762.8", "num_updates": "147800", "lr": "0.000342663", "gnorm": "0.268", "loss_scale": "1", "train_wall": "212", "gb_free": "40.3", "wall": "278632"}
[2024-10-07 23:36:53,870][fairseq_cli.train][INFO] - end of epoch 309 (average epoch stats below)
[2024-10-07 23:36:53,883][train][INFO] - {"epoch": 309, "train_loss": "0.812", "train_ntokens": "263544", "train_nsentences": "1753.71", "train_wps": "126145", "train_ups": "0.48", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "147949", "train_lr": "0.000342461", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "508", "train_gb_free": "39.6", "train_wall": "278806"}
[2024-10-07 23:36:54,007][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:36:54,053][fairseq.trainer][INFO] - begin training epoch 310
[2024-10-07 23:36:54,054][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-07 23:43:35,481][train_inner][INFO] - {"epoch": 310, "update": 309.106, "loss": "0.812", "ntokens": "263059", "nsentences": "1715.12", "wps": "91381.6", "ups": "0.35", "wpb": "263059", "bsz": "1715.1", "num_updates": "148000", "lr": "0.000342391", "gnorm": "0.274", "loss_scale": "1", "train_wall": "227", "gb_free": "39.4", "wall": "279208"}
[2024-10-07 23:47:03,792][train_inner][INFO] - {"epoch": 310, "update": 309.524, "loss": "0.812", "ntokens": "263981", "nsentences": "1754.6", "wps": "253468", "ups": "0.96", "wpb": "263981", "bsz": "1754.6", "num_updates": "148200", "lr": "0.00034212", "gnorm": "0.272", "loss_scale": "2", "train_wall": "171", "gb_free": "39.7", "wall": "279416"}
[2024-10-07 23:51:07,705][train_inner][INFO] - {"epoch": 310, "update": 309.942, "loss": "0.814", "ntokens": "264097", "nsentences": "1773.72", "wps": "216577", "ups": "0.82", "wpb": "264097", "bsz": "1773.7", "num_updates": "148400", "lr": "0.000341848", "gnorm": "0.277", "loss_scale": "2", "train_wall": "175", "gb_free": "40.1", "wall": "279660"}
[2024-10-07 23:51:59,230][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 310 @ 148428 updates
[2024-10-07 23:51:59,230][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 23:52:04,675][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-07 23:52:04,724][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 310 @ 148428 updates, score None) (writing took 5.494680519215763 seconds)
[2024-10-07 23:52:04,725][fairseq_cli.train][INFO] - end of epoch 310 (average epoch stats below)
[2024-10-07 23:52:04,734][train][INFO] - {"epoch": 310, "train_loss": "0.812", "train_ntokens": "263633", "train_nsentences": "1753.71", "train_wps": "138644", "train_ups": "0.53", "train_wpb": "263633", "train_bsz": "1753.7", "train_num_updates": "148428", "train_lr": "0.00034181", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "455", "train_gb_free": "39.7", "train_wall": "279717"}
[2024-10-07 23:52:04,764][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-07 23:52:04,804][fairseq.trainer][INFO] - begin training epoch 311
[2024-10-07 23:52:04,804][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:00:22,835][train_inner][INFO] - {"epoch": 311, "update": 310.359, "loss": "0.807", "ntokens": "263111", "nsentences": "1724.48", "wps": "94799.7", "ups": "0.36", "wpb": "263111", "bsz": "1724.5", "num_updates": "148600", "lr": "0.000341576", "gnorm": "0.266", "loss_scale": "2", "train_wall": "219", "gb_free": "39.2", "wall": "280215"}
[2024-10-08 00:04:27,864][train_inner][INFO] - {"epoch": 311, "update": 310.777, "loss": "0.815", "ntokens": "263694", "nsentences": "1792.41", "wps": "215244", "ups": "0.82", "wpb": "263694", "bsz": "1792.4", "num_updates": "148800", "lr": "0.000341304", "gnorm": "0.26", "loss_scale": "2", "train_wall": "193", "gb_free": "40.3", "wall": "280460"}
[2024-10-08 00:06:46,892][fairseq_cli.train][INFO] - end of epoch 311 (average epoch stats below)
[2024-10-08 00:06:46,897][train][INFO] - {"epoch": 311, "train_loss": "0.812", "train_ntokens": "263483", "train_nsentences": "1753.71", "train_wps": "143068", "train_ups": "0.54", "train_wpb": "263483", "train_bsz": "1753.7", "train_num_updates": "148907", "train_lr": "0.000341159", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "496", "train_gb_free": "39.7", "train_wall": "280599"}
[2024-10-08 00:06:46,980][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:06:46,988][fairseq.trainer][INFO] - begin training epoch 312
[2024-10-08 00:06:46,988][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:14:15,455][train_inner][INFO] - {"epoch": 312, "update": 311.194, "loss": "0.812", "ntokens": "262743", "nsentences": "1739.42", "wps": "89431.9", "ups": "0.34", "wpb": "262742", "bsz": "1739.4", "num_updates": "149000", "lr": "0.000341033", "gnorm": "0.266", "loss_scale": "2", "train_wall": "264", "gb_free": "39.6", "wall": "281048"}
[2024-10-08 00:17:55,855][train_inner][INFO] - {"epoch": 312, "update": 311.612, "loss": "0.811", "ntokens": "263898", "nsentences": "1778.62", "wps": "239485", "ups": "0.91", "wpb": "263898", "bsz": "1778.6", "num_updates": "149200", "lr": "0.000340761", "gnorm": "0.285", "loss_scale": "2", "train_wall": "215", "gb_free": "39.2", "wall": "281268"}
[2024-10-08 00:21:34,675][fairseq_cli.train][INFO] - end of epoch 312 (average epoch stats below)
[2024-10-08 00:21:34,700][train][INFO] - {"epoch": 312, "train_loss": "0.811", "train_ntokens": "263525", "train_nsentences": "1753.71", "train_wps": "142184", "train_ups": "0.54", "train_wpb": "263525", "train_bsz": "1753.7", "train_num_updates": "149386", "train_lr": "0.000340508", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "558", "train_gb_free": "39.6", "train_wall": "281487"}
[2024-10-08 00:21:34,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:21:34,840][fairseq.trainer][INFO] - begin training epoch 313
[2024-10-08 00:21:34,840][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:27:35,050][train_inner][INFO] - {"epoch": 313, "update": 312.029, "loss": "0.811", "ntokens": "263190", "nsentences": "1718.33", "wps": "90886.7", "ups": "0.35", "wpb": "263190", "bsz": "1718.3", "num_updates": "149400", "lr": "0.000340489", "gnorm": "0.259", "loss_scale": "2", "train_wall": "236", "gb_free": "39.8", "wall": "281847"}
[2024-10-08 00:30:59,539][train_inner][INFO] - {"epoch": 313, "update": 312.447, "loss": "0.809", "ntokens": "264320", "nsentences": "1726.59", "wps": "258565", "ups": "0.98", "wpb": "264320", "bsz": "1726.6", "num_updates": "149600", "lr": "0.000340217", "gnorm": "0.255", "loss_scale": "2", "train_wall": "199", "gb_free": "40.3", "wall": "282052"}
[2024-10-08 00:34:55,712][train_inner][INFO] - {"epoch": 313, "update": 312.864, "loss": "0.812", "ntokens": "263939", "nsentences": "1767.61", "wps": "223532", "ups": "0.85", "wpb": "263938", "bsz": "1767.6", "num_updates": "149800", "lr": "0.000339946", "gnorm": "0.251", "loss_scale": "2", "train_wall": "231", "gb_free": "39.3", "wall": "282288"}
[2024-10-08 00:36:15,094][fairseq_cli.train][INFO] - end of epoch 313 (average epoch stats below)
[2024-10-08 00:36:15,136][train][INFO] - {"epoch": 313, "train_loss": "0.811", "train_ntokens": "263554", "train_nsentences": "1753.71", "train_wps": "143387", "train_ups": "0.54", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "149865", "train_lr": "0.000339857", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "521", "train_gb_free": "39.6", "train_wall": "282367"}
[2024-10-08 00:36:15,242][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:36:15,277][fairseq.trainer][INFO] - begin training epoch 314
[2024-10-08 00:36:15,278][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:44:42,051][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 00:44:51,287][train_inner][INFO] - {"epoch": 314, "update": 313.284, "loss": "0.809", "ntokens": "262671", "nsentences": "1759.6", "wps": "88209.9", "ups": "0.34", "wpb": "262671", "bsz": "1759.6", "num_updates": "150000", "lr": "0.000339674", "gnorm": "0.284", "loss_scale": "1", "train_wall": "217", "gb_free": "39.3", "wall": "282883"}
[2024-10-08 00:44:51,300][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 314 @ 150000 updates
[2024-10-08 00:44:51,301][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_314_150000.pt
[2024-10-08 00:44:55,846][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_314_150000.pt
[2024-10-08 00:45:01,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_314_150000.pt (epoch 314 @ 150000 updates, score None) (writing took 10.095833376981318 seconds)
[2024-10-08 00:48:35,478][train_inner][INFO] - {"epoch": 314, "update": 313.701, "loss": "0.811", "ntokens": "263737", "nsentences": "1781.73", "wps": "235292", "ups": "0.89", "wpb": "263737", "bsz": "1781.7", "num_updates": "150200", "lr": "0.000339402", "gnorm": "0.266", "loss_scale": "1", "train_wall": "161", "gb_free": "39.2", "wall": "283108"}
[2024-10-08 00:51:24,847][fairseq_cli.train][INFO] - end of epoch 314 (average epoch stats below)
[2024-10-08 00:51:24,867][train][INFO] - {"epoch": 314, "train_loss": "0.81", "train_ntokens": "263436", "train_nsentences": "1752.42", "train_wps": "138420", "train_ups": "0.53", "train_wpb": "263436", "train_bsz": "1752.4", "train_num_updates": "150343", "train_lr": "0.000339208", "train_gnorm": "0.278", "train_loss_scale": "1", "train_train_wall": "449", "train_gb_free": "39.3", "train_wall": "283277"}
[2024-10-08 00:51:24,969][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 00:51:24,991][fairseq.trainer][INFO] - begin training epoch 315
[2024-10-08 00:51:24,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 00:57:58,195][train_inner][INFO] - {"epoch": 315, "update": 314.119, "loss": "0.812", "ntokens": "262785", "nsentences": "1743.36", "wps": "93400.1", "ups": "0.36", "wpb": "262785", "bsz": "1743.4", "num_updates": "150400", "lr": "0.00033913", "gnorm": "0.28", "loss_scale": "1", "train_wall": "187", "gb_free": "39.6", "wall": "283670"}
[2024-10-08 01:01:39,779][train_inner][INFO] - {"epoch": 315, "update": 314.537, "loss": "0.808", "ntokens": "264330", "nsentences": "1708.88", "wps": "238596", "ups": "0.9", "wpb": "264330", "bsz": "1708.9", "num_updates": "150600", "lr": "0.000338859", "gnorm": "0.258", "loss_scale": "1", "train_wall": "212", "gb_free": "39.6", "wall": "283892"}
[2024-10-08 01:05:16,028][train_inner][INFO] - {"epoch": 315, "update": 314.954, "loss": "0.814", "ntokens": "263570", "nsentences": "1804.93", "wps": "243802", "ups": "0.93", "wpb": "263570", "bsz": "1804.9", "num_updates": "150800", "lr": "0.000338587", "gnorm": "0.267", "loss_scale": "1", "train_wall": "187", "gb_free": "39.3", "wall": "284108"}
[2024-10-08 01:06:00,541][fairseq_cli.train][INFO] - end of epoch 315 (average epoch stats below)
[2024-10-08 01:06:00,588][train][INFO] - {"epoch": 315, "train_loss": "0.811", "train_ntokens": "263488", "train_nsentences": "1753.71", "train_wps": "144126", "train_ups": "0.55", "train_wpb": "263488", "train_bsz": "1753.7", "train_num_updates": "150822", "train_lr": "0.000338557", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "473", "train_gb_free": "40.3", "train_wall": "284153"}
[2024-10-08 01:06:00,814][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:06:00,851][fairseq.trainer][INFO] - begin training epoch 316
[2024-10-08 01:06:00,852][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:14:39,639][train_inner][INFO] - {"epoch": 316, "update": 315.372, "loss": "0.808", "ntokens": "262931", "nsentences": "1742.93", "wps": "93303.7", "ups": "0.35", "wpb": "262931", "bsz": "1742.9", "num_updates": "151000", "lr": "0.000338315", "gnorm": "0.268", "loss_scale": "1", "train_wall": "226", "gb_free": "39.8", "wall": "284672"}
[2024-10-08 01:18:31,831][train_inner][INFO] - {"epoch": 316, "update": 315.789, "loss": "0.81", "ntokens": "263745", "nsentences": "1766.2", "wps": "227192", "ups": "0.86", "wpb": "263744", "bsz": "1766.2", "num_updates": "151200", "lr": "0.000338043", "gnorm": "0.271", "loss_scale": "1", "train_wall": "227", "gb_free": "39.8", "wall": "284904"}
[2024-10-08 01:20:32,517][fairseq_cli.train][INFO] - end of epoch 316 (average epoch stats below)
[2024-10-08 01:20:32,589][train][INFO] - {"epoch": 316, "train_loss": "0.81", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "144747", "train_ups": "0.55", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "151301", "train_lr": "0.000337906", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "543", "train_gb_free": "40", "train_wall": "285025"}
[2024-10-08 01:20:32,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:20:32,709][fairseq.trainer][INFO] - begin training epoch 317
[2024-10-08 01:20:32,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:28:05,804][train_inner][INFO] - {"epoch": 317, "update": 316.207, "loss": "0.81", "ntokens": "263102", "nsentences": "1728.47", "wps": "91679.7", "ups": "0.35", "wpb": "263102", "bsz": "1728.5", "num_updates": "151400", "lr": "0.000337772", "gnorm": "0.282", "loss_scale": "1", "train_wall": "254", "gb_free": "39.3", "wall": "285478"}
[2024-10-08 01:31:55,803][train_inner][INFO] - {"epoch": 317, "update": 316.624, "loss": "0.812", "ntokens": "263713", "nsentences": "1792.93", "wps": "229339", "ups": "0.87", "wpb": "263713", "bsz": "1792.9", "num_updates": "151600", "lr": "0.0003375", "gnorm": "0.256", "loss_scale": "1", "train_wall": "224", "gb_free": "39.3", "wall": "285708"}
[2024-10-08 01:35:52,144][fairseq_cli.train][INFO] - end of epoch 317 (average epoch stats below)
[2024-10-08 01:35:52,170][train][INFO] - {"epoch": 317, "train_loss": "0.81", "train_ntokens": "263406", "train_nsentences": "1753.71", "train_wps": "137213", "train_ups": "0.52", "train_wpb": "263406", "train_bsz": "1753.7", "train_num_updates": "151780", "train_lr": "0.000337255", "train_gnorm": "0.277", "train_loss_scale": "1", "train_train_wall": "592", "train_gb_free": "39.6", "train_wall": "285944"}
[2024-10-08 01:35:52,278][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:35:52,308][fairseq.trainer][INFO] - begin training epoch 318
[2024-10-08 01:35:52,309][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:42:01,568][train_inner][INFO] - {"epoch": 318, "update": 317.042, "loss": "0.809", "ntokens": "262790", "nsentences": "1723.73", "wps": "86764.5", "ups": "0.33", "wpb": "262790", "bsz": "1723.7", "num_updates": "151800", "lr": "0.000337228", "gnorm": "0.282", "loss_scale": "1", "train_wall": "279", "gb_free": "40", "wall": "286314"}
[2024-10-08 01:45:34,199][train_inner][INFO] - {"epoch": 318, "update": 317.459, "loss": "0.809", "ntokens": "264127", "nsentences": "1737.03", "wps": "248454", "ups": "0.94", "wpb": "264127", "bsz": "1737", "num_updates": "152000", "lr": "0.000336957", "gnorm": "0.259", "loss_scale": "1", "train_wall": "207", "gb_free": "39.6", "wall": "286526"}
[2024-10-08 01:49:31,891][train_inner][INFO] - {"epoch": 318, "update": 317.877, "loss": "0.813", "ntokens": "263909", "nsentences": "1795.17", "wps": "222088", "ups": "0.84", "wpb": "263909", "bsz": "1795.2", "num_updates": "152200", "lr": "0.000336685", "gnorm": "0.268", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "286764"}
[2024-10-08 01:50:45,523][fairseq_cli.train][INFO] - end of epoch 318 (average epoch stats below)
[2024-10-08 01:50:45,553][train][INFO] - {"epoch": 318, "train_loss": "0.81", "train_ntokens": "263577", "train_nsentences": "1753.71", "train_wps": "141321", "train_ups": "0.54", "train_wpb": "263577", "train_bsz": "1753.7", "train_num_updates": "152259", "train_lr": "0.000336605", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "559", "train_gb_free": "40", "train_wall": "286838"}
[2024-10-08 01:50:45,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 01:50:45,752][fairseq.trainer][INFO] - begin training epoch 319
[2024-10-08 01:50:45,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 01:58:49,405][train_inner][INFO] - {"epoch": 319, "update": 318.294, "loss": "0.808", "ntokens": "262959", "nsentences": "1733.45", "wps": "94335.1", "ups": "0.36", "wpb": "262959", "bsz": "1733.5", "num_updates": "152400", "lr": "0.000336413", "gnorm": "0.271", "loss_scale": "2", "train_wall": "234", "gb_free": "39.7", "wall": "287322"}
[2024-10-08 02:02:41,042][train_inner][INFO] - {"epoch": 319, "update": 318.712, "loss": "0.809", "ntokens": "263926", "nsentences": "1754.33", "wps": "227899", "ups": "0.86", "wpb": "263926", "bsz": "1754.3", "num_updates": "152600", "lr": "0.000336141", "gnorm": "0.262", "loss_scale": "2", "train_wall": "225", "gb_free": "40.5", "wall": "287553"}
[2024-10-08 02:05:56,424][fairseq_cli.train][INFO] - end of epoch 319 (average epoch stats below)
[2024-10-08 02:05:56,448][train][INFO] - {"epoch": 319, "train_loss": "0.81", "train_ntokens": "263429", "train_nsentences": "1753.71", "train_wps": "138527", "train_ups": "0.53", "train_wpb": "263429", "train_bsz": "1753.7", "train_num_updates": "152738", "train_lr": "0.000335954", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "578", "train_gb_free": "39.3", "train_wall": "287749"}
[2024-10-08 02:05:56,539][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:05:56,565][fairseq.trainer][INFO] - begin training epoch 320
[2024-10-08 02:05:56,566][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:12:56,448][train_inner][INFO] - {"epoch": 320, "update": 319.129, "loss": "0.809", "ntokens": "262891", "nsentences": "1736.05", "wps": "85438.6", "ups": "0.32", "wpb": "262891", "bsz": "1736", "num_updates": "152800", "lr": "0.00033587", "gnorm": "0.276", "loss_scale": "2", "train_wall": "283", "gb_free": "39.7", "wall": "288169"}
[2024-10-08 02:16:22,534][train_inner][INFO] - {"epoch": 320, "update": 319.547, "loss": "0.809", "ntokens": "264377", "nsentences": "1736.17", "wps": "256586", "ups": "0.97", "wpb": "264377", "bsz": "1736.2", "num_updates": "153000", "lr": "0.000335598", "gnorm": "0.245", "loss_scale": "2", "train_wall": "200", "gb_free": "39.6", "wall": "288375"}
[2024-10-08 02:20:02,309][train_inner][INFO] - {"epoch": 320, "update": 319.965, "loss": "0.811", "ntokens": "263871", "nsentences": "1776.64", "wps": "240147", "ups": "0.91", "wpb": "263871", "bsz": "1776.6", "num_updates": "153200", "lr": "0.000335326", "gnorm": "0.264", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "288594"}
[2024-10-08 02:20:50,515][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 320 @ 153217 updates
[2024-10-08 02:20:50,516][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 02:20:57,156][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 02:20:57,277][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 320 @ 153217 updates, score None) (writing took 6.762253436259925 seconds)
[2024-10-08 02:20:57,278][fairseq_cli.train][INFO] - end of epoch 320 (average epoch stats below)
[2024-10-08 02:20:57,280][train][INFO] - {"epoch": 320, "train_loss": "0.809", "train_ntokens": "263630", "train_nsentences": "1753.71", "train_wps": "140181", "train_ups": "0.53", "train_wpb": "263630", "train_bsz": "1753.7", "train_num_updates": "153217", "train_lr": "0.000335303", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "554", "train_gb_free": "39.6", "train_wall": "288649"}
[2024-10-08 02:20:57,353][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:20:57,379][fairseq.trainer][INFO] - begin training epoch 321
[2024-10-08 02:20:57,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:29:34,204][train_inner][INFO] - {"epoch": 321, "update": 320.382, "loss": "0.808", "ntokens": "262245", "nsentences": "1806.49", "wps": "91712.4", "ups": "0.35", "wpb": "262245", "bsz": "1806.5", "num_updates": "153400", "lr": "0.000335054", "gnorm": "0.271", "loss_scale": "2", "train_wall": "234", "gb_free": "40", "wall": "289166"}
[2024-10-08 02:33:25,359][train_inner][INFO] - {"epoch": 321, "update": 320.8, "loss": "0.81", "ntokens": "264344", "nsentences": "1727.13", "wps": "228742", "ups": "0.87", "wpb": "264344", "bsz": "1727.1", "num_updates": "153600", "lr": "0.000334783", "gnorm": "0.26", "loss_scale": "2", "train_wall": "168", "gb_free": "39.6", "wall": "289398"}
[2024-10-08 02:35:25,531][fairseq_cli.train][INFO] - end of epoch 321 (average epoch stats below)
[2024-10-08 02:35:25,539][train][INFO] - {"epoch": 321, "train_loss": "0.809", "train_ntokens": "263523", "train_nsentences": "1753.71", "train_wps": "145381", "train_ups": "0.55", "train_wpb": "263523", "train_bsz": "1753.7", "train_num_updates": "153696", "train_lr": "0.000334652", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "448", "train_gb_free": "39.2", "train_wall": "289518"}
[2024-10-08 02:35:25,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:35:25,619][fairseq.trainer][INFO] - begin training epoch 322
[2024-10-08 02:35:25,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:42:55,845][train_inner][INFO] - {"epoch": 322, "update": 321.217, "loss": "0.809", "ntokens": "262682", "nsentences": "1756.98", "wps": "92094.2", "ups": "0.35", "wpb": "262682", "bsz": "1757", "num_updates": "153800", "lr": "0.000334511", "gnorm": "0.278", "loss_scale": "2", "train_wall": "221", "gb_free": "39.4", "wall": "289968"}
[2024-10-08 02:46:43,198][train_inner][INFO] - {"epoch": 322, "update": 321.635, "loss": "0.81", "ntokens": "263691", "nsentences": "1785.77", "wps": "231989", "ups": "0.88", "wpb": "263691", "bsz": "1785.8", "num_updates": "154000", "lr": "0.000334239", "gnorm": "0.265", "loss_scale": "2", "train_wall": "222", "gb_free": "39.8", "wall": "290195"}
[2024-10-08 02:50:39,966][fairseq_cli.train][INFO] - end of epoch 322 (average epoch stats below)
[2024-10-08 02:50:39,974][train][INFO] - {"epoch": 322, "train_loss": "0.809", "train_ntokens": "263492", "train_nsentences": "1753.71", "train_wps": "138024", "train_ups": "0.52", "train_wpb": "263492", "train_bsz": "1753.7", "train_num_updates": "154175", "train_lr": "0.000334001", "train_gnorm": "0.27", "train_loss_scale": "4", "train_train_wall": "584", "train_gb_free": "39.2", "train_wall": "290432"}
[2024-10-08 02:50:40,026][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 02:50:40,044][fairseq.trainer][INFO] - begin training epoch 323
[2024-10-08 02:50:40,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 02:56:50,853][train_inner][INFO] - {"epoch": 323, "update": 322.052, "loss": "0.81", "ntokens": "263289", "nsentences": "1706.8", "wps": "86660.1", "ups": "0.33", "wpb": "263289", "bsz": "1706.8", "num_updates": "154200", "lr": "0.000333967", "gnorm": "0.263", "loss_scale": "4", "train_wall": "278", "gb_free": "39.6", "wall": "290803"}
[2024-10-08 03:00:24,729][train_inner][INFO] - {"epoch": 323, "update": 322.47, "loss": "0.806", "ntokens": "263925", "nsentences": "1771.29", "wps": "246816", "ups": "0.94", "wpb": "263925", "bsz": "1771.3", "num_updates": "154400", "lr": "0.000333696", "gnorm": "0.253", "loss_scale": "4", "train_wall": "208", "gb_free": "39.6", "wall": "291017"}
[2024-10-08 03:04:24,984][train_inner][INFO] - {"epoch": 323, "update": 322.887, "loss": "0.811", "ntokens": "264250", "nsentences": "1740.51", "wps": "219999", "ups": "0.83", "wpb": "264250", "bsz": "1740.5", "num_updates": "154600", "lr": "0.000333424", "gnorm": "0.261", "loss_scale": "4", "train_wall": "234", "gb_free": "39.6", "wall": "291257"}
[2024-10-08 03:05:34,097][fairseq_cli.train][INFO] - end of epoch 323 (average epoch stats below)
[2024-10-08 03:05:34,113][train][INFO] - {"epoch": 323, "train_loss": "0.809", "train_ntokens": "263584", "train_nsentences": "1753.71", "train_wps": "141208", "train_ups": "0.54", "train_wpb": "263584", "train_bsz": "1753.7", "train_num_updates": "154654", "train_lr": "0.000333351", "train_gnorm": "0.26", "train_loss_scale": "4", "train_train_wall": "556", "train_gb_free": "39.7", "train_wall": "291326"}
[2024-10-08 03:05:34,177][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:05:34,209][fairseq.trainer][INFO] - begin training epoch 324
[2024-10-08 03:05:34,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:13:44,864][train_inner][INFO] - {"epoch": 324, "update": 323.305, "loss": "0.807", "ntokens": "262958", "nsentences": "1733.96", "wps": "93935.2", "ups": "0.36", "wpb": "262958", "bsz": "1734", "num_updates": "154800", "lr": "0.000333152", "gnorm": "0.262", "loss_scale": "4", "train_wall": "213", "gb_free": "40.2", "wall": "291817"}
[2024-10-08 03:17:37,878][train_inner][INFO] - {"epoch": 324, "update": 323.722, "loss": "0.811", "ntokens": "263801", "nsentences": "1795.94", "wps": "226440", "ups": "0.86", "wpb": "263801", "bsz": "1795.9", "num_updates": "155000", "lr": "0.00033288", "gnorm": "0.267", "loss_scale": "4", "train_wall": "225", "gb_free": "39.3", "wall": "292050"}
[2024-10-08 03:20:33,036][fairseq_cli.train][INFO] - end of epoch 324 (average epoch stats below)
[2024-10-08 03:20:33,049][train][INFO] - {"epoch": 324, "train_loss": "0.809", "train_ntokens": "263543", "train_nsentences": "1753.71", "train_wps": "140430", "train_ups": "0.53", "train_wpb": "263543", "train_bsz": "1753.7", "train_num_updates": "155133", "train_lr": "0.0003327", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "542", "train_gb_free": "39.3", "train_wall": "292225"}
[2024-10-08 03:20:33,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:20:33,095][fairseq.trainer][INFO] - begin training epoch 325
[2024-10-08 03:20:33,095][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:26:19,169][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 03:27:19,711][train_inner][INFO] - {"epoch": 325, "update": 324.142, "loss": "0.809", "ntokens": "263032", "nsentences": "1735.14", "wps": "90417.3", "ups": "0.34", "wpb": "263032", "bsz": "1735.1", "num_updates": "155200", "lr": "0.000332609", "gnorm": "0.255", "loss_scale": "2", "train_wall": "244", "gb_free": "39.3", "wall": "292632"}
[2024-10-08 03:30:57,222][train_inner][INFO] - {"epoch": 325, "update": 324.559, "loss": "0.808", "ntokens": "263866", "nsentences": "1777.6", "wps": "242633", "ups": "0.92", "wpb": "263866", "bsz": "1777.6", "num_updates": "155400", "lr": "0.000332337", "gnorm": "0.262", "loss_scale": "2", "train_wall": "202", "gb_free": "39.6", "wall": "292849"}
[2024-10-08 03:34:21,452][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 03:34:31,841][train_inner][INFO] - {"epoch": 325, "update": 324.979, "loss": "0.808", "ntokens": "264250", "nsentences": "1724.64", "wps": "246335", "ups": "0.93", "wpb": "264250", "bsz": "1724.6", "num_updates": "155600", "lr": "0.000332065", "gnorm": "0.256", "loss_scale": "1", "train_wall": "209", "gb_free": "39.3", "wall": "293064"}
[2024-10-08 03:35:13,600][fairseq_cli.train][INFO] - end of epoch 325 (average epoch stats below)
[2024-10-08 03:35:13,615][train][INFO] - {"epoch": 325, "train_loss": "0.809", "train_ntokens": "263571", "train_nsentences": "1751.97", "train_wps": "142776", "train_ups": "0.54", "train_wpb": "263571", "train_bsz": "1752", "train_num_updates": "155610", "train_lr": "0.000332052", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "524", "train_gb_free": "39.3", "train_wall": "293106"}
[2024-10-08 03:35:13,660][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:35:13,675][fairseq.trainer][INFO] - begin training epoch 326
[2024-10-08 03:35:13,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:44:12,914][train_inner][INFO] - {"epoch": 326, "update": 325.397, "loss": "0.809", "ntokens": "262562", "nsentences": "1784.8", "wps": "90376.7", "ups": "0.34", "wpb": "262562", "bsz": "1784.8", "num_updates": "155800", "lr": "0.000331793", "gnorm": "0.276", "loss_scale": "1", "train_wall": "259", "gb_free": "40", "wall": "293645"}
[2024-10-08 03:48:15,265][train_inner][INFO] - {"epoch": 326, "update": 325.814, "loss": "0.808", "ntokens": "264343", "nsentences": "1734.33", "wps": "218163", "ups": "0.83", "wpb": "264343", "bsz": "1734.3", "num_updates": "156000", "lr": "0.000331522", "gnorm": "0.271", "loss_scale": "1", "train_wall": "237", "gb_free": "39.3", "wall": "293887"}
[2024-10-08 03:49:57,026][fairseq_cli.train][INFO] - end of epoch 326 (average epoch stats below)
[2024-10-08 03:49:57,056][train][INFO] - {"epoch": 326, "train_loss": "0.808", "train_ntokens": "263575", "train_nsentences": "1753.71", "train_wps": "142911", "train_ups": "0.54", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "156089", "train_lr": "0.000331401", "train_gnorm": "0.276", "train_loss_scale": "1", "train_train_wall": "552", "train_gb_free": "40", "train_wall": "293989"}
[2024-10-08 03:49:57,148][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 03:49:57,156][fairseq.trainer][INFO] - begin training epoch 327
[2024-10-08 03:49:57,156][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 03:57:37,469][train_inner][INFO] - {"epoch": 327, "update": 326.232, "loss": "0.806", "ntokens": "262621", "nsentences": "1768.59", "wps": "93431.4", "ups": "0.36", "wpb": "262621", "bsz": "1768.6", "num_updates": "156200", "lr": "0.00033125", "gnorm": "0.291", "loss_scale": "1", "train_wall": "238", "gb_free": "39.7", "wall": "294450"}
[2024-10-08 04:01:16,408][train_inner][INFO] - {"epoch": 327, "update": 326.649, "loss": "0.808", "ntokens": "264394", "nsentences": "1707.05", "wps": "241536", "ups": "0.91", "wpb": "264394", "bsz": "1707", "num_updates": "156400", "lr": "0.000330978", "gnorm": "0.267", "loss_scale": "1", "train_wall": "214", "gb_free": "39.7", "wall": "294669"}
[2024-10-08 04:04:30,542][fairseq_cli.train][INFO] - end of epoch 327 (average epoch stats below)
[2024-10-08 04:04:30,571][train][INFO] - {"epoch": 327, "train_loss": "0.808", "train_ntokens": "263484", "train_nsentences": "1753.71", "train_wps": "144487", "train_ups": "0.55", "train_wpb": "263484", "train_bsz": "1753.7", "train_num_updates": "156568", "train_lr": "0.00033075", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "544", "train_gb_free": "39.7", "train_wall": "294863"}
[2024-10-08 04:04:30,789][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:04:30,811][fairseq.trainer][INFO] - begin training epoch 328
[2024-10-08 04:04:30,812][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:10:41,643][train_inner][INFO] - {"epoch": 328, "update": 327.067, "loss": "0.81", "ntokens": "262604", "nsentences": "1767.99", "wps": "92923.5", "ups": "0.35", "wpb": "262604", "bsz": "1768", "num_updates": "156600", "lr": "0.000330707", "gnorm": "0.264", "loss_scale": "1", "train_wall": "221", "gb_free": "39.6", "wall": "295234"}
[2024-10-08 04:14:12,936][train_inner][INFO] - {"epoch": 328, "update": 327.484, "loss": "0.808", "ntokens": "263476", "nsentences": "1809.27", "wps": "249410", "ups": "0.95", "wpb": "263476", "bsz": "1809.3", "num_updates": "156800", "lr": "0.000330435", "gnorm": "0.27", "loss_scale": "1", "train_wall": "176", "gb_free": "39.6", "wall": "295445"}
[2024-10-08 04:18:21,581][train_inner][INFO] - {"epoch": 328, "update": 327.902, "loss": "0.808", "ntokens": "264401", "nsentences": "1695.42", "wps": "212690", "ups": "0.8", "wpb": "264401", "bsz": "1695.4", "num_updates": "157000", "lr": "0.000330163", "gnorm": "0.264", "loss_scale": "1", "train_wall": "244", "gb_free": "41", "wall": "295694"}
[2024-10-08 04:19:41,897][fairseq_cli.train][INFO] - end of epoch 328 (average epoch stats below)
[2024-10-08 04:19:41,920][train][INFO] - {"epoch": 328, "train_loss": "0.808", "train_ntokens": "263420", "train_nsentences": "1753.71", "train_wps": "138453", "train_ups": "0.53", "train_wpb": "263420", "train_bsz": "1753.7", "train_num_updates": "157047", "train_lr": "0.000330099", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "531", "train_gb_free": "40.7", "train_wall": "295774"}
[2024-10-08 04:19:42,004][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:19:42,028][fairseq.trainer][INFO] - begin training epoch 329
[2024-10-08 04:19:42,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:27:59,614][train_inner][INFO] - {"epoch": 329, "update": 328.319, "loss": "0.807", "ntokens": "262852", "nsentences": "1752.24", "wps": "90952.5", "ups": "0.35", "wpb": "262852", "bsz": "1752.2", "num_updates": "157200", "lr": "0.000329891", "gnorm": "0.262", "loss_scale": "1", "train_wall": "261", "gb_free": "40", "wall": "296272"}
[2024-10-08 04:31:56,602][train_inner][INFO] - {"epoch": 329, "update": 328.737, "loss": "0.81", "ntokens": "263423", "nsentences": "1791.1", "wps": "222335", "ups": "0.84", "wpb": "263423", "bsz": "1791.1", "num_updates": "157400", "lr": "0.00032962", "gnorm": "0.291", "loss_scale": "1", "train_wall": "231", "gb_free": "39.6", "wall": "296509"}
[2024-10-08 04:33:17,949][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-08 04:34:38,758][fairseq_cli.train][INFO] - end of epoch 329 (average epoch stats below)
[2024-10-08 04:34:38,785][train][INFO] - {"epoch": 329, "train_loss": "0.808", "train_ntokens": "263436", "train_nsentences": "1753.99", "train_wps": "140404", "train_ups": "0.53", "train_wpb": "263436", "train_bsz": "1754", "train_num_updates": "157525", "train_lr": "0.00032945", "train_gnorm": "0.276", "train_loss_scale": "0.5", "train_train_wall": "571", "train_gb_free": "39.7", "train_wall": "296671"}
[2024-10-08 04:34:38,899][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:34:38,930][fairseq.trainer][INFO] - begin training epoch 330
[2024-10-08 04:34:38,931][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:41:26,720][train_inner][INFO] - {"epoch": 330, "update": 329.157, "loss": "0.806", "ntokens": "263162", "nsentences": "1714.34", "wps": "92322.5", "ups": "0.35", "wpb": "263162", "bsz": "1714.3", "num_updates": "157600", "lr": "0.000329348", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "256", "gb_free": "39.6", "wall": "297079"}
[2024-10-08 04:45:17,827][train_inner][INFO] - {"epoch": 330, "update": 329.574, "loss": "0.807", "ntokens": "263785", "nsentences": "1779.37", "wps": "228288", "ups": "0.87", "wpb": "263785", "bsz": "1779.4", "num_updates": "157800", "lr": "0.000329076", "gnorm": "0.269", "loss_scale": "0.5", "train_wall": "225", "gb_free": "40.5", "wall": "297310"}
[2024-10-08 04:49:27,394][train_inner][INFO] - {"epoch": 330, "update": 329.992, "loss": "0.809", "ntokens": "264039", "nsentences": "1739.89", "wps": "211623", "ups": "0.8", "wpb": "264039", "bsz": "1739.9", "num_updates": "158000", "lr": "0.000328804", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "245", "gb_free": "39.7", "wall": "297560"}
[2024-10-08 04:49:36,369][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 330 @ 158004 updates
[2024-10-08 04:49:36,370][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 04:49:42,013][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 04:49:42,190][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 330 @ 158004 updates, score None) (writing took 5.820926337502897 seconds)
[2024-10-08 04:49:42,206][fairseq_cli.train][INFO] - end of epoch 330 (average epoch stats below)
[2024-10-08 04:49:42,208][train][INFO] - {"epoch": 330, "train_loss": "0.807", "train_ntokens": "263435", "train_nsentences": "1753.71", "train_wps": "139678", "train_ups": "0.53", "train_wpb": "263435", "train_bsz": "1753.7", "train_num_updates": "158004", "train_lr": "0.000328799", "train_gnorm": "0.271", "train_loss_scale": "0.5", "train_train_wall": "576", "train_gb_free": "39.3", "train_wall": "297574"}
[2024-10-08 04:49:42,257][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 04:49:42,282][fairseq.trainer][INFO] - begin training epoch 331
[2024-10-08 04:49:42,283][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 04:58:42,708][train_inner][INFO] - {"epoch": 331, "update": 330.409, "loss": "0.803", "ntokens": "263014", "nsentences": "1725.33", "wps": "94729.8", "ups": "0.36", "wpb": "263014", "bsz": "1725.3", "num_updates": "158200", "lr": "0.000328533", "gnorm": "0.292", "loss_scale": "0.5", "train_wall": "148", "gb_free": "39.8", "wall": "298115"}
[2024-10-08 05:02:26,562][train_inner][INFO] - {"epoch": 331, "update": 330.827, "loss": "0.808", "ntokens": "263874", "nsentences": "1756.4", "wps": "235771", "ups": "0.89", "wpb": "263874", "bsz": "1756.4", "num_updates": "158400", "lr": "0.000328261", "gnorm": "0.264", "loss_scale": "0.5", "train_wall": "162", "gb_free": "39.6", "wall": "298339"}
[2024-10-08 05:04:26,940][fairseq_cli.train][INFO] - end of epoch 331 (average epoch stats below)
[2024-10-08 05:04:26,945][train][INFO] - {"epoch": 331, "train_loss": "0.807", "train_ntokens": "263389", "train_nsentences": "1753.71", "train_wps": "142601", "train_ups": "0.54", "train_wpb": "263389", "train_bsz": "1753.7", "train_num_updates": "158483", "train_lr": "0.000328148", "train_gnorm": "0.28", "train_loss_scale": "0.5", "train_train_wall": "411", "train_gb_free": "39.3", "train_wall": "298459"}
[2024-10-08 05:04:27,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:04:27,096][fairseq.trainer][INFO] - begin training epoch 332
[2024-10-08 05:04:27,096][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:12:18,874][train_inner][INFO] - {"epoch": 332, "update": 331.244, "loss": "0.808", "ntokens": "262624", "nsentences": "1751.93", "wps": "88680.6", "ups": "0.34", "wpb": "262624", "bsz": "1751.9", "num_updates": "158600", "lr": "0.000327989", "gnorm": "0.288", "loss_scale": "0.5", "train_wall": "271", "gb_free": "40", "wall": "298931"}
[2024-10-08 05:15:50,812][train_inner][INFO] - {"epoch": 332, "update": 331.662, "loss": "0.808", "ntokens": "263690", "nsentences": "1786.63", "wps": "248854", "ups": "0.94", "wpb": "263690", "bsz": "1786.6", "num_updates": "158800", "lr": "0.000327717", "gnorm": "0.266", "loss_scale": "0.5", "train_wall": "206", "gb_free": "40.1", "wall": "299143"}
[2024-10-08 05:19:27,208][fairseq_cli.train][INFO] - end of epoch 332 (average epoch stats below)
[2024-10-08 05:19:27,225][train][INFO] - {"epoch": 332, "train_loss": "0.807", "train_ntokens": "263418", "train_nsentences": "1753.71", "train_wps": "140154", "train_ups": "0.53", "train_wpb": "263418", "train_bsz": "1753.7", "train_num_updates": "158962", "train_lr": "0.000327497", "train_gnorm": "0.275", "train_loss_scale": "0.5", "train_train_wall": "580", "train_gb_free": "39.3", "train_wall": "299359"}
[2024-10-08 05:19:27,270][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:19:27,278][fairseq.trainer][INFO] - begin training epoch 333
[2024-10-08 05:19:27,278][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:25:41,320][train_inner][INFO] - {"epoch": 333, "update": 332.079, "loss": "0.809", "ntokens": "262645", "nsentences": "1764.48", "wps": "88959", "ups": "0.34", "wpb": "262645", "bsz": "1764.5", "num_updates": "159000", "lr": "0.000327446", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "251", "gb_free": "39.3", "wall": "299733"}
[2024-10-08 05:29:12,191][train_inner][INFO] - {"epoch": 333, "update": 332.497, "loss": "0.807", "ntokens": "264342", "nsentences": "1761.66", "wps": "250730", "ups": "0.95", "wpb": "264342", "bsz": "1761.7", "num_updates": "159200", "lr": "0.000327174", "gnorm": "0.265", "loss_scale": "0.5", "train_wall": "169", "gb_free": "39.6", "wall": "299944"}
[2024-10-08 05:33:13,083][train_inner][INFO] - {"epoch": 333, "update": 332.914, "loss": "0.807", "ntokens": "264252", "nsentences": "1711.8", "wps": "219401", "ups": "0.83", "wpb": "264252", "bsz": "1711.8", "num_updates": "159400", "lr": "0.000326902", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "204", "gb_free": "39.6", "wall": "300185"}
[2024-10-08 05:34:12,609][fairseq_cli.train][INFO] - end of epoch 333 (average epoch stats below)
[2024-10-08 05:34:12,633][train][INFO] - {"epoch": 333, "train_loss": "0.808", "train_ntokens": "263605", "train_nsentences": "1753.71", "train_wps": "142611", "train_ups": "0.54", "train_wpb": "263605", "train_bsz": "1753.7", "train_num_updates": "159441", "train_lr": "0.000326846", "train_gnorm": "0.266", "train_loss_scale": "0.5", "train_train_wall": "470", "train_gb_free": "39.8", "train_wall": "300245"}
[2024-10-08 05:34:12,713][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:34:12,730][fairseq.trainer][INFO] - begin training epoch 334
[2024-10-08 05:34:12,731][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:42:53,827][train_inner][INFO] - {"epoch": 334, "update": 333.332, "loss": "0.806", "ntokens": "262531", "nsentences": "1777.33", "wps": "90413.7", "ups": "0.34", "wpb": "262531", "bsz": "1777.3", "num_updates": "159600", "lr": "0.00032663", "gnorm": "0.271", "loss_scale": "1", "train_wall": "257", "gb_free": "39.7", "wall": "300766"}
[2024-10-08 05:46:35,436][train_inner][INFO] - {"epoch": 334, "update": 333.749, "loss": "0.808", "ntokens": "263754", "nsentences": "1758.48", "wps": "238048", "ups": "0.9", "wpb": "263754", "bsz": "1758.5", "num_updates": "159800", "lr": "0.000326359", "gnorm": "0.263", "loss_scale": "1", "train_wall": "216", "gb_free": "39.6", "wall": "300988"}
[2024-10-08 05:49:02,940][fairseq_cli.train][INFO] - end of epoch 334 (average epoch stats below)
[2024-10-08 05:49:02,950][train][INFO] - {"epoch": 334, "train_loss": "0.807", "train_ntokens": "263468", "train_nsentences": "1753.71", "train_wps": "141750", "train_ups": "0.54", "train_wpb": "263468", "train_bsz": "1753.7", "train_num_updates": "159920", "train_lr": "0.000326196", "train_gnorm": "0.263", "train_loss_scale": "1", "train_train_wall": "557", "train_gb_free": "40", "train_wall": "301135"}
[2024-10-08 05:49:03,030][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 05:49:03,080][fairseq.trainer][INFO] - begin training epoch 335
[2024-10-08 05:49:03,081][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 05:56:19,887][train_inner][INFO] - {"epoch": 335, "update": 334.167, "loss": "0.805", "ntokens": "263268", "nsentences": "1701.93", "wps": "90094.3", "ups": "0.34", "wpb": "263268", "bsz": "1701.9", "num_updates": "160000", "lr": "0.000326087", "gnorm": "0.264", "loss_scale": "1", "train_wall": "235", "gb_free": "39.3", "wall": "301572"}
[2024-10-08 05:59:40,688][train_inner][INFO] - {"epoch": 335, "update": 334.585, "loss": "0.807", "ntokens": "263941", "nsentences": "1781.74", "wps": "262924", "ups": "1", "wpb": "263941", "bsz": "1781.7", "num_updates": "160200", "lr": "0.000325815", "gnorm": "0.27", "loss_scale": "1", "train_wall": "196", "gb_free": "39.2", "wall": "301773"}
[2024-10-08 06:03:56,999][fairseq_cli.train][INFO] - end of epoch 335 (average epoch stats below)
[2024-10-08 06:03:57,032][train][INFO] - {"epoch": 335, "train_loss": "0.807", "train_ntokens": "263656", "train_nsentences": "1753.71", "train_wps": "141254", "train_ups": "0.54", "train_wpb": "263656", "train_bsz": "1753.7", "train_num_updates": "160399", "train_lr": "0.000325545", "train_gnorm": "0.278", "train_loss_scale": "1", "train_train_wall": "540", "train_gb_free": "39.6", "train_wall": "302029"}
[2024-10-08 06:03:57,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:03:57,136][fairseq.trainer][INFO] - begin training epoch 336
[2024-10-08 06:03:57,137][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:09:35,611][train_inner][INFO] - {"epoch": 336, "update": 335.002, "loss": "0.81", "ntokens": "263042", "nsentences": "1755.26", "wps": "88432.6", "ups": "0.34", "wpb": "263042", "bsz": "1755.3", "num_updates": "160400", "lr": "0.000325543", "gnorm": "0.282", "loss_scale": "1", "train_wall": "265", "gb_free": "39.3", "wall": "302368"}
[2024-10-08 06:13:01,998][train_inner][INFO] - {"epoch": 336, "update": 335.42, "loss": "0.805", "ntokens": "263795", "nsentences": "1770.31", "wps": "255644", "ups": "0.97", "wpb": "263795", "bsz": "1770.3", "num_updates": "160600", "lr": "0.000325272", "gnorm": "0.269", "loss_scale": "1", "train_wall": "196", "gb_free": "39.3", "wall": "302574"}
[2024-10-08 06:16:50,788][train_inner][INFO] - {"epoch": 336, "update": 335.837, "loss": "0.808", "ntokens": "264187", "nsentences": "1744.69", "wps": "230984", "ups": "0.87", "wpb": "264187", "bsz": "1744.7", "num_updates": "160800", "lr": "0.000325", "gnorm": "0.251", "loss_scale": "1", "train_wall": "210", "gb_free": "40.1", "wall": "302803"}
[2024-10-08 06:18:30,683][fairseq_cli.train][INFO] - end of epoch 336 (average epoch stats below)
[2024-10-08 06:18:30,703][train][INFO] - {"epoch": 336, "train_loss": "0.807", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "144467", "train_ups": "0.55", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "160878", "train_lr": "0.000324894", "train_gnorm": "0.262", "train_loss_scale": "1", "train_train_wall": "509", "train_gb_free": "40.1", "train_wall": "302903"}
[2024-10-08 06:18:30,775][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:18:30,795][fairseq.trainer][INFO] - begin training epoch 337
[2024-10-08 06:18:30,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:26:36,629][train_inner][INFO] - {"epoch": 337, "update": 336.255, "loss": "0.806", "ntokens": "262524", "nsentences": "1763.47", "wps": "89626.9", "ups": "0.34", "wpb": "262524", "bsz": "1763.5", "num_updates": "161000", "lr": "0.000324728", "gnorm": "0.275", "loss_scale": "1", "train_wall": "176", "gb_free": "39.2", "wall": "303389"}
[2024-10-08 06:30:18,535][train_inner][INFO] - {"epoch": 337, "update": 336.672, "loss": "0.804", "ntokens": "264143", "nsentences": "1727.79", "wps": "238084", "ups": "0.9", "wpb": "264143", "bsz": "1727.8", "num_updates": "161200", "lr": "0.000324457", "gnorm": "0.27", "loss_scale": "1", "train_wall": "160", "gb_free": "40", "wall": "303611"}
[2024-10-08 06:33:43,530][fairseq_cli.train][INFO] - end of epoch 337 (average epoch stats below)
[2024-10-08 06:33:43,634][train][INFO] - {"epoch": 337, "train_loss": "0.806", "train_ntokens": "263393", "train_nsentences": "1753.71", "train_wps": "138206", "train_ups": "0.52", "train_wpb": "263393", "train_bsz": "1753.7", "train_num_updates": "161357", "train_lr": "0.000324243", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "381", "train_gb_free": "39.6", "train_wall": "303816"}
[2024-10-08 06:33:43,922][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:33:43,960][fairseq.trainer][INFO] - begin training epoch 338
[2024-10-08 06:33:43,960][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:40:11,440][train_inner][INFO] - {"epoch": 338, "update": 337.09, "loss": "0.806", "ntokens": "262891", "nsentences": "1734.9", "wps": "88682.6", "ups": "0.34", "wpb": "262891", "bsz": "1734.9", "num_updates": "161400", "lr": "0.000324185", "gnorm": "0.264", "loss_scale": "1", "train_wall": "194", "gb_free": "39.8", "wall": "304204"}
[2024-10-08 06:43:41,264][train_inner][INFO] - {"epoch": 338, "update": 337.507, "loss": "0.806", "ntokens": "264023", "nsentences": "1739.74", "wps": "251694", "ups": "0.95", "wpb": "264023", "bsz": "1739.7", "num_updates": "161600", "lr": "0.000323913", "gnorm": "0.267", "loss_scale": "2", "train_wall": "204", "gb_free": "40", "wall": "304413"}
[2024-10-08 06:47:41,003][train_inner][INFO] - {"epoch": 338, "update": 337.925, "loss": "0.81", "ntokens": "263670", "nsentences": "1797.81", "wps": "219984", "ups": "0.83", "wpb": "263670", "bsz": "1797.8", "num_updates": "161800", "lr": "0.000323641", "gnorm": "0.27", "loss_scale": "2", "train_wall": "234", "gb_free": "39.8", "wall": "304653"}
[2024-10-08 06:48:10,846][fairseq_cli.train][INFO] - end of epoch 338 (average epoch stats below)
[2024-10-08 06:48:10,871][train][INFO] - {"epoch": 338, "train_loss": "0.807", "train_ntokens": "263486", "train_nsentences": "1753.71", "train_wps": "145543", "train_ups": "0.55", "train_wpb": "263486", "train_bsz": "1753.7", "train_num_updates": "161836", "train_lr": "0.000323592", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "524", "train_gb_free": "41", "train_wall": "304683"}
[2024-10-08 06:48:11,220][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 06:48:11,287][fairseq.trainer][INFO] - begin training epoch 339
[2024-10-08 06:48:11,287][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 06:57:21,013][train_inner][INFO] - {"epoch": 339, "update": 338.342, "loss": "0.805", "ntokens": "262802", "nsentences": "1773.42", "wps": "90620.9", "ups": "0.34", "wpb": "262802", "bsz": "1773.4", "num_updates": "162000", "lr": "0.00032337", "gnorm": "0.265", "loss_scale": "2", "train_wall": "192", "gb_free": "39.3", "wall": "305233"}
[2024-10-08 07:01:14,325][train_inner][INFO] - {"epoch": 339, "update": 338.76, "loss": "0.808", "ntokens": "264112", "nsentences": "1759.91", "wps": "226424", "ups": "0.86", "wpb": "264112", "bsz": "1759.9", "num_updates": "162200", "lr": "0.000323098", "gnorm": "0.279", "loss_scale": "2", "train_wall": "151", "gb_free": "39.8", "wall": "305466"}
[2024-10-08 07:03:33,493][fairseq_cli.train][INFO] - end of epoch 339 (average epoch stats below)
[2024-10-08 07:03:33,509][train][INFO] - {"epoch": 339, "train_loss": "0.806", "train_ntokens": "263599", "train_nsentences": "1753.71", "train_wps": "136852", "train_ups": "0.52", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "162315", "train_lr": "0.000322942", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "409", "train_gb_free": "40.1", "train_wall": "305606"}
[2024-10-08 07:03:33,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:03:33,739][fairseq.trainer][INFO] - begin training epoch 340
[2024-10-08 07:03:33,740][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 07:11:11,020][train_inner][INFO] - {"epoch": 340, "update": 339.177, "loss": "0.805", "ntokens": "262777", "nsentences": "1741.42", "wps": "88079", "ups": "0.34", "wpb": "262777", "bsz": "1741.4", "num_updates": "162400", "lr": "0.000322826", "gnorm": "0.261", "loss_scale": "2", "train_wall": "209", "gb_free": "39.6", "wall": "306063"}
[2024-10-08 07:14:42,955][train_inner][INFO] - {"epoch": 340, "update": 339.595, "loss": "0.805", "ntokens": "263920", "nsentences": "1768.08", "wps": "249091", "ups": "0.94", "wpb": "263920", "bsz": "1768.1", "num_updates": "162600", "lr": "0.000322554", "gnorm": "0.26", "loss_scale": "2", "train_wall": "206", "gb_free": "39.6", "wall": "306275"}
[2024-10-08 07:18:48,884][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 340 @ 162794 updates
[2024-10-08 07:18:48,888][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 07:18:53,633][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 07:18:53,680][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 340 @ 162794 updates, score None) (writing took 4.796529714949429 seconds)
[2024-10-08 07:18:53,681][fairseq_cli.train][INFO] - end of epoch 340 (average epoch stats below)
[2024-10-08 07:18:53,684][train][INFO] - {"epoch": 340, "train_loss": "0.806", "train_ntokens": "263439", "train_nsentences": "1753.71", "train_wps": "137137", "train_ups": "0.52", "train_wpb": "263439", "train_bsz": "1753.7", "train_num_updates": "162794", "train_lr": "0.000322291", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "561", "train_gb_free": "40.2", "train_wall": "306526"}
[2024-10-08 07:18:53,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:18:53,746][fairseq.trainer][INFO] - begin training epoch 341
[2024-10-08 07:18:53,747][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 07:24:39,336][train_inner][INFO] - {"epoch": 341, "update": 340.013, "loss": "0.807", "ntokens": "262924", "nsentences": "1726.04", "wps": "88176.1", "ups": "0.34", "wpb": "262924", "bsz": "1726", "num_updates": "162800", "lr": "0.000322283", "gnorm": "0.273", "loss_scale": "2", "train_wall": "276", "gb_free": "39.6", "wall": "306872"}
[2024-10-08 07:28:14,696][train_inner][INFO] - {"epoch": 341, "update": 340.43, "loss": "0.802", "ntokens": "264419", "nsentences": "1707.33", "wps": "245580", "ups": "0.93", "wpb": "264419", "bsz": "1707.3", "num_updates": "163000", "lr": "0.000322011", "gnorm": "0.247", "loss_scale": "2", "train_wall": "210", "gb_free": "39.6", "wall": "307087"}
[2024-10-08 07:32:52,379][train_inner][INFO] - {"epoch": 341, "update": 340.848, "loss": "0.809", "ntokens": "263711", "nsentences": "1800.54", "wps": "189946", "ups": "0.72", "wpb": "263711", "bsz": "1800.5", "num_updates": "163200", "lr": "0.000321739", "gnorm": "0.273", "loss_scale": "2", "train_wall": "272", "gb_free": "40.8", "wall": "307365"}
[2024-10-08 07:34:36,363][fairseq_cli.train][INFO] - end of epoch 341 (average epoch stats below)
[2024-10-08 07:34:36,379][train][INFO] - {"epoch": 341, "train_loss": "0.806", "train_ntokens": "263580", "train_nsentences": "1753.71", "train_wps": "133930", "train_ups": "0.51", "train_wpb": "263580", "train_bsz": "1753.7", "train_num_updates": "163273", "train_lr": "0.00032164", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "619", "train_gb_free": "40.3", "train_wall": "307469"}
[2024-10-08 07:34:36,570][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:34:36,580][fairseq.trainer][INFO] - begin training epoch 342
[2024-10-08 07:34:36,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 07:42:44,901][train_inner][INFO] - {"epoch": 342, "update": 341.265, "loss": "0.806", "ntokens": "262707", "nsentences": "1760.28", "wps": "88677.7", "ups": "0.34", "wpb": "262707", "bsz": "1760.3", "num_updates": "163400", "lr": "0.000321467", "gnorm": "0.27", "loss_scale": "2", "train_wall": "255", "gb_free": "39.6", "wall": "307957"}
[2024-10-08 07:46:50,751][train_inner][INFO] - {"epoch": 342, "update": 341.683, "loss": "0.804", "ntokens": "263947", "nsentences": "1765.52", "wps": "214732", "ups": "0.81", "wpb": "263947", "bsz": "1765.5", "num_updates": "163600", "lr": "0.000321196", "gnorm": "0.255", "loss_scale": "2", "train_wall": "240", "gb_free": "39.3", "wall": "308203"}
[2024-10-08 07:50:17,300][fairseq_cli.train][INFO] - end of epoch 342 (average epoch stats below)
[2024-10-08 07:50:17,398][train][INFO] - {"epoch": 342, "train_loss": "0.805", "train_ntokens": "263438", "train_nsentences": "1753.71", "train_wps": "134098", "train_ups": "0.51", "train_wpb": "263438", "train_bsz": "1753.7", "train_num_updates": "163752", "train_lr": "0.000320989", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "595", "train_gb_free": "39.2", "train_wall": "308410"}
[2024-10-08 07:50:17,550][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 07:50:17,580][fairseq.trainer][INFO] - begin training epoch 343
[2024-10-08 07:50:17,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 07:56:56,772][train_inner][INFO] - {"epoch": 343, "update": 342.1, "loss": "0.804", "ntokens": "262970", "nsentences": "1724.55", "wps": "86789.1", "ups": "0.33", "wpb": "262970", "bsz": "1724.5", "num_updates": "163800", "lr": "0.000320924", "gnorm": "0.249", "loss_scale": "4", "train_wall": "268", "gb_free": "39.6", "wall": "308809"}
[2024-10-08 07:59:59,896][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 08:01:06,560][train_inner][INFO] - {"epoch": 343, "update": 342.52, "loss": "0.803", "ntokens": "264145", "nsentences": "1738.54", "wps": "211509", "ups": "0.8", "wpb": "264144", "bsz": "1738.5", "num_updates": "164000", "lr": "0.000320652", "gnorm": "0.264", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "309059"}
[2024-10-08 08:05:11,513][train_inner][INFO] - {"epoch": 343, "update": 342.937, "loss": "0.807", "ntokens": "263774", "nsentences": "1790.29", "wps": "215384", "ups": "0.82", "wpb": "263774", "bsz": "1790.3", "num_updates": "164200", "lr": "0.00032038", "gnorm": "0.268", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "309304"}
[2024-10-08 08:05:58,464][fairseq_cli.train][INFO] - end of epoch 343 (average epoch stats below)
[2024-10-08 08:05:58,472][train][INFO] - {"epoch": 343, "train_loss": "0.805", "train_ntokens": "263572", "train_nsentences": "1753.14", "train_wps": "133880", "train_ups": "0.51", "train_wpb": "263572", "train_bsz": "1753.1", "train_num_updates": "164230", "train_lr": "0.00032034", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "595", "train_gb_free": "39.6", "train_wall": "309351"}
[2024-10-08 08:05:58,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 08:05:58,569][fairseq.trainer][INFO] - begin training epoch 344
[2024-10-08 08:05:58,569][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 08:15:10,919][train_inner][INFO] - {"epoch": 344, "update": 343.355, "loss": "0.802", "ntokens": "263102", "nsentences": "1722.98", "wps": "87789.5", "ups": "0.33", "wpb": "263102", "bsz": "1723", "num_updates": "164400", "lr": "0.000320109", "gnorm": "0.291", "loss_scale": "2", "train_wall": "255", "gb_free": "39.3", "wall": "309903"}
[2024-10-08 08:19:36,633][train_inner][INFO] - {"epoch": 344, "update": 343.772, "loss": "0.807", "ntokens": "263591", "nsentences": "1811.01", "wps": "198414", "ups": "0.75", "wpb": "263591", "bsz": "1811", "num_updates": "164600", "lr": "0.000319837", "gnorm": "0.279", "loss_scale": "2", "train_wall": "260", "gb_free": "39.6", "wall": "310169"}
[2024-10-08 08:21:50,863][fairseq_cli.train][INFO] - end of epoch 344 (average epoch stats below)
[2024-10-08 08:21:50,885][train][INFO] - {"epoch": 344, "train_loss": "0.805", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "132562", "train_ups": "0.5", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "164709", "train_lr": "0.000319689", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "599", "train_gb_free": "39.1", "train_wall": "310303"}
[2024-10-08 08:21:50,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 08:21:50,983][fairseq.trainer][INFO] - begin training epoch 345
[2024-10-08 08:21:50,984][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 08:29:04,679][train_inner][INFO] - {"epoch": 345, "update": 344.19, "loss": "0.804", "ntokens": "263456", "nsentences": "1692.7", "wps": "92761.8", "ups": "0.35", "wpb": "263456", "bsz": "1692.7", "num_updates": "164800", "lr": "0.000319565", "gnorm": "0.269", "loss_scale": "2", "train_wall": "237", "gb_free": "40", "wall": "310737"}
[2024-10-08 08:32:47,439][train_inner][INFO] - {"epoch": 345, "update": 344.608, "loss": "0.803", "ntokens": "264207", "nsentences": "1736.14", "wps": "237228", "ups": "0.9", "wpb": "264207", "bsz": "1736.1", "num_updates": "165000", "lr": "0.000319293", "gnorm": "0.273", "loss_scale": "2", "train_wall": "218", "gb_free": "39.6", "wall": "310960"}
[2024-10-08 08:36:40,708][fairseq_cli.train][INFO] - end of epoch 345 (average epoch stats below)
[2024-10-08 08:36:40,719][train][INFO] - {"epoch": 345, "train_loss": "0.805", "train_ntokens": "263579", "train_nsentences": "1753.71", "train_wps": "141887", "train_ups": "0.54", "train_wpb": "263579", "train_bsz": "1753.7", "train_num_updates": "165188", "train_lr": "0.000319038", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "554", "train_gb_free": "39.6", "train_wall": "311193"}
[2024-10-08 08:36:40,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 08:36:40,848][fairseq.trainer][INFO] - begin training epoch 346
[2024-10-08 08:36:40,848][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 08:43:02,504][train_inner][INFO] - {"epoch": 346, "update": 345.025, "loss": "0.81", "ntokens": "262568", "nsentences": "1790.53", "wps": "85381", "ups": "0.33", "wpb": "262568", "bsz": "1790.5", "num_updates": "165200", "lr": "0.000319022", "gnorm": "0.268", "loss_scale": "2", "train_wall": "277", "gb_free": "39.7", "wall": "311575"}
[2024-10-08 08:46:34,261][train_inner][INFO] - {"epoch": 346, "update": 345.443, "loss": "0.804", "ntokens": "264166", "nsentences": "1752.17", "wps": "249529", "ups": "0.94", "wpb": "264166", "bsz": "1752.2", "num_updates": "165400", "lr": "0.00031875", "gnorm": "0.259", "loss_scale": "2", "train_wall": "206", "gb_free": "39.7", "wall": "311786"}
[2024-10-08 08:50:34,812][train_inner][INFO] - {"epoch": 346, "update": 345.86, "loss": "0.805", "ntokens": "263975", "nsentences": "1752.98", "wps": "219488", "ups": "0.83", "wpb": "263974", "bsz": "1753", "num_updates": "165600", "lr": "0.000318478", "gnorm": "0.278", "loss_scale": "2", "train_wall": "235", "gb_free": "40.5", "wall": "312027"}
[2024-10-08 08:52:09,510][fairseq_cli.train][INFO] - end of epoch 346 (average epoch stats below)
[2024-10-08 08:52:09,527][train][INFO] - {"epoch": 346, "train_loss": "0.805", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "135899", "train_ups": "0.52", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "165667", "train_lr": "0.000318387", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "583", "train_gb_free": "39.6", "train_wall": "312122"}
[2024-10-08 08:52:09,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 08:52:09,640][fairseq.trainer][INFO] - begin training epoch 347
[2024-10-08 08:52:09,641][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:00:31,372][train_inner][INFO] - {"epoch": 347, "update": 346.278, "loss": "0.803", "ntokens": "262874", "nsentences": "1753.8", "wps": "88132.8", "ups": "0.34", "wpb": "262874", "bsz": "1753.8", "num_updates": "165800", "lr": "0.000318207", "gnorm": "0.273", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "312624"}
[2024-10-08 09:04:44,070][train_inner][INFO] - {"epoch": 347, "update": 346.695, "loss": "0.804", "ntokens": "263976", "nsentences": "1738.62", "wps": "208937", "ups": "0.79", "wpb": "263976", "bsz": "1738.6", "num_updates": "166000", "lr": "0.000317935", "gnorm": "0.27", "loss_scale": "2", "train_wall": "247", "gb_free": "40", "wall": "312876"}
[2024-10-08 09:07:41,357][fairseq_cli.train][INFO] - end of epoch 347 (average epoch stats below)
[2024-10-08 09:07:41,375][train][INFO] - {"epoch": 347, "train_loss": "0.805", "train_ntokens": "263485", "train_nsentences": "1753.71", "train_wps": "135441", "train_ups": "0.51", "train_wpb": "263485", "train_bsz": "1753.7", "train_num_updates": "166146", "train_lr": "0.000317736", "train_gnorm": "0.278", "train_loss_scale": "4", "train_train_wall": "565", "train_gb_free": "40.3", "train_wall": "313054"}
[2024-10-08 09:07:41,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:07:41,575][fairseq.trainer][INFO] - begin training epoch 348
[2024-10-08 09:07:41,576][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:14:36,003][train_inner][INFO] - {"epoch": 348, "update": 347.113, "loss": "0.807", "ntokens": "262599", "nsentences": "1778.45", "wps": "88733.9", "ups": "0.34", "wpb": "262599", "bsz": "1778.5", "num_updates": "166200", "lr": "0.000317663", "gnorm": "0.28", "loss_scale": "4", "train_wall": "263", "gb_free": "39.7", "wall": "313468"}
[2024-10-08 09:18:13,206][train_inner][INFO] - {"epoch": 348, "update": 347.53, "loss": "0.803", "ntokens": "263976", "nsentences": "1779.91", "wps": "243092", "ups": "0.92", "wpb": "263976", "bsz": "1779.9", "num_updates": "166400", "lr": "0.000317391", "gnorm": "0.269", "loss_scale": "4", "train_wall": "212", "gb_free": "39.7", "wall": "313685"}
[2024-10-08 09:18:56,692][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 09:22:14,625][train_inner][INFO] - {"epoch": 348, "update": 347.95, "loss": "0.804", "ntokens": "264242", "nsentences": "1746.21", "wps": "218916", "ups": "0.83", "wpb": "264242", "bsz": "1746.2", "num_updates": "166600", "lr": "0.00031712", "gnorm": "0.266", "loss_scale": "2", "train_wall": "237", "gb_free": "39.6", "wall": "313927"}
[2024-10-08 09:22:58,189][fairseq_cli.train][INFO] - end of epoch 348 (average epoch stats below)
[2024-10-08 09:22:58,200][train][INFO] - {"epoch": 348, "train_loss": "0.804", "train_ntokens": "263640", "train_nsentences": "1754.98", "train_wps": "137456", "train_ups": "0.52", "train_wpb": "263640", "train_bsz": "1755", "train_num_updates": "166624", "train_lr": "0.000317087", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "582", "train_gb_free": "39.6", "train_wall": "313970"}
[2024-10-08 09:22:58,281][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:22:58,294][fairseq.trainer][INFO] - begin training epoch 349
[2024-10-08 09:22:58,295][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:31:52,964][train_inner][INFO] - {"epoch": 349, "update": 348.367, "loss": "0.802", "ntokens": "262979", "nsentences": "1733.69", "wps": "90944.1", "ups": "0.35", "wpb": "262980", "bsz": "1733.7", "num_updates": "166800", "lr": "0.000316848", "gnorm": "0.268", "loss_scale": "2", "train_wall": "256", "gb_free": "39.3", "wall": "314505"}
[2024-10-08 09:35:59,759][train_inner][INFO] - {"epoch": 349, "update": 348.785, "loss": "0.807", "ntokens": "263600", "nsentences": "1808.39", "wps": "213640", "ups": "0.81", "wpb": "263600", "bsz": "1808.4", "num_updates": "167000", "lr": "0.000316576", "gnorm": "0.252", "loss_scale": "2", "train_wall": "241", "gb_free": "40", "wall": "314752"}
[2024-10-08 09:37:48,437][fairseq_cli.train][INFO] - end of epoch 349 (average epoch stats below)
[2024-10-08 09:37:48,461][train][INFO] - {"epoch": 349, "train_loss": "0.805", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "141783", "train_ups": "0.54", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "167103", "train_lr": "0.000316436", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "559", "train_gb_free": "40", "train_wall": "314861"}
[2024-10-08 09:37:48,564][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:37:48,585][fairseq.trainer][INFO] - begin training epoch 350
[2024-10-08 09:37:48,586][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:45:27,199][train_inner][INFO] - {"epoch": 350, "update": 349.203, "loss": "0.803", "ntokens": "263271", "nsentences": "1693.36", "wps": "92801.2", "ups": "0.35", "wpb": "263271", "bsz": "1693.4", "num_updates": "167200", "lr": "0.000316304", "gnorm": "0.281", "loss_scale": "2", "train_wall": "216", "gb_free": "39.3", "wall": "315319"}
[2024-10-08 09:49:04,345][train_inner][INFO] - {"epoch": 350, "update": 349.62, "loss": "0.804", "ntokens": "263932", "nsentences": "1749.22", "wps": "243111", "ups": "0.92", "wpb": "263932", "bsz": "1749.2", "num_updates": "167400", "lr": "0.000316033", "gnorm": "0.282", "loss_scale": "2", "train_wall": "211", "gb_free": "39.3", "wall": "315537"}
[2024-10-08 09:53:06,435][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 350 @ 167582 updates
[2024-10-08 09:53:06,437][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 09:53:13,153][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 09:53:13,431][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 350 @ 167582 updates, score None) (writing took 6.9955289689823985 seconds)
[2024-10-08 09:53:13,432][fairseq_cli.train][INFO] - end of epoch 350 (average epoch stats below)
[2024-10-08 09:53:13,446][train][INFO] - {"epoch": 350, "train_loss": "0.804", "train_ntokens": "263536", "train_nsentences": "1753.71", "train_wps": "136474", "train_ups": "0.52", "train_wpb": "263536", "train_bsz": "1753.7", "train_num_updates": "167582", "train_lr": "0.000315785", "train_gnorm": "0.281", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.6", "train_wall": "315786"}
[2024-10-08 09:53:13,564][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 09:53:13,598][fairseq.trainer][INFO] - begin training epoch 351
[2024-10-08 09:53:13,599][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 09:59:14,315][train_inner][INFO] - {"epoch": 351, "update": 350.038, "loss": "0.807", "ntokens": "262972", "nsentences": "1761.81", "wps": "86226.9", "ups": "0.33", "wpb": "262972", "bsz": "1761.8", "num_updates": "167600", "lr": "0.000315761", "gnorm": "0.287", "loss_scale": "2", "train_wall": "285", "gb_free": "39.1", "wall": "316146"}
[2024-10-08 10:02:33,157][train_inner][INFO] - {"epoch": 351, "update": 350.455, "loss": "0.799", "ntokens": "264440", "nsentences": "1711.42", "wps": "266000", "ups": "1.01", "wpb": "264440", "bsz": "1711.4", "num_updates": "167800", "lr": "0.000315489", "gnorm": "0.262", "loss_scale": "2", "train_wall": "194", "gb_free": "39.3", "wall": "316345"}
[2024-10-08 10:06:56,168][train_inner][INFO] - {"epoch": 351, "update": 350.873, "loss": "0.807", "ntokens": "263788", "nsentences": "1794.57", "wps": "200600", "ups": "0.76", "wpb": "263788", "bsz": "1794.6", "num_updates": "168000", "lr": "0.000315217", "gnorm": "0.27", "loss_scale": "2", "train_wall": "257", "gb_free": "39.6", "wall": "316608"}
[2024-10-08 10:08:05,823][fairseq_cli.train][INFO] - end of epoch 351 (average epoch stats below)
[2024-10-08 10:08:05,860][train][INFO] - {"epoch": 351, "train_loss": "0.804", "train_ntokens": "263642", "train_nsentences": "1753.71", "train_wps": "141512", "train_ups": "0.54", "train_wpb": "263642", "train_bsz": "1753.7", "train_num_updates": "168061", "train_lr": "0.000315135", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "40", "train_wall": "316678"}
[2024-10-08 10:08:06,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 10:08:06,299][fairseq.trainer][INFO] - begin training epoch 352
[2024-10-08 10:08:06,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 10:18:12,595][train_inner][INFO] - {"epoch": 352, "update": 351.29, "loss": "0.803", "ntokens": "263041", "nsentences": "1723.01", "wps": "77775.3", "ups": "0.3", "wpb": "263041", "bsz": "1723", "num_updates": "168200", "lr": "0.000314946", "gnorm": "0.266", "loss_scale": "2", "train_wall": "204", "gb_free": "40", "wall": "317285"}
[2024-10-08 10:21:56,744][train_inner][INFO] - {"epoch": 352, "update": 351.708, "loss": "0.804", "ntokens": "263795", "nsentences": "1779.45", "wps": "235391", "ups": "0.89", "wpb": "263795", "bsz": "1779.5", "num_updates": "168400", "lr": "0.000314674", "gnorm": "0.264", "loss_scale": "2", "train_wall": "219", "gb_free": "39", "wall": "317509"}
[2024-10-08 10:24:57,155][fairseq_cli.train][INFO] - end of epoch 352 (average epoch stats below)
[2024-10-08 10:24:57,173][train][INFO] - {"epoch": 352, "train_loss": "0.803", "train_ntokens": "263414", "train_nsentences": "1753.71", "train_wps": "124765", "train_ups": "0.47", "train_wpb": "263414", "train_bsz": "1753.7", "train_num_updates": "168540", "train_lr": "0.000314484", "train_gnorm": "0.265", "train_loss_scale": "4", "train_train_wall": "532", "train_gb_free": "39.1", "train_wall": "317689"}
[2024-10-08 10:24:57,348][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 10:24:57,390][fairseq.trainer][INFO] - begin training epoch 353
[2024-10-08 10:24:57,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 10:34:32,110][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 10:34:32,502][train_inner][INFO] - {"epoch": 353, "update": 352.127, "loss": "0.802", "ntokens": "262664", "nsentences": "1758.86", "wps": "69512.1", "ups": "0.26", "wpb": "262664", "bsz": "1758.9", "num_updates": "168600", "lr": "0.000314402", "gnorm": "0.254", "loss_scale": "2", "train_wall": "274", "gb_free": "39.7", "wall": "318265"}
[2024-10-08 10:38:15,633][train_inner][INFO] - {"epoch": 353, "update": 352.545, "loss": "0.805", "ntokens": "263345", "nsentences": "1812.22", "wps": "236070", "ups": "0.9", "wpb": "263345", "bsz": "1812.2", "num_updates": "168800", "lr": "0.00031413", "gnorm": "0.288", "loss_scale": "2", "train_wall": "216", "gb_free": "39.2", "wall": "318488"}
[2024-10-08 10:41:35,992][train_inner][INFO] - {"epoch": 353, "update": 352.962, "loss": "0.802", "ntokens": "264486", "nsentences": "1715.25", "wps": "264073", "ups": "1", "wpb": "264486", "bsz": "1715.2", "num_updates": "169000", "lr": "0.000313859", "gnorm": "0.26", "loss_scale": "2", "train_wall": "195", "gb_free": "39.2", "wall": "318688"}
[2024-10-08 10:42:20,026][fairseq_cli.train][INFO] - end of epoch 353 (average epoch stats below)
[2024-10-08 10:42:20,030][train][INFO] - {"epoch": 353, "train_loss": "0.803", "train_ntokens": "263519", "train_nsentences": "1752.42", "train_wps": "120786", "train_ups": "0.46", "train_wpb": "263519", "train_bsz": "1752.4", "train_num_updates": "169018", "train_lr": "0.000313834", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.6", "train_wall": "318732"}
[2024-10-08 10:42:20,165][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 10:42:20,244][fairseq.trainer][INFO] - begin training epoch 354
[2024-10-08 10:42:20,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 10:51:19,168][train_inner][INFO] - {"epoch": 354, "update": 353.38, "loss": "0.799", "ntokens": "262706", "nsentences": "1758.43", "wps": "90098.5", "ups": "0.34", "wpb": "262706", "bsz": "1758.4", "num_updates": "169200", "lr": "0.000313587", "gnorm": "0.276", "loss_scale": "2", "train_wall": "246", "gb_free": "40", "wall": "319271"}
[2024-10-08 10:55:06,976][train_inner][INFO] - {"epoch": 354, "update": 353.797, "loss": "0.805", "ntokens": "264082", "nsentences": "1741.17", "wps": "231860", "ups": "0.88", "wpb": "264082", "bsz": "1741.2", "num_updates": "169400", "lr": "0.000313315", "gnorm": "0.272", "loss_scale": "2", "train_wall": "221", "gb_free": "39.6", "wall": "319499"}
[2024-10-08 10:56:50,558][fairseq_cli.train][INFO] - end of epoch 354 (average epoch stats below)
[2024-10-08 10:56:50,589][train][INFO] - {"epoch": 354, "train_loss": "0.803", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "144971", "train_ups": "0.55", "train_wpb": "263475", "train_bsz": "1753.7", "train_num_updates": "169497", "train_lr": "0.000313183", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "525", "train_gb_free": "39.7", "train_wall": "319603"}
[2024-10-08 10:56:50,793][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 10:56:50,853][fairseq.trainer][INFO] - begin training epoch 355
[2024-10-08 10:56:50,853][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:04:51,322][train_inner][INFO] - {"epoch": 355, "update": 354.215, "loss": "0.802", "ntokens": "263055", "nsentences": "1741.31", "wps": "90036.7", "ups": "0.34", "wpb": "263055", "bsz": "1741.3", "num_updates": "169600", "lr": "0.000313043", "gnorm": "0.26", "loss_scale": "2", "train_wall": "212", "gb_free": "39.3", "wall": "320083"}
[2024-10-08 11:08:17,999][train_inner][INFO] - {"epoch": 355, "update": 354.633, "loss": "0.801", "ntokens": "264380", "nsentences": "1707.42", "wps": "255857", "ups": "0.97", "wpb": "264380", "bsz": "1707.4", "num_updates": "169800", "lr": "0.000312772", "gnorm": "0.254", "loss_scale": "2", "train_wall": "189", "gb_free": "39.6", "wall": "320290"}
[2024-10-08 11:12:04,692][fairseq_cli.train][INFO] - end of epoch 355 (average epoch stats below)
[2024-10-08 11:12:04,724][train][INFO] - {"epoch": 355, "train_loss": "0.803", "train_ntokens": "263628", "train_nsentences": "1753.71", "train_wps": "138143", "train_ups": "0.52", "train_wpb": "263628", "train_bsz": "1753.7", "train_num_updates": "169976", "train_lr": "0.000312533", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "521", "train_gb_free": "40.1", "train_wall": "320517"}
[2024-10-08 11:12:04,952][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:12:04,967][fairseq.trainer][INFO] - begin training epoch 356
[2024-10-08 11:12:04,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:18:04,107][train_inner][INFO] - {"epoch": 356, "update": 355.05, "loss": "0.807", "ntokens": "262617", "nsentences": "1793.15", "wps": "89616.2", "ups": "0.34", "wpb": "262617", "bsz": "1793.2", "num_updates": "170000", "lr": "0.0003125", "gnorm": "0.281", "loss_scale": "2", "train_wall": "259", "gb_free": "39.6", "wall": "320876"}
[2024-10-08 11:21:35,943][train_inner][INFO] - {"epoch": 356, "update": 355.468, "loss": "0.801", "ntokens": "263943", "nsentences": "1759.59", "wps": "249214", "ups": "0.94", "wpb": "263943", "bsz": "1759.6", "num_updates": "170200", "lr": "0.000312228", "gnorm": "0.261", "loss_scale": "2", "train_wall": "207", "gb_free": "39.4", "wall": "321088"}
[2024-10-08 11:25:33,536][train_inner][INFO] - {"epoch": 356, "update": 355.885, "loss": "0.802", "ntokens": "264052", "nsentences": "1751.07", "wps": "222301", "ups": "0.84", "wpb": "264052", "bsz": "1751.1", "num_updates": "170400", "lr": "0.000311957", "gnorm": "0.273", "loss_scale": "2", "train_wall": "232", "gb_free": "39.8", "wall": "321326"}
[2024-10-08 11:26:23,451][fairseq_cli.train][INFO] - end of epoch 356 (average epoch stats below)
[2024-10-08 11:26:23,494][train][INFO] - {"epoch": 356, "train_loss": "0.802", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "146985", "train_ups": "0.56", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "170455", "train_lr": "0.000311882", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "527", "train_gb_free": "40", "train_wall": "321376"}
[2024-10-08 11:26:23,667][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:26:23,709][fairseq.trainer][INFO] - begin training epoch 357
[2024-10-08 11:26:23,710][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:35:18,339][train_inner][INFO] - {"epoch": 357, "update": 356.303, "loss": "0.803", "ntokens": "262437", "nsentences": "1783.71", "wps": "89753.9", "ups": "0.34", "wpb": "262437", "bsz": "1783.7", "num_updates": "170600", "lr": "0.000311685", "gnorm": "0.264", "loss_scale": "2", "train_wall": "241", "gb_free": "39.7", "wall": "321911"}
[2024-10-08 11:38:59,614][train_inner][INFO] - {"epoch": 357, "update": 356.72, "loss": "0.801", "ntokens": "264316", "nsentences": "1728.61", "wps": "238920", "ups": "0.9", "wpb": "264316", "bsz": "1728.6", "num_updates": "170800", "lr": "0.000311413", "gnorm": "0.258", "loss_scale": "4", "train_wall": "216", "gb_free": "39.6", "wall": "322132"}
[2024-10-08 11:41:36,834][fairseq_cli.train][INFO] - end of epoch 357 (average epoch stats below)
[2024-10-08 11:41:36,868][train][INFO] - {"epoch": 357, "train_loss": "0.802", "train_ntokens": "263487", "train_nsentences": "1753.71", "train_wps": "138184", "train_ups": "0.52", "train_wpb": "263487", "train_bsz": "1753.7", "train_num_updates": "170934", "train_lr": "0.000311231", "train_gnorm": "0.26", "train_loss_scale": "4", "train_train_wall": "562", "train_gb_free": "40", "train_wall": "322289"}
[2024-10-08 11:41:36,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:41:36,976][fairseq.trainer][INFO] - begin training epoch 358
[2024-10-08 11:41:36,977][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 11:47:37,405][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 11:48:20,962][train_inner][INFO] - {"epoch": 358, "update": 357.14, "loss": "0.805", "ntokens": "262521", "nsentences": "1792.21", "wps": "93533.9", "ups": "0.36", "wpb": "262521", "bsz": "1792.2", "num_updates": "171000", "lr": "0.000311141", "gnorm": "0.27", "loss_scale": "2", "train_wall": "229", "gb_free": "39.2", "wall": "322693"}
[2024-10-08 11:51:42,547][train_inner][INFO] - {"epoch": 358, "update": 357.557, "loss": "0.8", "ntokens": "264150", "nsentences": "1735.28", "wps": "262099", "ups": "0.99", "wpb": "264150", "bsz": "1735.3", "num_updates": "171200", "lr": "0.00031087", "gnorm": "0.273", "loss_scale": "2", "train_wall": "196", "gb_free": "40", "wall": "322895"}
[2024-10-08 11:55:29,353][train_inner][INFO] - {"epoch": 358, "update": 357.975, "loss": "0.803", "ntokens": "264183", "nsentences": "1746.31", "wps": "232971", "ups": "0.88", "wpb": "264183", "bsz": "1746.3", "num_updates": "171400", "lr": "0.000310598", "gnorm": "0.273", "loss_scale": "2", "train_wall": "222", "gb_free": "39.6", "wall": "323122"}
[2024-10-08 11:56:13,664][fairseq_cli.train][INFO] - end of epoch 358 (average epoch stats below)
[2024-10-08 11:56:13,698][train][INFO] - {"epoch": 358, "train_loss": "0.802", "train_ntokens": "263550", "train_nsentences": "1755.67", "train_wps": "143679", "train_ups": "0.55", "train_wpb": "263550", "train_bsz": "1755.7", "train_num_updates": "171412", "train_lr": "0.000310582", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "538", "train_gb_free": "40", "train_wall": "323166"}
[2024-10-08 11:56:13,772][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 11:56:13,789][fairseq.trainer][INFO] - begin training epoch 359
[2024-10-08 11:56:13,790][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:04:55,704][train_inner][INFO] - {"epoch": 359, "update": 358.392, "loss": "0.798", "ntokens": "263147", "nsentences": "1711.27", "wps": "92928.7", "ups": "0.35", "wpb": "263146", "bsz": "1711.3", "num_updates": "171600", "lr": "0.000310326", "gnorm": "0.259", "loss_scale": "2", "train_wall": "249", "gb_free": "40", "wall": "323688"}
[2024-10-08 12:09:04,919][train_inner][INFO] - {"epoch": 359, "update": 358.81, "loss": "0.805", "ntokens": "263597", "nsentences": "1788.61", "wps": "211555", "ups": "0.8", "wpb": "263596", "bsz": "1788.6", "num_updates": "171800", "lr": "0.000310054", "gnorm": "0.257", "loss_scale": "2", "train_wall": "244", "gb_free": "39.2", "wall": "323937"}
[2024-10-08 12:11:09,249][fairseq_cli.train][INFO] - end of epoch 359 (average epoch stats below)
[2024-10-08 12:11:09,278][train][INFO] - {"epoch": 359, "train_loss": "0.802", "train_ntokens": "263402", "train_nsentences": "1753.71", "train_wps": "140882", "train_ups": "0.53", "train_wpb": "263402", "train_bsz": "1753.7", "train_num_updates": "171891", "train_lr": "0.000309931", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "571", "train_gb_free": "39.3", "train_wall": "324061"}
[2024-10-08 12:11:09,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:11:09,532][fairseq.trainer][INFO] - begin training epoch 360
[2024-10-08 12:11:09,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:18:49,638][train_inner][INFO] - {"epoch": 360, "update": 359.228, "loss": "0.801", "ntokens": "262789", "nsentences": "1748.92", "wps": "89887.2", "ups": "0.34", "wpb": "262789", "bsz": "1748.9", "num_updates": "172000", "lr": "0.000309783", "gnorm": "0.283", "loss_scale": "2", "train_wall": "269", "gb_free": "39.8", "wall": "324522"}
[2024-10-08 12:22:18,375][train_inner][INFO] - {"epoch": 360, "update": 359.645, "loss": "0.801", "ntokens": "263870", "nsentences": "1747.48", "wps": "252838", "ups": "0.96", "wpb": "263870", "bsz": "1747.5", "num_updates": "172200", "lr": "0.000309511", "gnorm": "0.282", "loss_scale": "2", "train_wall": "204", "gb_free": "39.6", "wall": "324731"}
[2024-10-08 12:25:50,348][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 360 @ 172370 updates
[2024-10-08 12:25:50,350][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 12:25:55,456][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 12:25:55,520][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 360 @ 172370 updates, score None) (writing took 5.17115936987102 seconds)
[2024-10-08 12:25:55,520][fairseq_cli.train][INFO] - end of epoch 360 (average epoch stats below)
[2024-10-08 12:25:55,538][train][INFO] - {"epoch": 360, "train_loss": "0.801", "train_ntokens": "263460", "train_nsentences": "1753.71", "train_wps": "142397", "train_ups": "0.54", "train_wpb": "263460", "train_bsz": "1753.7", "train_num_updates": "172370", "train_lr": "0.00030928", "train_gnorm": "0.277", "train_loss_scale": "2", "train_train_wall": "558", "train_gb_free": "39.6", "train_wall": "324948"}
[2024-10-08 12:25:55,591][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:25:55,663][fairseq.trainer][INFO] - begin training epoch 361
[2024-10-08 12:25:55,664][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:32:03,723][train_inner][INFO] - {"epoch": 361, "update": 360.063, "loss": "0.801", "ntokens": "262708", "nsentences": "1758.35", "wps": "89764.8", "ups": "0.34", "wpb": "262708", "bsz": "1758.3", "num_updates": "172400", "lr": "0.000309239", "gnorm": "0.28", "loss_scale": "2", "train_wall": "240", "gb_free": "39.6", "wall": "325316"}
[2024-10-08 12:32:19,950][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 12:35:48,989][train_inner][INFO] - {"epoch": 361, "update": 360.482, "loss": "0.801", "ntokens": "263817", "nsentences": "1772.18", "wps": "234250", "ups": "0.89", "wpb": "263817", "bsz": "1772.2", "num_updates": "172600", "lr": "0.000308967", "gnorm": "0.257", "loss_scale": "1", "train_wall": "219", "gb_free": "39.8", "wall": "325541"}
[2024-10-08 12:39:33,483][train_inner][INFO] - {"epoch": 361, "update": 360.9, "loss": "0.802", "ntokens": "264048", "nsentences": "1740.68", "wps": "235260", "ups": "0.89", "wpb": "264048", "bsz": "1740.7", "num_updates": "172800", "lr": "0.000308696", "gnorm": "0.257", "loss_scale": "1", "train_wall": "218", "gb_free": "40.5", "wall": "325766"}
[2024-10-08 12:40:48,027][fairseq_cli.train][INFO] - end of epoch 361 (average epoch stats below)
[2024-10-08 12:40:48,065][train][INFO] - {"epoch": 361, "train_loss": "0.802", "train_ntokens": "263412", "train_nsentences": "1754.25", "train_wps": "141074", "train_ups": "0.54", "train_wpb": "263412", "train_bsz": "1754.2", "train_num_updates": "172848", "train_lr": "0.00030863", "train_gnorm": "0.26", "train_loss_scale": "1", "train_train_wall": "540", "train_gb_free": "39.6", "train_wall": "325840"}
[2024-10-08 12:40:48,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:40:48,324][fairseq.trainer][INFO] - begin training epoch 362
[2024-10-08 12:40:48,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 12:49:24,662][train_inner][INFO] - {"epoch": 362, "update": 361.317, "loss": "0.802", "ntokens": "262562", "nsentences": "1783.87", "wps": "88829.5", "ups": "0.34", "wpb": "262562", "bsz": "1783.9", "num_updates": "173000", "lr": "0.000308424", "gnorm": "0.29", "loss_scale": "1", "train_wall": "257", "gb_free": "39.6", "wall": "326357"}
[2024-10-08 12:53:06,718][train_inner][INFO] - {"epoch": 362, "update": 361.735, "loss": "0.8", "ntokens": "264197", "nsentences": "1717.16", "wps": "237969", "ups": "0.9", "wpb": "264197", "bsz": "1717.2", "num_updates": "173200", "lr": "0.000308152", "gnorm": "0.258", "loss_scale": "1", "train_wall": "216", "gb_free": "39.3", "wall": "326579"}
[2024-10-08 12:56:00,160][fairseq_cli.train][INFO] - end of epoch 362 (average epoch stats below)
[2024-10-08 12:56:00,169][train][INFO] - {"epoch": 362, "train_loss": "0.801", "train_ntokens": "263469", "train_nsentences": "1753.71", "train_wps": "138364", "train_ups": "0.53", "train_wpb": "263469", "train_bsz": "1753.7", "train_num_updates": "173327", "train_lr": "0.00030798", "train_gnorm": "0.276", "train_loss_scale": "1", "train_train_wall": "570", "train_gb_free": "39.6", "train_wall": "326752"}
[2024-10-08 12:56:00,284][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 12:56:00,308][fairseq.trainer][INFO] - begin training epoch 363
[2024-10-08 12:56:00,309][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 13:03:13,944][train_inner][INFO] - {"epoch": 363, "update": 362.152, "loss": "0.801", "ntokens": "262844", "nsentences": "1749.72", "wps": "86574.5", "ups": "0.33", "wpb": "262844", "bsz": "1749.7", "num_updates": "173400", "lr": "0.00030788", "gnorm": "0.28", "loss_scale": "1", "train_wall": "285", "gb_free": "39.3", "wall": "327186"}
[2024-10-08 13:06:29,599][train_inner][INFO] - {"epoch": 363, "update": 362.57, "loss": "0.797", "ntokens": "264388", "nsentences": "1717.09", "wps": "270287", "ups": "1.02", "wpb": "264388", "bsz": "1717.1", "num_updates": "173600", "lr": "0.000307609", "gnorm": "0.273", "loss_scale": "1", "train_wall": "190", "gb_free": "39.1", "wall": "327382"}
[2024-10-08 13:10:34,234][train_inner][INFO] - {"epoch": 363, "update": 362.987, "loss": "0.806", "ntokens": "263316", "nsentences": "1811.2", "wps": "215302", "ups": "0.82", "wpb": "263316", "bsz": "1811.2", "num_updates": "173800", "lr": "0.000307337", "gnorm": "0.264", "loss_scale": "1", "train_wall": "240", "gb_free": "39.3", "wall": "327626"}
[2024-10-08 13:10:58,276][fairseq_cli.train][INFO] - end of epoch 363 (average epoch stats below)
[2024-10-08 13:10:58,290][train][INFO] - {"epoch": 363, "train_loss": "0.801", "train_ntokens": "263464", "train_nsentences": "1753.71", "train_wps": "140517", "train_ups": "0.53", "train_wpb": "263464", "train_bsz": "1753.7", "train_num_updates": "173806", "train_lr": "0.000307329", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "570", "train_gb_free": "39.6", "train_wall": "327650"}
[2024-10-08 13:10:58,364][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:10:58,373][fairseq.trainer][INFO] - begin training epoch 364
[2024-10-08 13:10:58,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 13:19:59,659][train_inner][INFO] - {"epoch": 364, "update": 363.405, "loss": "0.801", "ntokens": "262391", "nsentences": "1782.28", "wps": "92818.1", "ups": "0.35", "wpb": "262391", "bsz": "1782.3", "num_updates": "174000", "lr": "0.000307065", "gnorm": "0.263", "loss_scale": "1", "train_wall": "229", "gb_free": "39.6", "wall": "328192"}
[2024-10-08 13:24:09,371][train_inner][INFO] - {"epoch": 364, "update": 363.823, "loss": "0.8", "ntokens": "264181", "nsentences": "1717.02", "wps": "211606", "ups": "0.8", "wpb": "264181", "bsz": "1717", "num_updates": "174200", "lr": "0.000306793", "gnorm": "0.259", "loss_scale": "1", "train_wall": "244", "gb_free": "39.6", "wall": "328442"}
[2024-10-08 13:25:45,584][fairseq_cli.train][INFO] - end of epoch 364 (average epoch stats below)
[2024-10-08 13:25:45,592][train][INFO] - {"epoch": 364, "train_loss": "0.801", "train_ntokens": "263346", "train_nsentences": "1753.71", "train_wps": "142165", "train_ups": "0.54", "train_wpb": "263346", "train_bsz": "1753.7", "train_num_updates": "174285", "train_lr": "0.000306678", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "544", "train_gb_free": "39.6", "train_wall": "328538"}
[2024-10-08 13:25:45,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:25:45,703][fairseq.trainer][INFO] - begin training epoch 365
[2024-10-08 13:25:45,704][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 13:33:26,041][train_inner][INFO] - {"epoch": 365, "update": 364.24, "loss": "0.801", "ntokens": "262821", "nsentences": "1757.26", "wps": "94431.7", "ups": "0.36", "wpb": "262821", "bsz": "1757.3", "num_updates": "174400", "lr": "0.000306522", "gnorm": "0.255", "loss_scale": "1", "train_wall": "222", "gb_free": "39.6", "wall": "328998"}
[2024-10-08 13:37:19,371][train_inner][INFO] - {"epoch": 365, "update": 364.658, "loss": "0.801", "ntokens": "263934", "nsentences": "1766.62", "wps": "226251", "ups": "0.86", "wpb": "263934", "bsz": "1766.6", "num_updates": "174600", "lr": "0.00030625", "gnorm": "0.26", "loss_scale": "2", "train_wall": "228", "gb_free": "40.1", "wall": "329232"}
[2024-10-08 13:40:18,024][fairseq_cli.train][INFO] - end of epoch 365 (average epoch stats below)
[2024-10-08 13:40:18,045][train][INFO] - {"epoch": 365, "train_loss": "0.8", "train_ntokens": "263505", "train_nsentences": "1753.71", "train_wps": "144673", "train_ups": "0.55", "train_wpb": "263505", "train_bsz": "1753.7", "train_num_updates": "174764", "train_lr": "0.000306027", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "530", "train_gb_free": "39.6", "train_wall": "329410"}
[2024-10-08 13:40:18,214][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:40:18,229][fairseq.trainer][INFO] - begin training epoch 366
[2024-10-08 13:40:18,229][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 13:47:08,280][train_inner][INFO] - {"epoch": 366, "update": 365.075, "loss": "0.8", "ntokens": "262586", "nsentences": "1756.59", "wps": "89180.4", "ups": "0.34", "wpb": "262586", "bsz": "1756.6", "num_updates": "174800", "lr": "0.000305978", "gnorm": "0.278", "loss_scale": "2", "train_wall": "248", "gb_free": "39.3", "wall": "329820"}
[2024-10-08 13:50:32,415][train_inner][INFO] - {"epoch": 366, "update": 365.493, "loss": "0.798", "ntokens": "264262", "nsentences": "1729.11", "wps": "258937", "ups": "0.98", "wpb": "264262", "bsz": "1729.1", "num_updates": "175000", "lr": "0.000305707", "gnorm": "0.266", "loss_scale": "2", "train_wall": "199", "gb_free": "39.3", "wall": "330025"}
[2024-10-08 13:54:24,900][train_inner][INFO] - {"epoch": 366, "update": 365.91, "loss": "0.803", "ntokens": "264071", "nsentences": "1757.69", "wps": "227192", "ups": "0.86", "wpb": "264071", "bsz": "1757.7", "num_updates": "175200", "lr": "0.000305435", "gnorm": "0.273", "loss_scale": "2", "train_wall": "227", "gb_free": "40.3", "wall": "330257"}
[2024-10-08 13:55:34,234][fairseq_cli.train][INFO] - end of epoch 366 (average epoch stats below)
[2024-10-08 13:55:34,247][train][INFO] - {"epoch": 366, "train_loss": "0.801", "train_ntokens": "263546", "train_nsentences": "1753.71", "train_wps": "137786", "train_ups": "0.52", "train_wpb": "263546", "train_bsz": "1753.7", "train_num_updates": "175243", "train_lr": "0.000305376", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "40", "train_wall": "330326"}
[2024-10-08 13:55:34,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 13:55:34,455][fairseq.trainer][INFO] - begin training epoch 367
[2024-10-08 13:55:34,456][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:04:12,770][train_inner][INFO] - {"epoch": 367, "update": 366.328, "loss": "0.8", "ntokens": "262919", "nsentences": "1753.41", "wps": "89452.1", "ups": "0.34", "wpb": "262919", "bsz": "1753.4", "num_updates": "175400", "lr": "0.000305163", "gnorm": "0.251", "loss_scale": "2", "train_wall": "245", "gb_free": "40", "wall": "330845"}
[2024-10-08 14:08:23,097][train_inner][INFO] - {"epoch": 367, "update": 366.745, "loss": "0.801", "ntokens": "263960", "nsentences": "1759.24", "wps": "210899", "ups": "0.8", "wpb": "263960", "bsz": "1759.2", "num_updates": "175600", "lr": "0.000304891", "gnorm": "0.277", "loss_scale": "2", "train_wall": "245", "gb_free": "40.6", "wall": "331095"}
[2024-10-08 14:10:57,362][fairseq_cli.train][INFO] - end of epoch 367 (average epoch stats below)
[2024-10-08 14:10:57,375][train][INFO] - {"epoch": 367, "train_loss": "0.801", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "136745", "train_ups": "0.52", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "175722", "train_lr": "0.000304726", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "575", "train_gb_free": "39.8", "train_wall": "331250"}
[2024-10-08 14:10:57,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:10:57,508][fairseq.trainer][INFO] - begin training epoch 368
[2024-10-08 14:10:57,508][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:17:58,313][train_inner][INFO] - {"epoch": 368, "update": 367.163, "loss": "0.8", "ntokens": "263117", "nsentences": "1740.49", "wps": "91487.4", "ups": "0.35", "wpb": "263117", "bsz": "1740.5", "num_updates": "175800", "lr": "0.00030462", "gnorm": "0.259", "loss_scale": "2", "train_wall": "233", "gb_free": "39.6", "wall": "331670"}
[2024-10-08 14:21:38,118][train_inner][INFO] - {"epoch": 368, "update": 367.58, "loss": "0.801", "ntokens": "264132", "nsentences": "1764.67", "wps": "240349", "ups": "0.91", "wpb": "264132", "bsz": "1764.7", "num_updates": "176000", "lr": "0.000304348", "gnorm": "0.256", "loss_scale": "2", "train_wall": "214", "gb_free": "39.3", "wall": "331890"}
[2024-10-08 14:23:38,988][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 14:25:54,735][train_inner][INFO] - {"epoch": 368, "update": 368.0, "loss": "0.802", "ntokens": "262535", "nsentences": "1746.29", "wps": "204624", "ups": "0.78", "wpb": "262535", "bsz": "1746.3", "num_updates": "176200", "lr": "0.000304076", "gnorm": "0.256", "loss_scale": "1", "train_wall": "250", "gb_free": "39.2", "wall": "332147"}
[2024-10-08 14:25:54,748][fairseq_cli.train][INFO] - end of epoch 368 (average epoch stats below)
[2024-10-08 14:25:54,750][train][INFO] - {"epoch": 368, "train_loss": "0.801", "train_ntokens": "263567", "train_nsentences": "1752.89", "train_wps": "140394", "train_ups": "0.53", "train_wpb": "263567", "train_bsz": "1752.9", "train_num_updates": "176200", "train_lr": "0.000304076", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "547", "train_gb_free": "39.2", "train_wall": "332147"}
[2024-10-08 14:25:54,815][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:25:54,838][fairseq.trainer][INFO] - begin training epoch 369
[2024-10-08 14:25:54,839][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:35:23,262][train_inner][INFO] - {"epoch": 369, "update": 368.418, "loss": "0.797", "ntokens": "264211", "nsentences": "1742.97", "wps": "92948.1", "ups": "0.35", "wpb": "264210", "bsz": "1743", "num_updates": "176400", "lr": "0.000303804", "gnorm": "0.253", "loss_scale": "1", "train_wall": "236", "gb_free": "39.2", "wall": "332715"}
[2024-10-08 14:39:12,725][train_inner][INFO] - {"epoch": 369, "update": 368.835, "loss": "0.803", "ntokens": "263862", "nsentences": "1771.88", "wps": "230003", "ups": "0.87", "wpb": "263862", "bsz": "1771.9", "num_updates": "176600", "lr": "0.000303533", "gnorm": "0.266", "loss_scale": "1", "train_wall": "224", "gb_free": "39.7", "wall": "332945"}
[2024-10-08 14:41:14,383][fairseq_cli.train][INFO] - end of epoch 369 (average epoch stats below)
[2024-10-08 14:41:14,411][train][INFO] - {"epoch": 369, "train_loss": "0.8", "train_ntokens": "263537", "train_nsentences": "1753.71", "train_wps": "137262", "train_ups": "0.52", "train_wpb": "263537", "train_bsz": "1753.7", "train_num_updates": "176679", "train_lr": "0.000303425", "train_gnorm": "0.26", "train_loss_scale": "1", "train_train_wall": "580", "train_gb_free": "39.2", "train_wall": "333067"}
[2024-10-08 14:41:14,507][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:41:14,540][fairseq.trainer][INFO] - begin training epoch 370
[2024-10-08 14:41:14,541][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 14:49:05,598][train_inner][INFO] - {"epoch": 370, "update": 369.253, "loss": "0.795", "ntokens": "263205", "nsentences": "1715.87", "wps": "88793.4", "ups": "0.34", "wpb": "263205", "bsz": "1715.9", "num_updates": "176800", "lr": "0.000303261", "gnorm": "0.276", "loss_scale": "1", "train_wall": "260", "gb_free": "40", "wall": "333538"}
[2024-10-08 14:53:06,702][train_inner][INFO] - {"epoch": 370, "update": 369.67, "loss": "0.804", "ntokens": "263458", "nsentences": "1816.53", "wps": "218568", "ups": "0.83", "wpb": "263458", "bsz": "1816.5", "num_updates": "177000", "lr": "0.000302989", "gnorm": "0.269", "loss_scale": "1", "train_wall": "190", "gb_free": "39.6", "wall": "333779"}
[2024-10-08 14:56:17,047][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 370 @ 177158 updates
[2024-10-08 14:56:17,049][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 14:56:24,722][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 14:56:24,943][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 370 @ 177158 updates, score None) (writing took 7.895907204598188 seconds)
[2024-10-08 14:56:24,944][fairseq_cli.train][INFO] - end of epoch 370 (average epoch stats below)
[2024-10-08 14:56:24,954][train][INFO] - {"epoch": 370, "train_loss": "0.8", "train_ntokens": "263528", "train_nsentences": "1753.71", "train_wps": "138634", "train_ups": "0.53", "train_wpb": "263528", "train_bsz": "1753.7", "train_num_updates": "177158", "train_lr": "0.000302774", "train_gnorm": "0.282", "train_loss_scale": "1", "train_train_wall": "459", "train_gb_free": "39.8", "train_wall": "333977"}
[2024-10-08 14:56:25,003][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 14:56:25,040][fairseq.trainer][INFO] - begin training epoch 371
[2024-10-08 14:56:25,041][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 15:02:48,592][train_inner][INFO] - {"epoch": 371, "update": 370.088, "loss": "0.799", "ntokens": "263212", "nsentences": "1706.75", "wps": "90469.7", "ups": "0.34", "wpb": "263212", "bsz": "1706.8", "num_updates": "177200", "lr": "0.000302717", "gnorm": "0.3", "loss_scale": "1", "train_wall": "167", "gb_free": "39.8", "wall": "334361"}
[2024-10-08 15:06:37,825][train_inner][INFO] - {"epoch": 371, "update": 370.505, "loss": "0.799", "ntokens": "264055", "nsentences": "1759.98", "wps": "230396", "ups": "0.87", "wpb": "264055", "bsz": "1760", "num_updates": "177400", "lr": "0.000302446", "gnorm": "0.26", "loss_scale": "1", "train_wall": "156", "gb_free": "39.6", "wall": "334590"}
[2024-10-08 15:10:35,225][train_inner][INFO] - {"epoch": 371, "update": 370.923, "loss": "0.801", "ntokens": "264021", "nsentences": "1754.36", "wps": "222435", "ups": "0.84", "wpb": "264021", "bsz": "1754.4", "num_updates": "177600", "lr": "0.000302174", "gnorm": "0.28", "loss_scale": "1", "train_wall": "145", "gb_free": "39.2", "wall": "334827"}
[2024-10-08 15:11:22,640][fairseq_cli.train][INFO] - end of epoch 371 (average epoch stats below)
[2024-10-08 15:11:22,643][train][INFO] - {"epoch": 371, "train_loss": "0.8", "train_ntokens": "263589", "train_nsentences": "1753.71", "train_wps": "140650", "train_ups": "0.53", "train_wpb": "263589", "train_bsz": "1753.7", "train_num_updates": "177637", "train_lr": "0.000302124", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "380", "train_gb_free": "40.3", "train_wall": "334875"}
[2024-10-08 15:11:22,737][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 15:11:22,767][fairseq.trainer][INFO] - begin training epoch 372
[2024-10-08 15:11:22,767][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 15:20:07,841][train_inner][INFO] - {"epoch": 372, "update": 371.34, "loss": "0.8", "ntokens": "262571", "nsentences": "1787.86", "wps": "91711.8", "ups": "0.35", "wpb": "262571", "bsz": "1787.9", "num_updates": "177800", "lr": "0.000301902", "gnorm": "0.259", "loss_scale": "1", "train_wall": "220", "gb_free": "39.3", "wall": "335400"}
[2024-10-08 15:23:52,626][train_inner][INFO] - {"epoch": 372, "update": 371.758, "loss": "0.8", "ntokens": "263987", "nsentences": "1740.91", "wps": "234902", "ups": "0.89", "wpb": "263987", "bsz": "1740.9", "num_updates": "178000", "lr": "0.00030163", "gnorm": "0.262", "loss_scale": "1", "train_wall": "220", "gb_free": "39.8", "wall": "335625"}
[2024-10-08 15:26:21,442][fairseq_cli.train][INFO] - end of epoch 372 (average epoch stats below)
[2024-10-08 15:26:21,478][train][INFO] - {"epoch": 372, "train_loss": "0.799", "train_ntokens": "263490", "train_nsentences": "1753.71", "train_wps": "140420", "train_ups": "0.53", "train_wpb": "263490", "train_bsz": "1753.7", "train_num_updates": "178116", "train_lr": "0.000301473", "train_gnorm": "0.262", "train_loss_scale": "1", "train_train_wall": "542", "train_gb_free": "39.7", "train_wall": "335774"}
[2024-10-08 15:26:21,606][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 15:26:21,618][fairseq.trainer][INFO] - begin training epoch 373
[2024-10-08 15:26:21,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 15:33:54,308][train_inner][INFO] - {"epoch": 373, "update": 372.175, "loss": "0.799", "ntokens": "262862", "nsentences": "1744.18", "wps": "87377.4", "ups": "0.33", "wpb": "262862", "bsz": "1744.2", "num_updates": "178200", "lr": "0.000301359", "gnorm": "0.276", "loss_scale": "2", "train_wall": "250", "gb_free": "39.6", "wall": "336226"}
[2024-10-08 15:37:40,320][train_inner][INFO] - {"epoch": 373, "update": 372.593, "loss": "0.799", "ntokens": "263755", "nsentences": "1771.54", "wps": "233409", "ups": "0.88", "wpb": "263755", "bsz": "1771.5", "num_updates": "178400", "lr": "0.000301087", "gnorm": "0.273", "loss_scale": "2", "train_wall": "212", "gb_free": "40.3", "wall": "336452"}
[2024-10-08 15:42:11,645][fairseq_cli.train][INFO] - end of epoch 373 (average epoch stats below)
[2024-10-08 15:42:11,663][train][INFO] - {"epoch": 373, "train_loss": "0.799", "train_ntokens": "263435", "train_nsentences": "1753.71", "train_wps": "132802", "train_ups": "0.5", "train_wpb": "263435", "train_bsz": "1753.7", "train_num_updates": "178595", "train_lr": "0.000300822", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "584", "train_gb_free": "39.6", "train_wall": "336724"}
[2024-10-08 15:42:11,744][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 15:42:11,763][fairseq.trainer][INFO] - begin training epoch 374
[2024-10-08 15:42:11,764][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 15:49:23,054][train_inner][INFO] - {"epoch": 374, "update": 373.01, "loss": "0.799", "ntokens": "263050", "nsentences": "1725.19", "wps": "74868.1", "ups": "0.28", "wpb": "263050", "bsz": "1725.2", "num_updates": "178600", "lr": "0.000300815", "gnorm": "0.274", "loss_scale": "2", "train_wall": "275", "gb_free": "40.1", "wall": "337155"}
[2024-10-08 15:53:02,835][train_inner][INFO] - {"epoch": 374, "update": 373.428, "loss": "0.797", "ntokens": "264137", "nsentences": "1744.99", "wps": "240379", "ups": "0.91", "wpb": "264137", "bsz": "1745", "num_updates": "178800", "lr": "0.000300543", "gnorm": "0.251", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "337375"}
[2024-10-08 15:57:17,184][train_inner][INFO] - {"epoch": 374, "update": 373.846, "loss": "0.799", "ntokens": "263862", "nsentences": "1768.17", "wps": "207500", "ups": "0.79", "wpb": "263862", "bsz": "1768.2", "num_updates": "179000", "lr": "0.000300272", "gnorm": "0.261", "loss_scale": "2", "train_wall": "249", "gb_free": "39.8", "wall": "337629"}
[2024-10-08 15:58:48,444][fairseq_cli.train][INFO] - end of epoch 374 (average epoch stats below)
[2024-10-08 15:58:48,846][train][INFO] - {"epoch": 374, "train_loss": "0.799", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "126582", "train_ups": "0.48", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "179074", "train_lr": "0.000300171", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "561", "train_gb_free": "40.1", "train_wall": "337721"}
[2024-10-08 15:58:49,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 15:58:49,230][fairseq.trainer][INFO] - begin training epoch 375
[2024-10-08 15:58:49,230][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:07:36,086][train_inner][INFO] - {"epoch": 375, "update": 374.263, "loss": "0.8", "ntokens": "262724", "nsentences": "1766.56", "wps": "84901.6", "ups": "0.32", "wpb": "262724", "bsz": "1766.6", "num_updates": "179200", "lr": "0.0003", "gnorm": "0.277", "loss_scale": "2", "train_wall": "233", "gb_free": "39", "wall": "338248"}
[2024-10-08 16:11:08,287][train_inner][INFO] - {"epoch": 375, "update": 374.681, "loss": "0.799", "ntokens": "263983", "nsentences": "1765.57", "wps": "248855", "ups": "0.94", "wpb": "263983", "bsz": "1765.6", "num_updates": "179400", "lr": "0.000299728", "gnorm": "0.273", "loss_scale": "2", "train_wall": "207", "gb_free": "39.6", "wall": "338460"}
[2024-10-08 16:14:11,448][fairseq_cli.train][INFO] - end of epoch 375 (average epoch stats below)
[2024-10-08 16:14:11,478][train][INFO] - {"epoch": 375, "train_loss": "0.799", "train_ntokens": "263548", "train_nsentences": "1753.71", "train_wps": "136831", "train_ups": "0.52", "train_wpb": "263548", "train_bsz": "1753.7", "train_num_updates": "179553", "train_lr": "0.00029952", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "527", "train_gb_free": "39.1", "train_wall": "338644"}
[2024-10-08 16:14:11,584][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:14:11,612][fairseq.trainer][INFO] - begin training epoch 376
[2024-10-08 16:14:11,612][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:21:00,744][train_inner][INFO] - {"epoch": 376, "update": 375.098, "loss": "0.799", "ntokens": "262926", "nsentences": "1738.41", "wps": "88760.3", "ups": "0.34", "wpb": "262926", "bsz": "1738.4", "num_updates": "179600", "lr": "0.000299457", "gnorm": "0.274", "loss_scale": "2", "train_wall": "247", "gb_free": "39.1", "wall": "339053"}
[2024-10-08 16:24:36,934][train_inner][INFO] - {"epoch": 376, "update": 375.516, "loss": "0.796", "ntokens": "264173", "nsentences": "1729.73", "wps": "244419", "ups": "0.93", "wpb": "264173", "bsz": "1729.7", "num_updates": "179800", "lr": "0.000299185", "gnorm": "0.269", "loss_scale": "2", "train_wall": "206", "gb_free": "41", "wall": "339269"}
[2024-10-08 16:28:19,040][train_inner][INFO] - {"epoch": 376, "update": 375.933, "loss": "0.801", "ntokens": "263928", "nsentences": "1769.1", "wps": "237683", "ups": "0.9", "wpb": "263928", "bsz": "1769.1", "num_updates": "180000", "lr": "0.000298913", "gnorm": "0.276", "loss_scale": "2", "train_wall": "216", "gb_free": "41.1", "wall": "339491"}
[2024-10-08 16:29:15,614][fairseq_cli.train][INFO] - end of epoch 376 (average epoch stats below)
[2024-10-08 16:29:15,650][train][INFO] - {"epoch": 376, "train_loss": "0.799", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "139607", "train_ups": "0.53", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "180032", "train_lr": "0.00029887", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "549", "train_gb_free": "39.7", "train_wall": "339548"}
[2024-10-08 16:29:16,133][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:29:16,187][fairseq.trainer][INFO] - begin training epoch 377
[2024-10-08 16:29:16,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:38:15,450][train_inner][INFO] - {"epoch": 377, "update": 376.351, "loss": "0.797", "ntokens": "262947", "nsentences": "1768.87", "wps": "88182.4", "ups": "0.34", "wpb": "262947", "bsz": "1768.9", "num_updates": "180200", "lr": "0.000298641", "gnorm": "0.279", "loss_scale": "4", "train_wall": "216", "gb_free": "40.5", "wall": "340088"}
[2024-10-08 16:38:34,567][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 16:42:09,796][train_inner][INFO] - {"epoch": 377, "update": 376.77, "loss": "0.799", "ntokens": "263898", "nsentences": "1749.67", "wps": "225238", "ups": "0.85", "wpb": "263898", "bsz": "1749.7", "num_updates": "180400", "lr": "0.00029837", "gnorm": "0.252", "loss_scale": "2", "train_wall": "168", "gb_free": "39.3", "wall": "340322"}
[2024-10-08 16:44:21,638][fairseq_cli.train][INFO] - end of epoch 377 (average epoch stats below)
[2024-10-08 16:44:21,674][train][INFO] - {"epoch": 377, "train_loss": "0.798", "train_ntokens": "263571", "train_nsentences": "1753.13", "train_wps": "139069", "train_ups": "0.53", "train_wpb": "263571", "train_bsz": "1753.1", "train_num_updates": "180510", "train_lr": "0.00029822", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "420", "train_gb_free": "39.6", "train_wall": "340454"}
[2024-10-08 16:44:21,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:44:21,968][fairseq.trainer][INFO] - begin training epoch 378
[2024-10-08 16:44:21,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 16:52:03,133][train_inner][INFO] - {"epoch": 378, "update": 377.188, "loss": "0.8", "ntokens": "262758", "nsentences": "1759.63", "wps": "88571.8", "ups": "0.34", "wpb": "262758", "bsz": "1759.6", "num_updates": "180600", "lr": "0.000298098", "gnorm": "0.27", "loss_scale": "2", "train_wall": "208", "gb_free": "39.6", "wall": "340915"}
[2024-10-08 16:55:47,431][train_inner][INFO] - {"epoch": 378, "update": 377.605, "loss": "0.797", "ntokens": "264163", "nsentences": "1730.97", "wps": "235571", "ups": "0.89", "wpb": "264163", "bsz": "1731", "num_updates": "180800", "lr": "0.000297826", "gnorm": "0.276", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "341140"}
[2024-10-08 16:59:31,258][fairseq_cli.train][INFO] - end of epoch 378 (average epoch stats below)
[2024-10-08 16:59:31,293][train][INFO] - {"epoch": 378, "train_loss": "0.799", "train_ntokens": "263515", "train_nsentences": "1753.71", "train_wps": "138773", "train_ups": "0.53", "train_wpb": "263515", "train_bsz": "1753.7", "train_num_updates": "180989", "train_lr": "0.000297569", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "525", "train_gb_free": "39.8", "train_wall": "341363"}
[2024-10-08 16:59:31,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 16:59:31,443][fairseq.trainer][INFO] - begin training epoch 379
[2024-10-08 16:59:31,444][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:05:35,791][train_inner][INFO] - {"epoch": 379, "update": 378.023, "loss": "0.801", "ntokens": "262892", "nsentences": "1752.9", "wps": "89366.8", "ups": "0.34", "wpb": "262892", "bsz": "1752.9", "num_updates": "181000", "lr": "0.000297554", "gnorm": "0.269", "loss_scale": "2", "train_wall": "202", "gb_free": "40", "wall": "341728"}
[2024-10-08 17:09:29,940][train_inner][INFO] - {"epoch": 379, "update": 378.441, "loss": "0.797", "ntokens": "263929", "nsentences": "1771.9", "wps": "225472", "ups": "0.85", "wpb": "263929", "bsz": "1771.9", "num_updates": "181200", "lr": "0.000297283", "gnorm": "0.262", "loss_scale": "2", "train_wall": "170", "gb_free": "40.1", "wall": "341962"}
[2024-10-08 17:13:43,615][train_inner][INFO] - {"epoch": 379, "update": 378.858, "loss": "0.799", "ntokens": "263657", "nsentences": "1753.96", "wps": "207881", "ups": "0.79", "wpb": "263657", "bsz": "1754", "num_updates": "181400", "lr": "0.000297011", "gnorm": "0.264", "loss_scale": "2", "train_wall": "143", "gb_free": "39.6", "wall": "342216"}
[2024-10-08 17:15:05,964][fairseq_cli.train][INFO] - end of epoch 379 (average epoch stats below)
[2024-10-08 17:15:06,350][train][INFO] - {"epoch": 379, "train_loss": "0.798", "train_ntokens": "263391", "train_nsentences": "1753.71", "train_wps": "134942", "train_ups": "0.51", "train_wpb": "263391", "train_bsz": "1753.7", "train_num_updates": "181468", "train_lr": "0.000296918", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "385", "train_gb_free": "40", "train_wall": "342298"}
[2024-10-08 17:15:06,829][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 17:15:06,887][fairseq.trainer][INFO] - begin training epoch 380
[2024-10-08 17:15:06,888][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:23:33,448][train_inner][INFO] - {"epoch": 380, "update": 379.276, "loss": "0.797", "ntokens": "262612", "nsentences": "1756.46", "wps": "89053.6", "ups": "0.34", "wpb": "262612", "bsz": "1756.5", "num_updates": "181600", "lr": "0.000296739", "gnorm": "0.286", "loss_scale": "2", "train_wall": "215", "gb_free": "39.8", "wall": "342806"}
[2024-10-08 17:27:14,747][train_inner][INFO] - {"epoch": 380, "update": 379.693, "loss": "0.796", "ntokens": "264180", "nsentences": "1725.85", "wps": "238772", "ups": "0.9", "wpb": "264180", "bsz": "1725.9", "num_updates": "181800", "lr": "0.000296467", "gnorm": "0.271", "loss_scale": "2", "train_wall": "215", "gb_free": "40.2", "wall": "343027"}
[2024-10-08 17:30:07,117][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 380 @ 181947 updates
[2024-10-08 17:30:07,146][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 17:30:27,566][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 17:30:28,482][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 380 @ 181947 updates, score None) (writing took 21.36498957592994 seconds)
[2024-10-08 17:30:28,482][fairseq_cli.train][INFO] - end of epoch 380 (average epoch stats below)
[2024-10-08 17:30:28,509][train][INFO] - {"epoch": 380, "train_loss": "0.798", "train_ntokens": "263463", "train_nsentences": "1753.71", "train_wps": "136856", "train_ups": "0.52", "train_wpb": "263463", "train_bsz": "1753.7", "train_num_updates": "181947", "train_lr": "0.000296268", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "537", "train_gb_free": "40", "train_wall": "343221"}
[2024-10-08 17:30:28,982][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 17:30:28,993][fairseq.trainer][INFO] - begin training epoch 381
[2024-10-08 17:30:28,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:36:57,522][train_inner][INFO] - {"epoch": 381, "update": 380.111, "loss": "0.799", "ntokens": "262894", "nsentences": "1744.85", "wps": "90230.9", "ups": "0.34", "wpb": "262894", "bsz": "1744.9", "num_updates": "182000", "lr": "0.000296196", "gnorm": "0.259", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "343610"}
[2024-10-08 17:40:32,335][train_inner][INFO] - {"epoch": 381, "update": 380.528, "loss": "0.799", "ntokens": "263730", "nsentences": "1814.02", "wps": "245567", "ups": "0.93", "wpb": "263730", "bsz": "1814", "num_updates": "182200", "lr": "0.000295924", "gnorm": "0.25", "loss_scale": "2", "train_wall": "209", "gb_free": "39.6", "wall": "343825"}
[2024-10-08 17:44:16,860][train_inner][INFO] - {"epoch": 381, "update": 380.946, "loss": "0.798", "ntokens": "264385", "nsentences": "1709.26", "wps": "235531", "ups": "0.89", "wpb": "264386", "bsz": "1709.3", "num_updates": "182400", "lr": "0.000295652", "gnorm": "0.269", "loss_scale": "4", "train_wall": "218", "gb_free": "40.8", "wall": "344049"}
[2024-10-08 17:44:57,946][fairseq_cli.train][INFO] - end of epoch 381 (average epoch stats below)
[2024-10-08 17:44:57,958][train][INFO] - {"epoch": 381, "train_loss": "0.798", "train_ntokens": "263554", "train_nsentences": "1753.71", "train_wps": "145208", "train_ups": "0.55", "train_wpb": "263554", "train_bsz": "1753.7", "train_num_updates": "182426", "train_lr": "0.000295617", "train_gnorm": "0.259", "train_loss_scale": "4", "train_train_wall": "529", "train_gb_free": "40.6", "train_wall": "344090"}
[2024-10-08 17:44:58,063][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 17:44:58,070][fairseq.trainer][INFO] - begin training epoch 382
[2024-10-08 17:44:58,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 17:52:14,483][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 17:54:03,360][train_inner][INFO] - {"epoch": 382, "update": 381.365, "loss": "0.799", "ntokens": "262653", "nsentences": "1765.09", "wps": "89569.2", "ups": "0.34", "wpb": "262653", "bsz": "1765.1", "num_updates": "182600", "lr": "0.00029538", "gnorm": "0.261", "loss_scale": "2", "train_wall": "247", "gb_free": "39.1", "wall": "344636"}
[2024-10-08 17:57:59,157][train_inner][INFO] - {"epoch": 382, "update": 381.783, "loss": "0.797", "ntokens": "264080", "nsentences": "1754.78", "wps": "223999", "ups": "0.85", "wpb": "264080", "bsz": "1754.8", "num_updates": "182800", "lr": "0.000295109", "gnorm": "0.269", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "344871"}
[2024-10-08 18:00:20,323][fairseq_cli.train][INFO] - end of epoch 382 (average epoch stats below)
[2024-10-08 18:00:20,337][train][INFO] - {"epoch": 382, "train_loss": "0.798", "train_ntokens": "263462", "train_nsentences": "1755.22", "train_wps": "136534", "train_ups": "0.52", "train_wpb": "263462", "train_bsz": "1755.2", "train_num_updates": "182904", "train_lr": "0.000294967", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "345013"}
[2024-10-08 18:00:20,428][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:00:20,447][fairseq.trainer][INFO] - begin training epoch 383
[2024-10-08 18:00:20,448][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:08:25,682][train_inner][INFO] - {"epoch": 383, "update": 382.2, "loss": "0.799", "ntokens": "262404", "nsentences": "1777.18", "wps": "83766.3", "ups": "0.32", "wpb": "262404", "bsz": "1777.2", "num_updates": "183000", "lr": "0.000294837", "gnorm": "0.274", "loss_scale": "2", "train_wall": "249", "gb_free": "39.3", "wall": "345498"}
[2024-10-08 18:12:11,111][train_inner][INFO] - {"epoch": 383, "update": 382.618, "loss": "0.798", "ntokens": "263799", "nsentences": "1777.6", "wps": "234075", "ups": "0.89", "wpb": "263799", "bsz": "1777.6", "num_updates": "183200", "lr": "0.000294565", "gnorm": "0.27", "loss_scale": "2", "train_wall": "220", "gb_free": "40.1", "wall": "345723"}
[2024-10-08 18:15:29,179][fairseq_cli.train][INFO] - end of epoch 383 (average epoch stats below)
[2024-10-08 18:15:29,198][train][INFO] - {"epoch": 383, "train_loss": "0.798", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "138891", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "183383", "train_lr": "0.000294317", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "522", "train_gb_free": "39.3", "train_wall": "345921"}
[2024-10-08 18:15:29,272][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:15:29,300][fairseq.trainer][INFO] - begin training epoch 384
[2024-10-08 18:15:29,300][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:23:32,170][train_inner][INFO] - {"epoch": 384, "update": 383.035, "loss": "0.796", "ntokens": "263481", "nsentences": "1685.59", "wps": "77377.8", "ups": "0.29", "wpb": "263481", "bsz": "1685.6", "num_updates": "183400", "lr": "0.000294293", "gnorm": "0.269", "loss_scale": "2", "train_wall": "211", "gb_free": "39.7", "wall": "346404"}
[2024-10-08 18:27:07,473][train_inner][INFO] - {"epoch": 384, "update": 383.453, "loss": "0.795", "ntokens": "264133", "nsentences": "1750", "wps": "245375", "ups": "0.93", "wpb": "264133", "bsz": "1750", "num_updates": "183600", "lr": "0.000294022", "gnorm": "0.274", "loss_scale": "2", "train_wall": "209", "gb_free": "39.6", "wall": "346620"}
[2024-10-08 18:30:58,091][train_inner][INFO] - {"epoch": 384, "update": 383.871, "loss": "0.801", "ntokens": "263763", "nsentences": "1784.88", "wps": "228789", "ups": "0.87", "wpb": "263763", "bsz": "1784.9", "num_updates": "183800", "lr": "0.00029375", "gnorm": "0.25", "loss_scale": "2", "train_wall": "216", "gb_free": "39.3", "wall": "346850"}
[2024-10-08 18:32:22,957][fairseq_cli.train][INFO] - end of epoch 384 (average epoch stats below)
[2024-10-08 18:32:23,110][train][INFO] - {"epoch": 384, "train_loss": "0.798", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "124514", "train_ups": "0.47", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "183862", "train_lr": "0.000293666", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "524", "train_gb_free": "40.1", "train_wall": "346935"}
[2024-10-08 18:32:23,276][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:32:23,319][fairseq.trainer][INFO] - begin training epoch 385
[2024-10-08 18:32:23,320][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:41:59,519][train_inner][INFO] - {"epoch": 385, "update": 384.288, "loss": "0.795", "ntokens": "263009", "nsentences": "1731.71", "wps": "79529.7", "ups": "0.3", "wpb": "263009", "bsz": "1731.7", "num_updates": "184000", "lr": "0.000293478", "gnorm": "0.274", "loss_scale": "2", "train_wall": "246", "gb_free": "39.6", "wall": "347512"}
[2024-10-08 18:45:50,980][train_inner][INFO] - {"epoch": 385, "update": 384.706, "loss": "0.798", "ntokens": "263622", "nsentences": "1786.24", "wps": "227811", "ups": "0.86", "wpb": "263622", "bsz": "1786.2", "num_updates": "184200", "lr": "0.000293207", "gnorm": "0.273", "loss_scale": "2", "train_wall": "135", "gb_free": "39.7", "wall": "347743"}
[2024-10-08 18:48:38,611][fairseq_cli.train][INFO] - end of epoch 385 (average epoch stats below)
[2024-10-08 18:48:38,918][train][INFO] - {"epoch": 385, "train_loss": "0.797", "train_ntokens": "263407", "train_nsentences": "1753.71", "train_wps": "129302", "train_ups": "0.49", "train_wpb": "263407", "train_bsz": "1753.7", "train_num_updates": "184341", "train_lr": "0.000293015", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "399", "train_gb_free": "40", "train_wall": "347911"}
[2024-10-08 18:48:41,214][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 18:48:41,278][fairseq.trainer][INFO] - begin training epoch 386
[2024-10-08 18:48:41,282][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 18:56:43,824][train_inner][INFO] - {"epoch": 386, "update": 385.123, "loss": "0.797", "ntokens": "262839", "nsentences": "1732.57", "wps": "80523.2", "ups": "0.31", "wpb": "262839", "bsz": "1732.6", "num_updates": "184400", "lr": "0.000292935", "gnorm": "0.288", "loss_scale": "2", "train_wall": "178", "gb_free": "40.5", "wall": "348396"}
[2024-10-08 19:00:02,227][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-08 19:00:32,382][train_inner][INFO] - {"epoch": 386, "update": 385.543, "loss": "0.795", "ntokens": "263991", "nsentences": "1761.59", "wps": "231030", "ups": "0.88", "wpb": "263991", "bsz": "1761.6", "num_updates": "184600", "lr": "0.000292663", "gnorm": "0.277", "loss_scale": "2", "train_wall": "223", "gb_free": "39.3", "wall": "348625"}
[2024-10-08 19:02:01,934][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 19:04:05,506][train_inner][INFO] - {"epoch": 386, "update": 385.962, "loss": "0.798", "ntokens": "263885", "nsentences": "1755.15", "wps": "247649", "ups": "0.94", "wpb": "263885", "bsz": "1755.2", "num_updates": "184800", "lr": "0.000292391", "gnorm": "0.266", "loss_scale": "1", "train_wall": "187", "gb_free": "39.3", "wall": "348838"}
[2024-10-08 19:04:42,953][fairseq_cli.train][INFO] - end of epoch 386 (average epoch stats below)
[2024-10-08 19:04:42,962][train][INFO] - {"epoch": 386, "train_loss": "0.797", "train_ntokens": "263465", "train_nsentences": "1752.52", "train_wps": "130363", "train_ups": "0.49", "train_wpb": "263465", "train_bsz": "1752.5", "train_num_updates": "184818", "train_lr": "0.000292367", "train_gnorm": "0.275", "train_loss_scale": "1", "train_train_wall": "521", "train_gb_free": "39.3", "train_wall": "348875"}
[2024-10-08 19:04:43,064][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 19:04:43,091][fairseq.trainer][INFO] - begin training epoch 387
[2024-10-08 19:04:43,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:18:01,133][train_inner][INFO] - {"epoch": 387, "update": 386.38, "loss": "0.793", "ntokens": "262937", "nsentences": "1740.49", "wps": "62932.4", "ups": "0.24", "wpb": "262938", "bsz": "1740.5", "num_updates": "185000", "lr": "0.00029212", "gnorm": "0.266", "loss_scale": "1", "train_wall": "221", "gb_free": "39.3", "wall": "349673"}
[2024-10-08 19:21:45,402][train_inner][INFO] - {"epoch": 387, "update": 386.797, "loss": "0.797", "ntokens": "263938", "nsentences": "1742.85", "wps": "235386", "ups": "0.89", "wpb": "263938", "bsz": "1742.9", "num_updates": "185200", "lr": "0.000291848", "gnorm": "0.258", "loss_scale": "1", "train_wall": "219", "gb_free": "39.8", "wall": "349898"}
[2024-10-08 19:23:43,880][fairseq_cli.train][INFO] - end of epoch 387 (average epoch stats below)
[2024-10-08 19:23:43,902][train][INFO] - {"epoch": 387, "train_loss": "0.797", "train_ntokens": "263431", "train_nsentences": "1753.71", "train_wps": "110598", "train_ups": "0.42", "train_wpb": "263431", "train_bsz": "1753.7", "train_num_updates": "185297", "train_lr": "0.000291716", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "524", "train_gb_free": "39.3", "train_wall": "350016"}
[2024-10-08 19:23:44,025][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 19:23:44,049][fairseq.trainer][INFO] - begin training epoch 388
[2024-10-08 19:23:44,050][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:31:59,795][train_inner][INFO] - {"epoch": 388, "update": 387.215, "loss": "0.8", "ntokens": "262301", "nsentences": "1787.18", "wps": "85387.2", "ups": "0.33", "wpb": "262301", "bsz": "1787.2", "num_updates": "185400", "lr": "0.000291576", "gnorm": "0.26", "loss_scale": "1", "train_wall": "188", "gb_free": "40", "wall": "350512"}
[2024-10-08 19:35:28,152][train_inner][INFO] - {"epoch": 388, "update": 387.633, "loss": "0.794", "ntokens": "264449", "nsentences": "1704.45", "wps": "253855", "ups": "0.96", "wpb": "264449", "bsz": "1704.5", "num_updates": "185600", "lr": "0.000291304", "gnorm": "0.257", "loss_scale": "1", "train_wall": "203", "gb_free": "40.1", "wall": "350720"}
[2024-10-08 19:38:58,406][fairseq_cli.train][INFO] - end of epoch 388 (average epoch stats below)
[2024-10-08 19:38:58,437][train][INFO] - {"epoch": 388, "train_loss": "0.797", "train_ntokens": "263455", "train_nsentences": "1753.71", "train_wps": "137989", "train_ups": "0.52", "train_wpb": "263455", "train_bsz": "1753.7", "train_num_updates": "185776", "train_lr": "0.000291065", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "480", "train_gb_free": "39.3", "train_wall": "350931"}
[2024-10-08 19:38:58,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 19:38:58,668][fairseq.trainer][INFO] - begin training epoch 389
[2024-10-08 19:38:58,669][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 19:47:05,682][train_inner][INFO] - {"epoch": 389, "update": 388.05, "loss": "0.799", "ntokens": "262680", "nsentences": "1770.07", "wps": "75318.9", "ups": "0.29", "wpb": "262680", "bsz": "1770.1", "num_updates": "185800", "lr": "0.000291033", "gnorm": "0.266", "loss_scale": "1", "train_wall": "240", "gb_free": "39.3", "wall": "351418"}
[2024-10-08 19:50:22,970][train_inner][INFO] - {"epoch": 389, "update": 388.468, "loss": "0.796", "ntokens": "263633", "nsentences": "1777.65", "wps": "267274", "ups": "1.01", "wpb": "263633", "bsz": "1777.7", "num_updates": "186000", "lr": "0.000290761", "gnorm": "0.27", "loss_scale": "1", "train_wall": "191", "gb_free": "39.8", "wall": "351615"}
[2024-10-08 19:54:26,858][train_inner][INFO] - {"epoch": 389, "update": 388.885, "loss": "0.798", "ntokens": "264036", "nsentences": "1764.81", "wps": "216540", "ups": "0.82", "wpb": "264036", "bsz": "1764.8", "num_updates": "186200", "lr": "0.000290489", "gnorm": "0.275", "loss_scale": "1", "train_wall": "239", "gb_free": "40.2", "wall": "351859"}
[2024-10-08 19:55:36,581][fairseq_cli.train][INFO] - end of epoch 389 (average epoch stats below)
[2024-10-08 19:55:36,588][train][INFO] - {"epoch": 389, "train_loss": "0.796", "train_ntokens": "263501", "train_nsentences": "1753.71", "train_wps": "126454", "train_ups": "0.48", "train_wpb": "263501", "train_bsz": "1753.7", "train_num_updates": "186255", "train_lr": "0.000290414", "train_gnorm": "0.277", "train_loss_scale": "1", "train_train_wall": "533", "train_gb_free": "39.7", "train_wall": "351929"}
[2024-10-08 19:55:36,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 19:55:36,664][fairseq.trainer][INFO] - begin training epoch 390
[2024-10-08 19:55:36,665][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:04:31,255][train_inner][INFO] - {"epoch": 390, "update": 389.303, "loss": "0.794", "ntokens": "262860", "nsentences": "1742.05", "wps": "86986", "ups": "0.33", "wpb": "262860", "bsz": "1742", "num_updates": "186400", "lr": "0.000290217", "gnorm": "0.282", "loss_scale": "1", "train_wall": "232", "gb_free": "39.3", "wall": "352463"}
[2024-10-08 20:08:25,081][train_inner][INFO] - {"epoch": 390, "update": 389.72, "loss": "0.795", "ntokens": "263876", "nsentences": "1747.52", "wps": "225711", "ups": "0.86", "wpb": "263876", "bsz": "1747.5", "num_updates": "186600", "lr": "0.000289946", "gnorm": "0.266", "loss_scale": "1", "train_wall": "228", "gb_free": "39.3", "wall": "352697"}
[2024-10-08 20:11:12,164][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 390 @ 186734 updates
[2024-10-08 20:11:12,170][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 20:11:18,651][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 20:11:18,699][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 390 @ 186734 updates, score None) (writing took 6.535412415862083 seconds)
[2024-10-08 20:11:18,700][fairseq_cli.train][INFO] - end of epoch 390 (average epoch stats below)
[2024-10-08 20:11:18,708][train][INFO] - {"epoch": 390, "train_loss": "0.796", "train_ntokens": "263352", "train_nsentences": "1753.71", "train_wps": "133898", "train_ups": "0.51", "train_wpb": "263352", "train_bsz": "1753.7", "train_num_updates": "186734", "train_lr": "0.000289764", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.6", "train_wall": "352871"}
[2024-10-08 20:11:18,792][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:11:18,845][fairseq.trainer][INFO] - begin training epoch 391
[2024-10-08 20:11:18,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:19:32,041][train_inner][INFO] - {"epoch": 391, "update": 390.138, "loss": "0.798", "ntokens": "262727", "nsentences": "1750.93", "wps": "78786.1", "ups": "0.3", "wpb": "262727", "bsz": "1750.9", "num_updates": "186800", "lr": "0.000289674", "gnorm": "0.268", "loss_scale": "2", "train_wall": "248", "gb_free": "40.1", "wall": "353364"}
[2024-10-08 20:22:46,873][train_inner][INFO] - {"epoch": 391, "update": 390.555, "loss": "0.793", "ntokens": "264201", "nsentences": "1733.26", "wps": "271220", "ups": "1.03", "wpb": "264201", "bsz": "1733.3", "num_updates": "187000", "lr": "0.000289402", "gnorm": "0.262", "loss_scale": "2", "train_wall": "189", "gb_free": "39.8", "wall": "353559"}
[2024-10-08 20:26:35,475][train_inner][INFO] - {"epoch": 391, "update": 390.973, "loss": "0.799", "ntokens": "263695", "nsentences": "1781.12", "wps": "230731", "ups": "0.87", "wpb": "263695", "bsz": "1781.1", "num_updates": "187200", "lr": "0.00028913", "gnorm": "0.278", "loss_scale": "2", "train_wall": "223", "gb_free": "39.3", "wall": "353788"}
[2024-10-08 20:27:16,373][fairseq_cli.train][INFO] - end of epoch 391 (average epoch stats below)
[2024-10-08 20:27:16,390][train][INFO] - {"epoch": 391, "train_loss": "0.796", "train_ntokens": "263455", "train_nsentences": "1753.71", "train_wps": "131776", "train_ups": "0.5", "train_wpb": "263455", "train_bsz": "1753.7", "train_num_updates": "187213", "train_lr": "0.000289113", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "537", "train_gb_free": "40", "train_wall": "353829"}
[2024-10-08 20:27:16,655][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:27:16,670][fairseq.trainer][INFO] - begin training epoch 392
[2024-10-08 20:27:16,671][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:37:42,464][train_inner][INFO] - {"epoch": 392, "update": 391.39, "loss": "0.794", "ntokens": "262883", "nsentences": "1754.45", "wps": "78831.4", "ups": "0.3", "wpb": "262883", "bsz": "1754.5", "num_updates": "187400", "lr": "0.000288859", "gnorm": "0.263", "loss_scale": "2", "train_wall": "249", "gb_free": "39.3", "wall": "354455"}
[2024-10-08 20:41:33,262][train_inner][INFO] - {"epoch": 392, "update": 391.808, "loss": "0.796", "ntokens": "264092", "nsentences": "1743.47", "wps": "228871", "ups": "0.87", "wpb": "264092", "bsz": "1743.5", "num_updates": "187600", "lr": "0.000288587", "gnorm": "0.274", "loss_scale": "2", "train_wall": "226", "gb_free": "39.2", "wall": "354685"}
[2024-10-08 20:43:14,978][fairseq_cli.train][INFO] - end of epoch 392 (average epoch stats below)
[2024-10-08 20:43:15,015][train][INFO] - {"epoch": 392, "train_loss": "0.796", "train_ntokens": "263558", "train_nsentences": "1753.71", "train_wps": "131696", "train_ups": "0.5", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "187692", "train_lr": "0.000288462", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "534", "train_gb_free": "40.5", "train_wall": "354787"}
[2024-10-08 20:43:15,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:43:15,158][fairseq.trainer][INFO] - begin training epoch 393
[2024-10-08 20:43:15,159][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 20:52:21,519][train_inner][INFO] - {"epoch": 393, "update": 392.225, "loss": "0.794", "ntokens": "262818", "nsentences": "1746.79", "wps": "81086.2", "ups": "0.31", "wpb": "262818", "bsz": "1746.8", "num_updates": "187800", "lr": "0.000288315", "gnorm": "0.26", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "355334"}
[2024-10-08 20:55:59,229][train_inner][INFO] - {"epoch": 393, "update": 392.643, "loss": "0.795", "ntokens": "264018", "nsentences": "1749.51", "wps": "242557", "ups": "0.92", "wpb": "264018", "bsz": "1749.5", "num_updates": "188000", "lr": "0.000288043", "gnorm": "0.272", "loss_scale": "2", "train_wall": "147", "gb_free": "39.8", "wall": "355551"}
[2024-10-08 20:59:33,109][fairseq_cli.train][INFO] - end of epoch 393 (average epoch stats below)
[2024-10-08 20:59:33,112][train][INFO] - {"epoch": 393, "train_loss": "0.795", "train_ntokens": "263428", "train_nsentences": "1753.71", "train_wps": "129008", "train_ups": "0.49", "train_wpb": "263428", "train_bsz": "1753.7", "train_num_updates": "188171", "train_lr": "0.000287811", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "427", "train_gb_free": "39.3", "train_wall": "355765"}
[2024-10-08 20:59:33,177][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 20:59:33,219][fairseq.trainer][INFO] - begin training epoch 394
[2024-10-08 20:59:33,219][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:07:38,342][train_inner][INFO] - {"epoch": 394, "update": 393.061, "loss": "0.798", "ntokens": "262744", "nsentences": "1753.24", "wps": "75170.9", "ups": "0.29", "wpb": "262744", "bsz": "1753.2", "num_updates": "188200", "lr": "0.000287772", "gnorm": "0.262", "loss_scale": "2", "train_wall": "194", "gb_free": "39.6", "wall": "356251"}
[2024-10-08 21:09:46,495][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 21:11:10,206][train_inner][INFO] - {"epoch": 394, "update": 393.48, "loss": "0.795", "ntokens": "263913", "nsentences": "1788.83", "wps": "249161", "ups": "0.94", "wpb": "263913", "bsz": "1788.8", "num_updates": "188400", "lr": "0.0002875", "gnorm": "0.277", "loss_scale": "1", "train_wall": "206", "gb_free": "39.8", "wall": "356462"}
[2024-10-08 21:15:01,730][train_inner][INFO] - {"epoch": 394, "update": 393.898, "loss": "0.796", "ntokens": "263892", "nsentences": "1766.63", "wps": "227967", "ups": "0.86", "wpb": "263892", "bsz": "1766.6", "num_updates": "188600", "lr": "0.000287228", "gnorm": "0.282", "loss_scale": "1", "train_wall": "226", "gb_free": "39.1", "wall": "356694"}
[2024-10-08 21:16:12,888][fairseq_cli.train][INFO] - end of epoch 394 (average epoch stats below)
[2024-10-08 21:16:12,954][train][INFO] - {"epoch": 394, "train_loss": "0.795", "train_ntokens": "263638", "train_nsentences": "1751.01", "train_wps": "126041", "train_ups": "0.48", "train_wpb": "263638", "train_bsz": "1751", "train_num_updates": "188649", "train_lr": "0.000287162", "train_gnorm": "0.282", "train_loss_scale": "1", "train_train_wall": "536", "train_gb_free": "40.2", "train_wall": "356765"}
[2024-10-08 21:16:13,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:16:13,183][fairseq.trainer][INFO] - begin training epoch 395
[2024-10-08 21:16:13,184][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:24:34,716][train_inner][INFO] - {"epoch": 395, "update": 394.315, "loss": "0.792", "ntokens": "263403", "nsentences": "1686.46", "wps": "91942", "ups": "0.35", "wpb": "263403", "bsz": "1686.5", "num_updates": "188800", "lr": "0.000286957", "gnorm": "0.283", "loss_scale": "1", "train_wall": "211", "gb_free": "40.1", "wall": "357267"}
[2024-10-08 21:28:24,960][train_inner][INFO] - {"epoch": 395, "update": 394.733, "loss": "0.796", "ntokens": "264073", "nsentences": "1772.38", "wps": "229397", "ups": "0.87", "wpb": "264073", "bsz": "1772.4", "num_updates": "189000", "lr": "0.000286685", "gnorm": "0.274", "loss_scale": "1", "train_wall": "173", "gb_free": "39.6", "wall": "357497"}
[2024-10-08 21:31:18,100][fairseq_cli.train][INFO] - end of epoch 395 (average epoch stats below)
[2024-10-08 21:31:18,104][train][INFO] - {"epoch": 395, "train_loss": "0.795", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "139478", "train_ups": "0.53", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "189128", "train_lr": "0.000286511", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "483", "train_gb_free": "39.8", "train_wall": "357670"}
[2024-10-08 21:31:18,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:31:18,211][fairseq.trainer][INFO] - begin training epoch 396
[2024-10-08 21:31:18,211][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:38:18,722][train_inner][INFO] - {"epoch": 396, "update": 395.15, "loss": "0.797", "ntokens": "262679", "nsentences": "1771.75", "wps": "88481.5", "ups": "0.34", "wpb": "262679", "bsz": "1771.8", "num_updates": "189200", "lr": "0.000286413", "gnorm": "0.277", "loss_scale": "1", "train_wall": "275", "gb_free": "40.5", "wall": "358091"}
[2024-10-08 21:41:42,279][train_inner][INFO] - {"epoch": 396, "update": 395.568, "loss": "0.791", "ntokens": "264043", "nsentences": "1724.24", "wps": "259441", "ups": "0.98", "wpb": "264043", "bsz": "1724.2", "num_updates": "189400", "lr": "0.000286141", "gnorm": "0.267", "loss_scale": "1", "train_wall": "198", "gb_free": "40.5", "wall": "358294"}
[2024-10-08 21:46:11,678][train_inner][INFO] - {"epoch": 396, "update": 395.985, "loss": "0.799", "ntokens": "263911", "nsentences": "1777.8", "wps": "195933", "ups": "0.74", "wpb": "263911", "bsz": "1777.8", "num_updates": "189600", "lr": "0.00028587", "gnorm": "0.263", "loss_scale": "1", "train_wall": "265", "gb_free": "40.1", "wall": "358564"}
[2024-10-08 21:46:20,190][fairseq_cli.train][INFO] - end of epoch 396 (average epoch stats below)
[2024-10-08 21:46:20,192][train][INFO] - {"epoch": 396, "train_loss": "0.796", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "139923", "train_ups": "0.53", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "189607", "train_lr": "0.00028586", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "577", "train_gb_free": "39.8", "train_wall": "358572"}
[2024-10-08 21:46:20,291][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 21:46:20,322][fairseq.trainer][INFO] - begin training epoch 397
[2024-10-08 21:46:20,323][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 21:55:30,358][train_inner][INFO] - {"epoch": 397, "update": 396.403, "loss": "0.793", "ntokens": "263018", "nsentences": "1741.27", "wps": "94161.1", "ups": "0.36", "wpb": "263018", "bsz": "1741.3", "num_updates": "189800", "lr": "0.000285598", "gnorm": "0.261", "loss_scale": "1", "train_wall": "250", "gb_free": "39.1", "wall": "359123"}
[2024-10-08 21:59:44,305][train_inner][INFO] - {"epoch": 397, "update": 396.82, "loss": "0.796", "ntokens": "263959", "nsentences": "1763.01", "wps": "207894", "ups": "0.79", "wpb": "263959", "bsz": "1763", "num_updates": "190000", "lr": "0.000285326", "gnorm": "0.276", "loss_scale": "1", "train_wall": "248", "gb_free": "40.1", "wall": "359376"}
[2024-10-08 22:01:32,524][fairseq_cli.train][INFO] - end of epoch 397 (average epoch stats below)
[2024-10-08 22:01:32,551][train][INFO] - {"epoch": 397, "train_loss": "0.795", "train_ntokens": "263587", "train_nsentences": "1753.71", "train_wps": "138388", "train_ups": "0.53", "train_wpb": "263587", "train_bsz": "1753.7", "train_num_updates": "190086", "train_lr": "0.000285209", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "596", "train_gb_free": "39.3", "train_wall": "359485"}
[2024-10-08 22:01:32,705][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:01:32,760][fairseq.trainer][INFO] - begin training epoch 398
[2024-10-08 22:01:32,761][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:09:19,015][train_inner][INFO] - {"epoch": 398, "update": 397.238, "loss": "0.795", "ntokens": "262929", "nsentences": "1756.21", "wps": "91501.7", "ups": "0.35", "wpb": "262929", "bsz": "1756.2", "num_updates": "190200", "lr": "0.000285054", "gnorm": "0.268", "loss_scale": "1", "train_wall": "253", "gb_free": "39.2", "wall": "359951"}
[2024-10-08 22:12:54,584][train_inner][INFO] - {"epoch": 398, "update": 397.656, "loss": "0.794", "ntokens": "264207", "nsentences": "1750.42", "wps": "245143", "ups": "0.93", "wpb": "264206", "bsz": "1750.4", "num_updates": "190400", "lr": "0.000284783", "gnorm": "0.269", "loss_scale": "2", "train_wall": "210", "gb_free": "39.6", "wall": "360167"}
[2024-10-08 22:16:00,819][fairseq_cli.train][INFO] - end of epoch 398 (average epoch stats below)
[2024-10-08 22:16:00,860][train][INFO] - {"epoch": 398, "train_loss": "0.795", "train_ntokens": "263660", "train_nsentences": "1753.71", "train_wps": "145450", "train_ups": "0.55", "train_wpb": "263660", "train_bsz": "1753.7", "train_num_updates": "190565", "train_lr": "0.000284558", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.6", "train_wall": "360353"}
[2024-10-08 22:16:01,071][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:16:01,136][fairseq.trainer][INFO] - begin training epoch 399
[2024-10-08 22:16:01,137][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:22:33,384][train_inner][INFO] - {"epoch": 399, "update": 398.073, "loss": "0.795", "ntokens": "262950", "nsentences": "1748.93", "wps": "90861.8", "ups": "0.35", "wpb": "262950", "bsz": "1748.9", "num_updates": "190600", "lr": "0.000284511", "gnorm": "0.281", "loss_scale": "2", "train_wall": "243", "gb_free": "39.8", "wall": "360746"}
[2024-10-08 22:25:50,592][train_inner][INFO] - {"epoch": 399, "update": 398.491, "loss": "0.794", "ntokens": "263771", "nsentences": "1763.88", "wps": "267518", "ups": "1.01", "wpb": "263771", "bsz": "1763.9", "num_updates": "190800", "lr": "0.000284239", "gnorm": "0.272", "loss_scale": "2", "train_wall": "192", "gb_free": "39.8", "wall": "360943"}
[2024-10-08 22:26:14,092][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-08 22:30:02,028][train_inner][INFO] - {"epoch": 399, "update": 398.91, "loss": "0.794", "ntokens": "263911", "nsentences": "1765.88", "wps": "209932", "ups": "0.8", "wpb": "263912", "bsz": "1765.9", "num_updates": "191000", "lr": "0.000283967", "gnorm": "0.267", "loss_scale": "1", "train_wall": "246", "gb_free": "39.2", "wall": "361194"}
[2024-10-08 22:30:45,160][fairseq_cli.train][INFO] - end of epoch 399 (average epoch stats below)
[2024-10-08 22:30:45,194][train][INFO] - {"epoch": 399, "train_loss": "0.794", "train_ntokens": "263440", "train_nsentences": "1753.42", "train_wps": "142398", "train_ups": "0.54", "train_wpb": "263440", "train_bsz": "1753.4", "train_num_updates": "191043", "train_lr": "0.000283909", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "540", "train_gb_free": "39.8", "train_wall": "361237"}
[2024-10-08 22:30:45,530][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:30:45,551][fairseq.trainer][INFO] - begin training epoch 400
[2024-10-08 22:30:45,552][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:39:36,198][train_inner][INFO] - {"epoch": 400, "update": 399.328, "loss": "0.793", "ntokens": "262903", "nsentences": "1744.45", "wps": "91580", "ups": "0.35", "wpb": "262903", "bsz": "1744.5", "num_updates": "191200", "lr": "0.000283696", "gnorm": "0.276", "loss_scale": "1", "train_wall": "233", "gb_free": "39.3", "wall": "361768"}
[2024-10-08 22:43:02,739][train_inner][INFO] - {"epoch": 400, "update": 399.745, "loss": "0.793", "ntokens": "264163", "nsentences": "1732.38", "wps": "255822", "ups": "0.97", "wpb": "264163", "bsz": "1732.4", "num_updates": "191400", "lr": "0.000283424", "gnorm": "0.264", "loss_scale": "1", "train_wall": "198", "gb_free": "39.3", "wall": "361975"}
[2024-10-08 22:45:37,403][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 400 @ 191522 updates
[2024-10-08 22:45:37,404][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 22:45:43,140][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-08 22:45:43,236][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 400 @ 191522 updates, score None) (writing took 5.8333536414429545 seconds)
[2024-10-08 22:45:43,237][fairseq_cli.train][INFO] - end of epoch 400 (average epoch stats below)
[2024-10-08 22:45:43,241][train][INFO] - {"epoch": 400, "train_loss": "0.794", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "140554", "train_ups": "0.53", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "191522", "train_lr": "0.000283258", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "529", "train_gb_free": "40.3", "train_wall": "362135"}
[2024-10-08 22:45:43,288][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 22:45:43,311][fairseq.trainer][INFO] - begin training epoch 401
[2024-10-08 22:45:43,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 22:52:38,506][train_inner][INFO] - {"epoch": 401, "update": 400.163, "loss": "0.795", "ntokens": "262520", "nsentences": "1770.48", "wps": "91191.9", "ups": "0.35", "wpb": "262520", "bsz": "1770.5", "num_updates": "191600", "lr": "0.000283152", "gnorm": "0.285", "loss_scale": "1", "train_wall": "238", "gb_free": "39.6", "wall": "362551"}
[2024-10-08 22:56:08,044][train_inner][INFO] - {"epoch": 401, "update": 400.58, "loss": "0.795", "ntokens": "263921", "nsentences": "1757.99", "wps": "251926", "ups": "0.95", "wpb": "263921", "bsz": "1758", "num_updates": "191800", "lr": "0.00028288", "gnorm": "0.271", "loss_scale": "1", "train_wall": "204", "gb_free": "40", "wall": "362760"}
[2024-10-08 23:00:55,633][train_inner][INFO] - {"epoch": 401, "update": 400.998, "loss": "0.794", "ntokens": "263984", "nsentences": "1749.86", "wps": "183628", "ups": "0.7", "wpb": "263984", "bsz": "1749.9", "num_updates": "192000", "lr": "0.000282609", "gnorm": "0.274", "loss_scale": "1", "train_wall": "282", "gb_free": "40", "wall": "363048"}
[2024-10-08 23:01:03,137][fairseq_cli.train][INFO] - end of epoch 401 (average epoch stats below)
[2024-10-08 23:01:03,170][train][INFO] - {"epoch": 401, "train_loss": "0.794", "train_ntokens": "263397", "train_nsentences": "1753.71", "train_wps": "137154", "train_ups": "0.52", "train_wpb": "263397", "train_bsz": "1753.7", "train_num_updates": "192001", "train_lr": "0.000282607", "train_gnorm": "0.278", "train_loss_scale": "1", "train_train_wall": "591", "train_gb_free": "40.1", "train_wall": "363055"}
[2024-10-08 23:01:03,396][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:01:03,424][fairseq.trainer][INFO] - begin training epoch 402
[2024-10-08 23:01:03,424][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:10:22,779][train_inner][INFO] - {"epoch": 402, "update": 401.415, "loss": "0.791", "ntokens": "262881", "nsentences": "1741.81", "wps": "92711.6", "ups": "0.35", "wpb": "262881", "bsz": "1741.8", "num_updates": "192200", "lr": "0.000282337", "gnorm": "0.26", "loss_scale": "1", "train_wall": "241", "gb_free": "39.2", "wall": "363615"}
[2024-10-08 23:14:41,658][train_inner][INFO] - {"epoch": 402, "update": 401.833, "loss": "0.795", "ntokens": "263716", "nsentences": "1788.78", "wps": "203749", "ups": "0.77", "wpb": "263716", "bsz": "1788.8", "num_updates": "192400", "lr": "0.000282065", "gnorm": "0.267", "loss_scale": "1", "train_wall": "253", "gb_free": "39.3", "wall": "363874"}
[2024-10-08 23:16:14,622][fairseq_cli.train][INFO] - end of epoch 402 (average epoch stats below)
[2024-10-08 23:16:14,642][train][INFO] - {"epoch": 402, "train_loss": "0.793", "train_ntokens": "263454", "train_nsentences": "1753.71", "train_wps": "138456", "train_ups": "0.53", "train_wpb": "263454", "train_bsz": "1753.7", "train_num_updates": "192480", "train_lr": "0.000281957", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "577", "train_gb_free": "39.2", "train_wall": "363967"}
[2024-10-08 23:16:14,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:16:14,776][fairseq.trainer][INFO] - begin training epoch 403
[2024-10-08 23:16:14,777][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:24:18,282][train_inner][INFO] - {"epoch": 403, "update": 402.251, "loss": "0.791", "ntokens": "263378", "nsentences": "1687.11", "wps": "91353.7", "ups": "0.35", "wpb": "263378", "bsz": "1687.1", "num_updates": "192600", "lr": "0.000281793", "gnorm": "0.271", "loss_scale": "1", "train_wall": "241", "gb_free": "39.7", "wall": "364450"}
[2024-10-08 23:28:02,047][train_inner][INFO] - {"epoch": 403, "update": 402.668, "loss": "0.793", "ntokens": "264120", "nsentences": "1734.74", "wps": "236099", "ups": "0.89", "wpb": "264120", "bsz": "1734.7", "num_updates": "192800", "lr": "0.000281522", "gnorm": "0.276", "loss_scale": "1", "train_wall": "218", "gb_free": "40.5", "wall": "364674"}
[2024-10-08 23:31:49,530][fairseq_cli.train][INFO] - end of epoch 403 (average epoch stats below)
[2024-10-08 23:31:49,567][train][INFO] - {"epoch": 403, "train_loss": "0.793", "train_ntokens": "263493", "train_nsentences": "1753.71", "train_wps": "135000", "train_ups": "0.51", "train_wpb": "263493", "train_bsz": "1753.7", "train_num_updates": "192959", "train_lr": "0.000281306", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "592", "train_gb_free": "40.1", "train_wall": "364902"}
[2024-10-08 23:31:49,745][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:31:49,775][fairseq.trainer][INFO] - begin training epoch 404
[2024-10-08 23:31:49,776][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:38:29,978][train_inner][INFO] - {"epoch": 404, "update": 403.086, "loss": "0.796", "ntokens": "262170", "nsentences": "1808.94", "wps": "83506", "ups": "0.32", "wpb": "262170", "bsz": "1808.9", "num_updates": "193000", "lr": "0.00028125", "gnorm": "0.28", "loss_scale": "2", "train_wall": "309", "gb_free": "39.6", "wall": "365302"}
[2024-10-08 23:42:10,480][train_inner][INFO] - {"epoch": 404, "update": 403.503, "loss": "0.791", "ntokens": "263978", "nsentences": "1763.46", "wps": "239462", "ups": "0.91", "wpb": "263978", "bsz": "1763.5", "num_updates": "193200", "lr": "0.000280978", "gnorm": "0.255", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "365523"}
[2024-10-08 23:45:55,740][train_inner][INFO] - {"epoch": 404, "update": 403.921, "loss": "0.796", "ntokens": "264043", "nsentences": "1760.07", "wps": "234444", "ups": "0.89", "wpb": "264043", "bsz": "1760.1", "num_updates": "193400", "lr": "0.000280707", "gnorm": "0.271", "loss_scale": "2", "train_wall": "220", "gb_free": "40.6", "wall": "365748"}
[2024-10-08 23:46:56,757][fairseq_cli.train][INFO] - end of epoch 404 (average epoch stats below)
[2024-10-08 23:46:56,774][train][INFO] - {"epoch": 404, "train_loss": "0.794", "train_ntokens": "263518", "train_nsentences": "1753.71", "train_wps": "139142", "train_ups": "0.53", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "193438", "train_lr": "0.000280655", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "580", "train_gb_free": "40.1", "train_wall": "365809"}
[2024-10-08 23:46:56,840][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-08 23:46:56,849][fairseq.trainer][INFO] - begin training epoch 405
[2024-10-08 23:46:56,849][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-08 23:55:28,526][train_inner][INFO] - {"epoch": 405, "update": 404.338, "loss": "0.792", "ntokens": "263042", "nsentences": "1728.58", "wps": "91847.8", "ups": "0.35", "wpb": "263042", "bsz": "1728.6", "num_updates": "193600", "lr": "0.000280435", "gnorm": "0.264", "loss_scale": "2", "train_wall": "266", "gb_free": "40", "wall": "366321"}
[2024-10-08 23:59:21,129][train_inner][INFO] - {"epoch": 405, "update": 404.756, "loss": "0.794", "ntokens": "263752", "nsentences": "1784.47", "wps": "226802", "ups": "0.86", "wpb": "263752", "bsz": "1784.5", "num_updates": "193800", "lr": "0.000280163", "gnorm": "0.275", "loss_scale": "2", "train_wall": "227", "gb_free": "39.1", "wall": "366553"}
[2024-10-09 00:01:40,502][fairseq_cli.train][INFO] - end of epoch 405 (average epoch stats below)
[2024-10-09 00:01:40,554][train][INFO] - {"epoch": 405, "train_loss": "0.793", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "142832", "train_ups": "0.54", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "193917", "train_lr": "0.000280004", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.7", "train_wall": "366693"}
[2024-10-09 00:01:40,621][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:01:40,645][fairseq.trainer][INFO] - begin training epoch 406
[2024-10-09 00:01:40,645][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:08:48,546][train_inner][INFO] - {"epoch": 406, "update": 405.173, "loss": "0.794", "ntokens": "263141", "nsentences": "1719.06", "wps": "92754.2", "ups": "0.35", "wpb": "263141", "bsz": "1719.1", "num_updates": "194000", "lr": "0.000279891", "gnorm": "0.266", "loss_scale": "2", "train_wall": "236", "gb_free": "40.1", "wall": "367121"}
[2024-10-09 00:12:26,740][train_inner][INFO] - {"epoch": 406, "update": 405.591, "loss": "0.791", "ntokens": "264167", "nsentences": "1738.89", "wps": "242158", "ups": "0.92", "wpb": "264167", "bsz": "1738.9", "num_updates": "194200", "lr": "0.00027962", "gnorm": "0.262", "loss_scale": "2", "train_wall": "213", "gb_free": "40", "wall": "367339"}
[2024-10-09 00:16:29,750][fairseq_cli.train][INFO] - end of epoch 406 (average epoch stats below)
[2024-10-09 00:16:29,781][train][INFO] - {"epoch": 406, "train_loss": "0.793", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "141961", "train_ups": "0.54", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "194396", "train_lr": "0.000279353", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.2", "train_wall": "367582"}
[2024-10-09 00:16:29,903][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:16:29,935][fairseq.trainer][INFO] - begin training epoch 407
[2024-10-09 00:16:29,936][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:22:14,215][train_inner][INFO] - {"epoch": 407, "update": 406.008, "loss": "0.796", "ntokens": "262498", "nsentences": "1784.42", "wps": "89368.7", "ups": "0.34", "wpb": "262498", "bsz": "1784.4", "num_updates": "194400", "lr": "0.000279348", "gnorm": "0.272", "loss_scale": "2", "train_wall": "265", "gb_free": "40", "wall": "367926"}
[2024-10-09 00:25:29,777][train_inner][INFO] - {"epoch": 407, "update": 406.426, "loss": "0.79", "ntokens": "264149", "nsentences": "1730.78", "wps": "270157", "ups": "1.02", "wpb": "264149", "bsz": "1730.8", "num_updates": "194600", "lr": "0.000279076", "gnorm": "0.268", "loss_scale": "2", "train_wall": "191", "gb_free": "39.3", "wall": "368122"}
[2024-10-09 00:29:27,010][train_inner][INFO] - {"epoch": 407, "update": 406.843, "loss": "0.794", "ntokens": "263884", "nsentences": "1758.85", "wps": "222484", "ups": "0.84", "wpb": "263884", "bsz": "1758.9", "num_updates": "194800", "lr": "0.000278804", "gnorm": "0.27", "loss_scale": "2", "train_wall": "232", "gb_free": "40.1", "wall": "368359"}
[2024-10-09 00:30:58,239][fairseq_cli.train][INFO] - end of epoch 407 (average epoch stats below)
[2024-10-09 00:30:58,286][train][INFO] - {"epoch": 407, "train_loss": "0.792", "train_ntokens": "263393", "train_nsentences": "1753.71", "train_wps": "145272", "train_ups": "0.55", "train_wpb": "263393", "train_bsz": "1753.7", "train_num_updates": "194875", "train_lr": "0.000278702", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "538", "train_gb_free": "39.2", "train_wall": "368450"}
[2024-10-09 00:30:58,427][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:30:58,464][fairseq.trainer][INFO] - begin training epoch 408
[2024-10-09 00:30:58,465][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:38:31,440][train_inner][INFO] - {"epoch": 408, "update": 407.261, "loss": "0.793", "ntokens": "262350", "nsentences": "1792.07", "wps": "96380.1", "ups": "0.37", "wpb": "262350", "bsz": "1792.1", "num_updates": "195000", "lr": "0.000278533", "gnorm": "0.255", "loss_scale": "4", "train_wall": "222", "gb_free": "39.6", "wall": "368904"}
[2024-10-09 00:38:35,257][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 00:42:03,069][train_inner][INFO] - {"epoch": 408, "update": 407.681, "loss": "0.79", "ntokens": "264264", "nsentences": "1723.95", "wps": "249756", "ups": "0.95", "wpb": "264264", "bsz": "1724", "num_updates": "195200", "lr": "0.000278261", "gnorm": "0.258", "loss_scale": "2", "train_wall": "207", "gb_free": "39.3", "wall": "369115"}
[2024-10-09 00:45:23,904][fairseq_cli.train][INFO] - end of epoch 408 (average epoch stats below)
[2024-10-09 00:45:23,938][train][INFO] - {"epoch": 408, "train_loss": "0.793", "train_ntokens": "263493", "train_nsentences": "1754.9", "train_wps": "145501", "train_ups": "0.55", "train_wpb": "263493", "train_bsz": "1754.9", "train_num_updates": "195353", "train_lr": "0.000278053", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.2", "train_wall": "369316"}
[2024-10-09 00:45:24,013][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 00:45:24,030][fairseq.trainer][INFO] - begin training epoch 409
[2024-10-09 00:45:24,031][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 00:51:59,301][train_inner][INFO] - {"epoch": 409, "update": 408.098, "loss": "0.797", "ntokens": "262488", "nsentences": "1790.55", "wps": "88050.5", "ups": "0.34", "wpb": "262488", "bsz": "1790.5", "num_updates": "195400", "lr": "0.000277989", "gnorm": "0.273", "loss_scale": "2", "train_wall": "277", "gb_free": "39.2", "wall": "369711"}
[2024-10-09 00:55:32,214][train_inner][INFO] - {"epoch": 409, "update": 408.516, "loss": "0.791", "ntokens": "264079", "nsentences": "1745.82", "wps": "248076", "ups": "0.94", "wpb": "264079", "bsz": "1745.8", "num_updates": "195600", "lr": "0.000277717", "gnorm": "0.269", "loss_scale": "2", "train_wall": "207", "gb_free": "39.6", "wall": "369924"}
[2024-10-09 00:59:22,734][train_inner][INFO] - {"epoch": 409, "update": 408.933, "loss": "0.793", "ntokens": "264063", "nsentences": "1756.69", "wps": "229121", "ups": "0.87", "wpb": "264063", "bsz": "1756.7", "num_updates": "195800", "lr": "0.000277446", "gnorm": "0.274", "loss_scale": "2", "train_wall": "225", "gb_free": "39.7", "wall": "370155"}
[2024-10-09 01:00:10,923][fairseq_cli.train][INFO] - end of epoch 409 (average epoch stats below)
[2024-10-09 01:00:10,947][train][INFO] - {"epoch": 409, "train_loss": "0.792", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "142309", "train_ups": "0.54", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "195832", "train_lr": "0.000277402", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "562", "train_gb_free": "40.1", "train_wall": "370203"}
[2024-10-09 01:00:11,065][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:00:11,089][fairseq.trainer][INFO] - begin training epoch 410
[2024-10-09 01:00:11,089][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:08:51,764][train_inner][INFO] - {"epoch": 410, "update": 409.351, "loss": "0.79", "ntokens": "262720", "nsentences": "1744.86", "wps": "92341", "ups": "0.35", "wpb": "262720", "bsz": "1744.9", "num_updates": "196000", "lr": "0.000277174", "gnorm": "0.285", "loss_scale": "2", "train_wall": "241", "gb_free": "39.1", "wall": "370724"}
[2024-10-09 01:12:31,724][train_inner][INFO] - {"epoch": 410, "update": 409.768, "loss": "0.795", "ntokens": "264061", "nsentences": "1767.93", "wps": "240117", "ups": "0.91", "wpb": "264061", "bsz": "1767.9", "num_updates": "196200", "lr": "0.000276902", "gnorm": "0.273", "loss_scale": "2", "train_wall": "215", "gb_free": "39.1", "wall": "370944"}
[2024-10-09 01:14:58,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 410 @ 196311 updates
[2024-10-09 01:14:58,141][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 01:15:02,253][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 01:15:02,256][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 410 @ 196311 updates, score None) (writing took 4.116862435825169 seconds)
[2024-10-09 01:15:02,256][fairseq_cli.train][INFO] - end of epoch 410 (average epoch stats below)
[2024-10-09 01:15:02,262][train][INFO] - {"epoch": 410, "train_loss": "0.792", "train_ntokens": "263484", "train_nsentences": "1753.71", "train_wps": "141600", "train_ups": "0.54", "train_wpb": "263484", "train_bsz": "1753.7", "train_num_updates": "196311", "train_lr": "0.000276751", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "39.6", "train_wall": "371094"}
[2024-10-09 01:15:02,337][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:15:02,380][fairseq.trainer][INFO] - begin training epoch 411
[2024-10-09 01:15:02,381][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:22:01,086][train_inner][INFO] - {"epoch": 411, "update": 410.186, "loss": "0.788", "ntokens": "263053", "nsentences": "1710.15", "wps": "92408.4", "ups": "0.35", "wpb": "263053", "bsz": "1710.2", "num_updates": "196400", "lr": "0.00027663", "gnorm": "0.26", "loss_scale": "2", "train_wall": "252", "gb_free": "39.3", "wall": "371513"}
[2024-10-09 01:26:18,872][train_inner][INFO] - {"epoch": 411, "update": 410.603, "loss": "0.794", "ntokens": "263372", "nsentences": "1820.81", "wps": "204341", "ups": "0.78", "wpb": "263372", "bsz": "1820.8", "num_updates": "196600", "lr": "0.000276359", "gnorm": "0.275", "loss_scale": "2", "train_wall": "252", "gb_free": "39.6", "wall": "371771"}
[2024-10-09 01:30:16,246][fairseq_cli.train][INFO] - end of epoch 411 (average epoch stats below)
[2024-10-09 01:30:16,256][train][INFO] - {"epoch": 411, "train_loss": "0.792", "train_ntokens": "263496", "train_nsentences": "1753.71", "train_wps": "138092", "train_ups": "0.52", "train_wpb": "263496", "train_bsz": "1753.7", "train_num_updates": "196790", "train_lr": "0.000276101", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "594", "train_gb_free": "39.8", "train_wall": "372008"}
[2024-10-09 01:30:16,377][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:30:16,396][fairseq.trainer][INFO] - begin training epoch 412
[2024-10-09 01:30:16,396][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:35:55,693][train_inner][INFO] - {"epoch": 412, "update": 411.021, "loss": "0.792", "ntokens": "263378", "nsentences": "1696.54", "wps": "91323.6", "ups": "0.35", "wpb": "263378", "bsz": "1696.5", "num_updates": "196800", "lr": "0.000276087", "gnorm": "0.279", "loss_scale": "2", "train_wall": "273", "gb_free": "39.6", "wall": "372348"}
[2024-10-09 01:39:43,588][train_inner][INFO] - {"epoch": 412, "update": 411.438, "loss": "0.792", "ntokens": "264021", "nsentences": "1740.23", "wps": "231737", "ups": "0.88", "wpb": "264021", "bsz": "1740.2", "num_updates": "197000", "lr": "0.000275815", "gnorm": "0.264", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "372576"}
[2024-10-09 01:43:47,099][train_inner][INFO] - {"epoch": 412, "update": 411.856, "loss": "0.793", "ntokens": "264185", "nsentences": "1736.1", "wps": "216989", "ups": "0.82", "wpb": "264185", "bsz": "1736.1", "num_updates": "197200", "lr": "0.000275543", "gnorm": "0.281", "loss_scale": "4", "train_wall": "238", "gb_free": "40.1", "wall": "372819"}
[2024-10-09 01:45:41,733][fairseq_cli.train][INFO] - end of epoch 412 (average epoch stats below)
[2024-10-09 01:45:41,766][train][INFO] - {"epoch": 412, "train_loss": "0.792", "train_ntokens": "263462", "train_nsentences": "1753.71", "train_wps": "136358", "train_ups": "0.52", "train_wpb": "263462", "train_bsz": "1753.7", "train_num_updates": "197269", "train_lr": "0.00027545", "train_gnorm": "0.272", "train_loss_scale": "4", "train_train_wall": "615", "train_gb_free": "39.6", "train_wall": "372934"}
[2024-10-09 01:45:41,841][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 01:45:41,889][fairseq.trainer][INFO] - begin training epoch 413
[2024-10-09 01:45:41,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:53:45,981][train_inner][INFO] - {"epoch": 413, "update": 412.273, "loss": "0.791", "ntokens": "262451", "nsentences": "1784.79", "wps": "87651.6", "ups": "0.33", "wpb": "262451", "bsz": "1784.8", "num_updates": "197400", "lr": "0.000275272", "gnorm": "0.268", "loss_scale": "4", "train_wall": "293", "gb_free": "40.1", "wall": "373418"}
[2024-10-09 01:57:42,102][train_inner][INFO] - {"epoch": 413, "update": 412.691, "loss": "0.791", "ntokens": "263729", "nsentences": "1759.9", "wps": "223402", "ups": "0.85", "wpb": "263729", "bsz": "1759.9", "num_updates": "197600", "lr": "0.000275", "gnorm": "0.272", "loss_scale": "4", "train_wall": "231", "gb_free": "39.6", "wall": "373654"}
[2024-10-09 02:00:39,374][fairseq_cli.train][INFO] - end of epoch 413 (average epoch stats below)
[2024-10-09 02:00:39,411][train][INFO] - {"epoch": 413, "train_loss": "0.792", "train_ntokens": "263447", "train_nsentences": "1753.71", "train_wps": "140581", "train_ups": "0.53", "train_wpb": "263447", "train_bsz": "1753.7", "train_num_updates": "197748", "train_lr": "0.000274799", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "584", "train_gb_free": "40.2", "train_wall": "373832"}
[2024-10-09 02:00:39,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:00:39,620][fairseq.trainer][INFO] - begin training epoch 414
[2024-10-09 02:00:39,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:07:16,042][train_inner][INFO] - {"epoch": 414, "update": 413.109, "loss": "0.792", "ntokens": "263046", "nsentences": "1747.45", "wps": "91668.4", "ups": "0.35", "wpb": "263046", "bsz": "1747.5", "num_updates": "197800", "lr": "0.000274728", "gnorm": "0.25", "loss_scale": "4", "train_wall": "257", "gb_free": "40", "wall": "374228"}
[2024-10-09 02:09:49,760][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 02:10:53,454][train_inner][INFO] - {"epoch": 414, "update": 413.528, "loss": "0.791", "ntokens": "263953", "nsentences": "1766.33", "wps": "242823", "ups": "0.92", "wpb": "263952", "bsz": "1766.3", "num_updates": "198000", "lr": "0.000274457", "gnorm": "0.259", "loss_scale": "2", "train_wall": "213", "gb_free": "39.2", "wall": "374446"}
[2024-10-09 02:14:46,736][train_inner][INFO] - {"epoch": 414, "update": 413.946, "loss": "0.793", "ntokens": "264066", "nsentences": "1756.66", "wps": "226400", "ups": "0.86", "wpb": "264066", "bsz": "1756.7", "num_updates": "198200", "lr": "0.000274185", "gnorm": "0.269", "loss_scale": "2", "train_wall": "229", "gb_free": "40", "wall": "374679"}
[2024-10-09 02:15:29,657][fairseq_cli.train][INFO] - end of epoch 414 (average epoch stats below)
[2024-10-09 02:15:29,674][train][INFO] - {"epoch": 414, "train_loss": "0.792", "train_ntokens": "263577", "train_nsentences": "1754.24", "train_wps": "141526", "train_ups": "0.54", "train_wpb": "263577", "train_bsz": "1754.2", "train_num_updates": "198226", "train_lr": "0.000274149", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "567", "train_gb_free": "40", "train_wall": "374722"}
[2024-10-09 02:15:29,747][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:15:29,785][fairseq.trainer][INFO] - begin training epoch 415
[2024-10-09 02:15:29,786][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:24:29,215][train_inner][INFO] - {"epoch": 415, "update": 414.363, "loss": "0.79", "ntokens": "263242", "nsentences": "1725.13", "wps": "90388.1", "ups": "0.34", "wpb": "263242", "bsz": "1725.1", "num_updates": "198400", "lr": "0.000273913", "gnorm": "0.266", "loss_scale": "2", "train_wall": "248", "gb_free": "39.6", "wall": "375261"}
[2024-10-09 02:28:53,201][train_inner][INFO] - {"epoch": 415, "update": 414.781, "loss": "0.793", "ntokens": "263840", "nsentences": "1772.98", "wps": "199898", "ups": "0.76", "wpb": "263840", "bsz": "1773", "num_updates": "198600", "lr": "0.000273641", "gnorm": "0.265", "loss_scale": "2", "train_wall": "258", "gb_free": "39.6", "wall": "375525"}
[2024-10-09 02:31:15,399][fairseq_cli.train][INFO] - end of epoch 415 (average epoch stats below)
[2024-10-09 02:31:15,405][train][INFO] - {"epoch": 415, "train_loss": "0.792", "train_ntokens": "263584", "train_nsentences": "1753.71", "train_wps": "133502", "train_ups": "0.51", "train_wpb": "263584", "train_bsz": "1753.7", "train_num_updates": "198705", "train_lr": "0.000273499", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "604", "train_gb_free": "40.3", "train_wall": "375668"}
[2024-10-09 02:31:15,482][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:31:15,503][fairseq.trainer][INFO] - begin training epoch 416
[2024-10-09 02:31:15,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:38:29,633][train_inner][INFO] - {"epoch": 416, "update": 415.198, "loss": "0.789", "ntokens": "263078", "nsentences": "1720.2", "wps": "91282.6", "ups": "0.35", "wpb": "263078", "bsz": "1720.2", "num_updates": "198800", "lr": "0.00027337", "gnorm": "0.271", "loss_scale": "2", "train_wall": "260", "gb_free": "40.5", "wall": "376102"}
[2024-10-09 02:39:42,678][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-09 02:42:07,553][train_inner][INFO] - {"epoch": 416, "update": 415.618, "loss": "0.793", "ntokens": "264195", "nsentences": "1759.51", "wps": "242486", "ups": "0.92", "wpb": "264195", "bsz": "1759.5", "num_updates": "199000", "lr": "0.000273098", "gnorm": "0.285", "loss_scale": "1", "train_wall": "212", "gb_free": "40", "wall": "376320"}
[2024-10-09 02:45:36,691][fairseq_cli.train][INFO] - end of epoch 416 (average epoch stats below)
[2024-10-09 02:45:36,724][train][INFO] - {"epoch": 416, "train_loss": "0.792", "train_ntokens": "263646", "train_nsentences": "1753.56", "train_wps": "146318", "train_ups": "0.55", "train_wpb": "263646", "train_bsz": "1753.6", "train_num_updates": "199183", "train_lr": "0.000272849", "train_gnorm": "0.285", "train_loss_scale": "1", "train_train_wall": "537", "train_gb_free": "39.2", "train_wall": "376529"}
[2024-10-09 02:45:36,934][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 02:45:36,955][fairseq.trainer][INFO] - begin training epoch 417
[2024-10-09 02:45:36,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:51:45,048][train_inner][INFO] - {"epoch": 417, "update": 416.035, "loss": "0.794", "ntokens": "262679", "nsentences": "1776.23", "wps": "90975", "ups": "0.35", "wpb": "262679", "bsz": "1776.2", "num_updates": "199200", "lr": "0.000272826", "gnorm": "0.289", "loss_scale": "1", "train_wall": "227", "gb_free": "39.6", "wall": "376897"}
[2024-10-09 02:55:13,578][train_inner][INFO] - {"epoch": 417, "update": 416.453, "loss": "0.789", "ntokens": "264187", "nsentences": "1743.95", "wps": "253405", "ups": "0.96", "wpb": "264187", "bsz": "1744", "num_updates": "199400", "lr": "0.000272554", "gnorm": "0.277", "loss_scale": "1", "train_wall": "191", "gb_free": "40", "wall": "377106"}
[2024-10-09 02:59:18,487][train_inner][INFO] - {"epoch": 417, "update": 416.871, "loss": "0.794", "ntokens": "263718", "nsentences": "1782.36", "wps": "215394", "ups": "0.82", "wpb": "263718", "bsz": "1782.4", "num_updates": "199600", "lr": "0.000272283", "gnorm": "0.256", "loss_scale": "1", "train_wall": "239", "gb_free": "39.7", "wall": "377351"}
[2024-10-09 03:00:43,710][fairseq_cli.train][INFO] - end of epoch 417 (average epoch stats below)
[2024-10-09 03:00:43,726][train][INFO] - {"epoch": 417, "train_loss": "0.791", "train_ntokens": "263491", "train_nsentences": "1753.71", "train_wps": "139158", "train_ups": "0.53", "train_wpb": "263491", "train_bsz": "1753.7", "train_num_updates": "199662", "train_lr": "0.000272198", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "537", "train_gb_free": "39.7", "train_wall": "377436"}
[2024-10-09 03:00:43,831][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:00:43,851][fairseq.trainer][INFO] - begin training epoch 418
[2024-10-09 03:00:43,852][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:08:56,401][train_inner][INFO] - {"epoch": 418, "update": 417.288, "loss": "0.789", "ntokens": "263054", "nsentences": "1699.82", "wps": "91038.5", "ups": "0.35", "wpb": "263054", "bsz": "1699.8", "num_updates": "199800", "lr": "0.000272011", "gnorm": "0.263", "loss_scale": "1", "train_wall": "253", "gb_free": "39.6", "wall": "377929"}
[2024-10-09 03:12:56,917][train_inner][INFO] - {"epoch": 418, "update": 417.706, "loss": "0.791", "ntokens": "263837", "nsentences": "1770.61", "wps": "219408", "ups": "0.83", "wpb": "263837", "bsz": "1770.6", "num_updates": "200000", "lr": "0.000271739", "gnorm": "0.266", "loss_scale": "1", "train_wall": "235", "gb_free": "39.7", "wall": "378169"}
[2024-10-09 03:12:56,935][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 418 @ 200000 updates
[2024-10-09 03:12:56,936][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_418_200000.pt
[2024-10-09 03:13:01,346][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_418_200000.pt
[2024-10-09 03:13:10,739][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_418_200000.pt (epoch 418 @ 200000 updates, score None) (writing took 13.803909439593554 seconds)
[2024-10-09 03:16:16,256][fairseq_cli.train][INFO] - end of epoch 418 (average epoch stats below)
[2024-10-09 03:16:16,263][train][INFO] - {"epoch": 418, "train_loss": "0.791", "train_ntokens": "263476", "train_nsentences": "1753.71", "train_wps": "135336", "train_ups": "0.51", "train_wpb": "263476", "train_bsz": "1753.7", "train_num_updates": "200141", "train_lr": "0.000271548", "train_gnorm": "0.262", "train_loss_scale": "1", "train_train_wall": "587", "train_gb_free": "40", "train_wall": "378368"}
[2024-10-09 03:16:16,348][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:16:16,369][fairseq.trainer][INFO] - begin training epoch 419
[2024-10-09 03:16:16,369][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:23:00,448][train_inner][INFO] - {"epoch": 419, "update": 418.123, "loss": "0.792", "ntokens": "262631", "nsentences": "1784.45", "wps": "87032.8", "ups": "0.33", "wpb": "262631", "bsz": "1784.5", "num_updates": "200200", "lr": "0.000271467", "gnorm": "0.275", "loss_scale": "1", "train_wall": "280", "gb_free": "39.8", "wall": "378773"}
[2024-10-09 03:26:21,434][train_inner][INFO] - {"epoch": 419, "update": 418.541, "loss": "0.788", "ntokens": "264122", "nsentences": "1741.67", "wps": "262848", "ups": "1", "wpb": "264122", "bsz": "1741.7", "num_updates": "200400", "lr": "0.000271196", "gnorm": "0.257", "loss_scale": "1", "train_wall": "195", "gb_free": "39.8", "wall": "378974"}
[2024-10-09 03:30:01,504][train_inner][INFO] - {"epoch": 419, "update": 418.958, "loss": "0.794", "ntokens": "263654", "nsentences": "1774.83", "wps": "239634", "ups": "0.91", "wpb": "263654", "bsz": "1774.8", "num_updates": "200600", "lr": "0.000270924", "gnorm": "0.272", "loss_scale": "1", "train_wall": "215", "gb_free": "39.2", "wall": "379194"}
[2024-10-09 03:30:44,729][fairseq_cli.train][INFO] - end of epoch 419 (average epoch stats below)
[2024-10-09 03:30:44,754][train][INFO] - {"epoch": 419, "train_loss": "0.791", "train_ntokens": "263413", "train_nsentences": "1753.71", "train_wps": "145283", "train_ups": "0.55", "train_wpb": "263413", "train_bsz": "1753.7", "train_num_updates": "200620", "train_lr": "0.000270897", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "549", "train_gb_free": "39.6", "train_wall": "379237"}
[2024-10-09 03:30:44,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:30:44,902][fairseq.trainer][INFO] - begin training epoch 420
[2024-10-09 03:30:44,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:40:02,074][train_inner][INFO] - {"epoch": 420, "update": 419.376, "loss": "0.791", "ntokens": "262761", "nsentences": "1766.54", "wps": "87505.9", "ups": "0.33", "wpb": "262761", "bsz": "1766.5", "num_updates": "200800", "lr": "0.000270652", "gnorm": "0.262", "loss_scale": "1", "train_wall": "274", "gb_free": "39.2", "wall": "379794"}
[2024-10-09 03:40:25,074][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-09 03:44:01,264][train_inner][INFO] - {"epoch": 420, "update": 419.795, "loss": "0.79", "ntokens": "264358", "nsentences": "1718.02", "wps": "221059", "ups": "0.84", "wpb": "264358", "bsz": "1718", "num_updates": "201000", "lr": "0.00027038", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "234", "gb_free": "40", "wall": "380033"}
[2024-10-09 03:46:12,512][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 420 @ 201098 updates
[2024-10-09 03:46:12,514][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 03:46:18,956][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 03:46:18,961][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 420 @ 201098 updates, score None) (writing took 6.448699698783457 seconds)
[2024-10-09 03:46:18,962][fairseq_cli.train][INFO] - end of epoch 420 (average epoch stats below)
[2024-10-09 03:46:18,978][train][INFO] - {"epoch": 420, "train_loss": "0.791", "train_ntokens": "263585", "train_nsentences": "1754.68", "train_wps": "134867", "train_ups": "0.51", "train_wpb": "263584", "train_bsz": "1754.7", "train_num_updates": "201098", "train_lr": "0.000270247", "train_gnorm": "0.269", "train_loss_scale": "0.5", "train_train_wall": "596", "train_gb_free": "39.6", "train_wall": "380171"}
[2024-10-09 03:46:19,034][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 03:46:19,063][fairseq.trainer][INFO] - begin training epoch 421
[2024-10-09 03:46:19,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:53:45,923][train_inner][INFO] - {"epoch": 421, "update": 420.213, "loss": "0.79", "ntokens": "262658", "nsentences": "1777.11", "wps": "89854.6", "ups": "0.34", "wpb": "262658", "bsz": "1777.1", "num_updates": "201200", "lr": "0.000270109", "gnorm": "0.281", "loss_scale": "0.5", "train_wall": "260", "gb_free": "39.3", "wall": "380618"}
[2024-10-09 03:57:34,795][train_inner][INFO] - {"epoch": 421, "update": 420.63, "loss": "0.79", "ntokens": "264036", "nsentences": "1756.48", "wps": "230740", "ups": "0.87", "wpb": "264036", "bsz": "1756.5", "num_updates": "201400", "lr": "0.000269837", "gnorm": "0.274", "loss_scale": "0.5", "train_wall": "223", "gb_free": "40.3", "wall": "380847"}
[2024-10-09 04:00:41,327][fairseq_cli.train][INFO] - end of epoch 421 (average epoch stats below)
[2024-10-09 04:00:41,366][train][INFO] - {"epoch": 421, "train_loss": "0.79", "train_ntokens": "263561", "train_nsentences": "1753.71", "train_wps": "146393", "train_ups": "0.56", "train_wpb": "263561", "train_bsz": "1753.7", "train_num_updates": "201577", "train_lr": "0.000269596", "train_gnorm": "0.275", "train_loss_scale": "0.5", "train_train_wall": "537", "train_gb_free": "40", "train_wall": "381034"}
[2024-10-09 04:00:41,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:00:41,589][fairseq.trainer][INFO] - begin training epoch 422
[2024-10-09 04:00:41,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:07:07,491][train_inner][INFO] - {"epoch": 422, "update": 421.048, "loss": "0.79", "ntokens": "263201", "nsentences": "1715.17", "wps": "91918", "ups": "0.35", "wpb": "263201", "bsz": "1715.2", "num_updates": "201600", "lr": "0.000269565", "gnorm": "0.274", "loss_scale": "0.5", "train_wall": "242", "gb_free": "40.5", "wall": "381420"}
[2024-10-09 04:10:29,259][train_inner][INFO] - {"epoch": 422, "update": 421.466, "loss": "0.789", "ntokens": "263605", "nsentences": "1784.92", "wps": "261307", "ups": "0.99", "wpb": "263605", "bsz": "1784.9", "num_updates": "201800", "lr": "0.000269293", "gnorm": "0.282", "loss_scale": "0.5", "train_wall": "196", "gb_free": "39.4", "wall": "381621"}
[2024-10-09 04:14:14,121][train_inner][INFO] - {"epoch": 422, "update": 421.883, "loss": "0.791", "ntokens": "264051", "nsentences": "1745.68", "wps": "234873", "ups": "0.89", "wpb": "264051", "bsz": "1745.7", "num_updates": "202000", "lr": "0.000269022", "gnorm": "0.264", "loss_scale": "0.5", "train_wall": "215", "gb_free": "39.6", "wall": "381846"}
[2024-10-09 04:15:30,863][fairseq_cli.train][INFO] - end of epoch 422 (average epoch stats below)
[2024-10-09 04:15:30,870][train][INFO] - {"epoch": 422, "train_loss": "0.79", "train_ntokens": "263365", "train_nsentences": "1753.71", "train_wps": "141824", "train_ups": "0.54", "train_wpb": "263364", "train_bsz": "1753.7", "train_num_updates": "202056", "train_lr": "0.000268946", "train_gnorm": "0.276", "train_loss_scale": "0.5", "train_train_wall": "546", "train_gb_free": "39.2", "train_wall": "381923"}
[2024-10-09 04:15:30,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:15:30,993][fairseq.trainer][INFO] - begin training epoch 423
[2024-10-09 04:15:30,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:24:09,838][train_inner][INFO] - {"epoch": 423, "update": 422.301, "loss": "0.788", "ntokens": "262795", "nsentences": "1739.46", "wps": "88231.6", "ups": "0.34", "wpb": "262795", "bsz": "1739.5", "num_updates": "202200", "lr": "0.00026875", "gnorm": "0.268", "loss_scale": "0.5", "train_wall": "235", "gb_free": "40", "wall": "382442"}
[2024-10-09 04:28:11,338][train_inner][INFO] - {"epoch": 423, "update": 422.718, "loss": "0.79", "ntokens": "263914", "nsentences": "1779.93", "wps": "218587", "ups": "0.83", "wpb": "263914", "bsz": "1779.9", "num_updates": "202400", "lr": "0.000268478", "gnorm": "0.276", "loss_scale": "0.5", "train_wall": "236", "gb_free": "40.3", "wall": "382684"}
[2024-10-09 04:30:45,436][fairseq_cli.train][INFO] - end of epoch 423 (average epoch stats below)
[2024-10-09 04:30:45,454][train][INFO] - {"epoch": 423, "train_loss": "0.79", "train_ntokens": "263519", "train_nsentences": "1753.71", "train_wps": "138016", "train_ups": "0.52", "train_wpb": "263519", "train_bsz": "1753.7", "train_num_updates": "202535", "train_lr": "0.000268295", "train_gnorm": "0.269", "train_loss_scale": "0.5", "train_train_wall": "548", "train_gb_free": "40.3", "train_wall": "382838"}
[2024-10-09 04:30:45,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:30:45,589][fairseq.trainer][INFO] - begin training epoch 424
[2024-10-09 04:30:45,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:37:47,570][train_inner][INFO] - {"epoch": 424, "update": 423.136, "loss": "0.79", "ntokens": "262673", "nsentences": "1738.84", "wps": "91170.7", "ups": "0.35", "wpb": "262673", "bsz": "1738.8", "num_updates": "202600", "lr": "0.000268207", "gnorm": "0.269", "loss_scale": "0.5", "train_wall": "232", "gb_free": "39.3", "wall": "383260"}
[2024-10-09 04:41:30,821][train_inner][INFO] - {"epoch": 424, "update": 423.553, "loss": "0.787", "ntokens": "264229", "nsentences": "1722.88", "wps": "236724", "ups": "0.9", "wpb": "264229", "bsz": "1722.9", "num_updates": "202800", "lr": "0.000267935", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "218", "gb_free": "39.6", "wall": "383483"}
[2024-10-09 04:45:22,213][train_inner][INFO] - {"epoch": 424, "update": 423.971, "loss": "0.794", "ntokens": "263852", "nsentences": "1789.42", "wps": "228069", "ups": "0.86", "wpb": "263852", "bsz": "1789.4", "num_updates": "203000", "lr": "0.000267663", "gnorm": "0.265", "loss_scale": "1", "train_wall": "225", "gb_free": "39.2", "wall": "383714"}
[2024-10-09 04:45:39,428][fairseq_cli.train][INFO] - end of epoch 424 (average epoch stats below)
[2024-10-09 04:45:39,457][train][INFO] - {"epoch": 424, "train_loss": "0.79", "train_ntokens": "263494", "train_nsentences": "1753.71", "train_wps": "141181", "train_ups": "0.54", "train_wpb": "263494", "train_bsz": "1753.7", "train_num_updates": "203014", "train_lr": "0.000267644", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "541", "train_gb_free": "39.7", "train_wall": "383732"}
[2024-10-09 04:45:39,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 04:45:39,884][fairseq.trainer][INFO] - begin training epoch 425
[2024-10-09 04:45:39,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:55:05,213][train_inner][INFO] - {"epoch": 425, "update": 424.388, "loss": "0.79", "ntokens": "262644", "nsentences": "1764.74", "wps": "90102.1", "ups": "0.34", "wpb": "262644", "bsz": "1764.7", "num_updates": "203200", "lr": "0.000267391", "gnorm": "0.274", "loss_scale": "1", "train_wall": "212", "gb_free": "40.3", "wall": "384297"}
[2024-10-09 04:58:57,372][train_inner][INFO] - {"epoch": 425, "update": 424.806, "loss": "0.789", "ntokens": "263960", "nsentences": "1749.36", "wps": "227410", "ups": "0.86", "wpb": "263960", "bsz": "1749.4", "num_updates": "203400", "lr": "0.00026712", "gnorm": "0.266", "loss_scale": "1", "train_wall": "227", "gb_free": "39.6", "wall": "384530"}
[2024-10-09 05:00:54,631][fairseq_cli.train][INFO] - end of epoch 425 (average epoch stats below)
[2024-10-09 05:00:54,651][train][INFO] - {"epoch": 425, "train_loss": "0.79", "train_ntokens": "263436", "train_nsentences": "1753.71", "train_wps": "137887", "train_ups": "0.52", "train_wpb": "263436", "train_bsz": "1753.7", "train_num_updates": "203493", "train_lr": "0.000266993", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "538", "train_gb_free": "39.2", "train_wall": "384647"}
[2024-10-09 05:00:54,722][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:00:54,762][fairseq.trainer][INFO] - begin training epoch 426
[2024-10-09 05:00:54,763][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:08:44,683][train_inner][INFO] - {"epoch": 426, "update": 425.223, "loss": "0.792", "ntokens": "262617", "nsentences": "1771.96", "wps": "89433.6", "ups": "0.34", "wpb": "262618", "bsz": "1772", "num_updates": "203600", "lr": "0.000266848", "gnorm": "0.276", "loss_scale": "1", "train_wall": "263", "gb_free": "39.6", "wall": "385117"}
[2024-10-09 05:10:44,039][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-09 05:12:21,890][train_inner][INFO] - {"epoch": 426, "update": 425.643, "loss": "0.787", "ntokens": "264039", "nsentences": "1747.43", "wps": "243153", "ups": "0.92", "wpb": "264039", "bsz": "1747.4", "num_updates": "203800", "lr": "0.000266576", "gnorm": "0.277", "loss_scale": "0.5", "train_wall": "211", "gb_free": "39.6", "wall": "385334"}
[2024-10-09 05:16:03,393][fairseq_cli.train][INFO] - end of epoch 426 (average epoch stats below)
[2024-10-09 05:16:03,411][train][INFO] - {"epoch": 426, "train_loss": "0.789", "train_ntokens": "263493", "train_nsentences": "1752.34", "train_wps": "138597", "train_ups": "0.53", "train_wpb": "263493", "train_bsz": "1752.3", "train_num_updates": "203971", "train_lr": "0.000266344", "train_gnorm": "0.276", "train_loss_scale": "0.5", "train_train_wall": "576", "train_gb_free": "39.3", "train_wall": "385556"}
[2024-10-09 05:16:03,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:16:03,616][fairseq.trainer][INFO] - begin training epoch 427
[2024-10-09 05:16:03,617][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:22:07,375][train_inner][INFO] - {"epoch": 427, "update": 426.061, "loss": "0.79", "ntokens": "263245", "nsentences": "1703.67", "wps": "89930.8", "ups": "0.34", "wpb": "263245", "bsz": "1703.7", "num_updates": "204000", "lr": "0.000266304", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "274", "gb_free": "39.6", "wall": "385920"}
[2024-10-09 05:25:52,189][train_inner][INFO] - {"epoch": 427, "update": 426.478, "loss": "0.788", "ntokens": "264340", "nsentences": "1728.45", "wps": "235206", "ups": "0.89", "wpb": "264340", "bsz": "1728.5", "num_updates": "204200", "lr": "0.000266033", "gnorm": "0.258", "loss_scale": "0.5", "train_wall": "219", "gb_free": "39.1", "wall": "386144"}
[2024-10-09 05:30:28,620][train_inner][INFO] - {"epoch": 427, "update": 426.896, "loss": "0.79", "ntokens": "263626", "nsentences": "1790.17", "wps": "190749", "ups": "0.72", "wpb": "263626", "bsz": "1790.2", "num_updates": "204400", "lr": "0.000265761", "gnorm": "0.285", "loss_scale": "0.5", "train_wall": "271", "gb_free": "40", "wall": "386421"}
[2024-10-09 05:31:31,192][fairseq_cli.train][INFO] - end of epoch 427 (average epoch stats below)
[2024-10-09 05:31:31,218][train][INFO] - {"epoch": 427, "train_loss": "0.789", "train_ntokens": "263535", "train_nsentences": "1753.71", "train_wps": "136060", "train_ups": "0.52", "train_wpb": "263535", "train_bsz": "1753.7", "train_num_updates": "204450", "train_lr": "0.000265693", "train_gnorm": "0.27", "train_loss_scale": "0.5", "train_train_wall": "609", "train_gb_free": "39.6", "train_wall": "386483"}
[2024-10-09 05:31:31,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:31:31,459][fairseq.trainer][INFO] - begin training epoch 428
[2024-10-09 05:31:31,460][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:39:53,891][train_inner][INFO] - {"epoch": 428, "update": 427.313, "loss": "0.787", "ntokens": "262480", "nsentences": "1775.69", "wps": "92870.5", "ups": "0.35", "wpb": "262480", "bsz": "1775.7", "num_updates": "204600", "lr": "0.000265489", "gnorm": "0.256", "loss_scale": "0.5", "train_wall": "244", "gb_free": "39.3", "wall": "386986"}
[2024-10-09 05:44:03,072][train_inner][INFO] - {"epoch": 428, "update": 427.731, "loss": "0.79", "ntokens": "263963", "nsentences": "1770.94", "wps": "211873", "ups": "0.8", "wpb": "263963", "bsz": "1770.9", "num_updates": "204800", "lr": "0.000265217", "gnorm": "0.291", "loss_scale": "0.5", "train_wall": "244", "gb_free": "39.6", "wall": "387235"}
[2024-10-09 05:47:12,309][fairseq_cli.train][INFO] - end of epoch 428 (average epoch stats below)
[2024-10-09 05:47:12,329][train][INFO] - {"epoch": 428, "train_loss": "0.789", "train_ntokens": "263451", "train_nsentences": "1753.71", "train_wps": "134091", "train_ups": "0.51", "train_wpb": "263451", "train_bsz": "1753.7", "train_num_updates": "204929", "train_lr": "0.000265042", "train_gnorm": "0.28", "train_loss_scale": "0.5", "train_train_wall": "613", "train_gb_free": "40.1", "train_wall": "387424"}
[2024-10-09 05:47:12,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 05:47:12,392][fairseq.trainer][INFO] - begin training epoch 429
[2024-10-09 05:47:12,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:54:02,159][train_inner][INFO] - {"epoch": 429, "update": 428.148, "loss": "0.787", "ntokens": "263103", "nsentences": "1703.5", "wps": "87836.3", "ups": "0.33", "wpb": "263103", "bsz": "1703.5", "num_updates": "205000", "lr": "0.000264946", "gnorm": "0.29", "loss_scale": "0.5", "train_wall": "287", "gb_free": "39.2", "wall": "387834"}
[2024-10-09 05:57:42,356][train_inner][INFO] - {"epoch": 429, "update": 428.566, "loss": "0.788", "ntokens": "264129", "nsentences": "1741.81", "wps": "239913", "ups": "0.91", "wpb": "264129", "bsz": "1741.8", "num_updates": "205200", "lr": "0.000264674", "gnorm": "0.264", "loss_scale": "0.5", "train_wall": "215", "gb_free": "40.5", "wall": "388055"}
[2024-10-09 06:01:47,798][train_inner][INFO] - {"epoch": 429, "update": 428.983, "loss": "0.792", "ntokens": "263568", "nsentences": "1793.73", "wps": "214969", "ups": "0.82", "wpb": "263568", "bsz": "1793.7", "num_updates": "205400", "lr": "0.000264402", "gnorm": "0.284", "loss_scale": "0.5", "train_wall": "240", "gb_free": "41", "wall": "388300"}
[2024-10-09 06:02:10,938][fairseq_cli.train][INFO] - end of epoch 429 (average epoch stats below)
[2024-10-09 06:02:10,981][train][INFO] - {"epoch": 429, "train_loss": "0.789", "train_ntokens": "263447", "train_nsentences": "1753.71", "train_wps": "140426", "train_ups": "0.53", "train_wpb": "263447", "train_bsz": "1753.7", "train_num_updates": "205408", "train_lr": "0.000264391", "train_gnorm": "0.278", "train_loss_scale": "0.5", "train_train_wall": "578", "train_gb_free": "39.6", "train_wall": "388323"}
[2024-10-09 06:02:11,108][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:02:11,141][fairseq.trainer][INFO] - begin training epoch 430
[2024-10-09 06:02:11,141][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:11:03,180][train_inner][INFO] - {"epoch": 430, "update": 429.401, "loss": "0.786", "ntokens": "262872", "nsentences": "1741.98", "wps": "94669.7", "ups": "0.36", "wpb": "262872", "bsz": "1742", "num_updates": "205600", "lr": "0.00026413", "gnorm": "0.275", "loss_scale": "0.5", "train_wall": "224", "gb_free": "39.3", "wall": "388855"}
[2024-10-09 06:14:49,861][train_inner][INFO] - {"epoch": 430, "update": 429.818, "loss": "0.789", "ntokens": "264042", "nsentences": "1759.73", "wps": "232974", "ups": "0.88", "wpb": "264042", "bsz": "1759.7", "num_updates": "205800", "lr": "0.000263859", "gnorm": "0.272", "loss_scale": "1", "train_wall": "222", "gb_free": "39.6", "wall": "389082"}
[2024-10-09 06:16:40,496][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 430 @ 205887 updates
[2024-10-09 06:16:40,497][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 06:16:48,470][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 06:16:48,540][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 430 @ 205887 updates, score None) (writing took 8.044658433645964 seconds)
[2024-10-09 06:16:48,541][fairseq_cli.train][INFO] - end of epoch 430 (average epoch stats below)
[2024-10-09 06:16:48,558][train][INFO] - {"epoch": 430, "train_loss": "0.788", "train_ntokens": "263508", "train_nsentences": "1753.71", "train_wps": "143832", "train_ups": "0.55", "train_wpb": "263508", "train_bsz": "1753.7", "train_num_updates": "205887", "train_lr": "0.00026374", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "513", "train_gb_free": "39.2", "train_wall": "389201"}
[2024-10-09 06:16:48,624][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:16:48,651][fairseq.trainer][INFO] - begin training epoch 431
[2024-10-09 06:16:48,651][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:24:29,621][train_inner][INFO] - {"epoch": 431, "update": 430.236, "loss": "0.791", "ntokens": "262483", "nsentences": "1790.8", "wps": "90550.3", "ups": "0.34", "wpb": "262483", "bsz": "1790.8", "num_updates": "206000", "lr": "0.000263587", "gnorm": "0.268", "loss_scale": "1", "train_wall": "228", "gb_free": "39.3", "wall": "389662"}
[2024-10-09 06:28:24,051][train_inner][INFO] - {"epoch": 431, "update": 430.653, "loss": "0.789", "ntokens": "264077", "nsentences": "1750.68", "wps": "225304", "ups": "0.85", "wpb": "264077", "bsz": "1750.7", "num_updates": "206200", "lr": "0.000263315", "gnorm": "0.265", "loss_scale": "1", "train_wall": "229", "gb_free": "40", "wall": "389896"}
[2024-10-09 06:31:39,766][fairseq_cli.train][INFO] - end of epoch 431 (average epoch stats below)
[2024-10-09 06:31:39,774][train][INFO] - {"epoch": 431, "train_loss": "0.789", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "141630", "train_ups": "0.54", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "206366", "train_lr": "0.00026309", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "558", "train_gb_free": "40.2", "train_wall": "390092"}
[2024-10-09 06:31:39,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:31:39,904][fairseq.trainer][INFO] - begin training epoch 432
[2024-10-09 06:31:39,904][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:38:21,315][train_inner][INFO] - {"epoch": 432, "update": 431.071, "loss": "0.788", "ntokens": "262866", "nsentences": "1735.1", "wps": "88032.2", "ups": "0.33", "wpb": "262866", "bsz": "1735.1", "num_updates": "206400", "lr": "0.000263043", "gnorm": "0.262", "loss_scale": "1", "train_wall": "253", "gb_free": "39.6", "wall": "390493"}
[2024-10-09 06:41:34,762][train_inner][INFO] - {"epoch": 432, "update": 431.489, "loss": "0.785", "ntokens": "264453", "nsentences": "1725.85", "wps": "273439", "ups": "1.03", "wpb": "264453", "bsz": "1725.8", "num_updates": "206600", "lr": "0.000262772", "gnorm": "0.26", "loss_scale": "1", "train_wall": "189", "gb_free": "39.6", "wall": "390687"}
[2024-10-09 06:45:46,584][train_inner][INFO] - {"epoch": 432, "update": 431.906, "loss": "0.79", "ntokens": "263877", "nsentences": "1762.37", "wps": "209593", "ups": "0.79", "wpb": "263877", "bsz": "1762.4", "num_updates": "206800", "lr": "0.0002625", "gnorm": "0.257", "loss_scale": "1", "train_wall": "247", "gb_free": "39.6", "wall": "390939"}
[2024-10-09 06:46:48,489][fairseq_cli.train][INFO] - end of epoch 432 (average epoch stats below)
[2024-10-09 06:46:48,505][train][INFO] - {"epoch": 432, "train_loss": "0.788", "train_ntokens": "263487", "train_nsentences": "1753.71", "train_wps": "138889", "train_ups": "0.53", "train_wpb": "263487", "train_bsz": "1753.7", "train_num_updates": "206845", "train_lr": "0.000262439", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "558", "train_gb_free": "40", "train_wall": "391001"}
[2024-10-09 06:46:48,592][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 06:46:48,629][fairseq.trainer][INFO] - begin training epoch 433
[2024-10-09 06:46:48,629][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:55:14,965][train_inner][INFO] - {"epoch": 433, "update": 432.324, "loss": "0.788", "ntokens": "262373", "nsentences": "1771.53", "wps": "92324.5", "ups": "0.35", "wpb": "262373", "bsz": "1771.5", "num_updates": "207000", "lr": "0.000262228", "gnorm": "0.275", "loss_scale": "1", "train_wall": "239", "gb_free": "40.5", "wall": "391507"}
[2024-10-09 06:59:22,422][train_inner][INFO] - {"epoch": 433, "update": 432.741, "loss": "0.79", "ntokens": "263659", "nsentences": "1807.13", "wps": "213128", "ups": "0.81", "wpb": "263659", "bsz": "1807.1", "num_updates": "207200", "lr": "0.000261957", "gnorm": "0.27", "loss_scale": "1", "train_wall": "242", "gb_free": "39.8", "wall": "391755"}
[2024-10-09 07:01:55,143][fairseq_cli.train][INFO] - end of epoch 433 (average epoch stats below)
[2024-10-09 07:01:55,148][train][INFO] - {"epoch": 433, "train_loss": "0.787", "train_ntokens": "263493", "train_nsentences": "1753.71", "train_wps": "139211", "train_ups": "0.53", "train_wpb": "263493", "train_bsz": "1753.7", "train_num_updates": "207324", "train_lr": "0.000261788", "train_gnorm": "0.273", "train_loss_scale": "1", "train_train_wall": "570", "train_gb_free": "39.3", "train_wall": "391907"}
[2024-10-09 07:01:55,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:01:55,262][fairseq.trainer][INFO] - begin training epoch 434
[2024-10-09 07:01:55,263][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:08:53,162][train_inner][INFO] - {"epoch": 434, "update": 433.159, "loss": "0.784", "ntokens": "263228", "nsentences": "1691.57", "wps": "92243.1", "ups": "0.35", "wpb": "263228", "bsz": "1691.6", "num_updates": "207400", "lr": "0.000261685", "gnorm": "0.278", "loss_scale": "1", "train_wall": "259", "gb_free": "39.8", "wall": "392325"}
[2024-10-09 07:13:03,319][train_inner][INFO] - {"epoch": 434, "update": 433.576, "loss": "0.787", "ntokens": "263743", "nsentences": "1773.06", "wps": "210885", "ups": "0.8", "wpb": "263743", "bsz": "1773.1", "num_updates": "207600", "lr": "0.000261413", "gnorm": "0.268", "loss_scale": "1", "train_wall": "245", "gb_free": "39.7", "wall": "392575"}
[2024-10-09 07:17:11,494][train_inner][INFO] - {"epoch": 434, "update": 433.994, "loss": "0.79", "ntokens": "264080", "nsentences": "1742.28", "wps": "212844", "ups": "0.81", "wpb": "264080", "bsz": "1742.3", "num_updates": "207800", "lr": "0.000261141", "gnorm": "0.277", "loss_scale": "1", "train_wall": "244", "gb_free": "40.1", "wall": "392824"}
[2024-10-09 07:17:12,781][fairseq_cli.train][INFO] - end of epoch 434 (average epoch stats below)
[2024-10-09 07:17:12,799][train][INFO] - {"epoch": 434, "train_loss": "0.788", "train_ntokens": "263425", "train_nsentences": "1753.71", "train_wps": "137506", "train_ups": "0.52", "train_wpb": "263425", "train_bsz": "1753.7", "train_num_updates": "207803", "train_lr": "0.000261137", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "601", "train_gb_free": "39.6", "train_wall": "392825"}
[2024-10-09 07:17:12,893][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:17:12,915][fairseq.trainer][INFO] - begin training epoch 435
[2024-10-09 07:17:12,916][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:26:27,862][train_inner][INFO] - {"epoch": 435, "update": 434.411, "loss": "0.786", "ntokens": "262904", "nsentences": "1743.45", "wps": "94509.6", "ups": "0.36", "wpb": "262904", "bsz": "1743.5", "num_updates": "208000", "lr": "0.00026087", "gnorm": "0.277", "loss_scale": "2", "train_wall": "239", "gb_free": "39.7", "wall": "393380"}
[2024-10-09 07:30:33,393][train_inner][INFO] - {"epoch": 435, "update": 434.829, "loss": "0.787", "ntokens": "263960", "nsentences": "1750.63", "wps": "215034", "ups": "0.81", "wpb": "263960", "bsz": "1750.6", "num_updates": "208200", "lr": "0.000260598", "gnorm": "0.265", "loss_scale": "2", "train_wall": "240", "gb_free": "41", "wall": "393626"}
[2024-10-09 07:32:22,485][fairseq_cli.train][INFO] - end of epoch 435 (average epoch stats below)
[2024-10-09 07:32:22,501][train][INFO] - {"epoch": 435, "train_loss": "0.787", "train_ntokens": "263472", "train_nsentences": "1753.71", "train_wps": "138735", "train_ups": "0.53", "train_wpb": "263472", "train_bsz": "1753.7", "train_num_updates": "208282", "train_lr": "0.000260486", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "585", "train_gb_free": "40", "train_wall": "393735"}
[2024-10-09 07:32:22,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:32:22,608][fairseq.trainer][INFO] - begin training epoch 436
[2024-10-09 07:32:22,609][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:39:53,816][train_inner][INFO] - {"epoch": 436, "update": 435.246, "loss": "0.786", "ntokens": "262664", "nsentences": "1758.66", "wps": "93739.1", "ups": "0.36", "wpb": "262664", "bsz": "1758.7", "num_updates": "208400", "lr": "0.000260326", "gnorm": "0.276", "loss_scale": "2", "train_wall": "243", "gb_free": "40.1", "wall": "394186"}
[2024-10-09 07:43:51,251][train_inner][INFO] - {"epoch": 436, "update": 435.664, "loss": "0.788", "ntokens": "264006", "nsentences": "1756.46", "wps": "222395", "ups": "0.84", "wpb": "264006", "bsz": "1756.5", "num_updates": "208600", "lr": "0.000260054", "gnorm": "0.275", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "394423"}
[2024-10-09 07:47:12,713][fairseq_cli.train][INFO] - end of epoch 436 (average epoch stats below)
[2024-10-09 07:47:12,730][train][INFO] - {"epoch": 436, "train_loss": "0.788", "train_ntokens": "263553", "train_nsentences": "1753.71", "train_wps": "141810", "train_ups": "0.54", "train_wpb": "263553", "train_bsz": "1753.7", "train_num_updates": "208761", "train_lr": "0.000259836", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "565", "train_gb_free": "39.1", "train_wall": "394625"}
[2024-10-09 07:47:12,829][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 07:47:12,856][fairseq.trainer][INFO] - begin training epoch 437
[2024-10-09 07:47:12,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:54:42,543][train_inner][INFO] - {"epoch": 437, "update": 436.081, "loss": "0.79", "ntokens": "262937", "nsentences": "1760.32", "wps": "80744.8", "ups": "0.31", "wpb": "262937", "bsz": "1760.3", "num_updates": "208800", "lr": "0.000259783", "gnorm": "0.263", "loss_scale": "2", "train_wall": "251", "gb_free": "39.6", "wall": "395075"}
[2024-10-09 07:58:21,124][train_inner][INFO] - {"epoch": 437, "update": 436.499, "loss": "0.786", "ntokens": "264322", "nsentences": "1728.24", "wps": "241896", "ups": "0.92", "wpb": "264322", "bsz": "1728.2", "num_updates": "209000", "lr": "0.000259511", "gnorm": "0.278", "loss_scale": "2", "train_wall": "154", "gb_free": "39.3", "wall": "395293"}
[2024-10-09 08:02:22,048][train_inner][INFO] - {"epoch": 437, "update": 436.916, "loss": "0.789", "ntokens": "263912", "nsentences": "1772.47", "wps": "219090", "ups": "0.83", "wpb": "263912", "bsz": "1772.5", "num_updates": "209200", "lr": "0.000259239", "gnorm": "0.284", "loss_scale": "2", "train_wall": "236", "gb_free": "39.3", "wall": "395534"}
[2024-10-09 08:03:08,375][fairseq_cli.train][INFO] - end of epoch 437 (average epoch stats below)
[2024-10-09 08:03:08,406][train][INFO] - {"epoch": 437, "train_loss": "0.788", "train_ntokens": "263587", "train_nsentences": "1753.71", "train_wps": "132117", "train_ups": "0.5", "train_wpb": "263587", "train_bsz": "1753.7", "train_num_updates": "209240", "train_lr": "0.000259185", "train_gnorm": "0.281", "train_loss_scale": "2", "train_train_wall": "489", "train_gb_free": "39.6", "train_wall": "395581"}
[2024-10-09 08:03:08,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:03:08,667][fairseq.trainer][INFO] - begin training epoch 438
[2024-10-09 08:03:08,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:11:35,136][train_inner][INFO] - {"epoch": 438, "update": 437.334, "loss": "0.786", "ntokens": "262905", "nsentences": "1743.75", "wps": "95070.4", "ups": "0.36", "wpb": "262905", "bsz": "1743.8", "num_updates": "209400", "lr": "0.000258967", "gnorm": "0.275", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "396087"}
[2024-10-09 08:15:44,720][train_inner][INFO] - {"epoch": 438, "update": 437.752, "loss": "0.787", "ntokens": "264044", "nsentences": "1761.78", "wps": "211610", "ups": "0.8", "wpb": "264044", "bsz": "1761.8", "num_updates": "209600", "lr": "0.000258696", "gnorm": "0.275", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "396337"}
[2024-10-09 08:18:30,643][fairseq_cli.train][INFO] - end of epoch 438 (average epoch stats below)
[2024-10-09 08:18:30,657][train][INFO] - {"epoch": 438, "train_loss": "0.787", "train_ntokens": "263598", "train_nsentences": "1753.71", "train_wps": "136909", "train_ups": "0.52", "train_wpb": "263598", "train_bsz": "1753.7", "train_num_updates": "209719", "train_lr": "0.000258534", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "591", "train_gb_free": "39.6", "train_wall": "396503"}
[2024-10-09 08:18:30,721][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:18:30,740][fairseq.trainer][INFO] - begin training epoch 439
[2024-10-09 08:18:30,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:25:51,471][train_inner][INFO] - {"epoch": 439, "update": 438.169, "loss": "0.788", "ntokens": "263075", "nsentences": "1752.32", "wps": "86721.2", "ups": "0.33", "wpb": "263075", "bsz": "1752.3", "num_updates": "209800", "lr": "0.000258424", "gnorm": "0.259", "loss_scale": "2", "train_wall": "277", "gb_free": "40", "wall": "396944"}
[2024-10-09 08:29:36,792][train_inner][INFO] - {"epoch": 439, "update": 438.587, "loss": "0.787", "ntokens": "263951", "nsentences": "1771.49", "wps": "234321", "ups": "0.89", "wpb": "263951", "bsz": "1771.5", "num_updates": "210000", "lr": "0.000258152", "gnorm": "0.267", "loss_scale": "4", "train_wall": "220", "gb_free": "39.8", "wall": "397169"}
[2024-10-09 08:32:18,811][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 08:33:28,680][fairseq_cli.train][INFO] - end of epoch 439 (average epoch stats below)
[2024-10-09 08:33:28,750][train][INFO] - {"epoch": 439, "train_loss": "0.787", "train_ntokens": "263623", "train_nsentences": "1750.01", "train_wps": "140315", "train_ups": "0.53", "train_wpb": "263623", "train_bsz": "1750", "train_num_updates": "210197", "train_lr": "0.000257885", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "40", "train_wall": "397401"}
[2024-10-09 08:33:29,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:33:29,127][fairseq.trainer][INFO] - begin training epoch 440
[2024-10-09 08:33:29,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:39:33,758][train_inner][INFO] - {"epoch": 440, "update": 439.006, "loss": "0.788", "ntokens": "263024", "nsentences": "1720.51", "wps": "88123.5", "ups": "0.34", "wpb": "263024", "bsz": "1720.5", "num_updates": "210200", "lr": "0.00025788", "gnorm": "0.261", "loss_scale": "2", "train_wall": "259", "gb_free": "39.7", "wall": "397766"}
[2024-10-09 08:43:46,414][train_inner][INFO] - {"epoch": 440, "update": 439.424, "loss": "0.79", "ntokens": "263396", "nsentences": "1818.97", "wps": "208520", "ups": "0.79", "wpb": "263396", "bsz": "1819", "num_updates": "210400", "lr": "0.000257609", "gnorm": "0.267", "loss_scale": "2", "train_wall": "248", "gb_free": "39.8", "wall": "398019"}
[2024-10-09 08:47:47,237][train_inner][INFO] - {"epoch": 440, "update": 439.841, "loss": "0.784", "ntokens": "264367", "nsentences": "1689.22", "wps": "219570", "ups": "0.83", "wpb": "264367", "bsz": "1689.2", "num_updates": "210600", "lr": "0.000257337", "gnorm": "0.272", "loss_scale": "2", "train_wall": "236", "gb_free": "39.8", "wall": "398259"}
[2024-10-09 08:49:26,053][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 440 @ 210676 updates
[2024-10-09 08:49:26,055][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 08:49:34,174][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 08:49:34,287][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 440 @ 210676 updates, score None) (writing took 8.233469553291798 seconds)
[2024-10-09 08:49:34,287][fairseq_cli.train][INFO] - end of epoch 440 (average epoch stats below)
[2024-10-09 08:49:34,298][train][INFO] - {"epoch": 440, "train_loss": "0.787", "train_ntokens": "263367", "train_nsentences": "1753.71", "train_wps": "130656", "train_ups": "0.5", "train_wpb": "263366", "train_bsz": "1753.7", "train_num_updates": "210676", "train_lr": "0.000257234", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "614", "train_gb_free": "40.3", "train_wall": "398366"}
[2024-10-09 08:49:34,358][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 08:49:34,392][fairseq.trainer][INFO] - begin training epoch 441
[2024-10-09 08:49:34,393][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:57:41,083][train_inner][INFO] - {"epoch": 441, "update": 440.259, "loss": "0.787", "ntokens": "262554", "nsentences": "1767.33", "wps": "88426.7", "ups": "0.34", "wpb": "262554", "bsz": "1767.3", "num_updates": "210800", "lr": "0.000257065", "gnorm": "0.282", "loss_scale": "2", "train_wall": "219", "gb_free": "39.8", "wall": "398853"}
[2024-10-09 09:01:40,535][train_inner][INFO] - {"epoch": 441, "update": 440.676, "loss": "0.786", "ntokens": "263835", "nsentences": "1763.42", "wps": "220380", "ups": "0.84", "wpb": "263835", "bsz": "1763.4", "num_updates": "211000", "lr": "0.000256793", "gnorm": "0.275", "loss_scale": "2", "train_wall": "229", "gb_free": "39.7", "wall": "399093"}
[2024-10-09 09:04:21,978][fairseq_cli.train][INFO] - end of epoch 441 (average epoch stats below)
[2024-10-09 09:04:22,046][train][INFO] - {"epoch": 441, "train_loss": "0.787", "train_ntokens": "263410", "train_nsentences": "1753.71", "train_wps": "142134", "train_ups": "0.54", "train_wpb": "263410", "train_bsz": "1753.7", "train_num_updates": "211155", "train_lr": "0.000256583", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "507", "train_gb_free": "40", "train_wall": "399254"}
[2024-10-09 09:04:22,191][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:04:22,229][fairseq.trainer][INFO] - begin training epoch 442
[2024-10-09 09:04:22,230][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:11:08,612][train_inner][INFO] - {"epoch": 442, "update": 441.094, "loss": "0.789", "ntokens": "262808", "nsentences": "1742.78", "wps": "92531", "ups": "0.35", "wpb": "262808", "bsz": "1742.8", "num_updates": "211200", "lr": "0.000256522", "gnorm": "0.262", "loss_scale": "2", "train_wall": "234", "gb_free": "40", "wall": "399661"}
[2024-10-09 09:14:50,050][train_inner][INFO] - {"epoch": 442, "update": 441.511, "loss": "0.786", "ntokens": "264303", "nsentences": "1734.5", "wps": "238726", "ups": "0.9", "wpb": "264303", "bsz": "1734.5", "num_updates": "211400", "lr": "0.00025625", "gnorm": "0.264", "loss_scale": "2", "train_wall": "216", "gb_free": "40.2", "wall": "399882"}
[2024-10-09 09:18:56,185][train_inner][INFO] - {"epoch": 442, "update": 441.929, "loss": "0.787", "ntokens": "264201", "nsentences": "1748.05", "wps": "214693", "ups": "0.81", "wpb": "264201", "bsz": "1748", "num_updates": "211600", "lr": "0.000255978", "gnorm": "0.258", "loss_scale": "2", "train_wall": "241", "gb_free": "39.6", "wall": "400128"}
[2024-10-09 09:19:52,992][fairseq_cli.train][INFO] - end of epoch 442 (average epoch stats below)
[2024-10-09 09:19:53,134][train][INFO] - {"epoch": 442, "train_loss": "0.787", "train_ntokens": "263583", "train_nsentences": "1753.71", "train_wps": "135607", "train_ups": "0.51", "train_wpb": "263583", "train_bsz": "1753.7", "train_num_updates": "211634", "train_lr": "0.000255932", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "590", "train_gb_free": "40", "train_wall": "400185"}
[2024-10-09 09:19:53,334][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:19:53,352][fairseq.trainer][INFO] - begin training epoch 443
[2024-10-09 09:19:53,352][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:28:44,415][train_inner][INFO] - {"epoch": 443, "update": 442.347, "loss": "0.786", "ntokens": "262637", "nsentences": "1757.26", "wps": "89298.4", "ups": "0.34", "wpb": "262637", "bsz": "1757.3", "num_updates": "211800", "lr": "0.000255707", "gnorm": "0.283", "loss_scale": "2", "train_wall": "241", "gb_free": "39.6", "wall": "400717"}
[2024-10-09 09:33:01,333][train_inner][INFO] - {"epoch": 443, "update": 442.764, "loss": "0.789", "ntokens": "263864", "nsentences": "1776.16", "wps": "205415", "ups": "0.78", "wpb": "263864", "bsz": "1776.2", "num_updates": "212000", "lr": "0.000255435", "gnorm": "0.252", "loss_scale": "2", "train_wall": "251", "gb_free": "40", "wall": "400974"}
[2024-10-09 09:34:51,800][fairseq_cli.train][INFO] - end of epoch 443 (average epoch stats below)
[2024-10-09 09:34:51,858][train][INFO] - {"epoch": 443, "train_loss": "0.787", "train_ntokens": "263472", "train_nsentences": "1753.71", "train_wps": "140429", "train_ups": "0.53", "train_wpb": "263472", "train_bsz": "1753.7", "train_num_updates": "212113", "train_lr": "0.000255281", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "39.6", "train_wall": "401084"}
[2024-10-09 09:34:52,007][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:34:52,012][fairseq.trainer][INFO] - begin training epoch 444
[2024-10-09 09:34:52,012][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:43:26,387][train_inner][INFO] - {"epoch": 444, "update": 443.182, "loss": "0.786", "ntokens": "262872", "nsentences": "1738.29", "wps": "84114.8", "ups": "0.32", "wpb": "262872", "bsz": "1738.3", "num_updates": "212200", "lr": "0.000255163", "gnorm": "0.26", "loss_scale": "4", "train_wall": "160", "gb_free": "39.3", "wall": "401599"}
[2024-10-09 09:46:43,808][train_inner][INFO] - {"epoch": 444, "update": 443.599, "loss": "0.786", "ntokens": "263893", "nsentences": "1751.61", "wps": "267385", "ups": "1.01", "wpb": "263893", "bsz": "1751.6", "num_updates": "212400", "lr": "0.000254891", "gnorm": "0.26", "loss_scale": "4", "train_wall": "193", "gb_free": "39.7", "wall": "401796"}
[2024-10-09 09:47:47,927][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 09:50:45,267][fairseq_cli.train][INFO] - end of epoch 444 (average epoch stats below)
[2024-10-09 09:50:45,296][train][INFO] - {"epoch": 444, "train_loss": "0.786", "train_ntokens": "263417", "train_nsentences": "1755.37", "train_wps": "132064", "train_ups": "0.5", "train_wpb": "263417", "train_bsz": "1755.4", "train_num_updates": "212591", "train_lr": "0.000254632", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "440", "train_gb_free": "39.7", "train_wall": "402037"}
[2024-10-09 09:50:45,771][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 09:50:45,807][fairseq.trainer][INFO] - begin training epoch 445
[2024-10-09 09:50:45,807][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:56:51,114][train_inner][INFO] - {"epoch": 445, "update": 444.019, "loss": "0.788", "ntokens": "262676", "nsentences": "1765.81", "wps": "86509.8", "ups": "0.33", "wpb": "262676", "bsz": "1765.8", "num_updates": "212600", "lr": "0.00025462", "gnorm": "0.271", "loss_scale": "2", "train_wall": "212", "gb_free": "39.6", "wall": "402403"}
[2024-10-09 10:00:22,608][train_inner][INFO] - {"epoch": 445, "update": 444.436, "loss": "0.786", "ntokens": "263779", "nsentences": "1769.51", "wps": "249466", "ups": "0.95", "wpb": "263780", "bsz": "1769.5", "num_updates": "212800", "lr": "0.000254348", "gnorm": "0.282", "loss_scale": "2", "train_wall": "150", "gb_free": "39.3", "wall": "402615"}
[2024-10-09 10:04:18,488][train_inner][INFO] - {"epoch": 445, "update": 444.854, "loss": "0.787", "ntokens": "263922", "nsentences": "1769.45", "wps": "223785", "ups": "0.85", "wpb": "263922", "bsz": "1769.5", "num_updates": "213000", "lr": "0.000254076", "gnorm": "0.26", "loss_scale": "2", "train_wall": "151", "gb_free": "40.2", "wall": "402851"}
[2024-10-09 10:05:44,503][fairseq_cli.train][INFO] - end of epoch 445 (average epoch stats below)
[2024-10-09 10:05:44,532][train][INFO] - {"epoch": 445, "train_loss": "0.787", "train_ntokens": "263543", "train_nsentences": "1753.71", "train_wps": "140388", "train_ups": "0.53", "train_wpb": "263542", "train_bsz": "1753.7", "train_num_updates": "213070", "train_lr": "0.000253981", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "380", "train_gb_free": "39.3", "train_wall": "402937"}
[2024-10-09 10:05:44,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:05:44,715][fairseq.trainer][INFO] - begin training epoch 446
[2024-10-09 10:05:44,715][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:14:27,442][train_inner][INFO] - {"epoch": 446, "update": 445.271, "loss": "0.784", "ntokens": "263354", "nsentences": "1708.9", "wps": "86497.2", "ups": "0.33", "wpb": "263354", "bsz": "1708.9", "num_updates": "213200", "lr": "0.000253804", "gnorm": "0.259", "loss_scale": "2", "train_wall": "222", "gb_free": "40", "wall": "403460"}
[2024-10-09 10:18:26,278][train_inner][INFO] - {"epoch": 446, "update": 445.689, "loss": "0.788", "ntokens": "264147", "nsentences": "1759.49", "wps": "221206", "ups": "0.84", "wpb": "264147", "bsz": "1759.5", "num_updates": "213400", "lr": "0.000253533", "gnorm": "0.26", "loss_scale": "2", "train_wall": "233", "gb_free": "39.7", "wall": "403698"}
[2024-10-09 10:21:41,929][fairseq_cli.train][INFO] - end of epoch 446 (average epoch stats below)
[2024-10-09 10:21:41,944][train][INFO] - {"epoch": 446, "train_loss": "0.786", "train_ntokens": "263617", "train_nsentences": "1753.71", "train_wps": "131894", "train_ups": "0.5", "train_wpb": "263617", "train_bsz": "1753.7", "train_num_updates": "213549", "train_lr": "0.00025333", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "584", "train_gb_free": "39.6", "train_wall": "403894"}
[2024-10-09 10:21:42,137][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:21:42,183][fairseq.trainer][INFO] - begin training epoch 447
[2024-10-09 10:21:42,184][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:29:27,224][train_inner][INFO] - {"epoch": 447, "update": 446.106, "loss": "0.786", "ntokens": "262877", "nsentences": "1752.72", "wps": "79547", "ups": "0.3", "wpb": "262878", "bsz": "1752.7", "num_updates": "213600", "lr": "0.000253261", "gnorm": "0.272", "loss_scale": "2", "train_wall": "264", "gb_free": "39.6", "wall": "404359"}
[2024-10-09 10:33:20,823][train_inner][INFO] - {"epoch": 447, "update": 446.524, "loss": "0.786", "ntokens": "264029", "nsentences": "1779.3", "wps": "226061", "ups": "0.86", "wpb": "264028", "bsz": "1779.3", "num_updates": "213800", "lr": "0.000252989", "gnorm": "0.275", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "404593"}
[2024-10-09 10:37:10,855][train_inner][INFO] - {"epoch": 447, "update": 446.942, "loss": "0.786", "ntokens": "264147", "nsentences": "1739.88", "wps": "229670", "ups": "0.87", "wpb": "264147", "bsz": "1739.9", "num_updates": "214000", "lr": "0.000252717", "gnorm": "0.258", "loss_scale": "2", "train_wall": "225", "gb_free": "39.8", "wall": "404823"}
[2024-10-09 10:37:53,443][fairseq_cli.train][INFO] - end of epoch 447 (average epoch stats below)
[2024-10-09 10:37:53,482][train][INFO] - {"epoch": 447, "train_loss": "0.786", "train_ntokens": "263639", "train_nsentences": "1753.71", "train_wps": "129991", "train_ups": "0.49", "train_wpb": "263639", "train_bsz": "1753.7", "train_num_updates": "214028", "train_lr": "0.000252679", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "568", "train_gb_free": "39.6", "train_wall": "404866"}
[2024-10-09 10:37:53,707][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:37:53,727][fairseq.trainer][INFO] - begin training epoch 448
[2024-10-09 10:37:53,728][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:46:52,399][train_inner][INFO] - {"epoch": 448, "update": 447.359, "loss": "0.783", "ntokens": "263203", "nsentences": "1705.97", "wps": "90520.6", "ups": "0.34", "wpb": "263203", "bsz": "1706", "num_updates": "214200", "lr": "0.000252446", "gnorm": "0.276", "loss_scale": "2", "train_wall": "257", "gb_free": "40.2", "wall": "405405"}
[2024-10-09 10:51:00,824][train_inner][INFO] - {"epoch": 448, "update": 447.777, "loss": "0.786", "ntokens": "263660", "nsentences": "1798.65", "wps": "212274", "ups": "0.81", "wpb": "263660", "bsz": "1798.7", "num_updates": "214400", "lr": "0.000252174", "gnorm": "0.27", "loss_scale": "2", "train_wall": "243", "gb_free": "39.3", "wall": "405653"}
[2024-10-09 10:53:08,770][fairseq_cli.train][INFO] - end of epoch 448 (average epoch stats below)
[2024-10-09 10:53:08,804][train][INFO] - {"epoch": 448, "train_loss": "0.785", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "137882", "train_ups": "0.52", "train_wpb": "263475", "train_bsz": "1753.7", "train_num_updates": "214507", "train_lr": "0.000252029", "train_gnorm": "0.267", "train_loss_scale": "4", "train_train_wall": "585", "train_gb_free": "39.6", "train_wall": "405781"}
[2024-10-09 10:53:08,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 10:53:08,967][fairseq.trainer][INFO] - begin training epoch 449
[2024-10-09 10:53:08,968][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:00:33,988][train_inner][INFO] - {"epoch": 449, "update": 448.194, "loss": "0.785", "ntokens": "262669", "nsentences": "1759.44", "wps": "91657.2", "ups": "0.35", "wpb": "262669", "bsz": "1759.4", "num_updates": "214600", "lr": "0.000251902", "gnorm": "0.26", "loss_scale": "4", "train_wall": "229", "gb_free": "40.2", "wall": "406226"}
[2024-10-09 11:04:24,048][train_inner][INFO] - {"epoch": 449, "update": 448.612, "loss": "0.787", "ntokens": "263907", "nsentences": "1757.78", "wps": "229437", "ups": "0.87", "wpb": "263907", "bsz": "1757.8", "num_updates": "214800", "lr": "0.00025163", "gnorm": "0.269", "loss_scale": "4", "train_wall": "224", "gb_free": "39.2", "wall": "406456"}
[2024-10-09 11:08:00,881][fairseq_cli.train][INFO] - end of epoch 449 (average epoch stats below)
[2024-10-09 11:08:00,910][train][INFO] - {"epoch": 449, "train_loss": "0.786", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "141482", "train_ups": "0.54", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "214986", "train_lr": "0.000251378", "train_gnorm": "0.271", "train_loss_scale": "4", "train_train_wall": "539", "train_gb_free": "39.8", "train_wall": "406673"}
[2024-10-09 11:08:01,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:08:01,119][fairseq.trainer][INFO] - begin training epoch 450
[2024-10-09 11:08:01,120][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:14:00,067][train_inner][INFO] - {"epoch": 450, "update": 449.029, "loss": "0.786", "ntokens": "263046", "nsentences": "1726.34", "wps": "91334.3", "ups": "0.35", "wpb": "263046", "bsz": "1726.3", "num_updates": "215000", "lr": "0.000251359", "gnorm": "0.279", "loss_scale": "4", "train_wall": "252", "gb_free": "39.6", "wall": "407032"}
[2024-10-09 11:16:06,495][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 11:17:40,103][train_inner][INFO] - {"epoch": 450, "update": 449.449, "loss": "0.783", "ntokens": "264041", "nsentences": "1743.57", "wps": "240014", "ups": "0.91", "wpb": "264041", "bsz": "1743.6", "num_updates": "215200", "lr": "0.000251087", "gnorm": "0.269", "loss_scale": "2", "train_wall": "214", "gb_free": "39", "wall": "407252"}
[2024-10-09 11:21:54,383][train_inner][INFO] - {"epoch": 450, "update": 449.866, "loss": "0.787", "ntokens": "263767", "nsentences": "1784.23", "wps": "207482", "ups": "0.79", "wpb": "263767", "bsz": "1784.2", "num_updates": "215400", "lr": "0.000250815", "gnorm": "0.258", "loss_scale": "2", "train_wall": "249", "gb_free": "39.3", "wall": "407507"}
[2024-10-09 11:23:33,990][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 450 @ 215464 updates
[2024-10-09 11:23:33,991][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 11:23:38,023][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 11:23:38,043][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 450 @ 215464 updates, score None) (writing took 4.053310648538172 seconds)
[2024-10-09 11:23:38,044][fairseq_cli.train][INFO] - end of epoch 450 (average epoch stats below)
[2024-10-09 11:23:38,047][train][INFO] - {"epoch": 450, "train_loss": "0.785", "train_ntokens": "263454", "train_nsentences": "1752.8", "train_wps": "134380", "train_ups": "0.51", "train_wpb": "263454", "train_bsz": "1752.8", "train_num_updates": "215464", "train_lr": "0.000250728", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "600", "train_gb_free": "39.3", "train_wall": "407610"}
[2024-10-09 11:23:38,116][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:23:38,130][fairseq.trainer][INFO] - begin training epoch 451
[2024-10-09 11:23:38,131][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:31:26,877][train_inner][INFO] - {"epoch": 451, "update": 450.284, "loss": "0.784", "ntokens": "263233", "nsentences": "1719.84", "wps": "91961.4", "ups": "0.35", "wpb": "263233", "bsz": "1719.8", "num_updates": "215600", "lr": "0.000250543", "gnorm": "0.254", "loss_scale": "2", "train_wall": "241", "gb_free": "40.1", "wall": "408079"}
[2024-10-09 11:35:07,489][train_inner][INFO] - {"epoch": 451, "update": 450.701, "loss": "0.788", "ntokens": "263899", "nsentences": "1780.83", "wps": "239256", "ups": "0.91", "wpb": "263898", "bsz": "1780.8", "num_updates": "215800", "lr": "0.000250272", "gnorm": "0.26", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "408300"}
[2024-10-09 11:38:15,416][fairseq_cli.train][INFO] - end of epoch 451 (average epoch stats below)
[2024-10-09 11:38:15,452][train][INFO] - {"epoch": 451, "train_loss": "0.786", "train_ntokens": "263711", "train_nsentences": "1753.71", "train_wps": "143968", "train_ups": "0.55", "train_wpb": "263711", "train_bsz": "1753.7", "train_num_updates": "215943", "train_lr": "0.000250077", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "40", "train_wall": "408488"}
[2024-10-09 11:38:15,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:38:15,600][fairseq.trainer][INFO] - begin training epoch 452
[2024-10-09 11:38:15,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:44:57,974][train_inner][INFO] - {"epoch": 452, "update": 451.119, "loss": "0.786", "ntokens": "262990", "nsentences": "1757.08", "wps": "89077.1", "ups": "0.34", "wpb": "262990", "bsz": "1757.1", "num_updates": "216000", "lr": "0.00025", "gnorm": "0.263", "loss_scale": "2", "train_wall": "274", "gb_free": "39.8", "wall": "408890"}
[2024-10-09 11:48:42,191][train_inner][INFO] - {"epoch": 452, "update": 451.537, "loss": "0.784", "ntokens": "263754", "nsentences": "1775.53", "wps": "235275", "ups": "0.89", "wpb": "263754", "bsz": "1775.5", "num_updates": "216200", "lr": "0.000249728", "gnorm": "0.263", "loss_scale": "2", "train_wall": "219", "gb_free": "38.9", "wall": "409114"}
[2024-10-09 11:52:24,691][train_inner][INFO] - {"epoch": 452, "update": 451.954, "loss": "0.787", "ntokens": "264122", "nsentences": "1748.01", "wps": "237424", "ups": "0.9", "wpb": "264122", "bsz": "1748", "num_updates": "216400", "lr": "0.000249457", "gnorm": "0.27", "loss_scale": "2", "train_wall": "217", "gb_free": "40", "wall": "409337"}
[2024-10-09 11:53:12,292][fairseq_cli.train][INFO] - end of epoch 452 (average epoch stats below)
[2024-10-09 11:53:12,300][train][INFO] - {"epoch": 452, "train_loss": "0.786", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "140738", "train_ups": "0.53", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "216422", "train_lr": "0.000249427", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "39.3", "train_wall": "409384"}
[2024-10-09 11:53:12,398][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 11:53:12,422][fairseq.trainer][INFO] - begin training epoch 453
[2024-10-09 11:53:12,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:02:07,961][train_inner][INFO] - {"epoch": 453, "update": 452.372, "loss": "0.783", "ntokens": "262731", "nsentences": "1757.74", "wps": "90090.9", "ups": "0.34", "wpb": "262731", "bsz": "1757.7", "num_updates": "216600", "lr": "0.000249185", "gnorm": "0.269", "loss_scale": "2", "train_wall": "253", "gb_free": "40.2", "wall": "409920"}
[2024-10-09 12:05:43,775][train_inner][INFO] - {"epoch": 453, "update": 452.789, "loss": "0.783", "ntokens": "264320", "nsentences": "1719.04", "wps": "244969", "ups": "0.93", "wpb": "264320", "bsz": "1719", "num_updates": "216800", "lr": "0.000248913", "gnorm": "0.261", "loss_scale": "2", "train_wall": "210", "gb_free": "40.3", "wall": "410136"}
[2024-10-09 12:07:53,009][fairseq_cli.train][INFO] - end of epoch 453 (average epoch stats below)
[2024-10-09 12:07:53,025][train][INFO] - {"epoch": 453, "train_loss": "0.784", "train_ntokens": "263463", "train_nsentences": "1753.71", "train_wps": "143291", "train_ups": "0.54", "train_wpb": "263463", "train_bsz": "1753.7", "train_num_updates": "216901", "train_lr": "0.000248776", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "39.3", "train_wall": "410265"}
[2024-10-09 12:07:53,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:07:53,123][fairseq.trainer][INFO] - begin training epoch 454
[2024-10-09 12:07:53,124][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:15:15,988][train_inner][INFO] - {"epoch": 454, "update": 453.207, "loss": "0.786", "ntokens": "262663", "nsentences": "1748.88", "wps": "91811.3", "ups": "0.35", "wpb": "262662", "bsz": "1748.9", "num_updates": "217000", "lr": "0.000248641", "gnorm": "0.272", "loss_scale": "2", "train_wall": "257", "gb_free": "39.6", "wall": "410708"}
[2024-10-09 12:16:28,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-09 12:19:19,763][train_inner][INFO] - {"epoch": 454, "update": 453.626, "loss": "0.786", "ntokens": "263750", "nsentences": "1805.66", "wps": "216397", "ups": "0.82", "wpb": "263750", "bsz": "1805.7", "num_updates": "217200", "lr": "0.00024837", "gnorm": "0.278", "loss_scale": "1", "train_wall": "238", "gb_free": "39.2", "wall": "410952"}
[2024-10-09 12:22:01,956][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-09 12:22:43,477][fairseq_cli.train][INFO] - end of epoch 454 (average epoch stats below)
[2024-10-09 12:22:43,498][train][INFO] - {"epoch": 454, "train_loss": "0.785", "train_ntokens": "263573", "train_nsentences": "1750.46", "train_wps": "141191", "train_ups": "0.54", "train_wpb": "263573", "train_bsz": "1750.5", "train_num_updates": "217378", "train_lr": "0.000248128", "train_gnorm": "0.272", "train_loss_scale": "0.5", "train_train_wall": "568", "train_gb_free": "39.6", "train_wall": "411156"}
[2024-10-09 12:22:43,666][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:22:43,685][fairseq.trainer][INFO] - begin training epoch 455
[2024-10-09 12:22:43,686][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:28:53,586][train_inner][INFO] - {"epoch": 455, "update": 454.046, "loss": "0.783", "ntokens": "263250", "nsentences": "1701.36", "wps": "91755.3", "ups": "0.35", "wpb": "263250", "bsz": "1701.4", "num_updates": "217400", "lr": "0.000248098", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "241", "gb_free": "40", "wall": "411526"}
[2024-10-09 12:32:11,599][train_inner][INFO] - {"epoch": 455, "update": 454.463, "loss": "0.782", "ntokens": "264118", "nsentences": "1728.32", "wps": "266787", "ups": "1.01", "wpb": "264118", "bsz": "1728.3", "num_updates": "217600", "lr": "0.000247826", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "160", "gb_free": "39.6", "wall": "411724"}
[2024-10-09 12:36:21,065][train_inner][INFO] - {"epoch": 455, "update": 454.881, "loss": "0.786", "ntokens": "263621", "nsentences": "1793.27", "wps": "211363", "ups": "0.8", "wpb": "263621", "bsz": "1793.3", "num_updates": "217800", "lr": "0.000247554", "gnorm": "0.266", "loss_scale": "0.5", "train_wall": "243", "gb_free": "40.2", "wall": "411973"}
[2024-10-09 12:37:49,931][fairseq_cli.train][INFO] - end of epoch 455 (average epoch stats below)
[2024-10-09 12:37:49,952][train][INFO] - {"epoch": 455, "train_loss": "0.784", "train_ntokens": "263459", "train_nsentences": "1753.71", "train_wps": "139221", "train_ups": "0.53", "train_wpb": "263459", "train_bsz": "1753.7", "train_num_updates": "217857", "train_lr": "0.000247477", "train_gnorm": "0.269", "train_loss_scale": "0.5", "train_train_wall": "532", "train_gb_free": "39.6", "train_wall": "412062"}
[2024-10-09 12:37:50,012][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:37:50,016][fairseq.trainer][INFO] - begin training epoch 456
[2024-10-09 12:37:50,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:45:50,522][train_inner][INFO] - {"epoch": 456, "update": 455.299, "loss": "0.784", "ntokens": "262699", "nsentences": "1761.66", "wps": "92265.2", "ups": "0.35", "wpb": "262700", "bsz": "1761.7", "num_updates": "218000", "lr": "0.000247283", "gnorm": "0.273", "loss_scale": "0.5", "train_wall": "261", "gb_free": "40.3", "wall": "412543"}
[2024-10-09 12:50:01,448][train_inner][INFO] - {"epoch": 456, "update": 455.716, "loss": "0.784", "ntokens": "263801", "nsentences": "1767.85", "wps": "210282", "ups": "0.8", "wpb": "263801", "bsz": "1767.8", "num_updates": "218200", "lr": "0.000247011", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "245", "gb_free": "39.7", "wall": "412794"}
[2024-10-09 12:52:48,681][fairseq_cli.train][INFO] - end of epoch 456 (average epoch stats below)
[2024-10-09 12:52:48,722][train][INFO] - {"epoch": 456, "train_loss": "0.784", "train_ntokens": "263437", "train_nsentences": "1753.71", "train_wps": "140404", "train_ups": "0.53", "train_wpb": "263437", "train_bsz": "1753.7", "train_num_updates": "218336", "train_lr": "0.000246826", "train_gnorm": "0.27", "train_loss_scale": "0.5", "train_train_wall": "582", "train_gb_free": "39.6", "train_wall": "412961"}
[2024-10-09 12:52:48,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 12:52:48,791][fairseq.trainer][INFO] - begin training epoch 457
[2024-10-09 12:52:48,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:59:35,318][train_inner][INFO] - {"epoch": 457, "update": 456.134, "loss": "0.783", "ntokens": "263310", "nsentences": "1692.01", "wps": "91769.4", "ups": "0.35", "wpb": "263310", "bsz": "1692", "num_updates": "218400", "lr": "0.000246739", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "222", "gb_free": "39.2", "wall": "413367"}
[2024-10-09 13:03:06,443][train_inner][INFO] - {"epoch": 457, "update": 456.551, "loss": "0.785", "ntokens": "263740", "nsentences": "1781.99", "wps": "249870", "ups": "0.95", "wpb": "263740", "bsz": "1782", "num_updates": "218600", "lr": "0.000246467", "gnorm": "0.275", "loss_scale": "0.5", "train_wall": "206", "gb_free": "39.6", "wall": "413579"}
[2024-10-09 13:06:44,654][train_inner][INFO] - {"epoch": 457, "update": 456.969, "loss": "0.785", "ntokens": "264172", "nsentences": "1770.74", "wps": "242147", "ups": "0.92", "wpb": "264172", "bsz": "1770.7", "num_updates": "218800", "lr": "0.000246196", "gnorm": "0.266", "loss_scale": "0.5", "train_wall": "213", "gb_free": "39.2", "wall": "413797"}
[2024-10-09 13:07:25,724][fairseq_cli.train][INFO] - end of epoch 457 (average epoch stats below)
[2024-10-09 13:07:25,740][train][INFO] - {"epoch": 457, "train_loss": "0.784", "train_ntokens": "263626", "train_nsentences": "1753.71", "train_wps": "143986", "train_ups": "0.55", "train_wpb": "263626", "train_bsz": "1753.7", "train_num_updates": "218815", "train_lr": "0.000246175", "train_gnorm": "0.273", "train_loss_scale": "0.5", "train_train_wall": "516", "train_gb_free": "39.6", "train_wall": "413838"}
[2024-10-09 13:07:25,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:07:25,869][fairseq.trainer][INFO] - begin training epoch 458
[2024-10-09 13:07:25,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:16:22,799][train_inner][INFO] - {"epoch": 458, "update": 457.386, "loss": "0.783", "ntokens": "262762", "nsentences": "1754.83", "wps": "90900.1", "ups": "0.35", "wpb": "262762", "bsz": "1754.8", "num_updates": "219000", "lr": "0.000245924", "gnorm": "0.26", "loss_scale": "0.5", "train_wall": "256", "gb_free": "39.7", "wall": "414375"}
[2024-10-09 13:20:39,125][train_inner][INFO] - {"epoch": 458, "update": 457.804, "loss": "0.785", "ntokens": "264023", "nsentences": "1756.86", "wps": "206031", "ups": "0.78", "wpb": "264023", "bsz": "1756.9", "num_updates": "219200", "lr": "0.000245652", "gnorm": "0.276", "loss_scale": "0.5", "train_wall": "247", "gb_free": "40.1", "wall": "414631"}
[2024-10-09 13:22:24,021][fairseq_cli.train][INFO] - end of epoch 458 (average epoch stats below)
[2024-10-09 13:22:24,082][train][INFO] - {"epoch": 458, "train_loss": "0.784", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "140510", "train_ups": "0.53", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "219294", "train_lr": "0.000245524", "train_gnorm": "0.268", "train_loss_scale": "0.5", "train_train_wall": "566", "train_gb_free": "39.8", "train_wall": "414736"}
[2024-10-09 13:22:24,249][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:22:24,280][fairseq.trainer][INFO] - begin training epoch 459
[2024-10-09 13:22:24,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:30:15,453][train_inner][INFO] - {"epoch": 459, "update": 458.221, "loss": "0.783", "ntokens": "262696", "nsentences": "1763.36", "wps": "91165.1", "ups": "0.35", "wpb": "262696", "bsz": "1763.4", "num_updates": "219400", "lr": "0.00024538", "gnorm": "0.268", "loss_scale": "1", "train_wall": "192", "gb_free": "39.8", "wall": "415208"}
[2024-10-09 13:33:48,119][train_inner][INFO] - {"epoch": 459, "update": 458.639, "loss": "0.782", "ntokens": "264070", "nsentences": "1737.34", "wps": "248376", "ups": "0.94", "wpb": "264070", "bsz": "1737.3", "num_updates": "219600", "lr": "0.000245109", "gnorm": "0.258", "loss_scale": "1", "train_wall": "156", "gb_free": "39.6", "wall": "415420"}
[2024-10-09 13:37:18,777][fairseq_cli.train][INFO] - end of epoch 459 (average epoch stats below)
[2024-10-09 13:37:18,792][train][INFO] - {"epoch": 459, "train_loss": "0.783", "train_ntokens": "263513", "train_nsentences": "1753.71", "train_wps": "141078", "train_ups": "0.54", "train_wpb": "263513", "train_bsz": "1753.7", "train_num_updates": "219773", "train_lr": "0.000244874", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "439", "train_gb_free": "39.2", "train_wall": "415631"}
[2024-10-09 13:37:18,887][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:37:18,924][fairseq.trainer][INFO] - begin training epoch 460
[2024-10-09 13:37:18,924][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:43:39,187][train_inner][INFO] - {"epoch": 460, "update": 459.056, "loss": "0.784", "ntokens": "263131", "nsentences": "1730.78", "wps": "89038", "ups": "0.34", "wpb": "263131", "bsz": "1730.8", "num_updates": "219800", "lr": "0.000244837", "gnorm": "0.291", "loss_scale": "1", "train_wall": "249", "gb_free": "40.2", "wall": "416011"}
[2024-10-09 13:47:28,905][train_inner][INFO] - {"epoch": 460, "update": 459.474, "loss": "0.783", "ntokens": "263635", "nsentences": "1793.2", "wps": "229549", "ups": "0.87", "wpb": "263635", "bsz": "1793.2", "num_updates": "220000", "lr": "0.000244565", "gnorm": "0.263", "loss_scale": "1", "train_wall": "224", "gb_free": "39.6", "wall": "416241"}
[2024-10-09 13:51:17,519][train_inner][INFO] - {"epoch": 460, "update": 459.891, "loss": "0.784", "ntokens": "264062", "nsentences": "1746.39", "wps": "231019", "ups": "0.87", "wpb": "264062", "bsz": "1746.4", "num_updates": "220200", "lr": "0.000244293", "gnorm": "0.269", "loss_scale": "1", "train_wall": "223", "gb_free": "40.8", "wall": "416470"}
[2024-10-09 13:52:16,327][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 460 @ 220252 updates
[2024-10-09 13:52:16,328][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 13:52:24,194][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 13:52:24,500][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 460 @ 220252 updates, score None) (writing took 8.172787788324058 seconds)
[2024-10-09 13:52:24,508][fairseq_cli.train][INFO] - end of epoch 460 (average epoch stats below)
[2024-10-09 13:52:24,521][train][INFO] - {"epoch": 460, "train_loss": "0.783", "train_ntokens": "263437", "train_nsentences": "1753.71", "train_wps": "139322", "train_ups": "0.53", "train_wpb": "263437", "train_bsz": "1753.7", "train_num_updates": "220252", "train_lr": "0.000244223", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "559", "train_gb_free": "40", "train_wall": "416537"}
[2024-10-09 13:52:24,819][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 13:52:24,861][fairseq.trainer][INFO] - begin training epoch 461
[2024-10-09 13:52:24,862][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:00:44,960][train_inner][INFO] - {"epoch": 461, "update": 460.309, "loss": "0.782", "ntokens": "262892", "nsentences": "1736.21", "wps": "92662", "ups": "0.35", "wpb": "262892", "bsz": "1736.2", "num_updates": "220400", "lr": "0.000244022", "gnorm": "0.272", "loss_scale": "1", "train_wall": "237", "gb_free": "40.2", "wall": "417037"}
[2024-10-09 14:05:06,437][train_inner][INFO] - {"epoch": 461, "update": 460.727, "loss": "0.783", "ntokens": "264055", "nsentences": "1762.9", "wps": "201986", "ups": "0.76", "wpb": "264055", "bsz": "1762.9", "num_updates": "220600", "lr": "0.00024375", "gnorm": "0.271", "loss_scale": "1", "train_wall": "256", "gb_free": "39.6", "wall": "417299"}
[2024-10-09 14:08:10,821][fairseq_cli.train][INFO] - end of epoch 461 (average epoch stats below)
[2024-10-09 14:08:10,834][train][INFO] - {"epoch": 461, "train_loss": "0.783", "train_ntokens": "263541", "train_nsentences": "1753.71", "train_wps": "133401", "train_ups": "0.51", "train_wpb": "263541", "train_bsz": "1753.7", "train_num_updates": "220731", "train_lr": "0.000243572", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "617", "train_gb_free": "40.2", "train_wall": "417483"}
[2024-10-09 14:08:10,896][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:08:10,909][fairseq.trainer][INFO] - begin training epoch 462
[2024-10-09 14:08:10,910][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:14:55,215][train_inner][INFO] - {"epoch": 462, "update": 461.144, "loss": "0.786", "ntokens": "262522", "nsentences": "1775.8", "wps": "89177.5", "ups": "0.34", "wpb": "262522", "bsz": "1775.8", "num_updates": "220800", "lr": "0.000243478", "gnorm": "0.274", "loss_scale": "1", "train_wall": "272", "gb_free": "39.6", "wall": "417887"}
[2024-10-09 14:18:14,947][train_inner][INFO] - {"epoch": 462, "update": 461.562, "loss": "0.781", "ntokens": "264422", "nsentences": "1699.2", "wps": "264803", "ups": "1", "wpb": "264422", "bsz": "1699.2", "num_updates": "221000", "lr": "0.000243207", "gnorm": "0.261", "loss_scale": "1", "train_wall": "195", "gb_free": "40.5", "wall": "418087"}
[2024-10-09 14:22:30,894][train_inner][INFO] - {"epoch": 462, "update": 461.979, "loss": "0.785", "ntokens": "263931", "nsentences": "1788.18", "wps": "206266", "ups": "0.78", "wpb": "263931", "bsz": "1788.2", "num_updates": "221200", "lr": "0.000242935", "gnorm": "0.273", "loss_scale": "1", "train_wall": "251", "gb_free": "40", "wall": "418343"}
[2024-10-09 14:23:06,005][fairseq_cli.train][INFO] - end of epoch 462 (average epoch stats below)
[2024-10-09 14:23:06,037][train][INFO] - {"epoch": 462, "train_loss": "0.783", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "141032", "train_ups": "0.54", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "221210", "train_lr": "0.000242921", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "570", "train_gb_free": "39.1", "train_wall": "418378"}
[2024-10-09 14:23:06,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:23:06,197][fairseq.trainer][INFO] - begin training epoch 463
[2024-10-09 14:23:06,198][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:31:57,432][train_inner][INFO] - {"epoch": 463, "update": 462.397, "loss": "0.779", "ntokens": "263126", "nsentences": "1716.92", "wps": "92896", "ups": "0.35", "wpb": "263126", "bsz": "1716.9", "num_updates": "221400", "lr": "0.000242663", "gnorm": "0.271", "loss_scale": "1", "train_wall": "234", "gb_free": "39.8", "wall": "418910"}
[2024-10-09 14:36:11,456][train_inner][INFO] - {"epoch": 463, "update": 462.814, "loss": "0.785", "ntokens": "263785", "nsentences": "1770.07", "wps": "207696", "ups": "0.79", "wpb": "263785", "bsz": "1770.1", "num_updates": "221600", "lr": "0.000242391", "gnorm": "0.256", "loss_scale": "2", "train_wall": "248", "gb_free": "39.7", "wall": "419164"}
[2024-10-09 14:38:17,385][fairseq_cli.train][INFO] - end of epoch 463 (average epoch stats below)
[2024-10-09 14:38:17,388][train][INFO] - {"epoch": 463, "train_loss": "0.783", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "138485", "train_ups": "0.53", "train_wpb": "263475", "train_bsz": "1753.7", "train_num_updates": "221689", "train_lr": "0.00024227", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "572", "train_gb_free": "39.6", "train_wall": "419290"}
[2024-10-09 14:38:17,437][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:38:17,462][fairseq.trainer][INFO] - begin training epoch 464
[2024-10-09 14:38:17,462][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:45:43,189][train_inner][INFO] - {"epoch": 464, "update": 463.232, "loss": "0.783", "ntokens": "262886", "nsentences": "1757.9", "wps": "91967.8", "ups": "0.35", "wpb": "262886", "bsz": "1757.9", "num_updates": "221800", "lr": "0.00024212", "gnorm": "0.279", "loss_scale": "2", "train_wall": "269", "gb_free": "40", "wall": "419735"}
[2024-10-09 14:48:08,307][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-09 14:49:34,830][train_inner][INFO] - {"epoch": 464, "update": 463.651, "loss": "0.782", "ntokens": "264118", "nsentences": "1749.36", "wps": "228056", "ups": "0.86", "wpb": "264118", "bsz": "1749.4", "num_updates": "222000", "lr": "0.000241848", "gnorm": "0.266", "loss_scale": "1", "train_wall": "226", "gb_free": "39.6", "wall": "419967"}
[2024-10-09 14:53:03,531][fairseq_cli.train][INFO] - end of epoch 464 (average epoch stats below)
[2024-10-09 14:53:03,550][train][INFO] - {"epoch": 464, "train_loss": "0.783", "train_ntokens": "263510", "train_nsentences": "1752.43", "train_wps": "142140", "train_ups": "0.54", "train_wpb": "263510", "train_bsz": "1752.4", "train_num_updates": "222167", "train_lr": "0.000241621", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "575", "train_gb_free": "39.6", "train_wall": "420176"}
[2024-10-09 14:53:03,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 14:53:03,642][fairseq.trainer][INFO] - begin training epoch 465
[2024-10-09 14:53:03,643][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:59:25,816][train_inner][INFO] - {"epoch": 465, "update": 464.069, "loss": "0.786", "ntokens": "262488", "nsentences": "1761.16", "wps": "88832", "ups": "0.34", "wpb": "262488", "bsz": "1761.2", "num_updates": "222200", "lr": "0.000241576", "gnorm": "0.273", "loss_scale": "1", "train_wall": "276", "gb_free": "39.1", "wall": "420558"}
[2024-10-09 15:02:59,522][train_inner][INFO] - {"epoch": 465, "update": 464.486, "loss": "0.78", "ntokens": "264219", "nsentences": "1719.49", "wps": "247345", "ups": "0.94", "wpb": "264219", "bsz": "1719.5", "num_updates": "222400", "lr": "0.000241304", "gnorm": "0.264", "loss_scale": "1", "train_wall": "208", "gb_free": "40.8", "wall": "420772"}
[2024-10-09 15:07:26,561][train_inner][INFO] - {"epoch": 465, "update": 464.904, "loss": "0.782", "ntokens": "264081", "nsentences": "1758.81", "wps": "197792", "ups": "0.75", "wpb": "264082", "bsz": "1758.8", "num_updates": "222600", "lr": "0.000241033", "gnorm": "0.266", "loss_scale": "1", "train_wall": "261", "gb_free": "39.3", "wall": "421039"}
[2024-10-09 15:08:22,627][fairseq_cli.train][INFO] - end of epoch 465 (average epoch stats below)
[2024-10-09 15:08:22,642][train][INFO] - {"epoch": 465, "train_loss": "0.782", "train_ntokens": "263536", "train_nsentences": "1753.71", "train_wps": "137349", "train_ups": "0.52", "train_wpb": "263536", "train_bsz": "1753.7", "train_num_updates": "222646", "train_lr": "0.00024097", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "597", "train_gb_free": "39.6", "train_wall": "421095"}
[2024-10-09 15:08:22,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:08:22,752][fairseq.trainer][INFO] - begin training epoch 466
[2024-10-09 15:08:22,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:16:45,147][train_inner][INFO] - {"epoch": 466, "update": 465.322, "loss": "0.783", "ntokens": "262756", "nsentences": "1763.18", "wps": "94080.4", "ups": "0.36", "wpb": "262756", "bsz": "1763.2", "num_updates": "222800", "lr": "0.000240761", "gnorm": "0.281", "loss_scale": "1", "train_wall": "227", "gb_free": "40", "wall": "421597"}
[2024-10-09 15:20:39,047][train_inner][INFO] - {"epoch": 466, "update": 465.739, "loss": "0.783", "ntokens": "263886", "nsentences": "1765.35", "wps": "225674", "ups": "0.86", "wpb": "263886", "bsz": "1765.4", "num_updates": "223000", "lr": "0.000240489", "gnorm": "0.26", "loss_scale": "1", "train_wall": "228", "gb_free": "39.6", "wall": "421831"}
[2024-10-09 15:23:08,100][fairseq_cli.train][INFO] - end of epoch 466 (average epoch stats below)
[2024-10-09 15:23:08,125][train][INFO] - {"epoch": 466, "train_loss": "0.782", "train_ntokens": "263506", "train_nsentences": "1753.71", "train_wps": "142545", "train_ups": "0.54", "train_wpb": "263506", "train_bsz": "1753.7", "train_num_updates": "223125", "train_lr": "0.000240319", "train_gnorm": "0.273", "train_loss_scale": "1", "train_train_wall": "546", "train_gb_free": "40", "train_wall": "421980"}
[2024-10-09 15:23:08,217][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:23:08,261][fairseq.trainer][INFO] - begin training epoch 467
[2024-10-09 15:23:08,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:30:09,296][train_inner][INFO] - {"epoch": 467, "update": 466.157, "loss": "0.781", "ntokens": "262896", "nsentences": "1758.05", "wps": "92207.1", "ups": "0.35", "wpb": "262896", "bsz": "1758", "num_updates": "223200", "lr": "0.000240217", "gnorm": "0.267", "loss_scale": "1", "train_wall": "231", "gb_free": "39.3", "wall": "422401"}
[2024-10-09 15:34:05,835][train_inner][INFO] - {"epoch": 467, "update": 466.574, "loss": "0.783", "ntokens": "263570", "nsentences": "1797.01", "wps": "222878", "ups": "0.85", "wpb": "263570", "bsz": "1797", "num_updates": "223400", "lr": "0.000239946", "gnorm": "0.263", "loss_scale": "1", "train_wall": "231", "gb_free": "40", "wall": "422638"}
[2024-10-09 15:38:03,778][train_inner][INFO] - {"epoch": 467, "update": 466.992, "loss": "0.783", "ntokens": "264208", "nsentences": "1717.07", "wps": "222151", "ups": "0.84", "wpb": "264208", "bsz": "1717.1", "num_updates": "223600", "lr": "0.000239674", "gnorm": "0.289", "loss_scale": "1", "train_wall": "232", "gb_free": "39.6", "wall": "422876"}
[2024-10-09 15:38:15,910][fairseq_cli.train][INFO] - end of epoch 467 (average epoch stats below)
[2024-10-09 15:38:15,935][train][INFO] - {"epoch": 467, "train_loss": "0.782", "train_ntokens": "263448", "train_nsentences": "1753.71", "train_wps": "139013", "train_ups": "0.53", "train_wpb": "263448", "train_bsz": "1753.7", "train_num_updates": "223604", "train_lr": "0.000239668", "train_gnorm": "0.27", "train_loss_scale": "1", "train_train_wall": "561", "train_gb_free": "40", "train_wall": "422888"}
[2024-10-09 15:38:16,083][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:38:16,107][fairseq.trainer][INFO] - begin training epoch 468
[2024-10-09 15:38:16,108][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:47:48,729][train_inner][INFO] - {"epoch": 468, "update": 467.409, "loss": "0.781", "ntokens": "263119", "nsentences": "1732.32", "wps": "89969", "ups": "0.34", "wpb": "263119", "bsz": "1732.3", "num_updates": "223800", "lr": "0.000239402", "gnorm": "0.267", "loss_scale": "1", "train_wall": "256", "gb_free": "39.2", "wall": "423461"}
[2024-10-09 15:52:00,975][train_inner][INFO] - {"epoch": 468, "update": 467.827, "loss": "0.78", "ntokens": "264033", "nsentences": "1741.49", "wps": "209361", "ups": "0.79", "wpb": "264033", "bsz": "1741.5", "num_updates": "224000", "lr": "0.00023913", "gnorm": "0.268", "loss_scale": "2", "train_wall": "247", "gb_free": "40.2", "wall": "423713"}
[2024-10-09 15:53:41,056][fairseq_cli.train][INFO] - end of epoch 468 (average epoch stats below)
[2024-10-09 15:53:41,088][train][INFO] - {"epoch": 468, "train_loss": "0.781", "train_ntokens": "263524", "train_nsentences": "1753.71", "train_wps": "136441", "train_ups": "0.52", "train_wpb": "263524", "train_bsz": "1753.7", "train_num_updates": "224083", "train_lr": "0.000239018", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "590", "train_gb_free": "39.6", "train_wall": "423813"}
[2024-10-09 15:53:41,166][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 15:53:41,217][fairseq.trainer][INFO] - begin training epoch 469
[2024-10-09 15:53:41,218][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:01:38,793][train_inner][INFO] - {"epoch": 469, "update": 468.244, "loss": "0.782", "ntokens": "262622", "nsentences": "1772.99", "wps": "90905.8", "ups": "0.35", "wpb": "262622", "bsz": "1773", "num_updates": "224200", "lr": "0.000238859", "gnorm": "0.259", "loss_scale": "2", "train_wall": "241", "gb_free": "39.8", "wall": "424291"}
[2024-10-09 16:05:23,993][train_inner][INFO] - {"epoch": 469, "update": 468.662, "loss": "0.782", "ntokens": "263635", "nsentences": "1788.83", "wps": "234149", "ups": "0.89", "wpb": "263635", "bsz": "1788.8", "num_updates": "224400", "lr": "0.000238587", "gnorm": "0.275", "loss_scale": "2", "train_wall": "220", "gb_free": "40.5", "wall": "424516"}
[2024-10-09 16:08:36,333][fairseq_cli.train][INFO] - end of epoch 469 (average epoch stats below)
[2024-10-09 16:08:36,353][train][INFO] - {"epoch": 469, "train_loss": "0.782", "train_ntokens": "263450", "train_nsentences": "1753.71", "train_wps": "140957", "train_ups": "0.54", "train_wpb": "263450", "train_bsz": "1753.7", "train_num_updates": "224562", "train_lr": "0.000238367", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.3", "train_wall": "424709"}
[2024-10-09 16:08:36,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:08:36,555][fairseq.trainer][INFO] - begin training epoch 470
[2024-10-09 16:08:36,556][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:15:08,670][train_inner][INFO] - {"epoch": 470, "update": 469.079, "loss": "0.781", "ntokens": "262931", "nsentences": "1733.5", "wps": "89943.2", "ups": "0.34", "wpb": "262931", "bsz": "1733.5", "num_updates": "224600", "lr": "0.000238315", "gnorm": "0.266", "loss_scale": "2", "train_wall": "249", "gb_free": "39.3", "wall": "425101"}
[2024-10-09 16:19:16,320][train_inner][INFO] - {"epoch": 470, "update": 469.497, "loss": "0.783", "ntokens": "263720", "nsentences": "1797.49", "wps": "212991", "ups": "0.81", "wpb": "263720", "bsz": "1797.5", "num_updates": "224800", "lr": "0.000238043", "gnorm": "0.267", "loss_scale": "2", "train_wall": "242", "gb_free": "39.8", "wall": "425348"}
[2024-10-09 16:23:08,570][train_inner][INFO] - {"epoch": 470, "update": 469.914, "loss": "0.781", "ntokens": "264116", "nsentences": "1724.04", "wps": "227458", "ups": "0.86", "wpb": "264116", "bsz": "1724", "num_updates": "225000", "lr": "0.000237772", "gnorm": "0.271", "loss_scale": "2", "train_wall": "227", "gb_free": "39.2", "wall": "425581"}
[2024-10-09 16:24:10,551][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 470 @ 225041 updates
[2024-10-09 16:24:10,552][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 16:24:16,676][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 16:24:16,960][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 470 @ 225041 updates, score None) (writing took 6.408779158256948 seconds)
[2024-10-09 16:24:16,960][fairseq_cli.train][INFO] - end of epoch 470 (average epoch stats below)
[2024-10-09 16:24:16,972][train][INFO] - {"epoch": 470, "train_loss": "0.782", "train_ntokens": "263470", "train_nsentences": "1753.71", "train_wps": "134176", "train_ups": "0.51", "train_wpb": "263470", "train_bsz": "1753.7", "train_num_updates": "225041", "train_lr": "0.000237716", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "591", "train_gb_free": "40", "train_wall": "425649"}
[2024-10-09 16:24:17,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:24:17,130][fairseq.trainer][INFO] - begin training epoch 471
[2024-10-09 16:24:17,131][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:32:44,929][train_inner][INFO] - {"epoch": 471, "update": 470.332, "loss": "0.78", "ntokens": "262877", "nsentences": "1730.79", "wps": "91222.1", "ups": "0.35", "wpb": "262876", "bsz": "1730.8", "num_updates": "225200", "lr": "0.0002375", "gnorm": "0.265", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "426157"}
[2024-10-09 16:36:39,427][train_inner][INFO] - {"epoch": 471, "update": 470.749, "loss": "0.781", "ntokens": "263907", "nsentences": "1753.16", "wps": "225112", "ups": "0.85", "wpb": "263907", "bsz": "1753.2", "num_updates": "225400", "lr": "0.000237228", "gnorm": "0.27", "loss_scale": "2", "train_wall": "229", "gb_free": "39.8", "wall": "426392"}
[2024-10-09 16:38:52,356][fairseq_cli.train][INFO] - end of epoch 471 (average epoch stats below)
[2024-10-09 16:38:52,365][train][INFO] - {"epoch": 471, "train_loss": "0.781", "train_ntokens": "263427", "train_nsentences": "1753.71", "train_wps": "144144", "train_ups": "0.55", "train_wpb": "263427", "train_bsz": "1753.7", "train_num_updates": "225520", "train_lr": "0.000237065", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "528", "train_gb_free": "39.8", "train_wall": "426525"}
[2024-10-09 16:38:52,527][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:38:52,543][fairseq.trainer][INFO] - begin training epoch 472
[2024-10-09 16:38:52,544][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:46:10,651][train_inner][INFO] - {"epoch": 472, "update": 471.167, "loss": "0.781", "ntokens": "262835", "nsentences": "1756.77", "wps": "92031.3", "ups": "0.35", "wpb": "262835", "bsz": "1756.8", "num_updates": "225600", "lr": "0.000236957", "gnorm": "0.274", "loss_scale": "2", "train_wall": "248", "gb_free": "39.3", "wall": "426963"}
[2024-10-09 16:48:27,164][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-09 16:49:45,123][train_inner][INFO] - {"epoch": 472, "update": 471.587, "loss": "0.781", "ntokens": "264170", "nsentences": "1745.21", "wps": "246394", "ups": "0.93", "wpb": "264170", "bsz": "1745.2", "num_updates": "225800", "lr": "0.000236685", "gnorm": "0.256", "loss_scale": "1", "train_wall": "209", "gb_free": "39.6", "wall": "427177"}
[2024-10-09 16:51:15,774][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-09 16:53:53,414][fairseq_cli.train][INFO] - end of epoch 472 (average epoch stats below)
[2024-10-09 16:53:53,442][train][INFO] - {"epoch": 472, "train_loss": "0.781", "train_ntokens": "263592", "train_nsentences": "1753.13", "train_wps": "139542", "train_ups": "0.53", "train_wpb": "263592", "train_bsz": "1753.1", "train_num_updates": "225997", "train_lr": "0.000236417", "train_gnorm": "0.264", "train_loss_scale": "0.5", "train_train_wall": "570", "train_gb_free": "41", "train_wall": "427426"}
[2024-10-09 16:53:53,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 16:53:53,556][fairseq.trainer][INFO] - begin training epoch 473
[2024-10-09 16:53:53,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:59:34,233][train_inner][INFO] - {"epoch": 473, "update": 472.006, "loss": "0.782", "ntokens": "262772", "nsentences": "1763.92", "wps": "89213.8", "ups": "0.34", "wpb": "262772", "bsz": "1763.9", "num_updates": "226000", "lr": "0.000236413", "gnorm": "0.268", "loss_scale": "0.5", "train_wall": "272", "gb_free": "39.7", "wall": "427766"}
[2024-10-09 17:03:08,062][train_inner][INFO] - {"epoch": 473, "update": 472.424, "loss": "0.781", "ntokens": "263939", "nsentences": "1760.71", "wps": "246917", "ups": "0.94", "wpb": "263939", "bsz": "1760.7", "num_updates": "226200", "lr": "0.000236141", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "208", "gb_free": "39.6", "wall": "427980"}
[2024-10-09 17:06:57,756][train_inner][INFO] - {"epoch": 473, "update": 472.841, "loss": "0.78", "ntokens": "264063", "nsentences": "1747.6", "wps": "229935", "ups": "0.87", "wpb": "264063", "bsz": "1747.6", "num_updates": "226400", "lr": "0.00023587", "gnorm": "0.289", "loss_scale": "0.5", "train_wall": "224", "gb_free": "39.3", "wall": "428210"}
[2024-10-09 17:08:13,026][fairseq_cli.train][INFO] - end of epoch 473 (average epoch stats below)
[2024-10-09 17:08:13,043][train][INFO] - {"epoch": 473, "train_loss": "0.781", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "146830", "train_ups": "0.56", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "226476", "train_lr": "0.000235766", "train_gnorm": "0.277", "train_loss_scale": "0.5", "train_train_wall": "534", "train_gb_free": "40.9", "train_wall": "428285"}
[2024-10-09 17:08:13,558][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:08:13,591][fairseq.trainer][INFO] - begin training epoch 474
[2024-10-09 17:08:13,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:16:25,259][train_inner][INFO] - {"epoch": 474, "update": 473.259, "loss": "0.782", "ntokens": "262895", "nsentences": "1754.1", "wps": "92652.2", "ups": "0.35", "wpb": "262895", "bsz": "1754.1", "num_updates": "226600", "lr": "0.000235598", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "213", "gb_free": "40", "wall": "428777"}
[2024-10-09 17:20:10,165][train_inner][INFO] - {"epoch": 474, "update": 473.676, "loss": "0.782", "ntokens": "263977", "nsentences": "1756.49", "wps": "234797", "ups": "0.89", "wpb": "263977", "bsz": "1756.5", "num_updates": "226800", "lr": "0.000235326", "gnorm": "0.257", "loss_scale": "0.5", "train_wall": "179", "gb_free": "40.2", "wall": "429002"}
[2024-10-09 17:23:13,820][fairseq_cli.train][INFO] - end of epoch 474 (average epoch stats below)
[2024-10-09 17:23:13,831][train][INFO] - {"epoch": 474, "train_loss": "0.781", "train_ntokens": "263490", "train_nsentences": "1753.71", "train_wps": "140121", "train_ups": "0.53", "train_wpb": "263490", "train_bsz": "1753.7", "train_num_updates": "226955", "train_lr": "0.000235115", "train_gnorm": "0.268", "train_loss_scale": "0.5", "train_train_wall": "478", "train_gb_free": "39.2", "train_wall": "429186"}
[2024-10-09 17:23:13,928][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:23:13,952][fairseq.trainer][INFO] - begin training epoch 475
[2024-10-09 17:23:13,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:29:38,985][train_inner][INFO] - {"epoch": 475, "update": 474.094, "loss": "0.781", "ntokens": "262757", "nsentences": "1742.35", "wps": "92390.6", "ups": "0.35", "wpb": "262757", "bsz": "1742.4", "num_updates": "227000", "lr": "0.000235054", "gnorm": "0.275", "loss_scale": "0.5", "train_wall": "211", "gb_free": "39.7", "wall": "429571"}
[2024-10-09 17:33:30,679][train_inner][INFO] - {"epoch": 475, "update": 474.511, "loss": "0.778", "ntokens": "264136", "nsentences": "1740.6", "wps": "228037", "ups": "0.86", "wpb": "264136", "bsz": "1740.6", "num_updates": "227200", "lr": "0.000234783", "gnorm": "0.277", "loss_scale": "0.5", "train_wall": "226", "gb_free": "39.7", "wall": "429803"}
[2024-10-09 17:37:32,112][train_inner][INFO] - {"epoch": 475, "update": 474.929, "loss": "0.784", "ntokens": "263985", "nsentences": "1786.43", "wps": "218692", "ups": "0.83", "wpb": "263985", "bsz": "1786.4", "num_updates": "227400", "lr": "0.000234511", "gnorm": "0.254", "loss_scale": "0.5", "train_wall": "236", "gb_free": "39.7", "wall": "430044"}
[2024-10-09 17:38:25,431][fairseq_cli.train][INFO] - end of epoch 475 (average epoch stats below)
[2024-10-09 17:38:25,458][train][INFO] - {"epoch": 475, "train_loss": "0.781", "train_ntokens": "263611", "train_nsentences": "1753.71", "train_wps": "138518", "train_ups": "0.53", "train_wpb": "263611", "train_bsz": "1753.7", "train_num_updates": "227434", "train_lr": "0.000234465", "train_gnorm": "0.265", "train_loss_scale": "0.5", "train_train_wall": "566", "train_gb_free": "39.7", "train_wall": "430098"}
[2024-10-09 17:38:25,561][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:38:25,581][fairseq.trainer][INFO] - begin training epoch 476
[2024-10-09 17:38:25,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:46:58,758][train_inner][INFO] - {"epoch": 476, "update": 475.347, "loss": "0.78", "ntokens": "262871", "nsentences": "1749.89", "wps": "92783.2", "ups": "0.35", "wpb": "262871", "bsz": "1749.9", "num_updates": "227600", "lr": "0.000234239", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "250", "gb_free": "39.3", "wall": "430611"}
[2024-10-09 17:51:02,202][train_inner][INFO] - {"epoch": 476, "update": 475.764, "loss": "0.78", "ntokens": "264619", "nsentences": "1713.47", "wps": "217438", "ups": "0.82", "wpb": "264619", "bsz": "1713.5", "num_updates": "227800", "lr": "0.000233967", "gnorm": "0.261", "loss_scale": "0.5", "train_wall": "238", "gb_free": "39.3", "wall": "430854"}
[2024-10-09 17:53:30,825][fairseq_cli.train][INFO] - end of epoch 476 (average epoch stats below)
[2024-10-09 17:53:30,854][train][INFO] - {"epoch": 476, "train_loss": "0.78", "train_ntokens": "263624", "train_nsentences": "1753.71", "train_wps": "139473", "train_ups": "0.53", "train_wpb": "263624", "train_bsz": "1753.7", "train_num_updates": "227913", "train_lr": "0.000233814", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "581", "train_gb_free": "39.8", "train_wall": "431003"}
[2024-10-09 17:53:31,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 17:53:31,044][fairseq.trainer][INFO] - begin training epoch 477
[2024-10-09 17:53:31,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:00:41,729][train_inner][INFO] - {"epoch": 477, "update": 476.182, "loss": "0.783", "ntokens": "262459", "nsentences": "1791.95", "wps": "90579.7", "ups": "0.35", "wpb": "262459", "bsz": "1792", "num_updates": "228000", "lr": "0.000233696", "gnorm": "0.274", "loss_scale": "1", "train_wall": "246", "gb_free": "39.3", "wall": "431434"}
[2024-10-09 18:04:15,646][train_inner][INFO] - {"epoch": 477, "update": 476.599, "loss": "0.78", "ntokens": "264004", "nsentences": "1763.89", "wps": "246844", "ups": "0.93", "wpb": "264004", "bsz": "1763.9", "num_updates": "228200", "lr": "0.000233424", "gnorm": "0.266", "loss_scale": "1", "train_wall": "209", "gb_free": "39.1", "wall": "431648"}
[2024-10-09 18:08:23,196][fairseq_cli.train][INFO] - end of epoch 477 (average epoch stats below)
[2024-10-09 18:08:23,262][train][INFO] - {"epoch": 477, "train_loss": "0.78", "train_ntokens": "263568", "train_nsentences": "1753.71", "train_wps": "141473", "train_ups": "0.54", "train_wpb": "263568", "train_bsz": "1753.7", "train_num_updates": "228392", "train_lr": "0.000233163", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "551", "train_gb_free": "39.6", "train_wall": "431895"}
[2024-10-09 18:08:23,416][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:08:23,443][fairseq.trainer][INFO] - begin training epoch 478
[2024-10-09 18:08:23,444][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:14:28,731][train_inner][INFO] - {"epoch": 478, "update": 477.017, "loss": "0.78", "ntokens": "263027", "nsentences": "1736.05", "wps": "85806.9", "ups": "0.33", "wpb": "263027", "bsz": "1736", "num_updates": "228400", "lr": "0.000233152", "gnorm": "0.254", "loss_scale": "1", "train_wall": "275", "gb_free": "39.6", "wall": "432261"}
[2024-10-09 18:18:05,614][train_inner][INFO] - {"epoch": 478, "update": 477.434, "loss": "0.778", "ntokens": "264217", "nsentences": "1730.73", "wps": "243681", "ups": "0.92", "wpb": "264217", "bsz": "1730.7", "num_updates": "228600", "lr": "0.00023288", "gnorm": "0.277", "loss_scale": "1", "train_wall": "211", "gb_free": "40", "wall": "432478"}
[2024-10-09 18:22:15,158][train_inner][INFO] - {"epoch": 478, "update": 477.852, "loss": "0.784", "ntokens": "263707", "nsentences": "1770.28", "wps": "211417", "ups": "0.8", "wpb": "263707", "bsz": "1770.3", "num_updates": "228800", "lr": "0.000232609", "gnorm": "0.257", "loss_scale": "1", "train_wall": "244", "gb_free": "39.8", "wall": "432727"}
[2024-10-09 18:23:32,168][fairseq_cli.train][INFO] - end of epoch 478 (average epoch stats below)
[2024-10-09 18:23:32,196][train][INFO] - {"epoch": 478, "train_loss": "0.781", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "138851", "train_ups": "0.53", "train_wpb": "263474", "train_bsz": "1753.7", "train_num_updates": "228871", "train_lr": "0.000232512", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "563", "train_gb_free": "40.5", "train_wall": "432804"}
[2024-10-09 18:23:32,400][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:23:32,455][fairseq.trainer][INFO] - begin training epoch 479
[2024-10-09 18:23:32,456][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:31:56,204][train_inner][INFO] - {"epoch": 479, "update": 478.269, "loss": "0.779", "ntokens": "262819", "nsentences": "1774.83", "wps": "90465.3", "ups": "0.34", "wpb": "262819", "bsz": "1774.8", "num_updates": "229000", "lr": "0.000232337", "gnorm": "0.271", "loss_scale": "1", "train_wall": "247", "gb_free": "40.1", "wall": "433308"}
[2024-10-09 18:36:29,063][train_inner][INFO] - {"epoch": 479, "update": 478.687, "loss": "0.783", "ntokens": "263937", "nsentences": "1773.9", "wps": "193470", "ups": "0.73", "wpb": "263937", "bsz": "1773.9", "num_updates": "229200", "lr": "0.000232065", "gnorm": "0.255", "loss_scale": "1", "train_wall": "267", "gb_free": "39.2", "wall": "433581"}
[2024-10-09 18:39:24,389][fairseq_cli.train][INFO] - end of epoch 479 (average epoch stats below)
[2024-10-09 18:39:24,407][train][INFO] - {"epoch": 479, "train_loss": "0.781", "train_ntokens": "263688", "train_nsentences": "1753.71", "train_wps": "132647", "train_ups": "0.5", "train_wpb": "263688", "train_bsz": "1753.7", "train_num_updates": "229350", "train_lr": "0.000231861", "train_gnorm": "0.263", "train_loss_scale": "1", "train_train_wall": "611", "train_gb_free": "39.6", "train_wall": "433757"}
[2024-10-09 18:39:24,592][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:39:24,596][fairseq.trainer][INFO] - begin training epoch 480
[2024-10-09 18:39:24,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 18:46:02,892][train_inner][INFO] - {"epoch": 480, "update": 479.104, "loss": "0.779", "ntokens": "263269", "nsentences": "1724.27", "wps": "91759.8", "ups": "0.35", "wpb": "263269", "bsz": "1724.3", "num_updates": "229400", "lr": "0.000231793", "gnorm": "0.267", "loss_scale": "1", "train_wall": "269", "gb_free": "40", "wall": "434155"}
[2024-10-09 18:49:45,567][train_inner][INFO] - {"epoch": 480, "update": 479.522, "loss": "0.778", "ntokens": "264221", "nsentences": "1724.78", "wps": "237326", "ups": "0.9", "wpb": "264221", "bsz": "1724.8", "num_updates": "229600", "lr": "0.000231522", "gnorm": "0.288", "loss_scale": "1", "train_wall": "218", "gb_free": "39.8", "wall": "434378"}
[2024-10-09 18:53:54,595][train_inner][INFO] - {"epoch": 480, "update": 479.939, "loss": "0.783", "ntokens": "263739", "nsentences": "1791.94", "wps": "211845", "ups": "0.8", "wpb": "263739", "bsz": "1791.9", "num_updates": "229800", "lr": "0.00023125", "gnorm": "0.273", "loss_scale": "1", "train_wall": "243", "gb_free": "39.7", "wall": "434627"}
[2024-10-09 18:54:36,528][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 480 @ 229829 updates
[2024-10-09 18:54:36,529][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 18:54:43,910][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 18:54:44,252][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 480 @ 229829 updates, score None) (writing took 7.724854685366154 seconds)
[2024-10-09 18:54:44,253][fairseq_cli.train][INFO] - end of epoch 480 (average epoch stats below)
[2024-10-09 18:54:44,269][train][INFO] - {"epoch": 480, "train_loss": "0.78", "train_ntokens": "263539", "train_nsentences": "1753.71", "train_wps": "137249", "train_ups": "0.52", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "229829", "train_lr": "0.000231211", "train_gnorm": "0.278", "train_loss_scale": "1", "train_train_wall": "600", "train_gb_free": "39.7", "train_wall": "434676"}
[2024-10-09 18:54:44,341][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 18:54:44,388][fairseq.trainer][INFO] - begin training epoch 481
[2024-10-09 18:54:44,389][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:03:27,173][train_inner][INFO] - {"epoch": 481, "update": 480.357, "loss": "0.779", "ntokens": "262871", "nsentences": "1757.78", "wps": "91821.5", "ups": "0.35", "wpb": "262872", "bsz": "1757.8", "num_updates": "230000", "lr": "0.000230978", "gnorm": "0.276", "loss_scale": "2", "train_wall": "218", "gb_free": "39.8", "wall": "435199"}
[2024-10-09 19:07:27,594][train_inner][INFO] - {"epoch": 481, "update": 480.775, "loss": "0.78", "ntokens": "264147", "nsentences": "1746.56", "wps": "219746", "ups": "0.83", "wpb": "264147", "bsz": "1746.6", "num_updates": "230200", "lr": "0.000230707", "gnorm": "0.252", "loss_scale": "2", "train_wall": "235", "gb_free": "40.5", "wall": "435440"}
[2024-10-09 19:09:40,733][fairseq_cli.train][INFO] - end of epoch 481 (average epoch stats below)
[2024-10-09 19:09:40,755][train][INFO] - {"epoch": 481, "train_loss": "0.78", "train_ntokens": "263613", "train_nsentences": "1753.71", "train_wps": "140853", "train_ups": "0.53", "train_wpb": "263613", "train_bsz": "1753.7", "train_num_updates": "230308", "train_lr": "0.00023056", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.3", "train_wall": "435573"}
[2024-10-09 19:09:40,870][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:09:40,889][fairseq.trainer][INFO] - begin training epoch 482
[2024-10-09 19:09:40,889][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:17:07,617][train_inner][INFO] - {"epoch": 482, "update": 481.192, "loss": "0.779", "ntokens": "263169", "nsentences": "1726.86", "wps": "90746.6", "ups": "0.34", "wpb": "263169", "bsz": "1726.9", "num_updates": "230400", "lr": "0.000230435", "gnorm": "0.26", "loss_scale": "2", "train_wall": "252", "gb_free": "39.3", "wall": "436020"}
[2024-10-09 19:20:58,360][train_inner][INFO] - {"epoch": 482, "update": 481.61, "loss": "0.779", "ntokens": "264148", "nsentences": "1759.24", "wps": "228975", "ups": "0.87", "wpb": "264148", "bsz": "1759.2", "num_updates": "230600", "lr": "0.000230163", "gnorm": "0.261", "loss_scale": "2", "train_wall": "226", "gb_free": "40.2", "wall": "436251"}
[2024-10-09 19:25:09,470][fairseq_cli.train][INFO] - end of epoch 482 (average epoch stats below)
[2024-10-09 19:25:09,485][train][INFO] - {"epoch": 482, "train_loss": "0.779", "train_ntokens": "263566", "train_nsentences": "1753.71", "train_wps": "135938", "train_ups": "0.52", "train_wpb": "263566", "train_bsz": "1753.7", "train_num_updates": "230787", "train_lr": "0.000229909", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "595", "train_gb_free": "39.2", "train_wall": "436502"}
[2024-10-09 19:25:09,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:25:09,601][fairseq.trainer][INFO] - begin training epoch 483
[2024-10-09 19:25:09,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:30:52,352][train_inner][INFO] - {"epoch": 483, "update": 482.027, "loss": "0.782", "ntokens": "262682", "nsentences": "1764.35", "wps": "88452.2", "ups": "0.34", "wpb": "262682", "bsz": "1764.3", "num_updates": "230800", "lr": "0.000229891", "gnorm": "0.285", "loss_scale": "2", "train_wall": "289", "gb_free": "39.7", "wall": "436845"}
[2024-10-09 19:34:35,621][train_inner][INFO] - {"epoch": 483, "update": 482.445, "loss": "0.776", "ntokens": "264127", "nsentences": "1735.01", "wps": "236609", "ups": "0.9", "wpb": "264127", "bsz": "1735", "num_updates": "231000", "lr": "0.00022962", "gnorm": "0.266", "loss_scale": "2", "train_wall": "218", "gb_free": "39.3", "wall": "437068"}
[2024-10-09 19:38:50,715][train_inner][INFO] - {"epoch": 483, "update": 482.862, "loss": "0.781", "ntokens": "263896", "nsentences": "1762.72", "wps": "206907", "ups": "0.78", "wpb": "263896", "bsz": "1762.7", "num_updates": "231200", "lr": "0.000229348", "gnorm": "0.272", "loss_scale": "2", "train_wall": "249", "gb_free": "39.1", "wall": "437323"}
[2024-10-09 19:40:23,713][fairseq_cli.train][INFO] - end of epoch 483 (average epoch stats below)
[2024-10-09 19:40:23,734][train][INFO] - {"epoch": 483, "train_loss": "0.78", "train_ntokens": "263479", "train_nsentences": "1753.71", "train_wps": "138047", "train_ups": "0.52", "train_wpb": "263479", "train_bsz": "1753.7", "train_num_updates": "231266", "train_lr": "0.000229258", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "601", "train_gb_free": "40.5", "train_wall": "437416"}
[2024-10-09 19:40:23,918][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:40:23,943][fairseq.trainer][INFO] - begin training epoch 484
[2024-10-09 19:40:23,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:48:23,613][train_inner][INFO] - {"epoch": 484, "update": 483.28, "loss": "0.779", "ntokens": "262720", "nsentences": "1730.52", "wps": "91719.3", "ups": "0.35", "wpb": "262720", "bsz": "1730.5", "num_updates": "231400", "lr": "0.000229076", "gnorm": "0.267", "loss_scale": "2", "train_wall": "222", "gb_free": "39.6", "wall": "437896"}
[2024-10-09 19:52:11,008][train_inner][INFO] - {"epoch": 484, "update": 483.697, "loss": "0.781", "ntokens": "263838", "nsentences": "1788.23", "wps": "232075", "ups": "0.88", "wpb": "263838", "bsz": "1788.2", "num_updates": "231600", "lr": "0.000228804", "gnorm": "0.27", "loss_scale": "2", "train_wall": "162", "gb_free": "39.2", "wall": "438123"}
[2024-10-09 19:55:36,412][fairseq_cli.train][INFO] - end of epoch 484 (average epoch stats below)
[2024-10-09 19:55:36,430][train][INFO] - {"epoch": 484, "train_loss": "0.779", "train_ntokens": "263515", "train_nsentences": "1753.71", "train_wps": "138300", "train_ups": "0.52", "train_wpb": "263515", "train_bsz": "1753.7", "train_num_updates": "231745", "train_lr": "0.000228607", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "382", "train_gb_free": "40", "train_wall": "438329"}
[2024-10-09 19:55:36,674][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:55:36,688][fairseq.trainer][INFO] - begin training epoch 485
[2024-10-09 19:55:36,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 20:02:12,576][train_inner][INFO] - {"epoch": 485, "update": 484.115, "loss": "0.78", "ntokens": "263074", "nsentences": "1742.7", "wps": "87466.7", "ups": "0.33", "wpb": "263074", "bsz": "1742.7", "num_updates": "231800", "lr": "0.000228533", "gnorm": "0.275", "loss_scale": "2", "train_wall": "175", "gb_free": "39.7", "wall": "438725"}
[2024-10-09 20:05:42,240][train_inner][INFO] - {"epoch": 485, "update": 484.532, "loss": "0.779", "ntokens": "263559", "nsentences": "1800.96", "wps": "251444", "ups": "0.95", "wpb": "263559", "bsz": "1801", "num_updates": "232000", "lr": "0.000228261", "gnorm": "0.268", "loss_scale": "2", "train_wall": "198", "gb_free": "39.3", "wall": "438934"}
[2024-10-09 20:07:04,853][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 20:09:30,072][train_inner][INFO] - {"epoch": 485, "update": 484.952, "loss": "0.78", "ntokens": "264206", "nsentences": "1730.92", "wps": "231958", "ups": "0.88", "wpb": "264206", "bsz": "1730.9", "num_updates": "232200", "lr": "0.000227989", "gnorm": "0.272", "loss_scale": "2", "train_wall": "151", "gb_free": "39.2", "wall": "439162"}
[2024-10-09 20:10:11,790][fairseq_cli.train][INFO] - end of epoch 485 (average epoch stats below)
[2024-10-09 20:10:11,800][train][INFO] - {"epoch": 485, "train_loss": "0.779", "train_ntokens": "263497", "train_nsentences": "1753.55", "train_wps": "143896", "train_ups": "0.55", "train_wpb": "263497", "train_bsz": "1753.5", "train_num_updates": "232223", "train_lr": "0.000227958", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "462", "train_gb_free": "39.7", "train_wall": "439204"}
[2024-10-09 20:10:11,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 20:10:11,983][fairseq.trainer][INFO] - begin training epoch 486
[2024-10-09 20:10:11,984][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 20:19:01,970][train_inner][INFO] - {"epoch": 486, "update": 485.37, "loss": "0.778", "ntokens": "263146", "nsentences": "1722.57", "wps": "92028.2", "ups": "0.35", "wpb": "263146", "bsz": "1722.6", "num_updates": "232400", "lr": "0.000227717", "gnorm": "0.274", "loss_scale": "2", "train_wall": "194", "gb_free": "40.5", "wall": "439734"}
[2024-10-09 20:23:16,506][train_inner][INFO] - {"epoch": 486, "update": 485.787, "loss": "0.781", "ntokens": "263416", "nsentences": "1798.33", "wps": "206993", "ups": "0.79", "wpb": "263416", "bsz": "1798.3", "num_updates": "232600", "lr": "0.000227446", "gnorm": "0.257", "loss_scale": "2", "train_wall": "150", "gb_free": "40", "wall": "439989"}
[2024-10-09 20:25:22,627][fairseq_cli.train][INFO] - end of epoch 486 (average epoch stats below)
[2024-10-09 20:25:22,656][train][INFO] - {"epoch": 486, "train_loss": "0.779", "train_ntokens": "263446", "train_nsentences": "1753.71", "train_wps": "138542", "train_ups": "0.53", "train_wpb": "263446", "train_bsz": "1753.7", "train_num_updates": "232702", "train_lr": "0.000227307", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "387", "train_gb_free": "40", "train_wall": "440115"}
[2024-10-09 20:25:22,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 20:25:22,816][fairseq.trainer][INFO] - begin training epoch 487
[2024-10-09 20:25:22,817][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 20:32:35,840][train_inner][INFO] - {"epoch": 487, "update": 486.205, "loss": "0.778", "ntokens": "263349", "nsentences": "1692.77", "wps": "94172.1", "ups": "0.36", "wpb": "263350", "bsz": "1692.8", "num_updates": "232800", "lr": "0.000227174", "gnorm": "0.285", "loss_scale": "2", "train_wall": "169", "gb_free": "39.3", "wall": "440548"}
[2024-10-09 20:36:07,670][train_inner][INFO] - {"epoch": 487, "update": 486.622, "loss": "0.779", "ntokens": "264110", "nsentences": "1768.51", "wps": "249372", "ups": "0.94", "wpb": "264110", "bsz": "1768.5", "num_updates": "233000", "lr": "0.000226902", "gnorm": "0.266", "loss_scale": "2", "train_wall": "180", "gb_free": "39.6", "wall": "440760"}
[2024-10-09 20:39:53,945][fairseq_cli.train][INFO] - end of epoch 487 (average epoch stats below)
[2024-10-09 20:39:54,027][train][INFO] - {"epoch": 487, "train_loss": "0.779", "train_ntokens": "263581", "train_nsentences": "1753.71", "train_wps": "144903", "train_ups": "0.55", "train_wpb": "263581", "train_bsz": "1753.7", "train_num_updates": "233181", "train_lr": "0.000226656", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "454", "train_gb_free": "39.3", "train_wall": "440986"}
[2024-10-09 20:39:56,185][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 20:39:56,259][fairseq.trainer][INFO] - begin training epoch 488
[2024-10-09 20:39:56,259][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 20:46:02,791][train_inner][INFO] - {"epoch": 488, "update": 487.04, "loss": "0.78", "ntokens": "262665", "nsentences": "1757.38", "wps": "88275.5", "ups": "0.34", "wpb": "262665", "bsz": "1757.4", "num_updates": "233200", "lr": "0.00022663", "gnorm": "0.266", "loss_scale": "2", "train_wall": "196", "gb_free": "39.6", "wall": "441355"}
[2024-10-09 20:49:34,421][train_inner][INFO] - {"epoch": 488, "update": 487.457, "loss": "0.777", "ntokens": "264113", "nsentences": "1760.54", "wps": "249618", "ups": "0.95", "wpb": "264113", "bsz": "1760.5", "num_updates": "233400", "lr": "0.000226359", "gnorm": "0.279", "loss_scale": "2", "train_wall": "157", "gb_free": "39.3", "wall": "441567"}
[2024-10-09 20:53:42,359][train_inner][INFO] - {"epoch": 488, "update": 487.875, "loss": "0.78", "ntokens": "263990", "nsentences": "1778.96", "wps": "212964", "ups": "0.81", "wpb": "263990", "bsz": "1779", "num_updates": "233600", "lr": "0.000226087", "gnorm": "0.267", "loss_scale": "2", "train_wall": "157", "gb_free": "39.6", "wall": "441815"}
[2024-10-09 20:54:40,171][fairseq_cli.train][INFO] - end of epoch 488 (average epoch stats below)
[2024-10-09 20:54:40,187][train][INFO] - {"epoch": 488, "train_loss": "0.778", "train_ntokens": "263609", "train_nsentences": "1753.71", "train_wps": "142578", "train_ups": "0.54", "train_wpb": "263609", "train_bsz": "1753.7", "train_num_updates": "233660", "train_lr": "0.000226005", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "388", "train_gb_free": "40", "train_wall": "441872"}
[2024-10-09 20:54:40,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 20:54:40,329][fairseq.trainer][INFO] - begin training epoch 489
[2024-10-09 20:54:40,329][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:03:00,756][train_inner][INFO] - {"epoch": 489, "update": 488.292, "loss": "0.777", "ntokens": "263131", "nsentences": "1716.47", "wps": "94248", "ups": "0.36", "wpb": "263131", "bsz": "1716.5", "num_updates": "233800", "lr": "0.000225815", "gnorm": "0.292", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "442373"}
[2024-10-09 21:06:41,873][train_inner][INFO] - {"epoch": 489, "update": 488.71, "loss": "0.779", "ntokens": "264038", "nsentences": "1750.03", "wps": "238846", "ups": "0.9", "wpb": "264038", "bsz": "1750", "num_updates": "234000", "lr": "0.000225543", "gnorm": "0.267", "loss_scale": "2", "train_wall": "215", "gb_free": "40", "wall": "442594"}
[2024-10-09 21:09:29,925][fairseq_cli.train][INFO] - end of epoch 489 (average epoch stats below)
[2024-10-09 21:09:29,954][train][INFO] - {"epoch": 489, "train_loss": "0.779", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "141894", "train_ups": "0.54", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "234139", "train_lr": "0.000225355", "train_gnorm": "0.272", "train_loss_scale": "4", "train_train_wall": "541", "train_gb_free": "39.6", "train_wall": "442762"}
[2024-10-09 21:09:30,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:09:30,191][fairseq.trainer][INFO] - begin training epoch 490
[2024-10-09 21:09:30,191][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:15:53,122][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 21:16:17,474][train_inner][INFO] - {"epoch": 490, "update": 489.129, "loss": "0.778", "ntokens": "262791", "nsentences": "1758.12", "wps": "91314.7", "ups": "0.35", "wpb": "262791", "bsz": "1758.1", "num_updates": "234200", "lr": "0.000225272", "gnorm": "0.277", "loss_scale": "2", "train_wall": "257", "gb_free": "40.1", "wall": "443170"}
[2024-10-09 21:20:05,402][train_inner][INFO] - {"epoch": 490, "update": 489.547, "loss": "0.777", "ntokens": "263823", "nsentences": "1764.58", "wps": "231513", "ups": "0.88", "wpb": "263823", "bsz": "1764.6", "num_updates": "234400", "lr": "0.000225", "gnorm": "0.278", "loss_scale": "2", "train_wall": "222", "gb_free": "39.2", "wall": "443398"}
[2024-10-09 21:24:00,784][train_inner][INFO] - {"epoch": 490, "update": 489.965, "loss": "0.781", "ntokens": "263974", "nsentences": "1762.32", "wps": "224309", "ups": "0.85", "wpb": "263974", "bsz": "1762.3", "num_updates": "234600", "lr": "0.000224728", "gnorm": "0.269", "loss_scale": "2", "train_wall": "231", "gb_free": "39.3", "wall": "443633"}
[2024-10-09 21:24:41,821][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 490 @ 234617 updates
[2024-10-09 21:24:41,822][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 21:24:49,502][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 21:24:49,543][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 490 @ 234617 updates, score None) (writing took 7.722466153092682 seconds)
[2024-10-09 21:24:49,550][fairseq_cli.train][INFO] - end of epoch 490 (average epoch stats below)
[2024-10-09 21:24:49,552][train][INFO] - {"epoch": 490, "train_loss": "0.779", "train_ntokens": "263463", "train_nsentences": "1754.51", "train_wps": "136958", "train_ups": "0.52", "train_wpb": "263463", "train_bsz": "1754.5", "train_num_updates": "234617", "train_lr": "0.000224705", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "589", "train_gb_free": "39.2", "train_wall": "443682"}
[2024-10-09 21:24:49,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:24:49,644][fairseq.trainer][INFO] - begin training epoch 491
[2024-10-09 21:24:49,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:33:31,509][train_inner][INFO] - {"epoch": 491, "update": 490.382, "loss": "0.778", "ntokens": "263005", "nsentences": "1744.34", "wps": "92168.2", "ups": "0.35", "wpb": "263005", "bsz": "1744.3", "num_updates": "234800", "lr": "0.000224457", "gnorm": "0.277", "loss_scale": "2", "train_wall": "248", "gb_free": "40.1", "wall": "444204"}
[2024-10-09 21:37:43,117][train_inner][INFO] - {"epoch": 491, "update": 490.8, "loss": "0.779", "ntokens": "263846", "nsentences": "1753.38", "wps": "209738", "ups": "0.79", "wpb": "263846", "bsz": "1753.4", "num_updates": "235000", "lr": "0.000224185", "gnorm": "0.255", "loss_scale": "2", "train_wall": "246", "gb_free": "39.6", "wall": "444455"}
[2024-10-09 21:40:00,914][fairseq_cli.train][INFO] - end of epoch 491 (average epoch stats below)
[2024-10-09 21:40:00,950][train][INFO] - {"epoch": 491, "train_loss": "0.779", "train_ntokens": "263470", "train_nsentences": "1753.71", "train_wps": "138474", "train_ups": "0.53", "train_wpb": "263470", "train_bsz": "1753.7", "train_num_updates": "235096", "train_lr": "0.000224054", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "588", "train_gb_free": "39.7", "train_wall": "444593"}
[2024-10-09 21:40:01,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:40:01,220][fairseq.trainer][INFO] - begin training epoch 492
[2024-10-09 21:40:01,221][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:47:33,991][train_inner][INFO] - {"epoch": 492, "update": 491.217, "loss": "0.78", "ntokens": "262906", "nsentences": "1759.57", "wps": "88990.2", "ups": "0.34", "wpb": "262906", "bsz": "1759.6", "num_updates": "235200", "lr": "0.000223913", "gnorm": "0.271", "loss_scale": "2", "train_wall": "271", "gb_free": "39.7", "wall": "445046"}
[2024-10-09 21:51:38,324][train_inner][INFO] - {"epoch": 492, "update": 491.635, "loss": "0.78", "ntokens": "263567", "nsentences": "1802.74", "wps": "215752", "ups": "0.82", "wpb": "263567", "bsz": "1802.7", "num_updates": "235400", "lr": "0.000223641", "gnorm": "0.264", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "445290"}
[2024-10-09 21:55:43,282][fairseq_cli.train][INFO] - end of epoch 492 (average epoch stats below)
[2024-10-09 21:55:43,298][train][INFO] - {"epoch": 492, "train_loss": "0.778", "train_ntokens": "263580", "train_nsentences": "1753.71", "train_wps": "133980", "train_ups": "0.51", "train_wpb": "263580", "train_bsz": "1753.7", "train_num_updates": "235575", "train_lr": "0.000223404", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "615", "train_gb_free": "39.2", "train_wall": "445535"}
[2024-10-09 21:55:43,379][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:55:43,407][fairseq.trainer][INFO] - begin training epoch 493
[2024-10-09 21:55:43,407][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:01:48,235][train_inner][INFO] - {"epoch": 493, "update": 492.052, "loss": "0.777", "ntokens": "263282", "nsentences": "1703.97", "wps": "86336.2", "ups": "0.33", "wpb": "263282", "bsz": "1704", "num_updates": "235600", "lr": "0.00022337", "gnorm": "0.285", "loss_scale": "2", "train_wall": "279", "gb_free": "39.6", "wall": "445900"}
[2024-10-09 22:05:20,636][train_inner][INFO] - {"epoch": 493, "update": 492.47, "loss": "0.774", "ntokens": "264682", "nsentences": "1689.4", "wps": "249255", "ups": "0.94", "wpb": "264682", "bsz": "1689.4", "num_updates": "235800", "lr": "0.000223098", "gnorm": "0.253", "loss_scale": "2", "train_wall": "207", "gb_free": "39.5", "wall": "446113"}
[2024-10-09 22:09:33,531][train_inner][INFO] - {"epoch": 493, "update": 492.887, "loss": "0.781", "ntokens": "263334", "nsentences": "1824.06", "wps": "208263", "ups": "0.79", "wpb": "263334", "bsz": "1824.1", "num_updates": "236000", "lr": "0.000222826", "gnorm": "0.271", "loss_scale": "2", "train_wall": "247", "gb_free": "39.8", "wall": "446366"}
[2024-10-09 22:10:43,625][fairseq_cli.train][INFO] - end of epoch 493 (average epoch stats below)
[2024-10-09 22:10:43,645][train][INFO] - {"epoch": 493, "train_loss": "0.778", "train_ntokens": "263503", "train_nsentences": "1753.71", "train_wps": "140189", "train_ups": "0.53", "train_wpb": "263503", "train_bsz": "1753.7", "train_num_updates": "236054", "train_lr": "0.000222753", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "40", "train_wall": "446436"}
[2024-10-09 22:10:43,727][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:10:43,746][fairseq.trainer][INFO] - begin training epoch 494
[2024-10-09 22:10:43,747][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:19:07,120][train_inner][INFO] - {"epoch": 494, "update": 493.305, "loss": "0.778", "ntokens": "262752", "nsentences": "1742.38", "wps": "91618.3", "ups": "0.35", "wpb": "262752", "bsz": "1742.4", "num_updates": "236200", "lr": "0.000222554", "gnorm": "0.277", "loss_scale": "2", "train_wall": "232", "gb_free": "39.3", "wall": "446939"}
[2024-10-09 22:23:12,146][train_inner][INFO] - {"epoch": 494, "update": 493.722, "loss": "0.779", "ntokens": "263806", "nsentences": "1785.61", "wps": "215358", "ups": "0.82", "wpb": "263806", "bsz": "1785.6", "num_updates": "236400", "lr": "0.000222283", "gnorm": "0.291", "loss_scale": "4", "train_wall": "239", "gb_free": "39.6", "wall": "447184"}
[2024-10-09 22:26:29,144][fairseq_cli.train][INFO] - end of epoch 494 (average epoch stats below)
[2024-10-09 22:26:29,161][train][INFO] - {"epoch": 494, "train_loss": "0.778", "train_ntokens": "263555", "train_nsentences": "1753.71", "train_wps": "133519", "train_ups": "0.51", "train_wpb": "263555", "train_bsz": "1753.7", "train_num_updates": "236533", "train_lr": "0.000222102", "train_gnorm": "0.284", "train_loss_scale": "4", "train_train_wall": "592", "train_gb_free": "39.3", "train_wall": "447381"}
[2024-10-09 22:26:29,251][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:26:29,255][fairseq.trainer][INFO] - begin training epoch 495
[2024-10-09 22:26:29,256][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:33:07,312][train_inner][INFO] - {"epoch": 495, "update": 494.14, "loss": "0.779", "ntokens": "262906", "nsentences": "1745.64", "wps": "88350.5", "ups": "0.34", "wpb": "262906", "bsz": "1745.6", "num_updates": "236600", "lr": "0.000222011", "gnorm": "0.263", "loss_scale": "4", "train_wall": "283", "gb_free": "39.7", "wall": "447779"}
[2024-10-09 22:36:55,825][train_inner][INFO] - {"epoch": 495, "update": 494.557, "loss": "0.776", "ntokens": "264260", "nsentences": "1732.29", "wps": "231306", "ups": "0.88", "wpb": "264260", "bsz": "1732.3", "num_updates": "236800", "lr": "0.000221739", "gnorm": "0.259", "loss_scale": "4", "train_wall": "224", "gb_free": "39.1", "wall": "448008"}
[2024-10-09 22:40:43,115][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 22:41:01,007][train_inner][INFO] - {"epoch": 495, "update": 494.977, "loss": "0.779", "ntokens": "263848", "nsentences": "1771.8", "wps": "215235", "ups": "0.82", "wpb": "263848", "bsz": "1771.8", "num_updates": "237000", "lr": "0.000221467", "gnorm": "0.267", "loss_scale": "2", "train_wall": "241", "gb_free": "39.1", "wall": "448253"}
[2024-10-09 22:41:50,401][fairseq_cli.train][INFO] - end of epoch 495 (average epoch stats below)
[2024-10-09 22:41:50,404][train][INFO] - {"epoch": 495, "train_loss": "0.778", "train_ntokens": "263500", "train_nsentences": "1752.75", "train_wps": "136722", "train_ups": "0.52", "train_wpb": "263500", "train_bsz": "1752.8", "train_num_updates": "237011", "train_lr": "0.000221452", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "605", "train_gb_free": "39.6", "train_wall": "448303"}
[2024-10-09 22:41:50,451][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:41:50,460][fairseq.trainer][INFO] - begin training epoch 496
[2024-10-09 22:41:50,460][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:51:12,910][train_inner][INFO] - {"epoch": 496, "update": 495.395, "loss": "0.775", "ntokens": "262846", "nsentences": "1749.94", "wps": "85933.7", "ups": "0.33", "wpb": "262846", "bsz": "1749.9", "num_updates": "237200", "lr": "0.000221196", "gnorm": "0.266", "loss_scale": "2", "train_wall": "288", "gb_free": "40", "wall": "448865"}
[2024-10-09 22:55:04,820][train_inner][INFO] - {"epoch": 496, "update": 495.812, "loss": "0.778", "ntokens": "263986", "nsentences": "1755.49", "wps": "227681", "ups": "0.86", "wpb": "263986", "bsz": "1755.5", "num_updates": "237400", "lr": "0.000220924", "gnorm": "0.274", "loss_scale": "2", "train_wall": "225", "gb_free": "39.2", "wall": "449097"}
[2024-10-09 22:56:51,925][fairseq_cli.train][INFO] - end of epoch 496 (average epoch stats below)
[2024-10-09 22:56:51,963][train][INFO] - {"epoch": 496, "train_loss": "0.777", "train_ntokens": "263536", "train_nsentences": "1753.71", "train_wps": "140018", "train_ups": "0.53", "train_wpb": "263536", "train_bsz": "1753.7", "train_num_updates": "237490", "train_lr": "0.000220802", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "567", "train_gb_free": "39.6", "train_wall": "449204"}
[2024-10-09 22:56:52,100][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:56:52,117][fairseq.trainer][INFO] - begin training epoch 497
[2024-10-09 22:56:52,118][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:04:36,294][train_inner][INFO] - {"epoch": 497, "update": 496.23, "loss": "0.775", "ntokens": "263476", "nsentences": "1704.41", "wps": "92217.8", "ups": "0.35", "wpb": "263476", "bsz": "1704.4", "num_updates": "237600", "lr": "0.000220652", "gnorm": "0.277", "loss_scale": "2", "train_wall": "243", "gb_free": "39.6", "wall": "449668"}
[2024-10-09 23:08:21,015][train_inner][INFO] - {"epoch": 497, "update": 496.647, "loss": "0.78", "ntokens": "263828", "nsentences": "1770.41", "wps": "234823", "ups": "0.89", "wpb": "263828", "bsz": "1770.4", "num_updates": "237800", "lr": "0.00022038", "gnorm": "0.264", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "449893"}
[2024-10-09 23:12:18,850][fairseq_cli.train][INFO] - end of epoch 497 (average epoch stats below)
[2024-10-09 23:12:18,874][train][INFO] - {"epoch": 497, "train_loss": "0.778", "train_ntokens": "263577", "train_nsentences": "1753.71", "train_wps": "136211", "train_ups": "0.52", "train_wpb": "263577", "train_bsz": "1753.7", "train_num_updates": "237969", "train_lr": "0.000220151", "train_gnorm": "0.281", "train_loss_scale": "2", "train_train_wall": "593", "train_gb_free": "39.7", "train_wall": "450131"}
[2024-10-09 23:12:19,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:12:19,063][fairseq.trainer][INFO] - begin training epoch 498
[2024-10-09 23:12:19,064][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:18:25,583][train_inner][INFO] - {"epoch": 498, "update": 497.065, "loss": "0.778", "ntokens": "262664", "nsentences": "1771.06", "wps": "86895.7", "ups": "0.33", "wpb": "262664", "bsz": "1771.1", "num_updates": "238000", "lr": "0.000220109", "gnorm": "0.303", "loss_scale": "2", "train_wall": "279", "gb_free": "39.3", "wall": "450498"}
[2024-10-09 23:21:59,662][train_inner][INFO] - {"epoch": 498, "update": 497.482, "loss": "0.777", "ntokens": "264059", "nsentences": "1755.56", "wps": "246712", "ups": "0.93", "wpb": "264059", "bsz": "1755.6", "num_updates": "238200", "lr": "0.000219837", "gnorm": "0.268", "loss_scale": "2", "train_wall": "208", "gb_free": "39.6", "wall": "450712"}
[2024-10-09 23:25:58,231][train_inner][INFO] - {"epoch": 498, "update": 497.9, "loss": "0.776", "ntokens": "263975", "nsentences": "1765.71", "wps": "221322", "ups": "0.84", "wpb": "263975", "bsz": "1765.7", "num_updates": "238400", "lr": "0.000219565", "gnorm": "0.26", "loss_scale": "2", "train_wall": "232", "gb_free": "39.7", "wall": "450950"}
[2024-10-09 23:26:59,947][fairseq_cli.train][INFO] - end of epoch 498 (average epoch stats below)
[2024-10-09 23:26:59,958][train][INFO] - {"epoch": 498, "train_loss": "0.777", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "143293", "train_ups": "0.54", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "238448", "train_lr": "0.0002195", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "40", "train_wall": "451012"}
[2024-10-09 23:27:00,130][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:27:00,147][fairseq.trainer][INFO] - begin training epoch 499
[2024-10-09 23:27:00,147][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:35:22,536][train_inner][INFO] - {"epoch": 499, "update": 498.317, "loss": "0.778", "ntokens": "262826", "nsentences": "1757.85", "wps": "93153.2", "ups": "0.35", "wpb": "262826", "bsz": "1757.8", "num_updates": "238600", "lr": "0.000219293", "gnorm": "0.273", "loss_scale": "2", "train_wall": "237", "gb_free": "39.7", "wall": "451515"}
[2024-10-09 23:39:17,433][train_inner][INFO] - {"epoch": 499, "update": 498.735, "loss": "0.778", "ntokens": "264351", "nsentences": "1724.35", "wps": "225088", "ups": "0.85", "wpb": "264351", "bsz": "1724.3", "num_updates": "238800", "lr": "0.000219022", "gnorm": "0.283", "loss_scale": "2", "train_wall": "220", "gb_free": "40.1", "wall": "451750"}
[2024-10-09 23:42:00,702][fairseq_cli.train][INFO] - end of epoch 499 (average epoch stats below)
[2024-10-09 23:42:00,724][train][INFO] - {"epoch": 499, "train_loss": "0.777", "train_ntokens": "263542", "train_nsentences": "1753.71", "train_wps": "140147", "train_ups": "0.53", "train_wpb": "263542", "train_bsz": "1753.7", "train_num_updates": "238927", "train_lr": "0.000218849", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "40.5", "train_wall": "451913"}
[2024-10-09 23:42:01,034][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:42:01,063][fairseq.trainer][INFO] - begin training epoch 500
[2024-10-09 23:42:01,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:49:01,067][train_inner][INFO] - {"epoch": 500, "update": 499.152, "loss": "0.776", "ntokens": "262608", "nsentences": "1782.56", "wps": "89996.9", "ups": "0.34", "wpb": "262608", "bsz": "1782.6", "num_updates": "239000", "lr": "0.00021875", "gnorm": "0.27", "loss_scale": "2", "train_wall": "259", "gb_free": "39.6", "wall": "452333"}
[2024-10-09 23:52:47,908][train_inner][INFO] - {"epoch": 500, "update": 499.57, "loss": "0.775", "ntokens": "263848", "nsentences": "1785.05", "wps": "232648", "ups": "0.88", "wpb": "263848", "bsz": "1785", "num_updates": "239200", "lr": "0.000218478", "gnorm": "0.26", "loss_scale": "4", "train_wall": "221", "gb_free": "39.8", "wall": "452560"}
[2024-10-09 23:57:14,114][train_inner][INFO] - {"epoch": 500, "update": 499.987, "loss": "0.777", "ntokens": "264504", "nsentences": "1711.7", "wps": "198736", "ups": "0.75", "wpb": "264504", "bsz": "1711.7", "num_updates": "239400", "lr": "0.000218207", "gnorm": "0.265", "loss_scale": "4", "train_wall": "261", "gb_free": "39.3", "wall": "452826"}
[2024-10-09 23:57:17,033][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 500 @ 239406 updates
[2024-10-09 23:57:17,034][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 23:57:25,466][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-09 23:57:25,649][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 500 @ 239406 updates, score None) (writing took 8.615415609441698 seconds)
[2024-10-09 23:57:25,658][fairseq_cli.train][INFO] - end of epoch 500 (average epoch stats below)
[2024-10-09 23:57:25,660][train][INFO] - {"epoch": 500, "train_loss": "0.776", "train_ntokens": "263634", "train_nsentences": "1753.71", "train_wps": "136530", "train_ups": "0.52", "train_wpb": "263634", "train_bsz": "1753.7", "train_num_updates": "239406", "train_lr": "0.000218198", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "585", "train_gb_free": "39.6", "train_wall": "452838"}
[2024-10-09 23:57:25,754][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:57:25,791][fairseq.trainer][INFO] - begin training epoch 501
[2024-10-09 23:57:25,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:06:38,917][train_inner][INFO] - {"epoch": 501, "update": 500.405, "loss": "0.774", "ntokens": "262557", "nsentences": "1755.47", "wps": "92975.9", "ups": "0.35", "wpb": "262557", "bsz": "1755.5", "num_updates": "239600", "lr": "0.000217935", "gnorm": "0.28", "loss_scale": "4", "train_wall": "238", "gb_free": "39.7", "wall": "453391"}
[2024-10-10 00:07:50,614][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 00:10:36,627][train_inner][INFO] - {"epoch": 501, "update": 500.825, "loss": "0.779", "ntokens": "263925", "nsentences": "1768.64", "wps": "222069", "ups": "0.84", "wpb": "263925", "bsz": "1768.6", "num_updates": "239800", "lr": "0.000217663", "gnorm": "0.279", "loss_scale": "2", "train_wall": "232", "gb_free": "39.8", "wall": "453629"}
[2024-10-10 00:12:05,288][fairseq_cli.train][INFO] - end of epoch 501 (average epoch stats below)
[2024-10-10 00:12:05,322][train][INFO] - {"epoch": 501, "train_loss": "0.777", "train_ntokens": "263424", "train_nsentences": "1753.72", "train_wps": "143146", "train_ups": "0.54", "train_wpb": "263424", "train_bsz": "1753.7", "train_num_updates": "239884", "train_lr": "0.000217549", "train_gnorm": "0.277", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.1", "train_wall": "453717"}
[2024-10-10 00:12:05,741][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:12:05,775][fairseq.trainer][INFO] - begin training epoch 502
[2024-10-10 00:12:05,776][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:19:50,839][train_inner][INFO] - {"epoch": 502, "update": 501.242, "loss": "0.776", "ntokens": "263016", "nsentences": "1718.69", "wps": "94918.5", "ups": "0.36", "wpb": "263016", "bsz": "1718.7", "num_updates": "240000", "lr": "0.000217391", "gnorm": "0.277", "loss_scale": "2", "train_wall": "226", "gb_free": "39.3", "wall": "454183"}
[2024-10-10 00:23:31,076][train_inner][INFO] - {"epoch": 502, "update": 501.66, "loss": "0.774", "ntokens": "264014", "nsentences": "1762.74", "wps": "239764", "ups": "0.91", "wpb": "264014", "bsz": "1762.7", "num_updates": "240200", "lr": "0.00021712", "gnorm": "0.288", "loss_scale": "2", "train_wall": "215", "gb_free": "40.5", "wall": "454403"}
[2024-10-10 00:27:00,977][fairseq_cli.train][INFO] - end of epoch 502 (average epoch stats below)
[2024-10-10 00:27:01,004][train][INFO] - {"epoch": 502, "train_loss": "0.776", "train_ntokens": "263491", "train_nsentences": "1753.71", "train_wps": "140919", "train_ups": "0.53", "train_wpb": "263491", "train_bsz": "1753.7", "train_num_updates": "240363", "train_lr": "0.000216898", "train_gnorm": "0.282", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "39.8", "train_wall": "454613"}
[2024-10-10 00:27:01,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:27:01,196][fairseq.trainer][INFO] - begin training epoch 503
[2024-10-10 00:27:01,197][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:33:29,168][train_inner][INFO] - {"epoch": 503, "update": 502.077, "loss": "0.778", "ntokens": "262755", "nsentences": "1749.58", "wps": "87866.1", "ups": "0.33", "wpb": "262755", "bsz": "1749.6", "num_updates": "240400", "lr": "0.000216848", "gnorm": "0.27", "loss_scale": "2", "train_wall": "266", "gb_free": "39.3", "wall": "455001"}
[2024-10-10 00:37:21,868][train_inner][INFO] - {"epoch": 503, "update": 502.495, "loss": "0.774", "ntokens": "264163", "nsentences": "1729.66", "wps": "227058", "ups": "0.86", "wpb": "264163", "bsz": "1729.7", "num_updates": "240600", "lr": "0.000216576", "gnorm": "0.274", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "455234"}
[2024-10-10 00:41:12,714][train_inner][INFO] - {"epoch": 503, "update": 502.912, "loss": "0.779", "ntokens": "264066", "nsentences": "1750.03", "wps": "228796", "ups": "0.87", "wpb": "264066", "bsz": "1750", "num_updates": "240800", "lr": "0.000216304", "gnorm": "0.269", "loss_scale": "2", "train_wall": "225", "gb_free": "39.8", "wall": "455465"}
[2024-10-10 00:42:16,778][fairseq_cli.train][INFO] - end of epoch 503 (average epoch stats below)
[2024-10-10 00:42:16,798][train][INFO] - {"epoch": 503, "train_loss": "0.777", "train_ntokens": "263468", "train_nsentences": "1753.71", "train_wps": "137808", "train_ups": "0.52", "train_wpb": "263468", "train_bsz": "1753.7", "train_num_updates": "240842", "train_lr": "0.000216247", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "575", "train_gb_free": "39.8", "train_wall": "455529"}
[2024-10-10 00:42:16,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:42:16,892][fairseq.trainer][INFO] - begin training epoch 504
[2024-10-10 00:42:16,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:51:05,467][train_inner][INFO] - {"epoch": 504, "update": 503.33, "loss": "0.778", "ntokens": "262483", "nsentences": "1797.71", "wps": "88565.5", "ups": "0.34", "wpb": "262483", "bsz": "1797.7", "num_updates": "241000", "lr": "0.000216033", "gnorm": "0.279", "loss_scale": "2", "train_wall": "280", "gb_free": "40.1", "wall": "456058"}
[2024-10-10 00:55:25,130][train_inner][INFO] - {"epoch": 504, "update": 503.747, "loss": "0.774", "ntokens": "264235", "nsentences": "1717.32", "wps": "203552", "ups": "0.77", "wpb": "264235", "bsz": "1717.3", "num_updates": "241200", "lr": "0.000215761", "gnorm": "0.269", "loss_scale": "2", "train_wall": "254", "gb_free": "39.3", "wall": "456317"}
[2024-10-10 00:58:02,509][fairseq_cli.train][INFO] - end of epoch 504 (average epoch stats below)
[2024-10-10 00:58:02,536][train][INFO] - {"epoch": 504, "train_loss": "0.776", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "133465", "train_ups": "0.51", "train_wpb": "263511", "train_bsz": "1753.7", "train_num_updates": "241321", "train_lr": "0.000215596", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "627", "train_gb_free": "39.2", "train_wall": "456475"}
[2024-10-10 00:58:02,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:58:02,680][fairseq.trainer][INFO] - begin training epoch 505
[2024-10-10 00:58:02,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:05:04,013][train_inner][INFO] - {"epoch": 505, "update": 504.165, "loss": "0.777", "ntokens": "262711", "nsentences": "1766.87", "wps": "90768.1", "ups": "0.35", "wpb": "262711", "bsz": "1766.9", "num_updates": "241400", "lr": "0.000215489", "gnorm": "0.256", "loss_scale": "2", "train_wall": "232", "gb_free": "39.9", "wall": "456896"}
[2024-10-10 01:08:36,034][train_inner][INFO] - {"epoch": 505, "update": 504.582, "loss": "0.775", "ntokens": "264041", "nsentences": "1729.3", "wps": "249093", "ups": "0.94", "wpb": "264041", "bsz": "1729.3", "num_updates": "241600", "lr": "0.000215217", "gnorm": "0.282", "loss_scale": "2", "train_wall": "170", "gb_free": "39.7", "wall": "457108"}
[2024-10-10 01:12:56,218][train_inner][INFO] - {"epoch": 505, "update": 505.0, "loss": "0.778", "ntokens": "262427", "nsentences": "1794.17", "wps": "201762", "ups": "0.77", "wpb": "262427", "bsz": "1794.2", "num_updates": "241800", "lr": "0.000214946", "gnorm": "0.266", "loss_scale": "4", "train_wall": "163", "gb_free": "39.8", "wall": "457368"}
[2024-10-10 01:12:56,335][fairseq_cli.train][INFO] - end of epoch 505 (average epoch stats below)
[2024-10-10 01:12:56,342][train][INFO] - {"epoch": 505, "train_loss": "0.776", "train_ntokens": "263430", "train_nsentences": "1753.71", "train_wps": "141177", "train_ups": "0.54", "train_wpb": "263430", "train_bsz": "1753.7", "train_num_updates": "241800", "train_lr": "0.000214946", "train_gnorm": "0.269", "train_loss_scale": "4", "train_train_wall": "411", "train_gb_free": "39.8", "train_wall": "457369"}
[2024-10-10 01:12:56,488][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:12:56,527][fairseq.trainer][INFO] - begin training epoch 506
[2024-10-10 01:12:56,528][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:22:01,409][train_inner][INFO] - {"epoch": 506, "update": 505.418, "loss": "0.774", "ntokens": "264151", "nsentences": "1759.8", "wps": "96923.5", "ups": "0.37", "wpb": "264151", "bsz": "1759.8", "num_updates": "242000", "lr": "0.000214674", "gnorm": "0.258", "loss_scale": "4", "train_wall": "226", "gb_free": "40", "wall": "457914"}
[2024-10-10 01:25:04,641][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 01:25:47,122][train_inner][INFO] - {"epoch": 506, "update": 505.837, "loss": "0.777", "ntokens": "264022", "nsentences": "1746.29", "wps": "233963", "ups": "0.89", "wpb": "264022", "bsz": "1746.3", "num_updates": "242200", "lr": "0.000214402", "gnorm": "0.265", "loss_scale": "2", "train_wall": "187", "gb_free": "39.1", "wall": "458139"}
[2024-10-10 01:27:44,470][fairseq_cli.train][INFO] - end of epoch 506 (average epoch stats below)
[2024-10-10 01:27:44,506][train][INFO] - {"epoch": 506, "train_loss": "0.776", "train_ntokens": "263580", "train_nsentences": "1752.46", "train_wps": "141859", "train_ups": "0.54", "train_wpb": "263580", "train_bsz": "1752.5", "train_num_updates": "242278", "train_lr": "0.000214296", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "482", "train_gb_free": "39.7", "train_wall": "458257"}
[2024-10-10 01:27:46,015][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:27:46,067][fairseq.trainer][INFO] - begin training epoch 507
[2024-10-10 01:27:46,067][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:35:21,936][train_inner][INFO] - {"epoch": 507, "update": 506.255, "loss": "0.776", "ntokens": "262661", "nsentences": "1765.52", "wps": "91393.1", "ups": "0.35", "wpb": "262661", "bsz": "1765.5", "num_updates": "242400", "lr": "0.00021413", "gnorm": "0.273", "loss_scale": "2", "train_wall": "161", "gb_free": "39.3", "wall": "458714"}
[2024-10-10 01:39:01,978][train_inner][INFO] - {"epoch": 507, "update": 506.672, "loss": "0.774", "ntokens": "264177", "nsentences": "1751.03", "wps": "240132", "ups": "0.91", "wpb": "264177", "bsz": "1751", "num_updates": "242600", "lr": "0.000213859", "gnorm": "0.264", "loss_scale": "2", "train_wall": "153", "gb_free": "41", "wall": "458934"}
[2024-10-10 01:42:20,476][fairseq_cli.train][INFO] - end of epoch 507 (average epoch stats below)
[2024-10-10 01:42:20,584][train][INFO] - {"epoch": 507, "train_loss": "0.775", "train_ntokens": "263582", "train_nsentences": "1753.71", "train_wps": "144156", "train_ups": "0.55", "train_wpb": "263582", "train_bsz": "1753.7", "train_num_updates": "242757", "train_lr": "0.000213645", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "390", "train_gb_free": "39.6", "train_wall": "459133"}
[2024-10-10 01:42:22,748][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:42:22,943][fairseq.trainer][INFO] - begin training epoch 508
[2024-10-10 01:42:22,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:48:40,212][train_inner][INFO] - {"epoch": 508, "update": 507.09, "loss": "0.776", "ntokens": "262892", "nsentences": "1757.41", "wps": "90933.5", "ups": "0.35", "wpb": "262892", "bsz": "1757.4", "num_updates": "242800", "lr": "0.000213587", "gnorm": "0.272", "loss_scale": "2", "train_wall": "204", "gb_free": "39.3", "wall": "459512"}
[2024-10-10 01:52:04,169][train_inner][INFO] - {"epoch": 508, "update": 507.507, "loss": "0.774", "ntokens": "263663", "nsentences": "1769.68", "wps": "258563", "ups": "0.98", "wpb": "263663", "bsz": "1769.7", "num_updates": "243000", "lr": "0.000213315", "gnorm": "0.265", "loss_scale": "2", "train_wall": "196", "gb_free": "39.6", "wall": "459716"}
[2024-10-10 01:55:52,898][train_inner][INFO] - {"epoch": 508, "update": 507.925, "loss": "0.777", "ntokens": "264099", "nsentences": "1735.32", "wps": "230956", "ups": "0.87", "wpb": "264100", "bsz": "1735.3", "num_updates": "243200", "lr": "0.000213043", "gnorm": "0.273", "loss_scale": "2", "train_wall": "221", "gb_free": "40", "wall": "459945"}
[2024-10-10 01:56:50,642][fairseq_cli.train][INFO] - end of epoch 508 (average epoch stats below)
[2024-10-10 01:56:50,668][train][INFO] - {"epoch": 508, "train_loss": "0.775", "train_ntokens": "263400", "train_nsentences": "1753.71", "train_wps": "145036", "train_ups": "0.55", "train_wpb": "263400", "train_bsz": "1753.7", "train_num_updates": "243236", "train_lr": "0.000212995", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "532", "train_gb_free": "39.3", "train_wall": "460003"}
[2024-10-10 01:56:51,380][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:56:51,471][fairseq.trainer][INFO] - begin training epoch 509
[2024-10-10 01:56:51,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:05:08,654][train_inner][INFO] - {"epoch": 509, "update": 508.342, "loss": "0.774", "ntokens": "262721", "nsentences": "1757.59", "wps": "94548.4", "ups": "0.36", "wpb": "262721", "bsz": "1757.6", "num_updates": "243400", "lr": "0.000212772", "gnorm": "0.285", "loss_scale": "2", "train_wall": "237", "gb_free": "39.2", "wall": "460501"}
[2024-10-10 02:08:58,887][train_inner][INFO] - {"epoch": 509, "update": 508.76, "loss": "0.776", "ntokens": "263982", "nsentences": "1735.37", "wps": "229356", "ups": "0.87", "wpb": "263982", "bsz": "1735.4", "num_updates": "243600", "lr": "0.0002125", "gnorm": "0.262", "loss_scale": "2", "train_wall": "224", "gb_free": "39.6", "wall": "460731"}
[2024-10-10 02:11:27,009][fairseq_cli.train][INFO] - end of epoch 509 (average epoch stats below)
[2024-10-10 02:11:27,110][train][INFO] - {"epoch": 509, "train_loss": "0.776", "train_ntokens": "263475", "train_nsentences": "1753.71", "train_wps": "144004", "train_ups": "0.55", "train_wpb": "263475", "train_bsz": "1753.7", "train_num_updates": "243715", "train_lr": "0.000212344", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "547", "train_gb_free": "40", "train_wall": "460879"}
[2024-10-10 02:11:28,386][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:11:28,455][fairseq.trainer][INFO] - begin training epoch 510
[2024-10-10 02:11:28,456][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:18:34,365][train_inner][INFO] - {"epoch": 510, "update": 509.177, "loss": "0.776", "ntokens": "262610", "nsentences": "1773.83", "wps": "91270.1", "ups": "0.35", "wpb": "262610", "bsz": "1773.8", "num_updates": "243800", "lr": "0.000212228", "gnorm": "0.28", "loss_scale": "2", "train_wall": "259", "gb_free": "39.7", "wall": "461307"}
[2024-10-10 02:22:27,464][train_inner][INFO] - {"epoch": 510, "update": 509.595, "loss": "0.775", "ntokens": "264075", "nsentences": "1745.52", "wps": "226598", "ups": "0.86", "wpb": "264075", "bsz": "1745.5", "num_updates": "244000", "lr": "0.000211957", "gnorm": "0.267", "loss_scale": "2", "train_wall": "226", "gb_free": "39.3", "wall": "461540"}
[2024-10-10 02:26:07,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 510 @ 244194 updates
[2024-10-10 02:26:07,282][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 02:26:16,947][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 02:26:17,177][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 510 @ 244194 updates, score None) (writing took 9.901250526309013 seconds)
[2024-10-10 02:26:17,177][fairseq_cli.train][INFO] - end of epoch 510 (average epoch stats below)
[2024-10-10 02:26:17,220][train][INFO] - {"epoch": 510, "train_loss": "0.775", "train_ntokens": "263425", "train_nsentences": "1753.71", "train_wps": "141762", "train_ups": "0.54", "train_wpb": "263425", "train_bsz": "1753.7", "train_num_updates": "244194", "train_lr": "0.000211693", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.6", "train_wall": "461769"}
[2024-10-10 02:26:17,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:26:17,529][fairseq.trainer][INFO] - begin training epoch 511
[2024-10-10 02:26:17,531][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:32:03,336][train_inner][INFO] - {"epoch": 511, "update": 510.013, "loss": "0.775", "ntokens": "262865", "nsentences": "1745.79", "wps": "91294.9", "ups": "0.35", "wpb": "262865", "bsz": "1745.8", "num_updates": "244200", "lr": "0.000211685", "gnorm": "0.28", "loss_scale": "2", "train_wall": "225", "gb_free": "39.7", "wall": "462116"}
[2024-10-10 02:34:20,158][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 02:35:38,047][train_inner][INFO] - {"epoch": 511, "update": 510.432, "loss": "0.775", "ntokens": "264061", "nsentences": "1757.43", "wps": "245986", "ups": "0.93", "wpb": "264061", "bsz": "1757.4", "num_updates": "244400", "lr": "0.000211413", "gnorm": "0.272", "loss_scale": "2", "train_wall": "168", "gb_free": "39.6", "wall": "462330"}
[2024-10-10 02:40:00,256][train_inner][INFO] - {"epoch": 511, "update": 510.85, "loss": "0.775", "ntokens": "264511", "nsentences": "1739.84", "wps": "201769", "ups": "0.76", "wpb": "264511", "bsz": "1739.8", "num_updates": "244600", "lr": "0.000211141", "gnorm": "0.271", "loss_scale": "2", "train_wall": "146", "gb_free": "39.6", "wall": "462592"}
[2024-10-10 02:41:38,594][fairseq_cli.train][INFO] - end of epoch 511 (average epoch stats below)
[2024-10-10 02:41:38,604][train][INFO] - {"epoch": 511, "train_loss": "0.776", "train_ntokens": "263698", "train_nsentences": "1754.74", "train_wps": "136811", "train_ups": "0.52", "train_wpb": "263698", "train_bsz": "1754.7", "train_num_updates": "244672", "train_lr": "0.000211043", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "364", "train_gb_free": "39.1", "train_wall": "462691"}
[2024-10-10 02:41:38,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:41:38,681][fairseq.trainer][INFO] - begin training epoch 512
[2024-10-10 02:41:38,681][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:49:12,021][train_inner][INFO] - {"epoch": 512, "update": 511.267, "loss": "0.775", "ntokens": "262701", "nsentences": "1774.68", "wps": "95233.8", "ups": "0.36", "wpb": "262701", "bsz": "1774.7", "num_updates": "244800", "lr": "0.00021087", "gnorm": "0.26", "loss_scale": "2", "train_wall": "178", "gb_free": "40", "wall": "463144"}
[2024-10-10 02:52:51,952][train_inner][INFO] - {"epoch": 512, "update": 511.685, "loss": "0.774", "ntokens": "264081", "nsentences": "1745.21", "wps": "240189", "ups": "0.91", "wpb": "264082", "bsz": "1745.2", "num_updates": "245000", "lr": "0.000210598", "gnorm": "0.276", "loss_scale": "2", "train_wall": "213", "gb_free": "40.2", "wall": "463364"}
[2024-10-10 02:56:07,985][fairseq_cli.train][INFO] - end of epoch 512 (average epoch stats below)
[2024-10-10 02:56:08,050][train][INFO] - {"epoch": 512, "train_loss": "0.774", "train_ntokens": "263569", "train_nsentences": "1753.71", "train_wps": "145213", "train_ups": "0.55", "train_wpb": "263569", "train_bsz": "1753.7", "train_num_updates": "245151", "train_lr": "0.000210393", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "39.3", "train_wall": "463560"}
[2024-10-10 02:56:08,266][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:56:08,273][fairseq.trainer][INFO] - begin training epoch 513
[2024-10-10 02:56:08,273][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:02:35,664][train_inner][INFO] - {"epoch": 513, "update": 512.102, "loss": "0.774", "ntokens": "262939", "nsentences": "1750.45", "wps": "90096.5", "ups": "0.34", "wpb": "262939", "bsz": "1750.5", "num_updates": "245200", "lr": "0.000210326", "gnorm": "0.275", "loss_scale": "2", "train_wall": "234", "gb_free": "39.8", "wall": "463948"}
[2024-10-10 03:06:14,571][train_inner][INFO] - {"epoch": 513, "update": 512.52, "loss": "0.774", "ntokens": "263672", "nsentences": "1791.16", "wps": "240915", "ups": "0.91", "wpb": "263672", "bsz": "1791.2", "num_updates": "245400", "lr": "0.000210054", "gnorm": "0.279", "loss_scale": "2", "train_wall": "169", "gb_free": "39.6", "wall": "464167"}
[2024-10-10 03:09:57,588][train_inner][INFO] - {"epoch": 513, "update": 512.937, "loss": "0.776", "ntokens": "264249", "nsentences": "1723.9", "wps": "237010", "ups": "0.9", "wpb": "264249", "bsz": "1723.9", "num_updates": "245600", "lr": "0.000209783", "gnorm": "0.265", "loss_scale": "2", "train_wall": "136", "gb_free": "40.1", "wall": "464390"}
[2024-10-10 03:10:39,534][fairseq_cli.train][INFO] - end of epoch 513 (average epoch stats below)
[2024-10-10 03:10:39,537][train][INFO] - {"epoch": 513, "train_loss": "0.774", "train_ntokens": "263487", "train_nsentences": "1753.71", "train_wps": "144832", "train_ups": "0.55", "train_wpb": "263487", "train_bsz": "1753.7", "train_num_updates": "245630", "train_lr": "0.000209742", "train_gnorm": "0.275", "train_loss_scale": "2", "train_train_wall": "369", "train_gb_free": "39.6", "train_wall": "464432"}
[2024-10-10 03:10:39,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:10:39,752][fairseq.trainer][INFO] - begin training epoch 514
[2024-10-10 03:10:39,753][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:19:06,823][train_inner][INFO] - {"epoch": 514, "update": 513.355, "loss": "0.773", "ntokens": "262775", "nsentences": "1740.82", "wps": "95690.2", "ups": "0.36", "wpb": "262775", "bsz": "1740.8", "num_updates": "245800", "lr": "0.000209511", "gnorm": "0.265", "loss_scale": "2", "train_wall": "146", "gb_free": "39.3", "wall": "464939"}
[2024-10-10 03:23:18,449][train_inner][INFO] - {"epoch": 514, "update": 513.772, "loss": "0.774", "ntokens": "263905", "nsentences": "1764.48", "wps": "209777", "ups": "0.79", "wpb": "263905", "bsz": "1764.5", "num_updates": "246000", "lr": "0.000209239", "gnorm": "0.266", "loss_scale": "2", "train_wall": "200", "gb_free": "40", "wall": "465191"}
[2024-10-10 03:25:39,620][fairseq_cli.train][INFO] - end of epoch 514 (average epoch stats below)
[2024-10-10 03:25:39,644][train][INFO] - {"epoch": 514, "train_loss": "0.774", "train_ntokens": "263482", "train_nsentences": "1753.71", "train_wps": "140216", "train_ups": "0.53", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "246109", "train_lr": "0.000209091", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "416", "train_gb_free": "40", "train_wall": "465332"}
[2024-10-10 03:25:39,908][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:25:39,947][fairseq.trainer][INFO] - begin training epoch 515
[2024-10-10 03:25:39,948][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:32:34,066][train_inner][INFO] - {"epoch": 515, "update": 514.19, "loss": "0.775", "ntokens": "263163", "nsentences": "1723.38", "wps": "94734.2", "ups": "0.36", "wpb": "263163", "bsz": "1723.4", "num_updates": "246200", "lr": "0.000208967", "gnorm": "0.274", "loss_scale": "2", "train_wall": "185", "gb_free": "39.6", "wall": "465746"}
[2024-10-10 03:36:17,211][train_inner][INFO] - {"epoch": 515, "update": 514.608, "loss": "0.775", "ntokens": "263729", "nsentences": "1790.8", "wps": "236432", "ups": "0.9", "wpb": "263729", "bsz": "1790.8", "num_updates": "246400", "lr": "0.000208696", "gnorm": "0.275", "loss_scale": "4", "train_wall": "216", "gb_free": "40.3", "wall": "465969"}
[2024-10-10 03:39:29,725][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 03:40:16,112][fairseq_cli.train][INFO] - end of epoch 515 (average epoch stats below)
[2024-10-10 03:40:16,166][train][INFO] - {"epoch": 515, "train_loss": "0.774", "train_ntokens": "263522", "train_nsentences": "1754.26", "train_wps": "143730", "train_ups": "0.55", "train_wpb": "263522", "train_bsz": "1754.3", "train_num_updates": "246587", "train_lr": "0.000208442", "train_gnorm": "0.28", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "40.7", "train_wall": "466208"}
[2024-10-10 03:40:16,733][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:40:16,795][fairseq.trainer][INFO] - begin training epoch 516
[2024-10-10 03:40:16,802][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:45:47,469][train_inner][INFO] - {"epoch": 516, "update": 515.027, "loss": "0.774", "ntokens": "262779", "nsentences": "1749.33", "wps": "92167.4", "ups": "0.35", "wpb": "262779", "bsz": "1749.3", "num_updates": "246600", "lr": "0.000208424", "gnorm": "0.286", "loss_scale": "2", "train_wall": "249", "gb_free": "39.1", "wall": "466540"}
[2024-10-10 03:49:15,961][train_inner][INFO] - {"epoch": 516, "update": 515.445, "loss": "0.771", "ntokens": "264238", "nsentences": "1732.89", "wps": "253498", "ups": "0.96", "wpb": "264238", "bsz": "1732.9", "num_updates": "246800", "lr": "0.000208152", "gnorm": "0.269", "loss_scale": "2", "train_wall": "186", "gb_free": "39.3", "wall": "466748"}
[2024-10-10 03:53:10,862][train_inner][INFO] - {"epoch": 516, "update": 515.862, "loss": "0.776", "ntokens": "264121", "nsentences": "1750.45", "wps": "224910", "ups": "0.85", "wpb": "264121", "bsz": "1750.5", "num_updates": "247000", "lr": "0.00020788", "gnorm": "0.261", "loss_scale": "2", "train_wall": "180", "gb_free": "40.1", "wall": "466983"}
[2024-10-10 03:54:52,206][fairseq_cli.train][INFO] - end of epoch 516 (average epoch stats below)
[2024-10-10 03:54:52,232][train][INFO] - {"epoch": 516, "train_loss": "0.774", "train_ntokens": "263540", "train_nsentences": "1753.71", "train_wps": "144124", "train_ups": "0.55", "train_wpb": "263540", "train_bsz": "1753.7", "train_num_updates": "247066", "train_lr": "0.000207791", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "414", "train_gb_free": "39.7", "train_wall": "467084"}
[2024-10-10 03:54:52,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:54:52,499][fairseq.trainer][INFO] - begin training epoch 517
[2024-10-10 03:54:52,500][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:02:54,228][train_inner][INFO] - {"epoch": 517, "update": 516.28, "loss": "0.775", "ntokens": "262692", "nsentences": "1763.89", "wps": "90072", "ups": "0.34", "wpb": "262692", "bsz": "1763.9", "num_updates": "247200", "lr": "0.000207609", "gnorm": "0.268", "loss_scale": "2", "train_wall": "166", "gb_free": "40.1", "wall": "467566"}
[2024-10-10 04:06:45,212][train_inner][INFO] - {"epoch": 517, "update": 516.697, "loss": "0.777", "ntokens": "264187", "nsentences": "1780.75", "wps": "228770", "ups": "0.87", "wpb": "264187", "bsz": "1780.8", "num_updates": "247400", "lr": "0.000207337", "gnorm": "0.275", "loss_scale": "2", "train_wall": "221", "gb_free": "40", "wall": "467797"}
[2024-10-10 04:09:18,320][fairseq_cli.train][INFO] - end of epoch 517 (average epoch stats below)
[2024-10-10 04:09:18,370][train][INFO] - {"epoch": 517, "train_loss": "0.775", "train_ntokens": "263638", "train_nsentences": "1753.71", "train_wps": "145811", "train_ups": "0.55", "train_wpb": "263638", "train_bsz": "1753.7", "train_num_updates": "247545", "train_lr": "0.00020714", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "507", "train_gb_free": "39.6", "train_wall": "467951"}
[2024-10-10 04:09:18,552][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:09:18,607][fairseq.trainer][INFO] - begin training epoch 518
[2024-10-10 04:09:18,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:16:14,236][train_inner][INFO] - {"epoch": 518, "update": 517.115, "loss": "0.775", "ntokens": "262817", "nsentences": "1750.64", "wps": "92377.3", "ups": "0.35", "wpb": "262817", "bsz": "1750.6", "num_updates": "247600", "lr": "0.000207065", "gnorm": "0.26", "loss_scale": "2", "train_wall": "230", "gb_free": "39.2", "wall": "468366"}
[2024-10-10 04:19:55,945][train_inner][INFO] - {"epoch": 518, "update": 517.532, "loss": "0.773", "ntokens": "263668", "nsentences": "1791.85", "wps": "237885", "ups": "0.9", "wpb": "263668", "bsz": "1791.8", "num_updates": "247800", "lr": "0.000206793", "gnorm": "0.275", "loss_scale": "2", "train_wall": "216", "gb_free": "40", "wall": "468588"}
[2024-10-10 04:23:30,297][train_inner][INFO] - {"epoch": 518, "update": 517.95, "loss": "0.772", "ntokens": "264258", "nsentences": "1707.36", "wps": "246658", "ups": "0.93", "wpb": "264258", "bsz": "1707.4", "num_updates": "248000", "lr": "0.000206522", "gnorm": "0.271", "loss_scale": "2", "train_wall": "209", "gb_free": "40.1", "wall": "468802"}
[2024-10-10 04:24:09,057][fairseq_cli.train][INFO] - end of epoch 518 (average epoch stats below)
[2024-10-10 04:24:09,086][train][INFO] - {"epoch": 518, "train_loss": "0.774", "train_ntokens": "263451", "train_nsentences": "1753.71", "train_wps": "141683", "train_ups": "0.54", "train_wpb": "263451", "train_bsz": "1753.7", "train_num_updates": "248024", "train_lr": "0.000206489", "train_gnorm": "0.274", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "39.8", "train_wall": "468841"}
[2024-10-10 04:24:09,273][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:24:09,328][fairseq.trainer][INFO] - begin training epoch 519
[2024-10-10 04:24:09,329][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:32:53,810][train_inner][INFO] - {"epoch": 519, "update": 518.367, "loss": "0.772", "ntokens": "262845", "nsentences": "1753.65", "wps": "93291.8", "ups": "0.35", "wpb": "262844", "bsz": "1753.7", "num_updates": "248200", "lr": "0.00020625", "gnorm": "0.253", "loss_scale": "2", "train_wall": "236", "gb_free": "39.6", "wall": "469366"}
[2024-10-10 04:36:39,862][train_inner][INFO] - {"epoch": 519, "update": 518.785, "loss": "0.774", "ntokens": "263958", "nsentences": "1764.26", "wps": "233552", "ups": "0.88", "wpb": "263958", "bsz": "1764.3", "num_updates": "248400", "lr": "0.000205978", "gnorm": "0.263", "loss_scale": "2", "train_wall": "221", "gb_free": "40.6", "wall": "469592"}
[2024-10-10 04:39:05,466][fairseq_cli.train][INFO] - end of epoch 519 (average epoch stats below)
[2024-10-10 04:39:05,498][train][INFO] - {"epoch": 519, "train_loss": "0.773", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "140808", "train_ups": "0.53", "train_wpb": "263508", "train_bsz": "1753.7", "train_num_updates": "248503", "train_lr": "0.000205838", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "39.6", "train_wall": "469738"}
[2024-10-10 04:39:05,668][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:39:05,690][fairseq.trainer][INFO] - begin training epoch 520
[2024-10-10 04:39:05,691][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:46:20,411][train_inner][INFO] - {"epoch": 520, "update": 519.203, "loss": "0.771", "ntokens": "263021", "nsentences": "1707.89", "wps": "90613", "ups": "0.34", "wpb": "263021", "bsz": "1707.9", "num_updates": "248600", "lr": "0.000205707", "gnorm": "0.276", "loss_scale": "2", "train_wall": "269", "gb_free": "39.2", "wall": "470173"}
[2024-10-10 04:50:02,999][train_inner][INFO] - {"epoch": 520, "update": 519.62, "loss": "0.774", "ntokens": "264410", "nsentences": "1723.18", "wps": "237599", "ups": "0.9", "wpb": "264410", "bsz": "1723.2", "num_updates": "248800", "lr": "0.000205435", "gnorm": "0.267", "loss_scale": "4", "train_wall": "217", "gb_free": "40", "wall": "470395"}
[2024-10-10 04:54:03,560][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 520 @ 248982 updates
[2024-10-10 04:54:03,561][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 04:54:07,439][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 04:54:07,510][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 520 @ 248982 updates, score None) (writing took 3.9497934663668275 seconds)
[2024-10-10 04:54:07,511][fairseq_cli.train][INFO] - end of epoch 520 (average epoch stats below)
[2024-10-10 04:54:07,526][train][INFO] - {"epoch": 520, "train_loss": "0.774", "train_ntokens": "263550", "train_nsentences": "1753.71", "train_wps": "139956", "train_ups": "0.53", "train_wpb": "263550", "train_bsz": "1753.7", "train_num_updates": "248982", "train_lr": "0.000205188", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "579", "train_gb_free": "39.3", "train_wall": "470640"}
[2024-10-10 04:54:07,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:54:07,573][fairseq.trainer][INFO] - begin training epoch 521
[2024-10-10 04:54:07,573][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:59:53,762][train_inner][INFO] - {"epoch": 521, "update": 520.038, "loss": "0.778", "ntokens": "262316", "nsentences": "1806.3", "wps": "88808.7", "ups": "0.34", "wpb": "262316", "bsz": "1806.3", "num_updates": "249000", "lr": "0.000205163", "gnorm": "0.264", "loss_scale": "4", "train_wall": "268", "gb_free": "39.3", "wall": "470986"}
[2024-10-10 05:02:05,327][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 05:03:48,794][train_inner][INFO] - {"epoch": 521, "update": 520.457, "loss": "0.774", "ntokens": "263598", "nsentences": "1799.34", "wps": "224337", "ups": "0.85", "wpb": "263598", "bsz": "1799.3", "num_updates": "249200", "lr": "0.000204891", "gnorm": "0.264", "loss_scale": "2", "train_wall": "230", "gb_free": "40", "wall": "471221"}
[2024-10-10 05:07:39,319][train_inner][INFO] - {"epoch": 521, "update": 520.875, "loss": "0.771", "ntokens": "264465", "nsentences": "1713.9", "wps": "229458", "ups": "0.87", "wpb": "264465", "bsz": "1713.9", "num_updates": "249400", "lr": "0.00020462", "gnorm": "0.271", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "471451"}
[2024-10-10 05:09:04,162][fairseq_cli.train][INFO] - end of epoch 521 (average epoch stats below)
[2024-10-10 05:09:04,178][train][INFO] - {"epoch": 521, "train_loss": "0.773", "train_ntokens": "263545", "train_nsentences": "1755.38", "train_wps": "140496", "train_ups": "0.53", "train_wpb": "263545", "train_bsz": "1755.4", "train_num_updates": "249460", "train_lr": "0.000204538", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "570", "train_gb_free": "39.7", "train_wall": "471536"}
[2024-10-10 05:09:04,347][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:09:04,366][fairseq.trainer][INFO] - begin training epoch 522
[2024-10-10 05:09:04,366][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:17:17,502][train_inner][INFO] - {"epoch": 522, "update": 521.292, "loss": "0.774", "ntokens": "262969", "nsentences": "1772.26", "wps": "90966.4", "ups": "0.35", "wpb": "262969", "bsz": "1772.3", "num_updates": "249600", "lr": "0.000204348", "gnorm": "0.258", "loss_scale": "2", "train_wall": "255", "gb_free": "39.2", "wall": "472030"}
[2024-10-10 05:21:23,723][train_inner][INFO] - {"epoch": 522, "update": 521.71, "loss": "0.774", "ntokens": "263789", "nsentences": "1779.28", "wps": "214284", "ups": "0.81", "wpb": "263789", "bsz": "1779.3", "num_updates": "249800", "lr": "0.000204076", "gnorm": "0.27", "loss_scale": "2", "train_wall": "241", "gb_free": "39.3", "wall": "472276"}
[2024-10-10 05:24:02,536][fairseq_cli.train][INFO] - end of epoch 522 (average epoch stats below)
[2024-10-10 05:24:02,568][train][INFO] - {"epoch": 522, "train_loss": "0.773", "train_ntokens": "263578", "train_nsentences": "1753.71", "train_wps": "140536", "train_ups": "0.53", "train_wpb": "263578", "train_bsz": "1753.7", "train_num_updates": "249939", "train_lr": "0.000203887", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "568", "train_gb_free": "39.3", "train_wall": "472435"}
[2024-10-10 05:24:02,752][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:24:02,783][fairseq.trainer][INFO] - begin training epoch 523
[2024-10-10 05:24:02,783][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:30:51,316][train_inner][INFO] - {"epoch": 523, "update": 522.127, "loss": "0.772", "ntokens": "262875", "nsentences": "1728.22", "wps": "92629.9", "ups": "0.35", "wpb": "262875", "bsz": "1728.2", "num_updates": "250000", "lr": "0.000203804", "gnorm": "0.272", "loss_scale": "2", "train_wall": "231", "gb_free": "39.3", "wall": "472843"}
[2024-10-10 05:30:51,335][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 523 @ 250000 updates
[2024-10-10 05:30:51,336][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_523_250000.pt
[2024-10-10 05:30:55,095][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_523_250000.pt
[2024-10-10 05:31:00,534][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_523_250000.pt (epoch 523 @ 250000 updates, score None) (writing took 9.19914484769106 seconds)
[2024-10-10 05:34:09,637][train_inner][INFO] - {"epoch": 523, "update": 522.545, "loss": "0.772", "ntokens": "263877", "nsentences": "1772.29", "wps": "266131", "ups": "1.01", "wpb": "263877", "bsz": "1772.3", "num_updates": "250200", "lr": "0.000203533", "gnorm": "0.268", "loss_scale": "2", "train_wall": "169", "gb_free": "40", "wall": "473042"}
[2024-10-10 05:37:45,534][train_inner][INFO] - {"epoch": 523, "update": 522.962, "loss": "0.773", "ntokens": "264158", "nsentences": "1734.71", "wps": "244723", "ups": "0.93", "wpb": "264158", "bsz": "1734.7", "num_updates": "250400", "lr": "0.000203261", "gnorm": "0.265", "loss_scale": "2", "train_wall": "160", "gb_free": "40", "wall": "473258"}
[2024-10-10 05:38:31,057][fairseq_cli.train][INFO] - end of epoch 523 (average epoch stats below)
[2024-10-10 05:38:31,078][train][INFO] - {"epoch": 523, "train_loss": "0.772", "train_ntokens": "263445", "train_nsentences": "1753.71", "train_wps": "145299", "train_ups": "0.55", "train_wpb": "263445", "train_bsz": "1753.7", "train_num_updates": "250418", "train_lr": "0.000203236", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "449", "train_gb_free": "39.6", "train_wall": "473303"}
[2024-10-10 05:38:31,263][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:38:31,303][fairseq.trainer][INFO] - begin training epoch 524
[2024-10-10 05:38:31,304][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:47:29,910][train_inner][INFO] - {"epoch": 524, "update": 523.38, "loss": "0.773", "ntokens": "262680", "nsentences": "1748.02", "wps": "89903.7", "ups": "0.34", "wpb": "262680", "bsz": "1748", "num_updates": "250600", "lr": "0.000202989", "gnorm": "0.262", "loss_scale": "2", "train_wall": "271", "gb_free": "39.7", "wall": "473842"}
[2024-10-10 05:51:22,237][train_inner][INFO] - {"epoch": 524, "update": 523.797, "loss": "0.772", "ntokens": "263712", "nsentences": "1772.61", "wps": "227031", "ups": "0.86", "wpb": "263712", "bsz": "1772.6", "num_updates": "250800", "lr": "0.000202717", "gnorm": "0.269", "loss_scale": "2", "train_wall": "227", "gb_free": "39.8", "wall": "474074"}
[2024-10-10 05:53:12,956][fairseq_cli.train][INFO] - end of epoch 524 (average epoch stats below)
[2024-10-10 05:53:12,992][train][INFO] - {"epoch": 524, "train_loss": "0.773", "train_ntokens": "263397", "train_nsentences": "1753.71", "train_wps": "143062", "train_ups": "0.54", "train_wpb": "263397", "train_bsz": "1753.7", "train_num_updates": "250897", "train_lr": "0.000202586", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "562", "train_gb_free": "39.1", "train_wall": "474185"}
[2024-10-10 05:53:13,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:53:13,153][fairseq.trainer][INFO] - begin training epoch 525
[2024-10-10 05:53:13,154][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:00:50,526][train_inner][INFO] - {"epoch": 525, "update": 524.215, "loss": "0.771", "ntokens": "262984", "nsentences": "1732.45", "wps": "92555.1", "ups": "0.35", "wpb": "262984", "bsz": "1732.5", "num_updates": "251000", "lr": "0.000202446", "gnorm": "0.271", "loss_scale": "2", "train_wall": "198", "gb_free": "39.6", "wall": "474643"}
[2024-10-10 06:04:04,227][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 06:04:34,704][train_inner][INFO] - {"epoch": 525, "update": 524.635, "loss": "0.772", "ntokens": "263696", "nsentences": "1787.78", "wps": "235304", "ups": "0.89", "wpb": "263696", "bsz": "1787.8", "num_updates": "251200", "lr": "0.000202174", "gnorm": "0.262", "loss_scale": "2", "train_wall": "143", "gb_free": "39.6", "wall": "474867"}
[2024-10-10 06:08:10,770][fairseq_cli.train][INFO] - end of epoch 525 (average epoch stats below)
[2024-10-10 06:08:10,791][train][INFO] - {"epoch": 525, "train_loss": "0.772", "train_ntokens": "263558", "train_nsentences": "1754.33", "train_wps": "140324", "train_ups": "0.53", "train_wpb": "263558", "train_bsz": "1754.3", "train_num_updates": "251375", "train_lr": "0.000201936", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "378", "train_gb_free": "39.6", "train_wall": "475083"}
[2024-10-10 06:08:10,931][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:08:10,941][fairseq.trainer][INFO] - begin training epoch 526
[2024-10-10 06:08:10,941][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:14:16,985][train_inner][INFO] - {"epoch": 526, "update": 525.052, "loss": "0.773", "ntokens": "263430", "nsentences": "1698.36", "wps": "90484.6", "ups": "0.34", "wpb": "263430", "bsz": "1698.4", "num_updates": "251400", "lr": "0.000201902", "gnorm": "0.29", "loss_scale": "2", "train_wall": "197", "gb_free": "39.8", "wall": "475449"}
[2024-10-10 06:17:45,403][train_inner][INFO] - {"epoch": 526, "update": 525.47, "loss": "0.771", "ntokens": "263877", "nsentences": "1776.4", "wps": "253241", "ups": "0.96", "wpb": "263877", "bsz": "1776.4", "num_updates": "251600", "lr": "0.00020163", "gnorm": "0.256", "loss_scale": "2", "train_wall": "202", "gb_free": "38.9", "wall": "475658"}
[2024-10-10 06:21:34,850][train_inner][INFO] - {"epoch": 526, "update": 525.887, "loss": "0.771", "ntokens": "264080", "nsentences": "1722.79", "wps": "230201", "ups": "0.87", "wpb": "264080", "bsz": "1722.8", "num_updates": "251800", "lr": "0.000201359", "gnorm": "0.277", "loss_scale": "2", "train_wall": "221", "gb_free": "40", "wall": "475887"}
[2024-10-10 06:22:52,582][fairseq_cli.train][INFO] - end of epoch 526 (average epoch stats below)
[2024-10-10 06:22:52,615][train][INFO] - {"epoch": 526, "train_loss": "0.772", "train_ntokens": "263461", "train_nsentences": "1753.71", "train_wps": "143118", "train_ups": "0.54", "train_wpb": "263461", "train_bsz": "1753.7", "train_num_updates": "251854", "train_lr": "0.000201285", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "523", "train_gb_free": "39.6", "train_wall": "475965"}
[2024-10-10 06:22:52,814][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:22:52,840][fairseq.trainer][INFO] - begin training epoch 527
[2024-10-10 06:22:52,840][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:31:09,147][train_inner][INFO] - {"epoch": 527, "update": 526.305, "loss": "0.772", "ntokens": "262753", "nsentences": "1761.68", "wps": "91508.8", "ups": "0.35", "wpb": "262753", "bsz": "1761.7", "num_updates": "252000", "lr": "0.000201087", "gnorm": "0.269", "loss_scale": "2", "train_wall": "203", "gb_free": "41", "wall": "476461"}
[2024-10-10 06:35:04,940][train_inner][INFO] - {"epoch": 527, "update": 526.722, "loss": "0.773", "ntokens": "264045", "nsentences": "1758.85", "wps": "223979", "ups": "0.85", "wpb": "264045", "bsz": "1758.8", "num_updates": "252200", "lr": "0.000200815", "gnorm": "0.262", "loss_scale": "2", "train_wall": "222", "gb_free": "39.6", "wall": "476697"}
[2024-10-10 06:37:37,204][fairseq_cli.train][INFO] - end of epoch 527 (average epoch stats below)
[2024-10-10 06:37:37,238][train][INFO] - {"epoch": 527, "train_loss": "0.772", "train_ntokens": "263520", "train_nsentences": "1753.71", "train_wps": "142696", "train_ups": "0.54", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "252333", "train_lr": "0.000200635", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "525", "train_gb_free": "40.5", "train_wall": "476849"}
[2024-10-10 06:37:37,511][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:37:37,535][fairseq.trainer][INFO] - begin training epoch 528
[2024-10-10 06:37:37,536][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:44:46,232][train_inner][INFO] - {"epoch": 528, "update": 527.14, "loss": "0.774", "ntokens": "262431", "nsentences": "1791.55", "wps": "90295", "ups": "0.34", "wpb": "262431", "bsz": "1791.5", "num_updates": "252400", "lr": "0.000200543", "gnorm": "0.253", "loss_scale": "2", "train_wall": "243", "gb_free": "40", "wall": "477278"}
[2024-10-10 06:48:20,040][train_inner][INFO] - {"epoch": 528, "update": 527.557, "loss": "0.773", "ntokens": "263540", "nsentences": "1808.32", "wps": "246551", "ups": "0.94", "wpb": "263540", "bsz": "1808.3", "num_updates": "252600", "lr": "0.000200272", "gnorm": "0.276", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "477492"}
[2024-10-10 06:51:55,031][train_inner][INFO] - {"epoch": 528, "update": 527.975, "loss": "0.772", "ntokens": "264700", "nsentences": "1679.33", "wps": "246261", "ups": "0.93", "wpb": "264700", "bsz": "1679.3", "num_updates": "252800", "lr": "0.0002", "gnorm": "0.264", "loss_scale": "2", "train_wall": "210", "gb_free": "41", "wall": "477707"}
[2024-10-10 06:52:31,294][fairseq_cli.train][INFO] - end of epoch 528 (average epoch stats below)
[2024-10-10 06:52:31,314][train][INFO] - {"epoch": 528, "train_loss": "0.772", "train_ntokens": "263494", "train_nsentences": "1753.71", "train_wps": "141171", "train_ups": "0.54", "train_wpb": "263494", "train_bsz": "1753.7", "train_num_updates": "252812", "train_lr": "0.000199984", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "547", "train_gb_free": "40", "train_wall": "477743"}
[2024-10-10 06:52:31,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:52:31,500][fairseq.trainer][INFO] - begin training epoch 529
[2024-10-10 06:52:31,501][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:01:19,614][train_inner][INFO] - {"epoch": 529, "update": 528.392, "loss": "0.77", "ntokens": "262857", "nsentences": "1739.29", "wps": "93117", "ups": "0.35", "wpb": "262857", "bsz": "1739.3", "num_updates": "253000", "lr": "0.000199728", "gnorm": "0.261", "loss_scale": "2", "train_wall": "230", "gb_free": "39.1", "wall": "478272"}
[2024-10-10 07:05:00,838][train_inner][INFO] - {"epoch": 529, "update": 528.81, "loss": "0.774", "ntokens": "263806", "nsentences": "1780.22", "wps": "238530", "ups": "0.9", "wpb": "263806", "bsz": "1780.2", "num_updates": "253200", "lr": "0.000199457", "gnorm": "0.266", "loss_scale": "2", "train_wall": "216", "gb_free": "39.3", "wall": "478493"}
[2024-10-10 07:06:57,401][fairseq_cli.train][INFO] - end of epoch 529 (average epoch stats below)
[2024-10-10 07:06:57,405][train][INFO] - {"epoch": 529, "train_loss": "0.771", "train_ntokens": "263506", "train_nsentences": "1753.71", "train_wps": "145736", "train_ups": "0.55", "train_wpb": "263506", "train_bsz": "1753.7", "train_num_updates": "253291", "train_lr": "0.000199333", "train_gnorm": "0.265", "train_loss_scale": "4", "train_train_wall": "526", "train_gb_free": "40.1", "train_wall": "478610"}
[2024-10-10 07:06:57,510][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:06:57,524][fairseq.trainer][INFO] - begin training epoch 530
[2024-10-10 07:06:57,525][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:14:22,624][train_inner][INFO] - {"epoch": 530, "update": 529.228, "loss": "0.77", "ntokens": "263036", "nsentences": "1724.12", "wps": "93645.1", "ups": "0.36", "wpb": "263036", "bsz": "1724.1", "num_updates": "253400", "lr": "0.000199185", "gnorm": "0.262", "loss_scale": "4", "train_wall": "252", "gb_free": "39.6", "wall": "479055"}
[2024-10-10 07:18:13,755][train_inner][INFO] - {"epoch": 530, "update": 529.645, "loss": "0.771", "ntokens": "263635", "nsentences": "1785.29", "wps": "228142", "ups": "0.87", "wpb": "263635", "bsz": "1785.3", "num_updates": "253600", "lr": "0.000198913", "gnorm": "0.278", "loss_scale": "4", "train_wall": "226", "gb_free": "39.2", "wall": "479286"}
[2024-10-10 07:20:15,155][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 07:21:50,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 530 @ 253769 updates
[2024-10-10 07:21:50,279][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 07:21:54,512][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 07:21:54,597][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 530 @ 253769 updates, score None) (writing took 4.319471311755478 seconds)
[2024-10-10 07:21:54,598][fairseq_cli.train][INFO] - end of epoch 530 (average epoch stats below)
[2024-10-10 07:21:54,600][train][INFO] - {"epoch": 530, "train_loss": "0.771", "train_ntokens": "263500", "train_nsentences": "1753.17", "train_wps": "140387", "train_ups": "0.53", "train_wpb": "263500", "train_bsz": "1753.2", "train_num_updates": "253769", "train_lr": "0.000198683", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "575", "train_gb_free": "39.3", "train_wall": "479507"}
[2024-10-10 07:21:54,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:21:54,653][fairseq.trainer][INFO] - begin training epoch 531
[2024-10-10 07:21:54,654][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:27:42,028][train_inner][INFO] - {"epoch": 531, "update": 530.065, "loss": "0.772", "ntokens": "263108", "nsentences": "1730.51", "wps": "92603.5", "ups": "0.35", "wpb": "263108", "bsz": "1730.5", "num_updates": "253800", "lr": "0.000198641", "gnorm": "0.27", "loss_scale": "2", "train_wall": "236", "gb_free": "40", "wall": "479854"}
[2024-10-10 07:31:14,036][train_inner][INFO] - {"epoch": 531, "update": 530.482, "loss": "0.768", "ntokens": "264039", "nsentences": "1743.61", "wps": "249117", "ups": "0.94", "wpb": "264039", "bsz": "1743.6", "num_updates": "254000", "lr": "0.00019837", "gnorm": "0.276", "loss_scale": "2", "train_wall": "168", "gb_free": "39.1", "wall": "480066"}
[2024-10-10 07:35:32,736][train_inner][INFO] - {"epoch": 531, "update": 530.9, "loss": "0.773", "ntokens": "263901", "nsentences": "1769.11", "wps": "204036", "ups": "0.77", "wpb": "263902", "bsz": "1769.1", "num_updates": "254200", "lr": "0.000198098", "gnorm": "0.267", "loss_scale": "2", "train_wall": "141", "gb_free": "40", "wall": "480325"}
[2024-10-10 07:36:30,535][fairseq_cli.train][INFO] - end of epoch 531 (average epoch stats below)
[2024-10-10 07:36:30,562][train][INFO] - {"epoch": 531, "train_loss": "0.771", "train_ntokens": "263514", "train_nsentences": "1753.71", "train_wps": "144100", "train_ups": "0.55", "train_wpb": "263514", "train_bsz": "1753.7", "train_num_updates": "254248", "train_lr": "0.000198033", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "380", "train_gb_free": "40.5", "train_wall": "480383"}
[2024-10-10 07:36:30,686][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:36:30,717][fairseq.trainer][INFO] - begin training epoch 532
[2024-10-10 07:36:30,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:44:51,845][train_inner][INFO] - {"epoch": 532, "update": 531.317, "loss": "0.77", "ntokens": "262542", "nsentences": "1759.18", "wps": "93918.9", "ups": "0.36", "wpb": "262542", "bsz": "1759.2", "num_updates": "254400", "lr": "0.000197826", "gnorm": "0.28", "loss_scale": "2", "train_wall": "203", "gb_free": "40", "wall": "480884"}
[2024-10-10 07:49:05,981][train_inner][INFO] - {"epoch": 532, "update": 531.735, "loss": "0.771", "ntokens": "264084", "nsentences": "1775.12", "wps": "207854", "ups": "0.79", "wpb": "264084", "bsz": "1775.1", "num_updates": "254600", "lr": "0.000197554", "gnorm": "0.258", "loss_scale": "2", "train_wall": "143", "gb_free": "40", "wall": "481138"}
[2024-10-10 07:51:49,082][fairseq_cli.train][INFO] - end of epoch 532 (average epoch stats below)
[2024-10-10 07:51:49,100][train][INFO] - {"epoch": 532, "train_loss": "0.771", "train_ntokens": "263561", "train_nsentences": "1753.71", "train_wps": "137444", "train_ups": "0.52", "train_wpb": "263561", "train_bsz": "1753.7", "train_num_updates": "254727", "train_lr": "0.000197382", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "365", "train_gb_free": "39.1", "train_wall": "481301"}
[2024-10-10 07:51:49,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:51:49,252][fairseq.trainer][INFO] - begin training epoch 533
[2024-10-10 07:51:49,253][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:58:28,832][train_inner][INFO] - {"epoch": 533, "update": 532.152, "loss": "0.772", "ntokens": "263283", "nsentences": "1701.79", "wps": "93560.2", "ups": "0.36", "wpb": "263282", "bsz": "1701.8", "num_updates": "254800", "lr": "0.000197283", "gnorm": "0.256", "loss_scale": "2", "train_wall": "124", "gb_free": "40", "wall": "481701"}
[2024-10-10 08:02:02,755][train_inner][INFO] - {"epoch": 533, "update": 532.57, "loss": "0.771", "ntokens": "263784", "nsentences": "1770.38", "wps": "246646", "ups": "0.94", "wpb": "263784", "bsz": "1770.4", "num_updates": "255000", "lr": "0.000197011", "gnorm": "0.28", "loss_scale": "2", "train_wall": "160", "gb_free": "39.2", "wall": "481915"}
[2024-10-10 08:05:56,686][train_inner][INFO] - {"epoch": 533, "update": 532.987, "loss": "0.773", "ntokens": "263840", "nsentences": "1768.94", "wps": "225617", "ups": "0.86", "wpb": "263840", "bsz": "1768.9", "num_updates": "255200", "lr": "0.000196739", "gnorm": "0.268", "loss_scale": "2", "train_wall": "160", "gb_free": "39.4", "wall": "482149"}
[2024-10-10 08:06:26,770][fairseq_cli.train][INFO] - end of epoch 533 (average epoch stats below)
[2024-10-10 08:06:26,795][train][INFO] - {"epoch": 533, "train_loss": "0.771", "train_ntokens": "263419", "train_nsentences": "1753.71", "train_wps": "143770", "train_ups": "0.55", "train_wpb": "263419", "train_bsz": "1753.7", "train_num_updates": "255206", "train_lr": "0.000196731", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "407", "train_gb_free": "39.8", "train_wall": "482179"}
[2024-10-10 08:06:28,879][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:06:28,979][fairseq.trainer][INFO] - begin training epoch 534
[2024-10-10 08:06:28,979][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:15:08,103][train_inner][INFO] - {"epoch": 534, "update": 533.405, "loss": "0.767", "ntokens": "263435", "nsentences": "1695.09", "wps": "95565.5", "ups": "0.36", "wpb": "263435", "bsz": "1695.1", "num_updates": "255400", "lr": "0.000196467", "gnorm": "0.26", "loss_scale": "2", "train_wall": "217", "gb_free": "40", "wall": "482700"}
[2024-10-10 08:19:15,500][train_inner][INFO] - {"epoch": 534, "update": 533.823, "loss": "0.774", "ntokens": "263447", "nsentences": "1812.62", "wps": "212985", "ups": "0.81", "wpb": "263447", "bsz": "1812.6", "num_updates": "255600", "lr": "0.000196196", "gnorm": "0.261", "loss_scale": "2", "train_wall": "202", "gb_free": "40", "wall": "482948"}
[2024-10-10 08:21:08,016][fairseq_cli.train][INFO] - end of epoch 534 (average epoch stats below)
[2024-10-10 08:21:08,033][train][INFO] - {"epoch": 534, "train_loss": "0.771", "train_ntokens": "263515", "train_nsentences": "1753.71", "train_wps": "143236", "train_ups": "0.54", "train_wpb": "263515", "train_bsz": "1753.7", "train_num_updates": "255685", "train_lr": "0.00019608", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "454", "train_gb_free": "39.3", "train_wall": "483060"}
[2024-10-10 08:21:08,127][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:21:08,134][fairseq.trainer][INFO] - begin training epoch 535
[2024-10-10 08:21:08,134][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:28:50,061][train_inner][INFO] - {"epoch": 535, "update": 534.24, "loss": "0.773", "ntokens": "262578", "nsentences": "1772.62", "wps": "91403.4", "ups": "0.35", "wpb": "262578", "bsz": "1772.6", "num_updates": "255800", "lr": "0.000195924", "gnorm": "0.262", "loss_scale": "4", "train_wall": "203", "gb_free": "39.6", "wall": "483522"}
[2024-10-10 08:29:44,192][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 08:32:47,443][train_inner][INFO] - {"epoch": 535, "update": 534.66, "loss": "0.769", "ntokens": "264188", "nsentences": "1727.58", "wps": "222615", "ups": "0.84", "wpb": "264188", "bsz": "1727.6", "num_updates": "256000", "lr": "0.000195652", "gnorm": "0.275", "loss_scale": "2", "train_wall": "231", "gb_free": "40.5", "wall": "483760"}
[2024-10-10 08:36:11,467][fairseq_cli.train][INFO] - end of epoch 535 (average epoch stats below)
[2024-10-10 08:36:11,566][train][INFO] - {"epoch": 535, "train_loss": "0.771", "train_ntokens": "263481", "train_nsentences": "1754.97", "train_wps": "139397", "train_ups": "0.53", "train_wpb": "263481", "train_bsz": "1755", "train_num_updates": "256163", "train_lr": "0.000195431", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "567", "train_gb_free": "40.5", "train_wall": "483964"}
[2024-10-10 08:36:11,711][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:36:11,727][fairseq.trainer][INFO] - begin training epoch 536
[2024-10-10 08:36:11,727][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:42:39,839][train_inner][INFO] - {"epoch": 536, "update": 535.077, "loss": "0.771", "ntokens": "262747", "nsentences": "1757.99", "wps": "88729.8", "ups": "0.34", "wpb": "262747", "bsz": "1758", "num_updates": "256200", "lr": "0.00019538", "gnorm": "0.263", "loss_scale": "2", "train_wall": "251", "gb_free": "39.3", "wall": "484352"}
[2024-10-10 08:46:04,926][train_inner][INFO] - {"epoch": 536, "update": 535.495, "loss": "0.769", "ntokens": "264220", "nsentences": "1739.89", "wps": "257702", "ups": "0.98", "wpb": "264220", "bsz": "1739.9", "num_updates": "256400", "lr": "0.000195109", "gnorm": "0.271", "loss_scale": "2", "train_wall": "199", "gb_free": "39.6", "wall": "484557"}
[2024-10-10 08:49:59,396][train_inner][INFO] - {"epoch": 536, "update": 535.912, "loss": "0.772", "ntokens": "263776", "nsentences": "1763.04", "wps": "225010", "ups": "0.85", "wpb": "263776", "bsz": "1763", "num_updates": "256600", "lr": "0.000194837", "gnorm": "0.255", "loss_scale": "2", "train_wall": "227", "gb_free": "40", "wall": "484792"}
[2024-10-10 08:51:02,311][fairseq_cli.train][INFO] - end of epoch 536 (average epoch stats below)
[2024-10-10 08:51:02,339][train][INFO] - {"epoch": 536, "train_loss": "0.77", "train_ntokens": "263500", "train_nsentences": "1753.71", "train_wps": "141697", "train_ups": "0.54", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "256642", "train_lr": "0.00019478", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "40", "train_wall": "484855"}
[2024-10-10 08:51:02,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:51:02,535][fairseq.trainer][INFO] - begin training epoch 537
[2024-10-10 08:51:02,536][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:59:20,737][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-10 08:59:21,715][train_inner][INFO] - {"epoch": 537, "update": 536.332, "loss": "0.769", "ntokens": "262883", "nsentences": "1754.32", "wps": "93506.8", "ups": "0.36", "wpb": "262883", "bsz": "1754.3", "num_updates": "256800", "lr": "0.000194565", "gnorm": "0.269", "loss_scale": "1", "train_wall": "233", "gb_free": "39.1", "wall": "485354"}
[2024-10-10 09:03:37,360][train_inner][INFO] - {"epoch": 537, "update": 536.749, "loss": "0.771", "ntokens": "263904", "nsentences": "1771.98", "wps": "206497", "ups": "0.78", "wpb": "263904", "bsz": "1772", "num_updates": "257000", "lr": "0.000194293", "gnorm": "0.274", "loss_scale": "1", "train_wall": "250", "gb_free": "40.1", "wall": "485610"}
[2024-10-10 09:05:43,180][fairseq_cli.train][INFO] - end of epoch 537 (average epoch stats below)
[2024-10-10 09:05:43,250][train][INFO] - {"epoch": 537, "train_loss": "0.771", "train_ntokens": "263558", "train_nsentences": "1753.81", "train_wps": "143016", "train_ups": "0.54", "train_wpb": "263558", "train_bsz": "1753.8", "train_num_updates": "257120", "train_lr": "0.00019413", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "544", "train_gb_free": "39.6", "train_wall": "485735"}
[2024-10-10 09:05:43,617][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 09:05:43,638][fairseq.trainer][INFO] - begin training epoch 538
[2024-10-10 09:05:43,639][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 09:12:59,904][train_inner][INFO] - {"epoch": 538, "update": 537.167, "loss": "0.772", "ntokens": "262906", "nsentences": "1742.24", "wps": "93475.1", "ups": "0.36", "wpb": "262906", "bsz": "1742.2", "num_updates": "257200", "lr": "0.000194022", "gnorm": "0.269", "loss_scale": "1", "train_wall": "219", "gb_free": "39.3", "wall": "486172"}
[2024-10-10 09:16:30,078][train_inner][INFO] - {"epoch": 538, "update": 537.585, "loss": "0.77", "ntokens": "263727", "nsentences": "1765.3", "wps": "250982", "ups": "0.95", "wpb": "263727", "bsz": "1765.3", "num_updates": "257400", "lr": "0.00019375", "gnorm": "0.272", "loss_scale": "1", "train_wall": "205", "gb_free": "39.6", "wall": "486382"}
[2024-10-10 09:20:27,888][fairseq_cli.train][INFO] - end of epoch 538 (average epoch stats below)
[2024-10-10 09:20:27,907][train][INFO] - {"epoch": 538, "train_loss": "0.77", "train_ntokens": "263424", "train_nsentences": "1753.71", "train_wps": "142641", "train_ups": "0.54", "train_wpb": "263424", "train_bsz": "1753.7", "train_num_updates": "257599", "train_lr": "0.00019348", "train_gnorm": "0.274", "train_loss_scale": "1", "train_train_wall": "533", "train_gb_free": "39.6", "train_wall": "486620"}
[2024-10-10 09:20:28,067][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 09:20:28,103][fairseq.trainer][INFO] - begin training epoch 539
[2024-10-10 09:20:28,104][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 09:26:08,378][train_inner][INFO] - {"epoch": 539, "update": 538.002, "loss": "0.771", "ntokens": "262982", "nsentences": "1738.04", "wps": "90951.6", "ups": "0.35", "wpb": "262982", "bsz": "1738", "num_updates": "257600", "lr": "0.000193478", "gnorm": "0.276", "loss_scale": "1", "train_wall": "235", "gb_free": "39.1", "wall": "486961"}
[2024-10-10 09:29:33,710][train_inner][INFO] - {"epoch": 539, "update": 538.42, "loss": "0.769", "ntokens": "263974", "nsentences": "1752.2", "wps": "257131", "ups": "0.97", "wpb": "263974", "bsz": "1752.2", "num_updates": "257800", "lr": "0.000193207", "gnorm": "0.261", "loss_scale": "1", "train_wall": "200", "gb_free": "39.2", "wall": "487166"}
[2024-10-10 09:33:20,643][train_inner][INFO] - {"epoch": 539, "update": 538.837, "loss": "0.767", "ntokens": "263926", "nsentences": "1742.42", "wps": "232621", "ups": "0.88", "wpb": "263926", "bsz": "1742.4", "num_updates": "258000", "lr": "0.000192935", "gnorm": "0.267", "loss_scale": "1", "train_wall": "220", "gb_free": "39.3", "wall": "487393"}
[2024-10-10 09:34:58,240][fairseq_cli.train][INFO] - end of epoch 539 (average epoch stats below)
[2024-10-10 09:34:58,254][train][INFO] - {"epoch": 539, "train_loss": "0.77", "train_ntokens": "263393", "train_nsentences": "1753.71", "train_wps": "144969", "train_ups": "0.55", "train_wpb": "263393", "train_bsz": "1753.7", "train_num_updates": "258078", "train_lr": "0.000192829", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "518", "train_gb_free": "40", "train_wall": "487490"}
[2024-10-10 09:34:58,338][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 09:34:58,365][fairseq.trainer][INFO] - begin training epoch 540
[2024-10-10 09:34:58,366][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 09:42:54,056][train_inner][INFO] - {"epoch": 540, "update": 539.255, "loss": "0.772", "ntokens": "262750", "nsentences": "1767.55", "wps": "91647", "ups": "0.35", "wpb": "262750", "bsz": "1767.5", "num_updates": "258200", "lr": "0.000192663", "gnorm": "0.272", "loss_scale": "1", "train_wall": "249", "gb_free": "39.8", "wall": "487966"}
[2024-10-10 09:47:03,306][train_inner][INFO] - {"epoch": 540, "update": 539.672, "loss": "0.769", "ntokens": "264216", "nsentences": "1740.38", "wps": "212024", "ups": "0.8", "wpb": "264216", "bsz": "1740.4", "num_updates": "258400", "lr": "0.000192391", "gnorm": "0.275", "loss_scale": "1", "train_wall": "244", "gb_free": "40.5", "wall": "488215"}
[2024-10-10 09:50:20,814][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 540 @ 258557 updates
[2024-10-10 09:50:20,816][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 09:50:28,900][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 09:50:29,102][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 540 @ 258557 updates, score None) (writing took 8.287858195602894 seconds)
[2024-10-10 09:50:29,102][fairseq_cli.train][INFO] - end of epoch 540 (average epoch stats below)
[2024-10-10 09:50:29,105][train][INFO] - {"epoch": 540, "train_loss": "0.77", "train_ntokens": "263565", "train_nsentences": "1753.71", "train_wps": "135627", "train_ups": "0.51", "train_wpb": "263565", "train_bsz": "1753.7", "train_num_updates": "258557", "train_lr": "0.000192178", "train_gnorm": "0.276", "train_loss_scale": "1", "train_train_wall": "592", "train_gb_free": "39.8", "train_wall": "488421"}
[2024-10-10 09:50:29,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 09:50:29,279][fairseq.trainer][INFO] - begin training epoch 541
[2024-10-10 09:50:29,279][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 09:56:53,092][train_inner][INFO] - {"epoch": 541, "update": 540.09, "loss": "0.772", "ntokens": "262646", "nsentences": "1769.34", "wps": "89066.1", "ups": "0.34", "wpb": "262646", "bsz": "1769.3", "num_updates": "258600", "lr": "0.00019212", "gnorm": "0.275", "loss_scale": "1", "train_wall": "271", "gb_free": "39.3", "wall": "488805"}
[2024-10-10 10:00:28,794][train_inner][INFO] - {"epoch": 541, "update": 540.507, "loss": "0.769", "ntokens": "263995", "nsentences": "1770.93", "wps": "244788", "ups": "0.93", "wpb": "263994", "bsz": "1770.9", "num_updates": "258800", "lr": "0.000191848", "gnorm": "0.26", "loss_scale": "1", "train_wall": "211", "gb_free": "39.6", "wall": "489021"}
[2024-10-10 10:04:21,658][train_inner][INFO] - {"epoch": 541, "update": 540.925, "loss": "0.772", "ntokens": "264109", "nsentences": "1732.68", "wps": "226845", "ups": "0.86", "wpb": "264109", "bsz": "1732.7", "num_updates": "259000", "lr": "0.000191576", "gnorm": "0.263", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "489254"}
[2024-10-10 10:05:11,353][fairseq_cli.train][INFO] - end of epoch 541 (average epoch stats below)
[2024-10-10 10:05:11,365][train][INFO] - {"epoch": 541, "train_loss": "0.77", "train_ntokens": "263505", "train_nsentences": "1753.71", "train_wps": "143065", "train_ups": "0.54", "train_wpb": "263505", "train_bsz": "1753.7", "train_num_updates": "259036", "train_lr": "0.000191527", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "566", "train_gb_free": "39.6", "train_wall": "489304"}
[2024-10-10 10:05:11,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 10:05:11,644][fairseq.trainer][INFO] - begin training epoch 542
[2024-10-10 10:05:11,644][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 10:13:50,411][train_inner][INFO] - {"epoch": 542, "update": 541.342, "loss": "0.771", "ntokens": "262728", "nsentences": "1776.6", "wps": "92389.7", "ups": "0.35", "wpb": "262728", "bsz": "1776.6", "num_updates": "259200", "lr": "0.000191304", "gnorm": "0.266", "loss_scale": "2", "train_wall": "255", "gb_free": "39.6", "wall": "489823"}
[2024-10-10 10:17:32,514][train_inner][INFO] - {"epoch": 542, "update": 541.76, "loss": "0.768", "ntokens": "264290", "nsentences": "1730.41", "wps": "238004", "ups": "0.9", "wpb": "264290", "bsz": "1730.4", "num_updates": "259400", "lr": "0.000191033", "gnorm": "0.253", "loss_scale": "2", "train_wall": "212", "gb_free": "40.5", "wall": "490045"}
[2024-10-10 10:20:01,569][fairseq_cli.train][INFO] - end of epoch 542 (average epoch stats below)
[2024-10-10 10:20:01,588][train][INFO] - {"epoch": 542, "train_loss": "0.77", "train_ntokens": "263597", "train_nsentences": "1753.71", "train_wps": "141834", "train_ups": "0.54", "train_wpb": "263597", "train_bsz": "1753.7", "train_num_updates": "259515", "train_lr": "0.000190876", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "39.6", "train_wall": "490194"}
[2024-10-10 10:20:01,795][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 10:20:01,843][fairseq.trainer][INFO] - begin training epoch 543
[2024-10-10 10:20:01,844][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 10:26:57,750][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-10 10:26:59,251][train_inner][INFO] - {"epoch": 543, "update": 542.18, "loss": "0.77", "ntokens": "262883", "nsentences": "1746.2", "wps": "92776.9", "ups": "0.35", "wpb": "262883", "bsz": "1746.2", "num_updates": "259600", "lr": "0.000190761", "gnorm": "0.266", "loss_scale": "1", "train_wall": "241", "gb_free": "39.1", "wall": "490611"}
[2024-10-10 10:30:40,042][train_inner][INFO] - {"epoch": 543, "update": 542.597, "loss": "0.768", "ntokens": "264013", "nsentences": "1751.86", "wps": "239186", "ups": "0.91", "wpb": "264013", "bsz": "1751.9", "num_updates": "259800", "lr": "0.000190489", "gnorm": "0.296", "loss_scale": "1", "train_wall": "215", "gb_free": "40", "wall": "490832"}
[2024-10-10 10:34:38,954][fairseq_cli.train][INFO] - end of epoch 543 (average epoch stats below)
[2024-10-10 10:34:38,973][train][INFO] - {"epoch": 543, "train_loss": "0.769", "train_ntokens": "263532", "train_nsentences": "1754.93", "train_wps": "143574", "train_ups": "0.54", "train_wpb": "263532", "train_bsz": "1754.9", "train_num_updates": "259993", "train_lr": "0.000190227", "train_gnorm": "0.279", "train_loss_scale": "1", "train_train_wall": "545", "train_gb_free": "39.3", "train_wall": "491071"}
[2024-10-10 10:34:39,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 10:34:39,044][fairseq.trainer][INFO] - begin training epoch 544
[2024-10-10 10:34:39,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 10:40:22,146][train_inner][INFO] - {"epoch": 544, "update": 543.015, "loss": "0.772", "ntokens": "262803", "nsentences": "1760.61", "wps": "90296.9", "ups": "0.34", "wpb": "262803", "bsz": "1760.6", "num_updates": "260000", "lr": "0.000190217", "gnorm": "0.268", "loss_scale": "1", "train_wall": "254", "gb_free": "40.5", "wall": "491414"}
[2024-10-10 10:44:10,172][train_inner][INFO] - {"epoch": 544, "update": 543.432, "loss": "0.769", "ntokens": "263565", "nsentences": "1777.46", "wps": "231215", "ups": "0.88", "wpb": "263565", "bsz": "1777.5", "num_updates": "260200", "lr": "0.000189946", "gnorm": "0.26", "loss_scale": "1", "train_wall": "218", "gb_free": "40.1", "wall": "491642"}
[2024-10-10 10:48:10,288][train_inner][INFO] - {"epoch": 544, "update": 543.85, "loss": "0.771", "ntokens": "263855", "nsentences": "1770.11", "wps": "219787", "ups": "0.83", "wpb": "263855", "bsz": "1770.1", "num_updates": "260400", "lr": "0.000189674", "gnorm": "0.257", "loss_scale": "1", "train_wall": "234", "gb_free": "39.6", "wall": "491882"}
[2024-10-10 10:49:45,815][fairseq_cli.train][INFO] - end of epoch 544 (average epoch stats below)
[2024-10-10 10:49:45,835][train][INFO] - {"epoch": 544, "train_loss": "0.769", "train_ntokens": "263373", "train_nsentences": "1753.71", "train_wps": "139117", "train_ups": "0.53", "train_wpb": "263373", "train_bsz": "1753.7", "train_num_updates": "260472", "train_lr": "0.000189576", "train_gnorm": "0.258", "train_loss_scale": "1", "train_train_wall": "567", "train_gb_free": "40.5", "train_wall": "491978"}
[2024-10-10 10:49:45,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 10:49:45,962][fairseq.trainer][INFO] - begin training epoch 545
[2024-10-10 10:49:45,962][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 10:57:34,458][train_inner][INFO] - {"epoch": 545, "update": 544.267, "loss": "0.766", "ntokens": "263146", "nsentences": "1698.32", "wps": "93290", "ups": "0.35", "wpb": "263146", "bsz": "1698.3", "num_updates": "260600", "lr": "0.000189402", "gnorm": "0.25", "loss_scale": "1", "train_wall": "246", "gb_free": "40.3", "wall": "492447"}
[2024-10-10 11:01:52,725][train_inner][INFO] - {"epoch": 545, "update": 544.685, "loss": "0.768", "ntokens": "264195", "nsentences": "1745.73", "wps": "204607", "ups": "0.77", "wpb": "264195", "bsz": "1745.7", "num_updates": "260800", "lr": "0.00018913", "gnorm": "0.262", "loss_scale": "1", "train_wall": "253", "gb_free": "40.1", "wall": "492705"}
[2024-10-10 11:05:09,396][fairseq_cli.train][INFO] - end of epoch 545 (average epoch stats below)
[2024-10-10 11:05:09,409][train][INFO] - {"epoch": 545, "train_loss": "0.769", "train_ntokens": "263512", "train_nsentences": "1753.71", "train_wps": "136668", "train_ups": "0.52", "train_wpb": "263512", "train_bsz": "1753.7", "train_num_updates": "260951", "train_lr": "0.000188925", "train_gnorm": "0.26", "train_loss_scale": "1", "train_train_wall": "597", "train_gb_free": "39.3", "train_wall": "492902"}
[2024-10-10 11:05:09,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:05:09,555][fairseq.trainer][INFO] - begin training epoch 546
[2024-10-10 11:05:09,556][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:11:48,851][train_inner][INFO] - {"epoch": 546, "update": 545.102, "loss": "0.77", "ntokens": "262674", "nsentences": "1776.18", "wps": "88129.6", "ups": "0.34", "wpb": "262674", "bsz": "1776.2", "num_updates": "261000", "lr": "0.000188859", "gnorm": "0.274", "loss_scale": "1", "train_wall": "272", "gb_free": "40.3", "wall": "493301"}
[2024-10-10 11:15:21,257][train_inner][INFO] - {"epoch": 546, "update": 545.52, "loss": "0.768", "ntokens": "264354", "nsentences": "1740.21", "wps": "248936", "ups": "0.94", "wpb": "264354", "bsz": "1740.2", "num_updates": "261200", "lr": "0.000188587", "gnorm": "0.253", "loss_scale": "1", "train_wall": "206", "gb_free": "39.8", "wall": "493513"}
[2024-10-10 11:18:58,753][train_inner][INFO] - {"epoch": 546, "update": 545.937, "loss": "0.771", "ntokens": "264084", "nsentences": "1768.94", "wps": "242850", "ups": "0.92", "wpb": "264084", "bsz": "1768.9", "num_updates": "261400", "lr": "0.000188315", "gnorm": "0.277", "loss_scale": "1", "train_wall": "210", "gb_free": "39.7", "wall": "493731"}
[2024-10-10 11:19:36,280][fairseq_cli.train][INFO] - end of epoch 546 (average epoch stats below)
[2024-10-10 11:19:36,298][train][INFO] - {"epoch": 546, "train_loss": "0.77", "train_ntokens": "263729", "train_nsentences": "1753.71", "train_wps": "145727", "train_ups": "0.55", "train_wpb": "263729", "train_bsz": "1753.7", "train_num_updates": "261430", "train_lr": "0.000188274", "train_gnorm": "0.267", "train_loss_scale": "1", "train_train_wall": "532", "train_gb_free": "40", "train_wall": "493768"}
[2024-10-10 11:19:36,482][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:19:36,531][fairseq.trainer][INFO] - begin training epoch 547
[2024-10-10 11:19:36,531][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:28:25,552][train_inner][INFO] - {"epoch": 547, "update": 546.355, "loss": "0.77", "ntokens": "262150", "nsentences": "1822.97", "wps": "92504.2", "ups": "0.35", "wpb": "262150", "bsz": "1823", "num_updates": "261600", "lr": "0.000188043", "gnorm": "0.253", "loss_scale": "1", "train_wall": "220", "gb_free": "39.7", "wall": "494298"}
[2024-10-10 11:32:13,999][train_inner][INFO] - {"epoch": 547, "update": 546.772, "loss": "0.765", "ntokens": "264462", "nsentences": "1702.39", "wps": "231549", "ups": "0.88", "wpb": "264462", "bsz": "1702.4", "num_updates": "261800", "lr": "0.000187772", "gnorm": "0.266", "loss_scale": "2", "train_wall": "224", "gb_free": "39.8", "wall": "494526"}
[2024-10-10 11:34:23,784][fairseq_cli.train][INFO] - end of epoch 547 (average epoch stats below)
[2024-10-10 11:34:23,800][train][INFO] - {"epoch": 547, "train_loss": "0.768", "train_ntokens": "263477", "train_nsentences": "1753.71", "train_wps": "142205", "train_ups": "0.54", "train_wpb": "263477", "train_bsz": "1753.7", "train_num_updates": "261909", "train_lr": "0.000187624", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "40.3", "train_wall": "494656"}
[2024-10-10 11:34:23,932][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:34:23,964][fairseq.trainer][INFO] - begin training epoch 548
[2024-10-10 11:34:23,965][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:41:40,334][train_inner][INFO] - {"epoch": 548, "update": 547.19, "loss": "0.768", "ntokens": "262864", "nsentences": "1742.2", "wps": "92832.1", "ups": "0.35", "wpb": "262864", "bsz": "1742.2", "num_updates": "262000", "lr": "0.0001875", "gnorm": "0.258", "loss_scale": "2", "train_wall": "246", "gb_free": "40", "wall": "495093"}
[2024-10-10 11:45:54,346][train_inner][INFO] - {"epoch": 548, "update": 547.608, "loss": "0.77", "ntokens": "263504", "nsentences": "1794.51", "wps": "207490", "ups": "0.79", "wpb": "263504", "bsz": "1794.5", "num_updates": "262200", "lr": "0.000187228", "gnorm": "0.279", "loss_scale": "2", "train_wall": "249", "gb_free": "40.7", "wall": "495347"}
[2024-10-10 11:50:15,600][fairseq_cli.train][INFO] - end of epoch 548 (average epoch stats below)
[2024-10-10 11:50:15,618][train][INFO] - {"epoch": 548, "train_loss": "0.768", "train_ntokens": "263402", "train_nsentences": "1753.71", "train_wps": "132559", "train_ups": "0.5", "train_wpb": "263402", "train_bsz": "1753.7", "train_num_updates": "262388", "train_lr": "0.000186973", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "626", "train_gb_free": "39.7", "train_wall": "495608"}
[2024-10-10 11:50:15,711][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:50:15,768][fairseq.trainer][INFO] - begin training epoch 549
[2024-10-10 11:50:15,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:56:22,074][train_inner][INFO] - {"epoch": 549, "update": 548.025, "loss": "0.767", "ntokens": "263072", "nsentences": "1712.63", "wps": "83822.7", "ups": "0.32", "wpb": "263072", "bsz": "1712.6", "num_updates": "262400", "lr": "0.000186957", "gnorm": "0.274", "loss_scale": "2", "train_wall": "310", "gb_free": "39.3", "wall": "495974"}
[2024-10-10 12:00:01,622][train_inner][INFO] - {"epoch": 549, "update": 548.443, "loss": "0.766", "ntokens": "264111", "nsentences": "1736.64", "wps": "240611", "ups": "0.91", "wpb": "264111", "bsz": "1736.6", "num_updates": "262600", "lr": "0.000186685", "gnorm": "0.252", "loss_scale": "2", "train_wall": "214", "gb_free": "39.3", "wall": "496194"}
[2024-10-10 12:04:32,507][train_inner][INFO] - {"epoch": 549, "update": 548.86, "loss": "0.768", "ntokens": "263776", "nsentences": "1778.35", "wps": "194787", "ups": "0.74", "wpb": "263776", "bsz": "1778.4", "num_updates": "262800", "lr": "0.000186413", "gnorm": "0.272", "loss_scale": "2", "train_wall": "266", "gb_free": "39.2", "wall": "496465"}
[2024-10-10 12:06:11,562][fairseq_cli.train][INFO] - end of epoch 549 (average epoch stats below)
[2024-10-10 12:06:11,569][train][INFO] - {"epoch": 549, "train_loss": "0.768", "train_ntokens": "263482", "train_nsentences": "1753.71", "train_wps": "132025", "train_ups": "0.5", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "262867", "train_lr": "0.000186322", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "631", "train_gb_free": "39.7", "train_wall": "496564"}
[2024-10-10 12:06:11,646][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:06:11,679][fairseq.trainer][INFO] - begin training epoch 550
[2024-10-10 12:06:11,680][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:14:24,072][train_inner][INFO] - {"epoch": 550, "update": 549.278, "loss": "0.767", "ntokens": "263113", "nsentences": "1717.31", "wps": "88963.5", "ups": "0.34", "wpb": "263113", "bsz": "1717.3", "num_updates": "263000", "lr": "0.000186141", "gnorm": "0.265", "loss_scale": "2", "train_wall": "277", "gb_free": "39.6", "wall": "497056"}
[2024-10-10 12:18:30,738][train_inner][INFO] - {"epoch": 550, "update": 549.695, "loss": "0.767", "ntokens": "263719", "nsentences": "1792.93", "wps": "213846", "ups": "0.81", "wpb": "263719", "bsz": "1792.9", "num_updates": "263200", "lr": "0.00018587", "gnorm": "0.273", "loss_scale": "2", "train_wall": "241", "gb_free": "40.2", "wall": "497303"}
[2024-10-10 12:21:37,849][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 550 @ 263346 updates
[2024-10-10 12:21:37,854][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 12:21:46,288][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 12:21:46,503][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 550 @ 263346 updates, score None) (writing took 8.653545962646604 seconds)
[2024-10-10 12:21:46,530][fairseq_cli.train][INFO] - end of epoch 550 (average epoch stats below)
[2024-10-10 12:21:46,538][train][INFO] - {"epoch": 550, "train_loss": "0.768", "train_ntokens": "263473", "train_nsentences": "1753.71", "train_wps": "134984", "train_ups": "0.51", "train_wpb": "263473", "train_bsz": "1753.7", "train_num_updates": "263346", "train_lr": "0.000185671", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "603", "train_gb_free": "40", "train_wall": "497499"}
[2024-10-10 12:21:46,624][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:21:46,691][fairseq.trainer][INFO] - begin training epoch 551
[2024-10-10 12:21:46,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:28:24,753][train_inner][INFO] - {"epoch": 551, "update": 550.113, "loss": "0.77", "ntokens": "262511", "nsentences": "1755.42", "wps": "88387.1", "ups": "0.34", "wpb": "262511", "bsz": "1755.4", "num_updates": "263400", "lr": "0.000185598", "gnorm": "0.274", "loss_scale": "2", "train_wall": "254", "gb_free": "39.2", "wall": "497897"}
[2024-10-10 12:32:15,027][train_inner][INFO] - {"epoch": 551, "update": 550.53, "loss": "0.769", "ntokens": "264066", "nsentences": "1769.61", "wps": "229364", "ups": "0.87", "wpb": "264066", "bsz": "1769.6", "num_updates": "263600", "lr": "0.000185326", "gnorm": "0.269", "loss_scale": "2", "train_wall": "224", "gb_free": "40", "wall": "498127"}
[2024-10-10 12:36:13,198][train_inner][INFO] - {"epoch": 551, "update": 550.948, "loss": "0.768", "ntokens": "263984", "nsentences": "1732.04", "wps": "221710", "ups": "0.84", "wpb": "263984", "bsz": "1732", "num_updates": "263800", "lr": "0.000185054", "gnorm": "0.261", "loss_scale": "4", "train_wall": "233", "gb_free": "39.2", "wall": "498365"}
[2024-10-10 12:36:56,983][fairseq_cli.train][INFO] - end of epoch 551 (average epoch stats below)
[2024-10-10 12:36:57,118][train][INFO] - {"epoch": 551, "train_loss": "0.769", "train_ntokens": "263452", "train_nsentences": "1753.71", "train_wps": "138607", "train_ups": "0.53", "train_wpb": "263452", "train_bsz": "1753.7", "train_num_updates": "263825", "train_lr": "0.00018502", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "571", "train_gb_free": "39.6", "train_wall": "498409"}
[2024-10-10 12:36:57,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:36:57,280][fairseq.trainer][INFO] - begin training epoch 552
[2024-10-10 12:36:57,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:42:42,103][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 12:46:01,060][train_inner][INFO] - {"epoch": 552, "update": 551.367, "loss": "0.767", "ntokens": "262773", "nsentences": "1759.1", "wps": "89401.2", "ups": "0.34", "wpb": "262773", "bsz": "1759.1", "num_updates": "264000", "lr": "0.000184783", "gnorm": "0.281", "loss_scale": "2", "train_wall": "264", "gb_free": "40.3", "wall": "498953"}
[2024-10-10 12:49:46,662][train_inner][INFO] - {"epoch": 552, "update": 551.785, "loss": "0.768", "ntokens": "264235", "nsentences": "1734.46", "wps": "234288", "ups": "0.89", "wpb": "264235", "bsz": "1734.5", "num_updates": "264200", "lr": "0.000184511", "gnorm": "0.274", "loss_scale": "2", "train_wall": "220", "gb_free": "39.8", "wall": "499179"}
[2024-10-10 12:51:55,994][fairseq_cli.train][INFO] - end of epoch 552 (average epoch stats below)
[2024-10-10 12:51:56,003][train][INFO] - {"epoch": 552, "train_loss": "0.768", "train_ntokens": "263522", "train_nsentences": "1753.32", "train_wps": "140138", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.3", "train_num_updates": "264303", "train_lr": "0.000184371", "train_gnorm": "0.277", "train_loss_scale": "2", "train_train_wall": "567", "train_gb_free": "39.6", "train_wall": "499308"}
[2024-10-10 12:51:56,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:51:56,987][fairseq.trainer][INFO] - begin training epoch 553
[2024-10-10 12:51:56,988][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:59:04,733][train_inner][INFO] - {"epoch": 553, "update": 552.203, "loss": "0.767", "ntokens": "263038", "nsentences": "1737.41", "wps": "94270.2", "ups": "0.36", "wpb": "263038", "bsz": "1737.4", "num_updates": "264400", "lr": "0.000184239", "gnorm": "0.279", "loss_scale": "2", "train_wall": "232", "gb_free": "39.8", "wall": "499737"}
[2024-10-10 13:03:19,785][train_inner][INFO] - {"epoch": 553, "update": 552.62, "loss": "0.769", "ntokens": "263969", "nsentences": "1754.8", "wps": "207000", "ups": "0.78", "wpb": "263969", "bsz": "1754.8", "num_updates": "264600", "lr": "0.000183967", "gnorm": "0.277", "loss_scale": "2", "train_wall": "250", "gb_free": "40.3", "wall": "499992"}
[2024-10-10 13:07:07,204][fairseq_cli.train][INFO] - end of epoch 553 (average epoch stats below)
[2024-10-10 13:07:07,239][train][INFO] - {"epoch": 553, "train_loss": "0.768", "train_ntokens": "263532", "train_nsentences": "1753.71", "train_wps": "138531", "train_ups": "0.53", "train_wpb": "263532", "train_bsz": "1753.7", "train_num_updates": "264782", "train_lr": "0.00018372", "train_gnorm": "0.278", "train_loss_scale": "2", "train_train_wall": "578", "train_gb_free": "40.1", "train_wall": "500219"}
[2024-10-10 13:07:07,428][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:07:07,438][fairseq.trainer][INFO] - begin training epoch 554
[2024-10-10 13:07:07,439][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:13:15,717][train_inner][INFO] - {"epoch": 554, "update": 553.038, "loss": "0.769", "ntokens": "262725", "nsentences": "1757.42", "wps": "88176.9", "ups": "0.34", "wpb": "262724", "bsz": "1757.4", "num_updates": "264800", "lr": "0.000183696", "gnorm": "0.278", "loss_scale": "2", "train_wall": "267", "gb_free": "39.3", "wall": "500588"}
[2024-10-10 13:17:07,905][train_inner][INFO] - {"epoch": 554, "update": 553.455, "loss": "0.766", "ntokens": "263684", "nsentences": "1776.57", "wps": "227154", "ups": "0.86", "wpb": "263684", "bsz": "1776.6", "num_updates": "265000", "lr": "0.000183424", "gnorm": "0.275", "loss_scale": "2", "train_wall": "227", "gb_free": "39.7", "wall": "500820"}
[2024-10-10 13:21:04,385][train_inner][INFO] - {"epoch": 554, "update": 553.873, "loss": "0.767", "ntokens": "264115", "nsentences": "1732.73", "wps": "223384", "ups": "0.85", "wpb": "264116", "bsz": "1732.7", "num_updates": "265200", "lr": "0.000183152", "gnorm": "0.255", "loss_scale": "2", "train_wall": "231", "gb_free": "39.8", "wall": "501057"}
[2024-10-10 13:22:22,693][fairseq_cli.train][INFO] - end of epoch 554 (average epoch stats below)
[2024-10-10 13:22:22,703][train][INFO] - {"epoch": 554, "train_loss": "0.768", "train_ntokens": "263350", "train_nsentences": "1753.71", "train_wps": "137798", "train_ups": "0.52", "train_wpb": "263350", "train_bsz": "1753.7", "train_num_updates": "265261", "train_lr": "0.000183069", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "580", "train_gb_free": "40.2", "train_wall": "501135"}
[2024-10-10 13:22:23,942][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:22:24,247][fairseq.trainer][INFO] - begin training epoch 555
[2024-10-10 13:22:24,247][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:30:44,734][train_inner][INFO] - {"epoch": 555, "update": 554.29, "loss": "0.77", "ntokens": "262361", "nsentences": "1780.89", "wps": "90417", "ups": "0.34", "wpb": "262361", "bsz": "1780.9", "num_updates": "265400", "lr": "0.00018288", "gnorm": "0.267", "loss_scale": "2", "train_wall": "245", "gb_free": "39.6", "wall": "501637"}
[2024-10-10 13:34:34,921][train_inner][INFO] - {"epoch": 555, "update": 554.708, "loss": "0.766", "ntokens": "264342", "nsentences": "1736.9", "wps": "229684", "ups": "0.87", "wpb": "264342", "bsz": "1736.9", "num_updates": "265600", "lr": "0.000182609", "gnorm": "0.264", "loss_scale": "2", "train_wall": "224", "gb_free": "40.1", "wall": "501867"}
[2024-10-10 13:37:41,979][fairseq_cli.train][INFO] - end of epoch 555 (average epoch stats below)
[2024-10-10 13:37:42,012][train][INFO] - {"epoch": 555, "train_loss": "0.768", "train_ntokens": "263641", "train_nsentences": "1753.71", "train_wps": "137374", "train_ups": "0.52", "train_wpb": "263641", "train_bsz": "1753.7", "train_num_updates": "265740", "train_lr": "0.000182418", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "502054"}
[2024-10-10 13:37:42,132][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:37:42,170][fairseq.trainer][INFO] - begin training epoch 556
[2024-10-10 13:37:42,170][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:44:24,058][train_inner][INFO] - {"epoch": 556, "update": 555.125, "loss": "0.769", "ntokens": "262996", "nsentences": "1759.32", "wps": "89287", "ups": "0.34", "wpb": "262996", "bsz": "1759.3", "num_updates": "265800", "lr": "0.000182337", "gnorm": "0.268", "loss_scale": "2", "train_wall": "254", "gb_free": "39.6", "wall": "502456"}
[2024-10-10 13:48:04,215][train_inner][INFO] - {"epoch": 556, "update": 555.543, "loss": "0.766", "ntokens": "264046", "nsentences": "1742.95", "wps": "239901", "ups": "0.91", "wpb": "264046", "bsz": "1743", "num_updates": "266000", "lr": "0.000182065", "gnorm": "0.256", "loss_scale": "4", "train_wall": "214", "gb_free": "39.6", "wall": "502676"}
[2024-10-10 13:51:47,882][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 13:52:00,709][train_inner][INFO] - {"epoch": 556, "update": 555.962, "loss": "0.77", "ntokens": "263799", "nsentences": "1770.1", "wps": "223100", "ups": "0.85", "wpb": "263799", "bsz": "1770.1", "num_updates": "266200", "lr": "0.000181793", "gnorm": "0.267", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "502913"}
[2024-10-10 13:52:49,050][fairseq_cli.train][INFO] - end of epoch 556 (average epoch stats below)
[2024-10-10 13:52:49,061][train][INFO] - {"epoch": 556, "train_loss": "0.767", "train_ntokens": "263439", "train_nsentences": "1754.94", "train_wps": "138830", "train_ups": "0.53", "train_wpb": "263439", "train_bsz": "1754.9", "train_num_updates": "266218", "train_lr": "0.000181769", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "39.6", "train_wall": "502961"}
[2024-10-10 13:52:49,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:52:49,169][fairseq.trainer][INFO] - begin training epoch 557
[2024-10-10 13:52:49,170][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:02:04,089][train_inner][INFO] - {"epoch": 557, "update": 556.38, "loss": "0.763", "ntokens": "262869", "nsentences": "1730.64", "wps": "87134.2", "ups": "0.33", "wpb": "262869", "bsz": "1730.6", "num_updates": "266400", "lr": "0.000181522", "gnorm": "0.27", "loss_scale": "2", "train_wall": "254", "gb_free": "39.8", "wall": "503516"}
[2024-10-10 14:06:16,918][train_inner][INFO] - {"epoch": 557, "update": 556.797, "loss": "0.769", "ntokens": "263950", "nsentences": "1775.17", "wps": "208828", "ups": "0.79", "wpb": "263950", "bsz": "1775.2", "num_updates": "266600", "lr": "0.00018125", "gnorm": "0.254", "loss_scale": "2", "train_wall": "248", "gb_free": "39.2", "wall": "503769"}
[2024-10-10 14:08:31,142][fairseq_cli.train][INFO] - end of epoch 557 (average epoch stats below)
[2024-10-10 14:08:31,147][train][INFO] - {"epoch": 557, "train_loss": "0.767", "train_ntokens": "263504", "train_nsentences": "1753.71", "train_wps": "133978", "train_ups": "0.51", "train_wpb": "263504", "train_bsz": "1753.7", "train_num_updates": "266697", "train_lr": "0.000181118", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "587", "train_gb_free": "39.7", "train_wall": "503903"}
[2024-10-10 14:08:31,239][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:08:31,272][fairseq.trainer][INFO] - begin training epoch 558
[2024-10-10 14:08:31,273][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:15:55,452][train_inner][INFO] - {"epoch": 558, "update": 557.215, "loss": "0.766", "ntokens": "262887", "nsentences": "1744.91", "wps": "90882.6", "ups": "0.35", "wpb": "262887", "bsz": "1744.9", "num_updates": "266800", "lr": "0.000180978", "gnorm": "0.277", "loss_scale": "2", "train_wall": "261", "gb_free": "39.8", "wall": "504348"}
[2024-10-10 14:19:37,464][train_inner][INFO] - {"epoch": 558, "update": 557.633, "loss": "0.768", "ntokens": "264012", "nsentences": "1757.56", "wps": "237844", "ups": "0.9", "wpb": "264012", "bsz": "1757.6", "num_updates": "267000", "lr": "0.000180707", "gnorm": "0.259", "loss_scale": "2", "train_wall": "216", "gb_free": "39.6", "wall": "504570"}
[2024-10-10 14:23:08,165][fairseq_cli.train][INFO] - end of epoch 558 (average epoch stats below)
[2024-10-10 14:23:08,195][train][INFO] - {"epoch": 558, "train_loss": "0.767", "train_ntokens": "263570", "train_nsentences": "1753.71", "train_wps": "143953", "train_ups": "0.55", "train_wpb": "263570", "train_bsz": "1753.7", "train_num_updates": "267176", "train_lr": "0.000180467", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "40", "train_wall": "504780"}
[2024-10-10 14:23:08,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:23:08,390][fairseq.trainer][INFO] - begin training epoch 559
[2024-10-10 14:23:08,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:29:20,652][train_inner][INFO] - {"epoch": 559, "update": 558.05, "loss": "0.768", "ntokens": "262853", "nsentences": "1756.13", "wps": "90146.9", "ups": "0.34", "wpb": "262853", "bsz": "1756.1", "num_updates": "267200", "lr": "0.000180435", "gnorm": "0.261", "loss_scale": "2", "train_wall": "241", "gb_free": "39.8", "wall": "505153"}
[2024-10-10 14:32:54,268][train_inner][INFO] - {"epoch": 559, "update": 558.468, "loss": "0.761", "ntokens": "264375", "nsentences": "1717.62", "wps": "247535", "ups": "0.94", "wpb": "264375", "bsz": "1717.6", "num_updates": "267400", "lr": "0.000180163", "gnorm": "0.252", "loss_scale": "2", "train_wall": "208", "gb_free": "39.1", "wall": "505366"}
[2024-10-10 14:34:28,604][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-10 14:36:58,863][train_inner][INFO] - {"epoch": 559, "update": 558.887, "loss": "0.771", "ntokens": "264002", "nsentences": "1766.98", "wps": "215878", "ups": "0.82", "wpb": "264002", "bsz": "1767", "num_updates": "267600", "lr": "0.000179891", "gnorm": "0.248", "loss_scale": "1", "train_wall": "237", "gb_free": "40", "wall": "505611"}
[2024-10-10 14:37:58,084][fairseq_cli.train][INFO] - end of epoch 559 (average epoch stats below)
[2024-10-10 14:37:58,394][train][INFO] - {"epoch": 559, "train_loss": "0.767", "train_ntokens": "263588", "train_nsentences": "1751.07", "train_wps": "141586", "train_ups": "0.54", "train_wpb": "263588", "train_bsz": "1751.1", "train_num_updates": "267654", "train_lr": "0.000179818", "train_gnorm": "0.252", "train_loss_scale": "1", "train_train_wall": "537", "train_gb_free": "39.8", "train_wall": "505670"}
[2024-10-10 14:37:58,560][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:37:58,625][fairseq.trainer][INFO] - begin training epoch 560
[2024-10-10 14:37:58,625][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:46:04,349][train_inner][INFO] - {"epoch": 560, "update": 559.305, "loss": "0.77", "ntokens": "262707", "nsentences": "1766.13", "wps": "96325.5", "ups": "0.37", "wpb": "262707", "bsz": "1766.1", "num_updates": "267800", "lr": "0.00017962", "gnorm": "0.268", "loss_scale": "1", "train_wall": "164", "gb_free": "39.8", "wall": "506157"}
[2024-10-10 14:50:08,692][train_inner][INFO] - {"epoch": 560, "update": 559.722, "loss": "0.768", "ntokens": "263579", "nsentences": "1807.89", "wps": "215758", "ups": "0.82", "wpb": "263579", "bsz": "1807.9", "num_updates": "268000", "lr": "0.000179348", "gnorm": "0.275", "loss_scale": "1", "train_wall": "154", "gb_free": "39.8", "wall": "506401"}
[2024-10-10 14:52:43,624][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 560 @ 268133 updates
[2024-10-10 14:52:43,626][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 14:52:54,201][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 14:52:54,298][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 560 @ 268133 updates, score None) (writing took 10.673545324243605 seconds)
[2024-10-10 14:52:54,298][fairseq_cli.train][INFO] - end of epoch 560 (average epoch stats below)
[2024-10-10 14:52:54,301][train][INFO] - {"epoch": 560, "train_loss": "0.767", "train_ntokens": "263559", "train_nsentences": "1753.71", "train_wps": "140917", "train_ups": "0.53", "train_wpb": "263559", "train_bsz": "1753.7", "train_num_updates": "268133", "train_lr": "0.000179167", "train_gnorm": "0.272", "train_loss_scale": "1", "train_train_wall": "367", "train_gb_free": "39.6", "train_wall": "506566"}
[2024-10-10 14:52:54,376][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:52:54,412][fairseq.trainer][INFO] - begin training epoch 561
[2024-10-10 14:52:54,413][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:59:42,182][train_inner][INFO] - {"epoch": 561, "update": 560.14, "loss": "0.763", "ntokens": "263380", "nsentences": "1681.42", "wps": "91859.7", "ups": "0.35", "wpb": "263380", "bsz": "1681.4", "num_updates": "268200", "lr": "0.000179076", "gnorm": "0.259", "loss_scale": "1", "train_wall": "175", "gb_free": "39.4", "wall": "506974"}
[2024-10-10 15:02:51,212][train_inner][INFO] - {"epoch": 561, "update": 560.557, "loss": "0.766", "ntokens": "264058", "nsentences": "1747.26", "wps": "279434", "ups": "1.06", "wpb": "264058", "bsz": "1747.3", "num_updates": "268400", "lr": "0.000178804", "gnorm": "0.271", "loss_scale": "1", "train_wall": "184", "gb_free": "39.2", "wall": "507163"}
[2024-10-10 15:06:38,412][train_inner][INFO] - {"epoch": 561, "update": 560.975, "loss": "0.769", "ntokens": "263946", "nsentences": "1782.6", "wps": "232357", "ups": "0.88", "wpb": "263946", "bsz": "1782.6", "num_updates": "268600", "lr": "0.000178533", "gnorm": "0.277", "loss_scale": "1", "train_wall": "215", "gb_free": "39.6", "wall": "507391"}
[2024-10-10 15:07:17,425][fairseq_cli.train][INFO] - end of epoch 561 (average epoch stats below)
[2024-10-10 15:07:17,442][train][INFO] - {"epoch": 561, "train_loss": "0.767", "train_ntokens": "263543", "train_nsentences": "1753.71", "train_wps": "146259", "train_ups": "0.55", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "268612", "train_lr": "0.000178516", "train_gnorm": "0.269", "train_loss_scale": "1", "train_train_wall": "489", "train_gb_free": "39.6", "train_wall": "507430"}
[2024-10-10 15:07:17,601][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:07:17,613][fairseq.trainer][INFO] - begin training epoch 562
[2024-10-10 15:07:17,614][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:16:17,700][train_inner][INFO] - {"epoch": 562, "update": 561.392, "loss": "0.766", "ntokens": "262780", "nsentences": "1748.39", "wps": "90727.2", "ups": "0.35", "wpb": "262780", "bsz": "1748.4", "num_updates": "268800", "lr": "0.000178261", "gnorm": "0.269", "loss_scale": "1", "train_wall": "239", "gb_free": "39.6", "wall": "507970"}
[2024-10-10 15:20:18,927][train_inner][INFO] - {"epoch": 562, "update": 561.81, "loss": "0.765", "ntokens": "264091", "nsentences": "1741.04", "wps": "218982", "ups": "0.83", "wpb": "264091", "bsz": "1741", "num_updates": "269000", "lr": "0.000177989", "gnorm": "0.268", "loss_scale": "1", "train_wall": "236", "gb_free": "39.2", "wall": "508211"}
[2024-10-10 15:22:15,284][fairseq_cli.train][INFO] - end of epoch 562 (average epoch stats below)
[2024-10-10 15:22:15,299][train][INFO] - {"epoch": 562, "train_loss": "0.766", "train_ntokens": "263467", "train_nsentences": "1753.71", "train_wps": "140564", "train_ups": "0.53", "train_wpb": "263467", "train_bsz": "1753.7", "train_num_updates": "269091", "train_lr": "0.000177865", "train_gnorm": "0.268", "train_loss_scale": "1", "train_train_wall": "567", "train_gb_free": "40.2", "train_wall": "508327"}
[2024-10-10 15:22:15,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:22:15,380][fairseq.trainer][INFO] - begin training epoch 563
[2024-10-10 15:22:15,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:30:06,775][train_inner][INFO] - {"epoch": 563, "update": 562.228, "loss": "0.768", "ntokens": "262380", "nsentences": "1801.81", "wps": "89274.4", "ups": "0.34", "wpb": "262380", "bsz": "1801.8", "num_updates": "269200", "lr": "0.000177717", "gnorm": "0.263", "loss_scale": "1", "train_wall": "268", "gb_free": "39.6", "wall": "508799"}
[2024-10-10 15:34:08,775][train_inner][INFO] - {"epoch": 563, "update": 562.645, "loss": "0.763", "ntokens": "264147", "nsentences": "1740.87", "wps": "218324", "ups": "0.83", "wpb": "264147", "bsz": "1740.9", "num_updates": "269400", "lr": "0.000177446", "gnorm": "0.272", "loss_scale": "1", "train_wall": "237", "gb_free": "39.2", "wall": "509041"}
[2024-10-10 15:37:30,728][fairseq_cli.train][INFO] - end of epoch 563 (average epoch stats below)
[2024-10-10 15:37:30,732][train][INFO] - {"epoch": 563, "train_loss": "0.766", "train_ntokens": "263442", "train_nsentences": "1753.71", "train_wps": "137847", "train_ups": "0.52", "train_wpb": "263442", "train_bsz": "1753.7", "train_num_updates": "269570", "train_lr": "0.000177215", "train_gnorm": "0.272", "train_loss_scale": "2", "train_train_wall": "589", "train_gb_free": "39.8", "train_wall": "509243"}
[2024-10-10 15:37:30,845][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:37:30,855][fairseq.trainer][INFO] - begin training epoch 564
[2024-10-10 15:37:30,856][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:43:52,103][train_inner][INFO] - {"epoch": 564, "update": 563.063, "loss": "0.768", "ntokens": "262857", "nsentences": "1731.57", "wps": "90129.7", "ups": "0.34", "wpb": "262857", "bsz": "1731.6", "num_updates": "269600", "lr": "0.000177174", "gnorm": "0.28", "loss_scale": "2", "train_wall": "257", "gb_free": "39.3", "wall": "509624"}
[2024-10-10 15:47:27,126][train_inner][INFO] - {"epoch": 564, "update": 563.48, "loss": "0.764", "ntokens": "263803", "nsentences": "1781", "wps": "245412", "ups": "0.93", "wpb": "263803", "bsz": "1781", "num_updates": "269800", "lr": "0.000176902", "gnorm": "0.269", "loss_scale": "2", "train_wall": "209", "gb_free": "40", "wall": "509839"}
[2024-10-10 15:51:32,024][train_inner][INFO] - {"epoch": 564, "update": 563.898, "loss": "0.766", "ntokens": "264332", "nsentences": "1734.57", "wps": "215916", "ups": "0.82", "wpb": "264332", "bsz": "1734.6", "num_updates": "270000", "lr": "0.00017663", "gnorm": "0.266", "loss_scale": "2", "train_wall": "240", "gb_free": "39.7", "wall": "510084"}
[2024-10-10 15:52:36,816][fairseq_cli.train][INFO] - end of epoch 564 (average epoch stats below)
[2024-10-10 15:52:36,827][train][INFO] - {"epoch": 564, "train_loss": "0.765", "train_ntokens": "263547", "train_nsentences": "1753.71", "train_wps": "139324", "train_ups": "0.53", "train_wpb": "263547", "train_bsz": "1753.7", "train_num_updates": "270049", "train_lr": "0.000176564", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "572", "train_gb_free": "39.6", "train_wall": "510149"}
[2024-10-10 15:52:36,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:52:36,983][fairseq.trainer][INFO] - begin training epoch 565
[2024-10-10 15:52:36,983][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:01:17,340][train_inner][INFO] - {"epoch": 565, "update": 564.315, "loss": "0.763", "ntokens": "262806", "nsentences": "1742.78", "wps": "89804.5", "ups": "0.34", "wpb": "262806", "bsz": "1742.8", "num_updates": "270200", "lr": "0.000176359", "gnorm": "0.266", "loss_scale": "2", "train_wall": "232", "gb_free": "39.3", "wall": "510669"}
[2024-10-10 16:05:08,711][train_inner][INFO] - {"epoch": 565, "update": 564.733, "loss": "0.769", "ntokens": "263747", "nsentences": "1787.22", "wps": "228014", "ups": "0.86", "wpb": "263747", "bsz": "1787.2", "num_updates": "270400", "lr": "0.000176087", "gnorm": "0.264", "loss_scale": "2", "train_wall": "226", "gb_free": "39.6", "wall": "510901"}
[2024-10-10 16:07:34,940][fairseq_cli.train][INFO] - end of epoch 565 (average epoch stats below)
[2024-10-10 16:07:34,953][train][INFO] - {"epoch": 565, "train_loss": "0.765", "train_ntokens": "263557", "train_nsentences": "1753.71", "train_wps": "140566", "train_ups": "0.53", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "270528", "train_lr": "0.000175913", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "538", "train_gb_free": "40.3", "train_wall": "511047"}
[2024-10-10 16:07:35,109][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 16:07:35,152][fairseq.trainer][INFO] - begin training epoch 566
[2024-10-10 16:07:35,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:14:58,038][train_inner][INFO] - {"epoch": 566, "update": 565.15, "loss": "0.764", "ntokens": "262988", "nsentences": "1725.68", "wps": "89251.7", "ups": "0.34", "wpb": "262988", "bsz": "1725.7", "num_updates": "270600", "lr": "0.000175815", "gnorm": "0.28", "loss_scale": "2", "train_wall": "241", "gb_free": "39.6", "wall": "511490"}
[2024-10-10 16:18:43,761][train_inner][INFO] - {"epoch": 566, "update": 565.568, "loss": "0.763", "ntokens": "264299", "nsentences": "1724.95", "wps": "234193", "ups": "0.89", "wpb": "264299", "bsz": "1725", "num_updates": "270800", "lr": "0.000175543", "gnorm": "0.261", "loss_scale": "2", "train_wall": "216", "gb_free": "39.3", "wall": "511716"}
[2024-10-10 16:22:28,372][train_inner][INFO] - {"epoch": 566, "update": 565.985, "loss": "0.767", "ntokens": "263577", "nsentences": "1789.59", "wps": "234747", "ups": "0.89", "wpb": "263577", "bsz": "1789.6", "num_updates": "271000", "lr": "0.000175272", "gnorm": "0.281", "loss_scale": "2", "train_wall": "219", "gb_free": "39.7", "wall": "511941"}
[2024-10-10 16:22:41,679][fairseq_cli.train][INFO] - end of epoch 566 (average epoch stats below)
[2024-10-10 16:22:41,729][train][INFO] - {"epoch": 566, "train_loss": "0.765", "train_ntokens": "263401", "train_nsentences": "1753.71", "train_wps": "139149", "train_ups": "0.53", "train_wpb": "263401", "train_bsz": "1753.7", "train_num_updates": "271007", "train_lr": "0.000175262", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "39.6", "train_wall": "511954"}
[2024-10-10 16:22:42,064][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 16:22:42,104][fairseq.trainer][INFO] - begin training epoch 567
[2024-10-10 16:22:42,105][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:32:16,493][train_inner][INFO] - {"epoch": 567, "update": 566.403, "loss": "0.765", "ntokens": "262625", "nsentences": "1781.88", "wps": "89325.4", "ups": "0.34", "wpb": "262625", "bsz": "1781.9", "num_updates": "271200", "lr": "0.000175", "gnorm": "0.262", "loss_scale": "2", "train_wall": "227", "gb_free": "39.8", "wall": "512529"}
[2024-10-10 16:36:00,498][train_inner][INFO] - {"epoch": 567, "update": 566.82, "loss": "0.764", "ntokens": "264335", "nsentences": "1723.39", "wps": "236027", "ups": "0.89", "wpb": "264335", "bsz": "1723.4", "num_updates": "271400", "lr": "0.000174728", "gnorm": "0.258", "loss_scale": "2", "train_wall": "218", "gb_free": "39.6", "wall": "512753"}
[2024-10-10 16:37:27,697][fairseq_cli.train][INFO] - end of epoch 567 (average epoch stats below)
[2024-10-10 16:37:27,730][train][INFO] - {"epoch": 567, "train_loss": "0.765", "train_ntokens": "263545", "train_nsentences": "1753.71", "train_wps": "142490", "train_ups": "0.54", "train_wpb": "263545", "train_bsz": "1753.7", "train_num_updates": "271486", "train_lr": "0.000174611", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "517", "train_gb_free": "40.1", "train_wall": "512840"}
[2024-10-10 16:37:28,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 16:37:28,079][fairseq.trainer][INFO] - begin training epoch 568
[2024-10-10 16:37:28,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:45:25,408][train_inner][INFO] - {"epoch": 568, "update": 567.238, "loss": "0.766", "ntokens": "262544", "nsentences": "1780.24", "wps": "92952.9", "ups": "0.35", "wpb": "262544", "bsz": "1780.2", "num_updates": "271600", "lr": "0.000174457", "gnorm": "0.28", "loss_scale": "4", "train_wall": "224", "gb_free": "39.2", "wall": "513318"}
[2024-10-10 16:45:45,553][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 16:49:10,924][train_inner][INFO] - {"epoch": 568, "update": 567.658, "loss": "0.764", "ntokens": "264175", "nsentences": "1731.4", "wps": "234311", "ups": "0.89", "wpb": "264175", "bsz": "1731.4", "num_updates": "271800", "lr": "0.000174185", "gnorm": "0.262", "loss_scale": "2", "train_wall": "220", "gb_free": "39.7", "wall": "513543"}
[2024-10-10 16:52:32,474][fairseq_cli.train][INFO] - end of epoch 568 (average epoch stats below)
[2024-10-10 16:52:32,484][train][INFO] - {"epoch": 568, "train_loss": "0.765", "train_ntokens": "263528", "train_nsentences": "1754.32", "train_wps": "139229", "train_ups": "0.53", "train_wpb": "263528", "train_bsz": "1754.3", "train_num_updates": "271964", "train_lr": "0.000173962", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.3", "train_wall": "513745"}
[2024-10-10 16:52:32,578][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 16:52:32,613][fairseq.trainer][INFO] - begin training epoch 569
[2024-10-10 16:52:32,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:58:55,252][train_inner][INFO] - {"epoch": 569, "update": 568.075, "loss": "0.766", "ntokens": "263049", "nsentences": "1736.85", "wps": "90041.4", "ups": "0.34", "wpb": "263049", "bsz": "1736.9", "num_updates": "272000", "lr": "0.000173913", "gnorm": "0.268", "loss_scale": "2", "train_wall": "253", "gb_free": "39.7", "wall": "514127"}
[2024-10-10 17:02:14,234][train_inner][INFO] - {"epoch": 569, "update": 568.493, "loss": "0.764", "ntokens": "264403", "nsentences": "1711.61", "wps": "265791", "ups": "1.01", "wpb": "264403", "bsz": "1711.6", "num_updates": "272200", "lr": "0.000173641", "gnorm": "0.277", "loss_scale": "2", "train_wall": "194", "gb_free": "39.8", "wall": "514326"}
[2024-10-10 17:06:22,401][train_inner][INFO] - {"epoch": 569, "update": 568.91, "loss": "0.768", "ntokens": "263665", "nsentences": "1806.06", "wps": "212497", "ups": "0.81", "wpb": "263665", "bsz": "1806.1", "num_updates": "272400", "lr": "0.00017337", "gnorm": "0.266", "loss_scale": "2", "train_wall": "223", "gb_free": "40.1", "wall": "514575"}
[2024-10-10 17:07:24,519][fairseq_cli.train][INFO] - end of epoch 569 (average epoch stats below)
[2024-10-10 17:07:24,522][train][INFO] - {"epoch": 569, "train_loss": "0.765", "train_ntokens": "263569", "train_nsentences": "1753.71", "train_wps": "141531", "train_ups": "0.54", "train_wpb": "263569", "train_bsz": "1753.7", "train_num_updates": "272443", "train_lr": "0.000173311", "train_gnorm": "0.273", "train_loss_scale": "2", "train_train_wall": "528", "train_gb_free": "39.3", "train_wall": "514637"}
[2024-10-10 17:07:24,559][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:07:24,593][fairseq.trainer][INFO] - begin training epoch 570
[2024-10-10 17:07:24,594][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:15:33,456][train_inner][INFO] - {"epoch": 570, "update": 569.328, "loss": "0.766", "ntokens": "263007", "nsentences": "1754.19", "wps": "95459.4", "ups": "0.36", "wpb": "263007", "bsz": "1754.2", "num_updates": "272600", "lr": "0.000173098", "gnorm": "0.275", "loss_scale": "2", "train_wall": "225", "gb_free": "39.3", "wall": "515126"}
[2024-10-10 17:19:27,355][train_inner][INFO] - {"epoch": 570, "update": 569.745, "loss": "0.765", "ntokens": "263805", "nsentences": "1765.94", "wps": "225594", "ups": "0.86", "wpb": "263805", "bsz": "1765.9", "num_updates": "272800", "lr": "0.000172826", "gnorm": "0.267", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "515360"}
[2024-10-10 17:21:40,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 570 @ 272922 updates
[2024-10-10 17:21:40,990][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 17:21:54,257][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 17:21:54,584][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 570 @ 272922 updates, score None) (writing took 13.608327992260456 seconds)
[2024-10-10 17:21:54,585][fairseq_cli.train][INFO] - end of epoch 570 (average epoch stats below)
[2024-10-10 17:21:54,628][train][INFO] - {"epoch": 570, "train_loss": "0.765", "train_ntokens": "263582", "train_nsentences": "1753.71", "train_wps": "145112", "train_ups": "0.55", "train_wpb": "263582", "train_bsz": "1753.7", "train_num_updates": "272922", "train_lr": "0.00017266", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "527", "train_gb_free": "39.1", "train_wall": "515507"}
[2024-10-10 17:21:54,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:21:54,757][fairseq.trainer][INFO] - begin training epoch 571
[2024-10-10 17:21:54,758][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:29:12,692][train_inner][INFO] - {"epoch": 571, "update": 570.163, "loss": "0.765", "ntokens": "262817", "nsentences": "1760.96", "wps": "89804.3", "ups": "0.34", "wpb": "262817", "bsz": "1761", "num_updates": "273000", "lr": "0.000172554", "gnorm": "0.257", "loss_scale": "2", "train_wall": "235", "gb_free": "39.3", "wall": "515945"}
[2024-10-10 17:32:57,363][train_inner][INFO] - {"epoch": 571, "update": 570.58, "loss": "0.765", "ntokens": "264044", "nsentences": "1746.34", "wps": "235125", "ups": "0.89", "wpb": "264044", "bsz": "1746.3", "num_updates": "273200", "lr": "0.000172283", "gnorm": "0.258", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "516170"}
[2024-10-10 17:37:03,035][train_inner][INFO] - {"epoch": 571, "update": 570.998, "loss": "0.765", "ntokens": "263880", "nsentences": "1748.42", "wps": "214854", "ups": "0.81", "wpb": "263880", "bsz": "1748.4", "num_updates": "273400", "lr": "0.000172011", "gnorm": "0.255", "loss_scale": "2", "train_wall": "238", "gb_free": "39.6", "wall": "516415"}
[2024-10-10 17:37:03,858][fairseq_cli.train][INFO] - end of epoch 571 (average epoch stats below)
[2024-10-10 17:37:03,874][train][INFO] - {"epoch": 571, "train_loss": "0.765", "train_ntokens": "263421", "train_nsentences": "1753.71", "train_wps": "138775", "train_ups": "0.53", "train_wpb": "263421", "train_bsz": "1753.7", "train_num_updates": "273401", "train_lr": "0.00017201", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "39.6", "train_wall": "516416"}
[2024-10-10 17:37:04,056][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:37:04,083][fairseq.trainer][INFO] - begin training epoch 572
[2024-10-10 17:37:04,084][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:46:23,792][train_inner][INFO] - {"epoch": 572, "update": 571.415, "loss": "0.763", "ntokens": "262759", "nsentences": "1751.44", "wps": "93725.9", "ups": "0.36", "wpb": "262759", "bsz": "1751.4", "num_updates": "273600", "lr": "0.000171739", "gnorm": "0.274", "loss_scale": "2", "train_wall": "222", "gb_free": "40", "wall": "516976"}
[2024-10-10 17:50:14,605][train_inner][INFO] - {"epoch": 572, "update": 571.833, "loss": "0.765", "ntokens": "264252", "nsentences": "1729.77", "wps": "229006", "ups": "0.87", "wpb": "264252", "bsz": "1729.8", "num_updates": "273800", "lr": "0.000171467", "gnorm": "0.272", "loss_scale": "4", "train_wall": "225", "gb_free": "40", "wall": "517207"}
[2024-10-10 17:52:04,399][fairseq_cli.train][INFO] - end of epoch 572 (average epoch stats below)
[2024-10-10 17:52:04,416][train][INFO] - {"epoch": 572, "train_loss": "0.765", "train_ntokens": "263494", "train_nsentences": "1753.71", "train_wps": "140156", "train_ups": "0.53", "train_wpb": "263494", "train_bsz": "1753.7", "train_num_updates": "273880", "train_lr": "0.000171359", "train_gnorm": "0.27", "train_loss_scale": "4", "train_train_wall": "554", "train_gb_free": "39.8", "train_wall": "517317"}
[2024-10-10 17:52:04,493][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:52:04,537][fairseq.trainer][INFO] - begin training epoch 573
[2024-10-10 17:52:04,538][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:58:48,047][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 17:59:47,090][train_inner][INFO] - {"epoch": 573, "update": 572.253, "loss": "0.764", "ntokens": "262744", "nsentences": "1747.47", "wps": "91794.9", "ups": "0.35", "wpb": "262744", "bsz": "1747.5", "num_updates": "274000", "lr": "0.000171196", "gnorm": "0.264", "loss_scale": "2", "train_wall": "259", "gb_free": "40", "wall": "517779"}
[2024-10-10 18:03:39,390][train_inner][INFO] - {"epoch": 573, "update": 572.67, "loss": "0.765", "ntokens": "263547", "nsentences": "1814.61", "wps": "226916", "ups": "0.86", "wpb": "263547", "bsz": "1814.6", "num_updates": "274200", "lr": "0.000170924", "gnorm": "0.26", "loss_scale": "2", "train_wall": "227", "gb_free": "40.5", "wall": "518012"}
[2024-10-10 18:06:56,093][fairseq_cli.train][INFO] - end of epoch 573 (average epoch stats below)
[2024-10-10 18:06:56,112][train][INFO] - {"epoch": 573, "train_loss": "0.764", "train_ntokens": "263499", "train_nsentences": "1753.45", "train_wps": "141252", "train_ups": "0.54", "train_wpb": "263499", "train_bsz": "1753.4", "train_num_updates": "274358", "train_lr": "0.000170709", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.8", "train_wall": "518208"}
[2024-10-10 18:06:56,192][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:06:56,215][fairseq.trainer][INFO] - begin training epoch 574
[2024-10-10 18:06:56,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:13:05,872][train_inner][INFO] - {"epoch": 574, "update": 573.088, "loss": "0.765", "ntokens": "263035", "nsentences": "1724.56", "wps": "92869.6", "ups": "0.35", "wpb": "263035", "bsz": "1724.6", "num_updates": "274400", "lr": "0.000170652", "gnorm": "0.261", "loss_scale": "2", "train_wall": "255", "gb_free": "40.5", "wall": "518578"}
[2024-10-10 18:16:45,661][train_inner][INFO] - {"epoch": 574, "update": 573.505, "loss": "0.762", "ntokens": "264138", "nsentences": "1740.36", "wps": "240377", "ups": "0.91", "wpb": "264138", "bsz": "1740.4", "num_updates": "274600", "lr": "0.00017038", "gnorm": "0.266", "loss_scale": "2", "train_wall": "215", "gb_free": "39.1", "wall": "518798"}
[2024-10-10 18:20:42,874][train_inner][INFO] - {"epoch": 574, "update": 573.923, "loss": "0.766", "ntokens": "263889", "nsentences": "1755.32", "wps": "222523", "ups": "0.84", "wpb": "263889", "bsz": "1755.3", "num_updates": "274800", "lr": "0.000170109", "gnorm": "0.271", "loss_scale": "2", "train_wall": "232", "gb_free": "40.3", "wall": "519035"}
[2024-10-10 18:21:34,609][fairseq_cli.train][INFO] - end of epoch 574 (average epoch stats below)
[2024-10-10 18:21:34,630][train][INFO] - {"epoch": 574, "train_loss": "0.765", "train_ntokens": "263490", "train_nsentences": "1753.71", "train_wps": "143670", "train_ups": "0.55", "train_wpb": "263490", "train_bsz": "1753.7", "train_num_updates": "274837", "train_lr": "0.000170058", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "560", "train_gb_free": "39.3", "train_wall": "519087"}
[2024-10-10 18:21:34,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:21:34,755][fairseq.trainer][INFO] - begin training epoch 575
[2024-10-10 18:21:34,756][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:30:20,108][train_inner][INFO] - {"epoch": 575, "update": 574.34, "loss": "0.765", "ntokens": "262508", "nsentences": "1784.55", "wps": "90955", "ups": "0.35", "wpb": "262508", "bsz": "1784.5", "num_updates": "275000", "lr": "0.000169837", "gnorm": "0.274", "loss_scale": "2", "train_wall": "248", "gb_free": "40", "wall": "519612"}
[2024-10-10 18:33:52,772][train_inner][INFO] - {"epoch": 575, "update": 574.758, "loss": "0.762", "ntokens": "264337", "nsentences": "1711.56", "wps": "248615", "ups": "0.94", "wpb": "264337", "bsz": "1711.6", "num_updates": "275200", "lr": "0.000169565", "gnorm": "0.266", "loss_scale": "2", "train_wall": "206", "gb_free": "39.6", "wall": "519825"}
[2024-10-10 18:36:09,444][fairseq_cli.train][INFO] - end of epoch 575 (average epoch stats below)
[2024-10-10 18:36:09,479][train][INFO] - {"epoch": 575, "train_loss": "0.764", "train_ntokens": "263464", "train_nsentences": "1753.71", "train_wps": "144255", "train_ups": "0.55", "train_wpb": "263464", "train_bsz": "1753.7", "train_num_updates": "275316", "train_lr": "0.000169408", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.3", "train_wall": "519962"}
[2024-10-10 18:36:09,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:36:09,688][fairseq.trainer][INFO] - begin training epoch 576
[2024-10-10 18:36:09,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:43:26,910][train_inner][INFO] - {"epoch": 576, "update": 575.175, "loss": "0.767", "ntokens": "262770", "nsentences": "1756.65", "wps": "91543.6", "ups": "0.35", "wpb": "262770", "bsz": "1756.7", "num_updates": "275400", "lr": "0.000169293", "gnorm": "0.264", "loss_scale": "2", "train_wall": "243", "gb_free": "39.2", "wall": "520399"}
[2024-10-10 18:47:04,613][train_inner][INFO] - {"epoch": 576, "update": 575.593, "loss": "0.762", "ntokens": "264197", "nsentences": "1741.61", "wps": "242730", "ups": "0.92", "wpb": "264197", "bsz": "1741.6", "num_updates": "275600", "lr": "0.000169022", "gnorm": "0.267", "loss_scale": "2", "train_wall": "212", "gb_free": "39.6", "wall": "520617"}
[2024-10-10 18:51:21,481][fairseq_cli.train][INFO] - end of epoch 576 (average epoch stats below)
[2024-10-10 18:51:21,502][train][INFO] - {"epoch": 576, "train_loss": "0.763", "train_ntokens": "263469", "train_nsentences": "1753.71", "train_wps": "138380", "train_ups": "0.53", "train_wpb": "263469", "train_bsz": "1753.7", "train_num_updates": "275795", "train_lr": "0.000168757", "train_gnorm": "0.268", "train_loss_scale": "2", "train_train_wall": "571", "train_gb_free": "39.7", "train_wall": "520874"}
[2024-10-10 18:51:21,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:51:21,672][fairseq.trainer][INFO] - begin training epoch 577
[2024-10-10 18:51:21,673][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:56:47,708][train_inner][INFO] - {"epoch": 577, "update": 576.01, "loss": "0.764", "ntokens": "262536", "nsentences": "1773.38", "wps": "90054.6", "ups": "0.34", "wpb": "262536", "bsz": "1773.4", "num_updates": "275800", "lr": "0.00016875", "gnorm": "0.267", "loss_scale": "2", "train_wall": "251", "gb_free": "39.3", "wall": "521200"}
[2024-10-10 19:00:15,393][train_inner][INFO] - {"epoch": 577, "update": 576.428, "loss": "0.763", "ntokens": "263831", "nsentences": "1774.03", "wps": "254093", "ups": "0.96", "wpb": "263831", "bsz": "1774", "num_updates": "276000", "lr": "0.000168478", "gnorm": "0.269", "loss_scale": "4", "train_wall": "202", "gb_free": "40.2", "wall": "521408"}
[2024-10-10 19:04:22,607][train_inner][INFO] - {"epoch": 577, "update": 576.846, "loss": "0.763", "ntokens": "264022", "nsentences": "1725.79", "wps": "213633", "ups": "0.81", "wpb": "264022", "bsz": "1725.8", "num_updates": "276200", "lr": "0.000168207", "gnorm": "0.267", "loss_scale": "4", "train_wall": "242", "gb_free": "39.8", "wall": "521655"}
[2024-10-10 19:06:05,492][fairseq_cli.train][INFO] - end of epoch 577 (average epoch stats below)
[2024-10-10 19:06:05,516][train][INFO] - {"epoch": 577, "train_loss": "0.763", "train_ntokens": "263377", "train_nsentences": "1753.71", "train_wps": "142712", "train_ups": "0.54", "train_wpb": "263378", "train_bsz": "1753.7", "train_num_updates": "276274", "train_lr": "0.000168106", "train_gnorm": "0.266", "train_loss_scale": "4", "train_train_wall": "546", "train_gb_free": "40", "train_wall": "521758"}
[2024-10-10 19:06:05,680][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:06:05,727][fairseq.trainer][INFO] - begin training epoch 578
[2024-10-10 19:06:05,728][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:12:29,033][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 19:13:56,984][train_inner][INFO] - {"epoch": 578, "update": 577.265, "loss": "0.762", "ntokens": "262688", "nsentences": "1748.38", "wps": "91474.3", "ups": "0.35", "wpb": "262688", "bsz": "1748.4", "num_updates": "276400", "lr": "0.000167935", "gnorm": "0.262", "loss_scale": "2", "train_wall": "248", "gb_free": "39.7", "wall": "522229"}
[2024-10-10 19:18:06,033][train_inner][INFO] - {"epoch": 578, "update": 577.683, "loss": "0.764", "ntokens": "263468", "nsentences": "1797.06", "wps": "211600", "ups": "0.8", "wpb": "263468", "bsz": "1797.1", "num_updates": "276600", "lr": "0.000167663", "gnorm": "0.269", "loss_scale": "2", "train_wall": "243", "gb_free": "40", "wall": "522478"}
[2024-10-10 19:20:51,935][fairseq_cli.train][INFO] - end of epoch 578 (average epoch stats below)
[2024-10-10 19:20:51,984][train][INFO] - {"epoch": 578, "train_loss": "0.763", "train_ntokens": "263375", "train_nsentences": "1753.25", "train_wps": "142022", "train_ups": "0.54", "train_wpb": "263375", "train_bsz": "1753.2", "train_num_updates": "276752", "train_lr": "0.000167457", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "40.5", "train_wall": "522644"}
[2024-10-10 19:20:52,145][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:20:52,169][fairseq.trainer][INFO] - begin training epoch 579
[2024-10-10 19:20:52,170][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:27:39,565][train_inner][INFO] - {"epoch": 579, "update": 578.1, "loss": "0.765", "ntokens": "263006", "nsentences": "1726.8", "wps": "91720.7", "ups": "0.35", "wpb": "263006", "bsz": "1726.8", "num_updates": "276800", "lr": "0.000167391", "gnorm": "0.253", "loss_scale": "2", "train_wall": "237", "gb_free": "39.6", "wall": "523052"}
[2024-10-10 19:31:19,448][train_inner][INFO] - {"epoch": 579, "update": 578.518, "loss": "0.761", "ntokens": "264149", "nsentences": "1738.38", "wps": "240302", "ups": "0.91", "wpb": "264148", "bsz": "1738.4", "num_updates": "277000", "lr": "0.00016712", "gnorm": "0.254", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "523272"}
[2024-10-10 19:35:32,971][train_inner][INFO] - {"epoch": 579, "update": 578.935, "loss": "0.766", "ntokens": "263455", "nsentences": "1783.49", "wps": "207854", "ups": "0.79", "wpb": "263455", "bsz": "1783.5", "num_updates": "277200", "lr": "0.000166848", "gnorm": "0.261", "loss_scale": "2", "train_wall": "246", "gb_free": "39.7", "wall": "523525"}
[2024-10-10 19:36:21,155][fairseq_cli.train][INFO] - end of epoch 579 (average epoch stats below)
[2024-10-10 19:36:21,160][train][INFO] - {"epoch": 579, "train_loss": "0.763", "train_ntokens": "263405", "train_nsentences": "1753.71", "train_wps": "135794", "train_ups": "0.52", "train_wpb": "263406", "train_bsz": "1753.7", "train_num_updates": "277231", "train_lr": "0.000166806", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "581", "train_gb_free": "39.3", "train_wall": "523573"}
[2024-10-10 19:36:21,250][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:36:21,281][fairseq.trainer][INFO] - begin training epoch 580
[2024-10-10 19:36:21,282][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:44:48,037][train_inner][INFO] - {"epoch": 580, "update": 579.353, "loss": "0.761", "ntokens": "262836", "nsentences": "1734.38", "wps": "94710.5", "ups": "0.36", "wpb": "262836", "bsz": "1734.4", "num_updates": "277400", "lr": "0.000166576", "gnorm": "0.258", "loss_scale": "2", "train_wall": "189", "gb_free": "39.6", "wall": "524080"}
[2024-10-10 19:48:32,311][train_inner][INFO] - {"epoch": 580, "update": 579.77, "loss": "0.764", "ntokens": "264035", "nsentences": "1766.74", "wps": "235484", "ups": "0.89", "wpb": "264035", "bsz": "1766.7", "num_updates": "277600", "lr": "0.000166304", "gnorm": "0.26", "loss_scale": "2", "train_wall": "215", "gb_free": "39.7", "wall": "524304"}
[2024-10-10 19:50:32,128][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 580 @ 277710 updates
[2024-10-10 19:50:32,138][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 19:50:44,499][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 19:50:44,586][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 580 @ 277710 updates, score None) (writing took 12.458326320163906 seconds)
[2024-10-10 19:50:44,586][fairseq_cli.train][INFO] - end of epoch 580 (average epoch stats below)
[2024-10-10 19:50:44,589][train][INFO] - {"epoch": 580, "train_loss": "0.763", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "146180", "train_ups": "0.55", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "277710", "train_lr": "0.000166155", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "475", "train_gb_free": "39.6", "train_wall": "524437"}
[2024-10-10 19:50:44,639][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:50:44,671][fairseq.trainer][INFO] - begin training epoch 581
[2024-10-10 19:50:44,671][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:57:59,365][train_inner][INFO] - {"epoch": 581, "update": 580.188, "loss": "0.763", "ntokens": "262879", "nsentences": "1736.58", "wps": "92719.8", "ups": "0.35", "wpb": "262879", "bsz": "1736.6", "num_updates": "277800", "lr": "0.000166033", "gnorm": "0.276", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "524872"}
[2024-10-10 20:01:17,316][train_inner][INFO] - {"epoch": 581, "update": 580.605, "loss": "0.761", "ntokens": "264053", "nsentences": "1741.16", "wps": "266822", "ups": "1.01", "wpb": "264053", "bsz": "1741.2", "num_updates": "278000", "lr": "0.000165761", "gnorm": "0.267", "loss_scale": "2", "train_wall": "191", "gb_free": "39.6", "wall": "525069"}
[2024-10-10 20:05:12,000][fairseq_cli.train][INFO] - end of epoch 581 (average epoch stats below)
[2024-10-10 20:05:12,032][train][INFO] - {"epoch": 581, "train_loss": "0.763", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "145506", "train_ups": "0.55", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "278189", "train_lr": "0.000165504", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "40.5", "train_wall": "525304"}
[2024-10-10 20:05:12,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:05:12,200][fairseq.trainer][INFO] - begin training epoch 582
[2024-10-10 20:05:12,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:10:51,057][train_inner][INFO] - {"epoch": 582, "update": 581.023, "loss": "0.766", "ntokens": "262633", "nsentences": "1785.84", "wps": "91552.7", "ups": "0.35", "wpb": "262633", "bsz": "1785.8", "num_updates": "278200", "lr": "0.000165489", "gnorm": "0.259", "loss_scale": "2", "train_wall": "255", "gb_free": "40.1", "wall": "525643"}
[2024-10-10 20:14:12,764][train_inner][INFO] - {"epoch": 582, "update": 581.441, "loss": "0.758", "ntokens": "264591", "nsentences": "1682.51", "wps": "262391", "ups": "0.99", "wpb": "264591", "bsz": "1682.5", "num_updates": "278400", "lr": "0.000165217", "gnorm": "0.259", "loss_scale": "4", "train_wall": "197", "gb_free": "40.3", "wall": "525845"}
[2024-10-10 20:17:30,344][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 20:18:07,236][train_inner][INFO] - {"epoch": 582, "update": 581.86, "loss": "0.766", "ntokens": "263439", "nsentences": "1795.34", "wps": "224732", "ups": "0.85", "wpb": "263439", "bsz": "1795.3", "num_updates": "278600", "lr": "0.000164946", "gnorm": "0.264", "loss_scale": "2", "train_wall": "226", "gb_free": "40.1", "wall": "526079"}
[2024-10-10 20:19:40,151][fairseq_cli.train][INFO] - end of epoch 582 (average epoch stats below)
[2024-10-10 20:19:40,246][train][INFO] - {"epoch": 582, "train_loss": "0.763", "train_ntokens": "263422", "train_nsentences": "1752.05", "train_wps": "145036", "train_ups": "0.55", "train_wpb": "263422", "train_bsz": "1752", "train_num_updates": "278667", "train_lr": "0.000164855", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "40", "train_wall": "526172"}
[2024-10-10 20:19:40,487][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:19:40,514][fairseq.trainer][INFO] - begin training epoch 583
[2024-10-10 20:19:40,514][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:27:37,232][train_inner][INFO] - {"epoch": 583, "update": 582.278, "loss": "0.764", "ntokens": "262565", "nsentences": "1807.51", "wps": "92130.6", "ups": "0.35", "wpb": "262565", "bsz": "1807.5", "num_updates": "278800", "lr": "0.000164674", "gnorm": "0.26", "loss_scale": "2", "train_wall": "242", "gb_free": "40", "wall": "526649"}
[2024-10-10 20:31:33,758][train_inner][INFO] - {"epoch": 583, "update": 582.695, "loss": "0.76", "ntokens": "264301", "nsentences": "1724.45", "wps": "223504", "ups": "0.85", "wpb": "264300", "bsz": "1724.5", "num_updates": "279000", "lr": "0.000164402", "gnorm": "0.253", "loss_scale": "2", "train_wall": "231", "gb_free": "40", "wall": "526886"}
[2024-10-10 20:34:30,698][fairseq_cli.train][INFO] - end of epoch 583 (average epoch stats below)
[2024-10-10 20:34:30,728][train][INFO] - {"epoch": 583, "train_loss": "0.762", "train_ntokens": "263549", "train_nsentences": "1753.71", "train_wps": "141777", "train_ups": "0.54", "train_wpb": "263548", "train_bsz": "1753.7", "train_num_updates": "279146", "train_lr": "0.000164204", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "554", "train_gb_free": "40", "train_wall": "527063"}
[2024-10-10 20:34:30,865][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:34:30,892][fairseq.trainer][INFO] - begin training epoch 584
[2024-10-10 20:34:30,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:41:14,046][train_inner][INFO] - {"epoch": 584, "update": 583.113, "loss": "0.764", "ntokens": "262650", "nsentences": "1760.36", "wps": "90526.3", "ups": "0.34", "wpb": "262650", "bsz": "1760.4", "num_updates": "279200", "lr": "0.00016413", "gnorm": "0.282", "loss_scale": "2", "train_wall": "251", "gb_free": "40.1", "wall": "527466"}
[2024-10-10 20:44:36,648][train_inner][INFO] - {"epoch": 584, "update": 583.53, "loss": "0.763", "ntokens": "264144", "nsentences": "1751.08", "wps": "260794", "ups": "0.99", "wpb": "264144", "bsz": "1751.1", "num_updates": "279400", "lr": "0.000163859", "gnorm": "0.25", "loss_scale": "2", "train_wall": "197", "gb_free": "39.6", "wall": "527669"}
[2024-10-10 20:48:20,323][train_inner][INFO] - {"epoch": 584, "update": 583.948, "loss": "0.762", "ntokens": "264352", "nsentences": "1734.64", "wps": "236383", "ups": "0.89", "wpb": "264352", "bsz": "1734.6", "num_updates": "279600", "lr": "0.000163587", "gnorm": "0.259", "loss_scale": "2", "train_wall": "219", "gb_free": "39.3", "wall": "527892"}
[2024-10-10 20:49:07,325][fairseq_cli.train][INFO] - end of epoch 584 (average epoch stats below)
[2024-10-10 20:49:07,328][train][INFO] - {"epoch": 584, "train_loss": "0.763", "train_ntokens": "263619", "train_nsentences": "1753.71", "train_wps": "144051", "train_ups": "0.55", "train_wpb": "263619", "train_bsz": "1753.7", "train_num_updates": "279625", "train_lr": "0.000163553", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.8", "train_wall": "527939"}
[2024-10-10 20:49:07,414][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:49:07,434][fairseq.trainer][INFO] - begin training epoch 585
[2024-10-10 20:49:07,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:57:47,920][train_inner][INFO] - {"epoch": 585, "update": 584.365, "loss": "0.761", "ntokens": "263127", "nsentences": "1729.54", "wps": "92717.7", "ups": "0.35", "wpb": "263127", "bsz": "1729.5", "num_updates": "279800", "lr": "0.000163315", "gnorm": "0.265", "loss_scale": "2", "train_wall": "243", "gb_free": "39.8", "wall": "528460"}
[2024-10-10 21:02:05,838][train_inner][INFO] - {"epoch": 585, "update": 584.783, "loss": "0.764", "ntokens": "263854", "nsentences": "1786.59", "wps": "204616", "ups": "0.78", "wpb": "263854", "bsz": "1786.6", "num_updates": "280000", "lr": "0.000163043", "gnorm": "0.277", "loss_scale": "2", "train_wall": "252", "gb_free": "39.6", "wall": "528718"}
[2024-10-10 21:03:55,864][fairseq_cli.train][INFO] - end of epoch 585 (average epoch stats below)
[2024-10-10 21:03:55,876][train][INFO] - {"epoch": 585, "train_loss": "0.762", "train_ntokens": "263661", "train_nsentences": "1753.71", "train_wps": "142136", "train_ups": "0.54", "train_wpb": "263661", "train_bsz": "1753.7", "train_num_updates": "280104", "train_lr": "0.000162902", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.6", "train_wall": "528828"}
[2024-10-10 21:03:56,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:03:56,056][fairseq.trainer][INFO] - begin training epoch 586
[2024-10-10 21:03:56,057][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:11:41,352][train_inner][INFO] - {"epoch": 586, "update": 585.2, "loss": "0.762", "ntokens": "262880", "nsentences": "1749.88", "wps": "91358.9", "ups": "0.35", "wpb": "262880", "bsz": "1749.9", "num_updates": "280200", "lr": "0.000162772", "gnorm": "0.267", "loss_scale": "2", "train_wall": "235", "gb_free": "40.1", "wall": "529294"}
[2024-10-10 21:15:18,420][train_inner][INFO] - {"epoch": 586, "update": 585.618, "loss": "0.76", "ntokens": "264310", "nsentences": "1739.26", "wps": "243554", "ups": "0.92", "wpb": "264310", "bsz": "1739.3", "num_updates": "280400", "lr": "0.0001625", "gnorm": "0.268", "loss_scale": "2", "train_wall": "211", "gb_free": "39.7", "wall": "529511"}
[2024-10-10 21:19:20,495][fairseq_cli.train][INFO] - end of epoch 586 (average epoch stats below)
[2024-10-10 21:19:20,513][train][INFO] - {"epoch": 586, "train_loss": "0.762", "train_ntokens": "263625", "train_nsentences": "1753.71", "train_wps": "136574", "train_ups": "0.52", "train_wpb": "263625", "train_bsz": "1753.7", "train_num_updates": "280583", "train_lr": "0.000162251", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "577", "train_gb_free": "39.9", "train_wall": "529753"}
[2024-10-10 21:19:20,682][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:19:20,696][fairseq.trainer][INFO] - begin training epoch 587
[2024-10-10 21:19:20,697][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:25:18,358][train_inner][INFO] - {"epoch": 587, "update": 586.035, "loss": "0.765", "ntokens": "262804", "nsentences": "1769.73", "wps": "87614", "ups": "0.33", "wpb": "262804", "bsz": "1769.7", "num_updates": "280600", "lr": "0.000162228", "gnorm": "0.277", "loss_scale": "2", "train_wall": "282", "gb_free": "40.5", "wall": "530111"}
[2024-10-10 21:28:40,170][train_inner][INFO] - {"epoch": 587, "update": 586.453, "loss": "0.761", "ntokens": "263715", "nsentences": "1781.48", "wps": "261369", "ups": "0.99", "wpb": "263715", "bsz": "1781.5", "num_updates": "280800", "lr": "0.000161957", "gnorm": "0.267", "loss_scale": "4", "train_wall": "196", "gb_free": "39.6", "wall": "530312"}
[2024-10-10 21:32:22,167][train_inner][INFO] - {"epoch": 587, "update": 586.871, "loss": "0.763", "ntokens": "264250", "nsentences": "1727.92", "wps": "238090", "ups": "0.9", "wpb": "264250", "bsz": "1727.9", "num_updates": "281000", "lr": "0.000161685", "gnorm": "0.254", "loss_scale": "4", "train_wall": "217", "gb_free": "40.1", "wall": "530534"}
[2024-10-10 21:33:47,861][fairseq_cli.train][INFO] - end of epoch 587 (average epoch stats below)
[2024-10-10 21:33:47,865][train][INFO] - {"epoch": 587, "train_loss": "0.762", "train_ntokens": "263520", "train_nsentences": "1753.71", "train_wps": "145535", "train_ups": "0.55", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "281062", "train_lr": "0.000161601", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "542", "train_gb_free": "40.2", "train_wall": "530620"}
[2024-10-10 21:33:47,949][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:33:47,969][fairseq.trainer][INFO] - begin training epoch 588
[2024-10-10 21:33:47,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:39:17,636][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 21:41:50,147][train_inner][INFO] - {"epoch": 588, "update": 587.29, "loss": "0.763", "ntokens": "262819", "nsentences": "1750.88", "wps": "92550.1", "ups": "0.35", "wpb": "262819", "bsz": "1750.9", "num_updates": "281200", "lr": "0.000161413", "gnorm": "0.272", "loss_scale": "2", "train_wall": "255", "gb_free": "39.2", "wall": "531102"}
[2024-10-10 21:45:43,467][train_inner][INFO] - {"epoch": 588, "update": 587.708, "loss": "0.764", "ntokens": "263591", "nsentences": "1786.85", "wps": "226005", "ups": "0.86", "wpb": "263591", "bsz": "1786.8", "num_updates": "281400", "lr": "0.000161141", "gnorm": "0.277", "loss_scale": "2", "train_wall": "227", "gb_free": "39.8", "wall": "531336"}
[2024-10-10 21:48:04,416][fairseq_cli.train][INFO] - end of epoch 588 (average epoch stats below)
[2024-10-10 21:48:04,462][train][INFO] - {"epoch": 588, "train_loss": "0.762", "train_ntokens": "263426", "train_nsentences": "1753.15", "train_wps": "147002", "train_ups": "0.56", "train_wpb": "263426", "train_bsz": "1753.2", "train_num_updates": "281540", "train_lr": "0.000160951", "train_gnorm": "0.276", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "40", "train_wall": "531477"}
[2024-10-10 21:48:06,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:48:06,803][fairseq.trainer][INFO] - begin training epoch 589
[2024-10-10 21:48:06,804][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:55:05,007][train_inner][INFO] - {"epoch": 589, "update": 588.125, "loss": "0.759", "ntokens": "263075", "nsentences": "1705.05", "wps": "93701.5", "ups": "0.36", "wpb": "263075", "bsz": "1705", "num_updates": "281600", "lr": "0.00016087", "gnorm": "0.274", "loss_scale": "2", "train_wall": "213", "gb_free": "39.6", "wall": "531897"}
[2024-10-10 21:58:31,354][train_inner][INFO] - {"epoch": 589, "update": 588.543, "loss": "0.761", "ntokens": "263714", "nsentences": "1771.36", "wps": "255646", "ups": "0.97", "wpb": "263714", "bsz": "1771.4", "num_updates": "281800", "lr": "0.000160598", "gnorm": "0.273", "loss_scale": "2", "train_wall": "168", "gb_free": "40", "wall": "532104"}
[2024-10-10 22:02:13,263][train_inner][INFO] - {"epoch": 589, "update": 588.96, "loss": "0.764", "ntokens": "263965", "nsentences": "1757.78", "wps": "237934", "ups": "0.9", "wpb": "263966", "bsz": "1757.8", "num_updates": "282000", "lr": "0.000160326", "gnorm": "0.269", "loss_scale": "2", "train_wall": "164", "gb_free": "39.2", "wall": "532325"}
[2024-10-10 22:02:55,181][fairseq_cli.train][INFO] - end of epoch 589 (average epoch stats below)
[2024-10-10 22:02:55,186][train][INFO] - {"epoch": 589, "train_loss": "0.762", "train_ntokens": "263381", "train_nsentences": "1753.71", "train_wps": "141646", "train_ups": "0.54", "train_wpb": "263381", "train_bsz": "1753.7", "train_num_updates": "282019", "train_lr": "0.0001603", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "450", "train_gb_free": "39.6", "train_wall": "532367"}
[2024-10-10 22:02:55,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:02:55,324][fairseq.trainer][INFO] - begin training epoch 590
[2024-10-10 22:02:55,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:10:13,463][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-10 22:11:42,445][train_inner][INFO] - {"epoch": 590, "update": 589.38, "loss": "0.761", "ntokens": "262700", "nsentences": "1744.84", "wps": "92309.6", "ups": "0.35", "wpb": "262700", "bsz": "1744.8", "num_updates": "282200", "lr": "0.000160054", "gnorm": "0.268", "loss_scale": "1", "train_wall": "252", "gb_free": "40.1", "wall": "532895"}
[2024-10-10 22:15:47,412][train_inner][INFO] - {"epoch": 590, "update": 589.797, "loss": "0.763", "ntokens": "264036", "nsentences": "1756.01", "wps": "215585", "ups": "0.82", "wpb": "264036", "bsz": "1756", "num_updates": "282400", "lr": "0.000159783", "gnorm": "0.281", "loss_scale": "1", "train_wall": "239", "gb_free": "40.2", "wall": "533140"}
[2024-10-10 22:17:52,888][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 590 @ 282497 updates
[2024-10-10 22:17:52,889][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 22:18:01,002][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-10 22:18:01,484][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 590 @ 282497 updates, score None) (writing took 8.596306880004704 seconds)
[2024-10-10 22:18:01,494][fairseq_cli.train][INFO] - end of epoch 590 (average epoch stats below)
[2024-10-10 22:18:01,505][train][INFO] - {"epoch": 590, "train_loss": "0.762", "train_ntokens": "263442", "train_nsentences": "1752.9", "train_wps": "138944", "train_ups": "0.53", "train_wpb": "263442", "train_bsz": "1752.9", "train_num_updates": "282497", "train_lr": "0.000159651", "train_gnorm": "0.271", "train_loss_scale": "1", "train_train_wall": "569", "train_gb_free": "40.1", "train_wall": "533274"}
[2024-10-10 22:18:01,619][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:18:01,640][fairseq.trainer][INFO] - begin training epoch 591
[2024-10-10 22:18:01,640][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:25:28,168][train_inner][INFO] - {"epoch": 591, "update": 590.215, "loss": "0.761", "ntokens": "262708", "nsentences": "1751.63", "wps": "90476.2", "ups": "0.34", "wpb": "262708", "bsz": "1751.6", "num_updates": "282600", "lr": "0.000159511", "gnorm": "0.26", "loss_scale": "1", "train_wall": "239", "gb_free": "39.6", "wall": "533720"}
[2024-10-10 22:28:57,495][train_inner][INFO] - {"epoch": 591, "update": 590.633, "loss": "0.763", "ntokens": "263969", "nsentences": "1768.62", "wps": "252244", "ups": "0.96", "wpb": "263969", "bsz": "1768.6", "num_updates": "282800", "lr": "0.000159239", "gnorm": "0.256", "loss_scale": "1", "train_wall": "204", "gb_free": "39.2", "wall": "533930"}
[2024-10-10 22:32:27,887][fairseq_cli.train][INFO] - end of epoch 591 (average epoch stats below)
[2024-10-10 22:32:27,906][train][INFO] - {"epoch": 591, "train_loss": "0.761", "train_ntokens": "263409", "train_nsentences": "1753.71", "train_wps": "145632", "train_ups": "0.55", "train_wpb": "263409", "train_bsz": "1753.7", "train_num_updates": "282976", "train_lr": "0.000159", "train_gnorm": "0.257", "train_loss_scale": "1", "train_train_wall": "527", "train_gb_free": "39.6", "train_wall": "534140"}
[2024-10-10 22:32:28,052][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:32:28,113][fairseq.trainer][INFO] - begin training epoch 592
[2024-10-10 22:32:28,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:38:34,393][train_inner][INFO] - {"epoch": 592, "update": 591.05, "loss": "0.762", "ntokens": "262552", "nsentences": "1754.12", "wps": "91026.9", "ups": "0.35", "wpb": "262552", "bsz": "1754.1", "num_updates": "283000", "lr": "0.000158967", "gnorm": "0.26", "loss_scale": "1", "train_wall": "253", "gb_free": "40.5", "wall": "534507"}
[2024-10-10 22:42:33,740][train_inner][INFO] - {"epoch": 592, "update": 591.468, "loss": "0.762", "ntokens": "263633", "nsentences": "1809.37", "wps": "220314", "ups": "0.84", "wpb": "263633", "bsz": "1809.4", "num_updates": "283200", "lr": "0.000158696", "gnorm": "0.252", "loss_scale": "1", "train_wall": "234", "gb_free": "39.2", "wall": "534746"}
[2024-10-10 22:46:40,285][train_inner][INFO] - {"epoch": 592, "update": 591.885, "loss": "0.758", "ntokens": "264757", "nsentences": "1679.9", "wps": "214810", "ups": "0.81", "wpb": "264757", "bsz": "1679.9", "num_updates": "283400", "lr": "0.000158424", "gnorm": "0.259", "loss_scale": "1", "train_wall": "241", "gb_free": "39.6", "wall": "534992"}
[2024-10-10 22:48:00,797][fairseq_cli.train][INFO] - end of epoch 592 (average epoch stats below)
[2024-10-10 22:48:00,824][train][INFO] - {"epoch": 592, "train_loss": "0.761", "train_ntokens": "263550", "train_nsentences": "1753.71", "train_wps": "135330", "train_ups": "0.51", "train_wpb": "263550", "train_bsz": "1753.7", "train_num_updates": "283455", "train_lr": "0.000158349", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "601", "train_gb_free": "39.3", "train_wall": "535073"}
[2024-10-10 22:48:00,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:48:00,892][fairseq.trainer][INFO] - begin training epoch 593
[2024-10-10 22:48:00,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:55:56,697][train_inner][INFO] - {"epoch": 593, "update": 592.303, "loss": "0.761", "ntokens": "262593", "nsentences": "1762.4", "wps": "94390.1", "ups": "0.36", "wpb": "262592", "bsz": "1762.4", "num_updates": "283600", "lr": "0.000158152", "gnorm": "0.267", "loss_scale": "1", "train_wall": "228", "gb_free": "39.8", "wall": "535549"}
[2024-10-10 22:59:26,017][train_inner][INFO] - {"epoch": 593, "update": 592.72, "loss": "0.76", "ntokens": "264158", "nsentences": "1750.41", "wps": "252426", "ups": "0.96", "wpb": "264158", "bsz": "1750.4", "num_updates": "283800", "lr": "0.00015788", "gnorm": "0.261", "loss_scale": "1", "train_wall": "203", "gb_free": "39.6", "wall": "535758"}
[2024-10-10 23:02:08,859][fairseq_cli.train][INFO] - end of epoch 593 (average epoch stats below)
[2024-10-10 23:02:08,887][train][INFO] - {"epoch": 593, "train_loss": "0.761", "train_ntokens": "263518", "train_nsentences": "1753.71", "train_wps": "148841", "train_ups": "0.56", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "283934", "train_lr": "0.000157698", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "512", "train_gb_free": "39.3", "train_wall": "535921"}
[2024-10-10 23:02:08,939][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:02:08,954][fairseq.trainer][INFO] - begin training epoch 594
[2024-10-10 23:02:08,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:09:09,244][train_inner][INFO] - {"epoch": 594, "update": 593.138, "loss": "0.763", "ntokens": "262803", "nsentences": "1749.1", "wps": "90121.7", "ups": "0.34", "wpb": "262803", "bsz": "1749.1", "num_updates": "284000", "lr": "0.000157609", "gnorm": "0.264", "loss_scale": "1", "train_wall": "254", "gb_free": "40.5", "wall": "536341"}
[2024-10-10 23:12:41,574][train_inner][INFO] - {"epoch": 594, "update": 593.555, "loss": "0.76", "ntokens": "264204", "nsentences": "1718.58", "wps": "248875", "ups": "0.94", "wpb": "264204", "bsz": "1718.6", "num_updates": "284200", "lr": "0.000157337", "gnorm": "0.277", "loss_scale": "2", "train_wall": "207", "gb_free": "40", "wall": "536554"}
[2024-10-10 23:16:11,277][train_inner][INFO] - {"epoch": 594, "update": 593.973, "loss": "0.762", "ntokens": "263706", "nsentences": "1779.3", "wps": "251552", "ups": "0.95", "wpb": "263706", "bsz": "1779.3", "num_updates": "284400", "lr": "0.000157065", "gnorm": "0.27", "loss_scale": "2", "train_wall": "204", "gb_free": "39.3", "wall": "536763"}
[2024-10-10 23:16:51,105][fairseq_cli.train][INFO] - end of epoch 594 (average epoch stats below)
[2024-10-10 23:16:51,146][train][INFO] - {"epoch": 594, "train_loss": "0.762", "train_ntokens": "263449", "train_nsentences": "1753.71", "train_wps": "143038", "train_ups": "0.54", "train_wpb": "263449", "train_bsz": "1753.7", "train_num_updates": "284413", "train_lr": "0.000157048", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "40", "train_wall": "536803"}
[2024-10-10 23:16:51,221][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:16:51,243][fairseq.trainer][INFO] - begin training epoch 595
[2024-10-10 23:16:51,244][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:25:37,424][train_inner][INFO] - {"epoch": 595, "update": 594.39, "loss": "0.759", "ntokens": "262707", "nsentences": "1760.18", "wps": "92806.5", "ups": "0.35", "wpb": "262707", "bsz": "1760.2", "num_updates": "284600", "lr": "0.000156793", "gnorm": "0.261", "loss_scale": "2", "train_wall": "176", "gb_free": "39.4", "wall": "537330"}
[2024-10-10 23:29:30,983][train_inner][INFO] - {"epoch": 595, "update": 594.808, "loss": "0.761", "ntokens": "264432", "nsentences": "1730.59", "wps": "226504", "ups": "0.86", "wpb": "264432", "bsz": "1730.6", "num_updates": "284800", "lr": "0.000156522", "gnorm": "0.256", "loss_scale": "2", "train_wall": "146", "gb_free": "39.6", "wall": "537563"}
[2024-10-10 23:31:39,467][fairseq_cli.train][INFO] - end of epoch 595 (average epoch stats below)
[2024-10-10 23:31:39,488][train][INFO] - {"epoch": 595, "train_loss": "0.761", "train_ntokens": "263595", "train_nsentences": "1753.71", "train_wps": "142133", "train_ups": "0.54", "train_wpb": "263595", "train_bsz": "1753.7", "train_num_updates": "284892", "train_lr": "0.000156397", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "350", "train_gb_free": "39.6", "train_wall": "537692"}
[2024-10-10 23:31:39,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:31:39,597][fairseq.trainer][INFO] - begin training epoch 596
[2024-10-10 23:31:39,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:38:55,265][train_inner][INFO] - {"epoch": 596, "update": 595.225, "loss": "0.762", "ntokens": "262506", "nsentences": "1797.2", "wps": "93043.8", "ups": "0.35", "wpb": "262506", "bsz": "1797.2", "num_updates": "285000", "lr": "0.00015625", "gnorm": "0.273", "loss_scale": "2", "train_wall": "198", "gb_free": "40.5", "wall": "538127"}
[2024-10-10 23:42:34,283][train_inner][INFO] - {"epoch": 596, "update": 595.643, "loss": "0.759", "ntokens": "264466", "nsentences": "1713.15", "wps": "241518", "ups": "0.91", "wpb": "264466", "bsz": "1713.2", "num_updates": "285200", "lr": "0.000155978", "gnorm": "0.25", "loss_scale": "2", "train_wall": "213", "gb_free": "39.8", "wall": "538346"}
[2024-10-10 23:45:43,967][fairseq_cli.train][INFO] - end of epoch 596 (average epoch stats below)
[2024-10-10 23:45:44,068][train][INFO] - {"epoch": 596, "train_loss": "0.761", "train_ntokens": "263488", "train_nsentences": "1753.71", "train_wps": "149441", "train_ups": "0.57", "train_wpb": "263488", "train_bsz": "1753.7", "train_num_updates": "285371", "train_lr": "0.000155746", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "525", "train_gb_free": "40", "train_wall": "538536"}
[2024-10-10 23:45:45,605][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:45:45,663][fairseq.trainer][INFO] - begin training epoch 597
[2024-10-10 23:45:45,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:51:38,870][train_inner][INFO] - {"epoch": 597, "update": 596.061, "loss": "0.763", "ntokens": "262448", "nsentences": "1775.82", "wps": "96395.5", "ups": "0.37", "wpb": "262448", "bsz": "1775.8", "num_updates": "285400", "lr": "0.000155707", "gnorm": "0.28", "loss_scale": "2", "train_wall": "208", "gb_free": "39.2", "wall": "538891"}
[2024-10-10 23:55:01,480][train_inner][INFO] - {"epoch": 597, "update": 596.478, "loss": "0.759", "ntokens": "264196", "nsentences": "1746.62", "wps": "260823", "ups": "0.99", "wpb": "264196", "bsz": "1746.6", "num_updates": "285600", "lr": "0.000155435", "gnorm": "0.256", "loss_scale": "2", "train_wall": "175", "gb_free": "39.6", "wall": "539094"}
[2024-10-10 23:59:19,099][train_inner][INFO] - {"epoch": 597, "update": 596.896, "loss": "0.759", "ntokens": "264008", "nsentences": "1763.27", "wps": "204986", "ups": "0.78", "wpb": "264008", "bsz": "1763.3", "num_updates": "285800", "lr": "0.000155163", "gnorm": "0.284", "loss_scale": "2", "train_wall": "191", "gb_free": "39.6", "wall": "539351"}
[2024-10-11 00:00:34,674][fairseq_cli.train][INFO] - end of epoch 597 (average epoch stats below)
[2024-10-11 00:00:34,685][train][INFO] - {"epoch": 597, "train_loss": "0.76", "train_ntokens": "263611", "train_nsentences": "1753.71", "train_wps": "141794", "train_ups": "0.54", "train_wpb": "263611", "train_bsz": "1753.7", "train_num_updates": "285850", "train_lr": "0.000155095", "train_gnorm": "0.271", "train_loss_scale": "2", "train_train_wall": "451", "train_gb_free": "40.3", "train_wall": "539427"}
[2024-10-11 00:00:34,875][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:00:34,902][fairseq.trainer][INFO] - begin training epoch 598
[2024-10-11 00:00:34,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:08:58,955][train_inner][INFO] - {"epoch": 598, "update": 597.313, "loss": "0.759", "ntokens": "262578", "nsentences": "1754.57", "wps": "90575.7", "ups": "0.34", "wpb": "262578", "bsz": "1754.6", "num_updates": "286000", "lr": "0.000154891", "gnorm": "0.264", "loss_scale": "2", "train_wall": "183", "gb_free": "39.7", "wall": "539931"}
[2024-10-11 00:12:49,242][train_inner][INFO] - {"epoch": 598, "update": 597.731, "loss": "0.761", "ntokens": "263816", "nsentences": "1772.85", "wps": "229136", "ups": "0.87", "wpb": "263816", "bsz": "1772.8", "num_updates": "286200", "lr": "0.00015462", "gnorm": "0.244", "loss_scale": "2", "train_wall": "169", "gb_free": "39.8", "wall": "540161"}
[2024-10-11 00:13:03,010][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 00:15:43,201][fairseq_cli.train][INFO] - end of epoch 598 (average epoch stats below)
[2024-10-11 00:15:43,258][train][INFO] - {"epoch": 598, "train_loss": "0.76", "train_ntokens": "263386", "train_nsentences": "1754.22", "train_wps": "138589", "train_ups": "0.53", "train_wpb": "263386", "train_bsz": "1754.2", "train_num_updates": "286328", "train_lr": "0.000154446", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "410", "train_gb_free": "39.2", "train_wall": "540335"}
[2024-10-11 00:15:44,304][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:15:44,387][fairseq.trainer][INFO] - begin training epoch 599
[2024-10-11 00:15:44,387][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:22:36,282][train_inner][INFO] - {"epoch": 599, "update": 598.15, "loss": "0.762", "ntokens": "262883", "nsentences": "1742.96", "wps": "89568.9", "ups": "0.34", "wpb": "262883", "bsz": "1743", "num_updates": "286400", "lr": "0.000154348", "gnorm": "0.276", "loss_scale": "2", "train_wall": "208", "gb_free": "39.6", "wall": "540748"}
[2024-10-11 00:26:03,295][train_inner][INFO] - {"epoch": 599, "update": 598.568, "loss": "0.758", "ntokens": "263706", "nsentences": "1756.73", "wps": "254812", "ups": "0.97", "wpb": "263706", "bsz": "1756.7", "num_updates": "286600", "lr": "0.000154076", "gnorm": "0.266", "loss_scale": "2", "train_wall": "199", "gb_free": "39.3", "wall": "540955"}
[2024-10-11 00:29:41,448][train_inner][INFO] - {"epoch": 599, "update": 598.985, "loss": "0.76", "ntokens": "264080", "nsentences": "1753.19", "wps": "242146", "ups": "0.92", "wpb": "264080", "bsz": "1753.2", "num_updates": "286800", "lr": "0.000153804", "gnorm": "0.262", "loss_scale": "2", "train_wall": "211", "gb_free": "40", "wall": "541174"}
[2024-10-11 00:30:07,094][fairseq_cli.train][INFO] - end of epoch 599 (average epoch stats below)
[2024-10-11 00:30:07,117][train][INFO] - {"epoch": 599, "train_loss": "0.759", "train_ntokens": "263408", "train_nsentences": "1753.71", "train_wps": "146065", "train_ups": "0.55", "train_wpb": "263408", "train_bsz": "1753.7", "train_num_updates": "286807", "train_lr": "0.000153795", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "526", "train_gb_free": "39.6", "train_wall": "541199"}
[2024-10-11 00:30:07,193][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:30:07,209][fairseq.trainer][INFO] - begin training epoch 600
[2024-10-11 00:30:07,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:36:37,177][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 00:38:50,232][train_inner][INFO] - {"epoch": 600, "update": 599.405, "loss": "0.757", "ntokens": "263019", "nsentences": "1721.16", "wps": "95872.2", "ups": "0.36", "wpb": "263019", "bsz": "1721.2", "num_updates": "287000", "lr": "0.000153533", "gnorm": "0.246", "loss_scale": "1", "train_wall": "227", "gb_free": "39.6", "wall": "541722"}
[2024-10-11 00:42:39,045][train_inner][INFO] - {"epoch": 600, "update": 599.823, "loss": "0.761", "ntokens": "264127", "nsentences": "1755.8", "wps": "230880", "ups": "0.87", "wpb": "264127", "bsz": "1755.8", "num_updates": "287200", "lr": "0.000153261", "gnorm": "0.263", "loss_scale": "1", "train_wall": "190", "gb_free": "39.6", "wall": "541951"}
[2024-10-11 00:44:43,616][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 600 @ 287285 updates
[2024-10-11 00:44:43,618][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 00:44:48,678][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 00:44:48,799][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 600 @ 287285 updates, score None) (writing took 5.182997593656182 seconds)
[2024-10-11 00:44:48,800][fairseq_cli.train][INFO] - end of epoch 600 (average epoch stats below)
[2024-10-11 00:44:48,802][train][INFO] - {"epoch": 600, "train_loss": "0.76", "train_ntokens": "263538", "train_nsentences": "1752.43", "train_wps": "142877", "train_ups": "0.54", "train_wpb": "263538", "train_bsz": "1752.4", "train_num_updates": "287285", "train_lr": "0.000153145", "train_gnorm": "0.257", "train_loss_scale": "1", "train_train_wall": "487", "train_gb_free": "39.3", "train_wall": "542081"}
[2024-10-11 00:44:48,841][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:44:48,863][fairseq.trainer][INFO] - begin training epoch 601
[2024-10-11 00:44:48,863][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:52:23,287][train_inner][INFO] - {"epoch": 601, "update": 600.24, "loss": "0.762", "ntokens": "262571", "nsentences": "1774.19", "wps": "89889.7", "ups": "0.34", "wpb": "262571", "bsz": "1774.2", "num_updates": "287400", "lr": "0.000152989", "gnorm": "0.275", "loss_scale": "1", "train_wall": "194", "gb_free": "40", "wall": "542535"}
[2024-10-11 00:56:21,116][train_inner][INFO] - {"epoch": 601, "update": 600.658, "loss": "0.758", "ntokens": "264500", "nsentences": "1724.13", "wps": "222480", "ups": "0.84", "wpb": "264500", "bsz": "1724.1", "num_updates": "287600", "lr": "0.000152717", "gnorm": "0.249", "loss_scale": "1", "train_wall": "139", "gb_free": "40.2", "wall": "542773"}
[2024-10-11 00:59:55,618][fairseq_cli.train][INFO] - end of epoch 601 (average epoch stats below)
[2024-10-11 00:59:55,663][train][INFO] - {"epoch": 601, "train_loss": "0.76", "train_ntokens": "263608", "train_nsentences": "1753.71", "train_wps": "139242", "train_ups": "0.53", "train_wpb": "263608", "train_bsz": "1753.7", "train_num_updates": "287764", "train_lr": "0.000152495", "train_gnorm": "0.266", "train_loss_scale": "1", "train_train_wall": "381", "train_gb_free": "41", "train_wall": "542988"}
[2024-10-11 00:59:56,412][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:59:56,467][fairseq.trainer][INFO] - begin training epoch 602
[2024-10-11 00:59:56,474][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:06:06,610][train_inner][INFO] - {"epoch": 602, "update": 601.075, "loss": "0.763", "ntokens": "262496", "nsentences": "1794.89", "wps": "89670.8", "ups": "0.34", "wpb": "262496", "bsz": "1794.9", "num_updates": "287800", "lr": "0.000152446", "gnorm": "0.273", "loss_scale": "1", "train_wall": "189", "gb_free": "40.1", "wall": "543359"}
[2024-10-11 01:09:41,021][train_inner][INFO] - {"epoch": 602, "update": 601.493, "loss": "0.759", "ntokens": "263998", "nsentences": "1777.12", "wps": "246268", "ups": "0.93", "wpb": "263998", "bsz": "1777.1", "num_updates": "288000", "lr": "0.000152174", "gnorm": "0.273", "loss_scale": "1", "train_wall": "199", "gb_free": "39.8", "wall": "543573"}
[2024-10-11 01:13:47,506][train_inner][INFO] - {"epoch": 602, "update": 601.91, "loss": "0.76", "ntokens": "264144", "nsentences": "1719.64", "wps": "214354", "ups": "0.81", "wpb": "264144", "bsz": "1719.6", "num_updates": "288200", "lr": "0.000151902", "gnorm": "0.263", "loss_scale": "1", "train_wall": "169", "gb_free": "39.8", "wall": "543820"}
[2024-10-11 01:14:48,576][fairseq_cli.train][INFO] - end of epoch 602 (average epoch stats below)
[2024-10-11 01:14:48,798][train][INFO] - {"epoch": 602, "train_loss": "0.759", "train_ntokens": "263480", "train_nsentences": "1753.71", "train_wps": "141323", "train_ups": "0.54", "train_wpb": "263480", "train_bsz": "1753.7", "train_num_updates": "288243", "train_lr": "0.000151844", "train_gnorm": "0.266", "train_loss_scale": "1", "train_train_wall": "462", "train_gb_free": "40.7", "train_wall": "543881"}
[2024-10-11 01:14:50,823][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:14:50,939][fairseq.trainer][INFO] - begin training epoch 603
[2024-10-11 01:14:50,939][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:23:12,704][train_inner][INFO] - {"epoch": 603, "update": 602.328, "loss": "0.758", "ntokens": "262610", "nsentences": "1758.71", "wps": "92932.5", "ups": "0.35", "wpb": "262610", "bsz": "1758.7", "num_updates": "288400", "lr": "0.00015163", "gnorm": "0.265", "loss_scale": "1", "train_wall": "199", "gb_free": "39.3", "wall": "544385"}
[2024-10-11 01:26:55,798][train_inner][INFO] - {"epoch": 603, "update": 602.745, "loss": "0.757", "ntokens": "264606", "nsentences": "1709.42", "wps": "237245", "ups": "0.9", "wpb": "264606", "bsz": "1709.4", "num_updates": "288600", "lr": "0.000151359", "gnorm": "0.265", "loss_scale": "1", "train_wall": "172", "gb_free": "40.3", "wall": "544608"}
[2024-10-11 01:29:50,337][fairseq_cli.train][INFO] - end of epoch 603 (average epoch stats below)
[2024-10-11 01:29:50,362][train][INFO] - {"epoch": 603, "train_loss": "0.759", "train_ntokens": "263591", "train_nsentences": "1753.71", "train_wps": "140047", "train_ups": "0.53", "train_wpb": "263591", "train_bsz": "1753.7", "train_num_updates": "288722", "train_lr": "0.000151193", "train_gnorm": "0.265", "train_loss_scale": "1", "train_train_wall": "418", "train_gb_free": "39.5", "train_wall": "544783"}
[2024-10-11 01:29:50,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:29:50,426][fairseq.trainer][INFO] - begin training epoch 604
[2024-10-11 01:29:50,426][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:36:27,259][train_inner][INFO] - {"epoch": 604, "update": 603.163, "loss": "0.764", "ntokens": "262535", "nsentences": "1814.62", "wps": "91889", "ups": "0.35", "wpb": "262535", "bsz": "1814.6", "num_updates": "288800", "lr": "0.000151087", "gnorm": "0.268", "loss_scale": "1", "train_wall": "184", "gb_free": "40.3", "wall": "545179"}
[2024-10-11 01:40:22,832][train_inner][INFO] - {"epoch": 604, "update": 603.58, "loss": "0.759", "ntokens": "263834", "nsentences": "1768.98", "wps": "224006", "ups": "0.85", "wpb": "263834", "bsz": "1769", "num_updates": "289000", "lr": "0.000150815", "gnorm": "0.257", "loss_scale": "2", "train_wall": "190", "gb_free": "39.3", "wall": "545415"}
[2024-10-11 01:44:24,478][train_inner][INFO] - {"epoch": 604, "update": 603.998, "loss": "0.76", "ntokens": "264328", "nsentences": "1720.55", "wps": "219048", "ups": "0.83", "wpb": "264328", "bsz": "1720.5", "num_updates": "289200", "lr": "0.000150543", "gnorm": "0.254", "loss_scale": "2", "train_wall": "158", "gb_free": "40", "wall": "545657"}
[2024-10-11 01:44:28,551][fairseq_cli.train][INFO] - end of epoch 604 (average epoch stats below)
[2024-10-11 01:44:28,609][train][INFO] - {"epoch": 604, "train_loss": "0.76", "train_ntokens": "263582", "train_nsentences": "1753.71", "train_wps": "143770", "train_ups": "0.55", "train_wpb": "263582", "train_bsz": "1753.7", "train_num_updates": "289201", "train_lr": "0.000150542", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "441", "train_gb_free": "39.3", "train_wall": "545661"}
[2024-10-11 01:44:29,709][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:44:29,855][fairseq.trainer][INFO] - begin training epoch 605
[2024-10-11 01:44:29,855][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:53:51,274][train_inner][INFO] - {"epoch": 605, "update": 604.415, "loss": "0.759", "ntokens": "262434", "nsentences": "1788.49", "wps": "92667", "ups": "0.35", "wpb": "262434", "bsz": "1788.5", "num_updates": "289400", "lr": "0.000150272", "gnorm": "0.265", "loss_scale": "2", "train_wall": "239", "gb_free": "39.2", "wall": "546223"}
[2024-10-11 01:58:02,981][train_inner][INFO] - {"epoch": 605, "update": 604.833, "loss": "0.759", "ntokens": "264582", "nsentences": "1701.92", "wps": "210255", "ups": "0.79", "wpb": "264582", "bsz": "1701.9", "num_updates": "289600", "lr": "0.00015", "gnorm": "0.276", "loss_scale": "2", "train_wall": "246", "gb_free": "40", "wall": "546475"}
[2024-10-11 01:59:40,305][fairseq_cli.train][INFO] - end of epoch 605 (average epoch stats below)
[2024-10-11 01:59:40,328][train][INFO] - {"epoch": 605, "train_loss": "0.76", "train_ntokens": "263530", "train_nsentences": "1753.71", "train_wps": "138462", "train_ups": "0.53", "train_wpb": "263530", "train_bsz": "1753.7", "train_num_updates": "289680", "train_lr": "0.000149891", "train_gnorm": "0.27", "train_loss_scale": "2", "train_train_wall": "575", "train_gb_free": "39.1", "train_wall": "546572"}
[2024-10-11 01:59:41,187][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:59:41,231][fairseq.trainer][INFO] - begin training epoch 606
[2024-10-11 01:59:41,231][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:07:38,250][train_inner][INFO] - {"epoch": 606, "update": 605.251, "loss": "0.759", "ntokens": "262642", "nsentences": "1756.17", "wps": "91313.1", "ups": "0.35", "wpb": "262642", "bsz": "1756.2", "num_updates": "289800", "lr": "0.000149728", "gnorm": "0.262", "loss_scale": "2", "train_wall": "250", "gb_free": "39.8", "wall": "547050"}
[2024-10-11 02:11:07,324][train_inner][INFO] - {"epoch": 606, "update": 605.668, "loss": "0.758", "ntokens": "263874", "nsentences": "1772.49", "wps": "252437", "ups": "0.96", "wpb": "263874", "bsz": "1772.5", "num_updates": "290000", "lr": "0.000149457", "gnorm": "0.267", "loss_scale": "2", "train_wall": "203", "gb_free": "40", "wall": "547259"}
[2024-10-11 02:14:42,448][fairseq_cli.train][INFO] - end of epoch 606 (average epoch stats below)
[2024-10-11 02:14:42,453][train][INFO] - {"epoch": 606, "train_loss": "0.759", "train_ntokens": "263501", "train_nsentences": "1753.71", "train_wps": "139973", "train_ups": "0.53", "train_wpb": "263501", "train_bsz": "1753.7", "train_num_updates": "290159", "train_lr": "0.00014924", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "40", "train_wall": "547475"}
[2024-10-11 02:14:42,955][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:14:42,999][fairseq.trainer][INFO] - begin training epoch 607
[2024-10-11 02:14:43,000][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:21:07,732][train_inner][INFO] - {"epoch": 607, "update": 606.086, "loss": "0.759", "ntokens": "263467", "nsentences": "1692.86", "wps": "87764.8", "ups": "0.33", "wpb": "263467", "bsz": "1692.9", "num_updates": "290200", "lr": "0.000149185", "gnorm": "0.266", "loss_scale": "2", "train_wall": "251", "gb_free": "39.3", "wall": "547860"}
[2024-10-11 02:24:55,942][train_inner][INFO] - {"epoch": 607, "update": 606.503, "loss": "0.759", "ntokens": "263736", "nsentences": "1793.13", "wps": "231147", "ups": "0.88", "wpb": "263736", "bsz": "1793.1", "num_updates": "290400", "lr": "0.000148913", "gnorm": "0.266", "loss_scale": "2", "train_wall": "167", "gb_free": "39.6", "wall": "548088"}
[2024-10-11 02:29:07,813][train_inner][INFO] - {"epoch": 607, "update": 606.921, "loss": "0.759", "ntokens": "263717", "nsentences": "1784.53", "wps": "209423", "ups": "0.79", "wpb": "263717", "bsz": "1784.5", "num_updates": "290600", "lr": "0.000148641", "gnorm": "0.262", "loss_scale": "2", "train_wall": "163", "gb_free": "39.2", "wall": "548340"}
[2024-10-11 02:29:59,781][fairseq_cli.train][INFO] - end of epoch 607 (average epoch stats below)
[2024-10-11 02:29:59,796][train][INFO] - {"epoch": 607, "train_loss": "0.758", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "137611", "train_ups": "0.52", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "290638", "train_lr": "0.00014859", "train_gnorm": "0.266", "train_loss_scale": "2", "train_train_wall": "414", "train_gb_free": "40.8", "train_wall": "548392"}
[2024-10-11 02:29:59,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:29:59,989][fairseq.trainer][INFO] - begin training epoch 608
[2024-10-11 02:29:59,990][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:38:40,070][train_inner][INFO] - {"epoch": 608, "update": 607.338, "loss": "0.756", "ntokens": "263113", "nsentences": "1723.46", "wps": "91961.1", "ups": "0.35", "wpb": "263113", "bsz": "1723.5", "num_updates": "290800", "lr": "0.00014837", "gnorm": "0.262", "loss_scale": "2", "train_wall": "173", "gb_free": "39.6", "wall": "548912"}
[2024-10-11 02:42:32,012][train_inner][INFO] - {"epoch": 608, "update": 607.756, "loss": "0.758", "ntokens": "264230", "nsentences": "1747.17", "wps": "227857", "ups": "0.86", "wpb": "264230", "bsz": "1747.2", "num_updates": "291000", "lr": "0.000148098", "gnorm": "0.255", "loss_scale": "4", "train_wall": "161", "gb_free": "39.6", "wall": "549144"}
[2024-10-11 02:45:08,578][fairseq_cli.train][INFO] - end of epoch 608 (average epoch stats below)
[2024-10-11 02:45:08,594][train][INFO] - {"epoch": 608, "train_loss": "0.758", "train_ntokens": "263596", "train_nsentences": "1753.71", "train_wps": "138935", "train_ups": "0.53", "train_wpb": "263596", "train_bsz": "1753.7", "train_num_updates": "291117", "train_lr": "0.000147939", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "385", "train_gb_free": "40.6", "train_wall": "549301"}
[2024-10-11 02:45:09,886][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:45:10,007][fairseq.trainer][INFO] - begin training epoch 609
[2024-10-11 02:45:10,007][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:52:22,653][train_inner][INFO] - {"epoch": 609, "update": 608.173, "loss": "0.759", "ntokens": "262850", "nsentences": "1746.27", "wps": "89017.5", "ups": "0.34", "wpb": "262850", "bsz": "1746.3", "num_updates": "291200", "lr": "0.000147826", "gnorm": "0.265", "loss_scale": "4", "train_wall": "196", "gb_free": "40.3", "wall": "549735"}
[2024-10-11 02:55:46,868][train_inner][INFO] - {"epoch": 609, "update": 608.591, "loss": "0.757", "ntokens": "264020", "nsentences": "1744.62", "wps": "258599", "ups": "0.98", "wpb": "264020", "bsz": "1744.6", "num_updates": "291400", "lr": "0.000147554", "gnorm": "0.25", "loss_scale": "4", "train_wall": "190", "gb_free": "39.2", "wall": "549939"}
[2024-10-11 03:00:08,140][fairseq_cli.train][INFO] - end of epoch 609 (average epoch stats below)
[2024-10-11 03:00:08,238][train][INFO] - {"epoch": 609, "train_loss": "0.758", "train_ntokens": "263520", "train_nsentences": "1753.71", "train_wps": "140314", "train_ups": "0.53", "train_wpb": "263520", "train_bsz": "1753.7", "train_num_updates": "291596", "train_lr": "0.000147288", "train_gnorm": "0.255", "train_loss_scale": "4", "train_train_wall": "485", "train_gb_free": "39.8", "train_wall": "550200"}
[2024-10-11 03:00:08,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:00:08,445][fairseq.trainer][INFO] - begin training epoch 610
[2024-10-11 03:00:08,446][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:05:46,657][train_inner][INFO] - {"epoch": 610, "update": 609.008, "loss": "0.76", "ntokens": "262614", "nsentences": "1784.34", "wps": "87579.3", "ups": "0.33", "wpb": "262614", "bsz": "1784.3", "num_updates": "291600", "lr": "0.000147283", "gnorm": "0.254", "loss_scale": "4", "train_wall": "210", "gb_free": "39.8", "wall": "550539"}
[2024-10-11 03:09:25,213][train_inner][INFO] - {"epoch": 610, "update": 609.426, "loss": "0.758", "ntokens": "263795", "nsentences": "1775.54", "wps": "241412", "ups": "0.92", "wpb": "263795", "bsz": "1775.5", "num_updates": "291800", "lr": "0.000147011", "gnorm": "0.261", "loss_scale": "4", "train_wall": "192", "gb_free": "40", "wall": "550757"}
[2024-10-11 03:10:30,950][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 03:13:33,331][train_inner][INFO] - {"epoch": 610, "update": 609.846, "loss": "0.757", "ntokens": "264233", "nsentences": "1734.14", "wps": "213029", "ups": "0.81", "wpb": "264233", "bsz": "1734.1", "num_updates": "292000", "lr": "0.000146739", "gnorm": "0.256", "loss_scale": "2", "train_wall": "175", "gb_free": "39.6", "wall": "551006"}
[2024-10-11 03:15:11,202][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 610 @ 292074 updates
[2024-10-11 03:15:11,203][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 03:15:17,297][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 03:15:17,494][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 610 @ 292074 updates, score None) (writing took 6.292425839230418 seconds)
[2024-10-11 03:15:17,500][fairseq_cli.train][INFO] - end of epoch 610 (average epoch stats below)
[2024-10-11 03:15:17,503][train][INFO] - {"epoch": 610, "train_loss": "0.758", "train_ntokens": "263453", "train_nsentences": "1754.01", "train_wps": "138502", "train_ups": "0.53", "train_wpb": "263453", "train_bsz": "1754", "train_num_updates": "292074", "train_lr": "0.000146639", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "459", "train_gb_free": "40.1", "train_wall": "551110"}
[2024-10-11 03:15:17,619][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:15:17,647][fairseq.trainer][INFO] - begin training epoch 611
[2024-10-11 03:15:17,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:22:47,869][train_inner][INFO] - {"epoch": 611, "update": 610.263, "loss": "0.757", "ntokens": "262937", "nsentences": "1733.99", "wps": "94833.5", "ups": "0.36", "wpb": "262937", "bsz": "1734", "num_updates": "292200", "lr": "0.000146467", "gnorm": "0.255", "loss_scale": "2", "train_wall": "203", "gb_free": "39.6", "wall": "551560"}
[2024-10-11 03:26:29,391][train_inner][INFO] - {"epoch": 611, "update": 610.681, "loss": "0.761", "ntokens": "263673", "nsentences": "1796.21", "wps": "238099", "ups": "0.9", "wpb": "263673", "bsz": "1796.2", "num_updates": "292400", "lr": "0.000146196", "gnorm": "0.262", "loss_scale": "2", "train_wall": "194", "gb_free": "39.8", "wall": "551782"}
[2024-10-11 03:29:27,311][fairseq_cli.train][INFO] - end of epoch 611 (average epoch stats below)
[2024-10-11 03:29:27,343][train][INFO] - {"epoch": 611, "train_loss": "0.758", "train_ntokens": "263470", "train_nsentences": "1753.71", "train_wps": "148505", "train_ups": "0.56", "train_wpb": "263470", "train_bsz": "1753.7", "train_num_updates": "292553", "train_lr": "0.000145988", "train_gnorm": "0.26", "train_loss_scale": "2", "train_train_wall": "477", "train_gb_free": "39.1", "train_wall": "551960"}
[2024-10-11 03:29:27,577][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:29:27,619][fairseq.trainer][INFO] - begin training epoch 612
[2024-10-11 03:29:27,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:36:00,739][train_inner][INFO] - {"epoch": 612, "update": 611.098, "loss": "0.759", "ntokens": "262624", "nsentences": "1732.34", "wps": "91934.1", "ups": "0.35", "wpb": "262624", "bsz": "1732.3", "num_updates": "292600", "lr": "0.000145924", "gnorm": "0.275", "loss_scale": "2", "train_wall": "209", "gb_free": "39.2", "wall": "552353"}
[2024-10-11 03:39:42,994][train_inner][INFO] - {"epoch": 612, "update": 611.516, "loss": "0.755", "ntokens": "263954", "nsentences": "1760.05", "wps": "237550", "ups": "0.9", "wpb": "263954", "bsz": "1760", "num_updates": "292800", "lr": "0.000145652", "gnorm": "0.246", "loss_scale": "2", "train_wall": "157", "gb_free": "39.6", "wall": "552575"}
[2024-10-11 03:43:31,821][train_inner][INFO] - {"epoch": 612, "update": 611.933, "loss": "0.761", "ntokens": "264294", "nsentences": "1748.65", "wps": "231014", "ups": "0.87", "wpb": "264294", "bsz": "1748.7", "num_updates": "293000", "lr": "0.00014538", "gnorm": "0.256", "loss_scale": "2", "train_wall": "135", "gb_free": "39.8", "wall": "552804"}
[2024-10-11 03:44:18,583][fairseq_cli.train][INFO] - end of epoch 612 (average epoch stats below)
[2024-10-11 03:44:18,601][train][INFO] - {"epoch": 612, "train_loss": "0.758", "train_ntokens": "263549", "train_nsentences": "1753.71", "train_wps": "141646", "train_ups": "0.54", "train_wpb": "263549", "train_bsz": "1753.7", "train_num_updates": "293032", "train_lr": "0.000145337", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "369", "train_gb_free": "39.8", "train_wall": "552851"}
[2024-10-11 03:44:18,723][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:44:18,763][fairseq.trainer][INFO] - begin training epoch 613
[2024-10-11 03:44:18,764][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:52:59,280][train_inner][INFO] - {"epoch": 613, "update": 612.351, "loss": "0.757", "ntokens": "262806", "nsentences": "1755.51", "wps": "92628.7", "ups": "0.35", "wpb": "262806", "bsz": "1755.5", "num_updates": "293200", "lr": "0.000145109", "gnorm": "0.271", "loss_scale": "2", "train_wall": "174", "gb_free": "39.6", "wall": "553371"}
[2024-10-11 03:56:44,626][train_inner][INFO] - {"epoch": 613, "update": 612.768, "loss": "0.759", "ntokens": "263963", "nsentences": "1756.36", "wps": "234309", "ups": "0.89", "wpb": "263963", "bsz": "1756.4", "num_updates": "293400", "lr": "0.000144837", "gnorm": "0.273", "loss_scale": "2", "train_wall": "158", "gb_free": "39.7", "wall": "553597"}
[2024-10-11 03:58:56,385][fairseq_cli.train][INFO] - end of epoch 613 (average epoch stats below)
[2024-10-11 03:58:56,402][train][INFO] - {"epoch": 613, "train_loss": "0.758", "train_ntokens": "263467", "train_nsentences": "1753.71", "train_wps": "143772", "train_ups": "0.55", "train_wpb": "263467", "train_bsz": "1753.7", "train_num_updates": "293511", "train_lr": "0.000144686", "train_gnorm": "0.267", "train_loss_scale": "2", "train_train_wall": "390", "train_gb_free": "40", "train_wall": "553729"}
[2024-10-11 03:58:56,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:58:56,674][fairseq.trainer][INFO] - begin training epoch 614
[2024-10-11 03:58:56,675][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:06:25,418][train_inner][INFO] - {"epoch": 614, "update": 613.186, "loss": "0.757", "ntokens": "262756", "nsentences": "1744.73", "wps": "90490.6", "ups": "0.34", "wpb": "262756", "bsz": "1744.7", "num_updates": "293600", "lr": "0.000144565", "gnorm": "0.257", "loss_scale": "2", "train_wall": "185", "gb_free": "39.3", "wall": "554178"}
[2024-10-11 04:10:06,695][train_inner][INFO] - {"epoch": 614, "update": 613.603, "loss": "0.756", "ntokens": "263971", "nsentences": "1749.1", "wps": "238636", "ups": "0.9", "wpb": "263971", "bsz": "1749.1", "num_updates": "293800", "lr": "0.000144293", "gnorm": "0.245", "loss_scale": "2", "train_wall": "182", "gb_free": "39.2", "wall": "554399"}
[2024-10-11 04:14:12,781][fairseq_cli.train][INFO] - end of epoch 614 (average epoch stats below)
[2024-10-11 04:14:12,966][train][INFO] - {"epoch": 614, "train_loss": "0.758", "train_ntokens": "263538", "train_nsentences": "1753.71", "train_wps": "137752", "train_ups": "0.52", "train_wpb": "263538", "train_bsz": "1753.7", "train_num_updates": "293990", "train_lr": "0.000144035", "train_gnorm": "0.259", "train_loss_scale": "4", "train_train_wall": "463", "train_gb_free": "39.6", "train_wall": "554645"}
[2024-10-11 04:14:13,603][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:14:13,711][fairseq.trainer][INFO] - begin training epoch 615
[2024-10-11 04:14:13,712][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:19:59,441][train_inner][INFO] - {"epoch": 615, "update": 614.021, "loss": "0.759", "ntokens": "262996", "nsentences": "1754.16", "wps": "88742.8", "ups": "0.34", "wpb": "262996", "bsz": "1754.2", "num_updates": "294000", "lr": "0.000144022", "gnorm": "0.269", "loss_scale": "4", "train_wall": "205", "gb_free": "39.6", "wall": "554992"}
[2024-10-11 04:23:32,815][train_inner][INFO] - {"epoch": 615, "update": 614.438, "loss": "0.756", "ntokens": "264158", "nsentences": "1727.33", "wps": "247618", "ups": "0.94", "wpb": "264158", "bsz": "1727.3", "num_updates": "294200", "lr": "0.00014375", "gnorm": "0.256", "loss_scale": "4", "train_wall": "152", "gb_free": "40", "wall": "555205"}
[2024-10-11 04:27:35,174][train_inner][INFO] - {"epoch": 615, "update": 614.856, "loss": "0.757", "ntokens": "263828", "nsentences": "1774.84", "wps": "217732", "ups": "0.83", "wpb": "263828", "bsz": "1774.8", "num_updates": "294400", "lr": "0.000143478", "gnorm": "0.258", "loss_scale": "4", "train_wall": "179", "gb_free": "40", "wall": "555447"}
[2024-10-11 04:28:39,824][fairseq_cli.train][INFO] - end of epoch 615 (average epoch stats below)
[2024-10-11 04:28:39,827][train][INFO] - {"epoch": 615, "train_loss": "0.758", "train_ntokens": "263500", "train_nsentences": "1753.71", "train_wps": "145605", "train_ups": "0.55", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "294469", "train_lr": "0.000143385", "train_gnorm": "0.256", "train_loss_scale": "4", "train_train_wall": "421", "train_gb_free": "40.1", "train_wall": "555512"}
[2024-10-11 04:28:39,873][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:28:39,895][fairseq.trainer][INFO] - begin training epoch 616
[2024-10-11 04:28:39,896][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:35:55,551][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 04:36:46,757][train_inner][INFO] - {"epoch": 616, "update": 615.276, "loss": "0.759", "ntokens": "262758", "nsentences": "1776.7", "wps": "95281.7", "ups": "0.36", "wpb": "262758", "bsz": "1776.7", "num_updates": "294600", "lr": "0.000143207", "gnorm": "0.259", "loss_scale": "2", "train_wall": "213", "gb_free": "40", "wall": "555999"}
[2024-10-11 04:40:28,895][train_inner][INFO] - {"epoch": 616, "update": 615.693, "loss": "0.757", "ntokens": "263707", "nsentences": "1776.72", "wps": "237440", "ups": "0.9", "wpb": "263707", "bsz": "1776.7", "num_updates": "294800", "lr": "0.000142935", "gnorm": "0.256", "loss_scale": "2", "train_wall": "217", "gb_free": "39.3", "wall": "556221"}
[2024-10-11 04:43:36,232][fairseq_cli.train][INFO] - end of epoch 616 (average epoch stats below)
[2024-10-11 04:43:36,252][train][INFO] - {"epoch": 616, "train_loss": "0.757", "train_ntokens": "263485", "train_nsentences": "1754.86", "train_wps": "140499", "train_ups": "0.53", "train_wpb": "263485", "train_bsz": "1754.9", "train_num_updates": "294947", "train_lr": "0.000142735", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.6", "train_wall": "556408"}
[2024-10-11 04:43:36,379][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:43:36,400][fairseq.trainer][INFO] - begin training epoch 617
[2024-10-11 04:43:36,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:50:05,567][train_inner][INFO] - {"epoch": 617, "update": 616.111, "loss": "0.758", "ntokens": "263067", "nsentences": "1723.69", "wps": "91238.1", "ups": "0.35", "wpb": "263067", "bsz": "1723.7", "num_updates": "295000", "lr": "0.000142663", "gnorm": "0.271", "loss_scale": "2", "train_wall": "254", "gb_free": "39.7", "wall": "556798"}
[2024-10-11 04:53:33,365][train_inner][INFO] - {"epoch": 617, "update": 616.528, "loss": "0.756", "ntokens": "264189", "nsentences": "1735.47", "wps": "254288", "ups": "0.96", "wpb": "264189", "bsz": "1735.5", "num_updates": "295200", "lr": "0.000142391", "gnorm": "0.27", "loss_scale": "2", "train_wall": "202", "gb_free": "39.6", "wall": "557006"}
[2024-10-11 04:57:28,966][train_inner][INFO] - {"epoch": 617, "update": 616.946, "loss": "0.757", "ntokens": "263931", "nsentences": "1768.15", "wps": "224062", "ups": "0.85", "wpb": "263931", "bsz": "1768.2", "num_updates": "295400", "lr": "0.00014212", "gnorm": "0.273", "loss_scale": "2", "train_wall": "231", "gb_free": "39.8", "wall": "557241"}
[2024-10-11 04:58:16,262][fairseq_cli.train][INFO] - end of epoch 617 (average epoch stats below)
[2024-10-11 04:58:16,306][train][INFO] - {"epoch": 617, "train_loss": "0.757", "train_ntokens": "263518", "train_nsentences": "1753.71", "train_wps": "143434", "train_ups": "0.54", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "295426", "train_lr": "0.000142084", "train_gnorm": "0.277", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "39.6", "train_wall": "557288"}
[2024-10-11 04:58:16,415][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:58:16,450][fairseq.trainer][INFO] - begin training epoch 618
[2024-10-11 04:58:16,451][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:06:53,441][train_inner][INFO] - {"epoch": 618, "update": 617.363, "loss": "0.758", "ntokens": "262597", "nsentences": "1788.88", "wps": "93042.4", "ups": "0.35", "wpb": "262597", "bsz": "1788.9", "num_updates": "295600", "lr": "0.000141848", "gnorm": "0.262", "loss_scale": "2", "train_wall": "243", "gb_free": "39.2", "wall": "557806"}
[2024-10-11 05:11:14,880][train_inner][INFO] - {"epoch": 618, "update": 617.781, "loss": "0.756", "ntokens": "264170", "nsentences": "1712.85", "wps": "202100", "ups": "0.77", "wpb": "264170", "bsz": "1712.9", "num_updates": "295800", "lr": "0.000141576", "gnorm": "0.275", "loss_scale": "2", "train_wall": "256", "gb_free": "39.6", "wall": "558067"}
[2024-10-11 05:13:38,748][fairseq_cli.train][INFO] - end of epoch 618 (average epoch stats below)
[2024-10-11 05:13:38,769][train][INFO] - {"epoch": 618, "train_loss": "0.757", "train_ntokens": "263515", "train_nsentences": "1753.71", "train_wps": "136835", "train_ups": "0.52", "train_wpb": "263515", "train_bsz": "1753.7", "train_num_updates": "295905", "train_lr": "0.000141433", "train_gnorm": "0.269", "train_loss_scale": "2", "train_train_wall": "592", "train_gb_free": "39.8", "train_wall": "558211"}
[2024-10-11 05:13:38,980][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:13:39,007][fairseq.trainer][INFO] - begin training epoch 619
[2024-10-11 05:13:39,008][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:20:51,736][train_inner][INFO] - {"epoch": 619, "update": 618.198, "loss": "0.757", "ntokens": "262787", "nsentences": "1751.05", "wps": "91113.3", "ups": "0.35", "wpb": "262787", "bsz": "1751", "num_updates": "296000", "lr": "0.000141304", "gnorm": "0.267", "loss_scale": "2", "train_wall": "252", "gb_free": "40.5", "wall": "558644"}
[2024-10-11 05:24:39,802][train_inner][INFO] - {"epoch": 619, "update": 618.616, "loss": "0.758", "ntokens": "263576", "nsentences": "1820.68", "wps": "231175", "ups": "0.88", "wpb": "263576", "bsz": "1820.7", "num_updates": "296200", "lr": "0.000141033", "gnorm": "0.266", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "558872"}
[2024-10-11 05:27:55,210][fairseq_cli.train][INFO] - end of epoch 619 (average epoch stats below)
[2024-10-11 05:27:55,238][train][INFO] - {"epoch": 619, "train_loss": "0.757", "train_ntokens": "263491", "train_nsentences": "1753.71", "train_wps": "147370", "train_ups": "0.56", "train_wpb": "263491", "train_bsz": "1753.7", "train_num_updates": "296384", "train_lr": "0.000140783", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "526", "train_gb_free": "39.2", "train_wall": "559067"}
[2024-10-11 05:27:55,476][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:27:55,536][fairseq.trainer][INFO] - begin training epoch 620
[2024-10-11 05:27:55,536][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:34:16,049][train_inner][INFO] - {"epoch": 620, "update": 619.033, "loss": "0.756", "ntokens": "263256", "nsentences": "1696.08", "wps": "91370.7", "ups": "0.35", "wpb": "263256", "bsz": "1696.1", "num_updates": "296400", "lr": "0.000140761", "gnorm": "0.255", "loss_scale": "2", "train_wall": "234", "gb_free": "39.8", "wall": "559448"}
[2024-10-11 05:37:52,007][train_inner][INFO] - {"epoch": 620, "update": 619.451, "loss": "0.755", "ntokens": "263944", "nsentences": "1753.64", "wps": "244472", "ups": "0.93", "wpb": "263944", "bsz": "1753.6", "num_updates": "296600", "lr": "0.000140489", "gnorm": "0.256", "loss_scale": "2", "train_wall": "211", "gb_free": "39.2", "wall": "559664"}
[2024-10-11 05:41:33,421][train_inner][INFO] - {"epoch": 620, "update": 619.868, "loss": "0.756", "ntokens": "264363", "nsentences": "1726.02", "wps": "238814", "ups": "0.9", "wpb": "264363", "bsz": "1726", "num_updates": "296800", "lr": "0.000140217", "gnorm": "0.26", "loss_scale": "4", "train_wall": "212", "gb_free": "39.6", "wall": "559886"}
[2024-10-11 05:42:52,143][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 620 @ 296863 updates
[2024-10-11 05:42:52,145][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 05:43:02,721][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 05:43:02,855][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 620 @ 296863 updates, score None) (writing took 10.71176430862397 seconds)
[2024-10-11 05:43:02,856][fairseq_cli.train][INFO] - end of epoch 620 (average epoch stats below)
[2024-10-11 05:43:02,861][train][INFO] - {"epoch": 620, "train_loss": "0.757", "train_ntokens": "263545", "train_nsentences": "1753.71", "train_wps": "139092", "train_ups": "0.53", "train_wpb": "263545", "train_bsz": "1753.7", "train_num_updates": "296863", "train_lr": "0.000140132", "train_gnorm": "0.263", "train_loss_scale": "4", "train_train_wall": "544", "train_gb_free": "40.5", "train_wall": "559975"}
[2024-10-11 05:43:02,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:43:02,947][fairseq.trainer][INFO] - begin training epoch 621
[2024-10-11 05:43:02,948][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:51:13,026][train_inner][INFO] - {"epoch": 621, "update": 620.286, "loss": "0.756", "ntokens": "262457", "nsentences": "1778.26", "wps": "90570.7", "ups": "0.35", "wpb": "262458", "bsz": "1778.3", "num_updates": "297000", "lr": "0.000139946", "gnorm": "0.269", "loss_scale": "4", "train_wall": "258", "gb_free": "39.2", "wall": "560465"}
[2024-10-11 05:54:56,641][train_inner][INFO] - {"epoch": 621, "update": 620.704, "loss": "0.757", "ntokens": "264060", "nsentences": "1766.14", "wps": "236203", "ups": "0.89", "wpb": "264060", "bsz": "1766.1", "num_updates": "297200", "lr": "0.000139674", "gnorm": "0.253", "loss_scale": "4", "train_wall": "219", "gb_free": "39.2", "wall": "560689"}
[2024-10-11 05:58:08,750][fairseq_cli.train][INFO] - end of epoch 621 (average epoch stats below)
[2024-10-11 05:58:08,765][train][INFO] - {"epoch": 621, "train_loss": "0.757", "train_ntokens": "263493", "train_nsentences": "1753.71", "train_wps": "139325", "train_ups": "0.53", "train_wpb": "263493", "train_bsz": "1753.7", "train_num_updates": "297342", "train_lr": "0.000139481", "train_gnorm": "0.253", "train_loss_scale": "4", "train_train_wall": "588", "train_gb_free": "39.6", "train_wall": "560881"}
[2024-10-11 05:58:08,841][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:58:08,858][fairseq.trainer][INFO] - begin training epoch 622
[2024-10-11 05:58:08,858][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:04:39,059][train_inner][INFO] - {"epoch": 622, "update": 621.121, "loss": "0.757", "ntokens": "262859", "nsentences": "1748.04", "wps": "90266.6", "ups": "0.34", "wpb": "262859", "bsz": "1748", "num_updates": "297400", "lr": "0.000139402", "gnorm": "0.26", "loss_scale": "4", "train_wall": "253", "gb_free": "39.3", "wall": "561271"}
[2024-10-11 06:08:16,744][train_inner][INFO] - {"epoch": 622, "update": 621.539, "loss": "0.754", "ntokens": "263865", "nsentences": "1741.95", "wps": "242443", "ups": "0.92", "wpb": "263865", "bsz": "1742", "num_updates": "297600", "lr": "0.00013913", "gnorm": "0.271", "loss_scale": "4", "train_wall": "212", "gb_free": "40", "wall": "561489"}
[2024-10-11 06:08:53,368][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 06:12:10,656][train_inner][INFO] - {"epoch": 622, "update": 621.958, "loss": "0.759", "ntokens": "263860", "nsentences": "1763.36", "wps": "225616", "ups": "0.86", "wpb": "263860", "bsz": "1763.4", "num_updates": "297800", "lr": "0.000138859", "gnorm": "0.253", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "561723"}
[2024-10-11 06:12:37,769][fairseq_cli.train][INFO] - end of epoch 622 (average epoch stats below)
[2024-10-11 06:12:37,790][train][INFO] - {"epoch": 622, "train_loss": "0.756", "train_ntokens": "263401", "train_nsentences": "1753.77", "train_wps": "144884", "train_ups": "0.55", "train_wpb": "263401", "train_bsz": "1753.8", "train_num_updates": "297820", "train_lr": "0.000138832", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "532", "train_gb_free": "40.1", "train_wall": "561750"}
[2024-10-11 06:12:38,171][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:12:38,215][fairseq.trainer][INFO] - begin training epoch 623
[2024-10-11 06:12:38,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:21:35,858][train_inner][INFO] - {"epoch": 623, "update": 622.376, "loss": "0.755", "ntokens": "263087", "nsentences": "1724.2", "wps": "93098.6", "ups": "0.35", "wpb": "263087", "bsz": "1724.2", "num_updates": "298000", "lr": "0.000138587", "gnorm": "0.255", "loss_scale": "2", "train_wall": "231", "gb_free": "39.2", "wall": "562288"}
[2024-10-11 06:25:45,069][train_inner][INFO] - {"epoch": 623, "update": 622.793, "loss": "0.758", "ntokens": "263770", "nsentences": "1783.64", "wps": "211716", "ups": "0.8", "wpb": "263770", "bsz": "1783.6", "num_updates": "298200", "lr": "0.000138315", "gnorm": "0.251", "loss_scale": "2", "train_wall": "243", "gb_free": "40.3", "wall": "562537"}
[2024-10-11 06:27:46,140][fairseq_cli.train][INFO] - end of epoch 623 (average epoch stats below)
[2024-10-11 06:27:46,145][train][INFO] - {"epoch": 623, "train_loss": "0.756", "train_ntokens": "263474", "train_nsentences": "1753.71", "train_wps": "138938", "train_ups": "0.53", "train_wpb": "263474", "train_bsz": "1753.7", "train_num_updates": "298299", "train_lr": "0.000138181", "train_gnorm": "0.258", "train_loss_scale": "2", "train_train_wall": "566", "train_gb_free": "40", "train_wall": "562658"}
[2024-10-11 06:27:46,215][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:27:46,236][fairseq.trainer][INFO] - begin training epoch 624
[2024-10-11 06:27:46,237][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:35:16,995][train_inner][INFO] - {"epoch": 624, "update": 623.211, "loss": "0.755", "ntokens": "262887", "nsentences": "1727.83", "wps": "91933.8", "ups": "0.35", "wpb": "262887", "bsz": "1727.8", "num_updates": "298400", "lr": "0.000138043", "gnorm": "0.275", "loss_scale": "2", "train_wall": "233", "gb_free": "39.7", "wall": "563109"}
[2024-10-11 06:38:54,360][train_inner][INFO] - {"epoch": 624, "update": 623.628, "loss": "0.76", "ntokens": "263461", "nsentences": "1823.44", "wps": "242450", "ups": "0.92", "wpb": "263461", "bsz": "1823.4", "num_updates": "298600", "lr": "0.000137772", "gnorm": "0.263", "loss_scale": "2", "train_wall": "202", "gb_free": "39.4", "wall": "563327"}
[2024-10-11 06:42:26,961][fairseq_cli.train][INFO] - end of epoch 624 (average epoch stats below)
[2024-10-11 06:42:26,976][train][INFO] - {"epoch": 624, "train_loss": "0.757", "train_ntokens": "263535", "train_nsentences": "1753.71", "train_wps": "143317", "train_ups": "0.54", "train_wpb": "263535", "train_bsz": "1753.7", "train_num_updates": "298778", "train_lr": "0.00013753", "train_gnorm": "0.262", "train_loss_scale": "2", "train_train_wall": "512", "train_gb_free": "39.6", "train_wall": "563539"}
[2024-10-11 06:42:27,118][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:42:27,125][fairseq.trainer][INFO] - begin training epoch 625
[2024-10-11 06:42:27,125][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:48:26,812][train_inner][INFO] - {"epoch": 625, "update": 624.046, "loss": "0.755", "ntokens": "263237", "nsentences": "1704.66", "wps": "91970.7", "ups": "0.35", "wpb": "263237", "bsz": "1704.7", "num_updates": "298800", "lr": "0.0001375", "gnorm": "0.256", "loss_scale": "2", "train_wall": "237", "gb_free": "40.1", "wall": "563899"}
[2024-10-11 06:52:11,758][train_inner][INFO] - {"epoch": 625, "update": 624.463, "loss": "0.754", "ntokens": "264122", "nsentences": "1748.65", "wps": "234874", "ups": "0.89", "wpb": "264122", "bsz": "1748.7", "num_updates": "299000", "lr": "0.000137228", "gnorm": "0.256", "loss_scale": "2", "train_wall": "220", "gb_free": "39.2", "wall": "564124"}
[2024-10-11 06:56:28,058][train_inner][INFO] - {"epoch": 625, "update": 624.881, "loss": "0.755", "ntokens": "264250", "nsentences": "1729.32", "wps": "206228", "ups": "0.78", "wpb": "264250", "bsz": "1729.3", "num_updates": "299200", "lr": "0.000136957", "gnorm": "0.274", "loss_scale": "2", "train_wall": "250", "gb_free": "40", "wall": "564380"}
[2024-10-11 06:57:51,965][fairseq_cli.train][INFO] - end of epoch 625 (average epoch stats below)
[2024-10-11 06:57:51,978][train][INFO] - {"epoch": 625, "train_loss": "0.756", "train_ntokens": "263505", "train_nsentences": "1753.71", "train_wps": "136457", "train_ups": "0.52", "train_wpb": "263506", "train_bsz": "1753.7", "train_num_updates": "299257", "train_lr": "0.000136879", "train_gnorm": "0.264", "train_loss_scale": "2", "train_train_wall": "593", "train_gb_free": "40.2", "train_wall": "564464"}
[2024-10-11 06:57:52,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:57:52,128][fairseq.trainer][INFO] - begin training epoch 626
[2024-10-11 06:57:52,129][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:06:21,798][train_inner][INFO] - {"epoch": 626, "update": 625.299, "loss": "0.756", "ntokens": "262612", "nsentences": "1753.99", "wps": "88464.8", "ups": "0.34", "wpb": "262612", "bsz": "1754", "num_updates": "299400", "lr": "0.000136685", "gnorm": "0.256", "loss_scale": "2", "train_wall": "246", "gb_free": "40.1", "wall": "564974"}
[2024-10-11 07:10:29,920][train_inner][INFO] - {"epoch": 626, "update": 625.716, "loss": "0.756", "ntokens": "263820", "nsentences": "1768.38", "wps": "212669", "ups": "0.81", "wpb": "263820", "bsz": "1768.4", "num_updates": "299600", "lr": "0.000136413", "gnorm": "0.258", "loss_scale": "2", "train_wall": "242", "gb_free": "40", "wall": "565222"}
[2024-10-11 07:13:13,098][fairseq_cli.train][INFO] - end of epoch 626 (average epoch stats below)
[2024-10-11 07:13:13,132][train][INFO] - {"epoch": 626, "train_loss": "0.756", "train_ntokens": "263388", "train_nsentences": "1753.71", "train_wps": "136963", "train_ups": "0.52", "train_wpb": "263388", "train_bsz": "1753.7", "train_num_updates": "299736", "train_lr": "0.000136228", "train_gnorm": "0.256", "train_loss_scale": "4", "train_train_wall": "567", "train_gb_free": "39.2", "train_wall": "565385"}
[2024-10-11 07:13:13,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:13:13,328][fairseq.trainer][INFO] - begin training epoch 627
[2024-10-11 07:13:13,329][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:20:02,708][train_inner][INFO] - {"epoch": 627, "update": 626.134, "loss": "0.756", "ntokens": "262358", "nsentences": "1790.16", "wps": "91611.9", "ups": "0.35", "wpb": "262358", "bsz": "1790.2", "num_updates": "299800", "lr": "0.000136141", "gnorm": "0.26", "loss_scale": "4", "train_wall": "254", "gb_free": "39.8", "wall": "565795"}
[2024-10-11 07:23:29,253][train_inner][INFO] - {"epoch": 627, "update": 626.551, "loss": "0.755", "ntokens": "263720", "nsentences": "1773.89", "wps": "255377", "ups": "0.97", "wpb": "263720", "bsz": "1773.9", "num_updates": "300000", "lr": "0.00013587", "gnorm": "0.272", "loss_scale": "4", "train_wall": "201", "gb_free": "39.8", "wall": "566001"}
[2024-10-11 07:23:29,281][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 627 @ 300000 updates
[2024-10-11 07:23:29,282][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_627_300000.pt
[2024-10-11 07:23:32,904][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_627_300000.pt
[2024-10-11 07:23:37,910][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_627_300000.pt (epoch 627 @ 300000 updates, score None) (writing took 8.628648626618087 seconds)
[2024-10-11 07:25:38,894][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 07:27:07,320][train_inner][INFO] - {"epoch": 627, "update": 626.971, "loss": "0.756", "ntokens": "264255", "nsentences": "1729.46", "wps": "242380", "ups": "0.92", "wpb": "264255", "bsz": "1729.5", "num_updates": "300200", "lr": "0.000135598", "gnorm": "0.256", "loss_scale": "2", "train_wall": "204", "gb_free": "40", "wall": "566219"}
[2024-10-11 07:27:42,943][fairseq_cli.train][INFO] - end of epoch 627 (average epoch stats below)
[2024-10-11 07:27:42,958][train][INFO] - {"epoch": 627, "train_loss": "0.755", "train_ntokens": "263457", "train_nsentences": "1753.61", "train_wps": "144785", "train_ups": "0.55", "train_wpb": "263457", "train_bsz": "1753.6", "train_num_updates": "300214", "train_lr": "0.000135579", "train_gnorm": "0.265", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "39.2", "train_wall": "566255"}
[2024-10-11 07:27:43,112][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:27:43,155][fairseq.trainer][INFO] - begin training epoch 628
[2024-10-11 07:27:43,156][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:36:42,871][train_inner][INFO] - {"epoch": 628, "update": 627.388, "loss": "0.753", "ntokens": "263052", "nsentences": "1724.19", "wps": "91413", "ups": "0.35", "wpb": "263052", "bsz": "1724.2", "num_updates": "300400", "lr": "0.000135326", "gnorm": "0.251", "loss_scale": "2", "train_wall": "241", "gb_free": "39.8", "wall": "566795"}
[2024-10-11 07:40:44,444][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 07:41:01,355][train_inner][INFO] - {"epoch": 628, "update": 627.808, "loss": "0.754", "ntokens": "263988", "nsentences": "1760.58", "wps": "204273", "ups": "0.77", "wpb": "263988", "bsz": "1760.6", "num_updates": "300600", "lr": "0.000135054", "gnorm": "0.266", "loss_scale": "1", "train_wall": "252", "gb_free": "39.6", "wall": "567054"}
[2024-10-11 07:43:08,164][fairseq_cli.train][INFO] - end of epoch 628 (average epoch stats below)
[2024-10-11 07:43:08,167][train][INFO] - {"epoch": 628, "train_loss": "0.754", "train_ntokens": "263510", "train_nsentences": "1751.34", "train_wps": "136141", "train_ups": "0.52", "train_wpb": "263510", "train_bsz": "1751.3", "train_num_updates": "300692", "train_lr": "0.000134929", "train_gnorm": "0.257", "train_loss_scale": "1", "train_train_wall": "584", "train_gb_free": "39.8", "train_wall": "567180"}
[2024-10-11 07:43:08,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:43:08,317][fairseq.trainer][INFO] - begin training epoch 629
[2024-10-11 07:43:08,317][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:50:31,776][train_inner][INFO] - {"epoch": 629, "update": 628.225, "loss": "0.757", "ntokens": "262193", "nsentences": "1806.02", "wps": "91931.8", "ups": "0.35", "wpb": "262193", "bsz": "1806", "num_updates": "300800", "lr": "0.000134783", "gnorm": "0.263", "loss_scale": "1", "train_wall": "265", "gb_free": "39.1", "wall": "567624"}
[2024-10-11 07:54:28,454][train_inner][INFO] - {"epoch": 629, "update": 628.643, "loss": "0.754", "ntokens": "264346", "nsentences": "1745.45", "wps": "223406", "ups": "0.85", "wpb": "264346", "bsz": "1745.5", "num_updates": "301000", "lr": "0.000134511", "gnorm": "0.257", "loss_scale": "1", "train_wall": "231", "gb_free": "40.8", "wall": "567861"}
[2024-10-11 07:58:02,709][fairseq_cli.train][INFO] - end of epoch 629 (average epoch stats below)
[2024-10-11 07:58:02,720][train][INFO] - {"epoch": 629, "train_loss": "0.755", "train_ntokens": "263523", "train_nsentences": "1753.71", "train_wps": "141110", "train_ups": "0.54", "train_wpb": "263523", "train_bsz": "1753.7", "train_num_updates": "301171", "train_lr": "0.000134279", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "581", "train_gb_free": "39.8", "train_wall": "568075"}
[2024-10-11 07:58:02,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:58:02,804][fairseq.trainer][INFO] - begin training epoch 630
[2024-10-11 07:58:02,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:04:11,425][train_inner][INFO] - {"epoch": 630, "update": 629.061, "loss": "0.752", "ntokens": "263138", "nsentences": "1704.91", "wps": "90279.3", "ups": "0.34", "wpb": "263138", "bsz": "1704.9", "num_updates": "301200", "lr": "0.000134239", "gnorm": "0.255", "loss_scale": "1", "train_wall": "243", "gb_free": "39.8", "wall": "568444"}
[2024-10-11 08:07:41,308][train_inner][INFO] - {"epoch": 630, "update": 629.478, "loss": "0.753", "ntokens": "263912", "nsentences": "1756.49", "wps": "251547", "ups": "0.95", "wpb": "263912", "bsz": "1756.5", "num_updates": "301400", "lr": "0.000133967", "gnorm": "0.244", "loss_scale": "1", "train_wall": "205", "gb_free": "39.6", "wall": "568653"}
[2024-10-11 08:11:45,495][train_inner][INFO] - {"epoch": 630, "update": 629.896, "loss": "0.758", "ntokens": "264132", "nsentences": "1770.63", "wps": "216348", "ups": "0.82", "wpb": "264132", "bsz": "1770.6", "num_updates": "301600", "lr": "0.000133696", "gnorm": "0.249", "loss_scale": "1", "train_wall": "238", "gb_free": "40.3", "wall": "568898"}
[2024-10-11 08:12:57,391][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 630 @ 301650 updates
[2024-10-11 08:12:57,398][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 08:13:04,479][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 08:13:04,565][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 630 @ 301650 updates, score None) (writing took 7.1741500236094 seconds)
[2024-10-11 08:13:04,570][fairseq_cli.train][INFO] - end of epoch 630 (average epoch stats below)
[2024-10-11 08:13:04,582][train][INFO] - {"epoch": 630, "train_loss": "0.755", "train_ntokens": "263575", "train_nsentences": "1753.71", "train_wps": "139994", "train_ups": "0.53", "train_wpb": "263575", "train_bsz": "1753.7", "train_num_updates": "301650", "train_lr": "0.000133628", "train_gnorm": "0.248", "train_loss_scale": "1", "train_train_wall": "547", "train_gb_free": "39.7", "train_wall": "568977"}
[2024-10-11 08:13:04,638][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:13:04,665][fairseq.trainer][INFO] - begin training epoch 631
[2024-10-11 08:13:04,665][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:21:31,294][train_inner][INFO] - {"epoch": 631, "update": 630.313, "loss": "0.757", "ntokens": "262807", "nsentences": "1750.68", "wps": "89728.9", "ups": "0.34", "wpb": "262807", "bsz": "1750.7", "num_updates": "301800", "lr": "0.000133424", "gnorm": "0.262", "loss_scale": "1", "train_wall": "265", "gb_free": "40.5", "wall": "569483"}
[2024-10-11 08:25:18,005][train_inner][INFO] - {"epoch": 631, "update": 630.731, "loss": "0.754", "ntokens": "263649", "nsentences": "1778.56", "wps": "232598", "ups": "0.88", "wpb": "263649", "bsz": "1778.6", "num_updates": "302000", "lr": "0.000133152", "gnorm": "0.257", "loss_scale": "1", "train_wall": "222", "gb_free": "39.8", "wall": "569710"}
[2024-10-11 08:27:27,416][fairseq_cli.train][INFO] - end of epoch 631 (average epoch stats below)
[2024-10-11 08:27:27,444][train][INFO] - {"epoch": 631, "train_loss": "0.755", "train_ntokens": "263410", "train_nsentences": "1753.71", "train_wps": "146228", "train_ups": "0.56", "train_wpb": "263410", "train_bsz": "1753.7", "train_num_updates": "302129", "train_lr": "0.000132977", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "543", "train_gb_free": "40.1", "train_wall": "569840"}
[2024-10-11 08:27:27,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:27:27,559][fairseq.trainer][INFO] - begin training epoch 632
[2024-10-11 08:27:27,560][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:34:26,615][train_inner][INFO] - {"epoch": 632, "update": 631.148, "loss": "0.754", "ntokens": "263034", "nsentences": "1712.92", "wps": "95894.2", "ups": "0.36", "wpb": "263034", "bsz": "1712.9", "num_updates": "302200", "lr": "0.00013288", "gnorm": "0.257", "loss_scale": "1", "train_wall": "219", "gb_free": "40", "wall": "570259"}
[2024-10-11 08:38:12,659][train_inner][INFO] - {"epoch": 632, "update": 631.566, "loss": "0.755", "ntokens": "263762", "nsentences": "1778.78", "wps": "233388", "ups": "0.88", "wpb": "263762", "bsz": "1778.8", "num_updates": "302400", "lr": "0.000132609", "gnorm": "0.266", "loss_scale": "1", "train_wall": "221", "gb_free": "40.3", "wall": "570485"}
[2024-10-11 08:41:48,689][train_inner][INFO] - {"epoch": 632, "update": 631.983, "loss": "0.757", "ntokens": "264191", "nsentences": "1738.85", "wps": "244701", "ups": "0.93", "wpb": "264191", "bsz": "1738.9", "num_updates": "302600", "lr": "0.000132337", "gnorm": "0.26", "loss_scale": "1", "train_wall": "211", "gb_free": "39.7", "wall": "570701"}
[2024-10-11 08:42:15,209][fairseq_cli.train][INFO] - end of epoch 632 (average epoch stats below)
[2024-10-11 08:42:15,270][train][INFO] - {"epoch": 632, "train_loss": "0.755", "train_ntokens": "263531", "train_nsentences": "1753.71", "train_wps": "142189", "train_ups": "0.54", "train_wpb": "263531", "train_bsz": "1753.7", "train_num_updates": "302608", "train_lr": "0.000132326", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "550", "train_gb_free": "39.8", "train_wall": "570727"}
[2024-10-11 08:42:15,454][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:42:15,466][fairseq.trainer][INFO] - begin training epoch 633
[2024-10-11 08:42:15,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:51:22,716][train_inner][INFO] - {"epoch": 633, "update": 632.401, "loss": "0.751", "ntokens": "263210", "nsentences": "1714.52", "wps": "91716.1", "ups": "0.35", "wpb": "263210", "bsz": "1714.5", "num_updates": "302800", "lr": "0.000132065", "gnorm": "0.255", "loss_scale": "2", "train_wall": "240", "gb_free": "39.6", "wall": "571275"}
[2024-10-11 08:55:42,274][train_inner][INFO] - {"epoch": 633, "update": 632.818, "loss": "0.756", "ntokens": "263992", "nsentences": "1763.43", "wps": "203454", "ups": "0.77", "wpb": "263992", "bsz": "1763.4", "num_updates": "303000", "lr": "0.000131793", "gnorm": "0.25", "loss_scale": "2", "train_wall": "254", "gb_free": "39.6", "wall": "571534"}
[2024-10-11 08:57:46,978][fairseq_cli.train][INFO] - end of epoch 633 (average epoch stats below)
[2024-10-11 08:57:47,024][train][INFO] - {"epoch": 633, "train_loss": "0.755", "train_ntokens": "263556", "train_nsentences": "1753.71", "train_wps": "135493", "train_ups": "0.51", "train_wpb": "263556", "train_bsz": "1753.7", "train_num_updates": "303087", "train_lr": "0.000131675", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "589", "train_gb_free": "39.7", "train_wall": "571659"}
[2024-10-11 08:57:47,278][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:57:47,299][fairseq.trainer][INFO] - begin training epoch 634
[2024-10-11 08:57:47,300][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:05:12,691][train_inner][INFO] - {"epoch": 634, "update": 633.236, "loss": "0.756", "ntokens": "262433", "nsentences": "1797.74", "wps": "92018.3", "ups": "0.35", "wpb": "262433", "bsz": "1797.7", "num_updates": "303200", "lr": "0.000131522", "gnorm": "0.256", "loss_scale": "2", "train_wall": "238", "gb_free": "39.2", "wall": "572105"}
[2024-10-11 09:09:02,191][train_inner][INFO] - {"epoch": 634, "update": 633.653, "loss": "0.754", "ntokens": "264089", "nsentences": "1756.89", "wps": "230169", "ups": "0.87", "wpb": "264089", "bsz": "1756.9", "num_updates": "303400", "lr": "0.00013125", "gnorm": "0.252", "loss_scale": "2", "train_wall": "224", "gb_free": "40.2", "wall": "572334"}
[2024-10-11 09:12:54,277][fairseq_cli.train][INFO] - end of epoch 634 (average epoch stats below)
[2024-10-11 09:12:54,305][train][INFO] - {"epoch": 634, "train_loss": "0.754", "train_ntokens": "263592", "train_nsentences": "1753.71", "train_wps": "139172", "train_ups": "0.53", "train_wpb": "263592", "train_bsz": "1753.7", "train_num_updates": "303566", "train_lr": "0.000131024", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "568", "train_gb_free": "39.3", "train_wall": "572566"}
[2024-10-11 09:12:54,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:12:54,619][fairseq.trainer][INFO] - begin training epoch 635
[2024-10-11 09:12:54,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:19:09,466][train_inner][INFO] - {"epoch": 635, "update": 634.071, "loss": "0.754", "ntokens": "263071", "nsentences": "1730.29", "wps": "86642.4", "ups": "0.33", "wpb": "263070", "bsz": "1730.3", "num_updates": "303600", "lr": "0.000130978", "gnorm": "0.257", "loss_scale": "2", "train_wall": "292", "gb_free": "39.8", "wall": "572942"}
[2024-10-11 09:22:37,338][train_inner][INFO] - {"epoch": 635, "update": 634.489, "loss": "0.752", "ntokens": "264079", "nsentences": "1734.62", "wps": "254111", "ups": "0.96", "wpb": "264079", "bsz": "1734.6", "num_updates": "303800", "lr": "0.000130707", "gnorm": "0.271", "loss_scale": "2", "train_wall": "203", "gb_free": "40.1", "wall": "573150"}
[2024-10-11 09:26:18,433][train_inner][INFO] - {"epoch": 635, "update": 634.906, "loss": "0.755", "ntokens": "263799", "nsentences": "1771.41", "wps": "238671", "ups": "0.9", "wpb": "263799", "bsz": "1771.4", "num_updates": "304000", "lr": "0.000130435", "gnorm": "0.259", "loss_scale": "2", "train_wall": "216", "gb_free": "39.3", "wall": "573371"}
[2024-10-11 09:27:22,069][fairseq_cli.train][INFO] - end of epoch 635 (average epoch stats below)
[2024-10-11 09:27:22,090][train][INFO] - {"epoch": 635, "train_loss": "0.754", "train_ntokens": "263417", "train_nsentences": "1753.71", "train_wps": "145408", "train_ups": "0.55", "train_wpb": "263417", "train_bsz": "1753.7", "train_num_updates": "304045", "train_lr": "0.000130374", "train_gnorm": "0.263", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "40", "train_wall": "573434"}
[2024-10-11 09:27:22,183][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:27:22,205][fairseq.trainer][INFO] - begin training epoch 636
[2024-10-11 09:27:22,206][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:34:04,050][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 09:35:41,054][train_inner][INFO] - {"epoch": 636, "update": 635.326, "loss": "0.753", "ntokens": "262689", "nsentences": "1760.66", "wps": "93382.4", "ups": "0.36", "wpb": "262689", "bsz": "1760.7", "num_updates": "304200", "lr": "0.000130163", "gnorm": "0.248", "loss_scale": "1", "train_wall": "241", "gb_free": "39.3", "wall": "573933"}
[2024-10-11 09:39:38,821][train_inner][INFO] - {"epoch": 636, "update": 635.743, "loss": "0.755", "ntokens": "263792", "nsentences": "1764.09", "wps": "221903", "ups": "0.84", "wpb": "263792", "bsz": "1764.1", "num_updates": "304400", "lr": "0.000129891", "gnorm": "0.267", "loss_scale": "1", "train_wall": "232", "gb_free": "39.7", "wall": "574171"}
[2024-10-11 09:41:56,329][fairseq_cli.train][INFO] - end of epoch 636 (average epoch stats below)
[2024-10-11 09:41:56,364][train][INFO] - {"epoch": 636, "train_loss": "0.753", "train_ntokens": "263400", "train_nsentences": "1754.19", "train_wps": "144013", "train_ups": "0.55", "train_wpb": "263400", "train_bsz": "1754.2", "train_num_updates": "304523", "train_lr": "0.000129724", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "546", "train_gb_free": "39.7", "train_wall": "574309"}
[2024-10-11 09:41:56,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:41:56,579][fairseq.trainer][INFO] - begin training epoch 637
[2024-10-11 09:41:56,579][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:48:54,510][train_inner][INFO] - {"epoch": 637, "update": 636.161, "loss": "0.751", "ntokens": "262947", "nsentences": "1738.87", "wps": "94641.5", "ups": "0.36", "wpb": "262947", "bsz": "1738.9", "num_updates": "304600", "lr": "0.00012962", "gnorm": "0.261", "loss_scale": "1", "train_wall": "223", "gb_free": "39.7", "wall": "574727"}
[2024-10-11 09:52:23,452][train_inner][INFO] - {"epoch": 637, "update": 636.578, "loss": "0.756", "ntokens": "263769", "nsentences": "1784.68", "wps": "252526", "ups": "0.96", "wpb": "263769", "bsz": "1784.7", "num_updates": "304800", "lr": "0.000129348", "gnorm": "0.263", "loss_scale": "1", "train_wall": "201", "gb_free": "39.2", "wall": "574936"}
[2024-10-11 09:56:23,001][train_inner][INFO] - {"epoch": 637, "update": 636.996, "loss": "0.752", "ntokens": "264016", "nsentences": "1735.66", "wps": "220457", "ups": "0.83", "wpb": "264016", "bsz": "1735.7", "num_updates": "305000", "lr": "0.000129076", "gnorm": "0.261", "loss_scale": "1", "train_wall": "189", "gb_free": "39.2", "wall": "575175"}
[2024-10-11 09:56:28,074][fairseq_cli.train][INFO] - end of epoch 637 (average epoch stats below)
[2024-10-11 09:56:28,091][train][INFO] - {"epoch": 637, "train_loss": "0.754", "train_ntokens": "263483", "train_nsentences": "1753.71", "train_wps": "144782", "train_ups": "0.55", "train_wpb": "263483", "train_bsz": "1753.7", "train_num_updates": "305002", "train_lr": "0.000129073", "train_gnorm": "0.261", "train_loss_scale": "1", "train_train_wall": "483", "train_gb_free": "39.6", "train_wall": "575180"}
[2024-10-11 09:56:28,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:56:28,167][fairseq.trainer][INFO] - begin training epoch 638
[2024-10-11 09:56:28,168][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:05:46,235][train_inner][INFO] - {"epoch": 638, "update": 637.413, "loss": "0.753", "ntokens": "262689", "nsentences": "1752.87", "wps": "93285", "ups": "0.36", "wpb": "262689", "bsz": "1752.9", "num_updates": "305200", "lr": "0.000128804", "gnorm": "0.248", "loss_scale": "1", "train_wall": "201", "gb_free": "39.6", "wall": "575738"}
[2024-10-11 10:09:43,838][train_inner][INFO] - {"epoch": 638, "update": 637.831, "loss": "0.755", "ntokens": "263988", "nsentences": "1754.18", "wps": "222228", "ups": "0.84", "wpb": "263988", "bsz": "1754.2", "num_updates": "305400", "lr": "0.000128533", "gnorm": "0.244", "loss_scale": "1", "train_wall": "231", "gb_free": "39.7", "wall": "575976"}
[2024-10-11 10:11:15,703][fairseq_cli.train][INFO] - end of epoch 638 (average epoch stats below)
[2024-10-11 10:11:15,802][train][INFO] - {"epoch": 638, "train_loss": "0.754", "train_ntokens": "263471", "train_nsentences": "1753.71", "train_wps": "142170", "train_ups": "0.54", "train_wpb": "263471", "train_bsz": "1753.7", "train_num_updates": "305481", "train_lr": "0.000128423", "train_gnorm": "0.249", "train_loss_scale": "1", "train_train_wall": "514", "train_gb_free": "39.6", "train_wall": "576068"}
[2024-10-11 10:11:16,249][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:11:16,323][fairseq.trainer][INFO] - begin training epoch 639
[2024-10-11 10:11:16,323][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:19:11,051][train_inner][INFO] - {"epoch": 639, "update": 638.248, "loss": "0.754", "ntokens": "262829", "nsentences": "1751.24", "wps": "92680.3", "ups": "0.35", "wpb": "262829", "bsz": "1751.2", "num_updates": "305600", "lr": "0.000128261", "gnorm": "0.256", "loss_scale": "1", "train_wall": "220", "gb_free": "40", "wall": "576543"}
[2024-10-11 10:22:44,910][train_inner][INFO] - {"epoch": 639, "update": 638.666, "loss": "0.752", "ntokens": "264079", "nsentences": "1737.98", "wps": "246987", "ups": "0.94", "wpb": "264079", "bsz": "1738", "num_updates": "305800", "lr": "0.000127989", "gnorm": "0.247", "loss_scale": "1", "train_wall": "208", "gb_free": "39.6", "wall": "576757"}
[2024-10-11 10:26:02,242][fairseq_cli.train][INFO] - end of epoch 639 (average epoch stats below)
[2024-10-11 10:26:02,266][train][INFO] - {"epoch": 639, "train_loss": "0.754", "train_ntokens": "263461", "train_nsentences": "1753.71", "train_wps": "142376", "train_ups": "0.54", "train_wpb": "263461", "train_bsz": "1753.7", "train_num_updates": "305960", "train_lr": "0.000127772", "train_gnorm": "0.253", "train_loss_scale": "1", "train_train_wall": "534", "train_gb_free": "39.6", "train_wall": "576954"}
[2024-10-11 10:26:02,464][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:26:02,494][fairseq.trainer][INFO] - begin training epoch 640
[2024-10-11 10:26:02,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:32:22,752][train_inner][INFO] - {"epoch": 640, "update": 639.084, "loss": "0.755", "ntokens": "262830", "nsentences": "1749.86", "wps": "90971.5", "ups": "0.35", "wpb": "262830", "bsz": "1749.9", "num_updates": "306000", "lr": "0.000127717", "gnorm": "0.264", "loss_scale": "1", "train_wall": "246", "gb_free": "39.6", "wall": "577335"}
[2024-10-11 10:36:02,860][train_inner][INFO] - {"epoch": 640, "update": 639.501, "loss": "0.753", "ntokens": "263921", "nsentences": "1755.13", "wps": "239834", "ups": "0.91", "wpb": "263921", "bsz": "1755.1", "num_updates": "306200", "lr": "0.000127446", "gnorm": "0.239", "loss_scale": "2", "train_wall": "214", "gb_free": "39.3", "wall": "577555"}
[2024-10-11 10:40:29,256][train_inner][INFO] - {"epoch": 640, "update": 639.919, "loss": "0.755", "ntokens": "263874", "nsentences": "1766.57", "wps": "198119", "ups": "0.75", "wpb": "263874", "bsz": "1766.6", "num_updates": "306400", "lr": "0.000127174", "gnorm": "0.255", "loss_scale": "2", "train_wall": "262", "gb_free": "39.6", "wall": "577821"}
[2024-10-11 10:41:04,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 640 @ 306439 updates
[2024-10-11 10:41:04,246][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 10:41:14,891][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 10:41:15,394][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 640 @ 306439 updates, score None) (writing took 11.1493571260944 seconds)
[2024-10-11 10:41:15,395][fairseq_cli.train][INFO] - end of epoch 640 (average epoch stats below)
[2024-10-11 10:41:15,402][train][INFO] - {"epoch": 640, "train_loss": "0.754", "train_ntokens": "263471", "train_nsentences": "1753.71", "train_wps": "138220", "train_ups": "0.52", "train_wpb": "263471", "train_bsz": "1753.7", "train_num_updates": "306439", "train_lr": "0.000127121", "train_gnorm": "0.249", "train_loss_scale": "2", "train_train_wall": "564", "train_gb_free": "39.6", "train_wall": "577868"}
[2024-10-11 10:41:15,589][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:41:15,635][fairseq.trainer][INFO] - begin training epoch 641
[2024-10-11 10:41:15,636][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:49:45,590][train_inner][INFO] - {"epoch": 641, "update": 640.336, "loss": "0.753", "ntokens": "262981", "nsentences": "1711.44", "wps": "94542.7", "ups": "0.36", "wpb": "262981", "bsz": "1711.4", "num_updates": "306600", "lr": "0.000126902", "gnorm": "0.253", "loss_scale": "2", "train_wall": "214", "gb_free": "39.6", "wall": "578378"}
[2024-10-11 10:50:59,898][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 10:54:05,042][train_inner][INFO] - {"epoch": 641, "update": 640.756, "loss": "0.754", "ntokens": "263659", "nsentences": "1789.76", "wps": "203257", "ups": "0.77", "wpb": "263659", "bsz": "1789.8", "num_updates": "306800", "lr": "0.00012663", "gnorm": "0.247", "loss_scale": "1", "train_wall": "253", "gb_free": "39.6", "wall": "578637"}
[2024-10-11 10:56:40,340][fairseq_cli.train][INFO] - end of epoch 641 (average epoch stats below)
[2024-10-11 10:56:40,364][train][INFO] - {"epoch": 641, "train_loss": "0.753", "train_ntokens": "263432", "train_nsentences": "1753.69", "train_wps": "136142", "train_ups": "0.52", "train_wpb": "263432", "train_bsz": "1753.7", "train_num_updates": "306917", "train_lr": "0.000126471", "train_gnorm": "0.259", "train_loss_scale": "1", "train_train_wall": "585", "train_gb_free": "40", "train_wall": "578793"}
[2024-10-11 10:56:40,650][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:56:40,668][fairseq.trainer][INFO] - begin training epoch 642
[2024-10-11 10:56:40,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:04:02,644][train_inner][INFO] - {"epoch": 642, "update": 641.173, "loss": "0.752", "ntokens": "262708", "nsentences": "1757.93", "wps": "87922.8", "ups": "0.33", "wpb": "262708", "bsz": "1757.9", "num_updates": "307000", "lr": "0.000126359", "gnorm": "0.262", "loss_scale": "1", "train_wall": "269", "gb_free": "39.7", "wall": "579235"}
[2024-10-11 11:07:43,146][train_inner][INFO] - {"epoch": 642, "update": 641.591, "loss": "0.754", "ntokens": "263889", "nsentences": "1768.7", "wps": "239388", "ups": "0.91", "wpb": "263889", "bsz": "1768.7", "num_updates": "307200", "lr": "0.000126087", "gnorm": "0.269", "loss_scale": "1", "train_wall": "215", "gb_free": "39.8", "wall": "579455"}
[2024-10-11 11:11:26,965][fairseq_cli.train][INFO] - end of epoch 642 (average epoch stats below)
[2024-10-11 11:11:26,989][train][INFO] - {"epoch": 642, "train_loss": "0.752", "train_ntokens": "263410", "train_nsentences": "1753.71", "train_wps": "142311", "train_ups": "0.54", "train_wpb": "263410", "train_bsz": "1753.7", "train_num_updates": "307396", "train_lr": "0.000125821", "train_gnorm": "0.255", "train_loss_scale": "1", "train_train_wall": "551", "train_gb_free": "39.8", "train_wall": "579679"}
[2024-10-11 11:11:27,116][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:11:27,120][fairseq.trainer][INFO] - begin training epoch 643
[2024-10-11 11:11:27,121][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:17:09,382][train_inner][INFO] - {"epoch": 643, "update": 642.008, "loss": "0.752", "ntokens": "262825", "nsentences": "1737.76", "wps": "92834.5", "ups": "0.35", "wpb": "262825", "bsz": "1737.8", "num_updates": "307400", "lr": "0.000125815", "gnorm": "0.252", "loss_scale": "1", "train_wall": "232", "gb_free": "40", "wall": "580022"}
[2024-10-11 11:20:40,202][train_inner][INFO] - {"epoch": 643, "update": 642.426, "loss": "0.753", "ntokens": "263761", "nsentences": "1785.91", "wps": "250235", "ups": "0.95", "wpb": "263761", "bsz": "1785.9", "num_updates": "307600", "lr": "0.000125543", "gnorm": "0.252", "loss_scale": "1", "train_wall": "205", "gb_free": "39.6", "wall": "580232"}
[2024-10-11 11:24:33,860][train_inner][INFO] - {"epoch": 643, "update": 642.843, "loss": "0.752", "ntokens": "264298", "nsentences": "1728.3", "wps": "226244", "ups": "0.86", "wpb": "264298", "bsz": "1728.3", "num_updates": "307800", "lr": "0.000125272", "gnorm": "0.263", "loss_scale": "1", "train_wall": "228", "gb_free": "39.7", "wall": "580466"}
[2024-10-11 11:26:08,792][fairseq_cli.train][INFO] - end of epoch 643 (average epoch stats below)
[2024-10-11 11:26:08,811][train][INFO] - {"epoch": 643, "train_loss": "0.753", "train_ntokens": "263557", "train_nsentences": "1753.71", "train_wps": "143164", "train_ups": "0.54", "train_wpb": "263557", "train_bsz": "1753.7", "train_num_updates": "307875", "train_lr": "0.00012517", "train_gnorm": "0.26", "train_loss_scale": "1", "train_train_wall": "541", "train_gb_free": "39.8", "train_wall": "580561"}
[2024-10-11 11:26:08,994][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:26:09,012][fairseq.trainer][INFO] - begin training epoch 644
[2024-10-11 11:26:09,012][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:34:13,621][train_inner][INFO] - {"epoch": 644, "update": 643.261, "loss": "0.754", "ntokens": "262800", "nsentences": "1781.97", "wps": "90660.1", "ups": "0.34", "wpb": "262800", "bsz": "1782", "num_updates": "308000", "lr": "0.000125", "gnorm": "0.257", "loss_scale": "1", "train_wall": "231", "gb_free": "40.5", "wall": "581046"}
[2024-10-11 11:38:10,052][train_inner][INFO] - {"epoch": 644, "update": 643.678, "loss": "0.754", "ntokens": "264057", "nsentences": "1762.92", "wps": "223380", "ups": "0.85", "wpb": "264057", "bsz": "1762.9", "num_updates": "308200", "lr": "0.000124728", "gnorm": "0.253", "loss_scale": "1", "train_wall": "231", "gb_free": "40", "wall": "581282"}
[2024-10-11 11:41:25,238][fairseq_cli.train][INFO] - end of epoch 644 (average epoch stats below)
[2024-10-11 11:41:25,252][train][INFO] - {"epoch": 644, "train_loss": "0.753", "train_ntokens": "263612", "train_nsentences": "1753.71", "train_wps": "137787", "train_ups": "0.52", "train_wpb": "263612", "train_bsz": "1753.7", "train_num_updates": "308354", "train_lr": "0.000124519", "train_gnorm": "0.252", "train_loss_scale": "1", "train_train_wall": "558", "train_gb_free": "39.2", "train_wall": "581477"}
[2024-10-11 11:41:25,400][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:41:25,419][fairseq.trainer][INFO] - begin training epoch 645
[2024-10-11 11:41:25,420][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:47:44,589][train_inner][INFO] - {"epoch": 645, "update": 644.096, "loss": "0.753", "ntokens": "263028", "nsentences": "1715.74", "wps": "91564.6", "ups": "0.35", "wpb": "263028", "bsz": "1715.7", "num_updates": "308400", "lr": "0.000124457", "gnorm": "0.248", "loss_scale": "1", "train_wall": "249", "gb_free": "40.5", "wall": "581857"}
[2024-10-11 11:51:30,044][train_inner][INFO] - {"epoch": 645, "update": 644.514, "loss": "0.752", "ntokens": "263778", "nsentences": "1779.43", "wps": "234015", "ups": "0.89", "wpb": "263778", "bsz": "1779.4", "num_updates": "308600", "lr": "0.000124185", "gnorm": "0.243", "loss_scale": "1", "train_wall": "220", "gb_free": "40.5", "wall": "582082"}
[2024-10-11 11:55:40,083][train_inner][INFO] - {"epoch": 645, "update": 644.931, "loss": "0.752", "ntokens": "264332", "nsentences": "1725.45", "wps": "211442", "ups": "0.8", "wpb": "264332", "bsz": "1725.5", "num_updates": "308800", "lr": "0.000123913", "gnorm": "0.251", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "582332"}
[2024-10-11 11:56:33,809][fairseq_cli.train][INFO] - end of epoch 645 (average epoch stats below)
[2024-10-11 11:56:33,848][train][INFO] - {"epoch": 645, "train_loss": "0.752", "train_ntokens": "263544", "train_nsentences": "1753.71", "train_wps": "138943", "train_ups": "0.53", "train_wpb": "263544", "train_bsz": "1753.7", "train_num_updates": "308833", "train_lr": "0.000123868", "train_gnorm": "0.246", "train_loss_scale": "2", "train_train_wall": "577", "train_gb_free": "39.6", "train_wall": "582386"}
[2024-10-11 11:56:34,038][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:56:34,054][fairseq.trainer][INFO] - begin training epoch 646
[2024-10-11 11:56:34,055][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:05:11,878][train_inner][INFO] - {"epoch": 646, "update": 645.349, "loss": "0.749", "ntokens": "263186", "nsentences": "1741.36", "wps": "92057.6", "ups": "0.35", "wpb": "263186", "bsz": "1741.4", "num_updates": "309000", "lr": "0.000123641", "gnorm": "0.26", "loss_scale": "2", "train_wall": "242", "gb_free": "39.7", "wall": "582904"}
[2024-10-11 12:09:12,325][train_inner][INFO] - {"epoch": 646, "update": 645.766, "loss": "0.754", "ntokens": "263808", "nsentences": "1754.27", "wps": "219464", "ups": "0.83", "wpb": "263808", "bsz": "1754.3", "num_updates": "309200", "lr": "0.00012337", "gnorm": "0.259", "loss_scale": "2", "train_wall": "235", "gb_free": "39.8", "wall": "583144"}
[2024-10-11 12:11:22,395][fairseq_cli.train][INFO] - end of epoch 646 (average epoch stats below)
[2024-10-11 12:11:22,466][train][INFO] - {"epoch": 646, "train_loss": "0.752", "train_ntokens": "263566", "train_nsentences": "1753.71", "train_wps": "142076", "train_ups": "0.54", "train_wpb": "263566", "train_bsz": "1753.7", "train_num_updates": "309312", "train_lr": "0.000123217", "train_gnorm": "0.255", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.2", "train_wall": "583275"}
[2024-10-11 12:11:22,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:11:22,751][fairseq.trainer][INFO] - begin training epoch 647
[2024-10-11 12:11:22,752][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:18:48,626][train_inner][INFO] - {"epoch": 647, "update": 646.184, "loss": "0.751", "ntokens": "263044", "nsentences": "1731.66", "wps": "91290.3", "ups": "0.35", "wpb": "263044", "bsz": "1731.7", "num_updates": "309400", "lr": "0.000123098", "gnorm": "0.248", "loss_scale": "2", "train_wall": "246", "gb_free": "40.3", "wall": "583721"}
[2024-10-11 12:22:09,046][train_inner][INFO] - {"epoch": 647, "update": 646.601, "loss": "0.751", "ntokens": "264046", "nsentences": "1737.8", "wps": "263533", "ups": "1", "wpb": "264046", "bsz": "1737.8", "num_updates": "309600", "lr": "0.000122826", "gnorm": "0.257", "loss_scale": "2", "train_wall": "194", "gb_free": "39.6", "wall": "583921"}
[2024-10-11 12:26:20,686][fairseq_cli.train][INFO] - end of epoch 647 (average epoch stats below)
[2024-10-11 12:26:20,708][train][INFO] - {"epoch": 647, "train_loss": "0.751", "train_ntokens": "263427", "train_nsentences": "1753.71", "train_wps": "140485", "train_ups": "0.53", "train_wpb": "263427", "train_bsz": "1753.7", "train_num_updates": "309791", "train_lr": "0.000122567", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "558", "train_gb_free": "40.5", "train_wall": "584173"}
[2024-10-11 12:26:20,797][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:26:20,817][fairseq.trainer][INFO] - begin training epoch 648
[2024-10-11 12:26:20,817][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:32:03,724][train_inner][INFO] - {"epoch": 648, "update": 647.019, "loss": "0.753", "ntokens": "262412", "nsentences": "1800.3", "wps": "88254.9", "ups": "0.34", "wpb": "262412", "bsz": "1800.3", "num_updates": "309800", "lr": "0.000122554", "gnorm": "0.265", "loss_scale": "2", "train_wall": "261", "gb_free": "39.6", "wall": "584516"}
[2024-10-11 12:35:45,492][train_inner][INFO] - {"epoch": 648, "update": 647.436, "loss": "0.754", "ntokens": "263501", "nsentences": "1798.81", "wps": "237661", "ups": "0.9", "wpb": "263501", "bsz": "1798.8", "num_updates": "310000", "lr": "0.000122283", "gnorm": "0.258", "loss_scale": "2", "train_wall": "187", "gb_free": "39.7", "wall": "584738"}
[2024-10-11 12:39:52,576][train_inner][INFO] - {"epoch": 648, "update": 647.854, "loss": "0.754", "ntokens": "263841", "nsentences": "1763.14", "wps": "213581", "ups": "0.81", "wpb": "263841", "bsz": "1763.1", "num_updates": "310200", "lr": "0.000122011", "gnorm": "0.26", "loss_scale": "2", "train_wall": "150", "gb_free": "39.6", "wall": "584985"}
[2024-10-11 12:41:10,880][fairseq_cli.train][INFO] - end of epoch 648 (average epoch stats below)
[2024-10-11 12:41:10,900][train][INFO] - {"epoch": 648, "train_loss": "0.753", "train_ntokens": "263415", "train_nsentences": "1753.71", "train_wps": "141744", "train_ups": "0.54", "train_wpb": "263415", "train_bsz": "1753.7", "train_num_updates": "310270", "train_lr": "0.000121916", "train_gnorm": "0.257", "train_loss_scale": "2", "train_train_wall": "413", "train_gb_free": "39.2", "train_wall": "585063"}
[2024-10-11 12:41:11,059][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:41:11,079][fairseq.trainer][INFO] - begin training epoch 649
[2024-10-11 12:41:11,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:49:06,883][train_inner][INFO] - {"epoch": 649, "update": 648.271, "loss": "0.748", "ntokens": "263135", "nsentences": "1694.35", "wps": "94947.2", "ups": "0.36", "wpb": "263135", "bsz": "1694.4", "num_updates": "310400", "lr": "0.000121739", "gnorm": "0.257", "loss_scale": "2", "train_wall": "197", "gb_free": "40", "wall": "585539"}
[2024-10-11 12:53:06,196][train_inner][INFO] - {"epoch": 649, "update": 648.689, "loss": "0.753", "ntokens": "264098", "nsentences": "1768.31", "wps": "220730", "ups": "0.84", "wpb": "264098", "bsz": "1768.3", "num_updates": "310600", "lr": "0.000121467", "gnorm": "0.265", "loss_scale": "2", "train_wall": "234", "gb_free": "39.2", "wall": "585778"}
[2024-10-11 12:56:02,735][fairseq_cli.train][INFO] - end of epoch 649 (average epoch stats below)
[2024-10-11 12:56:02,739][train][INFO] - {"epoch": 649, "train_loss": "0.752", "train_ntokens": "263568", "train_nsentences": "1753.71", "train_wps": "141564", "train_ups": "0.54", "train_wpb": "263568", "train_bsz": "1753.7", "train_num_updates": "310749", "train_lr": "0.000121265", "train_gnorm": "0.264", "train_loss_scale": "4", "train_train_wall": "542", "train_gb_free": "39.6", "train_wall": "585955"}
[2024-10-11 12:56:02,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:56:02,841][fairseq.trainer][INFO] - begin training epoch 650
[2024-10-11 12:56:02,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:02:30,698][train_inner][INFO] - {"epoch": 650, "update": 649.106, "loss": "0.752", "ntokens": "262872", "nsentences": "1748.25", "wps": "93138.9", "ups": "0.35", "wpb": "262872", "bsz": "1748.2", "num_updates": "310800", "lr": "0.000121196", "gnorm": "0.253", "loss_scale": "4", "train_wall": "253", "gb_free": "39.6", "wall": "586343"}
[2024-10-11 13:05:59,178][train_inner][INFO] - {"epoch": 650, "update": 649.524, "loss": "0.75", "ntokens": "263846", "nsentences": "1768.11", "wps": "253163", "ups": "0.96", "wpb": "263846", "bsz": "1768.1", "num_updates": "311000", "lr": "0.000120924", "gnorm": "0.257", "loss_scale": "4", "train_wall": "203", "gb_free": "39.3", "wall": "586551"}
[2024-10-11 13:07:40,455][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 13:09:41,397][train_inner][INFO] - {"epoch": 650, "update": 649.944, "loss": "0.751", "ntokens": "263880", "nsentences": "1740.53", "wps": "237541", "ups": "0.9", "wpb": "263880", "bsz": "1740.5", "num_updates": "311200", "lr": "0.000120652", "gnorm": "0.246", "loss_scale": "2", "train_wall": "216", "gb_free": "39.2", "wall": "586774"}
[2024-10-11 13:10:25,228][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 650 @ 311227 updates
[2024-10-11 13:10:25,229][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 13:10:33,872][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 13:10:34,008][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 650 @ 311227 updates, score None) (writing took 8.780672991648316 seconds)
[2024-10-11 13:10:34,009][fairseq_cli.train][INFO] - end of epoch 650 (average epoch stats below)
[2024-10-11 13:10:34,011][train][INFO] - {"epoch": 650, "train_loss": "0.751", "train_ntokens": "263353", "train_nsentences": "1751.18", "train_wps": "144484", "train_ups": "0.55", "train_wpb": "263353", "train_bsz": "1751.2", "train_num_updates": "311227", "train_lr": "0.000120615", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "39.2", "train_wall": "586826"}
[2024-10-11 13:10:34,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:10:34,106][fairseq.trainer][INFO] - begin training epoch 651
[2024-10-11 13:10:34,107][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:18:58,679][train_inner][INFO] - {"epoch": 651, "update": 650.361, "loss": "0.752", "ntokens": "262598", "nsentences": "1750.9", "wps": "94251.7", "ups": "0.36", "wpb": "262598", "bsz": "1750.9", "num_updates": "311400", "lr": "0.00012038", "gnorm": "0.259", "loss_scale": "2", "train_wall": "226", "gb_free": "40", "wall": "587331"}
[2024-10-11 13:22:56,655][train_inner][INFO] - {"epoch": 651, "update": 650.779, "loss": "0.75", "ntokens": "263906", "nsentences": "1752.67", "wps": "221813", "ups": "0.84", "wpb": "263906", "bsz": "1752.7", "num_updates": "311600", "lr": "0.000120109", "gnorm": "0.239", "loss_scale": "2", "train_wall": "233", "gb_free": "39.6", "wall": "587569"}
[2024-10-11 13:24:48,205][fairseq_cli.train][INFO] - end of epoch 651 (average epoch stats below)
[2024-10-11 13:24:48,245][train][INFO] - {"epoch": 651, "train_loss": "0.751", "train_ntokens": "263396", "train_nsentences": "1753.71", "train_wps": "147698", "train_ups": "0.56", "train_wpb": "263396", "train_bsz": "1753.7", "train_num_updates": "311706", "train_lr": "0.000119965", "train_gnorm": "0.251", "train_loss_scale": "2", "train_train_wall": "525", "train_gb_free": "39.6", "train_wall": "587680"}
[2024-10-11 13:24:48,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:24:48,495][fairseq.trainer][INFO] - begin training epoch 652
[2024-10-11 13:24:48,499][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:32:29,038][train_inner][INFO] - {"epoch": 652, "update": 651.196, "loss": "0.753", "ntokens": "262534", "nsentences": "1796.48", "wps": "91737.7", "ups": "0.35", "wpb": "262534", "bsz": "1796.5", "num_updates": "311800", "lr": "0.000119837", "gnorm": "0.265", "loss_scale": "2", "train_wall": "209", "gb_free": "40", "wall": "588141"}
[2024-10-11 13:36:07,374][train_inner][INFO] - {"epoch": 652, "update": 651.614, "loss": "0.752", "ntokens": "263943", "nsentences": "1775.06", "wps": "241889", "ups": "0.92", "wpb": "263944", "bsz": "1775.1", "num_updates": "312000", "lr": "0.000119565", "gnorm": "0.252", "loss_scale": "2", "train_wall": "213", "gb_free": "39.6", "wall": "588359"}
[2024-10-11 13:40:00,489][fairseq_cli.train][INFO] - end of epoch 652 (average epoch stats below)
[2024-10-11 13:40:00,496][train][INFO] - {"epoch": 652, "train_loss": "0.752", "train_ntokens": "263546", "train_nsentences": "1753.71", "train_wps": "138383", "train_ups": "0.53", "train_wpb": "263546", "train_bsz": "1753.7", "train_num_updates": "312185", "train_lr": "0.000119314", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "40", "train_wall": "588593"}
[2024-10-11 13:40:00,682][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:40:00,686][fairseq.trainer][INFO] - begin training epoch 653
[2024-10-11 13:40:00,687][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:45:56,540][train_inner][INFO] - {"epoch": 653, "update": 652.031, "loss": "0.75", "ntokens": "263299", "nsentences": "1686.37", "wps": "89387.1", "ups": "0.34", "wpb": "263300", "bsz": "1686.4", "num_updates": "312200", "lr": "0.000119293", "gnorm": "0.253", "loss_scale": "2", "train_wall": "266", "gb_free": "39.3", "wall": "588949"}
[2024-10-11 13:49:28,151][train_inner][INFO] - {"epoch": 653, "update": 652.449, "loss": "0.749", "ntokens": "263994", "nsentences": "1761.64", "wps": "249536", "ups": "0.95", "wpb": "263994", "bsz": "1761.6", "num_updates": "312400", "lr": "0.000119022", "gnorm": "0.258", "loss_scale": "2", "train_wall": "206", "gb_free": "39.3", "wall": "589160"}
[2024-10-11 13:53:13,906][train_inner][INFO] - {"epoch": 653, "update": 652.866, "loss": "0.754", "ntokens": "263948", "nsentences": "1775.61", "wps": "233846", "ups": "0.89", "wpb": "263948", "bsz": "1775.6", "num_updates": "312600", "lr": "0.00011875", "gnorm": "0.242", "loss_scale": "2", "train_wall": "221", "gb_free": "39.6", "wall": "589386"}
[2024-10-11 13:54:20,495][fairseq_cli.train][INFO] - end of epoch 653 (average epoch stats below)
[2024-10-11 13:54:20,527][train][INFO] - {"epoch": 653, "train_loss": "0.751", "train_ntokens": "263616", "train_nsentences": "1753.71", "train_wps": "146832", "train_ups": "0.56", "train_wpb": "263616", "train_bsz": "1753.7", "train_num_updates": "312664", "train_lr": "0.000118663", "train_gnorm": "0.25", "train_loss_scale": "2", "train_train_wall": "529", "train_gb_free": "39.7", "train_wall": "589453"}
[2024-10-11 13:54:20,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:54:20,771][fairseq.trainer][INFO] - begin training epoch 654
[2024-10-11 13:54:20,772][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:02:38,315][train_inner][INFO] - {"epoch": 654, "update": 653.284, "loss": "0.75", "ntokens": "263181", "nsentences": "1729.6", "wps": "93260.6", "ups": "0.35", "wpb": "263181", "bsz": "1729.6", "num_updates": "312800", "lr": "0.000118478", "gnorm": "0.253", "loss_scale": "2", "train_wall": "231", "gb_free": "41", "wall": "589950"}
[2024-10-11 14:06:08,378][train_inner][INFO] - {"epoch": 654, "update": 653.701, "loss": "0.752", "ntokens": "263815", "nsentences": "1784.55", "wps": "251187", "ups": "0.95", "wpb": "263815", "bsz": "1784.5", "num_updates": "313000", "lr": "0.000118207", "gnorm": "0.248", "loss_scale": "2", "train_wall": "205", "gb_free": "39.2", "wall": "590161"}
[2024-10-11 14:09:15,990][fairseq_cli.train][INFO] - end of epoch 654 (average epoch stats below)
[2024-10-11 14:09:16,021][train][INFO] - {"epoch": 654, "train_loss": "0.751", "train_ntokens": "263591", "train_nsentences": "1753.71", "train_wps": "140999", "train_ups": "0.53", "train_wpb": "263591", "train_bsz": "1753.7", "train_num_updates": "313143", "train_lr": "0.000118012", "train_gnorm": "0.252", "train_loss_scale": "4", "train_train_wall": "555", "train_gb_free": "40", "train_wall": "590348"}
[2024-10-11 14:09:16,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:09:16,124][fairseq.trainer][INFO] - begin training epoch 655
[2024-10-11 14:09:16,125][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:15:42,844][train_inner][INFO] - {"epoch": 655, "update": 654.119, "loss": "0.751", "ntokens": "262945", "nsentences": "1729.6", "wps": "91546", "ups": "0.35", "wpb": "262945", "bsz": "1729.6", "num_updates": "313200", "lr": "0.000117935", "gnorm": "0.244", "loss_scale": "4", "train_wall": "249", "gb_free": "39.6", "wall": "590735"}
[2024-10-11 14:19:32,707][train_inner][INFO] - {"epoch": 655, "update": 654.537, "loss": "0.749", "ntokens": "264098", "nsentences": "1748.06", "wps": "229799", "ups": "0.87", "wpb": "264098", "bsz": "1748.1", "num_updates": "313400", "lr": "0.000117663", "gnorm": "0.264", "loss_scale": "4", "train_wall": "225", "gb_free": "39.3", "wall": "590965"}
[2024-10-11 14:23:19,620][train_inner][INFO] - {"epoch": 655, "update": 654.954, "loss": "0.752", "ntokens": "263941", "nsentences": "1755.28", "wps": "232660", "ups": "0.88", "wpb": "263941", "bsz": "1755.3", "num_updates": "313600", "lr": "0.000117391", "gnorm": "0.257", "loss_scale": "4", "train_wall": "222", "gb_free": "39.2", "wall": "591192"}
[2024-10-11 14:23:40,552][fairseq_cli.train][INFO] - end of epoch 655 (average epoch stats below)
[2024-10-11 14:23:40,602][train][INFO] - {"epoch": 655, "train_loss": "0.751", "train_ntokens": "263455", "train_nsentences": "1753.71", "train_wps": "145966", "train_ups": "0.55", "train_wpb": "263455", "train_bsz": "1753.7", "train_num_updates": "313622", "train_lr": "0.000117361", "train_gnorm": "0.258", "train_loss_scale": "4", "train_train_wall": "533", "train_gb_free": "39.8", "train_wall": "591213"}
[2024-10-11 14:23:40,764][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:23:40,777][fairseq.trainer][INFO] - begin training epoch 656
[2024-10-11 14:23:40,778][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:31:56,571][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 14:33:04,441][train_inner][INFO] - {"epoch": 656, "update": 655.374, "loss": "0.75", "ntokens": "262890", "nsentences": "1738.4", "wps": "89908.2", "ups": "0.34", "wpb": "262890", "bsz": "1738.4", "num_updates": "313800", "lr": "0.00011712", "gnorm": "0.247", "loss_scale": "2", "train_wall": "235", "gb_free": "39.3", "wall": "591777"}
[2024-10-11 14:37:18,027][train_inner][INFO] - {"epoch": 656, "update": 655.791, "loss": "0.75", "ntokens": "264199", "nsentences": "1747.44", "wps": "208404", "ups": "0.79", "wpb": "264199", "bsz": "1747.4", "num_updates": "314000", "lr": "0.000116848", "gnorm": "0.237", "loss_scale": "2", "train_wall": "248", "gb_free": "39.6", "wall": "592030"}
[2024-10-11 14:39:20,100][fairseq_cli.train][INFO] - end of epoch 656 (average epoch stats below)
[2024-10-11 14:39:20,119][train][INFO] - {"epoch": 656, "train_loss": "0.751", "train_ntokens": "263584", "train_nsentences": "1754.84", "train_wps": "134107", "train_ups": "0.51", "train_wpb": "263584", "train_bsz": "1754.8", "train_num_updates": "314100", "train_lr": "0.000116712", "train_gnorm": "0.242", "train_loss_scale": "2", "train_train_wall": "583", "train_gb_free": "39.6", "train_wall": "592152"}
[2024-10-11 14:39:20,248][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:39:20,281][fairseq.trainer][INFO] - begin training epoch 657
[2024-10-11 14:39:20,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:46:34,194][train_inner][INFO] - {"epoch": 657, "update": 656.209, "loss": "0.75", "ntokens": "262981", "nsentences": "1757.49", "wps": "94571.8", "ups": "0.36", "wpb": "262981", "bsz": "1757.5", "num_updates": "314200", "lr": "0.000116576", "gnorm": "0.261", "loss_scale": "2", "train_wall": "235", "gb_free": "40", "wall": "592586"}
[2024-10-11 14:50:20,480][train_inner][INFO] - {"epoch": 657, "update": 656.626, "loss": "0.747", "ntokens": "264158", "nsentences": "1746.3", "wps": "233505", "ups": "0.88", "wpb": "264158", "bsz": "1746.3", "num_updates": "314400", "lr": "0.000116304", "gnorm": "0.269", "loss_scale": "2", "train_wall": "218", "gb_free": "40.5", "wall": "592813"}
[2024-10-11 14:53:52,489][fairseq_cli.train][INFO] - end of epoch 657 (average epoch stats below)
[2024-10-11 14:53:52,525][train][INFO] - {"epoch": 657, "train_loss": "0.75", "train_ntokens": "263580", "train_nsentences": "1753.71", "train_wps": "144723", "train_ups": "0.55", "train_wpb": "263580", "train_bsz": "1753.7", "train_num_updates": "314579", "train_lr": "0.000116061", "train_gnorm": "0.261", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.6", "train_wall": "593025"}
[2024-10-11 14:53:52,639][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:53:52,668][fairseq.trainer][INFO] - begin training epoch 658
[2024-10-11 14:53:52,669][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:59:45,759][train_inner][INFO] - {"epoch": 658, "update": 657.044, "loss": "0.755", "ntokens": "262524", "nsentences": "1776.4", "wps": "92885.3", "ups": "0.35", "wpb": "262524", "bsz": "1776.4", "num_updates": "314600", "lr": "0.000116033", "gnorm": "0.245", "loss_scale": "2", "train_wall": "250", "gb_free": "40", "wall": "593378"}
[2024-10-11 15:03:11,519][train_inner][INFO] - {"epoch": 658, "update": 657.461, "loss": "0.748", "ntokens": "263854", "nsentences": "1767.26", "wps": "256485", "ups": "0.97", "wpb": "263854", "bsz": "1767.3", "num_updates": "314800", "lr": "0.000115761", "gnorm": "0.273", "loss_scale": "2", "train_wall": "200", "gb_free": "39.3", "wall": "593584"}
[2024-10-11 15:04:27,835][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 15:07:28,663][train_inner][INFO] - {"epoch": 658, "update": 657.881, "loss": "0.751", "ntokens": "264140", "nsentences": "1756.39", "wps": "205461", "ups": "0.78", "wpb": "264140", "bsz": "1756.4", "num_updates": "315000", "lr": "0.000115489", "gnorm": "0.254", "loss_scale": "1", "train_wall": "252", "gb_free": "39.6", "wall": "593841"}
[2024-10-11 15:08:33,965][fairseq_cli.train][INFO] - end of epoch 658 (average epoch stats below)
[2024-10-11 15:08:34,018][train][INFO] - {"epoch": 658, "train_loss": "0.751", "train_ntokens": "263503", "train_nsentences": "1754.48", "train_wps": "142891", "train_ups": "0.54", "train_wpb": "263503", "train_bsz": "1754.5", "train_num_updates": "315057", "train_lr": "0.000115412", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "560", "train_gb_free": "39.8", "train_wall": "593906"}
[2024-10-11 15:08:34,183][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:08:34,214][fairseq.trainer][INFO] - begin training epoch 659
[2024-10-11 15:08:34,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:17:00,014][train_inner][INFO] - {"epoch": 659, "update": 658.299, "loss": "0.749", "ntokens": "262817", "nsentences": "1726.78", "wps": "91999.9", "ups": "0.35", "wpb": "262816", "bsz": "1726.8", "num_updates": "315200", "lr": "0.000115217", "gnorm": "0.266", "loss_scale": "1", "train_wall": "246", "gb_free": "39.7", "wall": "594412"}
[2024-10-11 15:20:25,750][train_inner][INFO] - {"epoch": 659, "update": 658.716, "loss": "0.751", "ntokens": "263882", "nsentences": "1764.54", "wps": "256594", "ups": "0.97", "wpb": "263882", "bsz": "1764.5", "num_updates": "315400", "lr": "0.000114946", "gnorm": "0.251", "loss_scale": "1", "train_wall": "201", "gb_free": "40", "wall": "594618"}
[2024-10-11 15:23:18,761][fairseq_cli.train][INFO] - end of epoch 659 (average epoch stats below)
[2024-10-11 15:23:18,781][train][INFO] - {"epoch": 659, "train_loss": "0.75", "train_ntokens": "263477", "train_nsentences": "1753.71", "train_wps": "142646", "train_ups": "0.54", "train_wpb": "263477", "train_bsz": "1753.7", "train_num_updates": "315536", "train_lr": "0.000114761", "train_gnorm": "0.258", "train_loss_scale": "1", "train_train_wall": "552", "train_gb_free": "39.6", "train_wall": "594791"}
[2024-10-11 15:23:18,843][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:23:18,856][fairseq.trainer][INFO] - begin training epoch 660
[2024-10-11 15:23:18,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:29:51,069][train_inner][INFO] - {"epoch": 660, "update": 659.134, "loss": "0.751", "ntokens": "262862", "nsentences": "1756.84", "wps": "92998.8", "ups": "0.35", "wpb": "262862", "bsz": "1756.8", "num_updates": "315600", "lr": "0.000114674", "gnorm": "0.267", "loss_scale": "1", "train_wall": "254", "gb_free": "40", "wall": "595183"}
[2024-10-11 15:33:45,904][train_inner][INFO] - {"epoch": 660, "update": 659.551, "loss": "0.75", "ntokens": "263925", "nsentences": "1761.01", "wps": "224807", "ups": "0.85", "wpb": "263924", "bsz": "1761", "num_updates": "315800", "lr": "0.000114402", "gnorm": "0.236", "loss_scale": "1", "train_wall": "230", "gb_free": "39.1", "wall": "595418"}
[2024-10-11 15:37:41,611][train_inner][INFO] - {"epoch": 660, "update": 659.969, "loss": "0.751", "ntokens": "264057", "nsentences": "1749.35", "wps": "224066", "ups": "0.85", "wpb": "264057", "bsz": "1749.4", "num_updates": "316000", "lr": "0.00011413", "gnorm": "0.256", "loss_scale": "1", "train_wall": "231", "gb_free": "39.2", "wall": "595654"}
[2024-10-11 15:38:24,980][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 660 @ 316015 updates
[2024-10-11 15:38:24,981][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 15:38:32,716][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 15:38:32,802][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 660 @ 316015 updates, score None) (writing took 7.822344466112554 seconds)
[2024-10-11 15:38:32,803][fairseq_cli.train][INFO] - end of epoch 660 (average epoch stats below)
[2024-10-11 15:38:32,806][train][INFO] - {"epoch": 660, "train_loss": "0.75", "train_ntokens": "263501", "train_nsentences": "1753.71", "train_wps": "138090", "train_ups": "0.52", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "316015", "train_lr": "0.00011411", "train_gnorm": "0.25", "train_loss_scale": "1", "train_train_wall": "586", "train_gb_free": "39.2", "train_wall": "595705"}
[2024-10-11 15:38:32,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:38:32,862][fairseq.trainer][INFO] - begin training epoch 661
[2024-10-11 15:38:32,862][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:47:32,774][train_inner][INFO] - {"epoch": 661, "update": 660.386, "loss": "0.748", "ntokens": "263173", "nsentences": "1718.55", "wps": "89039.9", "ups": "0.34", "wpb": "263173", "bsz": "1718.5", "num_updates": "316200", "lr": "0.000113859", "gnorm": "0.261", "loss_scale": "1", "train_wall": "252", "gb_free": "39.7", "wall": "596245"}
[2024-10-11 15:51:46,911][train_inner][INFO] - {"epoch": 661, "update": 660.804, "loss": "0.75", "ntokens": "263724", "nsentences": "1790.42", "wps": "207561", "ups": "0.79", "wpb": "263724", "bsz": "1790.4", "num_updates": "316400", "lr": "0.000113587", "gnorm": "0.258", "loss_scale": "1", "train_wall": "249", "gb_free": "39.3", "wall": "596499"}
[2024-10-11 15:53:50,857][fairseq_cli.train][INFO] - end of epoch 661 (average epoch stats below)
[2024-10-11 15:53:50,884][train][INFO] - {"epoch": 661, "train_loss": "0.749", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "137489", "train_ups": "0.52", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "316494", "train_lr": "0.000113459", "train_gnorm": "0.258", "train_loss_scale": "1", "train_train_wall": "581", "train_gb_free": "39.2", "train_wall": "596623"}
[2024-10-11 15:53:51,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:53:51,060][fairseq.trainer][INFO] - begin training epoch 662
[2024-10-11 15:53:51,061][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:01:19,166][train_inner][INFO] - {"epoch": 662, "update": 661.221, "loss": "0.749", "ntokens": "262929", "nsentences": "1745.21", "wps": "91895.9", "ups": "0.35", "wpb": "262929", "bsz": "1745.2", "num_updates": "316600", "lr": "0.000113315", "gnorm": "0.254", "loss_scale": "1", "train_wall": "245", "gb_free": "39.6", "wall": "597071"}
[2024-10-11 16:04:56,446][train_inner][INFO] - {"epoch": 662, "update": 661.639, "loss": "0.749", "ntokens": "263787", "nsentences": "1767.84", "wps": "242829", "ups": "0.92", "wpb": "263786", "bsz": "1767.8", "num_updates": "316800", "lr": "0.000113043", "gnorm": "0.246", "loss_scale": "1", "train_wall": "212", "gb_free": "40.7", "wall": "597289"}
[2024-10-11 16:08:39,236][fairseq_cli.train][INFO] - end of epoch 662 (average epoch stats below)
[2024-10-11 16:08:39,265][train][INFO] - {"epoch": 662, "train_loss": "0.749", "train_ntokens": "263532", "train_nsentences": "1753.71", "train_wps": "142093", "train_ups": "0.54", "train_wpb": "263532", "train_bsz": "1753.7", "train_num_updates": "316973", "train_lr": "0.000112808", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "554", "train_gb_free": "39.6", "train_wall": "597511"}
[2024-10-11 16:08:39,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:08:39,522][fairseq.trainer][INFO] - begin training epoch 663
[2024-10-11 16:08:39,523][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:14:33,641][train_inner][INFO] - {"epoch": 663, "update": 662.056, "loss": "0.749", "ntokens": "263140", "nsentences": "1723.56", "wps": "91186.9", "ups": "0.35", "wpb": "263140", "bsz": "1723.6", "num_updates": "317000", "lr": "0.000112772", "gnorm": "0.254", "loss_scale": "2", "train_wall": "258", "gb_free": "40.3", "wall": "597866"}
[2024-10-11 16:18:03,650][train_inner][INFO] - {"epoch": 663, "update": 662.474, "loss": "0.749", "ntokens": "263752", "nsentences": "1784.23", "wps": "251196", "ups": "0.95", "wpb": "263752", "bsz": "1784.2", "num_updates": "317200", "lr": "0.0001125", "gnorm": "0.259", "loss_scale": "2", "train_wall": "205", "gb_free": "40", "wall": "598076"}
[2024-10-11 16:21:58,144][train_inner][INFO] - {"epoch": 663, "update": 662.891, "loss": "0.749", "ntokens": "264299", "nsentences": "1724.93", "wps": "225449", "ups": "0.85", "wpb": "264300", "bsz": "1724.9", "num_updates": "317400", "lr": "0.000112228", "gnorm": "0.247", "loss_scale": "2", "train_wall": "228", "gb_free": "39.6", "wall": "598310"}
[2024-10-11 16:23:07,999][fairseq_cli.train][INFO] - end of epoch 663 (average epoch stats below)
[2024-10-11 16:23:08,035][train][INFO] - {"epoch": 663, "train_loss": "0.749", "train_ntokens": "263531", "train_nsentences": "1753.71", "train_wps": "145309", "train_ups": "0.55", "train_wpb": "263531", "train_bsz": "1753.7", "train_num_updates": "317452", "train_lr": "0.000112158", "train_gnorm": "0.253", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "39.6", "train_wall": "598380"}
[2024-10-11 16:23:08,092][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:23:08,098][fairseq.trainer][INFO] - begin training epoch 664
[2024-10-11 16:23:08,099][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:31:37,563][train_inner][INFO] - {"epoch": 664, "update": 663.309, "loss": "0.75", "ntokens": "262924", "nsentences": "1766.87", "wps": "90761.7", "ups": "0.35", "wpb": "262924", "bsz": "1766.9", "num_updates": "317600", "lr": "0.000111957", "gnorm": "0.258", "loss_scale": "2", "train_wall": "261", "gb_free": "39.2", "wall": "598890"}
[2024-10-11 16:35:19,193][train_inner][INFO] - {"epoch": 664, "update": 663.727, "loss": "0.75", "ntokens": "263940", "nsentences": "1767.81", "wps": "238210", "ups": "0.9", "wpb": "263940", "bsz": "1767.8", "num_updates": "317800", "lr": "0.000111685", "gnorm": "0.234", "loss_scale": "2", "train_wall": "217", "gb_free": "39.4", "wall": "599111"}
[2024-10-11 16:38:00,505][fairseq_cli.train][INFO] - end of epoch 664 (average epoch stats below)
[2024-10-11 16:38:00,509][train][INFO] - {"epoch": 664, "train_loss": "0.75", "train_ntokens": "263602", "train_nsentences": "1753.71", "train_wps": "141482", "train_ups": "0.54", "train_wpb": "263602", "train_bsz": "1753.7", "train_num_updates": "317931", "train_lr": "0.000111507", "train_gnorm": "0.246", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "39.7", "train_wall": "599273"}
[2024-10-11 16:38:00,607][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:38:00,634][fairseq.trainer][INFO] - begin training epoch 665
[2024-10-11 16:38:00,635][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:44:45,835][train_inner][INFO] - {"epoch": 665, "update": 664.144, "loss": "0.749", "ntokens": "262921", "nsentences": "1736.17", "wps": "92803.5", "ups": "0.35", "wpb": "262921", "bsz": "1736.2", "num_updates": "318000", "lr": "0.000111413", "gnorm": "0.254", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "599678"}
[2024-10-11 16:48:12,365][train_inner][INFO] - {"epoch": 665, "update": 664.562, "loss": "0.749", "ntokens": "264079", "nsentences": "1737.22", "wps": "255761", "ups": "0.97", "wpb": "264079", "bsz": "1737.2", "num_updates": "318200", "lr": "0.000111141", "gnorm": "0.254", "loss_scale": "2", "train_wall": "201", "gb_free": "39.3", "wall": "599885"}
[2024-10-11 16:51:54,964][train_inner][INFO] - {"epoch": 665, "update": 664.979, "loss": "0.75", "ntokens": "263771", "nsentences": "1776.22", "wps": "237042", "ups": "0.9", "wpb": "263771", "bsz": "1776.2", "num_updates": "318400", "lr": "0.00011087", "gnorm": "0.247", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "600107"}
[2024-10-11 16:52:31,897][fairseq_cli.train][INFO] - end of epoch 665 (average epoch stats below)
[2024-10-11 16:52:31,910][train][INFO] - {"epoch": 665, "train_loss": "0.75", "train_ntokens": "263460", "train_nsentences": "1753.71", "train_wps": "144827", "train_ups": "0.55", "train_wpb": "263460", "train_bsz": "1753.7", "train_num_updates": "318410", "train_lr": "0.000110856", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "39.2", "train_wall": "600144"}
[2024-10-11 16:52:31,988][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:52:32,015][fairseq.trainer][INFO] - begin training epoch 666
[2024-10-11 16:52:32,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:01:28,490][train_inner][INFO] - {"epoch": 666, "update": 665.397, "loss": "0.747", "ntokens": "262722", "nsentences": "1759.39", "wps": "91628.7", "ups": "0.35", "wpb": "262722", "bsz": "1759.4", "num_updates": "318600", "lr": "0.000110598", "gnorm": "0.258", "loss_scale": "2", "train_wall": "255", "gb_free": "40", "wall": "600681"}
[2024-10-11 17:05:56,416][train_inner][INFO] - {"epoch": 666, "update": 665.814, "loss": "0.75", "ntokens": "264095", "nsentences": "1750.32", "wps": "197198", "ups": "0.75", "wpb": "264095", "bsz": "1750.3", "num_updates": "318800", "lr": "0.000110326", "gnorm": "0.248", "loss_scale": "2", "train_wall": "263", "gb_free": "39.3", "wall": "600949"}
[2024-10-11 17:07:33,221][fairseq_cli.train][INFO] - end of epoch 666 (average epoch stats below)
[2024-10-11 17:07:33,254][train][INFO] - {"epoch": 666, "train_loss": "0.749", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "140039", "train_ups": "0.53", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "318889", "train_lr": "0.000110205", "train_gnorm": "0.254", "train_loss_scale": "2", "train_train_wall": "572", "train_gb_free": "39.3", "train_wall": "601045"}
[2024-10-11 17:07:33,322][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:07:33,330][fairseq.trainer][INFO] - begin training epoch 667
[2024-10-11 17:07:33,331][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:14:48,627][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 17:15:02,255][train_inner][INFO] - {"epoch": 667, "update": 666.234, "loss": "0.748", "ntokens": "263077", "nsentences": "1730.12", "wps": "96396.3", "ups": "0.37", "wpb": "263077", "bsz": "1730.1", "num_updates": "319000", "lr": "0.000110054", "gnorm": "0.265", "loss_scale": "2", "train_wall": "209", "gb_free": "39.3", "wall": "601494"}
[2024-10-11 17:18:51,011][train_inner][INFO] - {"epoch": 667, "update": 666.651, "loss": "0.749", "ntokens": "263450", "nsentences": "1802.94", "wps": "230346", "ups": "0.87", "wpb": "263450", "bsz": "1802.9", "num_updates": "319200", "lr": "0.000109783", "gnorm": "0.249", "loss_scale": "2", "train_wall": "224", "gb_free": "39.6", "wall": "601723"}
[2024-10-11 17:22:14,445][fairseq_cli.train][INFO] - end of epoch 667 (average epoch stats below)
[2024-10-11 17:22:14,468][train][INFO] - {"epoch": 667, "train_loss": "0.748", "train_ntokens": "263456", "train_nsentences": "1754.07", "train_wps": "142909", "train_ups": "0.54", "train_wpb": "263456", "train_bsz": "1754.1", "train_num_updates": "319367", "train_lr": "0.000109556", "train_gnorm": "0.253", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "39.2", "train_wall": "601927"}
[2024-10-11 17:22:14,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:22:14,658][fairseq.trainer][INFO] - begin training epoch 668
[2024-10-11 17:22:14,659][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:28:39,110][train_inner][INFO] - {"epoch": 668, "update": 667.069, "loss": "0.749", "ntokens": "263183", "nsentences": "1706.43", "wps": "89504.5", "ups": "0.34", "wpb": "263183", "bsz": "1706.4", "num_updates": "319400", "lr": "0.000109511", "gnorm": "0.248", "loss_scale": "2", "train_wall": "267", "gb_free": "39.8", "wall": "602311"}
[2024-10-11 17:32:21,319][train_inner][INFO] - {"epoch": 668, "update": 667.486, "loss": "0.747", "ntokens": "264244", "nsentences": "1741.43", "wps": "237854", "ups": "0.9", "wpb": "264244", "bsz": "1741.4", "num_updates": "319600", "lr": "0.000109239", "gnorm": "0.26", "loss_scale": "2", "train_wall": "217", "gb_free": "40.3", "wall": "602533"}
[2024-10-11 17:36:17,160][train_inner][INFO] - {"epoch": 668, "update": 667.904, "loss": "0.753", "ntokens": "263663", "nsentences": "1789.32", "wps": "223615", "ups": "0.85", "wpb": "263663", "bsz": "1789.3", "num_updates": "319800", "lr": "0.000108967", "gnorm": "0.237", "loss_scale": "2", "train_wall": "230", "gb_free": "40.1", "wall": "602769"}
[2024-10-11 17:37:20,110][fairseq_cli.train][INFO] - end of epoch 668 (average epoch stats below)
[2024-10-11 17:37:20,130][train][INFO] - {"epoch": 668, "train_loss": "0.75", "train_ntokens": "263553", "train_nsentences": "1753.71", "train_wps": "139396", "train_ups": "0.53", "train_wpb": "263553", "train_bsz": "1753.7", "train_num_updates": "319846", "train_lr": "0.000108905", "train_gnorm": "0.248", "train_loss_scale": "2", "train_train_wall": "574", "train_gb_free": "39.6", "train_wall": "602832"}
[2024-10-11 17:37:20,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:37:20,291][fairseq.trainer][INFO] - begin training epoch 669
[2024-10-11 17:37:20,292][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:45:41,510][train_inner][INFO] - {"epoch": 669, "update": 668.322, "loss": "0.749", "ntokens": "263309", "nsentences": "1703.37", "wps": "93316.5", "ups": "0.35", "wpb": "263309", "bsz": "1703.4", "num_updates": "320000", "lr": "0.000108696", "gnorm": "0.243", "loss_scale": "2", "train_wall": "237", "gb_free": "39.3", "wall": "603334"}
[2024-10-11 17:49:55,393][train_inner][INFO] - {"epoch": 669, "update": 668.739, "loss": "0.75", "ntokens": "263636", "nsentences": "1805.6", "wps": "207700", "ups": "0.79", "wpb": "263636", "bsz": "1805.6", "num_updates": "320200", "lr": "0.000108424", "gnorm": "0.246", "loss_scale": "2", "train_wall": "247", "gb_free": "39.3", "wall": "603588"}
[2024-10-11 17:52:07,651][fairseq_cli.train][INFO] - end of epoch 669 (average epoch stats below)
[2024-10-11 17:52:07,690][train][INFO] - {"epoch": 669, "train_loss": "0.749", "train_ntokens": "263594", "train_nsentences": "1753.71", "train_wps": "142260", "train_ups": "0.54", "train_wpb": "263594", "train_bsz": "1753.7", "train_num_updates": "320325", "train_lr": "0.000108254", "train_gnorm": "0.243", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "40", "train_wall": "603720"}
[2024-10-11 17:52:07,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:52:07,939][fairseq.trainer][INFO] - begin training epoch 670
[2024-10-11 17:52:07,940][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:59:22,559][train_inner][INFO] - {"epoch": 670, "update": 669.157, "loss": "0.748", "ntokens": "262962", "nsentences": "1756.67", "wps": "92735.4", "ups": "0.35", "wpb": "262962", "bsz": "1756.7", "num_updates": "320400", "lr": "0.000108152", "gnorm": "0.253", "loss_scale": "2", "train_wall": "208", "gb_free": "39.6", "wall": "604155"}
[2024-10-11 18:02:58,437][train_inner][INFO] - {"epoch": 670, "update": 669.574, "loss": "0.749", "ntokens": "263793", "nsentences": "1771.95", "wps": "244410", "ups": "0.93", "wpb": "263793", "bsz": "1772", "num_updates": "320600", "lr": "0.00010788", "gnorm": "0.255", "loss_scale": "2", "train_wall": "175", "gb_free": "39.3", "wall": "604371"}
[2024-10-11 18:06:48,570][train_inner][INFO] - {"epoch": 670, "update": 669.992, "loss": "0.75", "ntokens": "264112", "nsentences": "1730.02", "wps": "229565", "ups": "0.87", "wpb": "264112", "bsz": "1730", "num_updates": "320800", "lr": "0.000107609", "gnorm": "0.258", "loss_scale": "2", "train_wall": "182", "gb_free": "39.8", "wall": "604601"}
[2024-10-11 18:06:50,264][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 670 @ 320804 updates
[2024-10-11 18:06:50,265][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 18:06:57,401][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 18:06:57,670][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 670 @ 320804 updates, score None) (writing took 7.406366770155728 seconds)
[2024-10-11 18:06:57,671][fairseq_cli.train][INFO] - end of epoch 670 (average epoch stats below)
[2024-10-11 18:06:57,698][train][INFO] - {"epoch": 670, "train_loss": "0.749", "train_ntokens": "263496", "train_nsentences": "1753.71", "train_wps": "141824", "train_ups": "0.54", "train_wpb": "263496", "train_bsz": "1753.7", "train_num_updates": "320804", "train_lr": "0.000107603", "train_gnorm": "0.259", "train_loss_scale": "2", "train_train_wall": "446", "train_gb_free": "40", "train_wall": "604610"}
[2024-10-11 18:06:57,784][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:06:57,837][fairseq.trainer][INFO] - begin training epoch 671
[2024-10-11 18:06:57,837][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:16:07,702][train_inner][INFO] - {"epoch": 671, "update": 670.409, "loss": "0.749", "ntokens": "262907", "nsentences": "1758.99", "wps": "94048.1", "ups": "0.36", "wpb": "262907", "bsz": "1759", "num_updates": "321000", "lr": "0.000107337", "gnorm": "0.257", "loss_scale": "2", "train_wall": "229", "gb_free": "39.8", "wall": "605160"}
[2024-10-11 18:17:44,734][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 18:19:52,861][train_inner][INFO] - {"epoch": 671, "update": 670.829, "loss": "0.75", "ntokens": "264027", "nsentences": "1766.62", "wps": "234544", "ups": "0.89", "wpb": "264027", "bsz": "1766.6", "num_updates": "321200", "lr": "0.000107065", "gnorm": "0.251", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "605385"}
[2024-10-11 18:21:42,629][fairseq_cli.train][INFO] - end of epoch 671 (average epoch stats below)
[2024-10-11 18:21:42,633][train][INFO] - {"epoch": 671, "train_loss": "0.749", "train_ntokens": "263646", "train_nsentences": "1752.04", "train_wps": "142410", "train_ups": "0.54", "train_wpb": "263646", "train_bsz": "1752", "train_num_updates": "321282", "train_lr": "0.000106954", "train_gnorm": "0.253", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.6", "train_wall": "605495"}
[2024-10-11 18:21:42,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:21:42,705][fairseq.trainer][INFO] - begin training epoch 672
[2024-10-11 18:21:42,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:29:05,558][train_inner][INFO] - {"epoch": 672, "update": 671.246, "loss": "0.746", "ntokens": "263191", "nsentences": "1710.97", "wps": "95244.9", "ups": "0.36", "wpb": "263191", "bsz": "1711", "num_updates": "321400", "lr": "0.000106793", "gnorm": "0.248", "loss_scale": "2", "train_wall": "222", "gb_free": "40", "wall": "605938"}
[2024-10-11 18:32:52,924][train_inner][INFO] - {"epoch": 672, "update": 671.664, "loss": "0.748", "ntokens": "263910", "nsentences": "1755.15", "wps": "232164", "ups": "0.88", "wpb": "263910", "bsz": "1755.2", "num_updates": "321600", "lr": "0.000106522", "gnorm": "0.244", "loss_scale": "2", "train_wall": "223", "gb_free": "39.6", "wall": "606165"}
[2024-10-11 18:36:29,139][fairseq_cli.train][INFO] - end of epoch 672 (average epoch stats below)
[2024-10-11 18:36:29,170][train][INFO] - {"epoch": 672, "train_loss": "0.747", "train_ntokens": "263485", "train_nsentences": "1753.71", "train_wps": "142368", "train_ups": "0.54", "train_wpb": "263485", "train_bsz": "1753.7", "train_num_updates": "321761", "train_lr": "0.000106303", "train_gnorm": "0.247", "train_loss_scale": "2", "train_train_wall": "546", "train_gb_free": "39.1", "train_wall": "606381"}
[2024-10-11 18:36:29,391][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:36:29,427][fairseq.trainer][INFO] - begin training epoch 673
[2024-10-11 18:36:29,428][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:42:56,139][train_inner][INFO] - {"epoch": 673, "update": 672.081, "loss": "0.749", "ntokens": "262611", "nsentences": "1775.03", "wps": "87073.9", "ups": "0.33", "wpb": "262611", "bsz": "1775", "num_updates": "321800", "lr": "0.00010625", "gnorm": "0.253", "loss_scale": "2", "train_wall": "258", "gb_free": "39.6", "wall": "606768"}
[2024-10-11 18:46:25,486][train_inner][INFO] - {"epoch": 673, "update": 672.499, "loss": "0.748", "ntokens": "264250", "nsentences": "1743.09", "wps": "252483", "ups": "0.96", "wpb": "264250", "bsz": "1743.1", "num_updates": "322000", "lr": "0.000105978", "gnorm": "0.251", "loss_scale": "2", "train_wall": "204", "gb_free": "39.3", "wall": "606978"}
[2024-10-11 18:50:57,110][train_inner][INFO] - {"epoch": 673, "update": 672.916, "loss": "0.747", "ntokens": "264052", "nsentences": "1747.96", "wps": "194432", "ups": "0.74", "wpb": "264052", "bsz": "1748", "num_updates": "322200", "lr": "0.000105707", "gnorm": "0.243", "loss_scale": "2", "train_wall": "266", "gb_free": "40.5", "wall": "607249"}
[2024-10-11 18:51:57,092][fairseq_cli.train][INFO] - end of epoch 673 (average epoch stats below)
[2024-10-11 18:51:57,094][train][INFO] - {"epoch": 673, "train_loss": "0.748", "train_ntokens": "263575", "train_nsentences": "1753.71", "train_wps": "136063", "train_ups": "0.52", "train_wpb": "263575", "train_bsz": "1753.7", "train_num_updates": "322240", "train_lr": "0.000105652", "train_gnorm": "0.246", "train_loss_scale": "2", "train_train_wall": "579", "train_gb_free": "40", "train_wall": "607309"}
[2024-10-11 18:51:57,257][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:51:57,291][fairseq.trainer][INFO] - begin training epoch 674
[2024-10-11 18:51:57,292][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:00:51,213][train_inner][INFO] - {"epoch": 674, "update": 673.334, "loss": "0.749", "ntokens": "262897", "nsentences": "1745.88", "wps": "88503.8", "ups": "0.34", "wpb": "262897", "bsz": "1745.9", "num_updates": "322400", "lr": "0.000105435", "gnorm": "0.248", "loss_scale": "2", "train_wall": "266", "gb_free": "41", "wall": "607843"}
[2024-10-11 19:05:05,199][train_inner][INFO] - {"epoch": 674, "update": 673.752, "loss": "0.748", "ntokens": "264088", "nsentences": "1768.94", "wps": "207978", "ups": "0.79", "wpb": "264088", "bsz": "1768.9", "num_updates": "322600", "lr": "0.000105163", "gnorm": "0.245", "loss_scale": "2", "train_wall": "244", "gb_free": "39.6", "wall": "608097"}
[2024-10-11 19:07:29,050][fairseq_cli.train][INFO] - end of epoch 674 (average epoch stats below)
[2024-10-11 19:07:29,069][train][INFO] - {"epoch": 674, "train_loss": "0.748", "train_ntokens": "263561", "train_nsentences": "1753.71", "train_wps": "135463", "train_ups": "0.51", "train_wpb": "263561", "train_bsz": "1753.7", "train_num_updates": "322719", "train_lr": "0.000105001", "train_gnorm": "0.249", "train_loss_scale": "2", "train_train_wall": "591", "train_gb_free": "39.6", "train_wall": "608241"}
[2024-10-11 19:07:29,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:07:29,162][fairseq.trainer][INFO] - begin training epoch 675
[2024-10-11 19:07:29,163][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:14:14,441][train_inner][INFO] - {"epoch": 675, "update": 674.169, "loss": "0.748", "ntokens": "262649", "nsentences": "1767.74", "wps": "95644.3", "ups": "0.36", "wpb": "262649", "bsz": "1767.7", "num_updates": "322800", "lr": "0.000104891", "gnorm": "0.25", "loss_scale": "2", "train_wall": "234", "gb_free": "39.6", "wall": "608647"}
[2024-10-11 19:17:54,216][train_inner][INFO] - {"epoch": 675, "update": 674.587, "loss": "0.746", "ntokens": "264097", "nsentences": "1758.48", "wps": "240352", "ups": "0.91", "wpb": "264097", "bsz": "1758.5", "num_updates": "323000", "lr": "0.00010462", "gnorm": "0.244", "loss_scale": "2", "train_wall": "215", "gb_free": "39.1", "wall": "608866"}
[2024-10-11 19:22:23,437][fairseq_cli.train][INFO] - end of epoch 675 (average epoch stats below)
[2024-10-11 19:22:23,463][train][INFO] - {"epoch": 675, "train_loss": "0.747", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "141139", "train_ups": "0.54", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "323198", "train_lr": "0.000104351", "train_gnorm": "0.254", "train_loss_scale": "4", "train_train_wall": "571", "train_gb_free": "39.3", "train_wall": "609136"}
[2024-10-11 19:22:23,561][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:22:23,580][fairseq.trainer][INFO] - begin training epoch 676
[2024-10-11 19:22:23,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:28:18,125][train_inner][INFO] - {"epoch": 676, "update": 675.004, "loss": "0.748", "ntokens": "262965", "nsentences": "1730.19", "wps": "84300.3", "ups": "0.32", "wpb": "262965", "bsz": "1730.2", "num_updates": "323200", "lr": "0.000104348", "gnorm": "0.267", "loss_scale": "4", "train_wall": "300", "gb_free": "39.2", "wall": "609490"}
[2024-10-11 19:31:49,624][train_inner][INFO] - {"epoch": 676, "update": 675.422, "loss": "0.747", "ntokens": "264033", "nsentences": "1764.7", "wps": "249691", "ups": "0.95", "wpb": "264033", "bsz": "1764.7", "num_updates": "323400", "lr": "0.000104076", "gnorm": "0.249", "loss_scale": "4", "train_wall": "207", "gb_free": "39.6", "wall": "609702"}
[2024-10-11 19:36:20,261][train_inner][INFO] - {"epoch": 676, "update": 675.839, "loss": "0.748", "ntokens": "264000", "nsentences": "1763.08", "wps": "195103", "ups": "0.74", "wpb": "264000", "bsz": "1763.1", "num_updates": "323600", "lr": "0.000103804", "gnorm": "0.252", "loss_scale": "4", "train_wall": "266", "gb_free": "39.6", "wall": "609972"}
[2024-10-11 19:37:59,401][fairseq_cli.train][INFO] - end of epoch 676 (average epoch stats below)
[2024-10-11 19:37:59,417][train][INFO] - {"epoch": 676, "train_loss": "0.747", "train_ntokens": "263597", "train_nsentences": "1753.71", "train_wps": "134905", "train_ups": "0.51", "train_wpb": "263597", "train_bsz": "1753.7", "train_num_updates": "323677", "train_lr": "0.0001037", "train_gnorm": "0.25", "train_loss_scale": "4", "train_train_wall": "607", "train_gb_free": "39.7", "train_wall": "610072"}
[2024-10-11 19:37:59,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:37:59,492][fairseq.trainer][INFO] - begin training epoch 677
[2024-10-11 19:37:59,493][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:45:04,218][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 19:45:57,909][train_inner][INFO] - {"epoch": 677, "update": 676.259, "loss": "0.748", "ntokens": "262524", "nsentences": "1780.35", "wps": "90897.4", "ups": "0.35", "wpb": "262524", "bsz": "1780.3", "num_updates": "323800", "lr": "0.000103533", "gnorm": "0.246", "loss_scale": "2", "train_wall": "262", "gb_free": "40.5", "wall": "610550"}
[2024-10-11 19:50:20,767][train_inner][INFO] - {"epoch": 677, "update": 676.676, "loss": "0.746", "ntokens": "264220", "nsentences": "1744.88", "wps": "201055", "ups": "0.76", "wpb": "264220", "bsz": "1744.9", "num_updates": "324000", "lr": "0.000103261", "gnorm": "0.248", "loss_scale": "2", "train_wall": "257", "gb_free": "39.6", "wall": "610813"}
[2024-10-11 19:53:39,270][fairseq_cli.train][INFO] - end of epoch 677 (average epoch stats below)
[2024-10-11 19:53:39,274][train][INFO] - {"epoch": 677, "train_loss": "0.747", "train_ntokens": "263521", "train_nsentences": "1753.13", "train_wps": "134025", "train_ups": "0.51", "train_wpb": "263521", "train_bsz": "1753.1", "train_num_updates": "324155", "train_lr": "0.00010305", "train_gnorm": "0.244", "train_loss_scale": "2", "train_train_wall": "616", "train_gb_free": "39.6", "train_wall": "611011"}
[2024-10-11 19:53:39,353][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:53:39,381][fairseq.trainer][INFO] - begin training epoch 678
[2024-10-11 19:53:39,381][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:59:55,907][train_inner][INFO] - {"epoch": 678, "update": 677.094, "loss": "0.747", "ntokens": "263271", "nsentences": "1702.41", "wps": "91558.1", "ups": "0.35", "wpb": "263271", "bsz": "1702.4", "num_updates": "324200", "lr": "0.000102989", "gnorm": "0.241", "loss_scale": "2", "train_wall": "258", "gb_free": "40.5", "wall": "611388"}
[2024-10-11 20:03:19,048][train_inner][INFO] - {"epoch": 678, "update": 677.511, "loss": "0.745", "ntokens": "264172", "nsentences": "1743.4", "wps": "260112", "ups": "0.98", "wpb": "264172", "bsz": "1743.4", "num_updates": "324400", "lr": "0.000102717", "gnorm": "0.268", "loss_scale": "2", "train_wall": "166", "gb_free": "39.6", "wall": "611591"}
[2024-10-11 20:07:23,405][train_inner][INFO] - {"epoch": 678, "update": 677.929, "loss": "0.75", "ntokens": "263848", "nsentences": "1776.63", "wps": "215989", "ups": "0.82", "wpb": "263848", "bsz": "1776.6", "num_updates": "324600", "lr": "0.000102446", "gnorm": "0.26", "loss_scale": "2", "train_wall": "239", "gb_free": "39.6", "wall": "611836"}
[2024-10-11 20:07:27,040][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 20:08:20,108][fairseq_cli.train][INFO] - end of epoch 678 (average epoch stats below)
[2024-10-11 20:08:20,124][train][INFO] - {"epoch": 678, "train_loss": "0.748", "train_ntokens": "263520", "train_nsentences": "1754.45", "train_wps": "143003", "train_ups": "0.54", "train_wpb": "263520", "train_bsz": "1754.5", "train_num_updates": "324633", "train_lr": "0.000102401", "train_gnorm": "0.264", "train_loss_scale": "1", "train_train_wall": "525", "train_gb_free": "39.8", "train_wall": "611892"}
[2024-10-11 20:08:20,198][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:08:20,210][fairseq.trainer][INFO] - begin training epoch 679
[2024-10-11 20:08:20,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:16:36,959][train_inner][INFO] - {"epoch": 679, "update": 678.349, "loss": "0.747", "ntokens": "262861", "nsentences": "1742.43", "wps": "94974.2", "ups": "0.36", "wpb": "262861", "bsz": "1742.4", "num_updates": "324800", "lr": "0.000102174", "gnorm": "0.257", "loss_scale": "1", "train_wall": "190", "gb_free": "39.2", "wall": "612389"}
[2024-10-11 20:20:24,594][train_inner][INFO] - {"epoch": 679, "update": 678.766, "loss": "0.747", "ntokens": "263988", "nsentences": "1759.62", "wps": "231962", "ups": "0.88", "wpb": "263988", "bsz": "1759.6", "num_updates": "325000", "lr": "0.000101902", "gnorm": "0.247", "loss_scale": "1", "train_wall": "222", "gb_free": "39.2", "wall": "612617"}
[2024-10-11 20:22:53,136][fairseq_cli.train][INFO] - end of epoch 679 (average epoch stats below)
[2024-10-11 20:22:53,153][train][INFO] - {"epoch": 679, "train_loss": "0.747", "train_ntokens": "263625", "train_nsentences": "1753.71", "train_wps": "144643", "train_ups": "0.55", "train_wpb": "263624", "train_bsz": "1753.7", "train_num_updates": "325112", "train_lr": "0.00010175", "train_gnorm": "0.248", "train_loss_scale": "1", "train_train_wall": "498", "train_gb_free": "39.6", "train_wall": "612765"}
[2024-10-11 20:22:53,270][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:22:53,295][fairseq.trainer][INFO] - begin training epoch 680
[2024-10-11 20:22:53,296][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:30:11,622][train_inner][INFO] - {"epoch": 680, "update": 679.184, "loss": "0.748", "ntokens": "262969", "nsentences": "1755.31", "wps": "89599.7", "ups": "0.34", "wpb": "262970", "bsz": "1755.3", "num_updates": "325200", "lr": "0.00010163", "gnorm": "0.251", "loss_scale": "1", "train_wall": "242", "gb_free": "39.2", "wall": "613204"}
[2024-10-11 20:33:39,874][train_inner][INFO] - {"epoch": 680, "update": 679.601, "loss": "0.747", "ntokens": "263982", "nsentences": "1781.97", "wps": "253551", "ups": "0.96", "wpb": "263982", "bsz": "1782", "num_updates": "325400", "lr": "0.000101359", "gnorm": "0.255", "loss_scale": "1", "train_wall": "201", "gb_free": "39.6", "wall": "613412"}
[2024-10-11 20:37:17,506][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 680 @ 325591 updates
[2024-10-11 20:37:17,510][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 20:37:25,306][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 20:37:25,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 680 @ 325591 updates, score None) (writing took 8.108659338206053 seconds)
[2024-10-11 20:37:25,615][fairseq_cli.train][INFO] - end of epoch 680 (average epoch stats below)
[2024-10-11 20:37:25,618][train][INFO] - {"epoch": 680, "train_loss": "0.747", "train_ntokens": "263531", "train_nsentences": "1753.71", "train_wps": "144691", "train_ups": "0.55", "train_wpb": "263531", "train_bsz": "1753.7", "train_num_updates": "325591", "train_lr": "0.000101099", "train_gnorm": "0.252", "train_loss_scale": "1", "train_train_wall": "514", "train_gb_free": "39.2", "train_wall": "613638"}
[2024-10-11 20:37:25,729][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:37:25,752][fairseq.trainer][INFO] - begin training epoch 681
[2024-10-11 20:37:25,752][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:43:13,628][train_inner][INFO] - {"epoch": 681, "update": 680.019, "loss": "0.747", "ntokens": "262688", "nsentences": "1746.63", "wps": "91570.2", "ups": "0.35", "wpb": "262688", "bsz": "1746.6", "num_updates": "325600", "lr": "0.000101087", "gnorm": "0.245", "loss_scale": "1", "train_wall": "239", "gb_free": "39.8", "wall": "613986"}
[2024-10-11 20:46:47,845][train_inner][INFO] - {"epoch": 681, "update": 680.436, "loss": "0.748", "ntokens": "264016", "nsentences": "1759.76", "wps": "246532", "ups": "0.93", "wpb": "264016", "bsz": "1759.8", "num_updates": "325800", "lr": "0.000100815", "gnorm": "0.244", "loss_scale": "1", "train_wall": "161", "gb_free": "40", "wall": "614200"}
[2024-10-11 20:51:11,634][train_inner][INFO] - {"epoch": 681, "update": 680.854, "loss": "0.748", "ntokens": "264031", "nsentences": "1758.09", "wps": "200201", "ups": "0.76", "wpb": "264031", "bsz": "1758.1", "num_updates": "326000", "lr": "0.000100543", "gnorm": "0.25", "loss_scale": "1", "train_wall": "146", "gb_free": "39.3", "wall": "614464"}
[2024-10-11 20:52:33,163][fairseq_cli.train][INFO] - end of epoch 681 (average epoch stats below)
[2024-10-11 20:52:33,187][train][INFO] - {"epoch": 681, "train_loss": "0.748", "train_ntokens": "263571", "train_nsentences": "1753.71", "train_wps": "139113", "train_ups": "0.53", "train_wpb": "263571", "train_bsz": "1753.7", "train_num_updates": "326070", "train_lr": "0.000100448", "train_gnorm": "0.247", "train_loss_scale": "1", "train_train_wall": "396", "train_gb_free": "39.7", "train_wall": "614545"}
[2024-10-11 20:52:33,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:52:33,476][fairseq.trainer][INFO] - begin training epoch 682
[2024-10-11 20:52:33,480][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:00:29,304][train_inner][INFO] - {"epoch": 682, "update": 681.271, "loss": "0.745", "ntokens": "263054", "nsentences": "1729.91", "wps": "94344.2", "ups": "0.36", "wpb": "263054", "bsz": "1729.9", "num_updates": "326200", "lr": "0.000100272", "gnorm": "0.242", "loss_scale": "1", "train_wall": "219", "gb_free": "39.6", "wall": "615021"}
[2024-10-11 21:04:13,388][train_inner][INFO] - {"epoch": 682, "update": 681.689, "loss": "0.747", "ntokens": "263793", "nsentences": "1774.04", "wps": "235456", "ups": "0.89", "wpb": "263793", "bsz": "1774", "num_updates": "326400", "lr": "0.0001", "gnorm": "0.265", "loss_scale": "1", "train_wall": "217", "gb_free": "40", "wall": "615246"}
[2024-10-11 21:06:57,630][fairseq_cli.train][INFO] - end of epoch 682 (average epoch stats below)
[2024-10-11 21:06:57,642][train][INFO] - {"epoch": 682, "train_loss": "0.746", "train_ntokens": "263474", "train_nsentences": "1753.71", "train_wps": "146000", "train_ups": "0.55", "train_wpb": "263474", "train_bsz": "1753.7", "train_num_updates": "326549", "train_lr": "9.97976e-05", "train_gnorm": "0.248", "train_loss_scale": "1", "train_train_wall": "532", "train_gb_free": "39.3", "train_wall": "615410"}
[2024-10-11 21:06:57,747][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:06:57,769][fairseq.trainer][INFO] - begin training epoch 683
[2024-10-11 21:06:57,770][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:13:39,427][train_inner][INFO] - {"epoch": 683, "update": 682.106, "loss": "0.747", "ntokens": "262945", "nsentences": "1743.77", "wps": "92914.5", "ups": "0.35", "wpb": "262945", "bsz": "1743.8", "num_updates": "326600", "lr": "9.97283e-05", "gnorm": "0.239", "loss_scale": "1", "train_wall": "200", "gb_free": "40.2", "wall": "615812"}
[2024-10-11 21:17:01,864][train_inner][INFO] - {"epoch": 683, "update": 682.524, "loss": "0.745", "ntokens": "264071", "nsentences": "1748.98", "wps": "260922", "ups": "0.99", "wpb": "264070", "bsz": "1749", "num_updates": "326800", "lr": "9.94565e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "149", "gb_free": "39", "wall": "616014"}
[2024-10-11 21:20:48,185][train_inner][INFO] - {"epoch": 683, "update": 682.942, "loss": "0.747", "ntokens": "263957", "nsentences": "1760.81", "wps": "233312", "ups": "0.88", "wpb": "263957", "bsz": "1760.8", "num_updates": "327000", "lr": "9.91848e-05", "gnorm": "0.253", "loss_scale": "2", "train_wall": "153", "gb_free": "39.3", "wall": "616240"}
[2024-10-11 21:21:43,782][fairseq_cli.train][INFO] - end of epoch 683 (average epoch stats below)
[2024-10-11 21:21:43,802][train][INFO] - {"epoch": 683, "train_loss": "0.746", "train_ntokens": "263537", "train_nsentences": "1753.71", "train_wps": "142455", "train_ups": "0.54", "train_wpb": "263537", "train_bsz": "1753.7", "train_num_updates": "327028", "train_lr": "9.91467e-05", "train_gnorm": "0.251", "train_loss_scale": "2", "train_train_wall": "380", "train_gb_free": "39.7", "train_wall": "616296"}
[2024-10-11 21:21:44,129][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:21:44,187][fairseq.trainer][INFO] - begin training epoch 684
[2024-10-11 21:21:44,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:30:11,111][train_inner][INFO] - {"epoch": 684, "update": 683.359, "loss": "0.743", "ntokens": "263078", "nsentences": "1719.35", "wps": "93471.9", "ups": "0.36", "wpb": "263078", "bsz": "1719.4", "num_updates": "327200", "lr": "9.8913e-05", "gnorm": "0.257", "loss_scale": "2", "train_wall": "216", "gb_free": "39.8", "wall": "616803"}
[2024-10-11 21:34:15,881][train_inner][INFO] - {"epoch": 684, "update": 683.777, "loss": "0.749", "ntokens": "263786", "nsentences": "1782.97", "wps": "215554", "ups": "0.82", "wpb": "263786", "bsz": "1783", "num_updates": "327400", "lr": "9.86413e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "239", "gb_free": "39.2", "wall": "617048"}
[2024-10-11 21:36:04,208][fairseq_cli.train][INFO] - end of epoch 684 (average epoch stats below)
[2024-10-11 21:36:04,259][train][INFO] - {"epoch": 684, "train_loss": "0.746", "train_ntokens": "263506", "train_nsentences": "1753.71", "train_wps": "146708", "train_ups": "0.56", "train_wpb": "263506", "train_bsz": "1753.7", "train_num_updates": "327507", "train_lr": "9.84959e-05", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "523", "train_gb_free": "39.2", "train_wall": "617156"}
[2024-10-11 21:36:04,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:36:04,663][fairseq.trainer][INFO] - begin training epoch 685
[2024-10-11 21:36:04,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:43:50,754][train_inner][INFO] - {"epoch": 685, "update": 684.194, "loss": "0.748", "ntokens": "262846", "nsentences": "1756.55", "wps": "91448.6", "ups": "0.35", "wpb": "262846", "bsz": "1756.5", "num_updates": "327600", "lr": "9.83696e-05", "gnorm": "0.249", "loss_scale": "2", "train_wall": "241", "gb_free": "39.7", "wall": "617623"}
[2024-10-11 21:47:38,130][train_inner][INFO] - {"epoch": 685, "update": 684.612, "loss": "0.747", "ntokens": "263616", "nsentences": "1793.11", "wps": "231914", "ups": "0.88", "wpb": "263616", "bsz": "1793.1", "num_updates": "327800", "lr": "9.80978e-05", "gnorm": "0.266", "loss_scale": "2", "train_wall": "221", "gb_free": "39.7", "wall": "617850"}
[2024-10-11 21:51:31,977][fairseq_cli.train][INFO] - end of epoch 685 (average epoch stats below)
[2024-10-11 21:51:32,012][train][INFO] - {"epoch": 685, "train_loss": "0.747", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "136044", "train_ups": "0.52", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "327986", "train_lr": "9.78451e-05", "train_gnorm": "0.253", "train_loss_scale": "2", "train_train_wall": "581", "train_gb_free": "40.5", "train_wall": "618084"}
[2024-10-11 21:51:32,992][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:51:33,067][fairseq.trainer][INFO] - begin training epoch 686
[2024-10-11 21:51:33,067][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:57:24,002][train_inner][INFO] - {"epoch": 686, "update": 685.029, "loss": "0.748", "ntokens": "263017", "nsentences": "1715.98", "wps": "89793.2", "ups": "0.34", "wpb": "263017", "bsz": "1716", "num_updates": "328000", "lr": "9.78261e-05", "gnorm": "0.244", "loss_scale": "2", "train_wall": "245", "gb_free": "39.6", "wall": "618436"}
[2024-10-11 22:01:03,291][train_inner][INFO] - {"epoch": 686, "update": 685.447, "loss": "0.744", "ntokens": "264255", "nsentences": "1737.36", "wps": "241071", "ups": "0.91", "wpb": "264255", "bsz": "1737.4", "num_updates": "328200", "lr": "9.75543e-05", "gnorm": "0.249", "loss_scale": "2", "train_wall": "163", "gb_free": "39.8", "wall": "618655"}
[2024-10-11 22:05:09,587][train_inner][INFO] - {"epoch": 686, "update": 685.864, "loss": "0.746", "ntokens": "263832", "nsentences": "1772.32", "wps": "214275", "ups": "0.81", "wpb": "263832", "bsz": "1772.3", "num_updates": "328400", "lr": "9.72826e-05", "gnorm": "0.256", "loss_scale": "2", "train_wall": "150", "gb_free": "39.6", "wall": "618902"}
[2024-10-11 22:06:54,190][fairseq_cli.train][INFO] - end of epoch 686 (average epoch stats below)
[2024-10-11 22:06:54,209][train][INFO] - {"epoch": 686, "train_loss": "0.745", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "136904", "train_ups": "0.52", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "328465", "train_lr": "9.71943e-05", "train_gnorm": "0.252", "train_loss_scale": "2", "train_train_wall": "413", "train_gb_free": "39.7", "train_wall": "619006"}
[2024-10-11 22:06:54,739][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:06:54,795][fairseq.trainer][INFO] - begin training epoch 687
[2024-10-11 22:06:54,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:14:52,939][train_inner][INFO] - {"epoch": 687, "update": 686.282, "loss": "0.745", "ntokens": "262912", "nsentences": "1751.35", "wps": "90143.8", "ups": "0.34", "wpb": "262912", "bsz": "1751.4", "num_updates": "328600", "lr": "9.70109e-05", "gnorm": "0.256", "loss_scale": "2", "train_wall": "189", "gb_free": "39.2", "wall": "619485"}
[2024-10-11 22:18:26,541][train_inner][INFO] - {"epoch": 687, "update": 686.699, "loss": "0.744", "ntokens": "264010", "nsentences": "1742.18", "wps": "247245", "ups": "0.94", "wpb": "264010", "bsz": "1742.2", "num_updates": "328800", "lr": "9.67391e-05", "gnorm": "0.24", "loss_scale": "4", "train_wall": "152", "gb_free": "39.2", "wall": "619699"}
[2024-10-11 22:21:45,567][fairseq_cli.train][INFO] - end of epoch 687 (average epoch stats below)
[2024-10-11 22:21:45,570][train][INFO] - {"epoch": 687, "train_loss": "0.746", "train_ntokens": "263458", "train_nsentences": "1753.71", "train_wps": "141584", "train_ups": "0.54", "train_wpb": "263458", "train_bsz": "1753.7", "train_num_updates": "328944", "train_lr": "9.65435e-05", "train_gnorm": "0.245", "train_loss_scale": "4", "train_train_wall": "411", "train_gb_free": "40.3", "train_wall": "619898"}
[2024-10-11 22:21:45,644][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:21:45,651][fairseq.trainer][INFO] - begin training epoch 688
[2024-10-11 22:21:45,652][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:28:05,600][train_inner][INFO] - {"epoch": 688, "update": 687.117, "loss": "0.747", "ntokens": "262773", "nsentences": "1740.01", "wps": "90768.5", "ups": "0.35", "wpb": "262773", "bsz": "1740", "num_updates": "329000", "lr": "9.64674e-05", "gnorm": "0.244", "loss_scale": "4", "train_wall": "212", "gb_free": "39.7", "wall": "620278"}
[2024-10-11 22:31:32,913][train_inner][INFO] - {"epoch": 688, "update": 687.534, "loss": "0.748", "ntokens": "263410", "nsentences": "1828.67", "wps": "254157", "ups": "0.96", "wpb": "263410", "bsz": "1828.7", "num_updates": "329200", "lr": "9.61957e-05", "gnorm": "0.246", "loss_scale": "4", "train_wall": "200", "gb_free": "40.3", "wall": "620485"}
[2024-10-11 22:35:15,753][train_inner][INFO] - {"epoch": 688, "update": 687.952, "loss": "0.744", "ntokens": "264416", "nsentences": "1699.01", "wps": "237325", "ups": "0.9", "wpb": "264416", "bsz": "1699", "num_updates": "329400", "lr": "9.59239e-05", "gnorm": "0.243", "loss_scale": "4", "train_wall": "217", "gb_free": "39.7", "wall": "620708"}
[2024-10-11 22:35:48,814][fairseq_cli.train][INFO] - end of epoch 688 (average epoch stats below)
[2024-10-11 22:35:48,826][train][INFO] - {"epoch": 688, "train_loss": "0.746", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "149675", "train_ups": "0.57", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "329423", "train_lr": "9.58927e-05", "train_gnorm": "0.246", "train_loss_scale": "4", "train_train_wall": "509", "train_gb_free": "39.8", "train_wall": "620741"}
[2024-10-11 22:35:48,982][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:35:49,016][fairseq.trainer][INFO] - begin training epoch 689
[2024-10-11 22:35:49,017][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:43:02,705][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 22:44:25,435][train_inner][INFO] - {"epoch": 689, "update": 688.372, "loss": "0.744", "ntokens": "262955", "nsentences": "1738.04", "wps": "95681.7", "ups": "0.36", "wpb": "262955", "bsz": "1738", "num_updates": "329600", "lr": "9.56522e-05", "gnorm": "0.258", "loss_scale": "2", "train_wall": "184", "gb_free": "40.5", "wall": "621258"}
[2024-10-11 22:48:18,547][train_inner][INFO] - {"epoch": 689, "update": 688.789, "loss": "0.744", "ntokens": "263849", "nsentences": "1784.85", "wps": "226391", "ups": "0.86", "wpb": "263849", "bsz": "1784.9", "num_updates": "329800", "lr": "9.53804e-05", "gnorm": "0.242", "loss_scale": "2", "train_wall": "176", "gb_free": "40", "wall": "621491"}
[2024-10-11 22:50:36,119][fairseq_cli.train][INFO] - end of epoch 689 (average epoch stats below)
[2024-10-11 22:50:36,152][train][INFO] - {"epoch": 689, "train_loss": "0.745", "train_ntokens": "263478", "train_nsentences": "1754.09", "train_wps": "141938", "train_ups": "0.54", "train_wpb": "263478", "train_bsz": "1754.1", "train_num_updates": "329901", "train_lr": "9.52432e-05", "train_gnorm": "0.248", "train_loss_scale": "2", "train_train_wall": "463", "train_gb_free": "39.2", "train_wall": "621628"}
[2024-10-11 22:50:36,507][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:50:36,536][fairseq.trainer][INFO] - begin training epoch 690
[2024-10-11 22:50:36,537][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:57:49,041][train_inner][INFO] - {"epoch": 690, "update": 689.207, "loss": "0.746", "ntokens": "262760", "nsentences": "1726.64", "wps": "92118.3", "ups": "0.35", "wpb": "262760", "bsz": "1726.6", "num_updates": "330000", "lr": "9.51087e-05", "gnorm": "0.242", "loss_scale": "2", "train_wall": "242", "gb_free": "39.6", "wall": "622061"}
[2024-10-11 23:01:33,835][train_inner][INFO] - {"epoch": 690, "update": 689.624, "loss": "0.745", "ntokens": "264014", "nsentences": "1751.07", "wps": "234914", "ups": "0.89", "wpb": "264014", "bsz": "1751.1", "num_updates": "330200", "lr": "9.4837e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "219", "gb_free": "40", "wall": "622286"}
[2024-10-11 23:05:21,722][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 690 @ 330380 updates
[2024-10-11 23:05:21,730][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 23:05:30,440][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-11 23:05:30,680][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 690 @ 330380 updates, score None) (writing took 8.958254330791533 seconds)
[2024-10-11 23:05:30,702][fairseq_cli.train][INFO] - end of epoch 690 (average epoch stats below)
[2024-10-11 23:05:30,704][train][INFO] - {"epoch": 690, "train_loss": "0.746", "train_ntokens": "263469", "train_nsentences": "1753.71", "train_wps": "141102", "train_ups": "0.54", "train_wpb": "263469", "train_bsz": "1753.7", "train_num_updates": "330380", "train_lr": "9.45924e-05", "train_gnorm": "0.246", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.1", "train_wall": "622523"}
[2024-10-11 23:05:30,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:05:30,808][fairseq.trainer][INFO] - begin training epoch 691
[2024-10-11 23:05:30,808][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:11:24,993][train_inner][INFO] - {"epoch": 691, "update": 690.042, "loss": "0.748", "ntokens": "262705", "nsentences": "1769.8", "wps": "88882.1", "ups": "0.34", "wpb": "262705", "bsz": "1769.8", "num_updates": "330400", "lr": "9.45652e-05", "gnorm": "0.254", "loss_scale": "2", "train_wall": "264", "gb_free": "39.6", "wall": "622877"}
[2024-10-11 23:14:57,374][train_inner][INFO] - {"epoch": 691, "update": 690.459, "loss": "0.745", "ntokens": "263741", "nsentences": "1780.71", "wps": "248396", "ups": "0.94", "wpb": "263741", "bsz": "1780.7", "num_updates": "330600", "lr": "9.42935e-05", "gnorm": "0.249", "loss_scale": "2", "train_wall": "206", "gb_free": "40.3", "wall": "623090"}
[2024-10-11 23:19:13,299][train_inner][INFO] - {"epoch": 691, "update": 690.877, "loss": "0.745", "ntokens": "264049", "nsentences": "1744.28", "wps": "206360", "ups": "0.78", "wpb": "264049", "bsz": "1744.3", "num_updates": "330800", "lr": "9.40217e-05", "gnorm": "0.255", "loss_scale": "2", "train_wall": "250", "gb_free": "39.6", "wall": "623345"}
[2024-10-11 23:20:22,932][fairseq_cli.train][INFO] - end of epoch 691 (average epoch stats below)
[2024-10-11 23:20:22,969][train][INFO] - {"epoch": 691, "train_loss": "0.745", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "141449", "train_ups": "0.54", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "330859", "train_lr": "9.39416e-05", "train_gnorm": "0.251", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "40.6", "train_wall": "623415"}
[2024-10-11 23:20:23,253][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:20:23,275][fairseq.trainer][INFO] - begin training epoch 692
[2024-10-11 23:20:23,276][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:28:23,539][train_inner][INFO] - {"epoch": 692, "update": 691.294, "loss": "0.744", "ntokens": "263365", "nsentences": "1702.7", "wps": "95730.7", "ups": "0.36", "wpb": "263365", "bsz": "1702.7", "num_updates": "331000", "lr": "9.375e-05", "gnorm": "0.241", "loss_scale": "2", "train_wall": "196", "gb_free": "39.3", "wall": "623896"}
[2024-10-11 23:31:55,570][train_inner][INFO] - {"epoch": 692, "update": 691.712, "loss": "0.745", "ntokens": "263867", "nsentences": "1765.41", "wps": "248944", "ups": "0.94", "wpb": "263867", "bsz": "1765.4", "num_updates": "331200", "lr": "9.34783e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "207", "gb_free": "39.8", "wall": "624108"}
[2024-10-11 23:34:50,347][fairseq_cli.train][INFO] - end of epoch 692 (average epoch stats below)
[2024-10-11 23:34:50,374][train][INFO] - {"epoch": 692, "train_loss": "0.745", "train_ntokens": "263540", "train_nsentences": "1753.71", "train_wps": "145541", "train_ups": "0.55", "train_wpb": "263540", "train_bsz": "1753.7", "train_num_updates": "331338", "train_lr": "9.32908e-05", "train_gnorm": "0.247", "train_loss_scale": "2", "train_train_wall": "460", "train_gb_free": "39.3", "train_wall": "624283"}
[2024-10-11 23:34:50,437][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:34:50,442][fairseq.trainer][INFO] - begin training epoch 693
[2024-10-11 23:34:50,443][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:41:18,931][train_inner][INFO] - {"epoch": 693, "update": 692.129, "loss": "0.745", "ntokens": "262694", "nsentences": "1775.69", "wps": "93269.3", "ups": "0.36", "wpb": "262694", "bsz": "1775.7", "num_updates": "331400", "lr": "9.32065e-05", "gnorm": "0.25", "loss_scale": "2", "train_wall": "192", "gb_free": "40.2", "wall": "624671"}
[2024-10-11 23:45:03,363][train_inner][INFO] - {"epoch": 693, "update": 692.547, "loss": "0.744", "ntokens": "264241", "nsentences": "1734.26", "wps": "235495", "ups": "0.89", "wpb": "264241", "bsz": "1734.3", "num_updates": "331600", "lr": "9.29348e-05", "gnorm": "0.25", "loss_scale": "4", "train_wall": "219", "gb_free": "40", "wall": "624896"}
[2024-10-11 23:48:32,766][train_inner][INFO] - {"epoch": 693, "update": 692.965, "loss": "0.746", "ntokens": "263782", "nsentences": "1771.41", "wps": "251980", "ups": "0.96", "wpb": "263782", "bsz": "1771.4", "num_updates": "331800", "lr": "9.2663e-05", "gnorm": "0.234", "loss_scale": "4", "train_wall": "202", "gb_free": "39.7", "wall": "625105"}
[2024-10-11 23:49:17,377][fairseq_cli.train][INFO] - end of epoch 693 (average epoch stats below)
[2024-10-11 23:49:17,418][train][INFO] - {"epoch": 693, "train_loss": "0.745", "train_ntokens": "263540", "train_nsentences": "1753.71", "train_wps": "145597", "train_ups": "0.55", "train_wpb": "263540", "train_bsz": "1753.7", "train_num_updates": "331817", "train_lr": "9.26399e-05", "train_gnorm": "0.242", "train_loss_scale": "4", "train_train_wall": "534", "train_gb_free": "39.6", "train_wall": "625150"}
[2024-10-11 23:49:17,611][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:49:17,651][fairseq.trainer][INFO] - begin training epoch 694
[2024-10-11 23:49:17,652][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:58:19,570][train_inner][INFO] - {"epoch": 694, "update": 693.382, "loss": "0.744", "ntokens": "263254", "nsentences": "1715.28", "wps": "89726.3", "ups": "0.34", "wpb": "263254", "bsz": "1715.3", "num_updates": "332000", "lr": "9.23913e-05", "gnorm": "0.242", "loss_scale": "4", "train_wall": "187", "gb_free": "39.6", "wall": "625692"}
[2024-10-12 00:01:59,492][train_inner][INFO] - {"epoch": 694, "update": 693.8, "loss": "0.745", "ntokens": "263968", "nsentences": "1775.39", "wps": "240140", "ups": "0.91", "wpb": "263968", "bsz": "1775.4", "num_updates": "332200", "lr": "9.21196e-05", "gnorm": "0.241", "loss_scale": "4", "train_wall": "152", "gb_free": "39.6", "wall": "625912"}
[2024-10-12 00:03:56,965][fairseq_cli.train][INFO] - end of epoch 694 (average epoch stats below)
[2024-10-12 00:03:56,996][train][INFO] - {"epoch": 694, "train_loss": "0.745", "train_ntokens": "263607", "train_nsentences": "1753.71", "train_wps": "143562", "train_ups": "0.54", "train_wpb": "263607", "train_bsz": "1753.7", "train_num_updates": "332296", "train_lr": "9.19891e-05", "train_gnorm": "0.244", "train_loss_scale": "4", "train_train_wall": "391", "train_gb_free": "39.6", "train_wall": "626029"}
[2024-10-12 00:03:57,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:03:57,181][fairseq.trainer][INFO] - begin training epoch 695
[2024-10-12 00:03:57,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:11:18,200][train_inner][INFO] - {"epoch": 695, "update": 694.217, "loss": "0.746", "ntokens": "262683", "nsentences": "1752.54", "wps": "94036.6", "ups": "0.36", "wpb": "262683", "bsz": "1752.5", "num_updates": "332400", "lr": "9.18478e-05", "gnorm": "0.246", "loss_scale": "4", "train_wall": "233", "gb_free": "39.2", "wall": "626470"}
[2024-10-12 00:15:17,962][train_inner][INFO] - {"epoch": 695, "update": 694.635, "loss": "0.744", "ntokens": "264151", "nsentences": "1743.83", "wps": "220355", "ups": "0.83", "wpb": "264151", "bsz": "1743.8", "num_updates": "332600", "lr": "9.15761e-05", "gnorm": "0.25", "loss_scale": "4", "train_wall": "235", "gb_free": "39.3", "wall": "626710"}
[2024-10-12 00:16:36,071][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 00:19:04,467][fairseq_cli.train][INFO] - end of epoch 695 (average epoch stats below)
[2024-10-12 00:19:04,502][train][INFO] - {"epoch": 695, "train_loss": "0.745", "train_ntokens": "263512", "train_nsentences": "1753.66", "train_wps": "138812", "train_ups": "0.53", "train_wpb": "263512", "train_bsz": "1753.7", "train_num_updates": "332774", "train_lr": "9.13397e-05", "train_gnorm": "0.245", "train_loss_scale": "2", "train_train_wall": "593", "train_gb_free": "39.2", "train_wall": "626937"}
[2024-10-12 00:19:04,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:19:04,763][fairseq.trainer][INFO] - begin training epoch 696
[2024-10-12 00:19:04,764][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:25:09,045][train_inner][INFO] - {"epoch": 696, "update": 695.054, "loss": "0.747", "ntokens": "262725", "nsentences": "1776.25", "wps": "88897.9", "ups": "0.34", "wpb": "262725", "bsz": "1776.2", "num_updates": "332800", "lr": "9.13043e-05", "gnorm": "0.248", "loss_scale": "2", "train_wall": "278", "gb_free": "39.3", "wall": "627301"}
[2024-10-12 00:29:09,230][train_inner][INFO] - {"epoch": 696, "update": 695.472, "loss": "0.744", "ntokens": "263889", "nsentences": "1747.88", "wps": "219756", "ups": "0.83", "wpb": "263889", "bsz": "1747.9", "num_updates": "333000", "lr": "9.10326e-05", "gnorm": "0.242", "loss_scale": "2", "train_wall": "235", "gb_free": "39.6", "wall": "627541"}
[2024-10-12 00:33:26,792][train_inner][INFO] - {"epoch": 696, "update": 695.889, "loss": "0.746", "ntokens": "264266", "nsentences": "1741.58", "wps": "205218", "ups": "0.78", "wpb": "264266", "bsz": "1741.6", "num_updates": "333200", "lr": "9.07609e-05", "gnorm": "0.25", "loss_scale": "2", "train_wall": "252", "gb_free": "40.5", "wall": "627799"}
[2024-10-12 00:34:34,913][fairseq_cli.train][INFO] - end of epoch 696 (average epoch stats below)
[2024-10-12 00:34:34,924][train][INFO] - {"epoch": 696, "train_loss": "0.745", "train_ntokens": "263512", "train_nsentences": "1753.71", "train_wps": "135667", "train_ups": "0.51", "train_wpb": "263512", "train_bsz": "1753.7", "train_num_updates": "333253", "train_lr": "9.06889e-05", "train_gnorm": "0.248", "train_loss_scale": "2", "train_train_wall": "611", "train_gb_free": "39.6", "train_wall": "627867"}
[2024-10-12 00:34:35,134][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:34:35,148][fairseq.trainer][INFO] - begin training epoch 697
[2024-10-12 00:34:35,149][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:43:09,356][train_inner][INFO] - {"epoch": 697, "update": 696.307, "loss": "0.744", "ntokens": "262494", "nsentences": "1778.47", "wps": "90120.2", "ups": "0.34", "wpb": "262494", "bsz": "1778.5", "num_updates": "333400", "lr": "9.04891e-05", "gnorm": "0.251", "loss_scale": "2", "train_wall": "258", "gb_free": "39.7", "wall": "628382"}
[2024-10-12 00:47:16,877][train_inner][INFO] - {"epoch": 697, "update": 696.724, "loss": "0.745", "ntokens": "263945", "nsentences": "1751.81", "wps": "213282", "ups": "0.81", "wpb": "263944", "bsz": "1751.8", "num_updates": "333600", "lr": "9.02174e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "243", "gb_free": "39.3", "wall": "628629"}
[2024-10-12 00:50:07,014][fairseq_cli.train][INFO] - end of epoch 697 (average epoch stats below)
[2024-10-12 00:50:07,046][train][INFO] - {"epoch": 697, "train_loss": "0.745", "train_ntokens": "263425", "train_nsentences": "1753.71", "train_wps": "135375", "train_ups": "0.51", "train_wpb": "263425", "train_bsz": "1753.7", "train_num_updates": "333732", "train_lr": "9.0038e-05", "train_gnorm": "0.239", "train_loss_scale": "2", "train_train_wall": "600", "train_gb_free": "39.7", "train_wall": "628799"}
[2024-10-12 00:50:07,276][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:50:07,324][fairseq.trainer][INFO] - begin training epoch 698
[2024-10-12 00:50:07,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:57:07,584][train_inner][INFO] - {"epoch": 698, "update": 697.142, "loss": "0.747", "ntokens": "262511", "nsentences": "1775.56", "wps": "88885.1", "ups": "0.34", "wpb": "262511", "bsz": "1775.6", "num_updates": "333800", "lr": "8.99457e-05", "gnorm": "0.244", "loss_scale": "2", "train_wall": "275", "gb_free": "40", "wall": "629220"}
[2024-10-12 01:01:10,902][train_inner][INFO] - {"epoch": 698, "update": 697.559, "loss": "0.743", "ntokens": "264254", "nsentences": "1742.74", "wps": "217223", "ups": "0.82", "wpb": "264254", "bsz": "1742.7", "num_updates": "334000", "lr": "8.96739e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "237", "gb_free": "40.3", "wall": "629463"}
[2024-10-12 01:05:05,628][train_inner][INFO] - {"epoch": 698, "update": 697.977, "loss": "0.742", "ntokens": "264087", "nsentences": "1735.41", "wps": "225026", "ups": "0.85", "wpb": "264087", "bsz": "1735.4", "num_updates": "334200", "lr": "8.94022e-05", "gnorm": "0.25", "loss_scale": "2", "train_wall": "230", "gb_free": "39.8", "wall": "629698"}
[2024-10-12 01:05:43,557][fairseq_cli.train][INFO] - end of epoch 698 (average epoch stats below)
[2024-10-12 01:05:43,583][train][INFO] - {"epoch": 698, "train_loss": "0.743", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "134765", "train_ups": "0.51", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "334211", "train_lr": "8.93872e-05", "train_gnorm": "0.249", "train_loss_scale": "2", "train_train_wall": "612", "train_gb_free": "39.6", "train_wall": "629736"}
[2024-10-12 01:05:43,891][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:05:43,931][fairseq.trainer][INFO] - begin training epoch 699
[2024-10-12 01:05:43,931][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:15:10,779][train_inner][INFO] - {"epoch": 699, "update": 698.395, "loss": "0.744", "ntokens": "263017", "nsentences": "1744.52", "wps": "86929.7", "ups": "0.33", "wpb": "263017", "bsz": "1744.5", "num_updates": "334400", "lr": "8.91304e-05", "gnorm": "0.238", "loss_scale": "2", "train_wall": "285", "gb_free": "39.6", "wall": "630303"}
[2024-10-12 01:15:21,206][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-12 01:19:29,002][train_inner][INFO] - {"epoch": 699, "update": 698.814, "loss": "0.745", "ntokens": "264130", "nsentences": "1765.38", "wps": "204604", "ups": "0.77", "wpb": "264130", "bsz": "1765.4", "num_updates": "334600", "lr": "8.88587e-05", "gnorm": "0.234", "loss_scale": "1", "train_wall": "254", "gb_free": "40.3", "wall": "630561"}
[2024-10-12 01:21:07,002][fairseq_cli.train][INFO] - end of epoch 699 (average epoch stats below)
[2024-10-12 01:21:07,054][train][INFO] - {"epoch": 699, "train_loss": "0.745", "train_ntokens": "263669", "train_nsentences": "1752.67", "train_wps": "136486", "train_ups": "0.52", "train_wpb": "263669", "train_bsz": "1752.7", "train_num_updates": "334689", "train_lr": "8.87378e-05", "train_gnorm": "0.238", "train_loss_scale": "1", "train_train_wall": "598", "train_gb_free": "39.2", "train_wall": "630659"}
[2024-10-12 01:21:07,592][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:21:07,639][fairseq.trainer][INFO] - begin training epoch 700
[2024-10-12 01:21:07,639][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:29:07,327][train_inner][INFO] - {"epoch": 700, "update": 699.232, "loss": "0.746", "ntokens": "262589", "nsentences": "1769.23", "wps": "90812.4", "ups": "0.35", "wpb": "262589", "bsz": "1769.2", "num_updates": "334800", "lr": "8.8587e-05", "gnorm": "0.248", "loss_scale": "1", "train_wall": "243", "gb_free": "40", "wall": "631139"}
[2024-10-12 01:32:56,721][train_inner][INFO] - {"epoch": 700, "update": 699.649, "loss": "0.744", "ntokens": "264286", "nsentences": "1747.79", "wps": "230466", "ups": "0.87", "wpb": "264286", "bsz": "1747.8", "num_updates": "335000", "lr": "8.83152e-05", "gnorm": "0.247", "loss_scale": "1", "train_wall": "223", "gb_free": "40", "wall": "631369"}
[2024-10-12 01:36:06,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 700 @ 335168 updates
[2024-10-12 01:36:06,518][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 01:36:11,927][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 01:36:12,110][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 700 @ 335168 updates, score None) (writing took 5.593757132068276 seconds)
[2024-10-12 01:36:12,120][fairseq_cli.train][INFO] - end of epoch 700 (average epoch stats below)
[2024-10-12 01:36:12,123][train][INFO] - {"epoch": 700, "train_loss": "0.744", "train_ntokens": "263583", "train_nsentences": "1753.71", "train_wps": "139509", "train_ups": "0.53", "train_wpb": "263584", "train_bsz": "1753.7", "train_num_updates": "335168", "train_lr": "8.8087e-05", "train_gnorm": "0.247", "train_loss_scale": "1", "train_train_wall": "554", "train_gb_free": "39.6", "train_wall": "631564"}
[2024-10-12 01:36:12,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:36:12,253][fairseq.trainer][INFO] - begin training epoch 701
[2024-10-12 01:36:12,254][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:42:11,809][train_inner][INFO] - {"epoch": 701, "update": 700.067, "loss": "0.743", "ntokens": "262723", "nsentences": "1765.69", "wps": "94664.3", "ups": "0.36", "wpb": "262723", "bsz": "1765.7", "num_updates": "335200", "lr": "8.80435e-05", "gnorm": "0.254", "loss_scale": "1", "train_wall": "232", "gb_free": "40.1", "wall": "631924"}
[2024-10-12 01:45:46,572][train_inner][INFO] - {"epoch": 701, "update": 700.484, "loss": "0.743", "ntokens": "263865", "nsentences": "1749.94", "wps": "245750", "ups": "0.93", "wpb": "263865", "bsz": "1749.9", "num_updates": "335400", "lr": "8.77717e-05", "gnorm": "0.245", "loss_scale": "1", "train_wall": "209", "gb_free": "40.5", "wall": "632139"}
[2024-10-12 01:49:31,695][train_inner][INFO] - {"epoch": 701, "update": 700.902, "loss": "0.743", "ntokens": "264231", "nsentences": "1735.53", "wps": "234758", "ups": "0.89", "wpb": "264231", "bsz": "1735.5", "num_updates": "335600", "lr": "8.75e-05", "gnorm": "0.25", "loss_scale": "1", "train_wall": "220", "gb_free": "39.3", "wall": "632364"}
[2024-10-12 01:50:30,365][fairseq_cli.train][INFO] - end of epoch 701 (average epoch stats below)
[2024-10-12 01:50:30,390][train][INFO] - {"epoch": 701, "train_loss": "0.744", "train_ntokens": "263458", "train_nsentences": "1753.71", "train_wps": "147044", "train_ups": "0.56", "train_wpb": "263458", "train_bsz": "1753.7", "train_num_updates": "335647", "train_lr": "8.74361e-05", "train_gnorm": "0.251", "train_loss_scale": "1", "train_train_wall": "533", "train_gb_free": "39.3", "train_wall": "632423"}
[2024-10-12 01:50:30,598][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:50:30,609][fairseq.trainer][INFO] - begin training epoch 702
[2024-10-12 01:50:30,609][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:58:54,401][train_inner][INFO] - {"epoch": 702, "update": 701.319, "loss": "0.745", "ntokens": "262613", "nsentences": "1780.53", "wps": "93344.6", "ups": "0.36", "wpb": "262613", "bsz": "1780.5", "num_updates": "335800", "lr": "8.72283e-05", "gnorm": "0.253", "loss_scale": "1", "train_wall": "247", "gb_free": "40", "wall": "632927"}
[2024-10-12 02:02:48,032][train_inner][INFO] - {"epoch": 702, "update": 701.737, "loss": "0.743", "ntokens": "264218", "nsentences": "1744.88", "wps": "226212", "ups": "0.86", "wpb": "264218", "bsz": "1744.9", "num_updates": "336000", "lr": "8.69565e-05", "gnorm": "0.242", "loss_scale": "1", "train_wall": "228", "gb_free": "39.1", "wall": "633160"}
[2024-10-12 02:05:12,887][fairseq_cli.train][INFO] - end of epoch 702 (average epoch stats below)
[2024-10-12 02:05:12,900][train][INFO] - {"epoch": 702, "train_loss": "0.744", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "143033", "train_ups": "0.54", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "336126", "train_lr": "8.67853e-05", "train_gnorm": "0.243", "train_loss_scale": "1", "train_train_wall": "560", "train_gb_free": "39.6", "train_wall": "633305"}
[2024-10-12 02:05:12,985][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:05:12,997][fairseq.trainer][INFO] - begin training epoch 703
[2024-10-12 02:05:12,997][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:12:14,734][train_inner][INFO] - {"epoch": 703, "update": 702.154, "loss": "0.743", "ntokens": "262554", "nsentences": "1764.01", "wps": "92665.9", "ups": "0.35", "wpb": "262554", "bsz": "1764", "num_updates": "336200", "lr": "8.66848e-05", "gnorm": "0.239", "loss_scale": "1", "train_wall": "233", "gb_free": "39.6", "wall": "633727"}
[2024-10-12 02:15:48,599][train_inner][INFO] - {"epoch": 703, "update": 702.572, "loss": "0.743", "ntokens": "264249", "nsentences": "1740.79", "wps": "247138", "ups": "0.94", "wpb": "264249", "bsz": "1740.8", "num_updates": "336400", "lr": "8.6413e-05", "gnorm": "0.238", "loss_scale": "1", "train_wall": "163", "gb_free": "40", "wall": "633941"}
[2024-10-12 02:19:37,842][train_inner][INFO] - {"epoch": 703, "update": 702.99, "loss": "0.743", "ntokens": "264212", "nsentences": "1734.43", "wps": "230589", "ups": "0.87", "wpb": "264212", "bsz": "1734.4", "num_updates": "336600", "lr": "8.61413e-05", "gnorm": "0.25", "loss_scale": "2", "train_wall": "223", "gb_free": "39.2", "wall": "634170"}
[2024-10-12 02:19:59,196][fairseq_cli.train][INFO] - end of epoch 703 (average epoch stats below)
[2024-10-12 02:19:59,210][train][INFO] - {"epoch": 703, "train_loss": "0.743", "train_ntokens": "263537", "train_nsentences": "1753.71", "train_wps": "142430", "train_ups": "0.54", "train_wpb": "263537", "train_bsz": "1753.7", "train_num_updates": "336605", "train_lr": "8.61345e-05", "train_gnorm": "0.244", "train_loss_scale": "2", "train_train_wall": "498", "train_gb_free": "39.6", "train_wall": "634191"}
[2024-10-12 02:19:59,284][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:19:59,322][fairseq.trainer][INFO] - begin training epoch 704
[2024-10-12 02:19:59,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:29:38,659][train_inner][INFO] - {"epoch": 704, "update": 703.407, "loss": "0.742", "ntokens": "262360", "nsentences": "1776.82", "wps": "87350.3", "ups": "0.33", "wpb": "262360", "bsz": "1776.8", "num_updates": "336800", "lr": "8.58696e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "261", "gb_free": "39.3", "wall": "634771"}
[2024-10-12 02:33:32,081][train_inner][INFO] - {"epoch": 704, "update": 703.825, "loss": "0.743", "ntokens": "264244", "nsentences": "1736.53", "wps": "226450", "ups": "0.86", "wpb": "264244", "bsz": "1736.5", "num_updates": "337000", "lr": "8.55978e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "228", "gb_free": "39.3", "wall": "635004"}
[2024-10-12 02:35:19,213][fairseq_cli.train][INFO] - end of epoch 704 (average epoch stats below)
[2024-10-12 02:35:19,244][train][INFO] - {"epoch": 704, "train_loss": "0.743", "train_ntokens": "263523", "train_nsentences": "1753.71", "train_wps": "137200", "train_ups": "0.52", "train_wpb": "263523", "train_bsz": "1753.7", "train_num_updates": "337084", "train_lr": "8.54837e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "39.6", "train_wall": "635111"}
[2024-10-12 02:35:19,291][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:35:19,296][fairseq.trainer][INFO] - begin training epoch 705
[2024-10-12 02:35:19,297][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:43:01,218][train_inner][INFO] - {"epoch": 705, "update": 704.242, "loss": "0.743", "ntokens": "262998", "nsentences": "1735.7", "wps": "92423.8", "ups": "0.35", "wpb": "262998", "bsz": "1735.7", "num_updates": "337200", "lr": "8.53261e-05", "gnorm": "0.238", "loss_scale": "2", "train_wall": "249", "gb_free": "39.6", "wall": "635573"}
[2024-10-12 02:46:49,116][train_inner][INFO] - {"epoch": 705, "update": 704.66, "loss": "0.741", "ntokens": "264046", "nsentences": "1757.1", "wps": "231756", "ups": "0.88", "wpb": "264046", "bsz": "1757.1", "num_updates": "337400", "lr": "8.50543e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "222", "gb_free": "40.3", "wall": "635801"}
[2024-10-12 02:50:28,300][fairseq_cli.train][INFO] - end of epoch 705 (average epoch stats below)
[2024-10-12 02:50:28,337][train][INFO] - {"epoch": 705, "train_loss": "0.742", "train_ntokens": "263518", "train_nsentences": "1753.71", "train_wps": "138849", "train_ups": "0.53", "train_wpb": "263518", "train_bsz": "1753.7", "train_num_updates": "337563", "train_lr": "8.48329e-05", "train_gnorm": "0.247", "train_loss_scale": "2", "train_train_wall": "578", "train_gb_free": "39.3", "train_wall": "636021"}
[2024-10-12 02:50:28,399][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:50:28,417][fairseq.trainer][INFO] - begin training epoch 706
[2024-10-12 02:50:28,418][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:56:34,400][train_inner][INFO] - {"epoch": 706, "update": 705.077, "loss": "0.745", "ntokens": "262850", "nsentences": "1761.71", "wps": "89825.3", "ups": "0.34", "wpb": "262850", "bsz": "1761.7", "num_updates": "337600", "lr": "8.47826e-05", "gnorm": "0.251", "loss_scale": "2", "train_wall": "278", "gb_free": "39.6", "wall": "636387"}
[2024-10-12 03:00:04,810][train_inner][INFO] - {"epoch": 706, "update": 705.495, "loss": "0.742", "ntokens": "264110", "nsentences": "1737.76", "wps": "251077", "ups": "0.95", "wpb": "264110", "bsz": "1737.8", "num_updates": "337800", "lr": "8.45109e-05", "gnorm": "0.251", "loss_scale": "2", "train_wall": "205", "gb_free": "39.6", "wall": "636597"}
[2024-10-12 03:04:09,403][train_inner][INFO] - {"epoch": 706, "update": 705.912, "loss": "0.745", "ntokens": "263720", "nsentences": "1802.48", "wps": "215654", "ups": "0.82", "wpb": "263720", "bsz": "1802.5", "num_updates": "338000", "lr": "8.42391e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "239", "gb_free": "40.1", "wall": "636842"}
[2024-10-12 03:04:59,993][fairseq_cli.train][INFO] - end of epoch 706 (average epoch stats below)
[2024-10-12 03:04:59,995][train][INFO] - {"epoch": 706, "train_loss": "0.743", "train_ntokens": "263561", "train_nsentences": "1753.71", "train_wps": "144837", "train_ups": "0.55", "train_wpb": "263561", "train_bsz": "1753.7", "train_num_updates": "338042", "train_lr": "8.41821e-05", "train_gnorm": "0.248", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.3", "train_wall": "636892"}
[2024-10-12 03:05:00,154][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:05:00,181][fairseq.trainer][INFO] - begin training epoch 707
[2024-10-12 03:05:00,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:13:55,190][train_inner][INFO] - {"epoch": 707, "update": 706.33, "loss": "0.741", "ntokens": "263124", "nsentences": "1710.35", "wps": "89837.9", "ups": "0.34", "wpb": "263124", "bsz": "1710.3", "num_updates": "338200", "lr": "8.39674e-05", "gnorm": "0.229", "loss_scale": "2", "train_wall": "246", "gb_free": "39.3", "wall": "637427"}
[2024-10-12 03:18:13,604][train_inner][INFO] - {"epoch": 707, "update": 706.747, "loss": "0.741", "ntokens": "264068", "nsentences": "1758.3", "wps": "204398", "ups": "0.77", "wpb": "264068", "bsz": "1758.3", "num_updates": "338400", "lr": "8.36957e-05", "gnorm": "0.238", "loss_scale": "2", "train_wall": "253", "gb_free": "39.6", "wall": "637686"}
[2024-10-12 03:20:55,185][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 03:21:02,502][fairseq_cli.train][INFO] - end of epoch 707 (average epoch stats below)
[2024-10-12 03:21:02,518][train][INFO] - {"epoch": 707, "train_loss": "0.743", "train_ntokens": "263541", "train_nsentences": "1754.27", "train_wps": "130883", "train_ups": "0.5", "train_wpb": "263541", "train_bsz": "1754.3", "train_num_updates": "338520", "train_lr": "8.35326e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "617", "train_gb_free": "40.2", "train_wall": "637855"}
[2024-10-12 03:21:02,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:21:02,623][fairseq.trainer][INFO] - begin training epoch 708
[2024-10-12 03:21:02,623][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:27:59,369][train_inner][INFO] - {"epoch": 708, "update": 707.167, "loss": "0.745", "ntokens": "262627", "nsentences": "1770.1", "wps": "89673.6", "ups": "0.34", "wpb": "262627", "bsz": "1770.1", "num_updates": "338600", "lr": "8.34239e-05", "gnorm": "0.25", "loss_scale": "2", "train_wall": "264", "gb_free": "39.6", "wall": "638272"}
[2024-10-12 03:32:20,093][train_inner][INFO] - {"epoch": 708, "update": 707.585, "loss": "0.745", "ntokens": "263597", "nsentences": "1797.45", "wps": "202216", "ups": "0.77", "wpb": "263598", "bsz": "1797.5", "num_updates": "338800", "lr": "8.31522e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "255", "gb_free": "39.2", "wall": "638532"}
[2024-10-12 03:36:41,861][fairseq_cli.train][INFO] - end of epoch 708 (average epoch stats below)
[2024-10-12 03:36:41,876][train][INFO] - {"epoch": 708, "train_loss": "0.743", "train_ntokens": "263574", "train_nsentences": "1753.71", "train_wps": "134404", "train_ups": "0.51", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "338999", "train_lr": "8.28818e-05", "train_gnorm": "0.238", "train_loss_scale": "2", "train_train_wall": "609", "train_gb_free": "40.5", "train_wall": "638794"}
[2024-10-12 03:36:41,934][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:36:41,940][fairseq.trainer][INFO] - begin training epoch 709
[2024-10-12 03:36:41,941][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:42:11,864][train_inner][INFO] - {"epoch": 709, "update": 708.002, "loss": "0.74", "ntokens": "263530", "nsentences": "1699.68", "wps": "89066.9", "ups": "0.34", "wpb": "263530", "bsz": "1699.7", "num_updates": "339000", "lr": "8.28804e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "282", "gb_free": "39.3", "wall": "639124"}
[2024-10-12 03:45:39,254][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-12 03:46:07,669][train_inner][INFO] - {"epoch": 709, "update": 708.422, "loss": "0.741", "ntokens": "264138", "nsentences": "1737.15", "wps": "224047", "ups": "0.85", "wpb": "264138", "bsz": "1737.2", "num_updates": "339200", "lr": "8.26087e-05", "gnorm": "0.239", "loss_scale": "1", "train_wall": "231", "gb_free": "40.5", "wall": "639360"}
[2024-10-12 03:50:32,414][train_inner][INFO] - {"epoch": 709, "update": 708.839, "loss": "0.743", "ntokens": "263821", "nsentences": "1792.12", "wps": "199330", "ups": "0.76", "wpb": "263822", "bsz": "1792.1", "num_updates": "339400", "lr": "8.2337e-05", "gnorm": "0.249", "loss_scale": "1", "train_wall": "259", "gb_free": "39.3", "wall": "639625"}
[2024-10-12 03:52:03,229][fairseq_cli.train][INFO] - end of epoch 709 (average epoch stats below)
[2024-10-12 03:52:03,250][train][INFO] - {"epoch": 709, "train_loss": "0.742", "train_ntokens": "263592", "train_nsentences": "1752.61", "train_wps": "136752", "train_ups": "0.52", "train_wpb": "263592", "train_bsz": "1752.6", "train_num_updates": "339477", "train_lr": "8.22323e-05", "train_gnorm": "0.241", "train_loss_scale": "1", "train_train_wall": "606", "train_gb_free": "40", "train_wall": "639715"}
[2024-10-12 03:52:03,357][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:52:03,394][fairseq.trainer][INFO] - begin training epoch 710
[2024-10-12 03:52:03,394][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:59:52,878][train_inner][INFO] - {"epoch": 710, "update": 709.257, "loss": "0.74", "ntokens": "262988", "nsentences": "1733.53", "wps": "93848.4", "ups": "0.36", "wpb": "262988", "bsz": "1733.5", "num_updates": "339600", "lr": "8.20652e-05", "gnorm": "0.247", "loss_scale": "1", "train_wall": "238", "gb_free": "39.6", "wall": "640185"}
[2024-10-12 04:03:43,143][train_inner][INFO] - {"epoch": 710, "update": 709.674, "loss": "0.742", "ntokens": "263627", "nsentences": "1771.92", "wps": "228992", "ups": "0.87", "wpb": "263627", "bsz": "1771.9", "num_updates": "339800", "lr": "8.17935e-05", "gnorm": "0.242", "loss_scale": "1", "train_wall": "225", "gb_free": "39.6", "wall": "640415"}
[2024-10-12 04:06:51,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 710 @ 339956 updates
[2024-10-12 04:06:51,143][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 04:06:56,582][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 04:06:57,008][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 710 @ 339956 updates, score None) (writing took 5.86667207442224 seconds)
[2024-10-12 04:06:57,025][fairseq_cli.train][INFO] - end of epoch 710 (average epoch stats below)
[2024-10-12 04:06:57,046][train][INFO] - {"epoch": 710, "train_loss": "0.742", "train_ntokens": "263370", "train_nsentences": "1753.71", "train_wps": "141150", "train_ups": "0.54", "train_wpb": "263370", "train_bsz": "1753.7", "train_num_updates": "339956", "train_lr": "8.15815e-05", "train_gnorm": "0.244", "train_loss_scale": "1", "train_train_wall": "555", "train_gb_free": "39.2", "train_wall": "640609"}
[2024-10-12 04:06:57,154][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:06:57,175][fairseq.trainer][INFO] - begin training epoch 711
[2024-10-12 04:06:57,176][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:13:20,089][train_inner][INFO] - {"epoch": 711, "update": 710.092, "loss": "0.744", "ntokens": "262806", "nsentences": "1748.42", "wps": "91108.2", "ups": "0.35", "wpb": "262806", "bsz": "1748.4", "num_updates": "340000", "lr": "8.15217e-05", "gnorm": "0.241", "loss_scale": "1", "train_wall": "248", "gb_free": "39.3", "wall": "640992"}
[2024-10-12 04:16:48,181][train_inner][INFO] - {"epoch": 711, "update": 710.509, "loss": "0.74", "ntokens": "264329", "nsentences": "1719.48", "wps": "254064", "ups": "0.96", "wpb": "264329", "bsz": "1719.5", "num_updates": "340200", "lr": "8.125e-05", "gnorm": "0.236", "loss_scale": "1", "train_wall": "203", "gb_free": "39.2", "wall": "641200"}
[2024-10-12 04:20:35,520][train_inner][INFO] - {"epoch": 711, "update": 710.927, "loss": "0.745", "ntokens": "263844", "nsentences": "1785.14", "wps": "232127", "ups": "0.88", "wpb": "263844", "bsz": "1785.1", "num_updates": "340400", "lr": "8.09783e-05", "gnorm": "0.24", "loss_scale": "1", "train_wall": "222", "gb_free": "40", "wall": "641428"}
[2024-10-12 04:21:30,620][fairseq_cli.train][INFO] - end of epoch 711 (average epoch stats below)
[2024-10-12 04:21:30,636][train][INFO] - {"epoch": 711, "train_loss": "0.742", "train_ntokens": "263600", "train_nsentences": "1753.71", "train_wps": "144537", "train_ups": "0.55", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "340435", "train_lr": "8.09307e-05", "train_gnorm": "0.239", "train_loss_scale": "1", "train_train_wall": "547", "train_gb_free": "39.7", "train_wall": "641483"}
[2024-10-12 04:21:30,710][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:21:30,732][fairseq.trainer][INFO] - begin training epoch 712
[2024-10-12 04:21:30,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:30:16,993][train_inner][INFO] - {"epoch": 712, "update": 711.344, "loss": "0.742", "ntokens": "262466", "nsentences": "1793.22", "wps": "90279.7", "ups": "0.34", "wpb": "262466", "bsz": "1793.2", "num_updates": "340600", "lr": "8.07065e-05", "gnorm": "0.236", "loss_scale": "1", "train_wall": "216", "gb_free": "39.6", "wall": "642009"}
[2024-10-12 04:34:06,011][train_inner][INFO] - {"epoch": 712, "update": 711.762, "loss": "0.737", "ntokens": "264283", "nsentences": "1718.61", "wps": "230815", "ups": "0.87", "wpb": "264283", "bsz": "1718.6", "num_updates": "340800", "lr": "8.04348e-05", "gnorm": "0.237", "loss_scale": "1", "train_wall": "159", "gb_free": "40.1", "wall": "642238"}
[2024-10-12 04:36:21,607][fairseq_cli.train][INFO] - end of epoch 712 (average epoch stats below)
[2024-10-12 04:36:21,624][train][INFO] - {"epoch": 712, "train_loss": "0.741", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "141665", "train_ups": "0.54", "train_wpb": "263509", "train_bsz": "1753.7", "train_num_updates": "340914", "train_lr": "8.02799e-05", "train_gnorm": "0.238", "train_loss_scale": "1", "train_train_wall": "419", "train_gb_free": "39.6", "train_wall": "642374"}
[2024-10-12 04:36:21,695][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:36:21,712][fairseq.trainer][INFO] - begin training epoch 713
[2024-10-12 04:36:21,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:43:29,983][train_inner][INFO] - {"epoch": 713, "update": 712.18, "loss": "0.743", "ntokens": "263048", "nsentences": "1738.47", "wps": "93286.1", "ups": "0.35", "wpb": "263048", "bsz": "1738.5", "num_updates": "341000", "lr": "8.0163e-05", "gnorm": "0.242", "loss_scale": "1", "train_wall": "204", "gb_free": "39.3", "wall": "642802"}
[2024-10-12 04:47:17,488][train_inner][INFO] - {"epoch": 713, "update": 712.597, "loss": "0.74", "ntokens": "263992", "nsentences": "1749.65", "wps": "232095", "ups": "0.88", "wpb": "263992", "bsz": "1749.7", "num_updates": "341200", "lr": "7.98913e-05", "gnorm": "0.231", "loss_scale": "1", "train_wall": "221", "gb_free": "39.6", "wall": "643030"}
[2024-10-12 04:50:54,408][fairseq_cli.train][INFO] - end of epoch 713 (average epoch stats below)
[2024-10-12 04:50:54,421][train][INFO] - {"epoch": 713, "train_loss": "0.741", "train_ntokens": "263527", "train_nsentences": "1753.71", "train_wps": "144629", "train_ups": "0.55", "train_wpb": "263527", "train_bsz": "1753.7", "train_num_updates": "341393", "train_lr": "7.96291e-05", "train_gnorm": "0.238", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "39.3", "train_wall": "643247"}
[2024-10-12 04:50:54,533][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:50:54,556][fairseq.trainer][INFO] - begin training epoch 714
[2024-10-12 04:50:54,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:56:33,241][train_inner][INFO] - {"epoch": 714, "update": 713.015, "loss": "0.742", "ntokens": "262930", "nsentences": "1749.82", "wps": "94626.9", "ups": "0.36", "wpb": "262930", "bsz": "1749.8", "num_updates": "341400", "lr": "7.96196e-05", "gnorm": "0.242", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "643585"}
[2024-10-12 05:00:21,931][train_inner][INFO] - {"epoch": 714, "update": 713.432, "loss": "0.742", "ntokens": "263677", "nsentences": "1802.03", "wps": "230700", "ups": "0.87", "wpb": "263677", "bsz": "1802", "num_updates": "341600", "lr": "7.93478e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "171", "gb_free": "39.2", "wall": "643814"}
[2024-10-12 05:04:31,070][train_inner][INFO] - {"epoch": 714, "update": 713.85, "loss": "0.74", "ntokens": "264068", "nsentences": "1737.92", "wps": "212013", "ups": "0.8", "wpb": "264068", "bsz": "1737.9", "num_updates": "341800", "lr": "7.90761e-05", "gnorm": "0.244", "loss_scale": "2", "train_wall": "154", "gb_free": "40.3", "wall": "644063"}
[2024-10-12 05:06:00,741][fairseq_cli.train][INFO] - end of epoch 714 (average epoch stats below)
[2024-10-12 05:06:00,748][train][INFO] - {"epoch": 714, "train_loss": "0.741", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "139281", "train_ups": "0.53", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "341872", "train_lr": "7.89783e-05", "train_gnorm": "0.239", "train_loss_scale": "2", "train_train_wall": "375", "train_gb_free": "39.6", "train_wall": "644153"}
[2024-10-12 05:06:00,875][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:06:00,880][fairseq.trainer][INFO] - begin training epoch 715
[2024-10-12 05:06:00,881][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:13:56,789][train_inner][INFO] - {"epoch": 715, "update": 714.267, "loss": "0.74", "ntokens": "263207", "nsentences": "1711.78", "wps": "93058.5", "ups": "0.35", "wpb": "263207", "bsz": "1711.8", "num_updates": "342000", "lr": "7.88043e-05", "gnorm": "0.225", "loss_scale": "2", "train_wall": "186", "gb_free": "39.6", "wall": "644629"}
[2024-10-12 05:17:58,995][train_inner][INFO] - {"epoch": 715, "update": 714.685, "loss": "0.744", "ntokens": "263795", "nsentences": "1806.35", "wps": "217845", "ups": "0.83", "wpb": "263795", "bsz": "1806.4", "num_updates": "342200", "lr": "7.85326e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "236", "gb_free": "39.1", "wall": "644871"}
[2024-10-12 05:20:47,601][fairseq_cli.train][INFO] - end of epoch 715 (average epoch stats below)
[2024-10-12 05:20:47,650][train][INFO] - {"epoch": 715, "train_loss": "0.742", "train_ntokens": "263655", "train_nsentences": "1753.71", "train_wps": "142408", "train_ups": "0.54", "train_wpb": "263655", "train_bsz": "1753.7", "train_num_updates": "342351", "train_lr": "7.83274e-05", "train_gnorm": "0.239", "train_loss_scale": "2", "train_train_wall": "549", "train_gb_free": "40.2", "train_wall": "645040"}
[2024-10-12 05:20:47,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:20:47,822][fairseq.trainer][INFO] - begin training epoch 716
[2024-10-12 05:20:47,823][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:27:36,893][train_inner][INFO] - {"epoch": 716, "update": 715.102, "loss": "0.74", "ntokens": "263256", "nsentences": "1723.36", "wps": "91112.6", "ups": "0.35", "wpb": "263256", "bsz": "1723.4", "num_updates": "342400", "lr": "7.82609e-05", "gnorm": "0.247", "loss_scale": "2", "train_wall": "231", "gb_free": "39.7", "wall": "645449"}
[2024-10-12 05:31:07,390][train_inner][INFO] - {"epoch": 716, "update": 715.52, "loss": "0.742", "ntokens": "263616", "nsentences": "1817.83", "wps": "250497", "ups": "0.95", "wpb": "263616", "bsz": "1817.8", "num_updates": "342600", "lr": "7.79891e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "197", "gb_free": "39.8", "wall": "645660"}
[2024-10-12 05:34:37,878][train_inner][INFO] - {"epoch": 716, "update": 715.937, "loss": "0.737", "ntokens": "264630", "nsentences": "1681.51", "wps": "251466", "ups": "0.95", "wpb": "264630", "bsz": "1681.5", "num_updates": "342800", "lr": "7.77174e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "197", "gb_free": "39.6", "wall": "645870"}
[2024-10-12 05:35:39,476][fairseq_cli.train][INFO] - end of epoch 716 (average epoch stats below)
[2024-10-12 05:35:39,478][train][INFO] - {"epoch": 716, "train_loss": "0.741", "train_ntokens": "263574", "train_nsentences": "1753.71", "train_wps": "141568", "train_ups": "0.54", "train_wpb": "263574", "train_bsz": "1753.7", "train_num_updates": "342830", "train_lr": "7.76766e-05", "train_gnorm": "0.242", "train_loss_scale": "2", "train_train_wall": "522", "train_gb_free": "39.9", "train_wall": "645932"}
[2024-10-12 05:35:39,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:35:39,533][fairseq.trainer][INFO] - begin training epoch 717
[2024-10-12 05:35:39,534][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:44:16,262][train_inner][INFO] - {"epoch": 717, "update": 716.355, "loss": "0.74", "ntokens": "262528", "nsentences": "1782.56", "wps": "90783", "ups": "0.35", "wpb": "262528", "bsz": "1782.6", "num_updates": "343000", "lr": "7.74457e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "262", "gb_free": "39.6", "wall": "646448"}
[2024-10-12 05:48:02,488][train_inner][INFO] - {"epoch": 717, "update": 716.772, "loss": "0.743", "ntokens": "264218", "nsentences": "1739.09", "wps": "233606", "ups": "0.88", "wpb": "264218", "bsz": "1739.1", "num_updates": "343200", "lr": "7.71739e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "220", "gb_free": "39.3", "wall": "646675"}
[2024-10-12 05:50:16,132][fairseq_cli.train][INFO] - end of epoch 717 (average epoch stats below)
[2024-10-12 05:50:16,145][train][INFO] - {"epoch": 717, "train_loss": "0.741", "train_ntokens": "263564", "train_nsentences": "1753.71", "train_wps": "144009", "train_ups": "0.55", "train_wpb": "263564", "train_bsz": "1753.7", "train_num_updates": "343309", "train_lr": "7.70258e-05", "train_gnorm": "0.234", "train_loss_scale": "4", "train_train_wall": "551", "train_gb_free": "39.6", "train_wall": "646808"}
[2024-10-12 05:50:16,287][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:50:16,307][fairseq.trainer][INFO] - begin training epoch 718
[2024-10-12 05:50:16,308][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:57:33,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 05:57:38,384][train_inner][INFO] - {"epoch": 718, "update": 717.192, "loss": "0.742", "ntokens": "262839", "nsentences": "1767.37", "wps": "91283.3", "ups": "0.35", "wpb": "262839", "bsz": "1767.4", "num_updates": "343400", "lr": "7.69022e-05", "gnorm": "0.244", "loss_scale": "2", "train_wall": "263", "gb_free": "39.6", "wall": "647251"}
[2024-10-12 06:01:36,147][train_inner][INFO] - {"epoch": 718, "update": 717.61, "loss": "0.739", "ntokens": "264337", "nsentences": "1716.67", "wps": "222363", "ups": "0.84", "wpb": "264337", "bsz": "1716.7", "num_updates": "343600", "lr": "7.66304e-05", "gnorm": "0.24", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "647488"}
[2024-10-12 06:05:37,350][fairseq_cli.train][INFO] - end of epoch 718 (average epoch stats below)
[2024-10-12 06:05:37,390][train][INFO] - {"epoch": 718, "train_loss": "0.74", "train_ntokens": "263578", "train_nsentences": "1754.16", "train_wps": "136764", "train_ups": "0.52", "train_wpb": "263578", "train_bsz": "1754.2", "train_num_updates": "343787", "train_lr": "7.63764e-05", "train_gnorm": "0.237", "train_loss_scale": "2", "train_train_wall": "600", "train_gb_free": "40", "train_wall": "647730"}
[2024-10-12 06:05:37,591][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:05:37,625][fairseq.trainer][INFO] - begin training epoch 719
[2024-10-12 06:05:37,626][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:11:27,767][train_inner][INFO] - {"epoch": 719, "update": 718.027, "loss": "0.741", "ntokens": "262786", "nsentences": "1765.95", "wps": "88840.2", "ups": "0.34", "wpb": "262786", "bsz": "1766", "num_updates": "343800", "lr": "7.63587e-05", "gnorm": "0.234", "loss_scale": "2", "train_wall": "264", "gb_free": "39.3", "wall": "648080"}
[2024-10-12 06:15:08,620][train_inner][INFO] - {"epoch": 719, "update": 718.445, "loss": "0.743", "ntokens": "263453", "nsentences": "1811.4", "wps": "238594", "ups": "0.91", "wpb": "263453", "bsz": "1811.4", "num_updates": "344000", "lr": "7.6087e-05", "gnorm": "0.227", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "648301"}
[2024-10-12 06:18:52,329][train_inner][INFO] - {"epoch": 719, "update": 718.862, "loss": "0.74", "ntokens": "264467", "nsentences": "1708.31", "wps": "236453", "ups": "0.89", "wpb": "264466", "bsz": "1708.3", "num_updates": "344200", "lr": "7.58152e-05", "gnorm": "0.234", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "648524"}
[2024-10-12 06:20:14,736][fairseq_cli.train][INFO] - end of epoch 719 (average epoch stats below)
[2024-10-12 06:20:14,778][train][INFO] - {"epoch": 719, "train_loss": "0.74", "train_ntokens": "263502", "train_nsentences": "1753.71", "train_wps": "143868", "train_ups": "0.55", "train_wpb": "263502", "train_bsz": "1753.7", "train_num_updates": "344266", "train_lr": "7.57255e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "40.5", "train_wall": "648607"}
[2024-10-12 06:20:14,910][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:20:14,932][fairseq.trainer][INFO] - begin training epoch 720
[2024-10-12 06:20:14,933][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:28:15,149][train_inner][INFO] - {"epoch": 720, "update": 719.28, "loss": "0.736", "ntokens": "263078", "nsentences": "1719.24", "wps": "93491.3", "ups": "0.36", "wpb": "263078", "bsz": "1719.2", "num_updates": "344400", "lr": "7.55435e-05", "gnorm": "0.237", "loss_scale": "2", "train_wall": "235", "gb_free": "40", "wall": "649087"}
[2024-10-12 06:32:10,299][train_inner][INFO] - {"epoch": 720, "update": 719.697, "loss": "0.74", "ntokens": "264111", "nsentences": "1748.12", "wps": "224698", "ups": "0.85", "wpb": "264111", "bsz": "1748.1", "num_updates": "344600", "lr": "7.52717e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "229", "gb_free": "40.1", "wall": "649322"}
[2024-10-12 06:35:07,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 720 @ 344745 updates
[2024-10-12 06:35:07,347][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 06:35:12,306][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 06:35:12,426][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 720 @ 344745 updates, score None) (writing took 5.079693237319589 seconds)
[2024-10-12 06:35:12,426][fairseq_cli.train][INFO] - end of epoch 720 (average epoch stats below)
[2024-10-12 06:35:12,434][train][INFO] - {"epoch": 720, "train_loss": "0.74", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "140622", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "344745", "train_lr": "7.50747e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.2", "train_wall": "649505"}
[2024-10-12 06:35:12,520][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:35:12,533][fairseq.trainer][INFO] - begin training epoch 721
[2024-10-12 06:35:12,534][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:41:53,094][train_inner][INFO] - {"epoch": 721, "update": 720.115, "loss": "0.742", "ntokens": "262515", "nsentences": "1784.49", "wps": "90097.4", "ups": "0.34", "wpb": "262515", "bsz": "1784.5", "num_updates": "344800", "lr": "7.5e-05", "gnorm": "0.241", "loss_scale": "2", "train_wall": "254", "gb_free": "40", "wall": "649905"}
[2024-10-12 06:45:28,747][train_inner][INFO] - {"epoch": 721, "update": 720.532, "loss": "0.74", "ntokens": "263751", "nsentences": "1752.86", "wps": "244630", "ups": "0.93", "wpb": "263751", "bsz": "1752.9", "num_updates": "345000", "lr": "7.47283e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "210", "gb_free": "39.7", "wall": "650121"}
[2024-10-12 06:49:09,020][train_inner][INFO] - {"epoch": 721, "update": 720.95, "loss": "0.741", "ntokens": "264097", "nsentences": "1741.72", "wps": "239846", "ups": "0.91", "wpb": "264097", "bsz": "1741.7", "num_updates": "345200", "lr": "7.44565e-05", "gnorm": "0.245", "loss_scale": "2", "train_wall": "215", "gb_free": "40.1", "wall": "650341"}
[2024-10-12 06:49:46,873][fairseq_cli.train][INFO] - end of epoch 721 (average epoch stats below)
[2024-10-12 06:49:46,891][train][INFO] - {"epoch": 721, "train_loss": "0.74", "train_ntokens": "263405", "train_nsentences": "1753.71", "train_wps": "144287", "train_ups": "0.55", "train_wpb": "263405", "train_bsz": "1753.7", "train_num_updates": "345224", "train_lr": "7.44239e-05", "train_gnorm": "0.24", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "39.6", "train_wall": "650379"}
[2024-10-12 06:49:46,979][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:49:47,042][fairseq.trainer][INFO] - begin training epoch 722
[2024-10-12 06:49:47,043][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:58:41,930][train_inner][INFO] - {"epoch": 722, "update": 721.367, "loss": "0.739", "ntokens": "262602", "nsentences": "1786.36", "wps": "91674.5", "ups": "0.35", "wpb": "262602", "bsz": "1786.4", "num_updates": "345400", "lr": "7.41848e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "242", "gb_free": "39.7", "wall": "650914"}
[2024-10-12 07:02:14,517][train_inner][INFO] - {"epoch": 722, "update": 721.785, "loss": "0.74", "ntokens": "264206", "nsentences": "1732.27", "wps": "248590", "ups": "0.94", "wpb": "264206", "bsz": "1732.3", "num_updates": "345600", "lr": "7.3913e-05", "gnorm": "0.231", "loss_scale": "4", "train_wall": "203", "gb_free": "40.5", "wall": "651127"}
[2024-10-12 07:04:11,620][fairseq_cli.train][INFO] - end of epoch 722 (average epoch stats below)
[2024-10-12 07:04:11,636][train][INFO] - {"epoch": 722, "train_loss": "0.74", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "145977", "train_ups": "0.55", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "345703", "train_lr": "7.37731e-05", "train_gnorm": "0.235", "train_loss_scale": "4", "train_train_wall": "525", "train_gb_free": "40.5", "train_wall": "651244"}
[2024-10-12 07:04:11,830][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:04:11,867][fairseq.trainer][INFO] - begin training epoch 723
[2024-10-12 07:04:11,867][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:11:46,651][train_inner][INFO] - {"epoch": 723, "update": 722.203, "loss": "0.741", "ntokens": "262974", "nsentences": "1751.06", "wps": "91931.8", "ups": "0.35", "wpb": "262974", "bsz": "1751.1", "num_updates": "345800", "lr": "7.36413e-05", "gnorm": "0.239", "loss_scale": "4", "train_wall": "238", "gb_free": "39.8", "wall": "651699"}
[2024-10-12 07:12:45,630][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 07:15:21,012][train_inner][INFO] - {"epoch": 723, "update": 722.622, "loss": "0.739", "ntokens": "264426", "nsentences": "1717.09", "wps": "246729", "ups": "0.93", "wpb": "264426", "bsz": "1717.1", "num_updates": "346000", "lr": "7.33696e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "208", "gb_free": "40", "wall": "651913"}
[2024-10-12 07:19:29,973][fairseq_cli.train][INFO] - end of epoch 723 (average epoch stats below)
[2024-10-12 07:19:29,996][train][INFO] - {"epoch": 723, "train_loss": "0.74", "train_ntokens": "263641", "train_nsentences": "1751.14", "train_wps": "137226", "train_ups": "0.52", "train_wpb": "263641", "train_bsz": "1751.1", "train_num_updates": "346181", "train_lr": "7.31236e-05", "train_gnorm": "0.235", "train_loss_scale": "2", "train_train_wall": "574", "train_gb_free": "39.6", "train_wall": "652162"}
[2024-10-12 07:19:30,180][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:19:30,199][fairseq.trainer][INFO] - begin training epoch 724
[2024-10-12 07:19:30,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:25:12,121][train_inner][INFO] - {"epoch": 724, "update": 723.04, "loss": "0.742", "ntokens": "262577", "nsentences": "1782.84", "wps": "88844", "ups": "0.34", "wpb": "262577", "bsz": "1782.8", "num_updates": "346200", "lr": "7.30978e-05", "gnorm": "0.238", "loss_scale": "2", "train_wall": "275", "gb_free": "39.3", "wall": "652504"}
[2024-10-12 07:28:40,548][train_inner][INFO] - {"epoch": 724, "update": 723.457, "loss": "0.738", "ntokens": "264081", "nsentences": "1749.1", "wps": "253421", "ups": "0.96", "wpb": "264081", "bsz": "1749.1", "num_updates": "346400", "lr": "7.28261e-05", "gnorm": "0.234", "loss_scale": "2", "train_wall": "199", "gb_free": "39.3", "wall": "652713"}
[2024-10-12 07:32:52,908][train_inner][INFO] - {"epoch": 724, "update": 723.875, "loss": "0.742", "ntokens": "263763", "nsentences": "1778.5", "wps": "209070", "ups": "0.79", "wpb": "263763", "bsz": "1778.5", "num_updates": "346600", "lr": "7.25543e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "247", "gb_free": "39.6", "wall": "652965"}
[2024-10-12 07:34:11,014][fairseq_cli.train][INFO] - end of epoch 724 (average epoch stats below)
[2024-10-12 07:34:11,034][train][INFO] - {"epoch": 724, "train_loss": "0.74", "train_ntokens": "263501", "train_nsentences": "1753.71", "train_wps": "143270", "train_ups": "0.54", "train_wpb": "263501", "train_bsz": "1753.7", "train_num_updates": "346660", "train_lr": "7.24728e-05", "train_gnorm": "0.23", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.2", "train_wall": "653043"}
[2024-10-12 07:34:11,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:34:11,268][fairseq.trainer][INFO] - begin training epoch 725
[2024-10-12 07:34:11,269][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:42:21,674][train_inner][INFO] - {"epoch": 725, "update": 724.292, "loss": "0.739", "ntokens": "263175", "nsentences": "1714.53", "wps": "92545.1", "ups": "0.35", "wpb": "263175", "bsz": "1714.5", "num_updates": "346800", "lr": "7.22826e-05", "gnorm": "0.223", "loss_scale": "2", "train_wall": "244", "gb_free": "40", "wall": "653534"}
[2024-10-12 07:46:37,902][train_inner][INFO] - {"epoch": 725, "update": 724.71, "loss": "0.739", "ntokens": "263832", "nsentences": "1781.65", "wps": "205948", "ups": "0.78", "wpb": "263832", "bsz": "1781.7", "num_updates": "347000", "lr": "7.20109e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "251", "gb_free": "39.6", "wall": "653790"}
[2024-10-12 07:49:20,986][fairseq_cli.train][INFO] - end of epoch 725 (average epoch stats below)
[2024-10-12 07:49:21,004][train][INFO] - {"epoch": 725, "train_loss": "0.739", "train_ntokens": "263454", "train_nsentences": "1753.71", "train_wps": "138687", "train_ups": "0.53", "train_wpb": "263454", "train_bsz": "1753.7", "train_num_updates": "347139", "train_lr": "7.1822e-05", "train_gnorm": "0.226", "train_loss_scale": "2", "train_train_wall": "578", "train_gb_free": "40.5", "train_wall": "653953"}
[2024-10-12 07:49:21,086][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:49:21,092][fairseq.trainer][INFO] - begin training epoch 726
[2024-10-12 07:49:21,092][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:56:03,910][train_inner][INFO] - {"epoch": 726, "update": 725.127, "loss": "0.741", "ntokens": "262360", "nsentences": "1773.82", "wps": "92709.8", "ups": "0.35", "wpb": "262360", "bsz": "1773.8", "num_updates": "347200", "lr": "7.17391e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "241", "gb_free": "40", "wall": "654356"}
[2024-10-12 08:00:01,396][train_inner][INFO] - {"epoch": 726, "update": 725.545, "loss": "0.738", "ntokens": "263910", "nsentences": "1758.43", "wps": "222273", "ups": "0.84", "wpb": "263910", "bsz": "1758.4", "num_updates": "347400", "lr": "7.14674e-05", "gnorm": "0.237", "loss_scale": "2", "train_wall": "227", "gb_free": "40.5", "wall": "654594"}
[2024-10-12 08:03:43,333][train_inner][INFO] - {"epoch": 726, "update": 725.962, "loss": "0.74", "ntokens": "264229", "nsentences": "1731.44", "wps": "238138", "ups": "0.9", "wpb": "264229", "bsz": "1731.4", "num_updates": "347600", "lr": "7.11957e-05", "gnorm": "0.235", "loss_scale": "2", "train_wall": "217", "gb_free": "40.1", "wall": "654816"}
[2024-10-12 08:04:10,450][fairseq_cli.train][INFO] - end of epoch 726 (average epoch stats below)
[2024-10-12 08:04:10,468][train][INFO] - {"epoch": 726, "train_loss": "0.74", "train_ntokens": "263469", "train_nsentences": "1753.71", "train_wps": "141889", "train_ups": "0.54", "train_wpb": "263469", "train_bsz": "1753.7", "train_num_updates": "347618", "train_lr": "7.11712e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.2", "train_wall": "654843"}
[2024-10-12 08:04:10,640][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:04:10,684][fairseq.trainer][INFO] - begin training epoch 727
[2024-10-12 08:04:10,684][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:13:26,025][train_inner][INFO] - {"epoch": 727, "update": 726.38, "loss": "0.738", "ntokens": "262624", "nsentences": "1763.83", "wps": "90143.1", "ups": "0.34", "wpb": "262624", "bsz": "1763.8", "num_updates": "347800", "lr": "7.09239e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "247", "gb_free": "39.3", "wall": "655398"}
[2024-10-12 08:17:21,739][train_inner][INFO] - {"epoch": 727, "update": 726.797, "loss": "0.738", "ntokens": "264121", "nsentences": "1725.9", "wps": "224116", "ups": "0.85", "wpb": "264121", "bsz": "1725.9", "num_updates": "348000", "lr": "7.06522e-05", "gnorm": "0.244", "loss_scale": "4", "train_wall": "231", "gb_free": "40.2", "wall": "655634"}
[2024-10-12 08:18:48,530][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 08:19:26,916][fairseq_cli.train][INFO] - end of epoch 727 (average epoch stats below)
[2024-10-12 08:19:26,941][train][INFO] - {"epoch": 727, "train_loss": "0.739", "train_ntokens": "263414", "train_nsentences": "1753.32", "train_wps": "137393", "train_ups": "0.52", "train_wpb": "263414", "train_bsz": "1753.3", "train_num_updates": "348096", "train_lr": "7.05217e-05", "train_gnorm": "0.239", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "40.3", "train_wall": "655759"}
[2024-10-12 08:19:27,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:19:27,104][fairseq.trainer][INFO] - begin training epoch 728
[2024-10-12 08:19:27,105][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:27:02,884][train_inner][INFO] - {"epoch": 728, "update": 727.217, "loss": "0.74", "ntokens": "262538", "nsentences": "1771.87", "wps": "90356", "ups": "0.34", "wpb": "262538", "bsz": "1771.9", "num_updates": "348200", "lr": "7.03804e-05", "gnorm": "0.242", "loss_scale": "2", "train_wall": "259", "gb_free": "40.5", "wall": "656215"}
[2024-10-12 08:30:27,887][train_inner][INFO] - {"epoch": 728, "update": 727.635, "loss": "0.738", "ntokens": "264190", "nsentences": "1748.22", "wps": "257765", "ups": "0.98", "wpb": "264190", "bsz": "1748.2", "num_updates": "348400", "lr": "7.01087e-05", "gnorm": "0.236", "loss_scale": "2", "train_wall": "199", "gb_free": "39.8", "wall": "656420"}
[2024-10-12 08:33:57,399][fairseq_cli.train][INFO] - end of epoch 728 (average epoch stats below)
[2024-10-12 08:33:57,432][train][INFO] - {"epoch": 728, "train_loss": "0.739", "train_ntokens": "263515", "train_nsentences": "1753.71", "train_wps": "145006", "train_ups": "0.55", "train_wpb": "263515", "train_bsz": "1753.7", "train_num_updates": "348575", "train_lr": "6.98709e-05", "train_gnorm": "0.238", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.2", "train_wall": "656630"}
[2024-10-12 08:33:57,684][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:33:57,718][fairseq.trainer][INFO] - begin training epoch 729
[2024-10-12 08:33:57,719][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:40:23,152][train_inner][INFO] - {"epoch": 729, "update": 728.052, "loss": "0.74", "ntokens": "262727", "nsentences": "1756.06", "wps": "88276.7", "ups": "0.34", "wpb": "262726", "bsz": "1756.1", "num_updates": "348600", "lr": "6.9837e-05", "gnorm": "0.237", "loss_scale": "2", "train_wall": "235", "gb_free": "40.5", "wall": "657015"}
[2024-10-12 08:43:43,331][train_inner][INFO] - {"epoch": 729, "update": 728.47, "loss": "0.738", "ntokens": "264002", "nsentences": "1762.02", "wps": "263783", "ups": "1", "wpb": "264002", "bsz": "1762", "num_updates": "348800", "lr": "6.95652e-05", "gnorm": "0.24", "loss_scale": "2", "train_wall": "195", "gb_free": "39.6", "wall": "657216"}
[2024-10-12 08:48:02,554][train_inner][INFO] - {"epoch": 729, "update": 728.887, "loss": "0.739", "ntokens": "264234", "nsentences": "1739.07", "wps": "203874", "ups": "0.77", "wpb": "264234", "bsz": "1739.1", "num_updates": "349000", "lr": "6.92935e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "254", "gb_free": "39.8", "wall": "657475"}
[2024-10-12 08:49:18,714][fairseq_cli.train][INFO] - end of epoch 729 (average epoch stats below)
[2024-10-12 08:49:18,726][train][INFO] - {"epoch": 729, "train_loss": "0.739", "train_ntokens": "263600", "train_nsentences": "1753.71", "train_wps": "137060", "train_ups": "0.52", "train_wpb": "263600", "train_bsz": "1753.7", "train_num_updates": "349054", "train_lr": "6.92201e-05", "train_gnorm": "0.234", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "40.1", "train_wall": "657551"}
[2024-10-12 08:49:18,818][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:49:18,823][fairseq.trainer][INFO] - begin training epoch 730
[2024-10-12 08:49:18,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:57:50,318][train_inner][INFO] - {"epoch": 730, "update": 729.305, "loss": "0.739", "ntokens": "263079", "nsentences": "1742.55", "wps": "89525.8", "ups": "0.34", "wpb": "263079", "bsz": "1742.5", "num_updates": "349200", "lr": "6.90217e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "277", "gb_free": "39.6", "wall": "658062"}
[2024-10-12 09:01:46,011][train_inner][INFO] - {"epoch": 730, "update": 729.722, "loss": "0.739", "ntokens": "263900", "nsentences": "1755.62", "wps": "223946", "ups": "0.85", "wpb": "263900", "bsz": "1755.6", "num_updates": "349400", "lr": "6.875e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "658298"}
[2024-10-12 09:04:47,109][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 730 @ 349533 updates
[2024-10-12 09:04:47,110][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 09:04:52,106][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 09:04:52,172][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 730 @ 349533 updates, score None) (writing took 5.063288378529251 seconds)
[2024-10-12 09:04:52,173][fairseq_cli.train][INFO] - end of epoch 730 (average epoch stats below)
[2024-10-12 09:04:52,176][train][INFO] - {"epoch": 730, "train_loss": "0.738", "train_ntokens": "263519", "train_nsentences": "1753.71", "train_wps": "135226", "train_ups": "0.51", "train_wpb": "263519", "train_bsz": "1753.7", "train_num_updates": "349533", "train_lr": "6.85693e-05", "train_gnorm": "0.229", "train_loss_scale": "2", "train_train_wall": "609", "train_gb_free": "39.3", "train_wall": "658484"}
[2024-10-12 09:04:52,251][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:04:52,267][fairseq.trainer][INFO] - begin training epoch 731
[2024-10-12 09:04:52,268][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:11:23,289][train_inner][INFO] - {"epoch": 731, "update": 730.14, "loss": "0.736", "ntokens": "262910", "nsentences": "1756.9", "wps": "91088.9", "ups": "0.35", "wpb": "262910", "bsz": "1756.9", "num_updates": "349600", "lr": "6.84783e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "254", "gb_free": "39.1", "wall": "658875"}
[2024-10-12 09:14:47,633][train_inner][INFO] - {"epoch": 731, "update": 730.557, "loss": "0.737", "ntokens": "264221", "nsentences": "1719.96", "wps": "258621", "ups": "0.98", "wpb": "264221", "bsz": "1720", "num_updates": "349800", "lr": "6.82065e-05", "gnorm": "0.225", "loss_scale": "2", "train_wall": "197", "gb_free": "39.6", "wall": "659080"}
[2024-10-12 09:18:42,235][train_inner][INFO] - {"epoch": 731, "update": 730.975, "loss": "0.74", "ntokens": "263790", "nsentences": "1781.09", "wps": "224899", "ups": "0.85", "wpb": "263790", "bsz": "1781.1", "num_updates": "350000", "lr": "6.79348e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "230", "gb_free": "39.7", "wall": "659314"}
[2024-10-12 09:18:42,246][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 731 @ 350000 updates
[2024-10-12 09:18:42,247][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_731_350000.pt
[2024-10-12 09:18:45,789][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_731_350000.pt
[2024-10-12 09:18:51,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_731_350000.pt (epoch 731 @ 350000 updates, score None) (writing took 9.098811335861683 seconds)
[2024-10-12 09:19:22,388][fairseq_cli.train][INFO] - end of epoch 731 (average epoch stats below)
[2024-10-12 09:19:22,426][train][INFO] - {"epoch": 731, "train_loss": "0.739", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "145050", "train_ups": "0.55", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "350012", "train_lr": "6.79185e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "534", "train_gb_free": "40.1", "train_wall": "659355"}
[2024-10-12 09:19:22,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:19:22,615][fairseq.trainer][INFO] - begin training epoch 732
[2024-10-12 09:19:22,615][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:28:05,641][train_inner][INFO] - {"epoch": 732, "update": 731.392, "loss": "0.737", "ntokens": "263040", "nsentences": "1724.77", "wps": "93376.7", "ups": "0.35", "wpb": "263040", "bsz": "1724.8", "num_updates": "350200", "lr": "6.7663e-05", "gnorm": "0.239", "loss_scale": "4", "train_wall": "191", "gb_free": "39.2", "wall": "659878"}
[2024-10-12 09:29:15,164][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 09:32:28,305][train_inner][INFO] - {"epoch": 732, "update": 731.812, "loss": "0.74", "ntokens": "264059", "nsentences": "1756.81", "wps": "201082", "ups": "0.76", "wpb": "264059", "bsz": "1756.8", "num_updates": "350400", "lr": "6.73913e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "232", "gb_free": "39.6", "wall": "660140"}
[2024-10-12 09:34:22,637][fairseq_cli.train][INFO] - end of epoch 732 (average epoch stats below)
[2024-10-12 09:34:22,674][train][INFO] - {"epoch": 732, "train_loss": "0.738", "train_ntokens": "263615", "train_nsentences": "1748.65", "train_wps": "139973", "train_ups": "0.53", "train_wpb": "263615", "train_bsz": "1748.6", "train_num_updates": "350490", "train_lr": "6.7269e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "505", "train_gb_free": "39.8", "train_wall": "660255"}
[2024-10-12 09:34:22,888][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:34:22,902][fairseq.trainer][INFO] - begin training epoch 733
[2024-10-12 09:34:22,902][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:42:01,747][train_inner][INFO] - {"epoch": 733, "update": 732.23, "loss": "0.74", "ntokens": "262520", "nsentences": "1792.51", "wps": "91562.3", "ups": "0.35", "wpb": "262520", "bsz": "1792.5", "num_updates": "350600", "lr": "6.71196e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "236", "gb_free": "39", "wall": "660714"}
[2024-10-12 09:45:29,844][train_inner][INFO] - {"epoch": 733, "update": 732.647, "loss": "0.736", "ntokens": "264016", "nsentences": "1748.24", "wps": "253817", "ups": "0.96", "wpb": "264016", "bsz": "1748.2", "num_updates": "350800", "lr": "6.68478e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "181", "gb_free": "39.3", "wall": "660922"}
[2024-10-12 09:48:51,085][fairseq_cli.train][INFO] - end of epoch 733 (average epoch stats below)
[2024-10-12 09:48:51,122][train][INFO] - {"epoch": 733, "train_loss": "0.738", "train_ntokens": "263453", "train_nsentences": "1753.71", "train_wps": "145320", "train_ups": "0.55", "train_wpb": "263453", "train_bsz": "1753.7", "train_num_updates": "350969", "train_lr": "6.66182e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "500", "train_gb_free": "39.6", "train_wall": "661123"}
[2024-10-12 09:48:51,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:48:51,419][fairseq.trainer][INFO] - begin training epoch 734
[2024-10-12 09:48:51,420][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:55:02,958][train_inner][INFO] - {"epoch": 734, "update": 733.065, "loss": "0.739", "ntokens": "262746", "nsentences": "1760.59", "wps": "91694", "ups": "0.35", "wpb": "262746", "bsz": "1760.6", "num_updates": "351000", "lr": "6.65761e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "253", "gb_free": "40.8", "wall": "661495"}
[2024-10-12 09:58:29,878][train_inner][INFO] - {"epoch": 734, "update": 733.482, "loss": "0.736", "ntokens": "264153", "nsentences": "1741.62", "wps": "255387", "ups": "0.97", "wpb": "264153", "bsz": "1741.6", "num_updates": "351200", "lr": "6.63043e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "202", "gb_free": "39.6", "wall": "661702"}
[2024-10-12 10:02:25,575][train_inner][INFO] - {"epoch": 734, "update": 733.9, "loss": "0.739", "ntokens": "264027", "nsentences": "1769.27", "wps": "224049", "ups": "0.85", "wpb": "264027", "bsz": "1769.3", "num_updates": "351400", "lr": "6.60326e-05", "gnorm": "0.227", "loss_scale": "2", "train_wall": "207", "gb_free": "39.6", "wall": "661938"}
[2024-10-12 10:03:32,289][fairseq_cli.train][INFO] - end of epoch 734 (average epoch stats below)
[2024-10-12 10:03:32,312][train][INFO] - {"epoch": 734, "train_loss": "0.738", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "143277", "train_ups": "0.54", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "351448", "train_lr": "6.59674e-05", "train_gnorm": "0.228", "train_loss_scale": "2", "train_train_wall": "530", "train_gb_free": "39.3", "train_wall": "662004"}
[2024-10-12 10:03:32,459][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:03:32,486][fairseq.trainer][INFO] - begin training epoch 735
[2024-10-12 10:03:32,486][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:11:46,049][train_inner][INFO] - {"epoch": 735, "update": 734.317, "loss": "0.739", "ntokens": "262683", "nsentences": "1779.81", "wps": "93739.5", "ups": "0.36", "wpb": "262682", "bsz": "1779.8", "num_updates": "351600", "lr": "6.57609e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "662498"}
[2024-10-12 10:15:37,355][train_inner][INFO] - {"epoch": 735, "update": 734.735, "loss": "0.739", "ntokens": "264411", "nsentences": "1734.04", "wps": "228650", "ups": "0.86", "wpb": "264411", "bsz": "1734", "num_updates": "351800", "lr": "6.54891e-05", "gnorm": "0.234", "loss_scale": "2", "train_wall": "226", "gb_free": "40.5", "wall": "662730"}
[2024-10-12 10:18:37,424][fairseq_cli.train][INFO] - end of epoch 735 (average epoch stats below)
[2024-10-12 10:18:37,441][train][INFO] - {"epoch": 735, "train_loss": "0.739", "train_ntokens": "263659", "train_nsentences": "1753.71", "train_wps": "139531", "train_ups": "0.53", "train_wpb": "263659", "train_bsz": "1753.7", "train_num_updates": "351927", "train_lr": "6.53166e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.6", "train_wall": "662910"}
[2024-10-12 10:18:37,499][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:18:37,512][fairseq.trainer][INFO] - begin training epoch 736
[2024-10-12 10:18:37,513][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:25:25,816][train_inner][INFO] - {"epoch": 736, "update": 735.152, "loss": "0.737", "ntokens": "262820", "nsentences": "1738.96", "wps": "89328", "ups": "0.34", "wpb": "262820", "bsz": "1739", "num_updates": "352000", "lr": "6.52174e-05", "gnorm": "0.237", "loss_scale": "2", "train_wall": "277", "gb_free": "39.2", "wall": "663318"}
[2024-10-12 10:29:14,059][train_inner][INFO] - {"epoch": 736, "update": 735.57, "loss": "0.739", "ntokens": "263906", "nsentences": "1778.81", "wps": "231271", "ups": "0.88", "wpb": "263906", "bsz": "1778.8", "num_updates": "352200", "lr": "6.49457e-05", "gnorm": "0.239", "loss_scale": "2", "train_wall": "223", "gb_free": "40", "wall": "663546"}
[2024-10-12 10:33:31,646][train_inner][INFO] - {"epoch": 736, "update": 735.987, "loss": "0.736", "ntokens": "264144", "nsentences": "1729.01", "wps": "205128", "ups": "0.78", "wpb": "264144", "bsz": "1729", "num_updates": "352400", "lr": "6.46739e-05", "gnorm": "0.227", "loss_scale": "4", "train_wall": "253", "gb_free": "39.3", "wall": "663804"}
[2024-10-12 10:33:48,593][fairseq_cli.train][INFO] - end of epoch 736 (average epoch stats below)
[2024-10-12 10:33:48,608][train][INFO] - {"epoch": 736, "train_loss": "0.738", "train_ntokens": "263503", "train_nsentences": "1753.71", "train_wps": "138526", "train_ups": "0.53", "train_wpb": "263503", "train_bsz": "1753.7", "train_num_updates": "352406", "train_lr": "6.46658e-05", "train_gnorm": "0.233", "train_loss_scale": "4", "train_train_wall": "593", "train_gb_free": "39.6", "train_wall": "663821"}
[2024-10-12 10:33:48,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:33:48,742][fairseq.trainer][INFO] - begin training epoch 737
[2024-10-12 10:33:48,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:40:08,746][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 10:42:45,091][train_inner][INFO] - {"epoch": 737, "update": 736.407, "loss": "0.735", "ntokens": "263072", "nsentences": "1722.51", "wps": "95073.5", "ups": "0.36", "wpb": "263072", "bsz": "1722.5", "num_updates": "352600", "lr": "6.44022e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "221", "gb_free": "40.5", "wall": "664357"}
[2024-10-12 10:46:48,475][train_inner][INFO] - {"epoch": 737, "update": 736.825, "loss": "0.74", "ntokens": "263810", "nsentences": "1795.96", "wps": "216794", "ups": "0.82", "wpb": "263810", "bsz": "1796", "num_updates": "352800", "lr": "6.41304e-05", "gnorm": "0.227", "loss_scale": "2", "train_wall": "239", "gb_free": "40", "wall": "664601"}
[2024-10-12 10:48:34,316][fairseq_cli.train][INFO] - end of epoch 737 (average epoch stats below)
[2024-10-12 10:48:34,352][train][INFO] - {"epoch": 737, "train_loss": "0.737", "train_ntokens": "263534", "train_nsentences": "1753.23", "train_wps": "142222", "train_ups": "0.54", "train_wpb": "263534", "train_bsz": "1753.2", "train_num_updates": "352884", "train_lr": "6.40163e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "547", "train_gb_free": "39.3", "train_wall": "664707"}
[2024-10-12 10:48:34,484][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:48:34,515][fairseq.trainer][INFO] - begin training epoch 738
[2024-10-12 10:48:34,516][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:56:18,146][train_inner][INFO] - {"epoch": 738, "update": 737.242, "loss": "0.735", "ntokens": "262761", "nsentences": "1750.96", "wps": "92251.8", "ups": "0.35", "wpb": "262761", "bsz": "1751", "num_updates": "353000", "lr": "6.38587e-05", "gnorm": "0.246", "loss_scale": "2", "train_wall": "250", "gb_free": "39.7", "wall": "665170"}
[2024-10-12 10:59:56,211][train_inner][INFO] - {"epoch": 738, "update": 737.66, "loss": "0.737", "ntokens": "264124", "nsentences": "1733.59", "wps": "242259", "ups": "0.92", "wpb": "264124", "bsz": "1733.6", "num_updates": "353200", "lr": "6.3587e-05", "gnorm": "0.231", "loss_scale": "2", "train_wall": "212", "gb_free": "40.3", "wall": "665388"}
[2024-10-12 11:03:13,990][fairseq_cli.train][INFO] - end of epoch 738 (average epoch stats below)
[2024-10-12 11:03:14,015][train][INFO] - {"epoch": 738, "train_loss": "0.737", "train_ntokens": "263476", "train_nsentences": "1753.71", "train_wps": "143475", "train_ups": "0.54", "train_wpb": "263476", "train_bsz": "1753.7", "train_num_updates": "353363", "train_lr": "6.33655e-05", "train_gnorm": "0.236", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.6", "train_wall": "665586"}
[2024-10-12 11:03:14,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:03:14,125][fairseq.trainer][INFO] - begin training epoch 739
[2024-10-12 11:03:14,126][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:09:28,201][train_inner][INFO] - {"epoch": 739, "update": 738.077, "loss": "0.737", "ntokens": "262871", "nsentences": "1738.38", "wps": "91916.4", "ups": "0.35", "wpb": "262871", "bsz": "1738.4", "num_updates": "353400", "lr": "6.33152e-05", "gnorm": "0.243", "loss_scale": "2", "train_wall": "259", "gb_free": "39.9", "wall": "665960"}
[2024-10-12 11:12:53,417][train_inner][INFO] - {"epoch": 739, "update": 738.495, "loss": "0.736", "ntokens": "264321", "nsentences": "1743.41", "wps": "257664", "ups": "0.97", "wpb": "264321", "bsz": "1743.4", "num_updates": "353600", "lr": "6.30435e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "200", "gb_free": "39.2", "wall": "666166"}
[2024-10-12 11:17:00,358][train_inner][INFO] - {"epoch": 739, "update": 738.912, "loss": "0.741", "ntokens": "263486", "nsentences": "1817.88", "wps": "213412", "ups": "0.81", "wpb": "263486", "bsz": "1817.9", "num_updates": "353800", "lr": "6.27717e-05", "gnorm": "0.24", "loss_scale": "2", "train_wall": "241", "gb_free": "40.5", "wall": "666413"}
[2024-10-12 11:18:01,649][fairseq_cli.train][INFO] - end of epoch 739 (average epoch stats below)
[2024-10-12 11:18:01,666][train][INFO] - {"epoch": 739, "train_loss": "0.737", "train_ntokens": "263584", "train_nsentences": "1753.71", "train_wps": "142243", "train_ups": "0.54", "train_wpb": "263584", "train_bsz": "1753.7", "train_num_updates": "353842", "train_lr": "6.27147e-05", "train_gnorm": "0.24", "train_loss_scale": "2", "train_train_wall": "568", "train_gb_free": "40.3", "train_wall": "666474"}
[2024-10-12 11:18:01,738][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:18:01,745][fairseq.trainer][INFO] - begin training epoch 740
[2024-10-12 11:18:01,746][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:26:19,817][train_inner][INFO] - {"epoch": 740, "update": 739.33, "loss": "0.735", "ntokens": "263171", "nsentences": "1701.06", "wps": "94082.7", "ups": "0.36", "wpb": "263171", "bsz": "1701.1", "num_updates": "354000", "lr": "6.25e-05", "gnorm": "0.241", "loss_scale": "2", "train_wall": "240", "gb_free": "40.6", "wall": "666972"}
[2024-10-12 11:30:11,786][train_inner][INFO] - {"epoch": 740, "update": 739.747, "loss": "0.737", "ntokens": "263743", "nsentences": "1774.12", "wps": "227417", "ups": "0.86", "wpb": "263742", "bsz": "1774.1", "num_updates": "354200", "lr": "6.22283e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "227", "gb_free": "40", "wall": "667204"}
[2024-10-12 11:32:42,253][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 740 @ 354321 updates
[2024-10-12 11:32:42,254][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 11:32:47,637][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 11:32:47,726][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 740 @ 354321 updates, score None) (writing took 5.473062773235142 seconds)
[2024-10-12 11:32:47,727][fairseq_cli.train][INFO] - end of epoch 740 (average epoch stats below)
[2024-10-12 11:32:47,730][train][INFO] - {"epoch": 740, "train_loss": "0.737", "train_ntokens": "263500", "train_nsentences": "1753.71", "train_wps": "142448", "train_ups": "0.54", "train_wpb": "263500", "train_bsz": "1753.7", "train_num_updates": "354321", "train_lr": "6.20639e-05", "train_gnorm": "0.233", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "39.2", "train_wall": "667360"}
[2024-10-12 11:32:47,773][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:32:47,791][fairseq.trainer][INFO] - begin training epoch 741
[2024-10-12 11:32:47,791][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:39:48,008][train_inner][INFO] - {"epoch": 741, "update": 740.165, "loss": "0.739", "ntokens": "262737", "nsentences": "1768.5", "wps": "91195.3", "ups": "0.35", "wpb": "262737", "bsz": "1768.5", "num_updates": "354400", "lr": "6.19565e-05", "gnorm": "0.223", "loss_scale": "2", "train_wall": "252", "gb_free": "39.3", "wall": "667780"}
[2024-10-12 11:43:31,093][train_inner][INFO] - {"epoch": 741, "update": 740.582, "loss": "0.738", "ntokens": "264158", "nsentences": "1754.43", "wps": "236850", "ups": "0.9", "wpb": "264158", "bsz": "1754.4", "num_updates": "354600", "lr": "6.16848e-05", "gnorm": "0.234", "loss_scale": "4", "train_wall": "218", "gb_free": "40.2", "wall": "668003"}
[2024-10-12 11:47:51,091][train_inner][INFO] - {"epoch": 741, "update": 741.0, "loss": "0.736", "ntokens": "263034", "nsentences": "1732.42", "wps": "202344", "ups": "0.77", "wpb": "263034", "bsz": "1732.4", "num_updates": "354800", "lr": "6.1413e-05", "gnorm": "0.226", "loss_scale": "4", "train_wall": "255", "gb_free": "39.3", "wall": "668263"}
[2024-10-12 11:47:51,102][fairseq_cli.train][INFO] - end of epoch 741 (average epoch stats below)
[2024-10-12 11:47:51,114][train][INFO] - {"epoch": 741, "train_loss": "0.737", "train_ntokens": "263577", "train_nsentences": "1753.71", "train_wps": "139759", "train_ups": "0.53", "train_wpb": "263577", "train_bsz": "1753.7", "train_num_updates": "354800", "train_lr": "6.1413e-05", "train_gnorm": "0.228", "train_loss_scale": "4", "train_train_wall": "579", "train_gb_free": "39.3", "train_wall": "668263"}
[2024-10-12 11:47:51,170][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:47:51,184][fairseq.trainer][INFO] - begin training epoch 742
[2024-10-12 11:47:51,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:56:52,013][train_inner][INFO] - {"epoch": 742, "update": 741.418, "loss": "0.738", "ntokens": "263641", "nsentences": "1802.39", "wps": "97481.3", "ups": "0.37", "wpb": "263641", "bsz": "1802.4", "num_updates": "355000", "lr": "6.11413e-05", "gnorm": "0.23", "loss_scale": "4", "train_wall": "229", "gb_free": "39.6", "wall": "668804"}
[2024-10-12 12:00:36,837][train_inner][INFO] - {"epoch": 742, "update": 741.835, "loss": "0.736", "ntokens": "264109", "nsentences": "1724.44", "wps": "234967", "ups": "0.89", "wpb": "264109", "bsz": "1724.4", "num_updates": "355200", "lr": "6.08696e-05", "gnorm": "0.222", "loss_scale": "4", "train_wall": "220", "gb_free": "39.6", "wall": "669029"}
[2024-10-12 12:02:02,933][fairseq_cli.train][INFO] - end of epoch 742 (average epoch stats below)
[2024-10-12 12:02:03,022][train][INFO] - {"epoch": 742, "train_loss": "0.737", "train_ntokens": "263479", "train_nsentences": "1753.71", "train_wps": "148162", "train_ups": "0.56", "train_wpb": "263479", "train_bsz": "1753.7", "train_num_updates": "355279", "train_lr": "6.07622e-05", "train_gnorm": "0.228", "train_loss_scale": "4", "train_train_wall": "532", "train_gb_free": "39.6", "train_wall": "669115"}
[2024-10-12 12:02:03,262][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:02:03,288][fairseq.trainer][INFO] - begin training epoch 743
[2024-10-12 12:02:03,289][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:10:22,759][train_inner][INFO] - {"epoch": 743, "update": 742.253, "loss": "0.736", "ntokens": "262966", "nsentences": "1738.66", "wps": "89763.7", "ups": "0.34", "wpb": "262966", "bsz": "1738.7", "num_updates": "355400", "lr": "6.05978e-05", "gnorm": "0.23", "loss_scale": "4", "train_wall": "241", "gb_free": "40", "wall": "669615"}
[2024-10-12 12:13:51,142][train_inner][INFO] - {"epoch": 743, "update": 742.67, "loss": "0.738", "ntokens": "264016", "nsentences": "1753.68", "wps": "253423", "ups": "0.96", "wpb": "264016", "bsz": "1753.7", "num_updates": "355600", "lr": "6.03261e-05", "gnorm": "0.238", "loss_scale": "4", "train_wall": "203", "gb_free": "40.3", "wall": "669823"}
[2024-10-12 12:17:05,617][fairseq_cli.train][INFO] - end of epoch 743 (average epoch stats below)
[2024-10-12 12:17:05,642][train][INFO] - {"epoch": 743, "train_loss": "0.737", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "139838", "train_ups": "0.53", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "355758", "train_lr": "6.01114e-05", "train_gnorm": "0.233", "train_loss_scale": "4", "train_train_wall": "550", "train_gb_free": "40", "train_wall": "670018"}
[2024-10-12 12:17:05,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:17:05,870][fairseq.trainer][INFO] - begin training epoch 744
[2024-10-12 12:17:05,871][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:23:30,155][train_inner][INFO] - {"epoch": 744, "update": 743.088, "loss": "0.736", "ntokens": "262740", "nsentences": "1765.04", "wps": "90757.1", "ups": "0.35", "wpb": "262740", "bsz": "1765", "num_updates": "355800", "lr": "6.00543e-05", "gnorm": "0.234", "loss_scale": "4", "train_wall": "257", "gb_free": "39.2", "wall": "670402"}
[2024-10-12 12:24:57,401][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 12:26:53,119][train_inner][INFO] - {"epoch": 744, "update": 743.507, "loss": "0.734", "ntokens": "264284", "nsentences": "1716.6", "wps": "260458", "ups": "0.99", "wpb": "264284", "bsz": "1716.6", "num_updates": "356000", "lr": "5.97826e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "198", "gb_free": "39.6", "wall": "670605"}
[2024-10-12 12:30:37,465][train_inner][INFO] - {"epoch": 744, "update": 743.925, "loss": "0.736", "ntokens": "263972", "nsentences": "1777.19", "wps": "235342", "ups": "0.89", "wpb": "263972", "bsz": "1777.2", "num_updates": "356200", "lr": "5.95109e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "670830"}
[2024-10-12 12:31:29,524][fairseq_cli.train][INFO] - end of epoch 744 (average epoch stats below)
[2024-10-12 12:31:29,536][train][INFO] - {"epoch": 744, "train_loss": "0.736", "train_ntokens": "263530", "train_nsentences": "1754.65", "train_wps": "145821", "train_ups": "0.55", "train_wpb": "263530", "train_bsz": "1754.6", "train_num_updates": "356236", "train_lr": "5.9462e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "535", "train_gb_free": "40.1", "train_wall": "670882"}
[2024-10-12 12:31:29,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:31:29,688][fairseq.trainer][INFO] - begin training epoch 745
[2024-10-12 12:31:29,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:40:09,503][train_inner][INFO] - {"epoch": 745, "update": 744.342, "loss": "0.738", "ntokens": "262430", "nsentences": "1782.99", "wps": "91754.7", "ups": "0.35", "wpb": "262430", "bsz": "1783", "num_updates": "356400", "lr": "5.92391e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "249", "gb_free": "39.6", "wall": "671402"}
[2024-10-12 12:44:00,004][train_inner][INFO] - {"epoch": 745, "update": 744.76, "loss": "0.736", "ntokens": "264301", "nsentences": "1738.79", "wps": "229361", "ups": "0.87", "wpb": "264301", "bsz": "1738.8", "num_updates": "356600", "lr": "5.89674e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "225", "gb_free": "39.1", "wall": "671632"}
[2024-10-12 12:46:02,649][fairseq_cli.train][INFO] - end of epoch 745 (average epoch stats below)
[2024-10-12 12:46:02,700][train][INFO] - {"epoch": 745, "train_loss": "0.737", "train_ntokens": "263528", "train_nsentences": "1753.71", "train_wps": "144570", "train_ups": "0.55", "train_wpb": "263528", "train_bsz": "1753.7", "train_num_updates": "356715", "train_lr": "5.88111e-05", "train_gnorm": "0.232", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "40.1", "train_wall": "671755"}
[2024-10-12 12:46:02,993][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:46:03,046][fairseq.trainer][INFO] - begin training epoch 746
[2024-10-12 12:46:03,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:53:20,167][train_inner][INFO] - {"epoch": 746, "update": 745.177, "loss": "0.738", "ntokens": "262885", "nsentences": "1723.99", "wps": "93866.2", "ups": "0.36", "wpb": "262885", "bsz": "1724", "num_updates": "356800", "lr": "5.86957e-05", "gnorm": "0.238", "loss_scale": "2", "train_wall": "224", "gb_free": "39.6", "wall": "672192"}
[2024-10-12 12:56:56,942][train_inner][INFO] - {"epoch": 746, "update": 745.595, "loss": "0.736", "ntokens": "264045", "nsentences": "1744.78", "wps": "243632", "ups": "0.92", "wpb": "264044", "bsz": "1744.8", "num_updates": "357000", "lr": "5.84239e-05", "gnorm": "0.232", "loss_scale": "2", "train_wall": "212", "gb_free": "39.6", "wall": "672409"}
[2024-10-12 13:01:32,289][fairseq_cli.train][INFO] - end of epoch 746 (average epoch stats below)
[2024-10-12 13:01:32,316][train][INFO] - {"epoch": 746, "train_loss": "0.737", "train_ntokens": "263506", "train_nsentences": "1753.71", "train_wps": "135785", "train_ups": "0.52", "train_wpb": "263506", "train_bsz": "1753.7", "train_num_updates": "357194", "train_lr": "5.81603e-05", "train_gnorm": "0.23", "train_loss_scale": "2", "train_train_wall": "588", "train_gb_free": "39.6", "train_wall": "672684"}
[2024-10-12 13:01:32,366][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:01:32,385][fairseq.trainer][INFO] - begin training epoch 747
[2024-10-12 13:01:32,385][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:07:12,027][train_inner][INFO] - {"epoch": 747, "update": 746.013, "loss": "0.738", "ntokens": "262687", "nsentences": "1777.93", "wps": "85418.5", "ups": "0.33", "wpb": "262687", "bsz": "1777.9", "num_updates": "357200", "lr": "5.81522e-05", "gnorm": "0.227", "loss_scale": "2", "train_wall": "299", "gb_free": "39.8", "wall": "673024"}
[2024-10-12 13:10:38,862][train_inner][INFO] - {"epoch": 747, "update": 746.43, "loss": "0.737", "ntokens": "263758", "nsentences": "1777.97", "wps": "255056", "ups": "0.97", "wpb": "263758", "bsz": "1778", "num_updates": "357400", "lr": "5.78804e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "201", "gb_free": "40", "wall": "673231"}
[2024-10-12 13:14:26,165][train_inner][INFO] - {"epoch": 747, "update": 746.848, "loss": "0.734", "ntokens": "264455", "nsentences": "1699.77", "wps": "232710", "ups": "0.88", "wpb": "264454", "bsz": "1699.8", "num_updates": "357600", "lr": "5.76087e-05", "gnorm": "0.236", "loss_scale": "2", "train_wall": "222", "gb_free": "39.8", "wall": "673458"}
[2024-10-12 13:16:08,203][fairseq_cli.train][INFO] - end of epoch 747 (average epoch stats below)
[2024-10-12 13:16:08,231][train][INFO] - {"epoch": 747, "train_loss": "0.736", "train_ntokens": "263509", "train_nsentences": "1753.71", "train_wps": "144103", "train_ups": "0.55", "train_wpb": "263509", "train_bsz": "1753.7", "train_num_updates": "357673", "train_lr": "5.75095e-05", "train_gnorm": "0.231", "train_loss_scale": "2", "train_train_wall": "552", "train_gb_free": "39.8", "train_wall": "673560"}
[2024-10-12 13:16:08,313][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:16:08,333][fairseq.trainer][INFO] - begin training epoch 748
[2024-10-12 13:16:08,334][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:24:05,826][train_inner][INFO] - {"epoch": 748, "update": 747.265, "loss": "0.736", "ntokens": "262485", "nsentences": "1792.29", "wps": "90569.5", "ups": "0.35", "wpb": "262485", "bsz": "1792.3", "num_updates": "357800", "lr": "5.7337e-05", "gnorm": "0.219", "loss_scale": "2", "train_wall": "271", "gb_free": "40.5", "wall": "674038"}
[2024-10-12 13:27:52,843][train_inner][INFO] - {"epoch": 748, "update": 747.683, "loss": "0.737", "ntokens": "264082", "nsentences": "1746.85", "wps": "232664", "ups": "0.88", "wpb": "264082", "bsz": "1746.9", "num_updates": "358000", "lr": "5.70652e-05", "gnorm": "0.232", "loss_scale": "4", "train_wall": "222", "gb_free": "39.2", "wall": "674265"}
[2024-10-12 13:31:11,217][fairseq_cli.train][INFO] - end of epoch 748 (average epoch stats below)
[2024-10-12 13:31:11,249][train][INFO] - {"epoch": 748, "train_loss": "0.736", "train_ntokens": "263548", "train_nsentences": "1753.71", "train_wps": "139799", "train_ups": "0.53", "train_wpb": "263548", "train_bsz": "1753.7", "train_num_updates": "358152", "train_lr": "5.68587e-05", "train_gnorm": "0.228", "train_loss_scale": "4", "train_train_wall": "588", "train_gb_free": "40", "train_wall": "674463"}
[2024-10-12 13:31:11,450][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:31:11,458][fairseq.trainer][INFO] - begin training epoch 749
[2024-10-12 13:31:11,458][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:37:38,767][train_inner][INFO] - {"epoch": 749, "update": 748.1, "loss": "0.735", "ntokens": "262902", "nsentences": "1762.08", "wps": "89742", "ups": "0.34", "wpb": "262902", "bsz": "1762.1", "num_updates": "358200", "lr": "5.67935e-05", "gnorm": "0.229", "loss_scale": "4", "train_wall": "265", "gb_free": "40", "wall": "674851"}
[2024-10-12 13:41:06,214][train_inner][INFO] - {"epoch": 749, "update": 748.518, "loss": "0.736", "ntokens": "263944", "nsentences": "1772.31", "wps": "254582", "ups": "0.96", "wpb": "263944", "bsz": "1772.3", "num_updates": "358400", "lr": "5.65217e-05", "gnorm": "0.224", "loss_scale": "4", "train_wall": "201", "gb_free": "40.3", "wall": "675058"}
[2024-10-12 13:41:53,259][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 13:44:46,518][train_inner][INFO] - {"epoch": 749, "update": 748.937, "loss": "0.737", "ntokens": "264174", "nsentences": "1745.06", "wps": "239846", "ups": "0.91", "wpb": "264174", "bsz": "1745.1", "num_updates": "358600", "lr": "5.625e-05", "gnorm": "0.223", "loss_scale": "2", "train_wall": "215", "gb_free": "39.6", "wall": "675279"}
[2024-10-12 13:45:36,603][fairseq_cli.train][INFO] - end of epoch 749 (average epoch stats below)
[2024-10-12 13:45:36,655][train][INFO] - {"epoch": 749, "train_loss": "0.736", "train_ntokens": "263565", "train_nsentences": "1753.6", "train_wps": "145584", "train_ups": "0.55", "train_wpb": "263565", "train_bsz": "1753.6", "train_num_updates": "358630", "train_lr": "5.62092e-05", "train_gnorm": "0.224", "train_loss_scale": "2", "train_train_wall": "533", "train_gb_free": "40", "train_wall": "675329"}
[2024-10-12 13:45:38,103][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:45:38,231][fairseq.trainer][INFO] - begin training epoch 750
[2024-10-12 13:45:38,231][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:53:50,850][train_inner][INFO] - {"epoch": 750, "update": 749.355, "loss": "0.734", "ntokens": "263001", "nsentences": "1727.32", "wps": "96641.7", "ups": "0.37", "wpb": "263001", "bsz": "1727.3", "num_updates": "358800", "lr": "5.59783e-05", "gnorm": "0.23", "loss_scale": "2", "train_wall": "217", "gb_free": "39.6", "wall": "675823"}
[2024-10-12 13:57:35,272][train_inner][INFO] - {"epoch": 750, "update": 749.772, "loss": "0.738", "ntokens": "264263", "nsentences": "1742.86", "wps": "235533", "ups": "0.89", "wpb": "264263", "bsz": "1742.9", "num_updates": "359000", "lr": "5.57065e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "218", "gb_free": "40", "wall": "676047"}
[2024-10-12 13:59:43,864][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 750 @ 359109 updates
[2024-10-12 13:59:43,870][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 13:59:51,972][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 13:59:52,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 750 @ 359109 updates, score None) (writing took 8.23554131295532 seconds)
[2024-10-12 13:59:52,100][fairseq_cli.train][INFO] - end of epoch 750 (average epoch stats below)
[2024-10-12 13:59:52,103][train][INFO] - {"epoch": 750, "train_loss": "0.736", "train_ntokens": "263579", "train_nsentences": "1753.71", "train_wps": "147662", "train_ups": "0.56", "train_wpb": "263580", "train_bsz": "1753.7", "train_num_updates": "359109", "train_lr": "5.55584e-05", "train_gnorm": "0.225", "train_loss_scale": "2", "train_train_wall": "514", "train_gb_free": "39.3", "train_wall": "676184"}
[2024-10-12 13:59:52,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:59:52,160][fairseq.trainer][INFO] - begin training epoch 751
[2024-10-12 13:59:52,161][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:07:42,629][train_inner][INFO] - {"epoch": 751, "update": 750.19, "loss": "0.736", "ntokens": "262310", "nsentences": "1812.17", "wps": "86389", "ups": "0.33", "wpb": "262310", "bsz": "1812.2", "num_updates": "359200", "lr": "5.54348e-05", "gnorm": "0.22", "loss_scale": "2", "train_wall": "263", "gb_free": "40.2", "wall": "676655"}
[2024-10-12 14:11:17,125][train_inner][INFO] - {"epoch": 751, "update": 750.608, "loss": "0.734", "ntokens": "264349", "nsentences": "1734.16", "wps": "246506", "ups": "0.93", "wpb": "264349", "bsz": "1734.2", "num_updates": "359400", "lr": "5.5163e-05", "gnorm": "0.226", "loss_scale": "2", "train_wall": "208", "gb_free": "40.2", "wall": "676869"}
[2024-10-12 14:14:49,439][fairseq_cli.train][INFO] - end of epoch 751 (average epoch stats below)
[2024-10-12 14:14:49,457][train][INFO] - {"epoch": 751, "train_loss": "0.735", "train_ntokens": "263522", "train_nsentences": "1753.71", "train_wps": "140668", "train_ups": "0.53", "train_wpb": "263522", "train_bsz": "1753.7", "train_num_updates": "359588", "train_lr": "5.49076e-05", "train_gnorm": "0.228", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "40", "train_wall": "677082"}
[2024-10-12 14:14:49,643][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:14:49,653][fairseq.trainer][INFO] - begin training epoch 752
[2024-10-12 14:14:49,654][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:20:36,022][train_inner][INFO] - {"epoch": 752, "update": 751.025, "loss": "0.735", "ntokens": "262881", "nsentences": "1729.78", "wps": "94081", "ups": "0.36", "wpb": "262881", "bsz": "1729.8", "num_updates": "359600", "lr": "5.48913e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "221", "gb_free": "39.3", "wall": "677428"}
[2024-10-12 14:24:32,646][train_inner][INFO] - {"epoch": 752, "update": 751.443, "loss": "0.734", "ntokens": "264056", "nsentences": "1748.03", "wps": "223203", "ups": "0.85", "wpb": "264056", "bsz": "1748", "num_updates": "359800", "lr": "5.46196e-05", "gnorm": "0.218", "loss_scale": "2", "train_wall": "231", "gb_free": "39.6", "wall": "677665"}
[2024-10-12 14:28:23,683][train_inner][INFO] - {"epoch": 752, "update": 751.86, "loss": "0.736", "ntokens": "263708", "nsentences": "1767.45", "wps": "228318", "ups": "0.87", "wpb": "263708", "bsz": "1767.5", "num_updates": "360000", "lr": "5.43478e-05", "gnorm": "0.218", "loss_scale": "2", "train_wall": "225", "gb_free": "40", "wall": "677896"}
[2024-10-12 14:29:45,319][fairseq_cli.train][INFO] - end of epoch 752 (average epoch stats below)
[2024-10-12 14:29:45,345][train][INFO] - {"epoch": 752, "train_loss": "0.735", "train_ntokens": "263464", "train_nsentences": "1753.71", "train_wps": "140877", "train_ups": "0.53", "train_wpb": "263464", "train_bsz": "1753.7", "train_num_updates": "360067", "train_lr": "5.42568e-05", "train_gnorm": "0.221", "train_loss_scale": "2", "train_train_wall": "550", "train_gb_free": "40.5", "train_wall": "677978"}
[2024-10-12 14:29:45,562][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:29:45,591][fairseq.trainer][INFO] - begin training epoch 753
[2024-10-12 14:29:45,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:37:38,730][train_inner][INFO] - {"epoch": 753, "update": 752.278, "loss": "0.735", "ntokens": "262965", "nsentences": "1762.42", "wps": "94760", "ups": "0.36", "wpb": "262965", "bsz": "1762.4", "num_updates": "360200", "lr": "5.40761e-05", "gnorm": "0.22", "loss_scale": "2", "train_wall": "211", "gb_free": "39.6", "wall": "678451"}
[2024-10-12 14:41:35,186][train_inner][INFO] - {"epoch": 753, "update": 752.695, "loss": "0.734", "ntokens": "264068", "nsentences": "1739.15", "wps": "223393", "ups": "0.85", "wpb": "264068", "bsz": "1739.2", "num_updates": "360400", "lr": "5.38043e-05", "gnorm": "0.235", "loss_scale": "2", "train_wall": "230", "gb_free": "39.6", "wall": "678687"}
[2024-10-12 14:44:08,171][fairseq_cli.train][INFO] - end of epoch 753 (average epoch stats below)
[2024-10-12 14:44:08,222][train][INFO] - {"epoch": 753, "train_loss": "0.735", "train_ntokens": "263589", "train_nsentences": "1753.71", "train_wps": "146338", "train_ups": "0.56", "train_wpb": "263589", "train_bsz": "1753.7", "train_num_updates": "360546", "train_lr": "5.3606e-05", "train_gnorm": "0.228", "train_loss_scale": "4", "train_train_wall": "510", "train_gb_free": "39.6", "train_wall": "678840"}
[2024-10-12 14:44:08,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:44:08,839][fairseq.trainer][INFO] - begin training epoch 754
[2024-10-12 14:44:08,846][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:51:03,520][train_inner][INFO] - {"epoch": 754, "update": 753.113, "loss": "0.734", "ntokens": "262996", "nsentences": "1754.54", "wps": "92551.9", "ups": "0.35", "wpb": "262996", "bsz": "1754.5", "num_updates": "360600", "lr": "5.35326e-05", "gnorm": "0.23", "loss_scale": "4", "train_wall": "209", "gb_free": "39.7", "wall": "679256"}
[2024-10-12 14:51:30,582][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 14:54:41,099][train_inner][INFO] - {"epoch": 754, "update": 753.532, "loss": "0.734", "ntokens": "264007", "nsentences": "1764.48", "wps": "242720", "ups": "0.92", "wpb": "264007", "bsz": "1764.5", "num_updates": "360800", "lr": "5.32609e-05", "gnorm": "0.223", "loss_scale": "2", "train_wall": "212", "gb_free": "39.7", "wall": "679473"}
[2024-10-12 14:58:18,331][train_inner][INFO] - {"epoch": 754, "update": 753.95, "loss": "0.735", "ntokens": "263952", "nsentences": "1756.41", "wps": "243047", "ups": "0.92", "wpb": "263952", "bsz": "1756.4", "num_updates": "361000", "lr": "5.29891e-05", "gnorm": "0.231", "loss_scale": "2", "train_wall": "212", "gb_free": "39.2", "wall": "679691"}
[2024-10-12 14:59:12,876][fairseq_cli.train][INFO] - end of epoch 754 (average epoch stats below)
[2024-10-12 14:59:12,890][train][INFO] - {"epoch": 754, "train_loss": "0.735", "train_ntokens": "263564", "train_nsentences": "1751.54", "train_wps": "139276", "train_ups": "0.53", "train_wpb": "263564", "train_bsz": "1751.5", "train_num_updates": "361024", "train_lr": "5.29565e-05", "train_gnorm": "0.229", "train_loss_scale": "2", "train_train_wall": "539", "train_gb_free": "39.6", "train_wall": "679745"}
[2024-10-12 14:59:13,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:59:13,027][fairseq.trainer][INFO] - begin training epoch 755
[2024-10-12 14:59:13,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:07:46,558][train_inner][INFO] - {"epoch": 755, "update": 754.367, "loss": "0.733", "ntokens": "262729", "nsentences": "1729.23", "wps": "92475.1", "ups": "0.35", "wpb": "262729", "bsz": "1729.2", "num_updates": "361200", "lr": "5.27174e-05", "gnorm": "0.241", "loss_scale": "2", "train_wall": "254", "gb_free": "41", "wall": "680259"}
[2024-10-12 15:11:48,454][train_inner][INFO] - {"epoch": 755, "update": 754.785, "loss": "0.735", "ntokens": "264083", "nsentences": "1758.88", "wps": "218363", "ups": "0.83", "wpb": "264083", "bsz": "1758.9", "num_updates": "361400", "lr": "5.24457e-05", "gnorm": "0.219", "loss_scale": "2", "train_wall": "237", "gb_free": "40.3", "wall": "680501"}
[2024-10-12 15:13:42,402][fairseq_cli.train][INFO] - end of epoch 755 (average epoch stats below)
[2024-10-12 15:13:42,420][train][INFO] - {"epoch": 755, "train_loss": "0.734", "train_ntokens": "263467", "train_nsentences": "1753.71", "train_wps": "145139", "train_ups": "0.55", "train_wpb": "263467", "train_bsz": "1753.7", "train_num_updates": "361503", "train_lr": "5.23057e-05", "train_gnorm": "0.23", "train_loss_scale": "2", "train_train_wall": "549", "train_gb_free": "39", "train_wall": "680615"}
[2024-10-12 15:13:42,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:13:42,500][fairseq.trainer][INFO] - begin training epoch 756
[2024-10-12 15:13:42,501][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:20:58,592][train_inner][INFO] - {"epoch": 756, "update": 755.203, "loss": "0.734", "ntokens": "262706", "nsentences": "1757.2", "wps": "95509.8", "ups": "0.36", "wpb": "262706", "bsz": "1757.2", "num_updates": "361600", "lr": "5.21739e-05", "gnorm": "0.233", "loss_scale": "2", "train_wall": "205", "gb_free": "39.2", "wall": "681051"}
[2024-10-12 15:23:38,287][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-12 15:24:44,363][train_inner][INFO] - {"epoch": 756, "update": 755.622, "loss": "0.737", "ntokens": "263834", "nsentences": "1765.01", "wps": "233730", "ups": "0.89", "wpb": "263834", "bsz": "1765", "num_updates": "361800", "lr": "5.19022e-05", "gnorm": "0.211", "loss_scale": "1", "train_wall": "220", "gb_free": "39.3", "wall": "681277"}
[2024-10-12 15:28:31,533][fairseq_cli.train][INFO] - end of epoch 756 (average epoch stats below)
[2024-10-12 15:28:31,576][train][INFO] - {"epoch": 756, "train_loss": "0.734", "train_ntokens": "263459", "train_nsentences": "1750.62", "train_wps": "141634", "train_ups": "0.54", "train_wpb": "263459", "train_bsz": "1750.6", "train_num_updates": "361981", "train_lr": "5.16563e-05", "train_gnorm": "0.221", "train_loss_scale": "1", "train_train_wall": "536", "train_gb_free": "39.3", "train_wall": "681504"}
[2024-10-12 15:28:31,726][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:28:31,754][fairseq.trainer][INFO] - begin training epoch 757
[2024-10-12 15:28:31,755][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:34:33,882][train_inner][INFO] - {"epoch": 757, "update": 756.04, "loss": "0.733", "ntokens": "263071", "nsentences": "1720.24", "wps": "89251.1", "ups": "0.34", "wpb": "263071", "bsz": "1720.2", "num_updates": "362000", "lr": "5.16304e-05", "gnorm": "0.228", "loss_scale": "1", "train_wall": "259", "gb_free": "39.8", "wall": "681866"}
[2024-10-12 15:38:52,165][train_inner][INFO] - {"epoch": 757, "update": 756.457, "loss": "0.735", "ntokens": "263936", "nsentences": "1790.65", "wps": "204397", "ups": "0.77", "wpb": "263936", "bsz": "1790.7", "num_updates": "362200", "lr": "5.13587e-05", "gnorm": "0.215", "loss_scale": "1", "train_wall": "253", "gb_free": "39.6", "wall": "682124"}
[2024-10-12 15:43:06,196][train_inner][INFO] - {"epoch": 757, "update": 756.875, "loss": "0.733", "ntokens": "264199", "nsentences": "1740.29", "wps": "208027", "ups": "0.79", "wpb": "264199", "bsz": "1740.3", "num_updates": "362400", "lr": "5.1087e-05", "gnorm": "0.23", "loss_scale": "1", "train_wall": "248", "gb_free": "40", "wall": "682378"}
[2024-10-12 15:44:25,430][fairseq_cli.train][INFO] - end of epoch 757 (average epoch stats below)
[2024-10-12 15:44:25,448][train][INFO] - {"epoch": 757, "train_loss": "0.734", "train_ntokens": "263614", "train_nsentences": "1753.71", "train_wps": "132382", "train_ups": "0.5", "train_wpb": "263614", "train_bsz": "1753.7", "train_num_updates": "362460", "train_lr": "5.10054e-05", "train_gnorm": "0.224", "train_loss_scale": "1", "train_train_wall": "616", "train_gb_free": "40", "train_wall": "682458"}
[2024-10-12 15:44:25,533][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:44:25,581][fairseq.trainer][INFO] - begin training epoch 758
[2024-10-12 15:44:25,581][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:52:34,956][train_inner][INFO] - {"epoch": 758, "update": 757.292, "loss": "0.734", "ntokens": "262723", "nsentences": "1764.26", "wps": "92386.1", "ups": "0.35", "wpb": "262723", "bsz": "1764.3", "num_updates": "362600", "lr": "5.08152e-05", "gnorm": "0.23", "loss_scale": "1", "train_wall": "216", "gb_free": "39.8", "wall": "682947"}
[2024-10-12 15:56:29,167][train_inner][INFO] - {"epoch": 758, "update": 757.71, "loss": "0.735", "ntokens": "263945", "nsentences": "1758.69", "wps": "225428", "ups": "0.85", "wpb": "263945", "bsz": "1758.7", "num_updates": "362800", "lr": "5.05435e-05", "gnorm": "0.225", "loss_scale": "1", "train_wall": "210", "gb_free": "39.6", "wall": "683181"}
[2024-10-12 15:59:00,228][fairseq_cli.train][INFO] - end of epoch 758 (average epoch stats below)
[2024-10-12 15:59:00,238][train][INFO] - {"epoch": 758, "train_loss": "0.735", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "144302", "train_ups": "0.55", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "362939", "train_lr": "5.03546e-05", "train_gnorm": "0.224", "train_loss_scale": "1", "train_train_wall": "495", "train_gb_free": "41.3", "train_wall": "683332"}
[2024-10-12 15:59:00,376][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:59:00,398][fairseq.trainer][INFO] - begin training epoch 759
[2024-10-12 15:59:00,399][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:05:41,763][train_inner][INFO] - {"epoch": 759, "update": 758.127, "loss": "0.735", "ntokens": "263221", "nsentences": "1727.09", "wps": "95272.5", "ups": "0.36", "wpb": "263221", "bsz": "1727.1", "num_updates": "363000", "lr": "5.02717e-05", "gnorm": "0.222", "loss_scale": "1", "train_wall": "233", "gb_free": "39.8", "wall": "683734"}
[2024-10-12 16:09:42,447][train_inner][INFO] - {"epoch": 759, "update": 758.545, "loss": "0.736", "ntokens": "263565", "nsentences": "1788.18", "wps": "219033", "ups": "0.83", "wpb": "263565", "bsz": "1788.2", "num_updates": "363200", "lr": "5e-05", "gnorm": "0.217", "loss_scale": "1", "train_wall": "235", "gb_free": "39.3", "wall": "683975"}
[2024-10-12 16:13:21,395][train_inner][INFO] - {"epoch": 759, "update": 758.962, "loss": "0.732", "ntokens": "264119", "nsentences": "1736.03", "wps": "241280", "ups": "0.91", "wpb": "264119", "bsz": "1736", "num_updates": "363400", "lr": "4.97283e-05", "gnorm": "0.219", "loss_scale": "1", "train_wall": "214", "gb_free": "40.5", "wall": "684194"}
[2024-10-12 16:14:01,060][fairseq_cli.train][INFO] - end of epoch 759 (average epoch stats below)
[2024-10-12 16:14:01,064][train][INFO] - {"epoch": 759, "train_loss": "0.734", "train_ntokens": "263487", "train_nsentences": "1753.71", "train_wps": "140110", "train_ups": "0.53", "train_wpb": "263487", "train_bsz": "1753.7", "train_num_updates": "363418", "train_lr": "4.97038e-05", "train_gnorm": "0.223", "train_loss_scale": "1", "train_train_wall": "572", "train_gb_free": "40", "train_wall": "684233"}
[2024-10-12 16:14:01,226][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:14:01,249][fairseq.trainer][INFO] - begin training epoch 760
[2024-10-12 16:14:01,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:22:58,625][train_inner][INFO] - {"epoch": 760, "update": 759.38, "loss": "0.735", "ntokens": "262649", "nsentences": "1756.47", "wps": "91004.9", "ups": "0.35", "wpb": "262649", "bsz": "1756.5", "num_updates": "363600", "lr": "4.94565e-05", "gnorm": "0.227", "loss_scale": "1", "train_wall": "233", "gb_free": "39.1", "wall": "684771"}
[2024-10-12 16:26:55,518][train_inner][INFO] - {"epoch": 760, "update": 759.797, "loss": "0.733", "ntokens": "264064", "nsentences": "1745.07", "wps": "222975", "ups": "0.84", "wpb": "264064", "bsz": "1745.1", "num_updates": "363800", "lr": "4.91848e-05", "gnorm": "0.221", "loss_scale": "1", "train_wall": "209", "gb_free": "39.7", "wall": "685008"}
[2024-10-12 16:28:54,226][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 760 @ 363897 updates
[2024-10-12 16:28:54,229][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 16:29:01,751][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 16:29:01,998][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 760 @ 363897 updates, score None) (writing took 7.771394761279225 seconds)
[2024-10-12 16:29:02,005][fairseq_cli.train][INFO] - end of epoch 760 (average epoch stats below)
[2024-10-12 16:29:02,008][train][INFO] - {"epoch": 760, "train_loss": "0.734", "train_ntokens": "263489", "train_nsentences": "1753.71", "train_wps": "140093", "train_ups": "0.53", "train_wpb": "263489", "train_bsz": "1753.7", "train_num_updates": "363897", "train_lr": "4.9053e-05", "train_gnorm": "0.222", "train_loss_scale": "2", "train_train_wall": "503", "train_gb_free": "40", "train_wall": "685134"}
[2024-10-12 16:29:02,087][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:29:02,114][fairseq.trainer][INFO] - begin training epoch 761
[2024-10-12 16:29:02,114][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:36:16,597][train_inner][INFO] - {"epoch": 761, "update": 760.215, "loss": "0.733", "ntokens": "262977", "nsentences": "1750.3", "wps": "93743.1", "ups": "0.36", "wpb": "262977", "bsz": "1750.3", "num_updates": "364000", "lr": "4.8913e-05", "gnorm": "0.229", "loss_scale": "2", "train_wall": "190", "gb_free": "40", "wall": "685569"}
[2024-10-12 16:39:51,963][train_inner][INFO] - {"epoch": 761, "update": 760.633, "loss": "0.733", "ntokens": "263912", "nsentences": "1748.23", "wps": "245119", "ups": "0.93", "wpb": "263912", "bsz": "1748.2", "num_updates": "364200", "lr": "4.86413e-05", "gnorm": "0.221", "loss_scale": "2", "train_wall": "202", "gb_free": "39.3", "wall": "685784"}
[2024-10-12 16:43:52,880][fairseq_cli.train][INFO] - end of epoch 761 (average epoch stats below)
[2024-10-12 16:43:52,907][train][INFO] - {"epoch": 761, "train_loss": "0.733", "train_ntokens": "263395", "train_nsentences": "1753.71", "train_wps": "141620", "train_ups": "0.54", "train_wpb": "263395", "train_bsz": "1753.7", "train_num_updates": "364376", "train_lr": "4.84022e-05", "train_gnorm": "0.226", "train_loss_scale": "2", "train_train_wall": "529", "train_gb_free": "39.3", "train_wall": "686025"}
[2024-10-12 16:43:52,986][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:43:52,993][fairseq.trainer][INFO] - begin training epoch 762
[2024-10-12 16:43:52,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:50:03,863][train_inner][INFO] - {"epoch": 762, "update": 761.05, "loss": "0.735", "ntokens": "262530", "nsentences": "1758.47", "wps": "85810.8", "ups": "0.33", "wpb": "262530", "bsz": "1758.5", "num_updates": "364400", "lr": "4.83696e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "294", "gb_free": "40.1", "wall": "686396"}
[2024-10-12 16:53:39,162][train_inner][INFO] - {"epoch": 762, "update": 761.468, "loss": "0.732", "ntokens": "264307", "nsentences": "1735.66", "wps": "245546", "ups": "0.93", "wpb": "264307", "bsz": "1735.7", "num_updates": "364600", "lr": "4.80978e-05", "gnorm": "0.224", "loss_scale": "2", "train_wall": "210", "gb_free": "39.7", "wall": "686611"}
[2024-10-12 16:57:56,882][train_inner][INFO] - {"epoch": 762, "update": 761.885, "loss": "0.734", "ntokens": "264117", "nsentences": "1759.19", "wps": "204976", "ups": "0.78", "wpb": "264117", "bsz": "1759.2", "num_updates": "364800", "lr": "4.78261e-05", "gnorm": "0.222", "loss_scale": "2", "train_wall": "252", "gb_free": "40.1", "wall": "686869"}
[2024-10-12 16:59:16,864][fairseq_cli.train][INFO] - end of epoch 762 (average epoch stats below)
[2024-10-12 16:59:16,881][train][INFO] - {"epoch": 762, "train_loss": "0.733", "train_ntokens": "263580", "train_nsentences": "1753.71", "train_wps": "136645", "train_ups": "0.52", "train_wpb": "263580", "train_bsz": "1753.7", "train_num_updates": "364855", "train_lr": "4.77514e-05", "train_gnorm": "0.224", "train_loss_scale": "2", "train_train_wall": "599", "train_gb_free": "39.6", "train_wall": "686949"}
[2024-10-12 16:59:16,988][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:59:17,020][fairseq.trainer][INFO] - begin training epoch 763
[2024-10-12 16:59:17,020][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:07:42,245][train_inner][INFO] - {"epoch": 763, "update": 762.303, "loss": "0.733", "ntokens": "262602", "nsentences": "1768.42", "wps": "89724.7", "ups": "0.34", "wpb": "262602", "bsz": "1768.4", "num_updates": "365000", "lr": "4.75543e-05", "gnorm": "0.231", "loss_scale": "2", "train_wall": "261", "gb_free": "39.8", "wall": "687454"}
[2024-10-12 17:11:58,087][train_inner][INFO] - {"epoch": 763, "update": 762.72, "loss": "0.734", "ntokens": "264373", "nsentences": "1730.13", "wps": "206681", "ups": "0.78", "wpb": "264373", "bsz": "1730.1", "num_updates": "365200", "lr": "4.72826e-05", "gnorm": "0.214", "loss_scale": "2", "train_wall": "250", "gb_free": "39.7", "wall": "687710"}
[2024-10-12 17:15:19,770][fairseq_cli.train][INFO] - end of epoch 763 (average epoch stats below)
[2024-10-12 17:15:19,795][train][INFO] - {"epoch": 763, "train_loss": "0.734", "train_ntokens": "263562", "train_nsentences": "1753.71", "train_wps": "131110", "train_ups": "0.5", "train_wpb": "263562", "train_bsz": "1753.7", "train_num_updates": "365334", "train_lr": "4.71005e-05", "train_gnorm": "0.222", "train_loss_scale": "2", "train_train_wall": "632", "train_gb_free": "39.8", "train_wall": "687912"}
[2024-10-12 17:15:19,860][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:15:19,879][fairseq.trainer][INFO] - begin training epoch 764
[2024-10-12 17:15:19,880][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:22:14,744][train_inner][INFO] - {"epoch": 764, "update": 763.138, "loss": "0.733", "ntokens": "262657", "nsentences": "1767.07", "wps": "85191.9", "ups": "0.32", "wpb": "262657", "bsz": "1767.1", "num_updates": "365400", "lr": "4.70109e-05", "gnorm": "0.224", "loss_scale": "2", "train_wall": "305", "gb_free": "39.7", "wall": "688327"}
[2024-10-12 17:26:16,666][train_inner][INFO] - {"epoch": 764, "update": 763.555, "loss": "0.729", "ntokens": "264443", "nsentences": "1701.78", "wps": "218641", "ups": "0.83", "wpb": "264443", "bsz": "1701.8", "num_updates": "365600", "lr": "4.67391e-05", "gnorm": "0.216", "loss_scale": "2", "train_wall": "236", "gb_free": "39.8", "wall": "688569"}
[2024-10-12 17:30:36,211][train_inner][INFO] - {"epoch": 764, "update": 763.973, "loss": "0.736", "ntokens": "263696", "nsentences": "1801.5", "wps": "203219", "ups": "0.77", "wpb": "263696", "bsz": "1801.5", "num_updates": "365800", "lr": "4.64674e-05", "gnorm": "0.22", "loss_scale": "2", "train_wall": "254", "gb_free": "40", "wall": "688828"}
[2024-10-12 17:31:17,880][fairseq_cli.train][INFO] - end of epoch 764 (average epoch stats below)
[2024-10-12 17:31:17,908][train][INFO] - {"epoch": 764, "train_loss": "0.733", "train_ntokens": "263508", "train_nsentences": "1753.71", "train_wps": "131740", "train_ups": "0.5", "train_wpb": "263508", "train_bsz": "1753.7", "train_num_updates": "365813", "train_lr": "4.64497e-05", "train_gnorm": "0.22", "train_loss_scale": "2", "train_train_wall": "638", "train_gb_free": "41", "train_wall": "688870"}
[2024-10-12 17:31:18,032][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:31:18,069][fairseq.trainer][INFO] - begin training epoch 765
[2024-10-12 17:31:18,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:40:33,710][train_inner][INFO] - {"epoch": 765, "update": 764.39, "loss": "0.733", "ntokens": "262570", "nsentences": "1765.81", "wps": "87891.7", "ups": "0.33", "wpb": "262570", "bsz": "1765.8", "num_updates": "366000", "lr": "4.61957e-05", "gnorm": "0.226", "loss_scale": "4", "train_wall": "277", "gb_free": "39.6", "wall": "689426"}
[2024-10-12 17:44:36,518][train_inner][INFO] - {"epoch": 765, "update": 764.808, "loss": "0.735", "ntokens": "263689", "nsentences": "1766.9", "wps": "217221", "ups": "0.82", "wpb": "263688", "bsz": "1766.9", "num_updates": "366200", "lr": "4.59239e-05", "gnorm": "0.218", "loss_scale": "4", "train_wall": "237", "gb_free": "39.6", "wall": "689669"}
[2024-10-12 17:46:44,020][fairseq_cli.train][INFO] - end of epoch 765 (average epoch stats below)
[2024-10-12 17:46:44,038][train][INFO] - {"epoch": 765, "train_loss": "0.733", "train_ntokens": "263361", "train_nsentences": "1753.71", "train_wps": "136214", "train_ups": "0.52", "train_wpb": "263361", "train_bsz": "1753.7", "train_num_updates": "366292", "train_lr": "4.57989e-05", "train_gnorm": "0.221", "train_loss_scale": "4", "train_train_wall": "596", "train_gb_free": "39.6", "train_wall": "689796"}
[2024-10-12 17:46:44,140][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:46:44,145][fairseq.trainer][INFO] - begin training epoch 766
[2024-10-12 17:46:44,146][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:54:25,870][train_inner][INFO] - {"epoch": 766, "update": 765.225, "loss": "0.731", "ntokens": "262933", "nsentences": "1745.38", "wps": "89232.1", "ups": "0.34", "wpb": "262933", "bsz": "1745.4", "num_updates": "366400", "lr": "4.56522e-05", "gnorm": "0.228", "loss_scale": "4", "train_wall": "271", "gb_free": "39.6", "wall": "690258"}
[2024-10-12 17:58:18,805][train_inner][INFO] - {"epoch": 766, "update": 765.643, "loss": "0.731", "ntokens": "264180", "nsentences": "1726.5", "wps": "226858", "ups": "0.86", "wpb": "264180", "bsz": "1726.5", "num_updates": "366600", "lr": "4.53804e-05", "gnorm": "0.214", "loss_scale": "4", "train_wall": "228", "gb_free": "39.2", "wall": "690491"}
[2024-10-12 18:01:48,242][fairseq_cli.train][INFO] - end of epoch 766 (average epoch stats below)
[2024-10-12 18:01:48,276][train][INFO] - {"epoch": 766, "train_loss": "0.732", "train_ntokens": "263505", "train_nsentences": "1753.71", "train_wps": "139588", "train_ups": "0.53", "train_wpb": "263505", "train_bsz": "1753.7", "train_num_updates": "366771", "train_lr": "4.51481e-05", "train_gnorm": "0.22", "train_loss_scale": "4", "train_train_wall": "579", "train_gb_free": "39.6", "train_wall": "690700"}
[2024-10-12 18:01:48,410][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:01:48,441][fairseq.trainer][INFO] - begin training epoch 767
[2024-10-12 18:01:48,442][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:07:51,512][train_inner][INFO] - {"epoch": 767, "update": 766.061, "loss": "0.734", "ntokens": "262694", "nsentences": "1767.94", "wps": "91740.4", "ups": "0.35", "wpb": "262694", "bsz": "1767.9", "num_updates": "366800", "lr": "4.51087e-05", "gnorm": "0.217", "loss_scale": "4", "train_wall": "244", "gb_free": "40.5", "wall": "691064"}
[2024-10-12 18:11:36,113][train_inner][INFO] - {"epoch": 767, "update": 766.478, "loss": "0.734", "ntokens": "263886", "nsentences": "1772.93", "wps": "234998", "ups": "0.89", "wpb": "263886", "bsz": "1772.9", "num_updates": "367000", "lr": "4.4837e-05", "gnorm": "0.208", "loss_scale": "4", "train_wall": "182", "gb_free": "39.2", "wall": "691288"}
[2024-10-12 18:14:53,935][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 18:15:33,343][train_inner][INFO] - {"epoch": 767, "update": 766.898, "loss": "0.732", "ntokens": "263856", "nsentences": "1754.61", "wps": "222463", "ups": "0.84", "wpb": "263856", "bsz": "1754.6", "num_updates": "367200", "lr": "4.45652e-05", "gnorm": "0.214", "loss_scale": "2", "train_wall": "162", "gb_free": "39.3", "wall": "691526"}
[2024-10-12 18:16:31,792][fairseq_cli.train][INFO] - end of epoch 767 (average epoch stats below)
[2024-10-12 18:16:31,798][train][INFO] - {"epoch": 767, "train_loss": "0.733", "train_ntokens": "263477", "train_nsentences": "1754.48", "train_wps": "142547", "train_ups": "0.54", "train_wpb": "263477", "train_bsz": "1754.5", "train_num_updates": "367249", "train_lr": "4.44986e-05", "train_gnorm": "0.21", "train_loss_scale": "2", "train_train_wall": "421", "train_gb_free": "39.8", "train_wall": "691584"}
[2024-10-12 18:16:31,915][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:16:31,932][fairseq.trainer][INFO] - begin training epoch 768
[2024-10-12 18:16:31,933][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:24:58,691][train_inner][INFO] - {"epoch": 768, "update": 767.315, "loss": "0.733", "ntokens": "262434", "nsentences": "1786.51", "wps": "92856", "ups": "0.35", "wpb": "262434", "bsz": "1786.5", "num_updates": "367400", "lr": "4.42935e-05", "gnorm": "0.212", "loss_scale": "2", "train_wall": "208", "gb_free": "39.3", "wall": "692091"}
[2024-10-12 18:28:40,473][train_inner][INFO] - {"epoch": 768, "update": 767.733, "loss": "0.732", "ntokens": "263983", "nsentences": "1752.77", "wps": "238074", "ups": "0.9", "wpb": "263983", "bsz": "1752.8", "num_updates": "367600", "lr": "4.40217e-05", "gnorm": "0.229", "loss_scale": "2", "train_wall": "140", "gb_free": "39.6", "wall": "692313"}
[2024-10-12 18:30:55,163][fairseq_cli.train][INFO] - end of epoch 768 (average epoch stats below)
[2024-10-12 18:30:55,206][train][INFO] - {"epoch": 768, "train_loss": "0.732", "train_ntokens": "263502", "train_nsentences": "1753.71", "train_wps": "146188", "train_ups": "0.55", "train_wpb": "263502", "train_bsz": "1753.7", "train_num_updates": "367728", "train_lr": "4.38478e-05", "train_gnorm": "0.225", "train_loss_scale": "2", "train_train_wall": "402", "train_gb_free": "39.3", "train_wall": "692447"}
[2024-10-12 18:30:55,679][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:30:55,732][fairseq.trainer][INFO] - begin training epoch 769
[2024-10-12 18:30:55,733][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:38:18,417][train_inner][INFO] - {"epoch": 769, "update": 768.15, "loss": "0.73", "ntokens": "263310", "nsentences": "1698.8", "wps": "91126.9", "ups": "0.35", "wpb": "263310", "bsz": "1698.8", "num_updates": "367800", "lr": "4.375e-05", "gnorm": "0.225", "loss_scale": "2", "train_wall": "190", "gb_free": "39.7", "wall": "692891"}
[2024-10-12 18:41:55,622][train_inner][INFO] - {"epoch": 769, "update": 768.568, "loss": "0.735", "ntokens": "263959", "nsentences": "1761.5", "wps": "243112", "ups": "0.92", "wpb": "263959", "bsz": "1761.5", "num_updates": "368000", "lr": "4.34783e-05", "gnorm": "0.215", "loss_scale": "2", "train_wall": "211", "gb_free": "39.7", "wall": "693108"}
[2024-10-12 18:45:34,777][train_inner][INFO] - {"epoch": 769, "update": 768.985, "loss": "0.732", "ntokens": "263942", "nsentences": "1761.68", "wps": "240911", "ups": "0.91", "wpb": "263942", "bsz": "1761.7", "num_updates": "368200", "lr": "4.32065e-05", "gnorm": "0.216", "loss_scale": "2", "train_wall": "180", "gb_free": "40", "wall": "693327"}
[2024-10-12 18:45:51,532][fairseq_cli.train][INFO] - end of epoch 769 (average epoch stats below)
[2024-10-12 18:45:51,534][train][INFO] - {"epoch": 769, "train_loss": "0.733", "train_ntokens": "263476", "train_nsentences": "1753.71", "train_wps": "140830", "train_ups": "0.53", "train_wpb": "263476", "train_bsz": "1753.7", "train_num_updates": "368207", "train_lr": "4.3197e-05", "train_gnorm": "0.216", "train_loss_scale": "2", "train_train_wall": "505", "train_gb_free": "39.8", "train_wall": "693344"}
[2024-10-12 18:45:51,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:45:51,843][fairseq.trainer][INFO] - begin training epoch 770
[2024-10-12 18:45:51,844][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:55:28,760][train_inner][INFO] - {"epoch": 770, "update": 769.403, "loss": "0.731", "ntokens": "263240", "nsentences": "1720.72", "wps": "88642.4", "ups": "0.34", "wpb": "263240", "bsz": "1720.7", "num_updates": "368400", "lr": "4.29348e-05", "gnorm": "0.217", "loss_scale": "2", "train_wall": "272", "gb_free": "39.6", "wall": "693921"}
[2024-10-12 18:59:13,498][train_inner][INFO] - {"epoch": 770, "update": 769.82, "loss": "0.733", "ntokens": "264042", "nsentences": "1742.24", "wps": "234993", "ups": "0.89", "wpb": "264042", "bsz": "1742.2", "num_updates": "368600", "lr": "4.2663e-05", "gnorm": "0.213", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "694146"}
[2024-10-12 19:01:16,161][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 770 @ 368686 updates
[2024-10-12 19:01:16,163][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 19:01:21,654][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 19:01:21,809][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 770 @ 368686 updates, score None) (writing took 5.647159504704177 seconds)
[2024-10-12 19:01:21,809][fairseq_cli.train][INFO] - end of epoch 770 (average epoch stats below)
[2024-10-12 19:01:21,814][train][INFO] - {"epoch": 770, "train_loss": "0.732", "train_ntokens": "263561", "train_nsentences": "1753.71", "train_wps": "135710", "train_ups": "0.51", "train_wpb": "263561", "train_bsz": "1753.7", "train_num_updates": "368686", "train_lr": "4.25462e-05", "train_gnorm": "0.218", "train_loss_scale": "2", "train_train_wall": "595", "train_gb_free": "39.6", "train_wall": "694274"}
[2024-10-12 19:01:21,887][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:01:21,894][fairseq.trainer][INFO] - begin training epoch 771
[2024-10-12 19:01:21,895][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:08:44,594][train_inner][INFO] - {"epoch": 771, "update": 770.238, "loss": "0.732", "ntokens": "262413", "nsentences": "1781.19", "wps": "91901.5", "ups": "0.35", "wpb": "262413", "bsz": "1781.2", "num_updates": "368800", "lr": "4.23913e-05", "gnorm": "0.228", "loss_scale": "2", "train_wall": "249", "gb_free": "40", "wall": "694717"}
[2024-10-12 19:12:04,672][train_inner][INFO] - {"epoch": 771, "update": 770.656, "loss": "0.732", "ntokens": "263748", "nsentences": "1754.47", "wps": "263678", "ups": "1", "wpb": "263748", "bsz": "1754.5", "num_updates": "369000", "lr": "4.21196e-05", "gnorm": "0.222", "loss_scale": "2", "train_wall": "195", "gb_free": "39.6", "wall": "694917"}
[2024-10-12 19:15:54,950][fairseq_cli.train][INFO] - end of epoch 771 (average epoch stats below)
[2024-10-12 19:15:54,964][train][INFO] - {"epoch": 771, "train_loss": "0.733", "train_ntokens": "263362", "train_nsentences": "1753.71", "train_wps": "144480", "train_ups": "0.55", "train_wpb": "263362", "train_bsz": "1753.7", "train_num_updates": "369165", "train_lr": "4.18954e-05", "train_gnorm": "0.22", "train_loss_scale": "2", "train_train_wall": "551", "train_gb_free": "39.8", "train_wall": "695147"}
[2024-10-12 19:15:55,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:15:55,036][fairseq.trainer][INFO] - begin training epoch 772
[2024-10-12 19:15:55,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:22:03,817][train_inner][INFO] - {"epoch": 772, "update": 771.073, "loss": "0.733", "ntokens": "262733", "nsentences": "1769.7", "wps": "87705.7", "ups": "0.33", "wpb": "262733", "bsz": "1769.7", "num_updates": "369200", "lr": "4.18478e-05", "gnorm": "0.216", "loss_scale": "2", "train_wall": "290", "gb_free": "39.6", "wall": "695516"}
[2024-10-12 19:25:51,723][train_inner][INFO] - {"epoch": 772, "update": 771.491, "loss": "0.731", "ntokens": "264206", "nsentences": "1720.28", "wps": "231922", "ups": "0.88", "wpb": "264206", "bsz": "1720.3", "num_updates": "369400", "lr": "4.15761e-05", "gnorm": "0.23", "loss_scale": "4", "train_wall": "223", "gb_free": "39.2", "wall": "695744"}
[2024-10-12 19:29:57,340][train_inner][INFO] - {"epoch": 772, "update": 771.908, "loss": "0.734", "ntokens": "263629", "nsentences": "1779.68", "wps": "214720", "ups": "0.81", "wpb": "263629", "bsz": "1779.7", "num_updates": "369600", "lr": "4.13043e-05", "gnorm": "0.216", "loss_scale": "4", "train_wall": "240", "gb_free": "39.3", "wall": "695990"}
[2024-10-12 19:31:08,289][fairseq_cli.train][INFO] - end of epoch 772 (average epoch stats below)
[2024-10-12 19:31:08,292][train][INFO] - {"epoch": 772, "train_loss": "0.732", "train_ntokens": "263418", "train_nsentences": "1753.71", "train_wps": "138153", "train_ups": "0.52", "train_wpb": "263418", "train_bsz": "1753.7", "train_num_updates": "369644", "train_lr": "4.12446e-05", "train_gnorm": "0.225", "train_loss_scale": "4", "train_train_wall": "595", "train_gb_free": "39.2", "train_wall": "696060"}
[2024-10-12 19:31:08,405][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:31:08,420][fairseq.trainer][INFO] - begin training epoch 773
[2024-10-12 19:31:08,421][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:39:53,259][train_inner][INFO] - {"epoch": 773, "update": 772.326, "loss": "0.729", "ntokens": "262896", "nsentences": "1749.6", "wps": "88235.2", "ups": "0.34", "wpb": "262896", "bsz": "1749.6", "num_updates": "369800", "lr": "4.10326e-05", "gnorm": "0.22", "loss_scale": "4", "train_wall": "269", "gb_free": "39.8", "wall": "696585"}
[2024-10-12 19:44:03,321][train_inner][INFO] - {"epoch": 773, "update": 772.743, "loss": "0.733", "ntokens": "264168", "nsentences": "1756.01", "wps": "211300", "ups": "0.8", "wpb": "264168", "bsz": "1756", "num_updates": "370000", "lr": "4.07609e-05", "gnorm": "0.224", "loss_scale": "4", "train_wall": "245", "gb_free": "39.3", "wall": "696835"}
[2024-10-12 19:46:55,342][fairseq_cli.train][INFO] - end of epoch 773 (average epoch stats below)
[2024-10-12 19:46:55,347][train][INFO] - {"epoch": 773, "train_loss": "0.732", "train_ntokens": "263481", "train_nsentences": "1753.71", "train_wps": "133264", "train_ups": "0.51", "train_wpb": "263481", "train_bsz": "1753.7", "train_num_updates": "370123", "train_lr": "4.05937e-05", "train_gnorm": "0.218", "train_loss_scale": "4", "train_train_wall": "612", "train_gb_free": "39.7", "train_wall": "697008"}
[2024-10-12 19:46:55,444][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:46:55,453][fairseq.trainer][INFO] - begin training epoch 774
[2024-10-12 19:46:55,453][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:53:41,694][train_inner][INFO] - {"epoch": 774, "update": 773.161, "loss": "0.734", "ntokens": "262397", "nsentences": "1753.36", "wps": "90740.1", "ups": "0.35", "wpb": "262397", "bsz": "1753.4", "num_updates": "370200", "lr": "4.04891e-05", "gnorm": "0.217", "loss_scale": "4", "train_wall": "263", "gb_free": "40.1", "wall": "697414"}
[2024-10-12 19:57:48,537][train_inner][INFO] - {"epoch": 774, "update": 773.578, "loss": "0.732", "ntokens": "263746", "nsentences": "1796.81", "wps": "213706", "ups": "0.81", "wpb": "263746", "bsz": "1796.8", "num_updates": "370400", "lr": "4.02174e-05", "gnorm": "0.223", "loss_scale": "4", "train_wall": "242", "gb_free": "39.6", "wall": "697661"}
[2024-10-12 20:02:11,219][train_inner][INFO] - {"epoch": 774, "update": 773.996, "loss": "0.73", "ntokens": "264317", "nsentences": "1718.46", "wps": "201262", "ups": "0.76", "wpb": "264317", "bsz": "1718.5", "num_updates": "370600", "lr": "3.99457e-05", "gnorm": "0.214", "loss_scale": "4", "train_wall": "257", "gb_free": "38.9", "wall": "697923"}
[2024-10-12 20:02:12,839][fairseq_cli.train][INFO] - end of epoch 774 (average epoch stats below)
[2024-10-12 20:02:12,869][train][INFO] - {"epoch": 774, "train_loss": "0.731", "train_ntokens": "263473", "train_nsentences": "1753.71", "train_wps": "137556", "train_ups": "0.52", "train_wpb": "263473", "train_bsz": "1753.7", "train_num_updates": "370602", "train_lr": "3.99429e-05", "train_gnorm": "0.22", "train_loss_scale": "4", "train_train_wall": "594", "train_gb_free": "40.2", "train_wall": "697925"}
[2024-10-12 20:02:13,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 20:02:13,067][fairseq.trainer][INFO] - begin training epoch 775
[2024-10-12 20:02:13,068][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:11:19,954][train_inner][INFO] - {"epoch": 775, "update": 774.413, "loss": "0.731", "ntokens": "262753", "nsentences": "1750.24", "wps": "95773.6", "ups": "0.36", "wpb": "262753", "bsz": "1750.2", "num_updates": "370800", "lr": "3.96739e-05", "gnorm": "0.224", "loss_scale": "4", "train_wall": "232", "gb_free": "39.3", "wall": "698472"}
[2024-10-12 20:14:35,335][train_inner][INFO] - {"epoch": 775, "update": 774.831, "loss": "0.729", "ntokens": "264315", "nsentences": "1723.79", "wps": "270595", "ups": "1.02", "wpb": "264315", "bsz": "1723.8", "num_updates": "371000", "lr": "3.94022e-05", "gnorm": "0.215", "loss_scale": "4", "train_wall": "190", "gb_free": "39.4", "wall": "698668"}
[2024-10-12 20:16:30,540][fairseq_cli.train][INFO] - end of epoch 775 (average epoch stats below)
[2024-10-12 20:16:30,558][train][INFO] - {"epoch": 775, "train_loss": "0.732", "train_ntokens": "263534", "train_nsentences": "1753.71", "train_wps": "147180", "train_ups": "0.56", "train_wpb": "263534", "train_bsz": "1753.7", "train_num_updates": "371081", "train_lr": "3.92921e-05", "train_gnorm": "0.22", "train_loss_scale": "4", "train_train_wall": "531", "train_gb_free": "40", "train_wall": "698783"}
[2024-10-12 20:16:30,628][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 20:16:30,649][fairseq.trainer][INFO] - begin training epoch 776
[2024-10-12 20:16:30,650][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:24:09,401][train_inner][INFO] - {"epoch": 776, "update": 775.248, "loss": "0.732", "ntokens": "262846", "nsentences": "1763.52", "wps": "91575.2", "ups": "0.35", "wpb": "262846", "bsz": "1763.5", "num_updates": "371200", "lr": "3.91304e-05", "gnorm": "0.22", "loss_scale": "4", "train_wall": "268", "gb_free": "40.5", "wall": "699242"}
[2024-10-12 20:24:59,295][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 20:27:49,013][train_inner][INFO] - {"epoch": 776, "update": 775.668, "loss": "0.732", "ntokens": "263600", "nsentences": "1791.66", "wps": "240094", "ups": "0.91", "wpb": "263600", "bsz": "1791.7", "num_updates": "371400", "lr": "3.88587e-05", "gnorm": "0.221", "loss_scale": "2", "train_wall": "214", "gb_free": "40", "wall": "699461"}
[2024-10-12 20:30:48,119][fairseq_cli.train][INFO] - end of epoch 776 (average epoch stats below)
[2024-10-12 20:30:48,134][train][INFO] - {"epoch": 776, "train_loss": "0.731", "train_ntokens": "263436", "train_nsentences": "1751", "train_wps": "146837", "train_ups": "0.56", "train_wpb": "263436", "train_bsz": "1751", "train_num_updates": "371559", "train_lr": "3.86427e-05", "train_gnorm": "0.218", "train_loss_scale": "2", "train_train_wall": "547", "train_gb_free": "40.6", "train_wall": "699640"}
[2024-10-12 20:30:48,286][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 20:30:48,308][fairseq.trainer][INFO] - begin training epoch 777
[2024-10-12 20:30:48,309][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:37:02,686][train_inner][INFO] - {"epoch": 777, "update": 776.086, "loss": "0.732", "ntokens": "262869", "nsentences": "1716.77", "wps": "94958.1", "ups": "0.36", "wpb": "262869", "bsz": "1716.8", "num_updates": "371600", "lr": "3.8587e-05", "gnorm": "0.217", "loss_scale": "2", "train_wall": "232", "gb_free": "40.2", "wall": "700015"}
[2024-10-12 20:40:24,765][train_inner][INFO] - {"epoch": 777, "update": 776.503, "loss": "0.732", "ntokens": "264075", "nsentences": "1753.29", "wps": "261374", "ups": "0.99", "wpb": "264075", "bsz": "1753.3", "num_updates": "371800", "lr": "3.83152e-05", "gnorm": "0.216", "loss_scale": "2", "train_wall": "197", "gb_free": "39.2", "wall": "700217"}
[2024-10-12 20:44:45,178][train_inner][INFO] - {"epoch": 777, "update": 776.921, "loss": "0.731", "ntokens": "263975", "nsentences": "1770.2", "wps": "202771", "ups": "0.77", "wpb": "263975", "bsz": "1770.2", "num_updates": "372000", "lr": "3.80435e-05", "gnorm": "0.218", "loss_scale": "2", "train_wall": "255", "gb_free": "39.6", "wall": "700477"}
[2024-10-12 20:45:34,410][fairseq_cli.train][INFO] - end of epoch 777 (average epoch stats below)
[2024-10-12 20:45:34,419][train][INFO] - {"epoch": 777, "train_loss": "0.732", "train_ntokens": "263529", "train_nsentences": "1753.71", "train_wps": "142430", "train_ups": "0.54", "train_wpb": "263529", "train_bsz": "1753.7", "train_num_updates": "372038", "train_lr": "3.79918e-05", "train_gnorm": "0.217", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.2", "train_wall": "700527"}
[2024-10-12 20:45:34,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 20:45:34,549][fairseq.trainer][INFO] - begin training epoch 778
[2024-10-12 20:45:34,550][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:53:53,762][train_inner][INFO] - {"epoch": 778, "update": 777.338, "loss": "0.73", "ntokens": "262866", "nsentences": "1738.89", "wps": "95836.8", "ups": "0.36", "wpb": "262866", "bsz": "1738.9", "num_updates": "372200", "lr": "3.77717e-05", "gnorm": "0.22", "loss_scale": "2", "train_wall": "218", "gb_free": "39.7", "wall": "701026"}
[2024-10-12 20:57:54,802][train_inner][INFO] - {"epoch": 778, "update": 777.756, "loss": "0.732", "ntokens": "264049", "nsentences": "1782.42", "wps": "219115", "ups": "0.83", "wpb": "264049", "bsz": "1782.4", "num_updates": "372400", "lr": "3.75e-05", "gnorm": "0.213", "loss_scale": "2", "train_wall": "235", "gb_free": "40.5", "wall": "701267"}
[2024-10-12 21:00:35,622][fairseq_cli.train][INFO] - end of epoch 778 (average epoch stats below)
[2024-10-12 21:00:35,662][train][INFO] - {"epoch": 778, "train_loss": "0.731", "train_ntokens": "263597", "train_nsentences": "1753.71", "train_wps": "140103", "train_ups": "0.53", "train_wpb": "263597", "train_bsz": "1753.7", "train_num_updates": "372517", "train_lr": "3.7341e-05", "train_gnorm": "0.217", "train_loss_scale": "2", "train_train_wall": "558", "train_gb_free": "40.3", "train_wall": "701428"}
[2024-10-12 21:00:35,857][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 21:00:35,878][fairseq.trainer][INFO] - begin training epoch 779
[2024-10-12 21:00:35,879][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 21:07:35,458][train_inner][INFO] - {"epoch": 779, "update": 778.173, "loss": "0.732", "ntokens": "262688", "nsentences": "1761.35", "wps": "90482.2", "ups": "0.34", "wpb": "262688", "bsz": "1761.4", "num_updates": "372600", "lr": "3.72283e-05", "gnorm": "0.216", "loss_scale": "2", "train_wall": "249", "gb_free": "40", "wall": "701848"}
[2024-10-12 21:11:28,273][train_inner][INFO] - {"epoch": 779, "update": 778.591, "loss": "0.73", "ntokens": "264013", "nsentences": "1759.34", "wps": "226820", "ups": "0.86", "wpb": "264013", "bsz": "1759.3", "num_updates": "372800", "lr": "3.69565e-05", "gnorm": "0.213", "loss_scale": "2", "train_wall": "221", "gb_free": "39.6", "wall": "702080"}
[2024-10-12 21:15:50,044][fairseq_cli.train][INFO] - end of epoch 779 (average epoch stats below)
[2024-10-12 21:15:50,052][train][INFO] - {"epoch": 779, "train_loss": "0.732", "train_ntokens": "263540", "train_nsentences": "1753.71", "train_wps": "138061", "train_ups": "0.52", "train_wpb": "263540", "train_bsz": "1753.7", "train_num_updates": "372996", "train_lr": "3.66902e-05", "train_gnorm": "0.213", "train_loss_scale": "2", "train_train_wall": "574", "train_gb_free": "40", "train_wall": "702342"}
[2024-10-12 21:15:50,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 21:15:50,205][fairseq.trainer][INFO] - begin training epoch 780
[2024-10-12 21:15:50,205][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 21:21:17,441][train_inner][INFO] - {"epoch": 780, "update": 779.008, "loss": "0.731", "ntokens": "263199", "nsentences": "1708.57", "wps": "89348", "ups": "0.34", "wpb": "263199", "bsz": "1708.6", "num_updates": "373000", "lr": "3.66848e-05", "gnorm": "0.213", "loss_scale": "2", "train_wall": "283", "gb_free": "39.6", "wall": "702670"}
[2024-10-12 21:24:47,384][train_inner][INFO] - {"epoch": 780, "update": 779.426, "loss": "0.73", "ntokens": "264398", "nsentences": "1739.97", "wps": "251887", "ups": "0.95", "wpb": "264398", "bsz": "1740", "num_updates": "373200", "lr": "3.6413e-05", "gnorm": "0.207", "loss_scale": "2", "train_wall": "205", "gb_free": "39.8", "wall": "702880"}
[2024-10-12 21:28:53,442][train_inner][INFO] - {"epoch": 780, "update": 779.843, "loss": "0.729", "ntokens": "263999", "nsentences": "1759.28", "wps": "214594", "ups": "0.81", "wpb": "263999", "bsz": "1759.3", "num_updates": "373400", "lr": "3.61413e-05", "gnorm": "0.205", "loss_scale": "4", "train_wall": "241", "gb_free": "40", "wall": "703126"}
[2024-10-12 21:30:31,340][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 780 @ 373475 updates
[2024-10-12 21:30:31,346][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 21:30:38,958][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 21:30:39,144][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 780 @ 373475 updates, score None) (writing took 7.803738636896014 seconds)
[2024-10-12 21:30:39,145][fairseq_cli.train][INFO] - end of epoch 780 (average epoch stats below)
[2024-10-12 21:30:39,147][train][INFO] - {"epoch": 780, "train_loss": "0.73", "train_ntokens": "263619", "train_nsentences": "1753.71", "train_wps": "142030", "train_ups": "0.54", "train_wpb": "263619", "train_bsz": "1753.7", "train_num_updates": "373475", "train_lr": "3.60394e-05", "train_gnorm": "0.207", "train_loss_scale": "4", "train_train_wall": "567", "train_gb_free": "39.6", "train_wall": "703231"}
[2024-10-12 21:30:39,216][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 21:30:39,239][fairseq.trainer][INFO] - begin training epoch 781
[2024-10-12 21:30:39,239][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 21:38:24,711][train_inner][INFO] - {"epoch": 781, "update": 780.261, "loss": "0.734", "ntokens": "262087", "nsentences": "1812.54", "wps": "91759.4", "ups": "0.35", "wpb": "262087", "bsz": "1812.5", "num_updates": "373600", "lr": "3.58696e-05", "gnorm": "0.211", "loss_scale": "4", "train_wall": "213", "gb_free": "39.7", "wall": "703697"}
[2024-10-12 21:41:55,628][train_inner][INFO] - {"epoch": 781, "update": 780.678, "loss": "0.729", "ntokens": "264854", "nsentences": "1687.21", "wps": "251173", "ups": "0.95", "wpb": "264854", "bsz": "1687.2", "num_updates": "373800", "lr": "3.55978e-05", "gnorm": "0.213", "loss_scale": "4", "train_wall": "206", "gb_free": "39.2", "wall": "703908"}
[2024-10-12 21:45:22,212][fairseq_cli.train][INFO] - end of epoch 781 (average epoch stats below)
[2024-10-12 21:45:22,229][train][INFO] - {"epoch": 781, "train_loss": "0.731", "train_ntokens": "263567", "train_nsentences": "1753.71", "train_wps": "142967", "train_ups": "0.54", "train_wpb": "263566", "train_bsz": "1753.7", "train_num_updates": "373954", "train_lr": "3.53886e-05", "train_gnorm": "0.212", "train_loss_scale": "4", "train_train_wall": "525", "train_gb_free": "39.6", "train_wall": "704114"}
[2024-10-12 21:45:22,312][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 21:45:22,331][fairseq.trainer][INFO] - begin training epoch 782
[2024-10-12 21:45:22,331][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 21:51:46,749][train_inner][INFO] - {"epoch": 782, "update": 781.096, "loss": "0.733", "ntokens": "262515", "nsentences": "1793.42", "wps": "88824.1", "ups": "0.34", "wpb": "262515", "bsz": "1793.4", "num_updates": "374000", "lr": "3.53261e-05", "gnorm": "0.214", "loss_scale": "4", "train_wall": "273", "gb_free": "39.3", "wall": "704499"}
[2024-10-12 21:55:52,626][train_inner][INFO] - {"epoch": 782, "update": 781.514, "loss": "0.731", "ntokens": "263464", "nsentences": "1802.42", "wps": "214327", "ups": "0.81", "wpb": "263464", "bsz": "1802.4", "num_updates": "374200", "lr": "3.50543e-05", "gnorm": "0.214", "loss_scale": "4", "train_wall": "240", "gb_free": "40", "wall": "704745"}
[2024-10-12 21:59:54,602][train_inner][INFO] - {"epoch": 782, "update": 781.931, "loss": "0.729", "ntokens": "264297", "nsentences": "1717.8", "wps": "218485", "ups": "0.83", "wpb": "264297", "bsz": "1717.8", "num_updates": "374400", "lr": "3.47826e-05", "gnorm": "0.208", "loss_scale": "4", "train_wall": "237", "gb_free": "40", "wall": "704987"}
[2024-10-12 22:00:49,759][fairseq_cli.train][INFO] - end of epoch 782 (average epoch stats below)
[2024-10-12 22:00:49,778][train][INFO] - {"epoch": 782, "train_loss": "0.73", "train_ntokens": "263437", "train_nsentences": "1753.71", "train_wps": "136046", "train_ups": "0.52", "train_wpb": "263437", "train_bsz": "1753.7", "train_num_updates": "374433", "train_lr": "3.47378e-05", "train_gnorm": "0.212", "train_loss_scale": "4", "train_train_wall": "602", "train_gb_free": "40", "train_wall": "705042"}
[2024-10-12 22:00:49,924][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 22:00:49,965][fairseq.trainer][INFO] - begin training epoch 783
[2024-10-12 22:00:49,966][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 22:09:27,249][train_inner][INFO] - {"epoch": 783, "update": 782.349, "loss": "0.729", "ntokens": "262736", "nsentences": "1742.72", "wps": "91764", "ups": "0.35", "wpb": "262736", "bsz": "1742.7", "num_updates": "374600", "lr": "3.45109e-05", "gnorm": "0.216", "loss_scale": "4", "train_wall": "246", "gb_free": "39.8", "wall": "705559"}
[2024-10-12 22:13:18,424][train_inner][INFO] - {"epoch": 783, "update": 782.766, "loss": "0.732", "ntokens": "263661", "nsentences": "1772.22", "wps": "228119", "ups": "0.87", "wpb": "263661", "bsz": "1772.2", "num_updates": "374800", "lr": "3.42391e-05", "gnorm": "0.206", "loss_scale": "4", "train_wall": "226", "gb_free": "40", "wall": "705791"}
[2024-10-12 22:15:14,978][fairseq_cli.train][INFO] - end of epoch 783 (average epoch stats below)
[2024-10-12 22:15:14,994][train][INFO] - {"epoch": 783, "train_loss": "0.73", "train_ntokens": "263417", "train_nsentences": "1753.71", "train_wps": "145834", "train_ups": "0.55", "train_wpb": "263417", "train_bsz": "1753.7", "train_num_updates": "374912", "train_lr": "3.4087e-05", "train_gnorm": "0.21", "train_loss_scale": "4", "train_train_wall": "532", "train_gb_free": "39.6", "train_wall": "705907"}
[2024-10-12 22:15:15,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 22:15:15,151][fairseq.trainer][INFO] - begin training epoch 784
[2024-10-12 22:15:15,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 22:22:46,646][train_inner][INFO] - {"epoch": 784, "update": 783.184, "loss": "0.73", "ntokens": "263340", "nsentences": "1726.42", "wps": "92691.8", "ups": "0.35", "wpb": "263340", "bsz": "1726.4", "num_updates": "375000", "lr": "3.39674e-05", "gnorm": "0.211", "loss_scale": "4", "train_wall": "209", "gb_free": "40.3", "wall": "706359"}
[2024-10-12 22:26:42,735][train_inner][INFO] - {"epoch": 784, "update": 783.601, "loss": "0.732", "ntokens": "263638", "nsentences": "1775.57", "wps": "223419", "ups": "0.85", "wpb": "263638", "bsz": "1775.6", "num_updates": "375200", "lr": "3.36957e-05", "gnorm": "0.217", "loss_scale": "4", "train_wall": "231", "gb_free": "39.3", "wall": "706595"}
[2024-10-12 22:29:49,808][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-12 22:30:26,090][fairseq_cli.train][INFO] - end of epoch 784 (average epoch stats below)
[2024-10-12 22:30:26,105][train][INFO] - {"epoch": 784, "train_loss": "0.731", "train_ntokens": "263532", "train_nsentences": "1754.23", "train_wps": "138263", "train_ups": "0.52", "train_wpb": "263532", "train_bsz": "1754.2", "train_num_updates": "375390", "train_lr": "3.34375e-05", "train_gnorm": "0.213", "train_loss_scale": "4", "train_train_wall": "545", "train_gb_free": "39.7", "train_wall": "706818"}
[2024-10-12 22:30:26,277][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 22:30:26,290][fairseq.trainer][INFO] - begin training epoch 785
[2024-10-12 22:30:26,291][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 22:36:31,780][train_inner][INFO] - {"epoch": 785, "update": 784.021, "loss": "0.729", "ntokens": "263059", "nsentences": "1733.18", "wps": "89319.7", "ups": "0.34", "wpb": "263059", "bsz": "1733.2", "num_updates": "375400", "lr": "3.34239e-05", "gnorm": "0.21", "loss_scale": "4", "train_wall": "258", "gb_free": "39.1", "wall": "707184"}
[2024-10-12 22:40:02,437][train_inner][INFO] - {"epoch": 785, "update": 784.438, "loss": "0.728", "ntokens": "264540", "nsentences": "1706.83", "wps": "251181", "ups": "0.95", "wpb": "264540", "bsz": "1706.8", "num_updates": "375600", "lr": "3.31522e-05", "gnorm": "0.213", "loss_scale": "4", "train_wall": "205", "gb_free": "39.6", "wall": "707395"}
[2024-10-12 22:41:47,191][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-12 22:44:16,117][train_inner][INFO] - {"epoch": 785, "update": 784.858, "loss": "0.732", "ntokens": "263939", "nsentences": "1775.78", "wps": "208103", "ups": "0.79", "wpb": "263939", "bsz": "1775.8", "num_updates": "375800", "lr": "3.28804e-05", "gnorm": "0.207", "loss_scale": "2", "train_wall": "248", "gb_free": "39.2", "wall": "707648"}
[2024-10-12 22:45:53,709][fairseq_cli.train][INFO] - end of epoch 785 (average epoch stats below)
[2024-10-12 22:45:53,738][train][INFO] - {"epoch": 785, "train_loss": "0.73", "train_ntokens": "263600", "train_nsentences": "1753.01", "train_wps": "135836", "train_ups": "0.52", "train_wpb": "263600", "train_bsz": "1753", "train_num_updates": "375868", "train_lr": "3.2788e-05", "train_gnorm": "0.211", "train_loss_scale": "2", "train_train_wall": "588", "train_gb_free": "39.8", "train_wall": "707746"}
[2024-10-12 22:45:53,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 22:45:53,842][fairseq.trainer][INFO] - begin training epoch 786
[2024-10-12 22:45:53,843][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 22:53:58,735][train_inner][INFO] - {"epoch": 786, "update": 785.276, "loss": "0.73", "ntokens": "262764", "nsentences": "1755.84", "wps": "90206.4", "ups": "0.34", "wpb": "262764", "bsz": "1755.8", "num_updates": "376000", "lr": "3.26087e-05", "gnorm": "0.212", "loss_scale": "2", "train_wall": "248", "gb_free": "40", "wall": "708231"}
[2024-10-12 22:57:53,581][train_inner][INFO] - {"epoch": 786, "update": 785.693, "loss": "0.728", "ntokens": "264098", "nsentences": "1748.1", "wps": "224924", "ups": "0.85", "wpb": "264098", "bsz": "1748.1", "num_updates": "376200", "lr": "3.2337e-05", "gnorm": "0.205", "loss_scale": "2", "train_wall": "229", "gb_free": "39.6", "wall": "708466"}
[2024-10-12 23:00:36,269][fairseq_cli.train][INFO] - end of epoch 786 (average epoch stats below)
[2024-10-12 23:00:36,273][train][INFO] - {"epoch": 786, "train_loss": "0.73", "train_ntokens": "263533", "train_nsentences": "1753.71", "train_wps": "143035", "train_ups": "0.54", "train_wpb": "263533", "train_bsz": "1753.7", "train_num_updates": "376347", "train_lr": "3.21372e-05", "train_gnorm": "0.211", "train_loss_scale": "2", "train_train_wall": "541", "train_gb_free": "39.3", "train_wall": "708628"}
[2024-10-12 23:00:36,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 23:00:36,400][fairseq.trainer][INFO] - begin training epoch 787
[2024-10-12 23:00:36,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 23:07:26,466][train_inner][INFO] - {"epoch": 787, "update": 786.111, "loss": "0.731", "ntokens": "262558", "nsentences": "1778.96", "wps": "91664.6", "ups": "0.35", "wpb": "262558", "bsz": "1779", "num_updates": "376400", "lr": "3.20652e-05", "gnorm": "0.219", "loss_scale": "2", "train_wall": "238", "gb_free": "39.2", "wall": "709039"}
[2024-10-12 23:10:57,990][train_inner][INFO] - {"epoch": 787, "update": 786.528, "loss": "0.73", "ntokens": "264382", "nsentences": "1730.76", "wps": "249997", "ups": "0.95", "wpb": "264382", "bsz": "1730.8", "num_updates": "376600", "lr": "3.17935e-05", "gnorm": "0.208", "loss_scale": "2", "train_wall": "206", "gb_free": "39.3", "wall": "709250"}
[2024-10-12 23:14:42,985][train_inner][INFO] - {"epoch": 787, "update": 786.946, "loss": "0.732", "ntokens": "263878", "nsentences": "1771.93", "wps": "234586", "ups": "0.89", "wpb": "263878", "bsz": "1771.9", "num_updates": "376800", "lr": "3.15217e-05", "gnorm": "0.21", "loss_scale": "2", "train_wall": "219", "gb_free": "39.6", "wall": "709475"}
[2024-10-12 23:15:24,948][fairseq_cli.train][INFO] - end of epoch 787 (average epoch stats below)
[2024-10-12 23:15:24,978][train][INFO] - {"epoch": 787, "train_loss": "0.731", "train_ntokens": "263596", "train_nsentences": "1753.71", "train_wps": "142081", "train_ups": "0.54", "train_wpb": "263596", "train_bsz": "1753.7", "train_num_updates": "376826", "train_lr": "3.14864e-05", "train_gnorm": "0.21", "train_loss_scale": "2", "train_train_wall": "544", "train_gb_free": "39.6", "train_wall": "709517"}
[2024-10-12 23:15:25,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 23:15:25,177][fairseq.trainer][INFO] - begin training epoch 788
[2024-10-12 23:15:25,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 23:24:13,687][train_inner][INFO] - {"epoch": 788, "update": 787.363, "loss": "0.732", "ntokens": "262636", "nsentences": "1781.92", "wps": "92041.1", "ups": "0.35", "wpb": "262636", "bsz": "1781.9", "num_updates": "377000", "lr": "3.125e-05", "gnorm": "0.212", "loss_scale": "2", "train_wall": "247", "gb_free": "39.7", "wall": "710046"}
[2024-10-12 23:28:13,714][train_inner][INFO] - {"epoch": 788, "update": 787.781, "loss": "0.729", "ntokens": "264178", "nsentences": "1747.2", "wps": "220135", "ups": "0.83", "wpb": "264178", "bsz": "1747.2", "num_updates": "377200", "lr": "3.09783e-05", "gnorm": "0.207", "loss_scale": "2", "train_wall": "235", "gb_free": "40.5", "wall": "710286"}
[2024-10-12 23:30:16,393][fairseq_cli.train][INFO] - end of epoch 788 (average epoch stats below)
[2024-10-12 23:30:16,406][train][INFO] - {"epoch": 788, "train_loss": "0.73", "train_ntokens": "263586", "train_nsentences": "1753.71", "train_wps": "141639", "train_ups": "0.54", "train_wpb": "263586", "train_bsz": "1753.7", "train_num_updates": "377305", "train_lr": "3.08356e-05", "train_gnorm": "0.208", "train_loss_scale": "2", "train_train_wall": "563", "train_gb_free": "39.8", "train_wall": "710409"}
[2024-10-12 23:30:16,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 23:30:16,509][fairseq.trainer][INFO] - begin training epoch 789
[2024-10-12 23:30:16,510][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 23:37:36,401][train_inner][INFO] - {"epoch": 789, "update": 788.198, "loss": "0.73", "ntokens": "262838", "nsentences": "1749.73", "wps": "93426.6", "ups": "0.36", "wpb": "262838", "bsz": "1749.7", "num_updates": "377400", "lr": "3.07065e-05", "gnorm": "0.21", "loss_scale": "2", "train_wall": "232", "gb_free": "39.3", "wall": "710849"}
[2024-10-12 23:41:37,103][train_inner][INFO] - {"epoch": 789, "update": 788.616, "loss": "0.732", "ntokens": "263882", "nsentences": "1797.46", "wps": "219299", "ups": "0.83", "wpb": "263882", "bsz": "1797.5", "num_updates": "377600", "lr": "3.04348e-05", "gnorm": "0.209", "loss_scale": "2", "train_wall": "235", "gb_free": "39.2", "wall": "711089"}
[2024-10-12 23:45:14,024][fairseq_cli.train][INFO] - end of epoch 789 (average epoch stats below)
[2024-10-12 23:45:14,058][train][INFO] - {"epoch": 789, "train_loss": "0.73", "train_ntokens": "263593", "train_nsentences": "1753.71", "train_wps": "140661", "train_ups": "0.53", "train_wpb": "263593", "train_bsz": "1753.7", "train_num_updates": "377784", "train_lr": "3.01848e-05", "train_gnorm": "0.209", "train_loss_scale": "4", "train_train_wall": "559", "train_gb_free": "39.3", "train_wall": "711306"}
[2024-10-12 23:45:14,198][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 23:45:14,243][fairseq.trainer][INFO] - begin training epoch 790
[2024-10-12 23:45:14,244][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 23:51:23,366][train_inner][INFO] - {"epoch": 790, "update": 789.033, "loss": "0.726", "ntokens": "263405", "nsentences": "1688.07", "wps": "89866.4", "ups": "0.34", "wpb": "263405", "bsz": "1688.1", "num_updates": "377800", "lr": "3.0163e-05", "gnorm": "0.207", "loss_scale": "4", "train_wall": "241", "gb_free": "39.6", "wall": "711676"}
[2024-10-12 23:54:33,066][train_inner][INFO] - {"epoch": 790, "update": 789.451, "loss": "0.729", "ntokens": "263929", "nsentences": "1756.44", "wps": "278299", "ups": "1.05", "wpb": "263929", "bsz": "1756.4", "num_updates": "378000", "lr": "2.98913e-05", "gnorm": "0.204", "loss_scale": "4", "train_wall": "178", "gb_free": "39.3", "wall": "711865"}
[2024-10-12 23:58:23,950][train_inner][INFO] - {"epoch": 790, "update": 789.868, "loss": "0.729", "ntokens": "264132", "nsentences": "1756.97", "wps": "228844", "ups": "0.87", "wpb": "264132", "bsz": "1757", "num_updates": "378200", "lr": "2.96196e-05", "gnorm": "0.208", "loss_scale": "4", "train_wall": "225", "gb_free": "39.6", "wall": "712096"}
[2024-10-12 23:59:36,255][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 790 @ 378263 updates
[2024-10-12 23:59:36,256][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 23:59:50,472][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-12 23:59:50,652][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 790 @ 378263 updates, score None) (writing took 14.397276498377323 seconds)
[2024-10-12 23:59:50,654][fairseq_cli.train][INFO] - end of epoch 790 (average epoch stats below)
[2024-10-12 23:59:50,664][train][INFO] - {"epoch": 790, "train_loss": "0.73", "train_ntokens": "263541", "train_nsentences": "1753.71", "train_wps": "144012", "train_ups": "0.55", "train_wpb": "263541", "train_bsz": "1753.7", "train_num_updates": "378263", "train_lr": "2.9534e-05", "train_gnorm": "0.206", "train_loss_scale": "4", "train_train_wall": "500", "train_gb_free": "39.6", "train_wall": "712183"}
[2024-10-12 23:59:50,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 23:59:50,753][fairseq.trainer][INFO] - begin training epoch 791
[2024-10-12 23:59:50,754][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 00:07:33,439][train_inner][INFO] - {"epoch": 791, "update": 790.286, "loss": "0.732", "ntokens": "262861", "nsentences": "1752.45", "wps": "95686.9", "ups": "0.36", "wpb": "262861", "bsz": "1752.5", "num_updates": "378400", "lr": "2.93478e-05", "gnorm": "0.207", "loss_scale": "4", "train_wall": "219", "gb_free": "40.1", "wall": "712646"}
[2024-10-13 00:11:27,479][train_inner][INFO] - {"epoch": 791, "update": 790.704, "loss": "0.728", "ntokens": "264052", "nsentences": "1751.17", "wps": "225679", "ups": "0.85", "wpb": "264052", "bsz": "1751.2", "num_updates": "378600", "lr": "2.90761e-05", "gnorm": "0.206", "loss_scale": "4", "train_wall": "205", "gb_free": "39.3", "wall": "712880"}
[2024-10-13 00:14:28,560][fairseq_cli.train][INFO] - end of epoch 791 (average epoch stats below)
[2024-10-13 00:14:28,568][train][INFO] - {"epoch": 791, "train_loss": "0.73", "train_ntokens": "263595", "train_nsentences": "1753.71", "train_wps": "143825", "train_ups": "0.55", "train_wpb": "263595", "train_bsz": "1753.7", "train_num_updates": "378742", "train_lr": "2.88832e-05", "train_gnorm": "0.206", "train_loss_scale": "4", "train_train_wall": "457", "train_gb_free": "40.4", "train_wall": "713061"}
[2024-10-13 00:14:28,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 00:14:28,713][fairseq.trainer][INFO] - begin training epoch 792
[2024-10-13 00:14:28,714][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 00:21:17,007][train_inner][INFO] - {"epoch": 792, "update": 791.121, "loss": "0.73", "ntokens": "263000", "nsentences": "1742.3", "wps": "89232.8", "ups": "0.34", "wpb": "263000", "bsz": "1742.3", "num_updates": "378800", "lr": "2.88043e-05", "gnorm": "0.208", "loss_scale": "4", "train_wall": "181", "gb_free": "39.6", "wall": "713469"}
[2024-10-13 00:24:44,491][train_inner][INFO] - {"epoch": 792, "update": 791.539, "loss": "0.729", "ntokens": "263724", "nsentences": "1779.59", "wps": "254270", "ups": "0.96", "wpb": "263724", "bsz": "1779.6", "num_updates": "379000", "lr": "2.85326e-05", "gnorm": "0.207", "loss_scale": "4", "train_wall": "201", "gb_free": "40.5", "wall": "713677"}
[2024-10-13 00:28:29,696][train_inner][INFO] - {"epoch": 792, "update": 791.956, "loss": "0.728", "ntokens": "264000", "nsentences": "1746.98", "wps": "234473", "ups": "0.89", "wpb": "264000", "bsz": "1747", "num_updates": "379200", "lr": "2.82609e-05", "gnorm": "0.203", "loss_scale": "4", "train_wall": "220", "gb_free": "39.6", "wall": "713902"}
[2024-10-13 00:28:54,660][fairseq_cli.train][INFO] - end of epoch 792 (average epoch stats below)
[2024-10-13 00:28:54,662][train][INFO] - {"epoch": 792, "train_loss": "0.729", "train_ntokens": "263417", "train_nsentences": "1753.71", "train_wps": "145694", "train_ups": "0.55", "train_wpb": "263417", "train_bsz": "1753.7", "train_num_updates": "379221", "train_lr": "2.82323e-05", "train_gnorm": "0.206", "train_loss_scale": "4", "train_train_wall": "524", "train_gb_free": "39.3", "train_wall": "713927"}
[2024-10-13 00:28:54,837][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 00:28:54,890][fairseq.trainer][INFO] - begin training epoch 793
[2024-10-13 00:28:54,891][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 00:37:50,625][train_inner][INFO] - {"epoch": 793, "update": 792.374, "loss": "0.731", "ntokens": "262745", "nsentences": "1730.82", "wps": "93684.5", "ups": "0.36", "wpb": "262745", "bsz": "1730.8", "num_updates": "379400", "lr": "2.79891e-05", "gnorm": "0.204", "loss_scale": "4", "train_wall": "223", "gb_free": "39.3", "wall": "714463"}
[2024-10-13 00:41:46,762][train_inner][INFO] - {"epoch": 793, "update": 792.791, "loss": "0.729", "ntokens": "263766", "nsentences": "1781.19", "wps": "223456", "ups": "0.85", "wpb": "263766", "bsz": "1781.2", "num_updates": "379600", "lr": "2.77174e-05", "gnorm": "0.206", "loss_scale": "4", "train_wall": "231", "gb_free": "39.7", "wall": "714699"}
[2024-10-13 00:43:59,586][fairseq_cli.train][INFO] - end of epoch 793 (average epoch stats below)
[2024-10-13 00:43:59,606][train][INFO] - {"epoch": 793, "train_loss": "0.729", "train_ntokens": "263443", "train_nsentences": "1753.71", "train_wps": "139449", "train_ups": "0.53", "train_wpb": "263443", "train_bsz": "1753.7", "train_num_updates": "379700", "train_lr": "2.75815e-05", "train_gnorm": "0.205", "train_loss_scale": "4", "train_train_wall": "560", "train_gb_free": "39.6", "train_wall": "714832"}
[2024-10-13 00:43:59,713][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 00:43:59,731][fairseq.trainer][INFO] - begin training epoch 794
[2024-10-13 00:43:59,732][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 00:51:18,954][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-13 00:51:30,962][train_inner][INFO] - {"epoch": 794, "update": 793.211, "loss": "0.729", "ntokens": "263111", "nsentences": "1737.6", "wps": "90078.5", "ups": "0.34", "wpb": "263112", "bsz": "1737.6", "num_updates": "379800", "lr": "2.74457e-05", "gnorm": "0.203", "loss_scale": "4", "train_wall": "263", "gb_free": "39.6", "wall": "715283"}
[2024-10-13 00:55:19,552][train_inner][INFO] - {"epoch": 794, "update": 793.628, "loss": "0.728", "ntokens": "264080", "nsentences": "1741.96", "wps": "231094", "ups": "0.88", "wpb": "264080", "bsz": "1742", "num_updates": "380000", "lr": "2.71739e-05", "gnorm": "0.207", "loss_scale": "4", "train_wall": "223", "gb_free": "40", "wall": "715512"}
[2024-10-13 00:59:18,170][fairseq_cli.train][INFO] - end of epoch 794 (average epoch stats below)
[2024-10-13 00:59:18,190][train][INFO] - {"epoch": 794, "train_loss": "0.729", "train_ntokens": "263517", "train_nsentences": "1753.77", "train_wps": "137131", "train_ups": "0.52", "train_wpb": "263517", "train_bsz": "1753.8", "train_num_updates": "380178", "train_lr": "2.69321e-05", "train_gnorm": "0.205", "train_loss_scale": "4", "train_train_wall": "589", "train_gb_free": "39.7", "train_wall": "715750"}
[2024-10-13 00:59:18,308][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 00:59:18,328][fairseq.trainer][INFO] - begin training epoch 795
[2024-10-13 00:59:18,329][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 01:05:26,076][train_inner][INFO] - {"epoch": 795, "update": 794.046, "loss": "0.728", "ntokens": "262605", "nsentences": "1767.5", "wps": "86601.8", "ups": "0.33", "wpb": "262604", "bsz": "1767.5", "num_updates": "380200", "lr": "2.69022e-05", "gnorm": "0.206", "loss_scale": "4", "train_wall": "284", "gb_free": "39.2", "wall": "716118"}
[2024-10-13 01:08:48,876][train_inner][INFO] - {"epoch": 795, "update": 794.463, "loss": "0.727", "ntokens": "264122", "nsentences": "1732.34", "wps": "260492", "ups": "0.99", "wpb": "264122", "bsz": "1732.3", "num_updates": "380400", "lr": "2.66304e-05", "gnorm": "0.201", "loss_scale": "4", "train_wall": "198", "gb_free": "39.8", "wall": "716321"}
[2024-10-13 01:11:43,294][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 01:13:10,088][train_inner][INFO] - {"epoch": 795, "update": 794.883, "loss": "0.729", "ntokens": "263861", "nsentences": "1774.59", "wps": "202051", "ups": "0.77", "wpb": "263861", "bsz": "1774.6", "num_updates": "380600", "lr": "2.63587e-05", "gnorm": "0.199", "loss_scale": "2", "train_wall": "256", "gb_free": "39.3", "wall": "716582"}
[2024-10-13 01:14:22,102][fairseq_cli.train][INFO] - end of epoch 795 (average epoch stats below)
[2024-10-13 01:14:22,116][train][INFO] - {"epoch": 795, "train_loss": "0.728", "train_ntokens": "263496", "train_nsentences": "1752.78", "train_wps": "139339", "train_ups": "0.53", "train_wpb": "263496", "train_bsz": "1752.8", "train_num_updates": "380656", "train_lr": "2.62826e-05", "train_gnorm": "0.202", "train_loss_scale": "2", "train_train_wall": "573", "train_gb_free": "38.8", "train_wall": "716654"}
[2024-10-13 01:14:22,256][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 01:14:22,278][fairseq.trainer][INFO] - begin training epoch 796
[2024-10-13 01:14:22,279][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 01:22:41,001][train_inner][INFO] - {"epoch": 796, "update": 795.301, "loss": "0.73", "ntokens": "262670", "nsentences": "1788.31", "wps": "92022.5", "ups": "0.35", "wpb": "262670", "bsz": "1788.3", "num_updates": "380800", "lr": "2.6087e-05", "gnorm": "0.206", "loss_scale": "2", "train_wall": "241", "gb_free": "39.3", "wall": "717153"}
[2024-10-13 01:26:18,562][train_inner][INFO] - {"epoch": 796, "update": 795.718, "loss": "0.727", "ntokens": "264326", "nsentences": "1717.82", "wps": "243010", "ups": "0.92", "wpb": "264326", "bsz": "1717.8", "num_updates": "381000", "lr": "2.58152e-05", "gnorm": "0.209", "loss_scale": "2", "train_wall": "211", "gb_free": "40.1", "wall": "717371"}
[2024-10-13 01:29:14,074][fairseq_cli.train][INFO] - end of epoch 796 (average epoch stats below)
[2024-10-13 01:29:14,105][train][INFO] - {"epoch": 796, "train_loss": "0.728", "train_ntokens": "263559", "train_nsentences": "1753.71", "train_wps": "141537", "train_ups": "0.54", "train_wpb": "263558", "train_bsz": "1753.7", "train_num_updates": "381135", "train_lr": "2.56318e-05", "train_gnorm": "0.204", "train_loss_scale": "2", "train_train_wall": "553", "train_gb_free": "39.7", "train_wall": "717546"}
[2024-10-13 01:29:14,252][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 01:29:14,257][fairseq.trainer][INFO] - begin training epoch 797
[2024-10-13 01:29:14,257][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 01:35:55,824][train_inner][INFO] - {"epoch": 797, "update": 796.136, "loss": "0.73", "ntokens": "262683", "nsentences": "1766.47", "wps": "91012.3", "ups": "0.35", "wpb": "262683", "bsz": "1766.5", "num_updates": "381200", "lr": "2.55435e-05", "gnorm": "0.2", "loss_scale": "2", "train_wall": "245", "gb_free": "40", "wall": "717948"}
[2024-10-13 01:39:38,273][train_inner][INFO] - {"epoch": 797, "update": 796.553, "loss": "0.728", "ntokens": "263681", "nsentences": "1806.37", "wps": "237084", "ups": "0.9", "wpb": "263681", "bsz": "1806.4", "num_updates": "381400", "lr": "2.52717e-05", "gnorm": "0.202", "loss_scale": "2", "train_wall": "217", "gb_free": "39.2", "wall": "718170"}
[2024-10-13 01:43:20,743][train_inner][INFO] - {"epoch": 797, "update": 796.971, "loss": "0.727", "ntokens": "264626", "nsentences": "1681.62", "wps": "237911", "ups": "0.9", "wpb": "264626", "bsz": "1681.6", "num_updates": "381600", "lr": "2.5e-05", "gnorm": "0.203", "loss_scale": "2", "train_wall": "217", "gb_free": "39.6", "wall": "718393"}
[2024-10-13 01:44:05,421][fairseq_cli.train][INFO] - end of epoch 797 (average epoch stats below)
[2024-10-13 01:44:05,426][train][INFO] - {"epoch": 797, "train_loss": "0.729", "train_ntokens": "263547", "train_nsentences": "1753.71", "train_wps": "141640", "train_ups": "0.54", "train_wpb": "263547", "train_bsz": "1753.7", "train_num_updates": "381614", "train_lr": "2.4981e-05", "train_gnorm": "0.204", "train_loss_scale": "2", "train_train_wall": "554", "train_gb_free": "39.6", "train_wall": "718438"}
[2024-10-13 01:44:05,476][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 01:44:05,487][fairseq.trainer][INFO] - begin training epoch 798
[2024-10-13 01:44:05,487][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 01:53:11,677][train_inner][INFO] - {"epoch": 798, "update": 797.388, "loss": "0.729", "ntokens": "262534", "nsentences": "1781.32", "wps": "88857.3", "ups": "0.34", "wpb": "262534", "bsz": "1781.3", "num_updates": "381800", "lr": "2.47283e-05", "gnorm": "0.208", "loss_scale": "2", "train_wall": "281", "gb_free": "40", "wall": "718984"}
[2024-10-13 01:57:11,770][train_inner][INFO] - {"epoch": 798, "update": 797.806, "loss": "0.728", "ntokens": "264449", "nsentences": "1713.39", "wps": "220355", "ups": "0.83", "wpb": "264449", "bsz": "1713.4", "num_updates": "382000", "lr": "2.44565e-05", "gnorm": "0.197", "loss_scale": "2", "train_wall": "235", "gb_free": "39.2", "wall": "719224"}
[2024-10-13 01:59:19,020][fairseq_cli.train][INFO] - end of epoch 798 (average epoch stats below)
[2024-10-13 01:59:19,037][train][INFO] - {"epoch": 798, "train_loss": "0.729", "train_ntokens": "263547", "train_nsentences": "1753.71", "train_wps": "138178", "train_ups": "0.52", "train_wpb": "263547", "train_bsz": "1753.7", "train_num_updates": "382093", "train_lr": "2.43302e-05", "train_gnorm": "0.202", "train_loss_scale": "2", "train_train_wall": "597", "train_gb_free": "40", "train_wall": "719351"}
[2024-10-13 01:59:19,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 01:59:19,147][fairseq.trainer][INFO] - begin training epoch 799
[2024-10-13 01:59:19,148][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 02:06:44,393][train_inner][INFO] - {"epoch": 799, "update": 798.223, "loss": "0.729", "ntokens": "262776", "nsentences": "1765.53", "wps": "91783.9", "ups": "0.35", "wpb": "262776", "bsz": "1765.5", "num_updates": "382200", "lr": "2.41848e-05", "gnorm": "0.205", "loss_scale": "2", "train_wall": "259", "gb_free": "40.1", "wall": "719797"}
[2024-10-13 02:10:57,110][train_inner][INFO] - {"epoch": 799, "update": 798.641, "loss": "0.726", "ntokens": "264208", "nsentences": "1738.28", "wps": "209106", "ups": "0.79", "wpb": "264208", "bsz": "1738.3", "num_updates": "382400", "lr": "2.3913e-05", "gnorm": "0.201", "loss_scale": "2", "train_wall": "248", "gb_free": "39.6", "wall": "720049"}
[2024-10-13 02:14:54,359][fairseq_cli.train][INFO] - end of epoch 799 (average epoch stats below)
[2024-10-13 02:14:54,380][train][INFO] - {"epoch": 799, "train_loss": "0.728", "train_ntokens": "263560", "train_nsentences": "1753.71", "train_wps": "134976", "train_ups": "0.51", "train_wpb": "263560", "train_bsz": "1753.7", "train_num_updates": "382572", "train_lr": "2.36793e-05", "train_gnorm": "0.201", "train_loss_scale": "2", "train_train_wall": "612", "train_gb_free": "39.6", "train_wall": "720287"}
[2024-10-13 02:14:54,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 02:14:54,540][fairseq.trainer][INFO] - begin training epoch 800
[2024-10-13 02:14:54,541][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 02:21:00,227][train_inner][INFO] - {"epoch": 800, "update": 799.058, "loss": "0.73", "ntokens": "262550", "nsentences": "1782.34", "wps": "87066", "ups": "0.33", "wpb": "262550", "bsz": "1782.3", "num_updates": "382600", "lr": "2.36413e-05", "gnorm": "0.202", "loss_scale": "4", "train_wall": "277", "gb_free": "39.6", "wall": "720652"}
[2024-10-13 02:24:32,992][train_inner][INFO] - {"epoch": 800, "update": 799.476, "loss": "0.727", "ntokens": "264366", "nsentences": "1712.33", "wps": "248520", "ups": "0.94", "wpb": "264366", "bsz": "1712.3", "num_updates": "382800", "lr": "2.33696e-05", "gnorm": "0.2", "loss_scale": "4", "train_wall": "208", "gb_free": "39.3", "wall": "720865"}
[2024-10-13 02:28:35,130][train_inner][INFO] - {"epoch": 800, "update": 799.894, "loss": "0.729", "ntokens": "263612", "nsentences": "1799.83", "wps": "217748", "ups": "0.83", "wpb": "263612", "bsz": "1799.8", "num_updates": "383000", "lr": "2.30978e-05", "gnorm": "0.208", "loss_scale": "4", "train_wall": "237", "gb_free": "39.7", "wall": "721107"}
[2024-10-13 02:29:52,545][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 800 @ 383051 updates
[2024-10-13 02:29:52,546][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 02:29:58,289][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 02:29:58,360][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 800 @ 383051 updates, score None) (writing took 5.815446257591248 seconds)
[2024-10-13 02:29:58,361][fairseq_cli.train][INFO] - end of epoch 800 (average epoch stats below)
[2024-10-13 02:29:58,364][train][INFO] - {"epoch": 800, "train_loss": "0.728", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "139626", "train_ups": "0.53", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "383051", "train_lr": "2.30285e-05", "train_gnorm": "0.205", "train_loss_scale": "4", "train_train_wall": "566", "train_gb_free": "39.2", "train_wall": "721191"}
[2024-10-13 02:29:58,404][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 02:29:58,431][fairseq.trainer][INFO] - begin training epoch 801
[2024-10-13 02:29:58,432][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 02:38:06,851][train_inner][INFO] - {"epoch": 801, "update": 800.311, "loss": "0.728", "ntokens": "263033", "nsentences": "1733.42", "wps": "92016.5", "ups": "0.35", "wpb": "263033", "bsz": "1733.4", "num_updates": "383200", "lr": "2.28261e-05", "gnorm": "0.204", "loss_scale": "4", "train_wall": "243", "gb_free": "40", "wall": "721679"}
[2024-10-13 02:42:19,679][train_inner][INFO] - {"epoch": 801, "update": 800.729, "loss": "0.728", "ntokens": "263909", "nsentences": "1758.05", "wps": "208778", "ups": "0.79", "wpb": "263909", "bsz": "1758", "num_updates": "383400", "lr": "2.25543e-05", "gnorm": "0.199", "loss_scale": "4", "train_wall": "247", "gb_free": "39.8", "wall": "721932"}
[2024-10-13 02:45:11,530][fairseq_cli.train][INFO] - end of epoch 801 (average epoch stats below)
[2024-10-13 02:45:11,534][train][INFO] - {"epoch": 801, "train_loss": "0.728", "train_ntokens": "263598", "train_nsentences": "1753.71", "train_wps": "138271", "train_ups": "0.52", "train_wpb": "263598", "train_bsz": "1753.7", "train_num_updates": "383530", "train_lr": "2.23777e-05", "train_gnorm": "0.202", "train_loss_scale": "4", "train_train_wall": "584", "train_gb_free": "39.6", "train_wall": "722104"}
[2024-10-13 02:45:11,658][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 02:45:11,691][fairseq.trainer][INFO] - begin training epoch 802
[2024-10-13 02:45:11,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 02:52:05,765][train_inner][INFO] - {"epoch": 802, "update": 801.146, "loss": "0.727", "ntokens": "262944", "nsentences": "1758.72", "wps": "89731", "ups": "0.34", "wpb": "262944", "bsz": "1758.7", "num_updates": "383600", "lr": "2.22826e-05", "gnorm": "0.202", "loss_scale": "4", "train_wall": "269", "gb_free": "39.3", "wall": "722518"}
[2024-10-13 02:55:26,831][train_inner][INFO] - {"epoch": 802, "update": 801.564, "loss": "0.728", "ntokens": "264066", "nsentences": "1735.44", "wps": "262717", "ups": "0.99", "wpb": "264066", "bsz": "1735.4", "num_updates": "383800", "lr": "2.20109e-05", "gnorm": "0.201", "loss_scale": "4", "train_wall": "195", "gb_free": "39.6", "wall": "722719"}
[2024-10-13 02:57:23,922][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 02:59:28,867][train_inner][INFO] - {"epoch": 802, "update": 801.983, "loss": "0.73", "ntokens": "263728", "nsentences": "1789.21", "wps": "217994", "ups": "0.83", "wpb": "263728", "bsz": "1789.2", "num_updates": "384000", "lr": "2.17391e-05", "gnorm": "0.204", "loss_scale": "2", "train_wall": "237", "gb_free": "39.3", "wall": "722961"}
[2024-10-13 03:00:01,786][fairseq_cli.train][INFO] - end of epoch 802 (average epoch stats below)
[2024-10-13 03:00:01,794][train][INFO] - {"epoch": 802, "train_loss": "0.728", "train_ntokens": "263465", "train_nsentences": "1752.47", "train_wps": "141466", "train_ups": "0.54", "train_wpb": "263465", "train_bsz": "1752.5", "train_num_updates": "384008", "train_lr": "2.17283e-05", "train_gnorm": "0.203", "train_loss_scale": "2", "train_train_wall": "565", "train_gb_free": "39.2", "train_wall": "722994"}
[2024-10-13 03:00:01,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 03:00:01,899][fairseq.trainer][INFO] - begin training epoch 803
[2024-10-13 03:00:01,900][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 03:09:08,746][train_inner][INFO] - {"epoch": 803, "update": 802.401, "loss": "0.727", "ntokens": "262956", "nsentences": "1738.9", "wps": "90710.1", "ups": "0.34", "wpb": "262956", "bsz": "1738.9", "num_updates": "384200", "lr": "2.14674e-05", "gnorm": "0.197", "loss_scale": "2", "train_wall": "265", "gb_free": "39.3", "wall": "723541"}
[2024-10-13 03:13:14,552][train_inner][INFO] - {"epoch": 803, "update": 802.818, "loss": "0.727", "ntokens": "264167", "nsentences": "1733.26", "wps": "214961", "ups": "0.81", "wpb": "264167", "bsz": "1733.3", "num_updates": "384400", "lr": "2.11957e-05", "gnorm": "0.202", "loss_scale": "2", "train_wall": "241", "gb_free": "40", "wall": "723787"}
[2024-10-13 03:15:17,826][fairseq_cli.train][INFO] - end of epoch 803 (average epoch stats below)
[2024-10-13 03:15:17,830][train][INFO] - {"epoch": 803, "train_loss": "0.727", "train_ntokens": "263495", "train_nsentences": "1753.71", "train_wps": "137786", "train_ups": "0.52", "train_wpb": "263495", "train_bsz": "1753.7", "train_num_updates": "384487", "train_lr": "2.10774e-05", "train_gnorm": "0.2", "train_loss_scale": "2", "train_train_wall": "595", "train_gb_free": "39.2", "train_wall": "723910"}
[2024-10-13 03:15:17,933][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 03:15:17,946][fairseq.trainer][INFO] - begin training epoch 804
[2024-10-13 03:15:17,946][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 03:23:01,617][train_inner][INFO] - {"epoch": 804, "update": 803.236, "loss": "0.727", "ntokens": "262911", "nsentences": "1741.67", "wps": "89571", "ups": "0.34", "wpb": "262911", "bsz": "1741.7", "num_updates": "384600", "lr": "2.09239e-05", "gnorm": "0.199", "loss_scale": "2", "train_wall": "264", "gb_free": "39.7", "wall": "724374"}
[2024-10-13 03:26:56,417][train_inner][INFO] - {"epoch": 804, "update": 803.653, "loss": "0.728", "ntokens": "263972", "nsentences": "1779.09", "wps": "224868", "ups": "0.85", "wpb": "263972", "bsz": "1779.1", "num_updates": "384800", "lr": "2.06522e-05", "gnorm": "0.203", "loss_scale": "2", "train_wall": "229", "gb_free": "39.6", "wall": "724609"}
[2024-10-13 03:30:25,916][fairseq_cli.train][INFO] - end of epoch 804 (average epoch stats below)
[2024-10-13 03:30:25,933][train][INFO] - {"epoch": 804, "train_loss": "0.727", "train_ntokens": "263566", "train_nsentences": "1753.71", "train_wps": "139029", "train_ups": "0.53", "train_wpb": "263566", "train_bsz": "1753.7", "train_num_updates": "384966", "train_lr": "2.04266e-05", "train_gnorm": "0.2", "train_loss_scale": "2", "train_train_wall": "576", "train_gb_free": "39.2", "train_wall": "724818"}
[2024-10-13 03:30:26,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 03:30:26,056][fairseq.trainer][INFO] - begin training epoch 805
[2024-10-13 03:30:26,057][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 03:36:34,402][train_inner][INFO] - {"epoch": 805, "update": 804.071, "loss": "0.727", "ntokens": "262688", "nsentences": "1763.57", "wps": "90899.8", "ups": "0.35", "wpb": "262688", "bsz": "1763.6", "num_updates": "385000", "lr": "2.03804e-05", "gnorm": "0.199", "loss_scale": "2", "train_wall": "266", "gb_free": "39.6", "wall": "725187"}
[2024-10-13 03:40:23,770][train_inner][INFO] - {"epoch": 805, "update": 804.489, "loss": "0.727", "ntokens": "264152", "nsentences": "1745.35", "wps": "230345", "ups": "0.87", "wpb": "264152", "bsz": "1745.4", "num_updates": "385200", "lr": "2.01087e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "224", "gb_free": "39.7", "wall": "725416"}
[2024-10-13 03:44:37,960][train_inner][INFO] - {"epoch": 805, "update": 804.906, "loss": "0.728", "ntokens": "263704", "nsentences": "1780.51", "wps": "207513", "ups": "0.79", "wpb": "263704", "bsz": "1780.5", "num_updates": "385400", "lr": "1.9837e-05", "gnorm": "0.198", "loss_scale": "2", "train_wall": "248", "gb_free": "39.6", "wall": "725670"}
[2024-10-13 03:45:34,733][fairseq_cli.train][INFO] - end of epoch 805 (average epoch stats below)
[2024-10-13 03:45:34,749][train][INFO] - {"epoch": 805, "train_loss": "0.727", "train_ntokens": "263503", "train_nsentences": "1753.71", "train_wps": "138884", "train_ups": "0.53", "train_wpb": "263503", "train_bsz": "1753.7", "train_num_updates": "385445", "train_lr": "1.97758e-05", "train_gnorm": "0.196", "train_loss_scale": "2", "train_train_wall": "589", "train_gb_free": "39.6", "train_wall": "725727"}
[2024-10-13 03:45:34,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 03:45:34,995][fairseq.trainer][INFO] - begin training epoch 806
[2024-10-13 03:45:34,996][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 03:54:03,613][train_inner][INFO] - {"epoch": 806, "update": 805.324, "loss": "0.726", "ntokens": "263139", "nsentences": "1704.84", "wps": "93043.7", "ups": "0.35", "wpb": "263139", "bsz": "1704.8", "num_updates": "385600", "lr": "1.95652e-05", "gnorm": "0.198", "loss_scale": "2", "train_wall": "225", "gb_free": "39.3", "wall": "726236"}
[2024-10-13 03:57:49,413][train_inner][INFO] - {"epoch": 806, "update": 805.741, "loss": "0.727", "ntokens": "263730", "nsentences": "1760.74", "wps": "233631", "ups": "0.89", "wpb": "263730", "bsz": "1760.7", "num_updates": "385800", "lr": "1.92935e-05", "gnorm": "0.197", "loss_scale": "2", "train_wall": "220", "gb_free": "39.8", "wall": "726462"}
[2024-10-13 04:00:26,267][fairseq_cli.train][INFO] - end of epoch 806 (average epoch stats below)
[2024-10-13 04:00:26,304][train][INFO] - {"epoch": 806, "train_loss": "0.727", "train_ntokens": "263421", "train_nsentences": "1753.71", "train_wps": "141532", "train_ups": "0.54", "train_wpb": "263421", "train_bsz": "1753.7", "train_num_updates": "385924", "train_lr": "1.9125e-05", "train_gnorm": "0.196", "train_loss_scale": "2", "train_train_wall": "543", "train_gb_free": "39.6", "train_wall": "726618"}
[2024-10-13 04:00:26,547][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 04:00:26,572][fairseq.trainer][INFO] - begin training epoch 807
[2024-10-13 04:00:26,573][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 04:07:27,675][train_inner][INFO] - {"epoch": 807, "update": 806.159, "loss": "0.727", "ntokens": "262693", "nsentences": "1764.16", "wps": "90858.5", "ups": "0.35", "wpb": "262693", "bsz": "1764.2", "num_updates": "386000", "lr": "1.90217e-05", "gnorm": "0.192", "loss_scale": "4", "train_wall": "271", "gb_free": "39.6", "wall": "727040"}
[2024-10-13 04:11:43,041][train_inner][INFO] - {"epoch": 807, "update": 806.576, "loss": "0.729", "ntokens": "263497", "nsentences": "1802.93", "wps": "206381", "ups": "0.78", "wpb": "263497", "bsz": "1802.9", "num_updates": "386200", "lr": "1.875e-05", "gnorm": "0.196", "loss_scale": "4", "train_wall": "250", "gb_free": "39.6", "wall": "727295"}
[2024-10-13 04:15:40,306][train_inner][INFO] - {"epoch": 807, "update": 806.994, "loss": "0.724", "ntokens": "264306", "nsentences": "1717.62", "wps": "222821", "ups": "0.84", "wpb": "264306", "bsz": "1717.6", "num_updates": "386400", "lr": "1.84783e-05", "gnorm": "0.201", "loss_scale": "4", "train_wall": "232", "gb_free": "40.1", "wall": "727532"}
[2024-10-13 04:15:54,214][fairseq_cli.train][INFO] - end of epoch 807 (average epoch stats below)
[2024-10-13 04:15:54,230][train][INFO] - {"epoch": 807, "train_loss": "0.727", "train_ntokens": "263443", "train_nsentences": "1753.71", "train_wps": "136000", "train_ups": "0.52", "train_wpb": "263443", "train_bsz": "1753.7", "train_num_updates": "386403", "train_lr": "1.84742e-05", "train_gnorm": "0.198", "train_loss_scale": "4", "train_train_wall": "613", "train_gb_free": "39.7", "train_wall": "727546"}
[2024-10-13 04:15:54,321][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 04:15:54,338][fairseq.trainer][INFO] - begin training epoch 808
[2024-10-13 04:15:54,339][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 04:24:59,171][train_inner][INFO] - {"epoch": 808, "update": 807.411, "loss": "0.726", "ntokens": "262947", "nsentences": "1748.31", "wps": "94109.7", "ups": "0.36", "wpb": "262947", "bsz": "1748.3", "num_updates": "386600", "lr": "1.82065e-05", "gnorm": "0.204", "loss_scale": "4", "train_wall": "248", "gb_free": "39.2", "wall": "728091"}
[2024-10-13 04:28:17,582][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 04:29:08,256][train_inner][INFO] - {"epoch": 808, "update": 807.831, "loss": "0.727", "ntokens": "264039", "nsentences": "1746.53", "wps": "212058", "ups": "0.8", "wpb": "264039", "bsz": "1746.5", "num_updates": "386800", "lr": "1.79348e-05", "gnorm": "0.198", "loss_scale": "2", "train_wall": "244", "gb_free": "40.1", "wall": "728340"}
[2024-10-13 04:30:50,961][fairseq_cli.train][INFO] - end of epoch 808 (average epoch stats below)
[2024-10-13 04:30:50,978][train][INFO] - {"epoch": 808, "train_loss": "0.726", "train_ntokens": "263482", "train_nsentences": "1753.65", "train_wps": "140447", "train_ups": "0.53", "train_wpb": "263482", "train_bsz": "1753.7", "train_num_updates": "386881", "train_lr": "1.78247e-05", "train_gnorm": "0.201", "train_loss_scale": "2", "train_train_wall": "578", "train_gb_free": "39.8", "train_wall": "728443"}
[2024-10-13 04:30:51,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 04:30:51,176][fairseq.trainer][INFO] - begin training epoch 809
[2024-10-13 04:30:51,177][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 04:38:36,324][train_inner][INFO] - {"epoch": 809, "update": 808.248, "loss": "0.725", "ntokens": "262729", "nsentences": "1752.55", "wps": "92505.9", "ups": "0.35", "wpb": "262729", "bsz": "1752.5", "num_updates": "387000", "lr": "1.7663e-05", "gnorm": "0.197", "loss_scale": "2", "train_wall": "182", "gb_free": "40", "wall": "728908"}
[2024-10-13 04:42:22,509][train_inner][INFO] - {"epoch": 809, "update": 808.666, "loss": "0.726", "ntokens": "263939", "nsentences": "1766.17", "wps": "233410", "ups": "0.88", "wpb": "263939", "bsz": "1766.2", "num_updates": "387200", "lr": "1.73913e-05", "gnorm": "0.202", "loss_scale": "2", "train_wall": "136", "gb_free": "39.7", "wall": "729135"}
[2024-10-13 04:45:30,081][fairseq_cli.train][INFO] - end of epoch 809 (average epoch stats below)
[2024-10-13 04:45:30,103][train][INFO] - {"epoch": 809, "train_loss": "0.726", "train_ntokens": "263510", "train_nsentences": "1753.71", "train_wps": "143578", "train_ups": "0.54", "train_wpb": "263510", "train_bsz": "1753.7", "train_num_updates": "387360", "train_lr": "1.71739e-05", "train_gnorm": "0.198", "train_loss_scale": "2", "train_train_wall": "367", "train_gb_free": "40.2", "train_wall": "729322"}
[2024-10-13 04:45:30,264][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 04:45:30,303][fairseq.trainer][INFO] - begin training epoch 810
[2024-10-13 04:45:30,304][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 04:51:50,303][train_inner][INFO] - {"epoch": 810, "update": 809.084, "loss": "0.727", "ntokens": "262683", "nsentences": "1759.55", "wps": "92531.6", "ups": "0.35", "wpb": "262683", "bsz": "1759.5", "num_updates": "387400", "lr": "1.71196e-05", "gnorm": "0.196", "loss_scale": "2", "train_wall": "220", "gb_free": "39.3", "wall": "729702"}
[2024-10-13 04:55:38,169][train_inner][INFO] - {"epoch": 810, "update": 809.501, "loss": "0.729", "ntokens": "264158", "nsentences": "1750.78", "wps": "231881", "ups": "0.88", "wpb": "264158", "bsz": "1750.8", "num_updates": "387600", "lr": "1.68478e-05", "gnorm": "0.194", "loss_scale": "2", "train_wall": "222", "gb_free": "39.6", "wall": "729930"}
[2024-10-13 04:59:53,199][train_inner][INFO] - {"epoch": 810, "update": 809.919, "loss": "0.726", "ntokens": "263656", "nsentences": "1783.41", "wps": "206784", "ups": "0.78", "wpb": "263656", "bsz": "1783.4", "num_updates": "387800", "lr": "1.65761e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "249", "gb_free": "39.1", "wall": "730185"}
[2024-10-13 05:00:52,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 810 @ 387839 updates
[2024-10-13 05:00:52,941][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 05:00:59,944][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 05:01:00,053][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 810 @ 387839 updates, score None) (writing took 7.113550442270935 seconds)
[2024-10-13 05:01:00,054][fairseq_cli.train][INFO] - end of epoch 810 (average epoch stats below)
[2024-10-13 05:01:00,070][train][INFO] - {"epoch": 810, "train_loss": "0.727", "train_ntokens": "263521", "train_nsentences": "1753.71", "train_wps": "135736", "train_ups": "0.52", "train_wpb": "263521", "train_bsz": "1753.7", "train_num_updates": "387839", "train_lr": "1.65231e-05", "train_gnorm": "0.195", "train_loss_scale": "2", "train_train_wall": "601", "train_gb_free": "39.6", "train_wall": "730252"}
[2024-10-13 05:01:00,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 05:01:00,191][fairseq.trainer][INFO] - begin training epoch 811
[2024-10-13 05:01:00,192][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 05:09:16,767][train_inner][INFO] - {"epoch": 811, "update": 810.336, "loss": "0.725", "ntokens": "263160", "nsentences": "1722.57", "wps": "93393.7", "ups": "0.35", "wpb": "263160", "bsz": "1722.6", "num_updates": "388000", "lr": "1.63043e-05", "gnorm": "0.199", "loss_scale": "2", "train_wall": "249", "gb_free": "39.7", "wall": "730749"}
[2024-10-13 05:13:27,865][train_inner][INFO] - {"epoch": 811, "update": 810.754, "loss": "0.727", "ntokens": "263689", "nsentences": "1764.17", "wps": "210063", "ups": "0.8", "wpb": "263688", "bsz": "1764.2", "num_updates": "388200", "lr": "1.60326e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "245", "gb_free": "40", "wall": "731000"}
[2024-10-13 05:16:03,335][fairseq_cli.train][INFO] - end of epoch 811 (average epoch stats below)
[2024-10-13 05:16:03,352][train][INFO] - {"epoch": 811, "train_loss": "0.726", "train_ntokens": "263465", "train_nsentences": "1753.71", "train_wps": "139714", "train_ups": "0.53", "train_wpb": "263465", "train_bsz": "1753.7", "train_num_updates": "388318", "train_lr": "1.58723e-05", "train_gnorm": "0.194", "train_loss_scale": "2", "train_train_wall": "586", "train_gb_free": "39.6", "train_wall": "731156"}
[2024-10-13 05:16:03,536][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 05:16:03,567][fairseq.trainer][INFO] - begin training epoch 812
[2024-10-13 05:16:03,568][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 05:23:13,183][train_inner][INFO] - {"epoch": 812, "update": 811.171, "loss": "0.724", "ntokens": "263135", "nsentences": "1728.33", "wps": "89916.5", "ups": "0.34", "wpb": "263135", "bsz": "1728.3", "num_updates": "388400", "lr": "1.57609e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "278", "gb_free": "39.6", "wall": "731585"}
[2024-10-13 05:26:39,275][train_inner][INFO] - {"epoch": 812, "update": 811.589, "loss": "0.726", "ntokens": "264148", "nsentences": "1731.75", "wps": "256356", "ups": "0.97", "wpb": "264148", "bsz": "1731.8", "num_updates": "388600", "lr": "1.54891e-05", "gnorm": "0.198", "loss_scale": "2", "train_wall": "200", "gb_free": "39.6", "wall": "731791"}
[2024-10-13 05:30:49,033][fairseq_cli.train][INFO] - end of epoch 812 (average epoch stats below)
[2024-10-13 05:30:49,049][train][INFO] - {"epoch": 812, "train_loss": "0.726", "train_ntokens": "263511", "train_nsentences": "1753.71", "train_wps": "142513", "train_ups": "0.54", "train_wpb": "263512", "train_bsz": "1753.7", "train_num_updates": "388797", "train_lr": "1.52215e-05", "train_gnorm": "0.195", "train_loss_scale": "2", "train_train_wall": "572", "train_gb_free": "39.8", "train_wall": "732041"}
[2024-10-13 05:30:49,141][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 05:30:49,159][fairseq.trainer][INFO] - begin training epoch 813
[2024-10-13 05:30:49,160][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 05:36:35,127][train_inner][INFO] - {"epoch": 813, "update": 812.006, "loss": "0.728", "ntokens": "262518", "nsentences": "1789.54", "wps": "88119.7", "ups": "0.34", "wpb": "262518", "bsz": "1789.5", "num_updates": "388800", "lr": "1.52174e-05", "gnorm": "0.196", "loss_scale": "2", "train_wall": "263", "gb_free": "39.6", "wall": "732387"}
[2024-10-13 05:39:58,486][train_inner][INFO] - {"epoch": 813, "update": 812.424, "loss": "0.725", "ntokens": "263943", "nsentences": "1755.42", "wps": "259602", "ups": "0.98", "wpb": "263943", "bsz": "1755.4", "num_updates": "389000", "lr": "1.49457e-05", "gnorm": "0.194", "loss_scale": "4", "train_wall": "193", "gb_free": "39.3", "wall": "732591"}
[2024-10-13 05:44:15,587][train_inner][INFO] - {"epoch": 813, "update": 812.841, "loss": "0.729", "ntokens": "263918", "nsentences": "1765.49", "wps": "205326", "ups": "0.78", "wpb": "263918", "bsz": "1765.5", "num_updates": "389200", "lr": "1.46739e-05", "gnorm": "0.189", "loss_scale": "4", "train_wall": "251", "gb_free": "40.3", "wall": "732848"}
[2024-10-13 05:44:16,435][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 05:45:41,671][fairseq_cli.train][INFO] - end of epoch 813 (average epoch stats below)
[2024-10-13 05:45:41,706][train][INFO] - {"epoch": 813, "train_loss": "0.726", "train_ntokens": "263508", "train_nsentences": "1753.29", "train_wps": "141107", "train_ups": "0.54", "train_wpb": "263508", "train_bsz": "1753.3", "train_num_updates": "389275", "train_lr": "1.4572e-05", "train_gnorm": "0.192", "train_loss_scale": "2", "train_train_wall": "545", "train_gb_free": "41", "train_wall": "732934"}
[2024-10-13 05:45:41,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 05:45:41,848][fairseq.trainer][INFO] - begin training epoch 814
[2024-10-13 05:45:41,849][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 05:53:43,156][train_inner][INFO] - {"epoch": 814, "update": 813.261, "loss": "0.726", "ntokens": "262799", "nsentences": "1747.58", "wps": "92609.7", "ups": "0.35", "wpb": "262799", "bsz": "1747.6", "num_updates": "389400", "lr": "1.44022e-05", "gnorm": "0.194", "loss_scale": "2", "train_wall": "235", "gb_free": "40", "wall": "733415"}
[2024-10-13 05:57:40,854][train_inner][INFO] - {"epoch": 814, "update": 813.678, "loss": "0.725", "ntokens": "263869", "nsentences": "1749.19", "wps": "222063", "ups": "0.84", "wpb": "263869", "bsz": "1749.2", "num_updates": "389600", "lr": "1.41304e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "232", "gb_free": "39.3", "wall": "733653"}
[2024-10-13 06:00:39,402][fairseq_cli.train][INFO] - end of epoch 814 (average epoch stats below)
[2024-10-13 06:00:39,426][train][INFO] - {"epoch": 814, "train_loss": "0.726", "train_ntokens": "263445", "train_nsentences": "1753.71", "train_wps": "140571", "train_ups": "0.53", "train_wpb": "263446", "train_bsz": "1753.7", "train_num_updates": "389754", "train_lr": "1.39212e-05", "train_gnorm": "0.193", "train_loss_scale": "2", "train_train_wall": "558", "train_gb_free": "39.2", "train_wall": "733832"}
[2024-10-13 06:00:39,583][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 06:00:39,602][fairseq.trainer][INFO] - begin training epoch 815
[2024-10-13 06:00:39,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 06:07:21,707][train_inner][INFO] - {"epoch": 815, "update": 814.096, "loss": "0.725", "ntokens": "263061", "nsentences": "1732.7", "wps": "90584.4", "ups": "0.34", "wpb": "263061", "bsz": "1732.7", "num_updates": "389800", "lr": "1.38587e-05", "gnorm": "0.193", "loss_scale": "2", "train_wall": "246", "gb_free": "40.1", "wall": "734234"}
[2024-10-13 06:10:46,659][train_inner][INFO] - {"epoch": 815, "update": 814.514, "loss": "0.729", "ntokens": "263894", "nsentences": "1785.45", "wps": "257536", "ups": "0.98", "wpb": "263894", "bsz": "1785.5", "num_updates": "390000", "lr": "1.3587e-05", "gnorm": "0.194", "loss_scale": "2", "train_wall": "200", "gb_free": "39.2", "wall": "734439"}
[2024-10-13 06:14:43,961][train_inner][INFO] - {"epoch": 815, "update": 814.931, "loss": "0.725", "ntokens": "264030", "nsentences": "1736.94", "wps": "222539", "ups": "0.84", "wpb": "264030", "bsz": "1736.9", "num_updates": "390200", "lr": "1.33152e-05", "gnorm": "0.19", "loss_scale": "2", "train_wall": "233", "gb_free": "39.8", "wall": "734676"}
[2024-10-13 06:15:36,069][fairseq_cli.train][INFO] - end of epoch 815 (average epoch stats below)
[2024-10-13 06:15:36,104][train][INFO] - {"epoch": 815, "train_loss": "0.727", "train_ntokens": "263507", "train_nsentences": "1753.71", "train_wps": "140771", "train_ups": "0.53", "train_wpb": "263507", "train_bsz": "1753.7", "train_num_updates": "390233", "train_lr": "1.32704e-05", "train_gnorm": "0.192", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "39.3", "train_wall": "734728"}
[2024-10-13 06:15:36,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 06:15:36,242][fairseq.trainer][INFO] - begin training epoch 816
[2024-10-13 06:15:36,243][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 06:24:19,981][train_inner][INFO] - {"epoch": 816, "update": 815.349, "loss": "0.725", "ntokens": "263110", "nsentences": "1731.7", "wps": "91355.9", "ups": "0.35", "wpb": "263110", "bsz": "1731.7", "num_updates": "390400", "lr": "1.30435e-05", "gnorm": "0.192", "loss_scale": "2", "train_wall": "243", "gb_free": "39.7", "wall": "735252"}
[2024-10-13 06:28:23,596][train_inner][INFO] - {"epoch": 816, "update": 815.766, "loss": "0.727", "ntokens": "264010", "nsentences": "1766.11", "wps": "216758", "ups": "0.82", "wpb": "264010", "bsz": "1766.1", "num_updates": "390600", "lr": "1.27717e-05", "gnorm": "0.194", "loss_scale": "2", "train_wall": "238", "gb_free": "39.6", "wall": "735496"}
[2024-10-13 06:30:45,086][fairseq_cli.train][INFO] - end of epoch 816 (average epoch stats below)
[2024-10-13 06:30:45,120][train][INFO] - {"epoch": 816, "train_loss": "0.726", "train_ntokens": "263542", "train_nsentences": "1753.71", "train_wps": "138876", "train_ups": "0.53", "train_wpb": "263542", "train_bsz": "1753.7", "train_num_updates": "390712", "train_lr": "1.26196e-05", "train_gnorm": "0.195", "train_loss_scale": "2", "train_train_wall": "569", "train_gb_free": "39.2", "train_wall": "735637"}
[2024-10-13 06:30:45,196][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 06:30:45,215][fairseq.trainer][INFO] - begin training epoch 817
[2024-10-13 06:30:45,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 06:38:01,049][train_inner][INFO] - {"epoch": 817, "update": 816.184, "loss": "0.726", "ntokens": "262489", "nsentences": "1773.91", "wps": "90914.6", "ups": "0.35", "wpb": "262489", "bsz": "1773.9", "num_updates": "390800", "lr": "1.25e-05", "gnorm": "0.2", "loss_scale": "2", "train_wall": "264", "gb_free": "39.3", "wall": "736073"}
[2024-10-13 06:41:46,325][train_inner][INFO] - {"epoch": 817, "update": 816.601, "loss": "0.726", "ntokens": "263880", "nsentences": "1771.71", "wps": "234290", "ups": "0.89", "wpb": "263880", "bsz": "1771.7", "num_updates": "391000", "lr": "1.22283e-05", "gnorm": "0.195", "loss_scale": "2", "train_wall": "220", "gb_free": "39.3", "wall": "736298"}
[2024-10-13 06:45:52,745][fairseq_cli.train][INFO] - end of epoch 817 (average epoch stats below)
[2024-10-13 06:45:52,768][train][INFO] - {"epoch": 817, "train_loss": "0.726", "train_ntokens": "263494", "train_nsentences": "1753.71", "train_wps": "139058", "train_ups": "0.53", "train_wpb": "263494", "train_bsz": "1753.7", "train_num_updates": "391191", "train_lr": "1.19687e-05", "train_gnorm": "0.193", "train_loss_scale": "2", "train_train_wall": "588", "train_gb_free": "39.8", "train_wall": "736545"}
[2024-10-13 06:45:52,860][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 06:45:52,867][fairseq.trainer][INFO] - begin training epoch 818
[2024-10-13 06:45:52,868][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 06:51:39,283][train_inner][INFO] - {"epoch": 818, "update": 817.019, "loss": "0.725", "ntokens": "263127", "nsentences": "1713.13", "wps": "88757.2", "ups": "0.34", "wpb": "263127", "bsz": "1713.1", "num_updates": "391200", "lr": "1.19565e-05", "gnorm": "0.193", "loss_scale": "2", "train_wall": "259", "gb_free": "40.7", "wall": "736891"}
[2024-10-13 06:55:14,190][train_inner][INFO] - {"epoch": 818, "update": 817.436, "loss": "0.722", "ntokens": "264393", "nsentences": "1729.81", "wps": "246084", "ups": "0.93", "wpb": "264393", "bsz": "1729.8", "num_updates": "391400", "lr": "1.16848e-05", "gnorm": "0.192", "loss_scale": "4", "train_wall": "209", "gb_free": "40", "wall": "737106"}
[2024-10-13 06:59:37,556][train_inner][INFO] - {"epoch": 818, "update": 817.854, "loss": "0.728", "ntokens": "263490", "nsentences": "1804.9", "wps": "200123", "ups": "0.76", "wpb": "263490", "bsz": "1804.9", "num_updates": "391600", "lr": "1.1413e-05", "gnorm": "0.192", "loss_scale": "4", "train_wall": "257", "gb_free": "39.7", "wall": "737370"}
[2024-10-13 07:00:55,743][fairseq_cli.train][INFO] - end of epoch 818 (average epoch stats below)
[2024-10-13 07:00:55,767][train][INFO] - {"epoch": 818, "train_loss": "0.725", "train_ntokens": "263516", "train_nsentences": "1753.71", "train_wps": "139788", "train_ups": "0.53", "train_wpb": "263516", "train_bsz": "1753.7", "train_num_updates": "391670", "train_lr": "1.13179e-05", "train_gnorm": "0.192", "train_loss_scale": "4", "train_train_wall": "558", "train_gb_free": "40", "train_wall": "737448"}
[2024-10-13 07:00:55,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 07:00:56,004][fairseq.trainer][INFO] - begin training epoch 819
[2024-10-13 07:00:56,005][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 07:08:51,737][train_inner][INFO] - {"epoch": 819, "update": 818.271, "loss": "0.727", "ntokens": "262808", "nsentences": "1752.79", "wps": "94847.3", "ups": "0.36", "wpb": "262808", "bsz": "1752.8", "num_updates": "391800", "lr": "1.11413e-05", "gnorm": "0.19", "loss_scale": "4", "train_wall": "234", "gb_free": "39.8", "wall": "737924"}
[2024-10-13 07:12:57,270][train_inner][INFO] - {"epoch": 819, "update": 818.689, "loss": "0.724", "ntokens": "263994", "nsentences": "1730.77", "wps": "215058", "ups": "0.81", "wpb": "263994", "bsz": "1730.8", "num_updates": "392000", "lr": "1.08696e-05", "gnorm": "0.19", "loss_scale": "4", "train_wall": "240", "gb_free": "39.3", "wall": "738169"}
[2024-10-13 07:15:58,587][fairseq_cli.train][INFO] - end of epoch 819 (average epoch stats below)
[2024-10-13 07:15:58,604][train][INFO] - {"epoch": 819, "train_loss": "0.725", "train_ntokens": "263485", "train_nsentences": "1753.71", "train_wps": "139799", "train_ups": "0.53", "train_wpb": "263485", "train_bsz": "1753.7", "train_num_updates": "392149", "train_lr": "1.06671e-05", "train_gnorm": "0.19", "train_loss_scale": "4", "train_train_wall": "576", "train_gb_free": "39.6", "train_wall": "738351"}
[2024-10-13 07:15:58,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 07:15:58,737][fairseq.trainer][INFO] - begin training epoch 820
[2024-10-13 07:15:58,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 07:22:17,542][train_inner][INFO] - {"epoch": 820, "update": 819.106, "loss": "0.725", "ntokens": "262764", "nsentences": "1750.46", "wps": "93801.1", "ups": "0.36", "wpb": "262764", "bsz": "1750.5", "num_updates": "392200", "lr": "1.05978e-05", "gnorm": "0.189", "loss_scale": "4", "train_wall": "244", "gb_free": "39.7", "wall": "738730"}
[2024-10-13 07:25:58,406][train_inner][INFO] - {"epoch": 820, "update": 819.524, "loss": "0.725", "ntokens": "263919", "nsentences": "1772.69", "wps": "239004", "ups": "0.91", "wpb": "263919", "bsz": "1772.7", "num_updates": "392400", "lr": "1.03261e-05", "gnorm": "0.187", "loss_scale": "4", "train_wall": "216", "gb_free": "39.8", "wall": "738951"}
[2024-10-13 07:30:17,215][train_inner][INFO] - {"epoch": 820, "update": 819.942, "loss": "0.727", "ntokens": "263971", "nsentences": "1750.55", "wps": "204004", "ups": "0.77", "wpb": "263971", "bsz": "1750.5", "num_updates": "392600", "lr": "1.00543e-05", "gnorm": "0.188", "loss_scale": "4", "train_wall": "254", "gb_free": "40.8", "wall": "739209"}
[2024-10-13 07:31:00,527][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 820 @ 392628 updates
[2024-10-13 07:31:00,529][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 07:31:13,506][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 07:31:13,589][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 820 @ 392628 updates, score None) (writing took 13.061420905403793 seconds)
[2024-10-13 07:31:13,590][fairseq_cli.train][INFO] - end of epoch 820 (average epoch stats below)
[2024-10-13 07:31:13,592][train][INFO] - {"epoch": 820, "train_loss": "0.725", "train_ntokens": "263424", "train_nsentences": "1753.71", "train_wps": "137905", "train_ups": "0.52", "train_wpb": "263424", "train_bsz": "1753.7", "train_num_updates": "392628", "train_lr": "1.00163e-05", "train_gnorm": "0.189", "train_loss_scale": "4", "train_train_wall": "577", "train_gb_free": "39.2", "train_wall": "739266"}
[2024-10-13 07:31:13,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 07:31:13,684][fairseq.trainer][INFO] - begin training epoch 821
[2024-10-13 07:31:13,685][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 07:39:47,359][train_inner][INFO] - {"epoch": 821, "update": 820.359, "loss": "0.727", "ntokens": "262664", "nsentences": "1774.53", "wps": "92141.9", "ups": "0.35", "wpb": "262664", "bsz": "1774.5", "num_updates": "392800", "lr": "9.78261e-06", "gnorm": "0.188", "loss_scale": "4", "train_wall": "195", "gb_free": "39.8", "wall": "739780"}
[2024-10-13 07:43:38,536][train_inner][INFO] - {"epoch": 821, "update": 820.777, "loss": "0.723", "ntokens": "264221", "nsentences": "1738.45", "wps": "228620", "ups": "0.87", "wpb": "264221", "bsz": "1738.5", "num_updates": "393000", "lr": "9.51087e-06", "gnorm": "0.187", "loss_scale": "4", "train_wall": "172", "gb_free": "39.3", "wall": "740011"}
[2024-10-13 07:45:57,137][fairseq_cli.train][INFO] - end of epoch 821 (average epoch stats below)
[2024-10-13 07:45:57,178][train][INFO] - {"epoch": 821, "train_loss": "0.726", "train_ntokens": "263579", "train_nsentences": "1753.71", "train_wps": "142891", "train_ups": "0.54", "train_wpb": "263579", "train_bsz": "1753.7", "train_num_updates": "393107", "train_lr": "9.36549e-06", "train_gnorm": "0.189", "train_loss_scale": "4", "train_train_wall": "404", "train_gb_free": "39.6", "train_wall": "740149"}
[2024-10-13 07:45:57,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 07:45:57,460][fairseq.trainer][INFO] - begin training epoch 822
[2024-10-13 07:45:57,461][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 07:53:01,931][train_inner][INFO] - {"epoch": 822, "update": 821.194, "loss": "0.725", "ntokens": "262971", "nsentences": "1729.46", "wps": "93362.7", "ups": "0.36", "wpb": "262971", "bsz": "1729.5", "num_updates": "393200", "lr": "9.23913e-06", "gnorm": "0.191", "loss_scale": "4", "train_wall": "186", "gb_free": "40.3", "wall": "740574"}
[2024-10-13 07:54:54,538][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-13 07:57:14,029][train_inner][INFO] - {"epoch": 822, "update": 821.614, "loss": "0.725", "ntokens": "263767", "nsentences": "1750.42", "wps": "209308", "ups": "0.79", "wpb": "263767", "bsz": "1750.4", "num_updates": "393400", "lr": "8.96739e-06", "gnorm": "0.188", "loss_scale": "4", "train_wall": "163", "gb_free": "39.6", "wall": "740826"}
[2024-10-13 08:01:23,419][fairseq_cli.train][INFO] - end of epoch 822 (average epoch stats below)
[2024-10-13 08:01:23,453][train][INFO] - {"epoch": 822, "train_loss": "0.725", "train_ntokens": "263375", "train_nsentences": "1753.17", "train_wps": "135918", "train_ups": "0.52", "train_wpb": "263375", "train_bsz": "1753.2", "train_num_updates": "393585", "train_lr": "8.71603e-06", "train_gnorm": "0.188", "train_loss_scale": "4", "train_train_wall": "425", "train_gb_free": "39.6", "train_wall": "741076"}
[2024-10-13 08:01:23,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 08:01:23,853][fairseq.trainer][INFO] - begin training epoch 823
[2024-10-13 08:01:23,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 08:07:19,129][train_inner][INFO] - {"epoch": 823, "update": 822.031, "loss": "0.724", "ntokens": "262812", "nsentences": "1753.34", "wps": "86869.7", "ups": "0.33", "wpb": "262812", "bsz": "1753.3", "num_updates": "393600", "lr": "8.69565e-06", "gnorm": "0.19", "loss_scale": "4", "train_wall": "175", "gb_free": "40.1", "wall": "741431"}
[2024-10-13 08:10:58,397][train_inner][INFO] - {"epoch": 823, "update": 822.449, "loss": "0.728", "ntokens": "263543", "nsentences": "1812.71", "wps": "240435", "ups": "0.91", "wpb": "263543", "bsz": "1812.7", "num_updates": "393800", "lr": "8.42391e-06", "gnorm": "0.184", "loss_scale": "4", "train_wall": "212", "gb_free": "39.7", "wall": "741651"}
[2024-10-13 08:14:37,148][train_inner][INFO] - {"epoch": 823, "update": 822.866, "loss": "0.725", "ntokens": "264044", "nsentences": "1749.9", "wps": "241437", "ups": "0.91", "wpb": "264044", "bsz": "1749.9", "num_updates": "394000", "lr": "8.15217e-06", "gnorm": "0.188", "loss_scale": "4", "train_wall": "211", "gb_free": "40.3", "wall": "741869"}
[2024-10-13 08:15:53,819][fairseq_cli.train][INFO] - end of epoch 823 (average epoch stats below)
[2024-10-13 08:15:53,892][train][INFO] - {"epoch": 823, "train_loss": "0.725", "train_ntokens": "263547", "train_nsentences": "1753.71", "train_wps": "145058", "train_ups": "0.55", "train_wpb": "263547", "train_bsz": "1753.7", "train_num_updates": "394064", "train_lr": "8.06522e-06", "train_gnorm": "0.186", "train_loss_scale": "4", "train_train_wall": "516", "train_gb_free": "39.3", "train_wall": "741946"}
[2024-10-13 08:15:56,517][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 08:15:56,655][fairseq.trainer][INFO] - begin training epoch 824
[2024-10-13 08:15:56,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 08:23:59,459][train_inner][INFO] - {"epoch": 824, "update": 823.284, "loss": "0.724", "ntokens": "263188", "nsentences": "1725.36", "wps": "93618.9", "ups": "0.36", "wpb": "263188", "bsz": "1725.4", "num_updates": "394200", "lr": "7.88043e-06", "gnorm": "0.186", "loss_scale": "4", "train_wall": "223", "gb_free": "39.8", "wall": "742432"}
[2024-10-13 08:25:30,203][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 08:27:38,030][train_inner][INFO] - {"epoch": 824, "update": 823.704, "loss": "0.723", "ntokens": "264192", "nsentences": "1741.4", "wps": "241778", "ups": "0.92", "wpb": "264192", "bsz": "1741.4", "num_updates": "394400", "lr": "7.6087e-06", "gnorm": "0.185", "loss_scale": "2", "train_wall": "211", "gb_free": "39.3", "wall": "742650"}
[2024-10-13 08:30:33,355][fairseq_cli.train][INFO] - end of epoch 824 (average epoch stats below)
[2024-10-13 08:30:33,406][train][INFO] - {"epoch": 824, "train_loss": "0.725", "train_ntokens": "263645", "train_nsentences": "1753.67", "train_wps": "143351", "train_ups": "0.54", "train_wpb": "263645", "train_bsz": "1753.7", "train_num_updates": "394542", "train_lr": "7.41576e-06", "train_gnorm": "0.186", "train_loss_scale": "2", "train_train_wall": "528", "train_gb_free": "39.7", "train_wall": "742826"}
[2024-10-13 08:30:34,054][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 08:30:34,079][fairseq.trainer][INFO] - begin training epoch 825
[2024-10-13 08:30:34,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 08:37:12,644][train_inner][INFO] - {"epoch": 825, "update": 824.121, "loss": "0.725", "ntokens": "263005", "nsentences": "1747.37", "wps": "91549.1", "ups": "0.35", "wpb": "263005", "bsz": "1747.4", "num_updates": "394600", "lr": "7.33696e-06", "gnorm": "0.188", "loss_scale": "2", "train_wall": "248", "gb_free": "40.1", "wall": "743225"}
[2024-10-13 08:40:30,708][train_inner][INFO] - {"epoch": 825, "update": 824.539, "loss": "0.726", "ntokens": "264039", "nsentences": "1752.31", "wps": "266674", "ups": "1.01", "wpb": "264039", "bsz": "1752.3", "num_updates": "394800", "lr": "7.06522e-06", "gnorm": "0.183", "loss_scale": "2", "train_wall": "189", "gb_free": "39.6", "wall": "743423"}
[2024-10-13 08:44:24,218][train_inner][INFO] - {"epoch": 825, "update": 824.956, "loss": "0.726", "ntokens": "263870", "nsentences": "1773.02", "wps": "226016", "ups": "0.86", "wpb": "263870", "bsz": "1773", "num_updates": "395000", "lr": "6.79348e-06", "gnorm": "0.186", "loss_scale": "2", "train_wall": "140", "gb_free": "39.6", "wall": "743656"}
[2024-10-13 08:45:07,726][fairseq_cli.train][INFO] - end of epoch 825 (average epoch stats below)
[2024-10-13 08:45:07,767][train][INFO] - {"epoch": 825, "train_loss": "0.725", "train_ntokens": "263497", "train_nsentences": "1753.71", "train_wps": "144373", "train_ups": "0.55", "train_wpb": "263497", "train_bsz": "1753.7", "train_num_updates": "395021", "train_lr": "6.76495e-06", "train_gnorm": "0.185", "train_loss_scale": "2", "train_train_wall": "441", "train_gb_free": "39.8", "train_wall": "743700"}
[2024-10-13 08:45:07,949][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 08:45:07,995][fairseq.trainer][INFO] - begin training epoch 826
[2024-10-13 08:45:07,996][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 08:54:03,430][train_inner][INFO] - {"epoch": 826, "update": 825.374, "loss": "0.724", "ntokens": "262918", "nsentences": "1744.11", "wps": "90788.5", "ups": "0.35", "wpb": "262918", "bsz": "1744.1", "num_updates": "395200", "lr": "6.52174e-06", "gnorm": "0.185", "loss_scale": "2", "train_wall": "212", "gb_free": "39.1", "wall": "744236"}
[2024-10-13 08:58:19,210][train_inner][INFO] - {"epoch": 826, "update": 825.791, "loss": "0.728", "ntokens": "263385", "nsentences": "1793.77", "wps": "205983", "ups": "0.78", "wpb": "263385", "bsz": "1793.8", "num_updates": "395400", "lr": "6.25e-06", "gnorm": "0.186", "loss_scale": "2", "train_wall": "149", "gb_free": "39.6", "wall": "744491"}
[2024-10-13 09:00:16,917][fairseq_cli.train][INFO] - end of epoch 826 (average epoch stats below)
[2024-10-13 09:00:16,943][train][INFO] - {"epoch": 826, "train_loss": "0.725", "train_ntokens": "263350", "train_nsentences": "1753.71", "train_wps": "138757", "train_ups": "0.53", "train_wpb": "263350", "train_bsz": "1753.7", "train_num_updates": "395500", "train_lr": "6.11413e-06", "train_gnorm": "0.186", "train_loss_scale": "2", "train_train_wall": "410", "train_gb_free": "39.8", "train_wall": "744609"}
[2024-10-13 09:00:17,007][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 09:00:17,024][fairseq.trainer][INFO] - begin training epoch 827
[2024-10-13 09:00:17,025][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 09:07:47,491][train_inner][INFO] - {"epoch": 827, "update": 826.209, "loss": "0.723", "ntokens": "263068", "nsentences": "1707.84", "wps": "92590", "ups": "0.35", "wpb": "263068", "bsz": "1707.8", "num_updates": "395600", "lr": "5.97826e-06", "gnorm": "0.185", "loss_scale": "2", "train_wall": "163", "gb_free": "39.3", "wall": "745060"}
[2024-10-13 09:11:33,815][train_inner][INFO] - {"epoch": 827, "update": 826.626, "loss": "0.724", "ntokens": "263876", "nsentences": "1769.86", "wps": "233231", "ups": "0.88", "wpb": "263876", "bsz": "1769.9", "num_updates": "395800", "lr": "5.70652e-06", "gnorm": "0.183", "loss_scale": "2", "train_wall": "153", "gb_free": "39.6", "wall": "745286"}
[2024-10-13 09:15:03,173][fairseq_cli.train][INFO] - end of epoch 827 (average epoch stats below)
[2024-10-13 09:15:03,238][train][INFO] - {"epoch": 827, "train_loss": "0.725", "train_ntokens": "263498", "train_nsentences": "1753.71", "train_wps": "142410", "train_ups": "0.54", "train_wpb": "263498", "train_bsz": "1753.7", "train_num_updates": "395979", "train_lr": "5.46332e-06", "train_gnorm": "0.183", "train_loss_scale": "2", "train_train_wall": "364", "train_gb_free": "39.6", "train_wall": "745495"}
[2024-10-13 09:15:03,892][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 09:15:03,951][fairseq.trainer][INFO] - begin training epoch 828
[2024-10-13 09:15:03,952][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 09:21:19,415][train_inner][INFO] - {"epoch": 828, "update": 827.044, "loss": "0.725", "ntokens": "262787", "nsentences": "1749.08", "wps": "89754.4", "ups": "0.34", "wpb": "262787", "bsz": "1749.1", "num_updates": "396000", "lr": "5.43478e-06", "gnorm": "0.184", "loss_scale": "2", "train_wall": "172", "gb_free": "39.6", "wall": "745872"}
[2024-10-13 09:24:40,400][train_inner][INFO] - {"epoch": 828, "update": 827.461, "loss": "0.724", "ntokens": "264230", "nsentences": "1747.14", "wps": "262990", "ups": "1", "wpb": "264230", "bsz": "1747.1", "num_updates": "396200", "lr": "5.16304e-06", "gnorm": "0.182", "loss_scale": "2", "train_wall": "189", "gb_free": "39.6", "wall": "746073"}
[2024-10-13 09:28:30,288][train_inner][INFO] - {"epoch": 828, "update": 827.879, "loss": "0.725", "ntokens": "263539", "nsentences": "1776.1", "wps": "229317", "ups": "0.87", "wpb": "263539", "bsz": "1776.1", "num_updates": "396400", "lr": "4.8913e-06", "gnorm": "0.184", "loss_scale": "4", "train_wall": "174", "gb_free": "39.6", "wall": "746302"}
[2024-10-13 09:29:47,329][fairseq_cli.train][INFO] - end of epoch 828 (average epoch stats below)
[2024-10-13 09:29:47,343][train][INFO] - {"epoch": 828, "train_loss": "0.725", "train_ntokens": "263439", "train_nsentences": "1753.71", "train_wps": "142743", "train_ups": "0.54", "train_wpb": "263439", "train_bsz": "1753.7", "train_num_updates": "396458", "train_lr": "4.8125e-06", "train_gnorm": "0.184", "train_loss_scale": "4", "train_train_wall": "438", "train_gb_free": "39.3", "train_wall": "746380"}
[2024-10-13 09:29:47,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 09:29:47,624][fairseq.trainer][INFO] - begin training epoch 829
[2024-10-13 09:29:47,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 09:36:45,815][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-13 09:37:52,642][train_inner][INFO] - {"epoch": 829, "update": 828.299, "loss": "0.726", "ntokens": "262831", "nsentences": "1748.32", "wps": "93479.5", "ups": "0.36", "wpb": "262831", "bsz": "1748.3", "num_updates": "396600", "lr": "4.61957e-06", "gnorm": "0.182", "loss_scale": "2", "train_wall": "204", "gb_free": "39.8", "wall": "746865"}
[2024-10-13 09:41:46,591][train_inner][INFO] - {"epoch": 829, "update": 828.716, "loss": "0.724", "ntokens": "264060", "nsentences": "1728.9", "wps": "225763", "ups": "0.85", "wpb": "264060", "bsz": "1728.9", "num_updates": "396800", "lr": "4.34783e-06", "gnorm": "0.181", "loss_scale": "2", "train_wall": "229", "gb_free": "39.6", "wall": "747099"}
[2024-10-13 09:44:31,926][fairseq_cli.train][INFO] - end of epoch 829 (average epoch stats below)
[2024-10-13 09:44:31,966][train][INFO] - {"epoch": 829, "train_loss": "0.725", "train_ntokens": "263521", "train_nsentences": "1754.05", "train_wps": "142411", "train_ups": "0.54", "train_wpb": "263522", "train_bsz": "1754.1", "train_num_updates": "396936", "train_lr": "4.16304e-06", "train_gnorm": "0.18", "train_loss_scale": "2", "train_train_wall": "565", "train_gb_free": "39.2", "train_wall": "747264"}
[2024-10-13 09:44:32,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 09:44:32,228][fairseq.trainer][INFO] - begin training epoch 830
[2024-10-13 09:44:32,229][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 09:51:15,366][train_inner][INFO] - {"epoch": 830, "update": 829.134, "loss": "0.724", "ntokens": "262759", "nsentences": "1777.08", "wps": "92397", "ups": "0.35", "wpb": "262759", "bsz": "1777.1", "num_updates": "397000", "lr": "4.07609e-06", "gnorm": "0.18", "loss_scale": "2", "train_wall": "240", "gb_free": "39.3", "wall": "747668"}
[2024-10-13 09:54:47,069][train_inner][INFO] - {"epoch": 830, "update": 829.551, "loss": "0.725", "ntokens": "264215", "nsentences": "1735.98", "wps": "249624", "ups": "0.94", "wpb": "264215", "bsz": "1736", "num_updates": "397200", "lr": "3.80435e-06", "gnorm": "0.178", "loss_scale": "2", "train_wall": "206", "gb_free": "39.6", "wall": "747879"}
[2024-10-13 09:58:46,527][train_inner][INFO] - {"epoch": 830, "update": 829.969, "loss": "0.724", "ntokens": "263991", "nsentences": "1757.71", "wps": "220500", "ups": "0.84", "wpb": "263991", "bsz": "1757.7", "num_updates": "397400", "lr": "3.53261e-06", "gnorm": "0.179", "loss_scale": "2", "train_wall": "235", "gb_free": "39.2", "wall": "748119"}
[2024-10-13 09:59:27,325][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 830 @ 397415 updates
[2024-10-13 09:59:27,326][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 09:59:33,896][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt
[2024-10-13 09:59:34,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_last.pt (epoch 830 @ 397415 updates, score None) (writing took 6.815521535463631 seconds)
[2024-10-13 09:59:34,142][fairseq_cli.train][INFO] - end of epoch 830 (average epoch stats below)
[2024-10-13 09:59:34,150][train][INFO] - {"epoch": 830, "train_loss": "0.725", "train_ntokens": "263546", "train_nsentences": "1753.71", "train_wps": "139934", "train_ups": "0.53", "train_wpb": "263546", "train_bsz": "1753.7", "train_num_updates": "397415", "train_lr": "3.51223e-06", "train_gnorm": "0.18", "train_loss_scale": "2", "train_train_wall": "557", "train_gb_free": "40", "train_wall": "748166"}
[2024-10-13 09:59:34,235][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 09:59:34,245][fairseq.trainer][INFO] - begin training epoch 831
[2024-10-13 09:59:34,245][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 10:08:38,630][train_inner][INFO] - {"epoch": 831, "update": 830.386, "loss": "0.724", "ntokens": "262756", "nsentences": "1770.62", "wps": "88755", "ups": "0.34", "wpb": "262756", "bsz": "1770.6", "num_updates": "397600", "lr": "3.26087e-06", "gnorm": "0.181", "loss_scale": "2", "train_wall": "254", "gb_free": "39.7", "wall": "748711"}
[2024-10-13 10:12:17,636][train_inner][INFO] - {"epoch": 831, "update": 830.804, "loss": "0.723", "ntokens": "264245", "nsentences": "1736.86", "wps": "241354", "ups": "0.91", "wpb": "264245", "bsz": "1736.9", "num_updates": "397800", "lr": "2.98913e-06", "gnorm": "0.177", "loss_scale": "2", "train_wall": "214", "gb_free": "40", "wall": "748930"}
[2024-10-13 10:14:12,777][fairseq_cli.train][INFO] - end of epoch 831 (average epoch stats below)
[2024-10-13 10:14:12,782][train][INFO] - {"epoch": 831, "train_loss": "0.724", "train_ntokens": "263526", "train_nsentences": "1753.71", "train_wps": "143670", "train_ups": "0.55", "train_wpb": "263526", "train_bsz": "1753.7", "train_num_updates": "397894", "train_lr": "2.86141e-06", "train_gnorm": "0.18", "train_loss_scale": "2", "train_train_wall": "542", "train_gb_free": "40.3", "train_wall": "749045"}
[2024-10-13 10:14:12,875][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 10:14:12,892][fairseq.trainer][INFO] - begin training epoch 832
[2024-10-13 10:14:12,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 10:21:39,472][train_inner][INFO] - {"epoch": 832, "update": 831.221, "loss": "0.724", "ntokens": "262753", "nsentences": "1744.83", "wps": "93540.1", "ups": "0.36", "wpb": "262754", "bsz": "1744.8", "num_updates": "398000", "lr": "2.71739e-06", "gnorm": "0.18", "loss_scale": "2", "train_wall": "242", "gb_free": "39.6", "wall": "749492"}
[2024-10-13 10:25:33,241][train_inner][INFO] - {"epoch": 832, "update": 831.639, "loss": "0.727", "ntokens": "263682", "nsentences": "1799.32", "wps": "225623", "ups": "0.86", "wpb": "263682", "bsz": "1799.3", "num_updates": "398200", "lr": "2.44565e-06", "gnorm": "0.177", "loss_scale": "2", "train_wall": "229", "gb_free": "39.6", "wall": "749725"}
[2024-10-13 10:28:54,740][fairseq_cli.train][INFO] - end of epoch 832 (average epoch stats below)
[2024-10-13 10:28:54,757][train][INFO] - {"epoch": 832, "train_loss": "0.724", "train_ntokens": "263491", "train_nsentences": "1753.71", "train_wps": "143104", "train_ups": "0.54", "train_wpb": "263491", "train_bsz": "1753.7", "train_num_updates": "398373", "train_lr": "2.2106e-06", "train_gnorm": "0.178", "train_loss_scale": "2", "train_train_wall": "556", "train_gb_free": "39.6", "train_wall": "749927"}
[2024-10-13 10:28:54,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 10:28:54,844][fairseq.trainer][INFO] - begin training epoch 833
[2024-10-13 10:28:54,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 10:35:13,064][train_inner][INFO] - {"epoch": 833, "update": 832.056, "loss": "0.722", "ntokens": "263068", "nsentences": "1704.74", "wps": "90748.1", "ups": "0.34", "wpb": "263068", "bsz": "1704.7", "num_updates": "398400", "lr": "2.17391e-06", "gnorm": "0.178", "loss_scale": "2", "train_wall": "260", "gb_free": "41.1", "wall": "750305"}
[2024-10-13 10:36:05,247][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-13 10:38:43,701][train_inner][INFO] - {"epoch": 833, "update": 832.476, "loss": "0.725", "ntokens": "263793", "nsentences": "1754.24", "wps": "250496", "ups": "0.95", "wpb": "263793", "bsz": "1754.2", "num_updates": "398600", "lr": "1.90217e-06", "gnorm": "0.177", "loss_scale": "1", "train_wall": "205", "gb_free": "39.6", "wall": "750516"}
[2024-10-13 10:42:23,745][train_inner][INFO] - {"epoch": 833, "update": 832.894, "loss": "0.724", "ntokens": "264236", "nsentences": "1739.51", "wps": "240198", "ups": "0.91", "wpb": "264236", "bsz": "1739.5", "num_updates": "398800", "lr": "1.63043e-06", "gnorm": "0.177", "loss_scale": "1", "train_wall": "214", "gb_free": "40.5", "wall": "750736"}
[2024-10-13 10:43:37,528][fairseq_cli.train][INFO] - end of epoch 833 (average epoch stats below)
[2024-10-13 10:43:37,542][train][INFO] - {"epoch": 833, "train_loss": "0.724", "train_ntokens": "263456", "train_nsentences": "1751.54", "train_wps": "142659", "train_ups": "0.54", "train_wpb": "263456", "train_bsz": "1751.5", "train_num_updates": "398851", "train_lr": "1.56114e-06", "train_gnorm": "0.178", "train_loss_scale": "1", "train_train_wall": "553", "train_gb_free": "40.6", "train_wall": "750810"}
[2024-10-13 10:43:37,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 10:43:37,660][fairseq.trainer][INFO] - begin training epoch 834
[2024-10-13 10:43:37,661][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 10:51:56,325][train_inner][INFO] - {"epoch": 834, "update": 833.311, "loss": "0.727", "ntokens": "262518", "nsentences": "1791.95", "wps": "91700.4", "ups": "0.35", "wpb": "262518", "bsz": "1792", "num_updates": "399000", "lr": "1.3587e-06", "gnorm": "0.179", "loss_scale": "1", "train_wall": "220", "gb_free": "39.6", "wall": "751308"}
[2024-10-13 10:55:59,514][train_inner][INFO] - {"epoch": 834, "update": 833.729, "loss": "0.723", "ntokens": "264102", "nsentences": "1763.09", "wps": "217258", "ups": "0.82", "wpb": "264102", "bsz": "1763.1", "num_updates": "399200", "lr": "1.08696e-06", "gnorm": "0.178", "loss_scale": "1", "train_wall": "237", "gb_free": "39.3", "wall": "751552"}
[2024-10-13 10:58:33,829][fairseq_cli.train][INFO] - end of epoch 834 (average epoch stats below)
[2024-10-13 10:58:33,931][train][INFO] - {"epoch": 834, "train_loss": "0.724", "train_ntokens": "263603", "train_nsentences": "1753.71", "train_wps": "140862", "train_ups": "0.53", "train_wpb": "263603", "train_bsz": "1753.7", "train_num_updates": "399330", "train_lr": "9.10326e-07", "train_gnorm": "0.178", "train_loss_scale": "1", "train_train_wall": "533", "train_gb_free": "39.6", "train_wall": "751706"}
[2024-10-13 10:58:36,343][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 10:58:36,451][fairseq.trainer][INFO] - begin training epoch 835
[2024-10-13 10:58:36,451][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 11:05:23,686][train_inner][INFO] - {"epoch": 835, "update": 834.146, "loss": "0.723", "ntokens": "263086", "nsentences": "1728.93", "wps": "93268.7", "ups": "0.35", "wpb": "263086", "bsz": "1728.9", "num_updates": "399400", "lr": "8.15217e-07", "gnorm": "0.179", "loss_scale": "1", "train_wall": "237", "gb_free": "40.2", "wall": "752116"}
[2024-10-13 11:08:59,140][train_inner][INFO] - {"epoch": 835, "update": 834.564, "loss": "0.725", "ntokens": "263969", "nsentences": "1754.23", "wps": "245057", "ups": "0.93", "wpb": "263969", "bsz": "1754.2", "num_updates": "399600", "lr": "5.43478e-07", "gnorm": "0.175", "loss_scale": "1", "train_wall": "209", "gb_free": "39.7", "wall": "752331"}
[2024-10-13 11:12:54,299][train_inner][INFO] - {"epoch": 835, "update": 834.981, "loss": "0.722", "ntokens": "264188", "nsentences": "1756.18", "wps": "224736", "ups": "0.85", "wpb": "264188", "bsz": "1756.2", "num_updates": "399800", "lr": "2.71739e-07", "gnorm": "0.174", "loss_scale": "1", "train_wall": "230", "gb_free": "39.3", "wall": "752566"}
[2024-10-13 11:13:26,226][fairseq_cli.train][INFO] - end of epoch 835 (average epoch stats below)
[2024-10-13 11:13:26,397][train][INFO] - {"epoch": 835, "train_loss": "0.724", "train_ntokens": "263572", "train_nsentences": "1753.71", "train_wps": "141563", "train_ups": "0.54", "train_wpb": "263572", "train_bsz": "1753.7", "train_num_updates": "399809", "train_lr": "2.59511e-07", "train_gnorm": "0.176", "train_loss_scale": "1", "train_train_wall": "559", "train_gb_free": "39.7", "train_wall": "752598"}
[2024-10-13 11:13:26,537][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-13 11:13:26,583][fairseq.trainer][INFO] - begin training epoch 836
[2024-10-13 11:13:26,584][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-13 11:22:27,711][train_inner][INFO] - {"epoch": 836, "update": 835.399, "loss": "0.721", "ntokens": "263196", "nsentences": "1702.68", "wps": "91827.7", "ups": "0.35", "wpb": "263196", "bsz": "1702.7", "num_updates": "400000", "lr": "0", "gnorm": "0.175", "loss_scale": "1", "train_wall": "243", "gb_free": "39.6", "wall": "753140"}
[2024-10-13 11:22:27,722][fairseq_cli.train][INFO] - Stopping training due to num_updates: 400000 >= max_update: 400000
[2024-10-13 11:22:27,732][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 836 @ 400000 updates
[2024-10-13 11:22:27,733][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_836_400000.pt
[2024-10-13 11:22:31,810][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_836_400000.pt
[2024-10-13 11:22:37,475][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400/ckpt/checkpoint_836_400000.pt (epoch 836 @ 400000 updates, score None) (writing took 9.74314197152853 seconds)
[2024-10-13 11:22:37,476][fairseq_cli.train][INFO] - end of epoch 836 (average epoch stats below)
[2024-10-13 11:22:37,478][train][INFO] - {"epoch": 836, "train_loss": "0.72", "train_ntokens": "264387", "train_nsentences": "1708.13", "train_wps": "91639.2", "train_ups": "0.35", "train_wpb": "264387", "train_bsz": "1708.1", "train_num_updates": "400000", "train_lr": "0", "train_gnorm": "0.174", "train_loss_scale": "1", "train_train_wall": "213", "train_gb_free": "39.6", "train_wall": "753150"}
[2024-10-13 11:22:37,493][fairseq_cli.train][INFO] - done training in 753014.2 seconds
