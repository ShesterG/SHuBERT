[2024-10-05 23:22:18,850][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13382', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:22,236][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:22,238][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:22,238][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:22,238][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:22,247][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:22,248][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:22,334][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17844', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:22,671][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18747', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:22,968][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:25,777][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:25,787][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:25,787][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:25,787][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:25,788][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:25,789][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:26,087][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:30,607][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17725', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:31,941][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:31,971][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:31,971][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:31,971][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:31,973][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:31,973][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:32,279][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14250', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:33,670][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:33,824][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19208', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:35,431][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16075', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:35,664][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:10275', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-05 23:22:36,918][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:36,920][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:36,927][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:36,927][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:36,928][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:36,955][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:37,556][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:38,032][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:38,034][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:38,043][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:38,043][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:38,044][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:38,044][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:38,651][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:43,762][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:43,816][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:43,816][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:43,816][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:43,817][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:43,818][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:45,305][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:22:46,105][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:22:46,107][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:22:46,107][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:22:46,107][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:22:46,108][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:22:46,109][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:22:47,257][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:23:15,950][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-05 23:23:16,283][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-05 23:23:16,283][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-05 23:23:16,283][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-05 23:23:16,284][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-05 23:23:16,284][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-05 23:23:24,912][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:23:45,621][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:23:45,628][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,628][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,628][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,628][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,629][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,629][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,629][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,629][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:23:45,629][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:23:45,629][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:23:45,635][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:23:45,639][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:23:45,639][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:23:45,639][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:23:46,144][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:23:57,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:23:57,407][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:23:57,407][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:24:09,264][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,265][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,266][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:09,266][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:09,266][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:24:09,266][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:24:09,267][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:09,267][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:09,267][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:24:09,506][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:24:12,035][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:12,035][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,035][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:12,036][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:12,036][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:24:12,037][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:24:12,038][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:12,038][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:12,038][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:24:12,493][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:24:21,833][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:24:21,841][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:24:21,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:24:23,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:24:23,692][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:24:23,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:24:27,886][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:27,886][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,886][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,886][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,886][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,887][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,887][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,887][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,887][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:27,887][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:27,887][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:24:27,887][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:24:27,889][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:27,889][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:27,889][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:24:31,569][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:24:50,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:24:50,696][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:24:50,696][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,600][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,601][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,601][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,601][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:55,601][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:55,601][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:24:55,601][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:24:55,667][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:55,668][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:55,668][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:24:59,304][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:24:59,304][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:24:59,305][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:24:59,305][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:59,306][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:24:59,306][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:24:59,881][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:25:00,139][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:25:09,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:25:09,596][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:25:09,596][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:25:11,203][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:25:11,207][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:25:11,207][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,566][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,567][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,567][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,567][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:15,567][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:25:15,567][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:25:15,567][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:25:15,568][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:25:15,569][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:25:15,569][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:25:16,228][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:25:24,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:25:24,830][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:25:24,830][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-05 23:25:36,812][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-05 23:25:36,812][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-05 23:25:36,813][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-05 23:25:36,813][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:25:36,813][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-05 23:25:36,814][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-05 23:25:37,455][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-05 23:25:45,133][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:25:45,144][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-05 23:25:45,146][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:36:43,674][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-05 23:37:32,593][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-05 23:37:35,960][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-05 23:37:45,967][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-05 23:37:50,207][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-05 23:37:59,502][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-05 23:38:01,680][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-05 23:39:04,889][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-05 23:39:08,282][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-05 23:39:08,506][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-05 23:40:12,319][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 
[2024-10-05 23:40:12,323][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   5780 MiB |   5781 MiB |   9034 MiB |   3254 MiB |
|       from large pool |   5733 MiB |   5733 MiB |   8860 MiB |   3127 MiB |
|       from small pool |     46 MiB |    101 MiB |    174 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   5780 MiB |   5781 MiB |   9034 MiB |   3254 MiB |
|       from large pool |   5733 MiB |   5733 MiB |   8860 MiB |   3127 MiB |
|       from small pool |     46 MiB |    101 MiB |    174 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   5768 MiB |   5769 MiB |   9020 MiB |   3252 MiB |
|       from large pool |   5721 MiB |   5721 MiB |   8847 MiB |   3125 MiB |
|       from small pool |     46 MiB |    101 MiB |    173 MiB |    127 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   5926 MiB |   5926 MiB |   5926 MiB |      0 B   |
|       from large pool |   5824 MiB |   5824 MiB |   5824 MiB |      0 B   |
|       from small pool |    102 MiB |    102 MiB |    102 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory | 149221 KiB | 315871 KiB |   3144 MiB |   2998 MiB |
|       from large pool |  92647 KiB | 258494 KiB |   2918 MiB |   2827 MiB |
|       from small pool |  56574 KiB |  67543 KiB |    226 MiB |    171 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    1958    |    2499    |    2843    |     885    |
|       from large pool |     225    |     225    |     279    |      54    |
|       from small pool |    1733    |    2423    |    2564    |     831    |
|---------------------------------------------------------------------------|
| Active allocs         |    1958    |    2499    |    2843    |     885    |
|       from large pool |     225    |     225    |     279    |      54    |
|       from small pool |    1733    |    2423    |    2564    |     831    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     123    |     123    |     123    |       0    |
|       from large pool |      72    |      72    |      72    |       0    |
|       from small pool |      51    |      51    |      51    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     297    |     298    |     530    |     233    |
|       from large pool |      51    |      52    |      96    |      45    |
|       from small pool |     246    |     248    |     434    |     188    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,324][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,331][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,331][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,332][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,332][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,332][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,333][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:40:12,333][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-05 23:42:54,225][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 168.00 MiB. GPU 
[2024-10-05 23:42:54,244][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   2112 MiB |   7452 MiB |  90376 MiB |  88263 MiB |
|       from large pool |   2073 MiB |   7403 MiB |  89663 MiB |  87590 MiB |
|       from small pool |     39 MiB |    103 MiB |    712 MiB |    673 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   2112 MiB |   7452 MiB |  90376 MiB |  88263 MiB |
|       from large pool |   2073 MiB |   7403 MiB |  89663 MiB |  87590 MiB |
|       from small pool |     39 MiB |    103 MiB |    712 MiB |    673 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   2102 MiB |   7438 MiB |  90205 MiB |  88102 MiB |
|       from large pool |   2064 MiB |   7389 MiB |  89495 MiB |  87430 MiB |
|       from small pool |     38 MiB |    102 MiB |    709 MiB |    671 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   2504 MiB |   7926 MiB |  16034 MiB |  13530 MiB |
|       from large pool |   2404 MiB |   7822 MiB |  15930 MiB |  13526 MiB |
|       from small pool |    100 MiB |    104 MiB |    104 MiB |      4 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 222641 KiB |   3589 MiB |  55283 MiB |  55066 MiB |
|       from large pool | 160490 KiB |   3525 MiB |  54234 MiB |  54077 MiB |
|       from small pool |  62151 KiB |     68 MiB |   1049 MiB |    988 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    6017    |    8804    |   19088    |   13071    |
|       from large pool |     123    |     266    |    2175    |    2052    |
|       from small pool |    5894    |    8724    |   16913    |   11019    |
|---------------------------------------------------------------------------|
| Active allocs         |    6017    |    8804    |   19088    |   13071    |
|       from large pool |     123    |     266    |    2175    |    2052    |
|       from small pool |    5894    |    8724    |   16913    |   11019    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      76    |     134    |     192    |     116    |
|       from large pool |      26    |      83    |     140    |     114    |
|       from small pool |      50    |      52    |      52    |       2    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     751    |     752    |    4517    |    3766    |
|       from large pool |      18    |      75    |    1224    |    1206    |
|       from small pool |     733    |     734    |    3293    |    2560    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,245][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,245][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,246][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,246][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,246][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,247][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,259][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:42:54,259][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-05 23:44:16,846][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 
[2024-10-05 23:44:16,851][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   1042 MiB |   1128 MiB |   1198 MiB | 159738 KiB |
|       from large pool |   1004 MiB |   1090 MiB |   1090 MiB |  88452 KiB |
|       from small pool |     37 MiB |    101 MiB |    107 MiB |  71286 KiB |
|---------------------------------------------------------------------------|
| Active memory         |   1042 MiB |   1128 MiB |   1198 MiB | 159738 KiB |
|       from large pool |   1004 MiB |   1090 MiB |   1090 MiB |  88452 KiB |
|       from small pool |     37 MiB |    101 MiB |    107 MiB |  71286 KiB |
|---------------------------------------------------------------------------|
| Requested memory      |   1034 MiB |   1121 MiB |   1190 MiB | 159693 KiB |
|       from large pool |    997 MiB |   1083 MiB |   1083 MiB |  88452 KiB |
|       from small pool |     37 MiB |    101 MiB |    106 MiB |  71241 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   1220 MiB |   1220 MiB |   1220 MiB |      0 B   |
|       from large pool |   1118 MiB |   1118 MiB |   1118 MiB |      0 B   |
|       from small pool |    102 MiB |    102 MiB |    102 MiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  89955 KiB |  94912 KiB | 375188 KiB | 285233 KiB |
|       from large pool |  24203 KiB |  29102 KiB | 202397 KiB | 178194 KiB |
|       from small pool |  65752 KiB |  67543 KiB | 172791 KiB | 107039 KiB |
|---------------------------------------------------------------------------|
| Allocations           |    1771    |    2499    |    2535    |     764    |
|       from large pool |      89    |      92    |      92    |       3    |
|       from small pool |    1682    |    2423    |    2443    |     761    |
|---------------------------------------------------------------------------|
| Active allocs         |    1771    |    2499    |    2535    |     764    |
|       from large pool |      89    |      92    |      92    |       3    |
|       from small pool |    1682    |    2423    |    2443    |     761    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      75    |      75    |      75    |       0    |
|       from large pool |      24    |      24    |      24    |       0    |
|       from small pool |      51    |      51    |      51    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     260    |     263    |     448    |     188    |
|       from large pool |      12    |      15    |      24    |      12    |
|       from small pool |     248    |     248    |     424    |     176    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,855][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,856][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,856][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,864][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,864][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,865][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,865][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:16,865][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-05 23:44:19,351][fairseq.trainer][WARNING] - OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 180.00 MiB. GPU 
[2024-10-05 23:44:19,352][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   8081 MiB |   8082 MiB | 287605 MiB | 279524 MiB |
|       from large pool |   8025 MiB |   8025 MiB | 285503 MiB | 277478 MiB |
|       from small pool |     56 MiB |    103 MiB |   2102 MiB |   2046 MiB |
|---------------------------------------------------------------------------|
| Active memory         |   8081 MiB |   8082 MiB | 287605 MiB | 279524 MiB |
|       from large pool |   8025 MiB |   8025 MiB | 285503 MiB | 277478 MiB |
|       from small pool |     56 MiB |    103 MiB |   2102 MiB |   2046 MiB |
|---------------------------------------------------------------------------|
| Requested memory      |   8054 MiB |   8055 MiB | 287016 MiB | 278961 MiB |
|       from large pool |   7999 MiB |   7999 MiB | 284921 MiB | 276922 MiB |
|       from small pool |     55 MiB |    102 MiB |   2094 MiB |   2038 MiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   8502 MiB |   8506 MiB |  33144 MiB |  24642 MiB |
|       from large pool |   8398 MiB |   8398 MiB |  32996 MiB |  24598 MiB |
|       from small pool |    104 MiB |    108 MiB |    148 MiB |     44 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory | 430909 KiB |   2530 MiB | 194735 MiB | 194314 MiB |
|       from large pool | 381787 KiB |   2467 MiB | 191759 MiB | 191386 MiB |
|       from small pool |  49121 KiB |     72 MiB |   2975 MiB |   2927 MiB |
|---------------------------------------------------------------------------|
| Allocations           |    2880    |    3782    |   54338    |   51458    |
|       from large pool |     267    |     267    |    6913    |    6646    |
|       from small pool |    2613    |    3700    |   47425    |   44812    |
|---------------------------------------------------------------------------|
| Active allocs         |    2880    |    3782    |   54338    |   51458    |
|       from large pool |     267    |     267    |    6913    |    6646    |
|       from small pool |    2613    |    3700    |   47425    |   44812    |
|---------------------------------------------------------------------------|
| GPU reserved segments |     117    |     119    |     323    |     206    |
|       from large pool |      65    |      65    |     249    |     184    |
|       from small pool |      52    |      54    |      74    |      22    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     354    |     356    |   15394    |   15040    |
|       from large pool |      30    |      32    |    3939    |    3909    |
|       from small pool |     324    |     325    |   11455    |   11131    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,352][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,353][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,353][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,353][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,354][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,354][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,354][fairseq.trainer][WARNING] - |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

[2024-10-05 23:44:19,354][fairseq.trainer][WARNING] - attempting to recover from OOM in forward/backward pass
[2024-10-05 23:45:16,692][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-05 23:47:20,438][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-05 23:47:20,620][train][INFO] - {"epoch": 1, "train_loss": "5.688", "train_ntokens": "260273", "train_nsentences": "1787.56", "train_wps": "25009.4", "train_ups": "0.1", "train_wpb": "260273", "train_bsz": "1787.6", "train_num_updates": "45", "train_lr": "7.03125e-07", "train_gnorm": "1.368", "train_loss_scale": "16", "train_train_wall": "672", "train_gb_free": "39.3", "train_wall": "1415"}
[2024-10-05 23:47:20,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:47:20,965][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-05 23:47:20,967][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:54:46,853][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-05 23:54:50,165][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-05 23:54:50,204][train][INFO] - {"epoch": 2, "train_loss": "5.581", "train_ntokens": "260847", "train_nsentences": "1754.09", "train_wps": "27271.2", "train_ups": "0.1", "train_wpb": "260847", "train_bsz": "1754.1", "train_num_updates": "92", "train_lr": "1.4375e-06", "train_gnorm": "0.88", "train_loss_scale": "8", "train_train_wall": "127", "train_gb_free": "40.2", "train_wall": "1865"}
[2024-10-05 23:54:50,326][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:54:50,329][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-05 23:54:50,330][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:57:13,860][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-05 23:57:13,863][train][INFO] - {"epoch": 3, "train_loss": "5.495", "train_ntokens": "260590", "train_nsentences": "1750.04", "train_wps": "87070.6", "train_ups": "0.33", "train_wpb": "260590", "train_bsz": "1750", "train_num_updates": "140", "train_lr": "2.1875e-06", "train_gnorm": "0.639", "train_loss_scale": "8", "train_train_wall": "44", "train_gb_free": "40.2", "train_wall": "2008"}
[2024-10-05 23:57:13,925][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:57:13,928][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-05 23:57:13,929][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-05 23:59:24,565][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-05 23:59:24,568][train][INFO] - {"epoch": 4, "train_loss": "5.418", "train_ntokens": "260387", "train_nsentences": "1750.04", "train_wps": "95625.8", "train_ups": "0.37", "train_wpb": "260388", "train_bsz": "1750", "train_num_updates": "188", "train_lr": "2.9375e-06", "train_gnorm": "0.585", "train_loss_scale": "8", "train_train_wall": "64", "train_gb_free": "39.6", "train_wall": "2139"}
[2024-10-05 23:59:24,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-05 23:59:24,631][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-05 23:59:24,631][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:00:59,710][train_inner][INFO] - {"epoch": 5, "update": 4.25, "loss": "5.532", "ntokens": "260512", "nsentences": "1769.42", "wps": "40591.8", "ups": "0.16", "wpb": "260512", "bsz": "1769.4", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.843", "loss_scale": "8", "train_wall": "929", "gb_free": "39.6", "wall": "2234"}
[2024-10-06 00:01:31,195][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-06 00:01:31,197][train][INFO] - {"epoch": 5, "train_loss": "5.3", "train_ntokens": "260704", "train_nsentences": "1750.04", "train_wps": "98824", "train_ups": "0.38", "train_wpb": "260704", "train_bsz": "1750", "train_num_updates": "236", "train_lr": "3.6875e-06", "train_gnorm": "0.67", "train_loss_scale": "8", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "2266"}
[2024-10-06 00:01:31,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:01:31,324][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-06 00:01:31,325][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:03:38,910][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-06 00:03:38,926][train][INFO] - {"epoch": 6, "train_loss": "5.087", "train_ntokens": "260530", "train_nsentences": "1750.04", "train_wps": "97909.2", "train_ups": "0.38", "train_wpb": "260530", "train_bsz": "1750", "train_num_updates": "284", "train_lr": "4.4375e-06", "train_gnorm": "0.721", "train_loss_scale": "8", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "2393"}
[2024-10-06 00:03:39,082][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:03:39,097][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-06 00:03:39,098][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:05:45,237][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-06 00:05:45,240][train][INFO] - {"epoch": 7, "train_loss": "4.866", "train_ntokens": "260880", "train_nsentences": "1750.04", "train_wps": "99140.2", "train_ups": "0.38", "train_wpb": "260880", "train_bsz": "1750", "train_num_updates": "332", "train_lr": "5.1875e-06", "train_gnorm": "0.689", "train_loss_scale": "8", "train_train_wall": "50", "train_gb_free": "40.3", "train_wall": "2520"}
[2024-10-06 00:05:45,364][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:05:45,388][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-06 00:05:45,388][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:07:52,646][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-06 00:07:52,649][train][INFO] - {"epoch": 8, "train_loss": "4.672", "train_ntokens": "260534", "train_nsentences": "1750.04", "train_wps": "98155.6", "train_ups": "0.38", "train_wpb": "260534", "train_bsz": "1750", "train_num_updates": "380", "train_lr": "5.9375e-06", "train_gnorm": "0.656", "train_loss_scale": "8", "train_train_wall": "56", "train_gb_free": "39.5", "train_wall": "2647"}
[2024-10-06 00:07:52,708][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:07:52,712][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-06 00:07:52,712][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:09:34,187][train_inner][INFO] - {"epoch": 9, "update": 8.417, "loss": "4.917", "ntokens": "260679", "nsentences": "1735.42", "wps": "101338", "ups": "0.39", "wpb": "260679", "bsz": "1735.4", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.683", "loss_scale": "8", "train_wall": "213", "gb_free": "39.6", "wall": "2749"}
[2024-10-06 00:09:56,980][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-06 00:09:56,986][train][INFO] - {"epoch": 9, "train_loss": "4.509", "train_ntokens": "260494", "train_nsentences": "1750.04", "train_wps": "100567", "train_ups": "0.39", "train_wpb": "260494", "train_bsz": "1750", "train_num_updates": "428", "train_lr": "6.6875e-06", "train_gnorm": "0.598", "train_loss_scale": "8", "train_train_wall": "51", "train_gb_free": "39.2", "train_wall": "2771"}
[2024-10-06 00:09:57,075][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:09:57,087][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-06 00:09:57,087][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:12:04,196][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-10-06 00:12:04,200][train][INFO] - {"epoch": 10, "train_loss": "4.355", "train_ntokens": "260674", "train_nsentences": "1750.04", "train_wps": "98358.7", "train_ups": "0.38", "train_wpb": "260674", "train_bsz": "1750", "train_num_updates": "476", "train_lr": "7.4375e-06", "train_gnorm": "0.59", "train_loss_scale": "8", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "2899"}
[2024-10-06 00:12:04,341][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:12:04,345][fairseq.trainer][INFO] - begin training epoch 11
[2024-10-06 00:12:04,345][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:14:11,914][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-10-06 00:14:11,922][train][INFO] - {"epoch": 11, "train_loss": "4.215", "train_ntokens": "260504", "train_nsentences": "1750.04", "train_wps": "97903.9", "train_ups": "0.38", "train_wpb": "260504", "train_bsz": "1750", "train_num_updates": "524", "train_lr": "8.1875e-06", "train_gnorm": "0.573", "train_loss_scale": "8", "train_train_wall": "54", "train_gb_free": "39.6", "train_wall": "3026"}
[2024-10-06 00:14:12,020][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:14:12,036][fairseq.trainer][INFO] - begin training epoch 12
[2024-10-06 00:14:12,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:16:17,800][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-10-06 00:16:17,803][train][INFO] - {"epoch": 12, "train_loss": "4.096", "train_ntokens": "260679", "train_nsentences": "1750.04", "train_wps": "99402.5", "train_ups": "0.38", "train_wpb": "260679", "train_bsz": "1750", "train_num_updates": "572", "train_lr": "8.9375e-06", "train_gnorm": "0.567", "train_loss_scale": "8", "train_train_wall": "59", "train_gb_free": "39.3", "train_wall": "3152"}
[2024-10-06 00:16:17,858][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:16:17,863][fairseq.trainer][INFO] - begin training epoch 13
[2024-10-06 00:16:17,863][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:18:10,103][train_inner][INFO] - {"epoch": 13, "update": 12.583, "loss": "4.224", "ntokens": "260715", "nsentences": "1745.31", "wps": "101070", "ups": "0.39", "wpb": "260716", "bsz": "1745.3", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.575", "loss_scale": "8", "train_wall": "229", "gb_free": "40.6", "wall": "3264"}
[2024-10-06 00:18:28,389][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-10-06 00:18:28,392][train][INFO] - {"epoch": 13, "train_loss": "3.968", "train_ntokens": "261167", "train_nsentences": "1750.04", "train_wps": "95998.2", "train_ups": "0.37", "train_wpb": "261167", "train_bsz": "1750", "train_num_updates": "620", "train_lr": "9.6875e-06", "train_gnorm": "0.558", "train_loss_scale": "8", "train_train_wall": "53", "train_gb_free": "40.5", "train_wall": "3283"}
[2024-10-06 00:18:28,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:18:28,537][fairseq.trainer][INFO] - begin training epoch 14
[2024-10-06 00:18:28,538][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:20:35,588][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-10-06 00:20:35,596][train][INFO] - {"epoch": 14, "train_loss": "3.857", "train_ntokens": "260395", "train_nsentences": "1750.04", "train_wps": "98263.6", "train_ups": "0.38", "train_wpb": "260395", "train_bsz": "1750", "train_num_updates": "668", "train_lr": "1.04375e-05", "train_gnorm": "0.565", "train_loss_scale": "8", "train_train_wall": "44", "train_gb_free": "39.6", "train_wall": "3410"}
[2024-10-06 00:20:35,690][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:20:35,713][fairseq.trainer][INFO] - begin training epoch 15
[2024-10-06 00:20:35,714][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:22:43,280][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-10-06 00:22:43,284][train][INFO] - {"epoch": 15, "train_loss": "3.747", "train_ntokens": "260569", "train_nsentences": "1750.04", "train_wps": "97958.9", "train_ups": "0.38", "train_wpb": "260568", "train_bsz": "1750", "train_num_updates": "716", "train_lr": "1.11875e-05", "train_gnorm": "0.546", "train_loss_scale": "8", "train_train_wall": "30", "train_gb_free": "40", "train_wall": "3538"}
[2024-10-06 00:22:43,343][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:22:43,347][fairseq.trainer][INFO] - begin training epoch 16
[2024-10-06 00:22:43,347][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:24:52,768][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-10-06 00:24:52,771][train][INFO] - {"epoch": 16, "train_loss": "3.651", "train_ntokens": "260636", "train_nsentences": "1750.04", "train_wps": "96617.9", "train_ups": "0.37", "train_wpb": "260636", "train_bsz": "1750", "train_num_updates": "764", "train_lr": "1.19375e-05", "train_gnorm": "0.563", "train_loss_scale": "8", "train_train_wall": "58", "train_gb_free": "40.5", "train_wall": "3667"}
[2024-10-06 00:24:52,831][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:24:52,835][fairseq.trainer][INFO] - begin training epoch 17
[2024-10-06 00:24:52,835][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:26:48,146][train_inner][INFO] - {"epoch": 17, "update": 16.75, "loss": "3.737", "ntokens": "260553", "nsentences": "1751.76", "wps": "100592", "ups": "0.39", "wpb": "260553", "bsz": "1751.8", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.564", "loss_scale": "8", "train_wall": "186", "gb_free": "39.8", "wall": "3783"}
[2024-10-06 00:26:59,458][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-10-06 00:26:59,463][train][INFO] - {"epoch": 17, "train_loss": "3.555", "train_ntokens": "260381", "train_nsentences": "1750.04", "train_wps": "98654.2", "train_ups": "0.38", "train_wpb": "260381", "train_bsz": "1750", "train_num_updates": "812", "train_lr": "1.26875e-05", "train_gnorm": "0.598", "train_loss_scale": "8", "train_train_wall": "46", "train_gb_free": "39.3", "train_wall": "3794"}
[2024-10-06 00:26:59,626][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:26:59,649][fairseq.trainer][INFO] - begin training epoch 18
[2024-10-06 00:26:59,649][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:29:48,352][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-10-06 00:29:48,357][train][INFO] - {"epoch": 18, "train_loss": "3.454", "train_ntokens": "260488", "train_nsentences": "1750.04", "train_wps": "74032.7", "train_ups": "0.28", "train_wpb": "260488", "train_bsz": "1750", "train_num_updates": "860", "train_lr": "1.34375e-05", "train_gnorm": "0.616", "train_loss_scale": "8", "train_train_wall": "50", "train_gb_free": "39.8", "train_wall": "3963"}
[2024-10-06 00:29:48,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:29:48,494][fairseq.trainer][INFO] - begin training epoch 19
[2024-10-06 00:29:48,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:32:04,570][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-10-06 00:32:04,573][train][INFO] - {"epoch": 19, "train_loss": "3.368", "train_ntokens": "260967", "train_nsentences": "1750.04", "train_wps": "91961.2", "train_ups": "0.35", "train_wpb": "260967", "train_bsz": "1750", "train_num_updates": "908", "train_lr": "1.41875e-05", "train_gnorm": "0.615", "train_loss_scale": "8", "train_train_wall": "31", "train_gb_free": "39.3", "train_wall": "4099"}
[2024-10-06 00:32:04,713][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:32:04,723][fairseq.trainer][INFO] - begin training epoch 20
[2024-10-06 00:32:04,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:34:19,309][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 956 updates
[2024-10-06 00:34:19,311][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 00:34:23,531][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 00:34:23,533][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 20 @ 956 updates, score None) (writing took 4.224172183312476 seconds)
[2024-10-06 00:34:23,533][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-10-06 00:34:23,535][train][INFO] - {"epoch": 20, "train_loss": "3.262", "train_ntokens": "260697", "train_nsentences": "1750.04", "train_wps": "90051.4", "train_ups": "0.35", "train_wpb": "260697", "train_bsz": "1750", "train_num_updates": "956", "train_lr": "1.49375e-05", "train_gnorm": "0.853", "train_loss_scale": "8", "train_train_wall": "60", "train_gb_free": "39.8", "train_wall": "4238"}
[2024-10-06 00:34:23,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:34:23,610][fairseq.trainer][INFO] - begin training epoch 21
[2024-10-06 00:34:23,610][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:36:34,187][train_inner][INFO] - {"epoch": 21, "update": 20.917, "loss": "3.331", "ntokens": "260557", "nsentences": "1757.38", "wps": "88924.8", "ups": "0.34", "wpb": "260557", "bsz": "1757.4", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.69", "loss_scale": "8", "train_wall": "204", "gb_free": "39.8", "wall": "4369"}
[2024-10-06 00:36:35,988][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-10-06 00:36:35,992][train][INFO] - {"epoch": 21, "train_loss": "3.174", "train_ntokens": "260425", "train_nsentences": "1750.04", "train_wps": "94376.6", "train_ups": "0.36", "train_wpb": "260425", "train_bsz": "1750", "train_num_updates": "1004", "train_lr": "1.56875e-05", "train_gnorm": "0.691", "train_loss_scale": "8", "train_train_wall": "55", "train_gb_free": "39.5", "train_wall": "4370"}
[2024-10-06 00:36:36,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:36:36,132][fairseq.trainer][INFO] - begin training epoch 22
[2024-10-06 00:36:36,133][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:38:49,648][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-10-06 00:38:49,669][train][INFO] - {"epoch": 22, "train_loss": "3.083", "train_ntokens": "260396", "train_nsentences": "1750.04", "train_wps": "93514.1", "train_ups": "0.36", "train_wpb": "260396", "train_bsz": "1750", "train_num_updates": "1052", "train_lr": "1.64375e-05", "train_gnorm": "0.882", "train_loss_scale": "8", "train_train_wall": "49", "train_gb_free": "39.8", "train_wall": "4504"}
[2024-10-06 00:38:49,794][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:38:49,799][fairseq.trainer][INFO] - begin training epoch 23
[2024-10-06 00:38:49,800][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:41:03,941][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-10-06 00:41:03,958][train][INFO] - {"epoch": 23, "train_loss": "3", "train_ntokens": "260646", "train_nsentences": "1750.04", "train_wps": "93166.4", "train_ups": "0.36", "train_wpb": "260646", "train_bsz": "1750", "train_num_updates": "1100", "train_lr": "1.71875e-05", "train_gnorm": "0.812", "train_loss_scale": "8", "train_train_wall": "32", "train_gb_free": "40", "train_wall": "4638"}
[2024-10-06 00:41:04,085][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:41:04,102][fairseq.trainer][INFO] - begin training epoch 24
[2024-10-06 00:41:04,103][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:43:15,221][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-10-06 00:43:15,233][train][INFO] - {"epoch": 24, "train_loss": "2.916", "train_ntokens": "260495", "train_nsentences": "1750.04", "train_wps": "95250.5", "train_ups": "0.37", "train_wpb": "260494", "train_bsz": "1750", "train_num_updates": "1148", "train_lr": "1.79375e-05", "train_gnorm": "0.984", "train_loss_scale": "8", "train_train_wall": "45", "train_gb_free": "40.2", "train_wall": "4770"}
[2024-10-06 00:43:15,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:43:15,391][fairseq.trainer][INFO] - begin training epoch 25
[2024-10-06 00:43:15,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:45:26,534][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-10-06 00:45:26,546][train][INFO] - {"epoch": 25, "train_loss": "2.83", "train_ntokens": "260947", "train_nsentences": "1750.04", "train_wps": "95388.5", "train_ups": "0.37", "train_wpb": "260947", "train_bsz": "1750", "train_num_updates": "1196", "train_lr": "1.86875e-05", "train_gnorm": "0.963", "train_loss_scale": "8", "train_train_wall": "50", "train_gb_free": "40.5", "train_wall": "4901"}
[2024-10-06 00:45:26,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:45:26,706][fairseq.trainer][INFO] - begin training epoch 26
[2024-10-06 00:45:26,706][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:47:10,195][train_inner][INFO] - {"epoch": 26, "update": 25.083, "loss": "2.957", "ntokens": "260572", "nsentences": "1755.36", "wps": "81940.9", "ups": "0.31", "wpb": "260572", "bsz": "1755.4", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.914", "loss_scale": "8", "train_wall": "210", "gb_free": "40.6", "wall": "5005"}
[2024-10-06 00:47:37,631][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-10-06 00:47:37,634][train][INFO] - {"epoch": 26, "train_loss": "2.755", "train_ntokens": "260270", "train_nsentences": "1750.04", "train_wps": "95304.4", "train_ups": "0.37", "train_wpb": "260270", "train_bsz": "1750", "train_num_updates": "1244", "train_lr": "1.94375e-05", "train_gnorm": "1.018", "train_loss_scale": "8", "train_train_wall": "59", "train_gb_free": "39.7", "train_wall": "5032"}
[2024-10-06 00:47:37,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:47:37,778][fairseq.trainer][INFO] - begin training epoch 27
[2024-10-06 00:47:37,779][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:49:51,158][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-10-06 00:49:51,161][train][INFO] - {"epoch": 27, "train_loss": "2.685", "train_ntokens": "260864", "train_nsentences": "1750.04", "train_wps": "93776.9", "train_ups": "0.36", "train_wpb": "260864", "train_bsz": "1750", "train_num_updates": "1292", "train_lr": "2.01875e-05", "train_gnorm": "1.217", "train_loss_scale": "8", "train_train_wall": "31", "train_gb_free": "39.7", "train_wall": "5166"}
[2024-10-06 00:49:51,238][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:49:51,248][fairseq.trainer][INFO] - begin training epoch 28
[2024-10-06 00:49:51,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:52:02,514][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-10-06 00:52:02,523][train][INFO] - {"epoch": 28, "train_loss": "2.614", "train_ntokens": "260564", "train_nsentences": "1750.04", "train_wps": "95216.3", "train_ups": "0.37", "train_wpb": "260564", "train_bsz": "1750", "train_num_updates": "1340", "train_lr": "2.09375e-05", "train_gnorm": "0.944", "train_loss_scale": "8", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "5297"}
[2024-10-06 00:52:02,693][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:52:02,705][fairseq.trainer][INFO] - begin training epoch 29
[2024-10-06 00:52:02,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:54:13,502][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-10-06 00:54:13,506][train][INFO] - {"epoch": 29, "train_loss": "2.544", "train_ntokens": "260958", "train_nsentences": "1750.04", "train_wps": "95633.5", "train_ups": "0.37", "train_wpb": "260958", "train_bsz": "1750", "train_num_updates": "1388", "train_lr": "2.16875e-05", "train_gnorm": "1.119", "train_loss_scale": "8", "train_train_wall": "52", "train_gb_free": "39.8", "train_wall": "5428"}
[2024-10-06 00:54:13,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:54:13,612][fairseq.trainer][INFO] - begin training epoch 30
[2024-10-06 00:54:13,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:56:01,373][train_inner][INFO] - {"epoch": 30, "update": 29.25, "loss": "2.638", "ntokens": "260827", "nsentences": "1744.51", "wps": "98208.8", "ups": "0.38", "wpb": "260827", "bsz": "1744.5", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.078", "loss_scale": "8", "train_wall": "203", "gb_free": "40.2", "wall": "5536"}
[2024-10-06 00:56:25,620][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-10-06 00:56:25,623][train][INFO] - {"epoch": 30, "train_loss": "2.484", "train_ntokens": "260589", "train_nsentences": "1750.04", "train_wps": "94677.7", "train_ups": "0.36", "train_wpb": "260589", "train_bsz": "1750", "train_num_updates": "1436", "train_lr": "2.24375e-05", "train_gnorm": "1.165", "train_loss_scale": "8", "train_train_wall": "57", "train_gb_free": "39.2", "train_wall": "5560"}
[2024-10-06 00:56:25,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:56:25,790][fairseq.trainer][INFO] - begin training epoch 31
[2024-10-06 00:56:25,792][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 00:58:40,363][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-10-06 00:58:40,371][train][INFO] - {"epoch": 31, "train_loss": "2.423", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "92815.3", "train_ups": "0.36", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "1484", "train_lr": "2.31875e-05", "train_gnorm": "1.136", "train_loss_scale": "8", "train_train_wall": "55", "train_gb_free": "39.4", "train_wall": "5695"}
[2024-10-06 00:58:40,461][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 00:58:40,468][fairseq.trainer][INFO] - begin training epoch 32
[2024-10-06 00:58:40,469][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:00:58,381][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-10-06 01:00:58,384][train][INFO] - {"epoch": 32, "train_loss": "2.369", "train_ntokens": "260822", "train_nsentences": "1750.04", "train_wps": "90714.1", "train_ups": "0.35", "train_wpb": "260822", "train_bsz": "1750", "train_num_updates": "1532", "train_lr": "2.39375e-05", "train_gnorm": "1.152", "train_loss_scale": "8", "train_train_wall": "59", "train_gb_free": "39.6", "train_wall": "5833"}
[2024-10-06 01:00:58,562][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:00:58,579][fairseq.trainer][INFO] - begin training epoch 33
[2024-10-06 01:00:58,580][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:03:12,892][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-10-06 01:03:12,910][train][INFO] - {"epoch": 33, "train_loss": "2.318", "train_ntokens": "260773", "train_nsentences": "1750.04", "train_wps": "93054.7", "train_ups": "0.36", "train_wpb": "260773", "train_bsz": "1750", "train_num_updates": "1580", "train_lr": "2.46875e-05", "train_gnorm": "1.38", "train_loss_scale": "8", "train_train_wall": "63", "train_gb_free": "39.8", "train_wall": "5967"}
[2024-10-06 01:03:13,055][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:03:13,061][fairseq.trainer][INFO] - begin training epoch 34
[2024-10-06 01:03:13,062][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:05:07,331][train_inner][INFO] - {"epoch": 34, "update": 33.417, "loss": "2.38", "ntokens": "260546", "nsentences": "1759.88", "wps": "95446.3", "ups": "0.37", "wpb": "260546", "bsz": "1759.9", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.228", "loss_scale": "8", "train_wall": "244", "gb_free": "42", "wall": "6082"}
[2024-10-06 01:05:13,527][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-06 01:05:24,929][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-10-06 01:05:24,931][train][INFO] - {"epoch": 34, "train_loss": "2.266", "train_ntokens": "260853", "train_nsentences": "1748.81", "train_wps": "92867.4", "train_ups": "0.36", "train_wpb": "260853", "train_bsz": "1748.8", "train_num_updates": "1627", "train_lr": "2.54219e-05", "train_gnorm": "1.345", "train_loss_scale": "4", "train_train_wall": "61", "train_gb_free": "39.8", "train_wall": "6099"}
[2024-10-06 01:05:25,086][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:05:25,094][fairseq.trainer][INFO] - begin training epoch 35
[2024-10-06 01:05:25,095][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:07:35,628][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-10-06 01:07:35,639][train][INFO] - {"epoch": 35, "train_loss": "2.219", "train_ntokens": "260952", "train_nsentences": "1750.04", "train_wps": "95831.8", "train_ups": "0.37", "train_wpb": "260952", "train_bsz": "1750", "train_num_updates": "1675", "train_lr": "2.61719e-05", "train_gnorm": "1.457", "train_loss_scale": "4", "train_train_wall": "59", "train_gb_free": "39.7", "train_wall": "6230"}
[2024-10-06 01:07:35,765][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:07:35,774][fairseq.trainer][INFO] - begin training epoch 36
[2024-10-06 01:07:35,775][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:09:44,637][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-10-06 01:09:44,640][train][INFO] - {"epoch": 36, "train_loss": "2.172", "train_ntokens": "260868", "train_nsentences": "1750.04", "train_wps": "97068.1", "train_ups": "0.37", "train_wpb": "260868", "train_bsz": "1750", "train_num_updates": "1723", "train_lr": "2.69219e-05", "train_gnorm": "1.546", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "6359"}
[2024-10-06 01:09:44,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:09:44,703][fairseq.trainer][INFO] - begin training epoch 37
[2024-10-06 01:09:44,703][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:11:51,699][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-10-06 01:11:51,715][train][INFO] - {"epoch": 37, "train_loss": "2.131", "train_ntokens": "260721", "train_nsentences": "1750.04", "train_wps": "98484.3", "train_ups": "0.38", "train_wpb": "260721", "train_bsz": "1750", "train_num_updates": "1771", "train_lr": "2.76719e-05", "train_gnorm": "1.257", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "6486"}
[2024-10-06 01:11:51,833][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:11:51,841][fairseq.trainer][INFO] - begin training epoch 38
[2024-10-06 01:11:51,842][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:13:40,915][train_inner][INFO] - {"epoch": 38, "update": 37.604, "loss": "2.173", "ntokens": "260962", "nsentences": "1746.2", "wps": "101624", "ups": "0.39", "wpb": "260962", "bsz": "1746.2", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.395", "loss_scale": "4", "train_wall": "201", "gb_free": "39.2", "wall": "6595"}
[2024-10-06 01:13:58,353][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-10-06 01:13:58,361][train][INFO] - {"epoch": 38, "train_loss": "2.084", "train_ntokens": "260689", "train_nsentences": "1750.04", "train_wps": "98809.8", "train_ups": "0.38", "train_wpb": "260689", "train_bsz": "1750", "train_num_updates": "1819", "train_lr": "2.84219e-05", "train_gnorm": "1.278", "train_loss_scale": "4", "train_train_wall": "37", "train_gb_free": "40.1", "train_wall": "6613"}
[2024-10-06 01:13:58,472][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:13:58,476][fairseq.trainer][INFO] - begin training epoch 39
[2024-10-06 01:13:58,476][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:16:03,190][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-10-06 01:16:03,205][train][INFO] - {"epoch": 39, "train_loss": "2.046", "train_ntokens": "260618", "train_nsentences": "1750.04", "train_wps": "100204", "train_ups": "0.38", "train_wpb": "260618", "train_bsz": "1750", "train_num_updates": "1867", "train_lr": "2.91719e-05", "train_gnorm": "1.693", "train_loss_scale": "4", "train_train_wall": "46", "train_gb_free": "39.2", "train_wall": "6738"}
[2024-10-06 01:16:03,387][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:16:03,397][fairseq.trainer][INFO] - begin training epoch 40
[2024-10-06 01:16:03,397][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:18:33,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 1915 updates
[2024-10-06 01:18:33,062][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 01:18:37,377][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 01:18:37,401][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 40 @ 1915 updates, score None) (writing took 4.340660162270069 seconds)
[2024-10-06 01:18:37,402][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-10-06 01:18:37,405][train][INFO] - {"epoch": 40, "train_loss": "2.008", "train_ntokens": "260506", "train_nsentences": "1750.04", "train_wps": "81094.5", "train_ups": "0.31", "train_wpb": "260506", "train_bsz": "1750", "train_num_updates": "1915", "train_lr": "2.99219e-05", "train_gnorm": "1.291", "train_loss_scale": "4", "train_train_wall": "70", "train_gb_free": "40.6", "train_wall": "6892"}
[2024-10-06 01:18:37,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:18:37,589][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-06 01:18:37,590][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:20:24,489][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-06 01:20:54,383][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-10-06 01:20:54,388][train][INFO] - {"epoch": 41, "train_loss": "1.979", "train_ntokens": "260681", "train_nsentences": "1762.62", "train_wps": "89444.1", "train_ups": "0.34", "train_wpb": "260681", "train_bsz": "1762.6", "train_num_updates": "1962", "train_lr": "3.06563e-05", "train_gnorm": "1.599", "train_loss_scale": "2", "train_train_wall": "40", "train_gb_free": "45.1", "train_wall": "7029"}
[2024-10-06 01:20:54,615][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:20:54,627][fairseq.trainer][INFO] - begin training epoch 42
[2024-10-06 01:20:54,628][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:23:01,671][train_inner][INFO] - {"epoch": 42, "update": 41.792, "loss": "2.004", "ntokens": "260595", "nsentences": "1738.87", "wps": "92949", "ups": "0.36", "wpb": "260595", "bsz": "1738.9", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.466", "loss_scale": "2", "train_wall": "211", "gb_free": "39.6", "wall": "7156"}
[2024-10-06 01:23:12,834][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-10-06 01:23:12,837][train][INFO] - {"epoch": 42, "train_loss": "1.94", "train_ntokens": "260504", "train_nsentences": "1750.04", "train_wps": "90317.8", "train_ups": "0.35", "train_wpb": "260504", "train_bsz": "1750", "train_num_updates": "2010", "train_lr": "3.14062e-05", "train_gnorm": "1.376", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "39.7", "train_wall": "7167"}
[2024-10-06 01:23:12,971][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:23:12,975][fairseq.trainer][INFO] - begin training epoch 43
[2024-10-06 01:23:12,976][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:25:26,673][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-10-06 01:25:26,679][train][INFO] - {"epoch": 43, "train_loss": "1.913", "train_ntokens": "260648", "train_nsentences": "1750.04", "train_wps": "93479.1", "train_ups": "0.36", "train_wpb": "260648", "train_bsz": "1750", "train_num_updates": "2058", "train_lr": "3.21562e-05", "train_gnorm": "1.406", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "40.1", "train_wall": "7301"}
[2024-10-06 01:25:26,801][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:25:26,805][fairseq.trainer][INFO] - begin training epoch 44
[2024-10-06 01:25:26,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:27:42,155][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-10-06 01:27:42,161][train][INFO] - {"epoch": 44, "train_loss": "1.876", "train_ntokens": "260836", "train_nsentences": "1750.04", "train_wps": "92414.2", "train_ups": "0.35", "train_wpb": "260836", "train_bsz": "1750", "train_num_updates": "2106", "train_lr": "3.29062e-05", "train_gnorm": "1.069", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.1", "train_wall": "7437"}
[2024-10-06 01:27:42,271][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:27:42,288][fairseq.trainer][INFO] - begin training epoch 45
[2024-10-06 01:27:42,288][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:29:51,653][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-10-06 01:29:51,659][train][INFO] - {"epoch": 45, "train_loss": "1.852", "train_ntokens": "260677", "train_nsentences": "1750.04", "train_wps": "96624.7", "train_ups": "0.37", "train_wpb": "260677", "train_bsz": "1750", "train_num_updates": "2154", "train_lr": "3.36563e-05", "train_gnorm": "1.495", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "40", "train_wall": "7566"}
[2024-10-06 01:29:51,771][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:29:51,774][fairseq.trainer][INFO] - begin training epoch 46
[2024-10-06 01:29:51,775][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:32:07,131][train_inner][INFO] - {"epoch": 46, "update": 45.958, "loss": "1.87", "ntokens": "260471", "nsentences": "1761.13", "wps": "95512", "ups": "0.37", "wpb": "260471", "bsz": "1761.1", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.5", "loss_scale": "2", "train_wall": "222", "gb_free": "39.3", "wall": "7701"}
[2024-10-06 01:32:07,666][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-10-06 01:32:07,667][train][INFO] - {"epoch": 46, "train_loss": "1.823", "train_ntokens": "260140", "train_nsentences": "1750.04", "train_wps": "91810.1", "train_ups": "0.35", "train_wpb": "260140", "train_bsz": "1750", "train_num_updates": "2202", "train_lr": "3.44062e-05", "train_gnorm": "2.071", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.1", "train_wall": "7702"}
[2024-10-06 01:32:07,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:32:07,828][fairseq.trainer][INFO] - begin training epoch 47
[2024-10-06 01:32:07,828][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:34:19,648][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-10-06 01:34:19,654][train][INFO] - {"epoch": 47, "train_loss": "1.801", "train_ntokens": "261131", "train_nsentences": "1750.04", "train_wps": "94968.8", "train_ups": "0.36", "train_wpb": "261131", "train_bsz": "1750", "train_num_updates": "2250", "train_lr": "3.51563e-05", "train_gnorm": "1.431", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.8", "train_wall": "7834"}
[2024-10-06 01:34:19,730][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:34:19,735][fairseq.trainer][INFO] - begin training epoch 48
[2024-10-06 01:34:19,736][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:36:27,529][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-10-06 01:36:27,535][train][INFO] - {"epoch": 48, "train_loss": "1.775", "train_ntokens": "260574", "train_nsentences": "1750.04", "train_wps": "97808.5", "train_ups": "0.38", "train_wpb": "260574", "train_bsz": "1750", "train_num_updates": "2298", "train_lr": "3.59063e-05", "train_gnorm": "1.627", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "7962"}
[2024-10-06 01:36:27,645][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:36:27,662][fairseq.trainer][INFO] - begin training epoch 49
[2024-10-06 01:36:27,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:38:36,516][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-10-06 01:38:36,521][train][INFO] - {"epoch": 49, "train_loss": "1.751", "train_ntokens": "260654", "train_nsentences": "1750.04", "train_wps": "97000.3", "train_ups": "0.37", "train_wpb": "260654", "train_bsz": "1750", "train_num_updates": "2346", "train_lr": "3.66562e-05", "train_gnorm": "1.267", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.6", "train_wall": "8091"}
[2024-10-06 01:38:36,631][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:38:36,647][fairseq.trainer][INFO] - begin training epoch 50
[2024-10-06 01:38:36,647][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:40:44,445][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-10-06 01:40:44,451][train][INFO] - {"epoch": 50, "train_loss": "1.73", "train_ntokens": "260426", "train_nsentences": "1750.04", "train_wps": "97715", "train_ups": "0.38", "train_wpb": "260426", "train_bsz": "1750", "train_num_updates": "2394", "train_lr": "3.74063e-05", "train_gnorm": "1.271", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "39.3", "train_wall": "8219"}
[2024-10-06 01:40:44,576][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:40:44,580][fairseq.trainer][INFO] - begin training epoch 51
[2024-10-06 01:40:44,580][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:42:27,353][train_inner][INFO] - {"epoch": 51, "update": 50.125, "loss": "1.764", "ntokens": "260716", "nsentences": "1751.49", "wps": "84074.2", "ups": "0.32", "wpb": "260716", "bsz": "1751.5", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.414", "loss_scale": "2", "train_wall": "237", "gb_free": "39.6", "wall": "8322"}
[2024-10-06 01:42:55,311][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-10-06 01:42:55,314][train][INFO] - {"epoch": 51, "train_loss": "1.712", "train_ntokens": "260724", "train_nsentences": "1750.04", "train_wps": "95634.5", "train_ups": "0.37", "train_wpb": "260724", "train_bsz": "1750", "train_num_updates": "2442", "train_lr": "3.81563e-05", "train_gnorm": "1.34", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.3", "train_wall": "8350"}
[2024-10-06 01:42:55,465][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:42:55,471][fairseq.trainer][INFO] - begin training epoch 52
[2024-10-06 01:42:55,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:45:06,971][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-10-06 01:45:06,989][train][INFO] - {"epoch": 52, "train_loss": "1.684", "train_ntokens": "260480", "train_nsentences": "1750.04", "train_wps": "94955.9", "train_ups": "0.36", "train_wpb": "260480", "train_bsz": "1750", "train_num_updates": "2490", "train_lr": "3.89063e-05", "train_gnorm": "1.481", "train_loss_scale": "2", "train_train_wall": "44", "train_gb_free": "39.6", "train_wall": "8481"}
[2024-10-06 01:45:07,110][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:45:07,114][fairseq.trainer][INFO] - begin training epoch 53
[2024-10-06 01:45:07,114][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:47:18,685][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-10-06 01:47:18,688][train][INFO] - {"epoch": 53, "train_loss": "1.667", "train_ntokens": "260659", "train_nsentences": "1750.04", "train_wps": "95003.6", "train_ups": "0.36", "train_wpb": "260659", "train_bsz": "1750", "train_num_updates": "2538", "train_lr": "3.96562e-05", "train_gnorm": "1.294", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.7", "train_wall": "8613"}
[2024-10-06 01:47:18,821][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:47:18,826][fairseq.trainer][INFO] - begin training epoch 54
[2024-10-06 01:47:18,827][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:49:30,270][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-10-06 01:49:30,281][train][INFO] - {"epoch": 54, "train_loss": "1.65", "train_ntokens": "260479", "train_nsentences": "1750.04", "train_wps": "95017.1", "train_ups": "0.36", "train_wpb": "260479", "train_bsz": "1750", "train_num_updates": "2586", "train_lr": "4.04062e-05", "train_gnorm": "1.559", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "40", "train_wall": "8745"}
[2024-10-06 01:49:30,433][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:49:30,442][fairseq.trainer][INFO] - begin training epoch 55
[2024-10-06 01:49:30,442][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:51:18,596][train_inner][INFO] - {"epoch": 55, "update": 54.292, "loss": "1.673", "ntokens": "260537", "nsentences": "1741.95", "wps": "98092", "ups": "0.38", "wpb": "260537", "bsz": "1742", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.439", "loss_scale": "2", "train_wall": "211", "gb_free": "40.1", "wall": "8853"}
[2024-10-06 01:51:41,384][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-10-06 01:51:41,385][train][INFO] - {"epoch": 55, "train_loss": "1.631", "train_ntokens": "260741", "train_nsentences": "1750.04", "train_wps": "95464.6", "train_ups": "0.37", "train_wpb": "260740", "train_bsz": "1750", "train_num_updates": "2634", "train_lr": "4.11563e-05", "train_gnorm": "1.527", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.5", "train_wall": "8876"}
[2024-10-06 01:51:41,509][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:51:41,515][fairseq.trainer][INFO] - begin training epoch 56
[2024-10-06 01:51:41,515][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:53:53,143][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-10-06 01:53:53,147][train][INFO] - {"epoch": 56, "train_loss": "1.612", "train_ntokens": "260779", "train_nsentences": "1750.04", "train_wps": "95002", "train_ups": "0.36", "train_wpb": "260779", "train_bsz": "1750", "train_num_updates": "2682", "train_lr": "4.19062e-05", "train_gnorm": "1.406", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "39.7", "train_wall": "9008"}
[2024-10-06 01:53:53,215][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:53:53,226][fairseq.trainer][INFO] - begin training epoch 57
[2024-10-06 01:53:53,227][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:56:05,164][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-10-06 01:56:05,179][train][INFO] - {"epoch": 57, "train_loss": "1.6", "train_ntokens": "260694", "train_nsentences": "1750.04", "train_wps": "94776.9", "train_ups": "0.36", "train_wpb": "260694", "train_bsz": "1750", "train_num_updates": "2730", "train_lr": "4.26563e-05", "train_gnorm": "1.781", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.4", "train_wall": "9140"}
[2024-10-06 01:56:05,295][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:56:05,309][fairseq.trainer][INFO] - begin training epoch 58
[2024-10-06 01:56:05,309][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 01:58:15,301][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-10-06 01:58:15,310][train][INFO] - {"epoch": 58, "train_loss": "1.583", "train_ntokens": "260674", "train_nsentences": "1750.04", "train_wps": "96158.6", "train_ups": "0.37", "train_wpb": "260674", "train_bsz": "1750", "train_num_updates": "2778", "train_lr": "4.34063e-05", "train_gnorm": "1.066", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.3", "train_wall": "9270"}
[2024-10-06 01:58:15,456][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 01:58:15,459][fairseq.trainer][INFO] - begin training epoch 59
[2024-10-06 01:58:15,460][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:00:03,228][train_inner][INFO] - {"epoch": 59, "update": 58.458, "loss": "1.602", "ntokens": "260763", "nsentences": "1756.42", "wps": "99408.8", "ups": "0.38", "wpb": "260763", "bsz": "1756.4", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.396", "loss_scale": "2", "train_wall": "208", "gb_free": "39.7", "wall": "9378"}
[2024-10-06 02:00:22,124][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-10-06 02:00:22,128][train][INFO] - {"epoch": 59, "train_loss": "1.57", "train_ntokens": "260648", "train_nsentences": "1750.04", "train_wps": "98656.9", "train_ups": "0.38", "train_wpb": "260648", "train_bsz": "1750", "train_num_updates": "2826", "train_lr": "4.41562e-05", "train_gnorm": "1.369", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "40", "train_wall": "9396"}
[2024-10-06 02:00:22,205][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:00:22,222][fairseq.trainer][INFO] - begin training epoch 60
[2024-10-06 02:00:22,223][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:02:33,478][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 2874 updates
[2024-10-06 02:02:33,479][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 02:02:37,122][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 02:02:37,137][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 60 @ 2874 updates, score None) (writing took 3.6589167369529605 seconds)
[2024-10-06 02:02:37,138][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-10-06 02:02:37,140][train][INFO] - {"epoch": 60, "train_loss": "1.555", "train_ntokens": "260619", "train_nsentences": "1750.04", "train_wps": "92658.4", "train_ups": "0.36", "train_wpb": "260619", "train_bsz": "1750", "train_num_updates": "2874", "train_lr": "4.49063e-05", "train_gnorm": "1.287", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "40.1", "train_wall": "9532"}
[2024-10-06 02:02:37,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:02:37,193][fairseq.trainer][INFO] - begin training epoch 61
[2024-10-06 02:02:37,193][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:04:54,048][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-10-06 02:04:54,059][train][INFO] - {"epoch": 61, "train_loss": "1.538", "train_ntokens": "260499", "train_nsentences": "1750.04", "train_wps": "91325.8", "train_ups": "0.35", "train_wpb": "260499", "train_bsz": "1750", "train_num_updates": "2922", "train_lr": "4.56563e-05", "train_gnorm": "1.146", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "40.1", "train_wall": "9668"}
[2024-10-06 02:04:54,257][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:04:54,261][fairseq.trainer][INFO] - begin training epoch 62
[2024-10-06 02:04:54,261][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:08:18,038][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-10-06 02:08:18,054][train][INFO] - {"epoch": 62, "train_loss": "1.528", "train_ntokens": "260640", "train_nsentences": "1750.04", "train_wps": "61331.3", "train_ups": "0.24", "train_wpb": "260640", "train_bsz": "1750", "train_num_updates": "2970", "train_lr": "4.64063e-05", "train_gnorm": "1.719", "train_loss_scale": "2", "train_train_wall": "97", "train_gb_free": "40.3", "train_wall": "9872"}
[2024-10-06 02:08:18,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:08:18,248][fairseq.trainer][INFO] - begin training epoch 63
[2024-10-06 02:08:18,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:10:37,862][train_inner][INFO] - {"epoch": 63, "update": 62.625, "loss": "1.541", "ntokens": "260606", "nsentences": "1760.22", "wps": "82129.4", "ups": "0.32", "wpb": "260606", "bsz": "1760.2", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.362", "loss_scale": "2", "train_wall": "301", "gb_free": "39.3", "wall": "10012"}
[2024-10-06 02:10:50,733][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-10-06 02:10:50,737][train][INFO] - {"epoch": 63, "train_loss": "1.516", "train_ntokens": "260827", "train_nsentences": "1750.04", "train_wps": "81999.4", "train_ups": "0.31", "train_wpb": "260827", "train_bsz": "1750", "train_num_updates": "3018", "train_lr": "4.71562e-05", "train_gnorm": "1.081", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.9", "train_wall": "10025"}
[2024-10-06 02:10:50,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:10:50,978][fairseq.trainer][INFO] - begin training epoch 64
[2024-10-06 02:10:50,979][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:13:25,570][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-10-06 02:13:25,576][train][INFO] - {"epoch": 64, "train_loss": "1.506", "train_ntokens": "260598", "train_nsentences": "1750.04", "train_wps": "80787.2", "train_ups": "0.31", "train_wpb": "260598", "train_bsz": "1750", "train_num_updates": "3066", "train_lr": "4.79062e-05", "train_gnorm": "1.604", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.6", "train_wall": "10180"}
[2024-10-06 02:13:25,755][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:13:25,773][fairseq.trainer][INFO] - begin training epoch 65
[2024-10-06 02:13:25,773][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:16:11,859][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-10-06 02:16:11,865][train][INFO] - {"epoch": 65, "train_loss": "1.491", "train_ntokens": "260705", "train_nsentences": "1750.04", "train_wps": "75254.9", "train_ups": "0.29", "train_wpb": "260705", "train_bsz": "1750", "train_num_updates": "3114", "train_lr": "4.86563e-05", "train_gnorm": "1.32", "train_loss_scale": "2", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "10346"}
[2024-10-06 02:16:12,016][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:16:12,020][fairseq.trainer][INFO] - begin training epoch 66
[2024-10-06 02:16:12,020][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:18:31,435][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-10-06 02:18:31,453][train][INFO] - {"epoch": 66, "train_loss": "1.482", "train_ntokens": "260769", "train_nsentences": "1750.04", "train_wps": "89677.3", "train_ups": "0.34", "train_wpb": "260769", "train_bsz": "1750", "train_num_updates": "3162", "train_lr": "4.94062e-05", "train_gnorm": "1.201", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.7", "train_wall": "10486"}
[2024-10-06 02:18:31,591][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:18:31,598][fairseq.trainer][INFO] - begin training epoch 67
[2024-10-06 02:18:31,599][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:20:53,591][train_inner][INFO] - {"epoch": 67, "update": 66.792, "loss": "1.489", "ntokens": "260595", "nsentences": "1742.64", "wps": "84648.6", "ups": "0.32", "wpb": "260595", "bsz": "1742.6", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.378", "loss_scale": "2", "train_wall": "254", "gb_free": "39.6", "wall": "10628"}
[2024-10-06 02:21:04,197][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-10-06 02:21:04,200][train][INFO] - {"epoch": 67, "train_loss": "1.469", "train_ntokens": "260426", "train_nsentences": "1750.04", "train_wps": "81839.5", "train_ups": "0.31", "train_wpb": "260426", "train_bsz": "1750", "train_num_updates": "3210", "train_lr": "5.01563e-05", "train_gnorm": "1.564", "train_loss_scale": "2", "train_train_wall": "80", "train_gb_free": "40.3", "train_wall": "10639"}
[2024-10-06 02:21:04,321][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:21:04,327][fairseq.trainer][INFO] - begin training epoch 68
[2024-10-06 02:21:04,327][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:23:24,042][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-10-06 02:23:24,058][train][INFO] - {"epoch": 68, "train_loss": "1.462", "train_ntokens": "260875", "train_nsentences": "1750.04", "train_wps": "89535.5", "train_ups": "0.34", "train_wpb": "260875", "train_bsz": "1750", "train_num_updates": "3258", "train_lr": "5.09063e-05", "train_gnorm": "1.204", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.3", "train_wall": "10778"}
[2024-10-06 02:23:24,202][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:23:24,210][fairseq.trainer][INFO] - begin training epoch 69
[2024-10-06 02:23:24,211][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:25:54,476][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-10-06 02:25:54,484][train][INFO] - {"epoch": 69, "train_loss": "1.454", "train_ntokens": "260843", "train_nsentences": "1750.04", "train_wps": "83235.8", "train_ups": "0.32", "train_wpb": "260843", "train_bsz": "1750", "train_num_updates": "3306", "train_lr": "5.16562e-05", "train_gnorm": "1.16", "train_loss_scale": "2", "train_train_wall": "76", "train_gb_free": "39.3", "train_wall": "10929"}
[2024-10-06 02:25:54,645][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:25:54,670][fairseq.trainer][INFO] - begin training epoch 70
[2024-10-06 02:25:54,670][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:28:27,091][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2024-10-06 02:28:27,098][train][INFO] - {"epoch": 70, "train_loss": "1.445", "train_ntokens": "260599", "train_nsentences": "1750.04", "train_wps": "81965.9", "train_ups": "0.31", "train_wpb": "260600", "train_bsz": "1750", "train_num_updates": "3354", "train_lr": "5.24063e-05", "train_gnorm": "1.441", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "40.1", "train_wall": "11081"}
[2024-10-06 02:28:27,271][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:28:27,296][fairseq.trainer][INFO] - begin training epoch 71
[2024-10-06 02:28:27,296][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:31:13,186][train_inner][INFO] - {"epoch": 71, "update": 70.958, "loss": "1.451", "ntokens": "260793", "nsentences": "1743.22", "wps": "84184.8", "ups": "0.32", "wpb": "260793", "bsz": "1743.2", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.304", "loss_scale": "2", "train_wall": "269", "gb_free": "39.3", "wall": "11248"}
[2024-10-06 02:31:13,646][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2024-10-06 02:31:13,649][train][INFO] - {"epoch": 71, "train_loss": "1.437", "train_ntokens": "260538", "train_nsentences": "1750.04", "train_wps": "75088.4", "train_ups": "0.29", "train_wpb": "260538", "train_bsz": "1750", "train_num_updates": "3402", "train_lr": "5.31563e-05", "train_gnorm": "1.394", "train_loss_scale": "2", "train_train_wall": "50", "train_gb_free": "39.2", "train_wall": "11248"}
[2024-10-06 02:31:13,777][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:31:13,794][fairseq.trainer][INFO] - begin training epoch 72
[2024-10-06 02:31:13,795][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:34:10,837][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2024-10-06 02:34:10,842][train][INFO] - {"epoch": 72, "train_loss": "1.424", "train_ntokens": "260437", "train_nsentences": "1750.04", "train_wps": "70550.9", "train_ups": "0.27", "train_wpb": "260437", "train_bsz": "1750", "train_num_updates": "3450", "train_lr": "5.39063e-05", "train_gnorm": "1.079", "train_loss_scale": "2", "train_train_wall": "87", "train_gb_free": "39.1", "train_wall": "11425"}
[2024-10-06 02:34:10,974][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:34:10,992][fairseq.trainer][INFO] - begin training epoch 73
[2024-10-06 02:34:10,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:36:57,648][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2024-10-06 02:36:57,653][train][INFO] - {"epoch": 73, "train_loss": "1.418", "train_ntokens": "260990", "train_nsentences": "1750.04", "train_wps": "75102.2", "train_ups": "0.29", "train_wpb": "260990", "train_bsz": "1750", "train_num_updates": "3498", "train_lr": "5.46563e-05", "train_gnorm": "1.273", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.9", "train_wall": "11592"}
[2024-10-06 02:36:57,862][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:36:57,865][fairseq.trainer][INFO] - begin training epoch 74
[2024-10-06 02:36:57,865][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:39:57,773][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2024-10-06 02:39:57,776][train][INFO] - {"epoch": 74, "train_loss": "1.411", "train_ntokens": "260613", "train_nsentences": "1750.04", "train_wps": "69450.4", "train_ups": "0.27", "train_wpb": "260613", "train_bsz": "1750", "train_num_updates": "3546", "train_lr": "5.54063e-05", "train_gnorm": "1.128", "train_loss_scale": "2", "train_train_wall": "100", "train_gb_free": "40.1", "train_wall": "11772"}
[2024-10-06 02:39:57,933][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:39:57,947][fairseq.trainer][INFO] - begin training epoch 75
[2024-10-06 02:39:57,948][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:42:39,857][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2024-10-06 02:42:39,859][train][INFO] - {"epoch": 75, "train_loss": "1.4", "train_ntokens": "260513", "train_nsentences": "1750.04", "train_wps": "77151.1", "train_ups": "0.3", "train_wpb": "260513", "train_bsz": "1750", "train_num_updates": "3594", "train_lr": "5.61562e-05", "train_gnorm": "1.259", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.6", "train_wall": "11934"}
[2024-10-06 02:42:39,961][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:42:39,964][fairseq.trainer][INFO] - begin training epoch 76
[2024-10-06 02:42:39,965][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:44:13,571][train_inner][INFO] - {"epoch": 76, "update": 75.125, "loss": "1.412", "ntokens": "260725", "nsentences": "1748.26", "wps": "66820.4", "ups": "0.26", "wpb": "260725", "bsz": "1748.3", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.203", "loss_scale": "2", "train_wall": "292", "gb_free": "40.7", "wall": "12028"}
[2024-10-06 02:44:48,112][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2024-10-06 02:44:48,123][train][INFO] - {"epoch": 76, "train_loss": "1.394", "train_ntokens": "260418", "train_nsentences": "1750.04", "train_wps": "97465.3", "train_ups": "0.37", "train_wpb": "260418", "train_bsz": "1750", "train_num_updates": "3642", "train_lr": "5.69062e-05", "train_gnorm": "1.564", "train_loss_scale": "2", "train_train_wall": "42", "train_gb_free": "39.3", "train_wall": "12062"}
[2024-10-06 02:44:48,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:44:48,272][fairseq.trainer][INFO] - begin training epoch 77
[2024-10-06 02:44:48,273][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:47:04,293][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2024-10-06 02:47:04,298][train][INFO] - {"epoch": 77, "train_loss": "1.384", "train_ntokens": "260948", "train_nsentences": "1750.04", "train_wps": "91983.4", "train_ups": "0.35", "train_wpb": "260948", "train_bsz": "1750", "train_num_updates": "3690", "train_lr": "5.76563e-05", "train_gnorm": "1.116", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.8", "train_wall": "12199"}
[2024-10-06 02:47:04,460][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:47:04,464][fairseq.trainer][INFO] - begin training epoch 78
[2024-10-06 02:47:04,464][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:49:45,384][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2024-10-06 02:49:45,389][train][INFO] - {"epoch": 78, "train_loss": "1.382", "train_ntokens": "261090", "train_nsentences": "1750.04", "train_wps": "77797.7", "train_ups": "0.3", "train_wpb": "261090", "train_bsz": "1750", "train_num_updates": "3738", "train_lr": "5.84063e-05", "train_gnorm": "1.172", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.4", "train_wall": "12360"}
[2024-10-06 02:49:45,562][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:49:45,574][fairseq.trainer][INFO] - begin training epoch 79
[2024-10-06 02:49:45,575][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:51:55,656][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-06 02:52:17,470][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2024-10-06 02:52:17,474][train][INFO] - {"epoch": 79, "train_loss": "1.375", "train_ntokens": "260421", "train_nsentences": "1750.19", "train_wps": "80481.7", "train_ups": "0.31", "train_wpb": "260421", "train_bsz": "1750.2", "train_num_updates": "3785", "train_lr": "5.91406e-05", "train_gnorm": "1.479", "train_loss_scale": "1", "train_train_wall": "72", "train_gb_free": "39.6", "train_wall": "12512"}
[2024-10-06 02:52:17,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:52:17,609][fairseq.trainer][INFO] - begin training epoch 80
[2024-10-06 02:52:17,609][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:54:26,676][train_inner][INFO] - {"epoch": 80, "update": 79.312, "loss": "1.382", "ntokens": "260725", "nsentences": "1745.81", "wps": "85052.7", "ups": "0.33", "wpb": "260725", "bsz": "1745.8", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.302", "loss_scale": "1", "train_wall": "248", "gb_free": "40.2", "wall": "12641"}
[2024-10-06 02:54:58,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 3833 updates
[2024-10-06 02:54:58,937][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 02:55:03,601][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 02:55:03,603][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 80 @ 3833 updates, score None) (writing took 4.667431192472577 seconds)
[2024-10-06 02:55:03,604][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2024-10-06 02:55:03,607][train][INFO] - {"epoch": 80, "train_loss": "1.364", "train_ntokens": "260803", "train_nsentences": "1750.04", "train_wps": "75354.8", "train_ups": "0.29", "train_wpb": "260804", "train_bsz": "1750", "train_num_updates": "3833", "train_lr": "5.98906e-05", "train_gnorm": "1.157", "train_loss_scale": "1", "train_train_wall": "71", "train_gb_free": "40.1", "train_wall": "12678"}
[2024-10-06 02:55:03,783][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:55:03,791][fairseq.trainer][INFO] - begin training epoch 81
[2024-10-06 02:55:03,791][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 02:57:44,521][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2024-10-06 02:57:44,525][train][INFO] - {"epoch": 81, "train_loss": "1.358", "train_ntokens": "260792", "train_nsentences": "1750.04", "train_wps": "77793", "train_ups": "0.3", "train_wpb": "260792", "train_bsz": "1750", "train_num_updates": "3881", "train_lr": "6.06406e-05", "train_gnorm": "1.087", "train_loss_scale": "1", "train_train_wall": "59", "train_gb_free": "40.1", "train_wall": "12839"}
[2024-10-06 02:57:44,660][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 02:57:44,663][fairseq.trainer][INFO] - begin training epoch 82
[2024-10-06 02:57:44,663][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:00:33,283][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2024-10-06 03:00:33,289][train][INFO] - {"epoch": 82, "train_loss": "1.354", "train_ntokens": "260773", "train_nsentences": "1750.04", "train_wps": "74170.6", "train_ups": "0.28", "train_wpb": "260773", "train_bsz": "1750", "train_num_updates": "3929", "train_lr": "6.13906e-05", "train_gnorm": "1.488", "train_loss_scale": "1", "train_train_wall": "81", "train_gb_free": "40.1", "train_wall": "13008"}
[2024-10-06 03:00:33,504][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:00:33,508][fairseq.trainer][INFO] - begin training epoch 83
[2024-10-06 03:00:33,508][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:03:20,328][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2024-10-06 03:03:20,333][train][INFO] - {"epoch": 83, "train_loss": "1.347", "train_ntokens": "261050", "train_nsentences": "1750.04", "train_wps": "75014.8", "train_ups": "0.29", "train_wpb": "261050", "train_bsz": "1750", "train_num_updates": "3977", "train_lr": "6.21406e-05", "train_gnorm": "1.089", "train_loss_scale": "1", "train_train_wall": "65", "train_gb_free": "40.3", "train_wall": "13175"}
[2024-10-06 03:03:20,512][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:03:20,517][fairseq.trainer][INFO] - begin training epoch 84
[2024-10-06 03:03:20,518][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:05:59,288][train_inner][INFO] - {"epoch": 84, "update": 83.479, "loss": "1.354", "ntokens": "260743", "nsentences": "1763.61", "wps": "75294.6", "ups": "0.29", "wpb": "260743", "bsz": "1763.6", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.196", "loss_scale": "1", "train_wall": "290", "gb_free": "39.3", "wall": "13334"}
[2024-10-06 03:06:14,033][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2024-10-06 03:06:14,035][train][INFO] - {"epoch": 84, "train_loss": "1.339", "train_ntokens": "260362", "train_nsentences": "1750.04", "train_wps": "71948.6", "train_ups": "0.28", "train_wpb": "260362", "train_bsz": "1750", "train_num_updates": "4025", "train_lr": "6.28906e-05", "train_gnorm": "1.083", "train_loss_scale": "1", "train_train_wall": "71", "train_gb_free": "39.7", "train_wall": "13348"}
[2024-10-06 03:06:14,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:06:14,259][fairseq.trainer][INFO] - begin training epoch 85
[2024-10-06 03:06:14,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:08:50,618][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2024-10-06 03:08:50,621][train][INFO] - {"epoch": 85, "train_loss": "1.33", "train_ntokens": "260686", "train_nsentences": "1750.04", "train_wps": "79912.6", "train_ups": "0.31", "train_wpb": "260686", "train_bsz": "1750", "train_num_updates": "4073", "train_lr": "6.36406e-05", "train_gnorm": "1.121", "train_loss_scale": "1", "train_train_wall": "76", "train_gb_free": "39.3", "train_wall": "13505"}
[2024-10-06 03:08:50,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:08:50,820][fairseq.trainer][INFO] - begin training epoch 86
[2024-10-06 03:08:50,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:11:42,215][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2024-10-06 03:11:42,221][train][INFO] - {"epoch": 86, "train_loss": "1.335", "train_ntokens": "260984", "train_nsentences": "1750.04", "train_wps": "73004.2", "train_ups": "0.28", "train_wpb": "260984", "train_bsz": "1750", "train_num_updates": "4121", "train_lr": "6.43906e-05", "train_gnorm": "1.695", "train_loss_scale": "1", "train_train_wall": "38", "train_gb_free": "40.2", "train_wall": "13677"}
[2024-10-06 03:11:42,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:11:42,396][fairseq.trainer][INFO] - begin training epoch 87
[2024-10-06 03:11:42,397][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:14:23,291][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2024-10-06 03:14:23,295][train][INFO] - {"epoch": 87, "train_loss": "1.322", "train_ntokens": "260729", "train_nsentences": "1750.04", "train_wps": "77698", "train_ups": "0.3", "train_wpb": "260728", "train_bsz": "1750", "train_num_updates": "4169", "train_lr": "6.51406e-05", "train_gnorm": "1.083", "train_loss_scale": "1", "train_train_wall": "70", "train_gb_free": "39.8", "train_wall": "13838"}
[2024-10-06 03:14:23,420][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:14:23,443][fairseq.trainer][INFO] - begin training epoch 88
[2024-10-06 03:14:23,444][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:17:06,660][train_inner][INFO] - {"epoch": 88, "update": 87.646, "loss": "1.327", "ntokens": "260571", "nsentences": "1747.35", "wps": "78089.3", "ups": "0.3", "wpb": "260571", "bsz": "1747.3", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.272", "loss_scale": "1", "train_wall": "228", "gb_free": "40.7", "wall": "14001"}
[2024-10-06 03:17:19,845][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2024-10-06 03:17:19,848][train][INFO] - {"epoch": 88, "train_loss": "1.316", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "70835.3", "train_ups": "0.27", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "4217", "train_lr": "6.58906e-05", "train_gnorm": "1.274", "train_loss_scale": "1", "train_train_wall": "43", "train_gb_free": "39.2", "train_wall": "14014"}
[2024-10-06 03:17:20,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:17:20,009][fairseq.trainer][INFO] - begin training epoch 89
[2024-10-06 03:17:20,009][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:19:48,156][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2024-10-06 03:19:48,163][train][INFO] - {"epoch": 89, "train_loss": "1.31", "train_ntokens": "260709", "train_nsentences": "1750.04", "train_wps": "84375.8", "train_ups": "0.32", "train_wpb": "260709", "train_bsz": "1750", "train_num_updates": "4265", "train_lr": "6.66406e-05", "train_gnorm": "0.947", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.2", "train_wall": "14163"}
[2024-10-06 03:19:48,323][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:19:48,328][fairseq.trainer][INFO] - begin training epoch 90
[2024-10-06 03:19:48,328][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:22:32,239][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2024-10-06 03:22:32,248][train][INFO] - {"epoch": 90, "train_loss": "1.312", "train_ntokens": "260998", "train_nsentences": "1750.04", "train_wps": "76354.4", "train_ups": "0.29", "train_wpb": "260998", "train_bsz": "1750", "train_num_updates": "4313", "train_lr": "6.73906e-05", "train_gnorm": "1.265", "train_loss_scale": "1", "train_train_wall": "79", "train_gb_free": "39.8", "train_wall": "14327"}
[2024-10-06 03:22:32,419][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:22:32,424][fairseq.trainer][INFO] - begin training epoch 91
[2024-10-06 03:22:32,425][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:25:13,867][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2024-10-06 03:25:13,873][train][INFO] - {"epoch": 91, "train_loss": "1.304", "train_ntokens": "260938", "train_nsentences": "1750.04", "train_wps": "77495.7", "train_ups": "0.3", "train_wpb": "260938", "train_bsz": "1750", "train_num_updates": "4361", "train_lr": "6.81406e-05", "train_gnorm": "1.391", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.3", "train_wall": "14488"}
[2024-10-06 03:25:14,019][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:25:14,042][fairseq.trainer][INFO] - begin training epoch 92
[2024-10-06 03:25:14,043][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:27:26,459][train_inner][INFO] - {"epoch": 92, "update": 91.812, "loss": "1.308", "ntokens": "260812", "nsentences": "1758.46", "wps": "84181.3", "ups": "0.32", "wpb": "260812", "bsz": "1758.5", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.151", "loss_scale": "1", "train_wall": "256", "gb_free": "41.5", "wall": "14621"}
[2024-10-06 03:27:30,290][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2024-10-06 03:27:30,292][train][INFO] - {"epoch": 92, "train_loss": "1.298", "train_ntokens": "261015", "train_nsentences": "1750.04", "train_wps": "91842.1", "train_ups": "0.35", "train_wpb": "261015", "train_bsz": "1750", "train_num_updates": "4409", "train_lr": "6.88906e-05", "train_gnorm": "0.929", "train_loss_scale": "1", "train_train_wall": "63", "train_gb_free": "40", "train_wall": "14625"}
[2024-10-06 03:27:30,364][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:27:30,368][fairseq.trainer][INFO] - begin training epoch 93
[2024-10-06 03:27:30,369][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:29:33,629][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2024-10-06 03:29:33,639][train][INFO] - {"epoch": 93, "train_loss": "1.297", "train_ntokens": "260617", "train_nsentences": "1750.04", "train_wps": "101420", "train_ups": "0.39", "train_wpb": "260618", "train_bsz": "1750", "train_num_updates": "4457", "train_lr": "6.96406e-05", "train_gnorm": "1.63", "train_loss_scale": "1", "train_train_wall": "42", "train_gb_free": "40.1", "train_wall": "14748"}
[2024-10-06 03:29:33,748][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:29:33,751][fairseq.trainer][INFO] - begin training epoch 94
[2024-10-06 03:29:33,752][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:31:39,732][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2024-10-06 03:31:39,751][train][INFO] - {"epoch": 94, "train_loss": "1.285", "train_ntokens": "260542", "train_nsentences": "1750.04", "train_wps": "99169.2", "train_ups": "0.38", "train_wpb": "260542", "train_bsz": "1750", "train_num_updates": "4505", "train_lr": "7.03906e-05", "train_gnorm": "1.07", "train_loss_scale": "1", "train_train_wall": "42", "train_gb_free": "39.8", "train_wall": "14874"}
[2024-10-06 03:31:39,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:31:39,904][fairseq.trainer][INFO] - begin training epoch 95
[2024-10-06 03:31:39,905][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:33:59,991][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2024-10-06 03:33:59,999][train][INFO] - {"epoch": 95, "train_loss": "1.283", "train_ntokens": "261039", "train_nsentences": "1750.04", "train_wps": "89343.3", "train_ups": "0.34", "train_wpb": "261039", "train_bsz": "1750", "train_num_updates": "4553", "train_lr": "7.11406e-05", "train_gnorm": "1.054", "train_loss_scale": "1", "train_train_wall": "48", "train_gb_free": "39.6", "train_wall": "15014"}
[2024-10-06 03:34:00,214][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:34:00,221][fairseq.trainer][INFO] - begin training epoch 96
[2024-10-06 03:34:00,222][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:36:36,520][train_inner][INFO] - {"epoch": 96, "update": 95.979, "loss": "1.286", "ntokens": "260955", "nsentences": "1734.98", "wps": "94883.5", "ups": "0.36", "wpb": "260955", "bsz": "1735", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.19", "loss_scale": "1", "train_wall": "209", "gb_free": "39.6", "wall": "15171"}
[2024-10-06 03:36:36,830][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2024-10-06 03:36:36,841][train][INFO] - {"epoch": 96, "train_loss": "1.278", "train_ntokens": "260663", "train_nsentences": "1750.04", "train_wps": "79780.5", "train_ups": "0.31", "train_wpb": "260663", "train_bsz": "1750", "train_num_updates": "4601", "train_lr": "7.18906e-05", "train_gnorm": "1.076", "train_loss_scale": "1", "train_train_wall": "73", "train_gb_free": "39.7", "train_wall": "15171"}
[2024-10-06 03:36:37,008][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:36:37,016][fairseq.trainer][INFO] - begin training epoch 97
[2024-10-06 03:36:37,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:39:01,136][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2024-10-06 03:39:01,140][train][INFO] - {"epoch": 97, "train_loss": "1.275", "train_ntokens": "260808", "train_nsentences": "1750.04", "train_wps": "86758", "train_ups": "0.33", "train_wpb": "260808", "train_bsz": "1750", "train_num_updates": "4649", "train_lr": "7.26406e-05", "train_gnorm": "1.147", "train_loss_scale": "1", "train_train_wall": "70", "train_gb_free": "41.1", "train_wall": "15316"}
[2024-10-06 03:39:01,266][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:39:01,279][fairseq.trainer][INFO] - begin training epoch 98
[2024-10-06 03:39:01,280][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:41:25,468][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2024-10-06 03:41:25,473][train][INFO] - {"epoch": 98, "train_loss": "1.267", "train_ntokens": "260973", "train_nsentences": "1750.04", "train_wps": "86793", "train_ups": "0.33", "train_wpb": "260973", "train_bsz": "1750", "train_num_updates": "4697", "train_lr": "7.33906e-05", "train_gnorm": "1.006", "train_loss_scale": "1", "train_train_wall": "40", "train_gb_free": "40.6", "train_wall": "15460"}
[2024-10-06 03:41:25,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:41:25,693][fairseq.trainer][INFO] - begin training epoch 99
[2024-10-06 03:41:25,693][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:43:45,560][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2024-10-06 03:43:45,566][train][INFO] - {"epoch": 99, "train_loss": "1.268", "train_ntokens": "260518", "train_nsentences": "1750.04", "train_wps": "89263.1", "train_ups": "0.34", "train_wpb": "260518", "train_bsz": "1750", "train_num_updates": "4745", "train_lr": "7.41406e-05", "train_gnorm": "1.369", "train_loss_scale": "1", "train_train_wall": "39", "train_gb_free": "40", "train_wall": "15600"}
[2024-10-06 03:43:45,690][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:43:45,694][fairseq.trainer][INFO] - begin training epoch 100
[2024-10-06 03:43:45,695][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:46:09,615][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 4793 updates
[2024-10-06 03:46:09,620][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 03:46:14,184][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 03:46:14,187][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 100 @ 4793 updates, score None) (writing took 4.572041407227516 seconds)
[2024-10-06 03:46:14,188][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2024-10-06 03:46:14,192][train][INFO] - {"epoch": 100, "train_loss": "1.259", "train_ntokens": "260900", "train_nsentences": "1750.04", "train_wps": "84262.5", "train_ups": "0.32", "train_wpb": "260900", "train_bsz": "1750", "train_num_updates": "4793", "train_lr": "7.48906e-05", "train_gnorm": "1.083", "train_loss_scale": "1", "train_train_wall": "71", "train_gb_free": "40.4", "train_wall": "15749"}
[2024-10-06 03:46:14,285][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:46:14,291][fairseq.trainer][INFO] - begin training epoch 101
[2024-10-06 03:46:14,291][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:47:56,354][train_inner][INFO] - {"epoch": 101, "update": 100.146, "loss": "1.267", "ntokens": "260803", "nsentences": "1746.19", "wps": "76727.8", "ups": "0.29", "wpb": "260803", "bsz": "1746.2", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.153", "loss_scale": "1", "train_wall": "244", "gb_free": "39.7", "wall": "15851"}
[2024-10-06 03:48:29,327][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2024-10-06 03:48:29,330][train][INFO] - {"epoch": 101, "train_loss": "1.256", "train_ntokens": "260712", "train_nsentences": "1750.04", "train_wps": "92605.8", "train_ups": "0.36", "train_wpb": "260712", "train_bsz": "1750", "train_num_updates": "4841", "train_lr": "7.56406e-05", "train_gnorm": "0.924", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "40.3", "train_wall": "15884"}
[2024-10-06 03:48:29,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:48:29,479][fairseq.trainer][INFO] - begin training epoch 102
[2024-10-06 03:48:29,480][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:50:45,239][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2024-10-06 03:50:45,253][train][INFO] - {"epoch": 102, "train_loss": "1.252", "train_ntokens": "260845", "train_nsentences": "1750.04", "train_wps": "92121", "train_ups": "0.35", "train_wpb": "260845", "train_bsz": "1750", "train_num_updates": "4889", "train_lr": "7.63906e-05", "train_gnorm": "1.138", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "39.6", "train_wall": "16020"}
[2024-10-06 03:50:45,394][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:50:45,397][fairseq.trainer][INFO] - begin training epoch 103
[2024-10-06 03:50:45,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:52:59,481][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2024-10-06 03:52:59,488][train][INFO] - {"epoch": 103, "train_loss": "1.251", "train_ntokens": "260587", "train_nsentences": "1750.04", "train_wps": "93183.3", "train_ups": "0.36", "train_wpb": "260587", "train_bsz": "1750", "train_num_updates": "4937", "train_lr": "7.71406e-05", "train_gnorm": "1.412", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "16154"}
[2024-10-06 03:52:59,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:52:59,656][fairseq.trainer][INFO] - begin training epoch 104
[2024-10-06 03:52:59,658][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:55:16,560][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2024-10-06 03:55:16,565][train][INFO] - {"epoch": 104, "train_loss": "1.246", "train_ntokens": "260896", "train_nsentences": "1750.04", "train_wps": "91360.2", "train_ups": "0.35", "train_wpb": "260896", "train_bsz": "1750", "train_num_updates": "4985", "train_lr": "7.78906e-05", "train_gnorm": "1.043", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "16291"}
[2024-10-06 03:55:16,682][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:55:16,688][fairseq.trainer][INFO] - begin training epoch 105
[2024-10-06 03:55:16,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:56:50,863][train_inner][INFO] - {"epoch": 105, "update": 104.312, "loss": "1.25", "ntokens": "260868", "nsentences": "1744.42", "wps": "97614.3", "ups": "0.37", "wpb": "260868", "bsz": "1744.4", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "1.116", "loss_scale": "1", "train_wall": "203", "gb_free": "39.6", "wall": "16385"}
[2024-10-06 03:57:20,657][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2024-10-06 03:57:20,675][train][INFO] - {"epoch": 105, "train_loss": "1.24", "train_ntokens": "260746", "train_nsentences": "1750.04", "train_wps": "100859", "train_ups": "0.39", "train_wpb": "260746", "train_bsz": "1750", "train_num_updates": "5033", "train_lr": "7.86406e-05", "train_gnorm": "0.903", "train_loss_scale": "1", "train_train_wall": "40", "train_gb_free": "40.2", "train_wall": "16415"}
[2024-10-06 03:57:20,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:57:20,809][fairseq.trainer][INFO] - begin training epoch 106
[2024-10-06 03:57:20,810][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 03:59:28,265][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2024-10-06 03:59:28,272][train][INFO] - {"epoch": 106, "train_loss": "1.237", "train_ntokens": "260581", "train_nsentences": "1750.04", "train_wps": "98029.2", "train_ups": "0.38", "train_wpb": "260581", "train_bsz": "1750", "train_num_updates": "5081", "train_lr": "7.93906e-05", "train_gnorm": "1.2", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "39.6", "train_wall": "16543"}
[2024-10-06 03:59:28,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 03:59:28,384][fairseq.trainer][INFO] - begin training epoch 107
[2024-10-06 03:59:28,384][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:01:35,845][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2024-10-06 04:01:35,862][train][INFO] - {"epoch": 107, "train_loss": "1.233", "train_ntokens": "260546", "train_nsentences": "1750.04", "train_wps": "98021.3", "train_ups": "0.38", "train_wpb": "260546", "train_bsz": "1750", "train_num_updates": "5129", "train_lr": "8.01406e-05", "train_gnorm": "1.246", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.8", "train_wall": "16670"}
[2024-10-06 04:01:35,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:01:35,977][fairseq.trainer][INFO] - begin training epoch 108
[2024-10-06 04:01:35,978][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:03:45,529][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2024-10-06 04:03:45,533][train][INFO] - {"epoch": 108, "train_loss": "1.23", "train_ntokens": "260565", "train_nsentences": "1750.04", "train_wps": "96455.9", "train_ups": "0.37", "train_wpb": "260565", "train_bsz": "1750", "train_num_updates": "5177", "train_lr": "8.08906e-05", "train_gnorm": "1.055", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "40.3", "train_wall": "16800"}
[2024-10-06 04:03:45,591][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:03:45,594][fairseq.trainer][INFO] - begin training epoch 109
[2024-10-06 04:03:45,595][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:05:35,710][train_inner][INFO] - {"epoch": 109, "update": 108.479, "loss": "1.235", "ntokens": "260361", "nsentences": "1770.79", "wps": "99217", "ups": "0.38", "wpb": "260361", "bsz": "1770.8", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.123", "loss_scale": "1", "train_wall": "230", "gb_free": "39.6", "wall": "16910"}
[2024-10-06 04:05:54,973][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2024-10-06 04:05:54,984][train][INFO] - {"epoch": 109, "train_loss": "1.226", "train_ntokens": "260705", "train_nsentences": "1750.04", "train_wps": "96676.2", "train_ups": "0.37", "train_wpb": "260705", "train_bsz": "1750", "train_num_updates": "5225", "train_lr": "8.16406e-05", "train_gnorm": "1.141", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "40.5", "train_wall": "16929"}
[2024-10-06 04:05:55,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:05:55,103][fairseq.trainer][INFO] - begin training epoch 110
[2024-10-06 04:05:55,108][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:08:02,628][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2024-10-06 04:08:02,631][train][INFO] - {"epoch": 110, "train_loss": "1.219", "train_ntokens": "260568", "train_nsentences": "1750.04", "train_wps": "97986", "train_ups": "0.38", "train_wpb": "260568", "train_bsz": "1750", "train_num_updates": "5273", "train_lr": "8.23906e-05", "train_gnorm": "0.93", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.3", "train_wall": "17057"}
[2024-10-06 04:08:02,697][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:08:02,701][fairseq.trainer][INFO] - begin training epoch 111
[2024-10-06 04:08:02,701][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:10:11,760][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2024-10-06 04:10:11,769][train][INFO] - {"epoch": 111, "train_loss": "1.216", "train_ntokens": "260772", "train_nsentences": "1750.04", "train_wps": "96930", "train_ups": "0.37", "train_wpb": "260772", "train_bsz": "1750", "train_num_updates": "5321", "train_lr": "8.31406e-05", "train_gnorm": "1.061", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "39.6", "train_wall": "17186"}
[2024-10-06 04:10:11,856][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:10:11,861][fairseq.trainer][INFO] - begin training epoch 112
[2024-10-06 04:10:11,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:12:18,085][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2024-10-06 04:12:18,089][train][INFO] - {"epoch": 112, "train_loss": "1.214", "train_ntokens": "260885", "train_nsentences": "1750.04", "train_wps": "99136.1", "train_ups": "0.38", "train_wpb": "260885", "train_bsz": "1750", "train_num_updates": "5369", "train_lr": "8.38906e-05", "train_gnorm": "0.978", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.6", "train_wall": "17312"}
[2024-10-06 04:12:18,177][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:12:18,209][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-06 04:12:18,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:14:09,986][train_inner][INFO] - {"epoch": 113, "update": 112.646, "loss": "1.215", "ntokens": "260926", "nsentences": "1731.49", "wps": "101474", "ups": "0.39", "wpb": "260926", "bsz": "1731.5", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.034", "loss_scale": "1", "train_wall": "205", "gb_free": "39.9", "wall": "17424"}
[2024-10-06 04:14:28,085][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-10-06 04:14:28,088][train][INFO] - {"epoch": 113, "train_loss": "1.209", "train_ntokens": "260373", "train_nsentences": "1750.04", "train_wps": "96141.1", "train_ups": "0.37", "train_wpb": "260373", "train_bsz": "1750", "train_num_updates": "5417", "train_lr": "8.46406e-05", "train_gnorm": "1.243", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "17442"}
[2024-10-06 04:14:28,146][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:14:28,150][fairseq.trainer][INFO] - begin training epoch 114
[2024-10-06 04:14:28,162][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:16:32,404][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-10-06 04:16:32,419][train][INFO] - {"epoch": 114, "train_loss": "1.209", "train_ntokens": "260888", "train_nsentences": "1750.04", "train_wps": "100724", "train_ups": "0.39", "train_wpb": "260888", "train_bsz": "1750", "train_num_updates": "5465", "train_lr": "8.53906e-05", "train_gnorm": "1.07", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.7", "train_wall": "17567"}
[2024-10-06 04:16:32,526][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:16:32,530][fairseq.trainer][INFO] - begin training epoch 115
[2024-10-06 04:16:32,530][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:18:40,574][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-10-06 04:18:40,577][train][INFO] - {"epoch": 115, "train_loss": "1.207", "train_ntokens": "260844", "train_nsentences": "1750.04", "train_wps": "97698.9", "train_ups": "0.37", "train_wpb": "260844", "train_bsz": "1750", "train_num_updates": "5513", "train_lr": "8.61406e-05", "train_gnorm": "1.158", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "39.8", "train_wall": "17695"}
[2024-10-06 04:18:40,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:18:40,678][fairseq.trainer][INFO] - begin training epoch 116
[2024-10-06 04:18:40,679][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:20:49,185][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-10-06 04:20:49,196][train][INFO] - {"epoch": 116, "train_loss": "1.203", "train_ntokens": "260539", "train_nsentences": "1750.04", "train_wps": "97234.5", "train_ups": "0.37", "train_wpb": "260539", "train_bsz": "1750", "train_num_updates": "5561", "train_lr": "8.68906e-05", "train_gnorm": "0.891", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "17824"}
[2024-10-06 04:20:49,300][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:20:49,322][fairseq.trainer][INFO] - begin training epoch 117
[2024-10-06 04:20:49,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:22:52,239][train_inner][INFO] - {"epoch": 117, "update": 116.812, "loss": "1.205", "ntokens": "260480", "nsentences": "1761.14", "wps": "99755.3", "ups": "0.38", "wpb": "260480", "bsz": "1761.1", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.11", "loss_scale": "1", "train_wall": "217", "gb_free": "40.1", "wall": "17947"}
[2024-10-06 04:22:56,410][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-10-06 04:22:56,415][train][INFO] - {"epoch": 117, "train_loss": "1.199", "train_ntokens": "260737", "train_nsentences": "1750.04", "train_wps": "98380.5", "train_ups": "0.38", "train_wpb": "260737", "train_bsz": "1750", "train_num_updates": "5609", "train_lr": "8.76406e-05", "train_gnorm": "1.223", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "39.8", "train_wall": "17951"}
[2024-10-06 04:22:56,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:22:56,537][fairseq.trainer][INFO] - begin training epoch 118
[2024-10-06 04:22:56,538][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:25:07,499][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-10-06 04:25:07,509][train][INFO] - {"epoch": 118, "train_loss": "1.197", "train_ntokens": "260717", "train_nsentences": "1750.04", "train_wps": "95465", "train_ups": "0.37", "train_wpb": "260717", "train_bsz": "1750", "train_num_updates": "5657", "train_lr": "8.83906e-05", "train_gnorm": "0.963", "train_loss_scale": "1", "train_train_wall": "67", "train_gb_free": "39.3", "train_wall": "18082"}
[2024-10-06 04:25:07,618][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:25:07,623][fairseq.trainer][INFO] - begin training epoch 119
[2024-10-06 04:25:07,623][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:27:16,901][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-10-06 04:27:16,904][train][INFO] - {"epoch": 119, "train_loss": "1.196", "train_ntokens": "260992", "train_nsentences": "1750.04", "train_wps": "96818.9", "train_ups": "0.37", "train_wpb": "260992", "train_bsz": "1750", "train_num_updates": "5705", "train_lr": "8.91406e-05", "train_gnorm": "1.261", "train_loss_scale": "1", "train_train_wall": "33", "train_gb_free": "39.8", "train_wall": "18211"}
[2024-10-06 04:27:16,967][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:27:16,971][fairseq.trainer][INFO] - begin training epoch 120
[2024-10-06 04:27:16,971][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:29:24,919][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 5753 updates
[2024-10-06 04:29:24,920][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 04:29:28,485][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 04:29:28,488][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 120 @ 5753 updates, score None) (writing took 3.56861384678632 seconds)
[2024-10-06 04:29:28,488][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-10-06 04:29:28,491][train][INFO] - {"epoch": 120, "train_loss": "1.187", "train_ntokens": "260737", "train_nsentences": "1750.04", "train_wps": "95113.8", "train_ups": "0.36", "train_wpb": "260737", "train_bsz": "1750", "train_num_updates": "5753", "train_lr": "8.98906e-05", "train_gnorm": "0.826", "train_loss_scale": "1", "train_train_wall": "48", "train_gb_free": "39.4", "train_wall": "18343"}
[2024-10-06 04:29:28,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:29:28,563][fairseq.trainer][INFO] - begin training epoch 121
[2024-10-06 04:29:28,563][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:31:31,908][train_inner][INFO] - {"epoch": 121, "update": 120.979, "loss": "1.192", "ntokens": "260934", "nsentences": "1742.17", "wps": "100431", "ups": "0.38", "wpb": "260934", "bsz": "1742.2", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "1.023", "loss_scale": "1", "train_wall": "180", "gb_free": "39.7", "wall": "18466"}
[2024-10-06 04:31:32,272][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-10-06 04:31:32,286][train][INFO] - {"epoch": 121, "train_loss": "1.184", "train_ntokens": "260476", "train_nsentences": "1750.04", "train_wps": "101007", "train_ups": "0.39", "train_wpb": "260476", "train_bsz": "1750", "train_num_updates": "5801", "train_lr": "9.06406e-05", "train_gnorm": "1.027", "train_loss_scale": "1", "train_train_wall": "28", "train_gb_free": "42.3", "train_wall": "18467"}
[2024-10-06 04:31:32,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:31:32,396][fairseq.trainer][INFO] - begin training epoch 122
[2024-10-06 04:31:32,397][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:33:38,751][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-10-06 04:33:38,754][train][INFO] - {"epoch": 122, "train_loss": "1.187", "train_ntokens": "260599", "train_nsentences": "1750.04", "train_wps": "98910.8", "train_ups": "0.38", "train_wpb": "260599", "train_bsz": "1750", "train_num_updates": "5849", "train_lr": "9.13906e-05", "train_gnorm": "1.146", "train_loss_scale": "2", "train_train_wall": "48", "train_gb_free": "40.1", "train_wall": "18593"}
[2024-10-06 04:33:38,910][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:33:38,919][fairseq.trainer][INFO] - begin training epoch 123
[2024-10-06 04:33:38,920][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:35:44,518][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-10-06 04:35:44,522][train][INFO] - {"epoch": 123, "train_loss": "1.178", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "99540.1", "train_ups": "0.38", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "5897", "train_lr": "9.21406e-05", "train_gnorm": "0.9", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "40.1", "train_wall": "18719"}
[2024-10-06 04:35:44,623][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:35:44,632][fairseq.trainer][INFO] - begin training epoch 124
[2024-10-06 04:35:44,633][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:37:51,135][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-10-06 04:37:51,138][train][INFO] - {"epoch": 124, "train_loss": "1.173", "train_ntokens": "260936", "train_nsentences": "1750.04", "train_wps": "98924.5", "train_ups": "0.38", "train_wpb": "260936", "train_bsz": "1750", "train_num_updates": "5945", "train_lr": "9.28906e-05", "train_gnorm": "0.977", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "39.3", "train_wall": "18846"}
[2024-10-06 04:37:51,199][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:37:51,202][fairseq.trainer][INFO] - begin training epoch 125
[2024-10-06 04:37:51,202][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:39:31,807][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-06 04:39:57,732][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-10-06 04:39:57,739][train][INFO] - {"epoch": 125, "train_loss": "1.172", "train_ntokens": "259959", "train_nsentences": "1764.02", "train_wps": "96513.7", "train_ups": "0.37", "train_wpb": "259959", "train_bsz": "1764", "train_num_updates": "5992", "train_lr": "9.3625e-05", "train_gnorm": "1.117", "train_loss_scale": "1", "train_train_wall": "39", "train_gb_free": "39.7", "train_wall": "18972"}
[2024-10-06 04:39:57,865][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:39:57,869][fairseq.trainer][INFO] - begin training epoch 126
[2024-10-06 04:39:57,869][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:41:26,042][train_inner][INFO] - {"epoch": 126, "update": 125.167, "loss": "1.178", "ntokens": "260392", "nsentences": "1757.22", "wps": "87655.2", "ups": "0.34", "wpb": "260392", "bsz": "1757.2", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "1.035", "loss_scale": "1", "train_wall": "180", "gb_free": "39.6", "wall": "19060"}
[2024-10-06 04:42:05,159][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-10-06 04:42:05,176][train][INFO] - {"epoch": 126, "train_loss": "1.17", "train_ntokens": "260322", "train_nsentences": "1750.04", "train_wps": "98065.9", "train_ups": "0.38", "train_wpb": "260322", "train_bsz": "1750", "train_num_updates": "6040", "train_lr": "9.4375e-05", "train_gnorm": "0.985", "train_loss_scale": "1", "train_train_wall": "44", "train_gb_free": "39.6", "train_wall": "19100"}
[2024-10-06 04:42:05,281][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:42:05,309][fairseq.trainer][INFO] - begin training epoch 127
[2024-10-06 04:42:05,310][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:44:12,399][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-10-06 04:44:12,417][train][INFO] - {"epoch": 127, "train_loss": "1.169", "train_ntokens": "260760", "train_nsentences": "1750.04", "train_wps": "98374.8", "train_ups": "0.38", "train_wpb": "260760", "train_bsz": "1750", "train_num_updates": "6088", "train_lr": "9.5125e-05", "train_gnorm": "1.084", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.2", "train_wall": "19227"}
[2024-10-06 04:44:12,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:44:12,527][fairseq.trainer][INFO] - begin training epoch 128
[2024-10-06 04:44:12,527][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:46:21,487][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-10-06 04:46:21,504][train][INFO] - {"epoch": 128, "train_loss": "1.167", "train_ntokens": "260423", "train_nsentences": "1750.04", "train_wps": "96842.3", "train_ups": "0.37", "train_wpb": "260423", "train_bsz": "1750", "train_num_updates": "6136", "train_lr": "9.5875e-05", "train_gnorm": "0.947", "train_loss_scale": "1", "train_train_wall": "50", "train_gb_free": "39.6", "train_wall": "19356"}
[2024-10-06 04:46:21,602][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:46:21,605][fairseq.trainer][INFO] - begin training epoch 129
[2024-10-06 04:46:21,606][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:48:29,777][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-10-06 04:48:29,780][train][INFO] - {"epoch": 129, "train_loss": "1.161", "train_ntokens": "260305", "train_nsentences": "1750.04", "train_wps": "97407.7", "train_ups": "0.37", "train_wpb": "260305", "train_bsz": "1750", "train_num_updates": "6184", "train_lr": "9.6625e-05", "train_gnorm": "1.015", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "40.1", "train_wall": "19484"}
[2024-10-06 04:48:29,835][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:48:29,839][fairseq.trainer][INFO] - begin training epoch 130
[2024-10-06 04:48:29,839][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:50:11,971][train_inner][INFO] - {"epoch": 130, "update": 129.333, "loss": "1.166", "ntokens": "260431", "nsentences": "1759.95", "wps": "99037.7", "ups": "0.38", "wpb": "260431", "bsz": "1760", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "1.035", "loss_scale": "1", "train_wall": "234", "gb_free": "39.7", "wall": "19586"}
[2024-10-06 04:50:35,794][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-10-06 04:50:35,796][train][INFO] - {"epoch": 130, "train_loss": "1.157", "train_ntokens": "260517", "train_nsentences": "1750.04", "train_wps": "99234.7", "train_ups": "0.38", "train_wpb": "260517", "train_bsz": "1750", "train_num_updates": "6232", "train_lr": "9.7375e-05", "train_gnorm": "1.032", "train_loss_scale": "1", "train_train_wall": "63", "train_gb_free": "39.6", "train_wall": "19610"}
[2024-10-06 04:50:35,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:50:35,902][fairseq.trainer][INFO] - begin training epoch 131
[2024-10-06 04:50:35,903][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:52:45,140][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-10-06 04:52:45,144][train][INFO] - {"epoch": 131, "train_loss": "1.158", "train_ntokens": "260964", "train_nsentences": "1750.04", "train_wps": "96844.2", "train_ups": "0.37", "train_wpb": "260964", "train_bsz": "1750", "train_num_updates": "6280", "train_lr": "9.8125e-05", "train_gnorm": "0.815", "train_loss_scale": "1", "train_train_wall": "54", "train_gb_free": "39.7", "train_wall": "19740"}
[2024-10-06 04:52:45,242][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:52:45,250][fairseq.trainer][INFO] - begin training epoch 132
[2024-10-06 04:52:45,251][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:54:53,329][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-10-06 04:54:53,332][train][INFO] - {"epoch": 132, "train_loss": "1.157", "train_ntokens": "260935", "train_nsentences": "1750.04", "train_wps": "97710.3", "train_ups": "0.37", "train_wpb": "260935", "train_bsz": "1750", "train_num_updates": "6328", "train_lr": "9.8875e-05", "train_gnorm": "1.024", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "19868"}
[2024-10-06 04:54:53,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:54:53,433][fairseq.trainer][INFO] - begin training epoch 133
[2024-10-06 04:54:53,433][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:57:00,497][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-10-06 04:57:00,504][train][INFO] - {"epoch": 133, "train_loss": "1.151", "train_ntokens": "260679", "train_nsentences": "1750.04", "train_wps": "98395.7", "train_ups": "0.38", "train_wpb": "260679", "train_bsz": "1750", "train_num_updates": "6376", "train_lr": "9.9625e-05", "train_gnorm": "1.078", "train_loss_scale": "1", "train_train_wall": "58", "train_gb_free": "39.5", "train_wall": "19995"}
[2024-10-06 04:57:00,564][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:57:00,567][fairseq.trainer][INFO] - begin training epoch 134
[2024-10-06 04:57:00,568][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 04:58:44,912][train_inner][INFO] - {"epoch": 134, "update": 133.5, "loss": "1.154", "ntokens": "261030", "nsentences": "1737.61", "wps": "101779", "ups": "0.39", "wpb": "261030", "bsz": "1737.6", "num_updates": "6400", "lr": "0.0001", "gnorm": "0.966", "loss_scale": "1", "train_wall": "220", "gb_free": "39.3", "wall": "20099"}
[2024-10-06 04:59:09,453][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-10-06 04:59:09,455][train][INFO] - {"epoch": 134, "train_loss": "1.149", "train_ntokens": "260944", "train_nsentences": "1750.04", "train_wps": "97135.1", "train_ups": "0.37", "train_wpb": "260944", "train_bsz": "1750", "train_num_updates": "6424", "train_lr": "0.000100375", "train_gnorm": "1.188", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.3", "train_wall": "20124"}
[2024-10-06 04:59:09,574][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 04:59:09,590][fairseq.trainer][INFO] - begin training epoch 135
[2024-10-06 04:59:09,591][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:01:18,381][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-10-06 05:01:18,388][train][INFO] - {"epoch": 135, "train_loss": "1.148", "train_ntokens": "260715", "train_nsentences": "1750.04", "train_wps": "97063.6", "train_ups": "0.37", "train_wpb": "260715", "train_bsz": "1750", "train_num_updates": "6472", "train_lr": "0.000101125", "train_gnorm": "0.707", "train_loss_scale": "1", "train_train_wall": "53", "train_gb_free": "39.8", "train_wall": "20253"}
[2024-10-06 05:01:18,449][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:01:18,452][fairseq.trainer][INFO] - begin training epoch 136
[2024-10-06 05:01:18,453][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:03:31,149][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-10-06 05:03:31,152][train][INFO] - {"epoch": 136, "train_loss": "1.147", "train_ntokens": "260738", "train_nsentences": "1750.04", "train_wps": "94270.3", "train_ups": "0.36", "train_wpb": "260738", "train_bsz": "1750", "train_num_updates": "6520", "train_lr": "0.000101875", "train_gnorm": "0.922", "train_loss_scale": "1", "train_train_wall": "62", "train_gb_free": "39.3", "train_wall": "20386"}
[2024-10-06 05:03:31,232][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:03:31,239][fairseq.trainer][INFO] - begin training epoch 137
[2024-10-06 05:03:31,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:05:38,552][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-10-06 05:05:38,580][train][INFO] - {"epoch": 137, "train_loss": "1.139", "train_ntokens": "260929", "train_nsentences": "1750.04", "train_wps": "98301.7", "train_ups": "0.38", "train_wpb": "260929", "train_bsz": "1750", "train_num_updates": "6568", "train_lr": "0.000102625", "train_gnorm": "0.996", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "20513"}
[2024-10-06 05:05:38,664][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:05:38,667][fairseq.trainer][INFO] - begin training epoch 138
[2024-10-06 05:05:38,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:07:30,450][train_inner][INFO] - {"epoch": 138, "update": 137.667, "loss": "1.145", "ntokens": "260694", "nsentences": "1763.66", "wps": "99211.5", "ups": "0.38", "wpb": "260694", "bsz": "1763.7", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.941", "loss_scale": "1", "train_wall": "242", "gb_free": "39.5", "wall": "20625"}
[2024-10-06 05:07:46,358][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-10-06 05:07:46,363][train][INFO] - {"epoch": 138, "train_loss": "1.138", "train_ntokens": "260644", "train_nsentences": "1750.04", "train_wps": "97913.8", "train_ups": "0.38", "train_wpb": "260644", "train_bsz": "1750", "train_num_updates": "6616", "train_lr": "0.000103375", "train_gnorm": "0.954", "train_loss_scale": "1", "train_train_wall": "62", "train_gb_free": "39.3", "train_wall": "20641"}
[2024-10-06 05:07:46,459][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:07:46,467][fairseq.trainer][INFO] - begin training epoch 139
[2024-10-06 05:07:46,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:09:57,632][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-10-06 05:09:57,649][train][INFO] - {"epoch": 139, "train_loss": "1.137", "train_ntokens": "261040", "train_nsentences": "1750.04", "train_wps": "95445.3", "train_ups": "0.37", "train_wpb": "261040", "train_bsz": "1750", "train_num_updates": "6664", "train_lr": "0.000104125", "train_gnorm": "0.963", "train_loss_scale": "1", "train_train_wall": "66", "train_gb_free": "39.1", "train_wall": "20772"}
[2024-10-06 05:09:57,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:09:57,848][fairseq.trainer][INFO] - begin training epoch 140
[2024-10-06 05:09:57,849][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:12:04,065][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 6712 updates
[2024-10-06 05:12:04,066][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 05:12:07,766][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 05:12:07,770][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 140 @ 6712 updates, score None) (writing took 3.7051685452461243 seconds)
[2024-10-06 05:12:07,771][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-10-06 05:12:07,773][train][INFO] - {"epoch": 140, "train_loss": "1.133", "train_ntokens": "260859", "train_nsentences": "1750.04", "train_wps": "96229.6", "train_ups": "0.37", "train_wpb": "260860", "train_bsz": "1750", "train_num_updates": "6712", "train_lr": "0.000104875", "train_gnorm": "0.904", "train_loss_scale": "1", "train_train_wall": "30", "train_gb_free": "39.3", "train_wall": "20902"}
[2024-10-06 05:12:07,857][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:12:07,889][fairseq.trainer][INFO] - begin training epoch 141
[2024-10-06 05:12:07,890][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:14:10,374][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-10-06 05:14:10,384][train][INFO] - {"epoch": 141, "train_loss": "1.133", "train_ntokens": "260713", "train_nsentences": "1750.04", "train_wps": "102070", "train_ups": "0.39", "train_wpb": "260713", "train_bsz": "1750", "train_num_updates": "6760", "train_lr": "0.000105625", "train_gnorm": "0.991", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.7", "train_wall": "21025"}
[2024-10-06 05:14:10,511][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:14:10,516][fairseq.trainer][INFO] - begin training epoch 142
[2024-10-06 05:14:10,517][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:16:13,708][train_inner][INFO] - {"epoch": 142, "update": 141.833, "loss": "1.134", "ntokens": "260715", "nsentences": "1744.81", "wps": "99653.8", "ups": "0.38", "wpb": "260715", "bsz": "1744.8", "num_updates": "6800", "lr": "0.00010625", "gnorm": "0.953", "loss_scale": "1", "train_wall": "219", "gb_free": "40.3", "wall": "21148"}
[2024-10-06 05:16:18,172][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-10-06 05:16:18,175][train][INFO] - {"epoch": 142, "train_loss": "1.131", "train_ntokens": "260462", "train_nsentences": "1750.04", "train_wps": "97836.2", "train_ups": "0.38", "train_wpb": "260462", "train_bsz": "1750", "train_num_updates": "6808", "train_lr": "0.000106375", "train_gnorm": "0.984", "train_loss_scale": "1", "train_train_wall": "61", "train_gb_free": "40.2", "train_wall": "21153"}
[2024-10-06 05:16:18,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:16:18,243][fairseq.trainer][INFO] - begin training epoch 143
[2024-10-06 05:16:18,243][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:18:25,401][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-10-06 05:18:25,407][train][INFO] - {"epoch": 143, "train_loss": "1.128", "train_ntokens": "260641", "train_nsentences": "1750.04", "train_wps": "98333.9", "train_ups": "0.38", "train_wpb": "260640", "train_bsz": "1750", "train_num_updates": "6856", "train_lr": "0.000107125", "train_gnorm": "0.981", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "39.6", "train_wall": "21280"}
[2024-10-06 05:18:25,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:18:25,598][fairseq.trainer][INFO] - begin training epoch 144
[2024-10-06 05:18:25,599][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:20:30,898][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-10-06 05:20:30,904][train][INFO] - {"epoch": 144, "train_loss": "1.126", "train_ntokens": "260758", "train_nsentences": "1750.04", "train_wps": "99737.2", "train_ups": "0.38", "train_wpb": "260758", "train_bsz": "1750", "train_num_updates": "6904", "train_lr": "0.000107875", "train_gnorm": "1.199", "train_loss_scale": "1", "train_train_wall": "36", "train_gb_free": "39.7", "train_wall": "21405"}
[2024-10-06 05:20:31,043][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:20:31,047][fairseq.trainer][INFO] - begin training epoch 145
[2024-10-06 05:20:31,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:22:40,755][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-10-06 05:22:40,777][train][INFO] - {"epoch": 145, "train_loss": "1.119", "train_ntokens": "260755", "train_nsentences": "1750.04", "train_wps": "96376", "train_ups": "0.37", "train_wpb": "260755", "train_bsz": "1750", "train_num_updates": "6952", "train_lr": "0.000108625", "train_gnorm": "0.712", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "21535"}
[2024-10-06 05:22:40,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:22:40,901][fairseq.trainer][INFO] - begin training epoch 146
[2024-10-06 05:22:40,901][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:24:48,578][train_inner][INFO] - {"epoch": 146, "update": 146.0, "loss": "1.122", "ntokens": "260633", "nsentences": "1747.71", "wps": "101244", "ups": "0.39", "wpb": "260633", "bsz": "1747.7", "num_updates": "7000", "lr": "0.000109375", "gnorm": "0.949", "loss_scale": "1", "train_wall": "204", "gb_free": "39.9", "wall": "21663"}
[2024-10-06 05:24:48,581][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-10-06 05:24:48,583][train][INFO] - {"epoch": 146, "train_loss": "1.118", "train_ntokens": "260280", "train_nsentences": "1750.04", "train_wps": "97755.5", "train_ups": "0.38", "train_wpb": "260280", "train_bsz": "1750", "train_num_updates": "7000", "train_lr": "0.000109375", "train_gnorm": "0.88", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.9", "train_wall": "21663"}
[2024-10-06 05:24:48,656][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:24:48,659][fairseq.trainer][INFO] - begin training epoch 147
[2024-10-06 05:24:48,659][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:26:59,228][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-10-06 05:26:59,250][train][INFO] - {"epoch": 147, "train_loss": "1.117", "train_ntokens": "260788", "train_nsentences": "1750.04", "train_wps": "95801.4", "train_ups": "0.37", "train_wpb": "260788", "train_bsz": "1750", "train_num_updates": "7048", "train_lr": "0.000110125", "train_gnorm": "0.96", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "21794"}
[2024-10-06 05:26:59,370][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:26:59,388][fairseq.trainer][INFO] - begin training epoch 148
[2024-10-06 05:26:59,389][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:29:08,614][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-10-06 05:29:08,625][train][INFO] - {"epoch": 148, "train_loss": "1.118", "train_ntokens": "260701", "train_nsentences": "1750.04", "train_wps": "96728", "train_ups": "0.37", "train_wpb": "260701", "train_bsz": "1750", "train_num_updates": "7096", "train_lr": "0.000110875", "train_gnorm": "1.081", "train_loss_scale": "1", "train_train_wall": "59", "train_gb_free": "39.8", "train_wall": "21923"}
[2024-10-06 05:29:08,735][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:29:08,742][fairseq.trainer][INFO] - begin training epoch 149
[2024-10-06 05:29:08,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:31:20,122][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-10-06 05:31:20,125][train][INFO] - {"epoch": 149, "train_loss": "1.112", "train_ntokens": "260544", "train_nsentences": "1750.04", "train_wps": "95106", "train_ups": "0.37", "train_wpb": "260544", "train_bsz": "1750", "train_num_updates": "7144", "train_lr": "0.000111625", "train_gnorm": "0.87", "train_loss_scale": "1", "train_train_wall": "54", "train_gb_free": "39.8", "train_wall": "22054"}
[2024-10-06 05:31:20,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:31:20,185][fairseq.trainer][INFO] - begin training epoch 150
[2024-10-06 05:31:20,185][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:33:28,771][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2024-10-06 05:33:28,780][train][INFO] - {"epoch": 150, "train_loss": "1.111", "train_ntokens": "260629", "train_nsentences": "1750.04", "train_wps": "97241.3", "train_ups": "0.37", "train_wpb": "260629", "train_bsz": "1750", "train_num_updates": "7192", "train_lr": "0.000112375", "train_gnorm": "1.067", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.6", "train_wall": "22183"}
[2024-10-06 05:33:28,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:33:28,898][fairseq.trainer][INFO] - begin training epoch 151
[2024-10-06 05:33:28,899][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:35:08,040][train_inner][INFO] - {"epoch": 151, "update": 150.167, "loss": "1.114", "ntokens": "260586", "nsentences": "1759", "wps": "84135.5", "ups": "0.32", "wpb": "260586", "bsz": "1759", "num_updates": "7200", "lr": "0.0001125", "gnorm": "1.004", "loss_scale": "1", "train_wall": "240", "gb_free": "39.1", "wall": "22282"}
[2024-10-06 05:35:44,559][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2024-10-06 05:35:44,561][train][INFO] - {"epoch": 151, "train_loss": "1.108", "train_ntokens": "261045", "train_nsentences": "1750.04", "train_wps": "92284.6", "train_ups": "0.35", "train_wpb": "261045", "train_bsz": "1750", "train_num_updates": "7240", "train_lr": "0.000113125", "train_gnorm": "0.967", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "22319"}
[2024-10-06 05:35:44,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:35:44,633][fairseq.trainer][INFO] - begin training epoch 152
[2024-10-06 05:35:44,633][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:37:53,865][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2024-10-06 05:37:53,884][train][INFO] - {"epoch": 152, "train_loss": "1.106", "train_ntokens": "260603", "train_nsentences": "1750.04", "train_wps": "96732", "train_ups": "0.37", "train_wpb": "260603", "train_bsz": "1750", "train_num_updates": "7288", "train_lr": "0.000113875", "train_gnorm": "0.933", "train_loss_scale": "1", "train_train_wall": "34", "train_gb_free": "39.6", "train_wall": "22448"}
[2024-10-06 05:37:54,028][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:37:54,037][fairseq.trainer][INFO] - begin training epoch 153
[2024-10-06 05:37:54,038][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:40:06,671][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2024-10-06 05:40:06,690][train][INFO] - {"epoch": 153, "train_loss": "1.108", "train_ntokens": "261138", "train_nsentences": "1750.04", "train_wps": "94391.3", "train_ups": "0.36", "train_wpb": "261138", "train_bsz": "1750", "train_num_updates": "7336", "train_lr": "0.000114625", "train_gnorm": "0.848", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "22581"}
[2024-10-06 05:40:06,865][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:40:06,872][fairseq.trainer][INFO] - begin training epoch 154
[2024-10-06 05:40:06,873][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:42:20,176][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2024-10-06 05:42:20,197][train][INFO] - {"epoch": 154, "train_loss": "1.101", "train_ntokens": "260677", "train_nsentences": "1750.04", "train_wps": "93737.8", "train_ups": "0.36", "train_wpb": "260677", "train_bsz": "1750", "train_num_updates": "7384", "train_lr": "0.000115375", "train_gnorm": "0.971", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "40.1", "train_wall": "22715"}
[2024-10-06 05:42:20,365][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:42:20,381][fairseq.trainer][INFO] - begin training epoch 155
[2024-10-06 05:42:20,382][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:43:57,829][train_inner][INFO] - {"epoch": 155, "update": 154.333, "loss": "1.105", "ntokens": "260765", "nsentences": "1747.31", "wps": "98442.7", "ups": "0.38", "wpb": "260765", "bsz": "1747.3", "num_updates": "7400", "lr": "0.000115625", "gnorm": "0.916", "loss_scale": "1", "train_wall": "205", "gb_free": "40.7", "wall": "22812"}
[2024-10-06 05:44:27,494][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2024-10-06 05:44:27,499][train][INFO] - {"epoch": 155, "train_loss": "1.098", "train_ntokens": "260304", "train_nsentences": "1750.04", "train_wps": "98152.3", "train_ups": "0.38", "train_wpb": "260304", "train_bsz": "1750", "train_num_updates": "7432", "train_lr": "0.000116125", "train_gnorm": "0.954", "train_loss_scale": "1", "train_train_wall": "47", "train_gb_free": "39.8", "train_wall": "22842"}
[2024-10-06 05:44:27,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:44:27,619][fairseq.trainer][INFO] - begin training epoch 156
[2024-10-06 05:44:27,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:46:34,320][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2024-10-06 05:46:34,329][train][INFO] - {"epoch": 156, "train_loss": "1.098", "train_ntokens": "260844", "train_nsentences": "1750.04", "train_wps": "98722", "train_ups": "0.38", "train_wpb": "260844", "train_bsz": "1750", "train_num_updates": "7480", "train_lr": "0.000116875", "train_gnorm": "1.038", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "40.1", "train_wall": "22969"}
[2024-10-06 05:46:34,419][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:46:34,429][fairseq.trainer][INFO] - begin training epoch 157
[2024-10-06 05:46:34,430][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:48:41,675][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2024-10-06 05:48:41,678][train][INFO] - {"epoch": 157, "train_loss": "1.093", "train_ntokens": "260939", "train_nsentences": "1750.04", "train_wps": "98354.9", "train_ups": "0.38", "train_wpb": "260939", "train_bsz": "1750", "train_num_updates": "7528", "train_lr": "0.000117625", "train_gnorm": "0.803", "train_loss_scale": "1", "train_train_wall": "51", "train_gb_free": "39.8", "train_wall": "23096"}
[2024-10-06 05:48:41,772][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:48:41,776][fairseq.trainer][INFO] - begin training epoch 158
[2024-10-06 05:48:41,776][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:50:51,258][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2024-10-06 05:50:51,262][train][INFO] - {"epoch": 158, "train_loss": "1.092", "train_ntokens": "260927", "train_nsentences": "1750.04", "train_wps": "96653.8", "train_ups": "0.37", "train_wpb": "260926", "train_bsz": "1750", "train_num_updates": "7576", "train_lr": "0.000118375", "train_gnorm": "0.926", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.3", "train_wall": "23226"}
[2024-10-06 05:50:51,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:50:51,320][fairseq.trainer][INFO] - begin training epoch 159
[2024-10-06 05:50:51,321][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:52:40,527][train_inner][INFO] - {"epoch": 159, "update": 158.5, "loss": "1.094", "ntokens": "260994", "nsentences": "1746.1", "wps": "99865.5", "ups": "0.38", "wpb": "260994", "bsz": "1746.1", "num_updates": "7600", "lr": "0.00011875", "gnorm": "0.919", "loss_scale": "1", "train_wall": "222", "gb_free": "40.3", "wall": "23335"}
[2024-10-06 05:52:58,591][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2024-10-06 05:52:58,593][train][INFO] - {"epoch": 159, "train_loss": "1.087", "train_ntokens": "260560", "train_nsentences": "1750.04", "train_wps": "98226.1", "train_ups": "0.38", "train_wpb": "260560", "train_bsz": "1750", "train_num_updates": "7624", "train_lr": "0.000119125", "train_gnorm": "0.848", "train_loss_scale": "1", "train_train_wall": "62", "train_gb_free": "39.3", "train_wall": "23353"}
[2024-10-06 05:52:58,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:52:58,712][fairseq.trainer][INFO] - begin training epoch 160
[2024-10-06 05:52:58,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:55:06,714][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 7672 updates
[2024-10-06 05:55:06,716][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 05:55:11,295][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 05:55:11,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 160 @ 7672 updates, score None) (writing took 4.583212362602353 seconds)
[2024-10-06 05:55:11,298][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2024-10-06 05:55:11,300][train][INFO] - {"epoch": 160, "train_loss": "1.091", "train_ntokens": "260653", "train_nsentences": "1750.04", "train_wps": "94281.3", "train_ups": "0.36", "train_wpb": "260653", "train_bsz": "1750", "train_num_updates": "7672", "train_lr": "0.000119875", "train_gnorm": "0.838", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "23486"}
[2024-10-06 05:55:11,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:55:11,390][fairseq.trainer][INFO] - begin training epoch 161
[2024-10-06 05:55:11,390][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:57:23,412][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2024-10-06 05:57:23,417][train][INFO] - {"epoch": 161, "train_loss": "1.088", "train_ntokens": "260749", "train_nsentences": "1750.04", "train_wps": "94736.5", "train_ups": "0.36", "train_wpb": "260749", "train_bsz": "1750", "train_num_updates": "7720", "train_lr": "0.000120625", "train_gnorm": "0.981", "train_loss_scale": "1", "train_train_wall": "31", "train_gb_free": "42.5", "train_wall": "23618"}
[2024-10-06 05:57:23,490][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:57:23,493][fairseq.trainer][INFO] - begin training epoch 162
[2024-10-06 05:57:23,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 05:59:28,031][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2024-10-06 05:59:28,038][train][INFO] - {"epoch": 162, "train_loss": "1.085", "train_ntokens": "260637", "train_nsentences": "1750.04", "train_wps": "100393", "train_ups": "0.39", "train_wpb": "260637", "train_bsz": "1750", "train_num_updates": "7768", "train_lr": "0.000121375", "train_gnorm": "0.949", "train_loss_scale": "1", "train_train_wall": "49", "train_gb_free": "40.3", "train_wall": "23742"}
[2024-10-06 05:59:28,118][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 05:59:28,123][fairseq.trainer][INFO] - begin training epoch 163
[2024-10-06 05:59:28,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:01:18,972][train_inner][INFO] - {"epoch": 163, "update": 162.667, "loss": "1.086", "ntokens": "260584", "nsentences": "1739.22", "wps": "100527", "ups": "0.39", "wpb": "260584", "bsz": "1739.2", "num_updates": "7800", "lr": "0.000121875", "gnorm": "0.898", "loss_scale": "1", "train_wall": "192", "gb_free": "39.6", "wall": "23853"}
[2024-10-06 06:01:36,046][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2024-10-06 06:01:36,048][train][INFO] - {"epoch": 163, "train_loss": "1.08", "train_ntokens": "260666", "train_nsentences": "1750.04", "train_wps": "97745", "train_ups": "0.37", "train_wpb": "260666", "train_bsz": "1750", "train_num_updates": "7816", "train_lr": "0.000122125", "train_gnorm": "0.802", "train_loss_scale": "1", "train_train_wall": "54", "train_gb_free": "39.3", "train_wall": "23870"}
[2024-10-06 06:01:36,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:01:36,187][fairseq.trainer][INFO] - begin training epoch 164
[2024-10-06 06:01:36,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:03:47,722][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2024-10-06 06:03:47,725][train][INFO] - {"epoch": 164, "train_loss": "1.077", "train_ntokens": "260538", "train_nsentences": "1750.04", "train_wps": "94976.9", "train_ups": "0.36", "train_wpb": "260538", "train_bsz": "1750", "train_num_updates": "7864", "train_lr": "0.000122875", "train_gnorm": "0.907", "train_loss_scale": "1", "train_train_wall": "45", "train_gb_free": "40.3", "train_wall": "24002"}
[2024-10-06 06:03:47,789][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:03:47,793][fairseq.trainer][INFO] - begin training epoch 165
[2024-10-06 06:03:47,794][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:05:56,727][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2024-10-06 06:05:56,743][train][INFO] - {"epoch": 165, "train_loss": "1.077", "train_ntokens": "260502", "train_nsentences": "1750.04", "train_wps": "96921.6", "train_ups": "0.37", "train_wpb": "260502", "train_bsz": "1750", "train_num_updates": "7912", "train_lr": "0.000123625", "train_gnorm": "0.994", "train_loss_scale": "1", "train_train_wall": "49", "train_gb_free": "39.7", "train_wall": "24131"}
[2024-10-06 06:05:56,866][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:05:56,878][fairseq.trainer][INFO] - begin training epoch 166
[2024-10-06 06:05:56,879][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:08:03,618][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2024-10-06 06:08:03,623][train][INFO] - {"epoch": 166, "train_loss": "1.075", "train_ntokens": "260451", "train_nsentences": "1750.04", "train_wps": "98534.6", "train_ups": "0.38", "train_wpb": "260451", "train_bsz": "1750", "train_num_updates": "7960", "train_lr": "0.000124375", "train_gnorm": "0.84", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.3", "train_wall": "24258"}
[2024-10-06 06:08:03,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:08:03,703][fairseq.trainer][INFO] - begin training epoch 167
[2024-10-06 06:08:03,703][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:10:06,396][train_inner][INFO] - {"epoch": 167, "update": 166.833, "loss": "1.077", "ntokens": "260487", "nsentences": "1759.96", "wps": "98777.8", "ups": "0.38", "wpb": "260487", "bsz": "1760", "num_updates": "8000", "lr": "0.000125", "gnorm": "0.883", "loss_scale": "1", "train_wall": "218", "gb_free": "40.1", "wall": "24381"}
[2024-10-06 06:10:08,526][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2024-10-06 06:10:08,530][train][INFO] - {"epoch": 167, "train_loss": "1.073", "train_ntokens": "260578", "train_nsentences": "1750.04", "train_wps": "100139", "train_ups": "0.38", "train_wpb": "260578", "train_bsz": "1750", "train_num_updates": "8008", "train_lr": "0.000125125", "train_gnorm": "0.9", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40", "train_wall": "24383"}
[2024-10-06 06:10:08,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:10:08,585][fairseq.trainer][INFO] - begin training epoch 168
[2024-10-06 06:10:08,586][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:12:16,422][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2024-10-06 06:12:16,434][train][INFO] - {"epoch": 168, "train_loss": "1.071", "train_ntokens": "260671", "train_nsentences": "1750.04", "train_wps": "97827.9", "train_ups": "0.38", "train_wpb": "260670", "train_bsz": "1750", "train_num_updates": "8056", "train_lr": "0.000125875", "train_gnorm": "0.812", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.2", "train_wall": "24511"}
[2024-10-06 06:12:16,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:12:16,544][fairseq.trainer][INFO] - begin training epoch 169
[2024-10-06 06:12:16,544][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:14:26,376][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2024-10-06 06:14:26,379][train][INFO] - {"epoch": 169, "train_loss": "1.07", "train_ntokens": "260292", "train_nsentences": "1750.04", "train_wps": "96151.6", "train_ups": "0.37", "train_wpb": "260292", "train_bsz": "1750", "train_num_updates": "8104", "train_lr": "0.000126625", "train_gnorm": "0.845", "train_loss_scale": "2", "train_train_wall": "31", "train_gb_free": "39.3", "train_wall": "24641"}
[2024-10-06 06:14:26,438][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:14:26,441][fairseq.trainer][INFO] - begin training epoch 170
[2024-10-06 06:14:26,442][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:16:36,150][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2024-10-06 06:16:36,163][train][INFO] - {"epoch": 170, "train_loss": "1.067", "train_ntokens": "260517", "train_nsentences": "1750.04", "train_wps": "96354.8", "train_ups": "0.37", "train_wpb": "260517", "train_bsz": "1750", "train_num_updates": "8152", "train_lr": "0.000127375", "train_gnorm": "1.283", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.7", "train_wall": "24771"}
[2024-10-06 06:16:36,256][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:16:36,260][fairseq.trainer][INFO] - begin training epoch 171
[2024-10-06 06:16:36,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:18:42,102][train_inner][INFO] - {"epoch": 171, "update": 171.0, "loss": "1.068", "ntokens": "260473", "nsentences": "1748.65", "wps": "101019", "ups": "0.39", "wpb": "260473", "bsz": "1748.7", "num_updates": "8200", "lr": "0.000128125", "gnorm": "0.946", "loss_scale": "2", "train_wall": "185", "gb_free": "40.5", "wall": "24896"}
[2024-10-06 06:18:42,107][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2024-10-06 06:18:42,108][train][INFO] - {"epoch": 171, "train_loss": "1.065", "train_ntokens": "260248", "train_nsentences": "1750.04", "train_wps": "99189.3", "train_ups": "0.38", "train_wpb": "260248", "train_bsz": "1750", "train_num_updates": "8200", "train_lr": "0.000128125", "train_gnorm": "0.771", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "40.5", "train_wall": "24896"}
[2024-10-06 06:18:42,212][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:18:42,223][fairseq.trainer][INFO] - begin training epoch 172
[2024-10-06 06:18:42,224][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:20:53,338][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2024-10-06 06:20:53,342][train][INFO] - {"epoch": 172, "train_loss": "1.065", "train_ntokens": "261166", "train_nsentences": "1750.04", "train_wps": "95525.6", "train_ups": "0.37", "train_wpb": "261166", "train_bsz": "1750", "train_num_updates": "8248", "train_lr": "0.000128875", "train_gnorm": "0.856", "train_loss_scale": "2", "train_train_wall": "32", "train_gb_free": "39.6", "train_wall": "25028"}
[2024-10-06 06:20:53,406][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:20:53,410][fairseq.trainer][INFO] - begin training epoch 173
[2024-10-06 06:20:53,410][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:22:58,073][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2024-10-06 06:22:58,085][train][INFO] - {"epoch": 173, "train_loss": "1.062", "train_ntokens": "260299", "train_nsentences": "1750.04", "train_wps": "100165", "train_ups": "0.38", "train_wpb": "260299", "train_bsz": "1750", "train_num_updates": "8296", "train_lr": "0.000129625", "train_gnorm": "0.833", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "40.4", "train_wall": "25152"}
[2024-10-06 06:22:58,188][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:22:58,210][fairseq.trainer][INFO] - begin training epoch 174
[2024-10-06 06:22:58,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:25:06,425][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2024-10-06 06:25:06,428][train][INFO] - {"epoch": 174, "train_loss": "1.059", "train_ntokens": "260876", "train_nsentences": "1750.04", "train_wps": "97569.4", "train_ups": "0.37", "train_wpb": "260876", "train_bsz": "1750", "train_num_updates": "8344", "train_lr": "0.000130375", "train_gnorm": "0.867", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.3", "train_wall": "25281"}
[2024-10-06 06:25:06,489][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:25:06,495][fairseq.trainer][INFO] - begin training epoch 175
[2024-10-06 06:25:06,496][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:27:11,924][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2024-10-06 06:27:11,927][train][INFO] - {"epoch": 175, "train_loss": "1.058", "train_ntokens": "260661", "train_nsentences": "1750.04", "train_wps": "99699.1", "train_ups": "0.38", "train_wpb": "260661", "train_bsz": "1750", "train_num_updates": "8392", "train_lr": "0.000131125", "train_gnorm": "0.768", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40.1", "train_wall": "25406"}
[2024-10-06 06:27:12,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:27:12,003][fairseq.trainer][INFO] - begin training epoch 176
[2024-10-06 06:27:12,004][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:28:41,082][train_inner][INFO] - {"epoch": 176, "update": 175.167, "loss": "1.061", "ntokens": "260755", "nsentences": "1753.19", "wps": "87067.4", "ups": "0.33", "wpb": "260756", "bsz": "1753.2", "num_updates": "8400", "lr": "0.00013125", "gnorm": "0.83", "loss_scale": "2", "train_wall": "191", "gb_free": "39.6", "wall": "25495"}
[2024-10-06 06:29:17,014][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2024-10-06 06:29:17,017][train][INFO] - {"epoch": 176, "train_loss": "1.056", "train_ntokens": "260698", "train_nsentences": "1750.04", "train_wps": "100040", "train_ups": "0.38", "train_wpb": "260698", "train_bsz": "1750", "train_num_updates": "8440", "train_lr": "0.000131875", "train_gnorm": "0.902", "train_loss_scale": "2", "train_train_wall": "42", "train_gb_free": "39.3", "train_wall": "25531"}
[2024-10-06 06:29:17,075][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:29:17,079][fairseq.trainer][INFO] - begin training epoch 177
[2024-10-06 06:29:17,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:31:07,122][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-06 06:31:25,267][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2024-10-06 06:31:25,271][train][INFO] - {"epoch": 177, "train_loss": "1.054", "train_ntokens": "261045", "train_nsentences": "1750.62", "train_wps": "95665.4", "train_ups": "0.37", "train_wpb": "261044", "train_bsz": "1750.6", "train_num_updates": "8487", "train_lr": "0.000132609", "train_gnorm": "0.988", "train_loss_scale": "1", "train_train_wall": "31", "train_gb_free": "39.7", "train_wall": "25660"}
[2024-10-06 06:31:25,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:31:25,392][fairseq.trainer][INFO] - begin training epoch 178
[2024-10-06 06:31:25,393][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:33:32,929][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2024-10-06 06:33:32,934][train][INFO] - {"epoch": 178, "train_loss": "1.051", "train_ntokens": "260506", "train_nsentences": "1750.04", "train_wps": "97951.5", "train_ups": "0.38", "train_wpb": "260506", "train_bsz": "1750", "train_num_updates": "8535", "train_lr": "0.000133359", "train_gnorm": "0.696", "train_loss_scale": "1", "train_train_wall": "61", "train_gb_free": "39.6", "train_wall": "25787"}
[2024-10-06 06:33:32,995][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:33:32,998][fairseq.trainer][INFO] - begin training epoch 179
[2024-10-06 06:33:32,999][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:35:39,970][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2024-10-06 06:35:39,975][train][INFO] - {"epoch": 179, "train_loss": "1.052", "train_ntokens": "260740", "train_nsentences": "1750.04", "train_wps": "98518.9", "train_ups": "0.38", "train_wpb": "260740", "train_bsz": "1750", "train_num_updates": "8583", "train_lr": "0.000134109", "train_gnorm": "1.019", "train_loss_scale": "1", "train_train_wall": "63", "train_gb_free": "39.7", "train_wall": "25914"}
[2024-10-06 06:35:40,083][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:35:40,098][fairseq.trainer][INFO] - begin training epoch 180
[2024-10-06 06:35:40,098][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:37:19,767][train_inner][INFO] - {"epoch": 180, "update": 179.354, "loss": "1.051", "ntokens": "260878", "nsentences": "1732.64", "wps": "100593", "ups": "0.39", "wpb": "260878", "bsz": "1732.6", "num_updates": "8600", "lr": "0.000134375", "gnorm": "0.884", "loss_scale": "1", "train_wall": "224", "gb_free": "39.8", "wall": "26014"}
[2024-10-06 06:37:47,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 8631 updates
[2024-10-06 06:37:47,346][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 06:37:51,754][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 06:37:51,756][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 180 @ 8631 updates, score None) (writing took 4.410266950726509 seconds)
[2024-10-06 06:37:51,756][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2024-10-06 06:37:51,758][train][INFO] - {"epoch": 180, "train_loss": "1.044", "train_ntokens": "260632", "train_nsentences": "1750.04", "train_wps": "94934.2", "train_ups": "0.36", "train_wpb": "260632", "train_bsz": "1750", "train_num_updates": "8631", "train_lr": "0.000134859", "train_gnorm": "0.699", "train_loss_scale": "1", "train_train_wall": "61", "train_gb_free": "39.8", "train_wall": "26046"}
[2024-10-06 06:37:51,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:37:51,853][fairseq.trainer][INFO] - begin training epoch 181
[2024-10-06 06:37:51,853][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:39:53,081][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2024-10-06 06:39:53,097][train][INFO] - {"epoch": 181, "train_loss": "1.049", "train_ntokens": "260589", "train_nsentences": "1750.04", "train_wps": "103089", "train_ups": "0.4", "train_wpb": "260589", "train_bsz": "1750", "train_num_updates": "8679", "train_lr": "0.000135609", "train_gnorm": "1.069", "train_loss_scale": "1", "train_train_wall": "42", "train_gb_free": "39.6", "train_wall": "26167"}
[2024-10-06 06:39:53,196][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:39:53,206][fairseq.trainer][INFO] - begin training epoch 182
[2024-10-06 06:39:53,207][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:41:58,077][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2024-10-06 06:41:58,080][train][INFO] - {"epoch": 182, "train_loss": "1.043", "train_ntokens": "260736", "train_nsentences": "1750.04", "train_wps": "100139", "train_ups": "0.38", "train_wpb": "260736", "train_bsz": "1750", "train_num_updates": "8727", "train_lr": "0.000136359", "train_gnorm": "0.803", "train_loss_scale": "1", "train_train_wall": "48", "train_gb_free": "40.1", "train_wall": "26292"}
[2024-10-06 06:41:58,187][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:41:58,191][fairseq.trainer][INFO] - begin training epoch 183
[2024-10-06 06:41:58,203][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:44:04,787][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2024-10-06 06:44:04,798][train][INFO] - {"epoch": 183, "train_loss": "1.042", "train_ntokens": "260635", "train_nsentences": "1750.04", "train_wps": "98734.9", "train_ups": "0.38", "train_wpb": "260635", "train_bsz": "1750", "train_num_updates": "8775", "train_lr": "0.000137109", "train_gnorm": "0.711", "train_loss_scale": "1", "train_train_wall": "35", "train_gb_free": "40", "train_wall": "26419"}
[2024-10-06 06:44:04,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:44:04,963][fairseq.trainer][INFO] - begin training epoch 184
[2024-10-06 06:44:04,963][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:45:55,227][train_inner][INFO] - {"epoch": 184, "update": 183.521, "loss": "1.045", "ntokens": "260479", "nsentences": "1764.12", "wps": "101070", "ups": "0.39", "wpb": "260479", "bsz": "1764.1", "num_updates": "8800", "lr": "0.0001375", "gnorm": "0.847", "loss_scale": "1", "train_wall": "174", "gb_free": "40.1", "wall": "26530"}
[2024-10-06 06:46:13,067][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2024-10-06 06:46:13,071][train][INFO] - {"epoch": 184, "train_loss": "1.042", "train_ntokens": "260598", "train_nsentences": "1750.04", "train_wps": "97521.5", "train_ups": "0.37", "train_wpb": "260598", "train_bsz": "1750", "train_num_updates": "8823", "train_lr": "0.000137859", "train_gnorm": "0.931", "train_loss_scale": "1", "train_train_wall": "39", "train_gb_free": "39.7", "train_wall": "26547"}
[2024-10-06 06:46:13,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:46:13,196][fairseq.trainer][INFO] - begin training epoch 185
[2024-10-06 06:46:13,196][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:48:18,939][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2024-10-06 06:48:18,943][train][INFO] - {"epoch": 185, "train_loss": "1.037", "train_ntokens": "260429", "train_nsentences": "1750.04", "train_wps": "99316.8", "train_ups": "0.38", "train_wpb": "260429", "train_bsz": "1750", "train_num_updates": "8871", "train_lr": "0.000138609", "train_gnorm": "0.835", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "39.8", "train_wall": "26673"}
[2024-10-06 06:48:19,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:48:19,033][fairseq.trainer][INFO] - begin training epoch 186
[2024-10-06 06:48:19,033][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:50:29,294][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2024-10-06 06:50:29,297][train][INFO] - {"epoch": 186, "train_loss": "1.037", "train_ntokens": "260741", "train_nsentences": "1750.04", "train_wps": "96016.4", "train_ups": "0.37", "train_wpb": "260741", "train_bsz": "1750", "train_num_updates": "8919", "train_lr": "0.000139359", "train_gnorm": "1.057", "train_loss_scale": "1", "train_train_wall": "50", "train_gb_free": "40.1", "train_wall": "26804"}
[2024-10-06 06:50:29,386][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:50:29,392][fairseq.trainer][INFO] - begin training epoch 187
[2024-10-06 06:50:29,392][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:52:37,634][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2024-10-06 06:52:37,641][train][INFO] - {"epoch": 187, "train_loss": "1.034", "train_ntokens": "260853", "train_nsentences": "1750.04", "train_wps": "97560.7", "train_ups": "0.37", "train_wpb": "260853", "train_bsz": "1750", "train_num_updates": "8967", "train_lr": "0.000140109", "train_gnorm": "0.707", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.3", "train_wall": "26932"}
[2024-10-06 06:52:37,736][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:52:37,744][fairseq.trainer][INFO] - begin training epoch 188
[2024-10-06 06:52:37,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:54:31,643][train_inner][INFO] - {"epoch": 188, "update": 187.688, "loss": "1.036", "ntokens": "260590", "nsentences": "1752.08", "wps": "100924", "ups": "0.39", "wpb": "260590", "bsz": "1752.1", "num_updates": "9000", "lr": "0.000140625", "gnorm": "0.848", "loss_scale": "1", "train_wall": "202", "gb_free": "39.3", "wall": "27046"}
[2024-10-06 06:54:43,704][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2024-10-06 06:54:43,706][train][INFO] - {"epoch": 188, "train_loss": "1.033", "train_ntokens": "260422", "train_nsentences": "1750.04", "train_wps": "99160.8", "train_ups": "0.38", "train_wpb": "260422", "train_bsz": "1750", "train_num_updates": "9015", "train_lr": "0.000140859", "train_gnorm": "0.762", "train_loss_scale": "1", "train_train_wall": "45", "train_gb_free": "40.1", "train_wall": "27058"}
[2024-10-06 06:54:43,808][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:54:43,825][fairseq.trainer][INFO] - begin training epoch 189
[2024-10-06 06:54:43,826][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:56:49,945][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2024-10-06 06:56:49,960][train][INFO] - {"epoch": 189, "train_loss": "1.033", "train_ntokens": "260615", "train_nsentences": "1750.04", "train_wps": "99088.2", "train_ups": "0.38", "train_wpb": "260616", "train_bsz": "1750", "train_num_updates": "9063", "train_lr": "0.000141609", "train_gnorm": "0.813", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.8", "train_wall": "27184"}
[2024-10-06 06:56:50,049][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:56:50,081][fairseq.trainer][INFO] - begin training epoch 190
[2024-10-06 06:56:50,081][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 06:58:56,851][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2024-10-06 06:58:56,858][train][INFO] - {"epoch": 190, "train_loss": "1.029", "train_ntokens": "260712", "train_nsentences": "1750.04", "train_wps": "98622", "train_ups": "0.38", "train_wpb": "260712", "train_bsz": "1750", "train_num_updates": "9111", "train_lr": "0.000142359", "train_gnorm": "0.862", "train_loss_scale": "1", "train_train_wall": "56", "train_gb_free": "40.2", "train_wall": "27311"}
[2024-10-06 06:58:56,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 06:58:56,966][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-06 06:58:56,966][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:01:05,410][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-06 07:01:05,416][train][INFO] - {"epoch": 191, "train_loss": "1.028", "train_ntokens": "260651", "train_nsentences": "1750.04", "train_wps": "97325.6", "train_ups": "0.37", "train_wpb": "260651", "train_bsz": "1750", "train_num_updates": "9159", "train_lr": "0.000143109", "train_gnorm": "0.722", "train_loss_scale": "1", "train_train_wall": "46", "train_gb_free": "40.1", "train_wall": "27440"}
[2024-10-06 07:01:05,531][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:01:05,546][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-06 07:01:05,546][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:03:05,603][train_inner][INFO] - {"epoch": 192, "update": 191.854, "loss": "1.03", "ntokens": "260911", "nsentences": "1746.67", "wps": "101539", "ups": "0.39", "wpb": "260911", "bsz": "1746.7", "num_updates": "9200", "lr": "0.00014375", "gnorm": "0.851", "loss_scale": "1", "train_wall": "194", "gb_free": "39.8", "wall": "27560"}
[2024-10-06 07:03:11,390][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-06 07:03:11,393][train][INFO] - {"epoch": 192, "train_loss": "1.027", "train_ntokens": "260841", "train_nsentences": "1750.04", "train_wps": "99388.7", "train_ups": "0.38", "train_wpb": "260842", "train_bsz": "1750", "train_num_updates": "9207", "train_lr": "0.000143859", "train_gnorm": "1.001", "train_loss_scale": "1", "train_train_wall": "34", "train_gb_free": "40.5", "train_wall": "27566"}
[2024-10-06 07:03:11,499][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:03:11,517][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-06 07:03:11,518][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:05:18,017][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-06 07:05:18,026][train][INFO] - {"epoch": 193, "train_loss": "1.022", "train_ntokens": "260525", "train_nsentences": "1750.04", "train_wps": "98755.1", "train_ups": "0.38", "train_wpb": "260525", "train_bsz": "1750", "train_num_updates": "9255", "train_lr": "0.000144609", "train_gnorm": "0.74", "train_loss_scale": "1", "train_train_wall": "58", "train_gb_free": "40", "train_wall": "27692"}
[2024-10-06 07:05:18,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:05:18,161][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-06 07:05:18,162][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:07:24,372][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-06 07:07:24,381][train][INFO] - {"epoch": 194, "train_loss": "1.019", "train_ntokens": "260781", "train_nsentences": "1750.04", "train_wps": "99069", "train_ups": "0.38", "train_wpb": "260781", "train_bsz": "1750", "train_num_updates": "9303", "train_lr": "0.000145359", "train_gnorm": "0.729", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "40", "train_wall": "27819"}
[2024-10-06 07:07:24,491][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:07:24,507][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-06 07:07:24,507][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:09:30,880][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-06 07:09:30,891][train][INFO] - {"epoch": 195, "train_loss": "1.022", "train_ntokens": "260618", "train_nsentences": "1750.04", "train_wps": "98892.1", "train_ups": "0.38", "train_wpb": "260618", "train_bsz": "1750", "train_num_updates": "9351", "train_lr": "0.000146109", "train_gnorm": "1.073", "train_loss_scale": "1", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "27945"}
[2024-10-06 07:09:31,032][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:09:31,036][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-06 07:09:31,036][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:11:38,556][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-06 07:11:38,559][train][INFO] - {"epoch": 196, "train_loss": "1.017", "train_ntokens": "260894", "train_nsentences": "1750.04", "train_wps": "98092.3", "train_ups": "0.38", "train_wpb": "260894", "train_bsz": "1750", "train_num_updates": "9399", "train_lr": "0.000146859", "train_gnorm": "0.794", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "28073"}
[2024-10-06 07:11:38,616][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:11:38,620][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-06 07:11:38,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:12:55,713][train_inner][INFO] - {"epoch": 197, "update": 196.021, "loss": "1.02", "ntokens": "260548", "nsentences": "1751.17", "wps": "88310.3", "ups": "0.34", "wpb": "260548", "bsz": "1751.2", "num_updates": "9400", "lr": "0.000146875", "gnorm": "0.836", "loss_scale": "1", "train_wall": "236", "gb_free": "39.6", "wall": "28150"}
[2024-10-06 07:13:46,152][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-06 07:13:46,154][train][INFO] - {"epoch": 197, "train_loss": "1.016", "train_ntokens": "260684", "train_nsentences": "1750.04", "train_wps": "98070.4", "train_ups": "0.38", "train_wpb": "260684", "train_bsz": "1750", "train_num_updates": "9447", "train_lr": "0.000147609", "train_gnorm": "0.839", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "40.1", "train_wall": "28201"}
[2024-10-06 07:13:46,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:13:46,210][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-06 07:13:46,211][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:15:56,303][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-06 07:15:56,317][train][INFO] - {"epoch": 198, "train_loss": "1.012", "train_ntokens": "260656", "train_nsentences": "1750.04", "train_wps": "96126.1", "train_ups": "0.37", "train_wpb": "260656", "train_bsz": "1750", "train_num_updates": "9495", "train_lr": "0.000148359", "train_gnorm": "0.703", "train_loss_scale": "1", "train_train_wall": "57", "train_gb_free": "39.3", "train_wall": "28331"}
[2024-10-06 07:15:56,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:15:56,427][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-06 07:15:56,427][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:18:05,220][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-06 07:18:05,228][train][INFO] - {"epoch": 199, "train_loss": "1.012", "train_ntokens": "260748", "train_nsentences": "1750.04", "train_wps": "97093.2", "train_ups": "0.37", "train_wpb": "260748", "train_bsz": "1750", "train_num_updates": "9543", "train_lr": "0.000149109", "train_gnorm": "0.816", "train_loss_scale": "1", "train_train_wall": "52", "train_gb_free": "39.6", "train_wall": "28460"}
[2024-10-06 07:18:05,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:18:05,305][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-06 07:18:05,305][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:20:12,346][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 9591 updates
[2024-10-06 07:20:12,347][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 07:20:15,632][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-06 07:20:15,635][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 200 @ 9591 updates, score None) (writing took 3.2892236579209566 seconds)
[2024-10-06 07:20:15,636][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-06 07:20:15,638][train][INFO] - {"epoch": 200, "train_loss": "1.01", "train_ntokens": "260557", "train_nsentences": "1750.04", "train_wps": "95906.9", "train_ups": "0.37", "train_wpb": "260557", "train_bsz": "1750", "train_num_updates": "9591", "train_lr": "0.000149859", "train_gnorm": "0.75", "train_loss_scale": "1", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "28590"}
[2024-10-06 07:20:15,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-06 07:20:15,720][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-06 07:20:15,720][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-06 07:21:45,825][train_inner][INFO] - {"epoch": 201, "update": 200.188, "loss": "1.013", "ntokens": "260704", "nsentences": "1751.15", "wps": "98359.8", "ups": "0.38", "wpb": "260704", "bsz": "1751.2", "num_updates": "9600", "lr": "0.00015", "gnorm": "0.786", "loss_scale": "1", "train_wall": "221", "gb_free": "40", "wall": "28680"}
