[2024-10-10 10:55:12,236][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15851', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:14,382][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19142', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:14,400][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18523', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:14,674][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19774', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:14,832][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12288', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:14,978][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19217', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:15,410][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13481', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:16,129][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13205', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.5, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'channel'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-10 10:55:18,772][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:18,783][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:18,786][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:18,786][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:18,787][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:18,795][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:18,800][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:18,802][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:18,802][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:18,802][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:18,823][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:18,823][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:19,808][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:19,811][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:19,826][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:19,826][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:19,827][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:19,828][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:20,310][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:20,319][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:20,319][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:20,319][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:20,320][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:20,320][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:20,460][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:20,461][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:20,461][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:20,462][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:20,474][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:20,483][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:21,072][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:21,079][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:21,079][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:21,082][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:21,083][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:21,087][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:21,608][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:21,619][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:21,619][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:21,619][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:21,620][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:21,621][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:24,090][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-10 10:55:24,144][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-10 10:55:24,144][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-10 10:55:24,144][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-10 10:55:24,145][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-10 10:55:24,146][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-10 10:55:24,908][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:25,884][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:26,464][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:27,206][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:27,904][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:35,723][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:48,216][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:55:59,235][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:57:53,595][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 10:57:53,602][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,602][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,602][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,602][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,603][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,603][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,603][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,603][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:57:53,603][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 10:57:53,603][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 10:57:53,606][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 10:57:53,607][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 10:57:53,607][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 10:57:53,607][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 10:57:56,384][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 10:58:56,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 10:58:56,072][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 10:58:56,072][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 10:59:17,865][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 10:59:17,865][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,865][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 10:59:17,866][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 10:59:17,866][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 10:59:17,866][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 10:59:17,868][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 10:59:17,868][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 10:59:17,868][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 10:59:23,736][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:00:10,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:00:10,194][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:00:10,199][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:01:27,846][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:01:27,981][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:01:27,981][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:01:27,982][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:01:27,982][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:01:27,982][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:01:27,982][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:02:02,953][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:08:08,876][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:08,890][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:08,891][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:08,891][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:08:08,894][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:08:08,895][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:08,896][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:08,896][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:08:12,248][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,444][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,445][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:45,445][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:45,445][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:08:45,445][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:08:45,446][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:45,446][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:45,446][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:08:48,394][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:08:52,607][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:52,618][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,618][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,618][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,618][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,619][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,619][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,619][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,619][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,619][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:52,619][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:08:52,619][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:08:52,620][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:52,620][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:52,620][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,674][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:08:52,675][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:08:52,675][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:08:52,675][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:08:52,676][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:52,676][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:08:52,676][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:08:57,164][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:08:57,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:08:57,824][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:08:57,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:09:01,294][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:09:14,649][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:09:14,664][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:09:14,664][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-10 11:09:26,364][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-10 11:09:26,365][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-10 11:09:26,365][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-10 11:09:26,366][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:09:26,366][fairseq.trainer][INFO] - No existing checkpoint found /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 11:09:26,366][fairseq.trainer][INFO] - loading train data for epoch 1
[2024-10-10 11:09:46,230][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:09:46,239][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:09:46,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:09:55,763][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-10 11:10:00,267][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:10:00,275][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:10:00,276][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:10:09,019][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:10:09,039][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:10:09,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:10:44,745][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 11:10:44,759][fairseq.trainer][INFO] - begin training epoch 1
[2024-10-10 11:10:44,760][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 11:32:00,735][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-10 11:32:04,153][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-10 11:32:07,639][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-10 11:32:07,788][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2024-10-10 11:32:17,293][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2024-10-10 11:32:18,831][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2024-10-10 11:32:34,028][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-10 11:32:42,820][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 11:33:24,588][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2024-10-10 11:33:35,950][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 11:52:08,183][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.553", "ntokens": "238984", "nsentences": "1773.83", "wps": "39665.2", "ups": "0.17", "wpb": "238984", "bsz": "1773.8", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.926", "loss_scale": "4", "train_wall": "1178", "gb_free": "39.6", "wall": "2595"}
[2024-10-10 11:52:08,218][train_inner][INFO] - {"epoch": 1, "update": 0.428, "loss": "5.553", "ntokens": "238984", "nsentences": "1773.83", "wps": "40013.6", "ups": "0.17", "wpb": "238984", "bsz": "1773.8", "num_updates": "200", "lr": "3.125e-06", "gnorm": "0.926", "loss_scale": "4", "train_wall": "1055", "gb_free": "39.6", "wall": "2562"}
[2024-10-10 12:11:29,540][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "5.141", "ntokens": "238770", "nsentences": "1717.45", "wps": "41123.4", "ups": "0.17", "wpb": "238770", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "612", "gb_free": "40.1", "wall": "3723"}
[2024-10-10 12:11:30,378][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "5.141", "ntokens": "238770", "nsentences": "1717.45", "wps": "41092.9", "ups": "0.17", "wpb": "238770", "bsz": "1717.5", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.871", "loss_scale": "4", "train_wall": "599", "gb_free": "40.1", "wall": "3758"}
[2024-10-10 12:17:57,324][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-10 12:17:57,332][train][INFO] - {"epoch": 1, "train_loss": "5.253", "train_ntokens": "238446", "train_nsentences": "1751.34", "train_wps": "41033.3", "train_ups": "0.17", "train_wpb": "238446", "train_bsz": "1751.3", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.901", "train_loss_scale": "4", "train_train_wall": "2163", "train_gb_free": "39.6", "train_wall": "4145"}
[2024-10-10 12:17:57,603][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2024-10-10 12:17:57,608][train][INFO] - {"epoch": 1, "train_loss": "5.253", "train_ntokens": "238446", "train_nsentences": "1751.34", "train_wps": "41190.4", "train_ups": "0.17", "train_wpb": "238446", "train_bsz": "1751.3", "train_num_updates": "474", "train_lr": "7.40625e-06", "train_gnorm": "0.901", "train_loss_scale": "4", "train_train_wall": "2053", "train_gb_free": "39.6", "train_wall": "4111"}
[2024-10-10 12:18:00,410][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:18:00,412][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:18:00,437][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-10 12:18:00,437][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:18:00,439][fairseq.trainer][INFO] - begin training epoch 2
[2024-10-10 12:18:00,440][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:31:29,463][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.597", "ntokens": "237885", "nsentences": "1773.64", "wps": "39652.1", "ups": "0.17", "wpb": "237885", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.961", "loss_scale": "4", "train_wall": "804", "gb_free": "39.2", "wall": "4923"}
[2024-10-10 12:31:36,915][train_inner][INFO] - {"epoch": 2, "update": 1.263, "loss": "4.597", "ntokens": "237885", "nsentences": "1773.64", "wps": "39433.1", "ups": "0.17", "wpb": "237885", "bsz": "1773.6", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.961", "loss_scale": "4", "train_wall": "816", "gb_free": "39.2", "wall": "4964"}
[2024-10-10 12:42:29,760][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "4.202", "ntokens": "238821", "nsentences": "1758.35", "wps": "73164.3", "ups": "0.31", "wpb": "238822", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "1.065", "loss_scale": "4", "train_wall": "543", "gb_free": "40.2", "wall": "5617"}
[2024-10-10 12:42:31,827][train_inner][INFO] - {"epoch": 2, "update": 1.681, "loss": "4.202", "ntokens": "238821", "nsentences": "1758.35", "wps": "72114", "ups": "0.3", "wpb": "238822", "bsz": "1758.4", "num_updates": "800", "lr": "1.25e-05", "gnorm": "1.065", "loss_scale": "4", "train_wall": "526", "gb_free": "40.2", "wall": "5585"}
[2024-10-10 12:54:46,109][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-10 12:54:46,128][train][INFO] - {"epoch": 2, "train_loss": "4.192", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "51716.9", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "1.093", "train_loss_scale": "4", "train_train_wall": "1618", "train_gb_free": "39.3", "train_wall": "6320"}
[2024-10-10 12:54:46,551][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:54:46,566][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-10 12:54:46,566][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 12:54:46,865][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2024-10-10 12:54:46,867][train][INFO] - {"epoch": 2, "train_loss": "4.192", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "51692.9", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "953", "train_lr": "1.48906e-05", "train_gnorm": "1.093", "train_loss_scale": "4", "train_train_wall": "1693", "train_gb_free": "39.3", "train_wall": "6354"}
[2024-10-10 12:54:46,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 12:54:46,926][fairseq.trainer][INFO] - begin training epoch 3
[2024-10-10 12:54:46,927][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:04:26,682][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.883", "ntokens": "237907", "nsentences": "1775.94", "wps": "36132.2", "ups": "0.15", "wpb": "237907", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "1.229", "loss_scale": "4", "train_wall": "948", "gb_free": "39.2", "wall": "6934"}
[2024-10-10 13:04:27,523][train_inner][INFO] - {"epoch": 3, "update": 2.098, "loss": "3.883", "ntokens": "237907", "nsentences": "1775.94", "wps": "36165.2", "ups": "0.15", "wpb": "237907", "bsz": "1775.9", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "1.229", "loss_scale": "4", "train_wall": "875", "gb_free": "39.2", "wall": "6901"}
[2024-10-10 13:18:25,682][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "3.634", "ntokens": "238830", "nsentences": "1729.12", "wps": "56938.1", "ups": "0.24", "wpb": "238830", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "1.425", "loss_scale": "4", "train_wall": "749", "gb_free": "39.7", "wall": "7773"}
[2024-10-10 13:18:33,847][train_inner][INFO] - {"epoch": 3, "update": 2.516, "loss": "3.634", "ntokens": "238830", "nsentences": "1729.12", "wps": "56440.8", "ups": "0.24", "wpb": "238830", "bsz": "1729.1", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "1.425", "loss_scale": "4", "train_wall": "755", "gb_free": "39.7", "wall": "7747"}
[2024-10-10 13:29:41,967][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "3.444", "ntokens": "238947", "nsentences": "1741.91", "wps": "71531.7", "ups": "0.3", "wpb": "238946", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.499", "loss_scale": "4", "train_wall": "636", "gb_free": "39.4", "wall": "8416"}
[2024-10-10 13:29:43,147][train_inner][INFO] - {"epoch": 3, "update": 2.933, "loss": "3.444", "ntokens": "238947", "nsentences": "1741.91", "wps": "70548.1", "ups": "0.3", "wpb": "238946", "bsz": "1741.9", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "1.499", "loss_scale": "4", "train_wall": "641", "gb_free": "39.4", "wall": "8451"}
[2024-10-10 13:32:11,478][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-10 13:32:11,482][train][INFO] - {"epoch": 3, "train_loss": "3.552", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "50885.1", "train_ups": "0.21", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.453", "train_loss_scale": "4", "train_train_wall": "1764", "train_gb_free": "39.3", "train_wall": "8599"}
[2024-10-10 13:32:11,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:32:11,563][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-10 13:32:11,564][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:32:13,445][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2024-10-10 13:32:13,447][train][INFO] - {"epoch": 3, "train_loss": "3.552", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "50823.8", "train_ups": "0.21", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "1432", "train_lr": "2.2375e-05", "train_gnorm": "1.453", "train_loss_scale": "4", "train_train_wall": "1742", "train_gb_free": "39.3", "train_wall": "8567"}
[2024-10-10 13:32:13,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 13:32:13,824][fairseq.trainer][INFO] - begin training epoch 4
[2024-10-10 13:32:13,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 13:47:41,006][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "3.307", "ntokens": "237743", "nsentences": "1810.06", "wps": "44114.5", "ups": "0.19", "wpb": "237743", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.583", "loss_scale": "4", "train_wall": "697", "gb_free": "39.2", "wall": "9528"}
[2024-10-10 13:47:43,020][train_inner][INFO] - {"epoch": 4, "update": 3.351, "loss": "3.307", "ntokens": "237743", "nsentences": "1810.06", "wps": "43984.3", "ups": "0.19", "wpb": "237743", "bsz": "1810.1", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "1.583", "loss_scale": "4", "train_wall": "669", "gb_free": "39.2", "wall": "9497"}
[2024-10-10 14:01:53,240][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "3.184", "ntokens": "238919", "nsentences": "1707.52", "wps": "56202.7", "ups": "0.24", "wpb": "238919", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.722", "loss_scale": "4", "train_wall": "692", "gb_free": "39.3", "wall": "10347"}
[2024-10-10 14:01:53,547][train_inner][INFO] - {"epoch": 4, "update": 3.768, "loss": "3.184", "ntokens": "238919", "nsentences": "1707.52", "wps": "56050.9", "ups": "0.23", "wpb": "238919", "bsz": "1707.5", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "1.722", "loss_scale": "4", "train_wall": "716", "gb_free": "39.3", "wall": "10381"}
[2024-10-10 14:12:40,363][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-10 14:12:40,381][train][INFO] - {"epoch": 4, "train_loss": "3.209", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "47062.6", "train_ups": "0.2", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.686", "train_loss_scale": "4", "train_train_wall": "1800", "train_gb_free": "40.6", "train_wall": "10994"}
[2024-10-10 14:12:40,974][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:12:40,996][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-10 14:12:40,997][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:12:47,646][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2024-10-10 14:12:47,649][train][INFO] - {"epoch": 4, "train_loss": "3.209", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "46884", "train_ups": "0.2", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "1911", "train_lr": "2.98594e-05", "train_gnorm": "1.686", "train_loss_scale": "4", "train_train_wall": "1855", "train_gb_free": "40.6", "train_wall": "11035"}
[2024-10-10 14:12:47,710][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:12:47,714][fairseq.trainer][INFO] - begin training epoch 5
[2024-10-10 14:12:47,714][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:24:43,599][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "3.102", "ntokens": "237863", "nsentences": "1755.84", "wps": "34723.5", "ups": "0.15", "wpb": "237863", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.761", "loss_scale": "4", "train_wall": "793", "gb_free": "40.1", "wall": "11751"}
[2024-10-10 14:24:53,604][train_inner][INFO] - {"epoch": 5, "update": 4.186, "loss": "3.102", "ntokens": "237863", "nsentences": "1755.84", "wps": "34466.4", "ups": "0.14", "wpb": "237863", "bsz": "1755.8", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.762", "loss_scale": "4", "train_wall": "844", "gb_free": "40.1", "wall": "11727"}
[2024-10-10 14:35:04,078][train_inner][INFO] - {"epoch": 5, "update": 4.603, "loss": "3.022", "ntokens": "238846", "nsentences": "1789.87", "wps": "78251", "ups": "0.33", "wpb": "238846", "bsz": "1789.9", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.715", "loss_scale": "8", "train_wall": "598", "gb_free": "39.6", "wall": "12338"}
[2024-10-10 14:35:14,073][train_inner][INFO] - {"epoch": 5, "update": 4.603, "loss": "3.022", "ntokens": "238846", "nsentences": "1789.87", "wps": "75769.5", "ups": "0.32", "wpb": "238846", "bsz": "1789.9", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.715", "loss_scale": "8", "train_wall": "618", "gb_free": "39.6", "wall": "12381"}
[2024-10-10 14:48:25,262][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-10 14:48:25,274][train][INFO] - {"epoch": 5, "train_loss": "3.009", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "53432.1", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "2390", "train_lr": "3.73438e-05", "train_gnorm": "1.739", "train_loss_scale": "8", "train_train_wall": "1608", "train_gb_free": "39.7", "train_wall": "13173"}
[2024-10-10 14:48:25,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:48:25,627][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-10 14:48:25,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:48:27,350][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2024-10-10 14:48:27,366][train][INFO] - {"epoch": 5, "train_loss": "3.009", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "53199.3", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "2390", "train_lr": "3.73438e-05", "train_gnorm": "1.739", "train_loss_scale": "8", "train_train_wall": "1652", "train_gb_free": "39.7", "train_wall": "13141"}
[2024-10-10 14:48:27,496][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 14:48:27,499][fairseq.trainer][INFO] - begin training epoch 6
[2024-10-10 14:48:27,499][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 14:56:15,295][train_inner][INFO] - {"epoch": 6, "update": 5.021, "loss": "2.96", "ntokens": "237903", "nsentences": "1706.68", "wps": "37430.9", "ups": "0.16", "wpb": "237903", "bsz": "1706.7", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.768", "loss_scale": "8", "train_wall": "875", "gb_free": "39.3", "wall": "13609"}
[2024-10-10 14:56:16,113][train_inner][INFO] - {"epoch": 6, "update": 5.021, "loss": "2.96", "ntokens": "237903", "nsentences": "1706.68", "wps": "37701.5", "ups": "0.16", "wpb": "237903", "bsz": "1706.7", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.768", "loss_scale": "8", "train_wall": "867", "gb_free": "39.3", "wall": "13643"}
[2024-10-10 15:07:32,111][train_inner][INFO] - {"epoch": 6, "update": 5.438, "loss": "2.907", "ntokens": "238860", "nsentences": "1767.89", "wps": "70669.5", "ups": "0.3", "wpb": "238860", "bsz": "1767.9", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.737", "loss_scale": "8", "train_wall": "602", "gb_free": "40.1", "wall": "14319"}
[2024-10-10 15:07:32,349][train_inner][INFO] - {"epoch": 6, "update": 5.438, "loss": "2.907", "ntokens": "238860", "nsentences": "1767.89", "wps": "70560.4", "ups": "0.3", "wpb": "238860", "bsz": "1767.9", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.737", "loss_scale": "8", "train_wall": "602", "gb_free": "40.1", "wall": "14286"}
[2024-10-10 15:19:59,045][train_inner][INFO] - {"epoch": 6, "update": 5.856, "loss": "2.867", "ntokens": "238856", "nsentences": "1758.21", "wps": "63961.7", "ups": "0.27", "wpb": "238856", "bsz": "1758.2", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.764", "loss_scale": "8", "train_wall": "699", "gb_free": "40.1", "wall": "15066"}
[2024-10-10 15:19:59,247][train_inner][INFO] - {"epoch": 6, "update": 5.856, "loss": "2.867", "ntokens": "238856", "nsentences": "1758.21", "wps": "63960.2", "ups": "0.27", "wpb": "238856", "bsz": "1758.2", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.764", "loss_scale": "8", "train_wall": "700", "gb_free": "40.1", "wall": "15033"}
[2024-10-10 15:24:09,550][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-10 15:24:09,555][train][INFO] - {"epoch": 6, "train_loss": "2.88", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "53318.1", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "2869", "train_lr": "4.48281e-05", "train_gnorm": "1.762", "train_loss_scale": "8", "train_train_wall": "1518", "train_gb_free": "39.4", "train_wall": "15283"}
[2024-10-10 15:24:09,735][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:24:09,759][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-10 15:24:09,759][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:24:11,212][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2024-10-10 15:24:11,219][train][INFO] - {"epoch": 6, "train_loss": "2.88", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "53224.8", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "2869", "train_lr": "4.48281e-05", "train_gnorm": "1.762", "train_loss_scale": "8", "train_train_wall": "1532", "train_gb_free": "39.4", "train_wall": "15319"}
[2024-10-10 15:24:11,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:24:11,480][fairseq.trainer][INFO] - begin training epoch 7
[2024-10-10 15:24:11,480][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:38:15,207][train_inner][INFO] - {"epoch": 7, "update": 6.273, "loss": "2.82", "ntokens": "237948", "nsentences": "1732.86", "wps": "43423.6", "ups": "0.18", "wpb": "237948", "bsz": "1732.9", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.739", "loss_scale": "8", "train_wall": "638", "gb_free": "40.2", "wall": "16129"}
[2024-10-10 15:38:21,854][train_inner][INFO] - {"epoch": 7, "update": 6.273, "loss": "2.82", "ntokens": "237948", "nsentences": "1732.86", "wps": "43156.2", "ups": "0.18", "wpb": "237948", "bsz": "1732.9", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.739", "loss_scale": "8", "train_wall": "670", "gb_free": "40.2", "wall": "16169"}
[2024-10-10 15:48:48,243][train_inner][INFO] - {"epoch": 7, "update": 6.691, "loss": "2.783", "ntokens": "238920", "nsentences": "1719.13", "wps": "76285.7", "ups": "0.32", "wpb": "238920", "bsz": "1719.1", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.742", "loss_scale": "8", "train_wall": "558", "gb_free": "39.3", "wall": "16796"}
[2024-10-10 15:48:49,934][train_inner][INFO] - {"epoch": 7, "update": 6.691, "loss": "2.783", "ntokens": "238920", "nsentences": "1719.13", "wps": "75841", "ups": "0.32", "wpb": "238920", "bsz": "1719.1", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.742", "loss_scale": "8", "train_wall": "568", "gb_free": "39.3", "wall": "16764"}
[2024-10-10 15:59:06,193][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-10 15:59:06,371][train][INFO] - {"epoch": 7, "train_loss": "2.785", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "54517.8", "train_ups": "0.23", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "3348", "train_lr": "5.23125e-05", "train_gnorm": "1.72", "train_loss_scale": "8", "train_train_wall": "1613", "train_gb_free": "39.9", "train_wall": "17414"}
[2024-10-10 15:59:06,829][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2024-10-10 15:59:06,879][train][INFO] - {"epoch": 7, "train_loss": "2.785", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "54458.9", "train_ups": "0.23", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "3348", "train_lr": "5.23125e-05", "train_gnorm": "1.72", "train_loss_scale": "8", "train_train_wall": "1618", "train_gb_free": "39.9", "train_wall": "17381"}
[2024-10-10 15:59:08,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:59:08,533][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 15:59:08,566][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-10 15:59:08,566][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 15:59:08,596][fairseq.trainer][INFO] - begin training epoch 8
[2024-10-10 15:59:08,631][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 16:13:31,460][train_inner][INFO] - {"epoch": 8, "update": 7.109, "loss": "2.756", "ntokens": "237734", "nsentences": "1782.88", "wps": "32093.5", "ups": "0.13", "wpb": "237734", "bsz": "1782.9", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.703", "loss_scale": "8", "train_wall": "983", "gb_free": "39.6", "wall": "18245"}
[2024-10-10 16:13:31,657][train_inner][INFO] - {"epoch": 8, "update": 7.109, "loss": "2.756", "ntokens": "237734", "nsentences": "1782.88", "wps": "32052.6", "ups": "0.13", "wpb": "237734", "bsz": "1782.9", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.703", "loss_scale": "8", "train_wall": "967", "gb_free": "39.6", "wall": "18279"}
[2024-10-10 16:34:15,454][train_inner][INFO] - {"epoch": 8, "update": 7.526, "loss": "2.715", "ntokens": "238853", "nsentences": "1735.31", "wps": "38407.5", "ups": "0.16", "wpb": "238854", "bsz": "1735.3", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.7", "loss_scale": "8", "train_wall": "1127", "gb_free": "39.6", "wall": "19523"}
[2024-10-10 16:34:15,601][train_inner][INFO] - {"epoch": 8, "update": 7.526, "loss": "2.715", "ntokens": "238853", "nsentences": "1735.31", "wps": "38398.5", "ups": "0.16", "wpb": "238854", "bsz": "1735.3", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.7", "loss_scale": "8", "train_wall": "1131", "gb_free": "39.6", "wall": "19489"}
[2024-10-10 16:56:39,759][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 16:56:45,810][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 16:58:06,759][train_inner][INFO] - {"epoch": 8, "update": 7.946, "loss": "2.698", "ntokens": "238918", "nsentences": "1758.62", "wps": "33386.6", "ups": "0.14", "wpb": "238918", "bsz": "1758.6", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.715", "loss_scale": "4", "train_wall": "1425", "gb_free": "39.2", "wall": "20954"}
[2024-10-10 16:58:08,607][train_inner][INFO] - {"epoch": 8, "update": 7.946, "loss": "2.698", "ntokens": "238918", "nsentences": "1758.62", "wps": "33345.4", "ups": "0.14", "wpb": "238918", "bsz": "1758.6", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.715", "loss_scale": "4", "train_wall": "1424", "gb_free": "39.2", "wall": "20922"}
[2024-10-10 17:00:32,577][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-10 17:00:32,588][train][INFO] - {"epoch": 8, "train_loss": "2.711", "train_ntokens": "238448", "train_nsentences": "1754.57", "train_wps": "30924.5", "train_ups": "0.13", "train_wpb": "238448", "train_bsz": "1754.6", "train_num_updates": "3826", "train_lr": "5.97812e-05", "train_gnorm": "1.708", "train_loss_scale": "4", "train_train_wall": "3130", "train_gb_free": "39.3", "train_wall": "21066"}
[2024-10-10 17:00:32,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:00:32,689][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-10 17:00:32,689][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:00:33,087][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2024-10-10 17:00:33,089][train][INFO] - {"epoch": 8, "train_loss": "2.711", "train_ntokens": "238448", "train_nsentences": "1754.57", "train_wps": "30916.1", "train_ups": "0.13", "train_wpb": "238448", "train_bsz": "1754.6", "train_num_updates": "3826", "train_lr": "5.97812e-05", "train_gnorm": "1.708", "train_loss_scale": "4", "train_train_wall": "3128", "train_gb_free": "39.3", "train_wall": "21100"}
[2024-10-10 17:00:33,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:00:33,150][fairseq.trainer][INFO] - begin training epoch 9
[2024-10-10 17:00:33,150][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:16:52,252][train_inner][INFO] - {"epoch": 9, "update": 8.363, "loss": "2.674", "ntokens": "237768", "nsentences": "1782.27", "wps": "42321.4", "ups": "0.18", "wpb": "237768", "bsz": "1782.3", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.702", "loss_scale": "4", "train_wall": "777", "gb_free": "39.6", "wall": "22046"}
[2024-10-10 17:16:56,639][train_inner][INFO] - {"epoch": 9, "update": 8.363, "loss": "2.674", "ntokens": "237768", "nsentences": "1782.27", "wps": "42087.5", "ups": "0.18", "wpb": "237768", "bsz": "1782.3", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.702", "loss_scale": "4", "train_wall": "766", "gb_free": "39.6", "wall": "22084"}
[2024-10-10 17:28:32,292][train_inner][INFO] - {"epoch": 9, "update": 8.781, "loss": "2.643", "ntokens": "238948", "nsentences": "1765.61", "wps": "68267.9", "ups": "0.29", "wpb": "238948", "bsz": "1765.6", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.631", "loss_scale": "4", "train_wall": "697", "gb_free": "39.8", "wall": "22746"}
[2024-10-10 17:28:33,331][train_inner][INFO] - {"epoch": 9, "update": 8.781, "loss": "2.643", "ntokens": "238948", "nsentences": "1765.61", "wps": "68596.1", "ups": "0.29", "wpb": "238948", "bsz": "1765.6", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.631", "loss_scale": "4", "train_wall": "693", "gb_free": "39.8", "wall": "22781"}
[2024-10-10 17:35:06,173][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-10 17:35:06,187][train][INFO] - {"epoch": 9, "train_loss": "2.647", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "55081.8", "train_ups": "0.23", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "4305", "train_lr": "6.72656e-05", "train_gnorm": "1.649", "train_loss_scale": "4", "train_train_wall": "1723", "train_gb_free": "39.6", "train_wall": "23140"}
[2024-10-10 17:35:06,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:35:06,636][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-10 17:35:06,637][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:35:13,572][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2024-10-10 17:35:13,591][train][INFO] - {"epoch": 9, "train_loss": "2.647", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "54899.4", "train_ups": "0.23", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "4305", "train_lr": "6.72656e-05", "train_gnorm": "1.649", "train_loss_scale": "4", "train_train_wall": "1712", "train_gb_free": "39.6", "train_wall": "23181"}
[2024-10-10 17:35:13,716][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 17:35:13,741][fairseq.trainer][INFO] - begin training epoch 10
[2024-10-10 17:35:13,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 17:46:41,706][train_inner][INFO] - {"epoch": 10, "update": 9.198, "loss": "2.616", "ntokens": "237903", "nsentences": "1716.69", "wps": "43677.7", "ups": "0.18", "wpb": "237903", "bsz": "1716.7", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.626", "loss_scale": "4", "train_wall": "710", "gb_free": "39.6", "wall": "23835"}
[2024-10-10 17:46:51,491][train_inner][INFO] - {"epoch": 10, "update": 9.198, "loss": "2.616", "ntokens": "237903", "nsentences": "1716.69", "wps": "43328", "ups": "0.18", "wpb": "237903", "bsz": "1716.7", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.626", "loss_scale": "4", "train_wall": "727", "gb_free": "39.6", "wall": "23879"}
[2024-10-10 17:57:23,328][train_inner][INFO] - {"epoch": 10, "update": 9.616, "loss": "2.595", "ntokens": "238933", "nsentences": "1751.85", "wps": "74485.4", "ups": "0.31", "wpb": "238933", "bsz": "1751.8", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.592", "loss_scale": "4", "train_wall": "548", "gb_free": "39.3", "wall": "24477"}
[2024-10-10 17:57:39,602][train_inner][INFO] - {"epoch": 10, "update": 9.616, "loss": "2.595", "ntokens": "238933", "nsentences": "1751.85", "wps": "73733.8", "ups": "0.31", "wpb": "238933", "bsz": "1751.8", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.592", "loss_scale": "4", "train_wall": "543", "gb_free": "39.3", "wall": "24527"}
[2024-10-10 18:11:44,952][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 4784 updates
[2024-10-10 18:11:44,953][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 18:11:45,769][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 4784 updates
[2024-10-10 18:11:45,775][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 18:11:50,552][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 18:11:50,556][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 10 @ 4784 updates, score None) (writing took 5.602114264853299 seconds)
[2024-10-10 18:11:50,556][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2024-10-10 18:11:50,559][train][INFO] - {"epoch": 10, "train_loss": "2.591", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "51988.6", "train_ups": "0.22", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "4784", "train_lr": "7.475e-05", "train_gnorm": "1.583", "train_loss_scale": "4", "train_train_wall": "1386", "train_gb_free": "40.1", "train_wall": "25378"}
[2024-10-10 18:11:50,613][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:11:50,632][fairseq.trainer][INFO] - begin training epoch 11
[2024-10-10 18:11:50,632][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:17:38,184][train_inner][INFO] - {"epoch": 11, "update": 10.033, "loss": "2.577", "ntokens": "237755", "nsentences": "1776.43", "wps": "39672.9", "ups": "0.17", "wpb": "237755", "bsz": "1776.4", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.554", "loss_scale": "4", "train_wall": "573", "gb_free": "40.1", "wall": "25726"}
[2024-10-10 18:25:51,805][train_inner][INFO] - {"epoch": 11, "update": 10.451, "loss": "2.552", "ntokens": "238938", "nsentences": "1775.29", "wps": "96819.3", "ups": "0.41", "wpb": "238938", "bsz": "1775.3", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "1.54", "loss_scale": "4", "train_wall": "492", "gb_free": "39.8", "wall": "26219"}
[2024-10-10 18:33:21,498][train_inner][INFO] - {"epoch": 11, "update": 10.868, "loss": "2.533", "ntokens": "238807", "nsentences": "1736.66", "wps": "106217", "ups": "0.44", "wpb": "238807", "bsz": "1736.7", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "1.513", "loss_scale": "4", "train_wall": "399", "gb_free": "39.7", "wall": "26669"}
[2024-10-10 18:35:36,262][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2024-10-10 18:35:36,273][train][INFO] - {"epoch": 11, "train_loss": "2.54", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "80112.4", "train_ups": "0.34", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "5263", "train_lr": "8.22344e-05", "train_gnorm": "1.526", "train_loss_scale": "4", "train_train_wall": "1083", "train_gb_free": "39.3", "train_wall": "26804"}
[2024-10-10 18:35:36,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:35:36,595][fairseq.trainer][INFO] - begin training epoch 12
[2024-10-10 18:35:36,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:42:13,703][train_inner][INFO] - {"epoch": 12, "update": 11.286, "loss": "2.505", "ntokens": "237870", "nsentences": "1709.73", "wps": "89399.4", "ups": "0.38", "wpb": "237870", "bsz": "1709.7", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "1.479", "loss_scale": "4", "train_wall": "237", "gb_free": "39.8", "wall": "27201"}
[2024-10-10 18:45:21,297][train_inner][INFO] - {"epoch": 12, "update": 11.704, "loss": "2.495", "ntokens": "238971", "nsentences": "1758.74", "wps": "254781", "ups": "1.07", "wpb": "238970", "bsz": "1758.7", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "1.448", "loss_scale": "4", "train_wall": "184", "gb_free": "39.6", "wall": "27389"}
[2024-10-10 18:48:00,765][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2024-10-10 18:48:00,792][train][INFO] - {"epoch": 12, "train_loss": "2.494", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153414", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "5742", "train_lr": "8.97187e-05", "train_gnorm": "1.468", "train_loss_scale": "4", "train_train_wall": "421", "train_gb_free": "39.9", "train_wall": "27548"}
[2024-10-10 18:48:01,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 18:48:01,112][fairseq.trainer][INFO] - begin training epoch 13
[2024-10-10 18:48:01,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 18:53:48,449][train_inner][INFO] - {"epoch": 13, "update": 12.121, "loss": "2.485", "ntokens": "237697", "nsentences": "1794.66", "wps": "93740.2", "ups": "0.39", "wpb": "237696", "bsz": "1794.7", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "1.474", "loss_scale": "4", "train_wall": "194", "gb_free": "40.2", "wall": "27896"}
[2024-10-10 18:56:57,039][train_inner][INFO] - {"epoch": 13, "update": 12.539, "loss": "2.451", "ntokens": "238942", "nsentences": "1745.91", "wps": "253411", "ups": "1.06", "wpb": "238942", "bsz": "1745.9", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "1.41", "loss_scale": "8", "train_wall": "184", "gb_free": "39.2", "wall": "28084"}
[2024-10-10 19:00:19,756][train_inner][INFO] - {"epoch": 13, "update": 12.956, "loss": "2.447", "ntokens": "238854", "nsentences": "1766.56", "wps": "235658", "ups": "0.99", "wpb": "238854", "bsz": "1766.6", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "1.382", "loss_scale": "8", "train_wall": "200", "gb_free": "39.4", "wall": "28287"}
[2024-10-10 19:00:24,961][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 19:00:55,038][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2024-10-10 19:00:55,041][train][INFO] - {"epoch": 13, "train_loss": "2.452", "train_ntokens": "238448", "train_nsentences": "1755.03", "train_wps": "147212", "train_ups": "0.62", "train_wpb": "238448", "train_bsz": "1755", "train_num_updates": "6220", "train_lr": "9.71875e-05", "train_gnorm": "1.403", "train_loss_scale": "4", "train_train_wall": "480", "train_gb_free": "39.8", "train_wall": "28322"}
[2024-10-10 19:00:55,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:00:55,188][fairseq.trainer][INFO] - begin training epoch 14
[2024-10-10 19:00:55,188][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:08:35,872][train_inner][INFO] - {"epoch": 14, "update": 13.376, "loss": "2.42", "ntokens": "237867", "nsentences": "1746.83", "wps": "95892.4", "ups": "0.4", "wpb": "237867", "bsz": "1746.8", "num_updates": "6400", "lr": "0.0001", "gnorm": "1.375", "loss_scale": "4", "train_wall": "221", "gb_free": "39.6", "wall": "28783"}
[2024-10-10 19:11:33,153][train_inner][INFO] - {"epoch": 14, "update": 13.793, "loss": "2.408", "ntokens": "238871", "nsentences": "1767.4", "wps": "269490", "ups": "1.13", "wpb": "238871", "bsz": "1767.4", "num_updates": "6600", "lr": "0.000103125", "gnorm": "1.33", "loss_scale": "4", "train_wall": "173", "gb_free": "39.6", "wall": "28961"}
[2024-10-10 19:13:03,364][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2024-10-10 19:13:03,408][train][INFO] - {"epoch": 14, "train_loss": "2.411", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156814", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "6699", "train_lr": "0.000104672", "train_gnorm": "1.347", "train_loss_scale": "4", "train_train_wall": "448", "train_gb_free": "39.1", "train_wall": "29051"}
[2024-10-10 19:13:03,620][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:13:03,636][fairseq.trainer][INFO] - begin training epoch 15
[2024-10-10 19:13:03,636][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:19:34,198][train_inner][INFO] - {"epoch": 15, "update": 14.211, "loss": "2.393", "ntokens": "237781", "nsentences": "1727.75", "wps": "98861.6", "ups": "0.42", "wpb": "237781", "bsz": "1727.8", "num_updates": "6800", "lr": "0.00010625", "gnorm": "1.329", "loss_scale": "4", "train_wall": "179", "gb_free": "41", "wall": "29442"}
[2024-10-10 19:22:28,486][train_inner][INFO] - {"epoch": 15, "update": 14.628, "loss": "2.383", "ntokens": "238911", "nsentences": "1776.3", "wps": "274166", "ups": "1.15", "wpb": "238911", "bsz": "1776.3", "num_updates": "7000", "lr": "0.000109375", "gnorm": "1.277", "loss_scale": "4", "train_wall": "171", "gb_free": "39.6", "wall": "29616"}
[2024-10-10 19:25:18,131][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2024-10-10 19:25:18,134][train][INFO] - {"epoch": 15, "train_loss": "2.376", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155456", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "7178", "train_lr": "0.000112156", "train_gnorm": "1.283", "train_loss_scale": "4", "train_train_wall": "428", "train_gb_free": "40.5", "train_wall": "29786"}
[2024-10-10 19:25:18,261][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:25:18,275][fairseq.trainer][INFO] - begin training epoch 16
[2024-10-10 19:25:18,275][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:30:29,382][train_inner][INFO] - {"epoch": 16, "update": 15.046, "loss": "2.363", "ntokens": "237790", "nsentences": "1734.81", "wps": "98895.8", "ups": "0.42", "wpb": "237790", "bsz": "1734.8", "num_updates": "7200", "lr": "0.0001125", "gnorm": "1.278", "loss_scale": "4", "train_wall": "196", "gb_free": "40.6", "wall": "30097"}
[2024-10-10 19:33:08,232][train_inner][INFO] - {"epoch": 16, "update": 15.463, "loss": "2.343", "ntokens": "238988", "nsentences": "1746.09", "wps": "300906", "ups": "1.26", "wpb": "238988", "bsz": "1746.1", "num_updates": "7400", "lr": "0.000115625", "gnorm": "1.254", "loss_scale": "4", "train_wall": "153", "gb_free": "40.4", "wall": "30256"}
[2024-10-10 19:36:25,776][train_inner][INFO] - {"epoch": 16, "update": 15.881, "loss": "2.344", "ntokens": "238874", "nsentences": "1770.28", "wps": "241858", "ups": "1.01", "wpb": "238874", "bsz": "1770.3", "num_updates": "7600", "lr": "0.00011875", "gnorm": "1.234", "loss_scale": "4", "train_wall": "193", "gb_free": "40.1", "wall": "30453"}
[2024-10-10 19:37:09,134][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2024-10-10 19:37:09,154][train][INFO] - {"epoch": 16, "train_loss": "2.343", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "160641", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "7657", "train_lr": "0.000119641", "train_gnorm": "1.243", "train_loss_scale": "4", "train_train_wall": "418", "train_gb_free": "39.8", "train_wall": "30497"}
[2024-10-10 19:37:09,441][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:37:09,459][fairseq.trainer][INFO] - begin training epoch 17
[2024-10-10 19:37:09,460][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:44:15,796][train_inner][INFO] - {"epoch": 17, "update": 16.299, "loss": "2.323", "ntokens": "237895", "nsentences": "1751.79", "wps": "101229", "ups": "0.43", "wpb": "237895", "bsz": "1751.8", "num_updates": "7800", "lr": "0.000121875", "gnorm": "1.21", "loss_scale": "4", "train_wall": "174", "gb_free": "39.6", "wall": "30923"}
[2024-10-10 19:47:26,723][train_inner][INFO] - {"epoch": 17, "update": 16.716, "loss": "2.31", "ntokens": "238852", "nsentences": "1741.04", "wps": "250209", "ups": "1.05", "wpb": "238852", "bsz": "1741", "num_updates": "8000", "lr": "0.000125", "gnorm": "1.192", "loss_scale": "4", "train_wall": "187", "gb_free": "39.7", "wall": "31114"}
[2024-10-10 19:49:34,711][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2024-10-10 19:49:34,744][train][INFO] - {"epoch": 17, "train_loss": "2.311", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153191", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "8136", "train_lr": "0.000127125", "train_gnorm": "1.189", "train_loss_scale": "4", "train_train_wall": "444", "train_gb_free": "39.2", "train_wall": "31242"}
[2024-10-10 19:49:35,102][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 19:49:35,132][fairseq.trainer][INFO] - begin training epoch 18
[2024-10-10 19:49:35,133][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 19:55:12,749][train_inner][INFO] - {"epoch": 18, "update": 17.134, "loss": "2.299", "ntokens": "237843", "nsentences": "1748.88", "wps": "102074", "ups": "0.43", "wpb": "237843", "bsz": "1748.9", "num_updates": "8200", "lr": "0.000128125", "gnorm": "1.164", "loss_scale": "4", "train_wall": "180", "gb_free": "39.3", "wall": "31580"}
[2024-10-10 19:56:48,986][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 19:58:03,039][train_inner][INFO] - {"epoch": 18, "update": 17.553, "loss": "2.292", "ntokens": "238801", "nsentences": "1775.91", "wps": "280470", "ups": "1.17", "wpb": "238801", "bsz": "1775.9", "num_updates": "8400", "lr": "0.00013125", "gnorm": "1.143", "loss_scale": "4", "train_wall": "166", "gb_free": "39.2", "wall": "31750"}
[2024-10-10 20:01:06,786][train_inner][INFO] - {"epoch": 18, "update": 17.971, "loss": "2.283", "ntokens": "238958", "nsentences": "1747.66", "wps": "260100", "ups": "1.09", "wpb": "238958", "bsz": "1747.7", "num_updates": "8600", "lr": "0.000134375", "gnorm": "1.125", "loss_scale": "4", "train_wall": "180", "gb_free": "39.6", "wall": "31934"}
[2024-10-10 20:01:38,077][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2024-10-10 20:01:38,092][train][INFO] - {"epoch": 18, "train_loss": "2.287", "train_ntokens": "238452", "train_nsentences": "1751.01", "train_wps": "157574", "train_ups": "0.66", "train_wpb": "238452", "train_bsz": "1751", "train_num_updates": "8614", "train_lr": "0.000134594", "train_gnorm": "1.139", "train_loss_scale": "4", "train_train_wall": "431", "train_gb_free": "39.8", "train_wall": "31965"}
[2024-10-10 20:01:38,369][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:01:38,397][fairseq.trainer][INFO] - begin training epoch 19
[2024-10-10 20:01:38,398][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:09:06,415][train_inner][INFO] - {"epoch": 19, "update": 18.388, "loss": "2.265", "ntokens": "237930", "nsentences": "1745.58", "wps": "99214.8", "ups": "0.42", "wpb": "237930", "bsz": "1745.6", "num_updates": "8800", "lr": "0.0001375", "gnorm": "1.107", "loss_scale": "4", "train_wall": "203", "gb_free": "39.6", "wall": "32414"}
[2024-10-10 20:12:20,728][train_inner][INFO] - {"epoch": 19, "update": 18.806, "loss": "2.253", "ntokens": "238777", "nsentences": "1740.41", "wps": "245775", "ups": "1.03", "wpb": "238777", "bsz": "1740.4", "num_updates": "9000", "lr": "0.000140625", "gnorm": "1.083", "loss_scale": "4", "train_wall": "190", "gb_free": "39.3", "wall": "32608"}
[2024-10-10 20:14:07,311][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2024-10-10 20:14:07,331][train][INFO] - {"epoch": 19, "train_loss": "2.259", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152445", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "9093", "train_lr": "0.000142078", "train_gnorm": "1.092", "train_loss_scale": "4", "train_train_wall": "467", "train_gb_free": "39.2", "train_wall": "32715"}
[2024-10-10 20:14:07,461][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:14:07,475][fairseq.trainer][INFO] - begin training epoch 20
[2024-10-10 20:14:07,475][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:20:34,271][train_inner][INFO] - {"epoch": 20, "update": 19.223, "loss": "2.249", "ntokens": "237853", "nsentences": "1788.14", "wps": "96386.9", "ups": "0.41", "wpb": "237853", "bsz": "1788.1", "num_updates": "9200", "lr": "0.00014375", "gnorm": "1.073", "loss_scale": "4", "train_wall": "225", "gb_free": "39.4", "wall": "33102"}
[2024-10-10 20:23:36,742][train_inner][INFO] - {"epoch": 20, "update": 19.641, "loss": "2.238", "ntokens": "238950", "nsentences": "1741.61", "wps": "261913", "ups": "1.1", "wpb": "238950", "bsz": "1741.6", "num_updates": "9400", "lr": "0.000146875", "gnorm": "1.053", "loss_scale": "4", "train_wall": "178", "gb_free": "39.6", "wall": "33284"}
[2024-10-10 20:26:31,137][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 9572 updates
[2024-10-10 20:26:31,143][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 20:26:37,065][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 20:26:37,069][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 20 @ 9572 updates, score None) (writing took 5.932044279761612 seconds)
[2024-10-10 20:26:37,069][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2024-10-10 20:26:37,071][train][INFO] - {"epoch": 20, "train_loss": "2.236", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152343", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "9572", "train_lr": "0.000149562", "train_gnorm": "1.055", "train_loss_scale": "4", "train_train_wall": "468", "train_gb_free": "39.2", "train_wall": "33464"}
[2024-10-10 20:26:37,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:26:37,293][fairseq.trainer][INFO] - begin training epoch 21
[2024-10-10 20:26:37,294][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:31:49,156][train_inner][INFO] - {"epoch": 21, "update": 20.058, "loss": "2.228", "ntokens": "237764", "nsentences": "1748.26", "wps": "96572.6", "ups": "0.41", "wpb": "237764", "bsz": "1748.3", "num_updates": "9600", "lr": "0.00015", "gnorm": "1.052", "loss_scale": "4", "train_wall": "219", "gb_free": "39.3", "wall": "33777"}
[2024-10-10 20:34:26,851][train_inner][INFO] - {"epoch": 21, "update": 20.476, "loss": "2.211", "ntokens": "238797", "nsentences": "1762.52", "wps": "302867", "ups": "1.27", "wpb": "238796", "bsz": "1762.5", "num_updates": "9800", "lr": "0.000153125", "gnorm": "1.016", "loss_scale": "4", "train_wall": "154", "gb_free": "39.3", "wall": "33934"}
[2024-10-10 20:37:51,714][train_inner][INFO] - {"epoch": 21, "update": 20.894, "loss": "2.208", "ntokens": "238995", "nsentences": "1744.79", "wps": "233328", "ups": "0.98", "wpb": "238995", "bsz": "1744.8", "num_updates": "10000", "lr": "0.00015625", "gnorm": "0.984", "loss_scale": "4", "train_wall": "201", "gb_free": "39.1", "wall": "34139"}
[2024-10-10 20:38:45,814][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2024-10-10 20:38:45,817][train][INFO] - {"epoch": 21, "train_loss": "2.211", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156732", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "10051", "train_lr": "0.000157047", "train_gnorm": "1.003", "train_loss_scale": "4", "train_train_wall": "456", "train_gb_free": "39.4", "train_wall": "34193"}
[2024-10-10 20:38:45,968][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:38:45,991][fairseq.trainer][INFO] - begin training epoch 22
[2024-10-10 20:38:45,992][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:45:36,410][train_inner][INFO] - {"epoch": 22, "update": 21.311, "loss": "2.2", "ntokens": "237844", "nsentences": "1756.97", "wps": "102367", "ups": "0.43", "wpb": "237844", "bsz": "1757", "num_updates": "10200", "lr": "0.000159375", "gnorm": "0.981", "loss_scale": "4", "train_wall": "193", "gb_free": "40.1", "wall": "34604"}
[2024-10-10 20:48:35,686][train_inner][INFO] - {"epoch": 22, "update": 21.729, "loss": "2.189", "ntokens": "238918", "nsentences": "1725.31", "wps": "266549", "ups": "1.12", "wpb": "238918", "bsz": "1725.3", "num_updates": "10400", "lr": "0.0001625", "gnorm": "0.956", "loss_scale": "8", "train_wall": "175", "gb_free": "39.9", "wall": "34783"}
[2024-10-10 20:48:49,089][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-10 20:50:49,896][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2024-10-10 20:50:49,909][train][INFO] - {"epoch": 22, "train_loss": "2.192", "train_ntokens": "238453", "train_nsentences": "1753.3", "train_wps": "157412", "train_ups": "0.66", "train_wpb": "238452", "train_bsz": "1753.3", "train_num_updates": "10529", "train_lr": "0.000164516", "train_gnorm": "0.959", "train_loss_scale": "4", "train_train_wall": "447", "train_gb_free": "39.3", "train_wall": "34917"}
[2024-10-10 20:50:50,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 20:50:50,221][fairseq.trainer][INFO] - begin training epoch 23
[2024-10-10 20:50:50,221][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 20:56:45,169][train_inner][INFO] - {"epoch": 23, "update": 22.148, "loss": "2.188", "ntokens": "237826", "nsentences": "1787.41", "wps": "97176.1", "ups": "0.41", "wpb": "237826", "bsz": "1787.4", "num_updates": "10600", "lr": "0.000165625", "gnorm": "0.943", "loss_scale": "4", "train_wall": "208", "gb_free": "40", "wall": "35273"}
[2024-10-10 20:59:32,807][train_inner][INFO] - {"epoch": 23, "update": 22.566, "loss": "2.168", "ntokens": "238960", "nsentences": "1752.6", "wps": "285107", "ups": "1.19", "wpb": "238960", "bsz": "1752.6", "num_updates": "10800", "lr": "0.00016875", "gnorm": "0.917", "loss_scale": "4", "train_wall": "164", "gb_free": "39.3", "wall": "35440"}
[2024-10-10 21:02:28,393][train_inner][INFO] - {"epoch": 23, "update": 22.983, "loss": "2.172", "ntokens": "238797", "nsentences": "1751.47", "wps": "272009", "ups": "1.14", "wpb": "238797", "bsz": "1751.5", "num_updates": "11000", "lr": "0.000171875", "gnorm": "0.917", "loss_scale": "4", "train_wall": "172", "gb_free": "39.6", "wall": "35616"}
[2024-10-10 21:02:43,841][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2024-10-10 21:02:43,848][train][INFO] - {"epoch": 23, "train_loss": "2.171", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159982", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "11008", "train_lr": "0.000172", "train_gnorm": "0.925", "train_loss_scale": "4", "train_train_wall": "427", "train_gb_free": "40.1", "train_wall": "35631"}
[2024-10-10 21:02:44,288][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:02:44,339][fairseq.trainer][INFO] - begin training epoch 24
[2024-10-10 21:02:44,340][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:10:35,106][train_inner][INFO] - {"epoch": 24, "update": 23.401, "loss": "2.156", "ntokens": "237813", "nsentences": "1774.84", "wps": "97725.4", "ups": "0.41", "wpb": "237812", "bsz": "1774.8", "num_updates": "11200", "lr": "0.000175", "gnorm": "0.913", "loss_scale": "4", "train_wall": "203", "gb_free": "39.2", "wall": "36102"}
[2024-10-10 21:13:43,640][train_inner][INFO] - {"epoch": 24, "update": 23.818, "loss": "2.152", "ntokens": "238895", "nsentences": "1758.32", "wps": "253428", "ups": "1.06", "wpb": "238895", "bsz": "1758.3", "num_updates": "11400", "lr": "0.000178125", "gnorm": "0.863", "loss_scale": "4", "train_wall": "185", "gb_free": "39.4", "wall": "36291"}
[2024-10-10 21:15:12,705][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2024-10-10 21:15:12,737][train][INFO] - {"epoch": 24, "train_loss": "2.152", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152516", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "11487", "train_lr": "0.000179484", "train_gnorm": "0.886", "train_loss_scale": "4", "train_train_wall": "460", "train_gb_free": "39.8", "train_wall": "36380"}
[2024-10-10 21:15:13,109][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:15:13,141][fairseq.trainer][INFO] - begin training epoch 25
[2024-10-10 21:15:13,147][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:21:35,723][train_inner][INFO] - {"epoch": 25, "update": 24.236, "loss": "2.138", "ntokens": "237862", "nsentences": "1691.97", "wps": "100772", "ups": "0.42", "wpb": "237862", "bsz": "1692", "num_updates": "11600", "lr": "0.00018125", "gnorm": "0.878", "loss_scale": "4", "train_wall": "170", "gb_free": "39.6", "wall": "36763"}
[2024-10-10 21:24:36,274][train_inner][INFO] - {"epoch": 25, "update": 24.653, "loss": "2.138", "ntokens": "238989", "nsentences": "1757.44", "wps": "264737", "ups": "1.11", "wpb": "238989", "bsz": "1757.4", "num_updates": "11800", "lr": "0.000184375", "gnorm": "0.843", "loss_scale": "4", "train_wall": "177", "gb_free": "39.6", "wall": "36944"}
[2024-10-10 21:27:16,429][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2024-10-10 21:27:16,451][train][INFO] - {"epoch": 25, "train_loss": "2.137", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157823", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "11966", "train_lr": "0.000186969", "train_gnorm": "0.851", "train_loss_scale": "4", "train_train_wall": "417", "train_gb_free": "41", "train_wall": "37104"}
[2024-10-10 21:27:16,746][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:27:16,788][fairseq.trainer][INFO] - begin training epoch 26
[2024-10-10 21:27:16,788][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:32:41,944][train_inner][INFO] - {"epoch": 26, "update": 25.071, "loss": "2.138", "ntokens": "237726", "nsentences": "1783.14", "wps": "97897", "ups": "0.41", "wpb": "237726", "bsz": "1783.1", "num_updates": "12000", "lr": "0.0001875", "gnorm": "0.857", "loss_scale": "4", "train_wall": "205", "gb_free": "40.3", "wall": "37429"}
[2024-10-10 21:35:10,911][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 21:35:22,996][train_inner][INFO] - {"epoch": 26, "update": 25.491, "loss": "2.114", "ntokens": "238921", "nsentences": "1737.25", "wps": "296726", "ups": "1.24", "wpb": "238921", "bsz": "1737.2", "num_updates": "12200", "lr": "0.000190625", "gnorm": "0.818", "loss_scale": "2", "train_wall": "157", "gb_free": "39.8", "wall": "37590"}
[2024-10-10 21:38:35,634][train_inner][INFO] - {"epoch": 26, "update": 25.908, "loss": "2.124", "ntokens": "238961", "nsentences": "1768.27", "wps": "248097", "ups": "1.04", "wpb": "238961", "bsz": "1768.3", "num_updates": "12400", "lr": "0.00019375", "gnorm": "0.804", "loss_scale": "2", "train_wall": "188", "gb_free": "40.6", "wall": "37783"}
[2024-10-10 21:39:26,825][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2024-10-10 21:39:26,843][train][INFO] - {"epoch": 26, "train_loss": "2.122", "train_ntokens": "238454", "train_nsentences": "1753.93", "train_wps": "156058", "train_ups": "0.65", "train_wpb": "238454", "train_bsz": "1753.9", "train_num_updates": "12444", "train_lr": "0.000194438", "train_gnorm": "0.818", "train_loss_scale": "2", "train_train_wall": "443", "train_gb_free": "39.8", "train_wall": "37834"}
[2024-10-10 21:39:27,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:39:27,199][fairseq.trainer][INFO] - begin training epoch 27
[2024-10-10 21:39:27,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:46:17,570][train_inner][INFO] - {"epoch": 27, "update": 26.326, "loss": "2.112", "ntokens": "237748", "nsentences": "1751.04", "wps": "102937", "ups": "0.43", "wpb": "237748", "bsz": "1751", "num_updates": "12600", "lr": "0.000196875", "gnorm": "0.812", "loss_scale": "2", "train_wall": "185", "gb_free": "39.6", "wall": "38245"}
[2024-10-10 21:49:38,795][train_inner][INFO] - {"epoch": 27, "update": 26.743, "loss": "2.102", "ntokens": "238823", "nsentences": "1731.5", "wps": "237373", "ups": "0.99", "wpb": "238823", "bsz": "1731.5", "num_updates": "12800", "lr": "0.0002", "gnorm": "0.778", "loss_scale": "2", "train_wall": "197", "gb_free": "40.6", "wall": "38446"}
[2024-10-10 21:51:46,018][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2024-10-10 21:51:46,025][train][INFO] - {"epoch": 27, "train_loss": "2.107", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154519", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "12923", "train_lr": "0.000201922", "train_gnorm": "0.788", "train_loss_scale": "2", "train_train_wall": "457", "train_gb_free": "39.6", "train_wall": "38573"}
[2024-10-10 21:51:46,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 21:51:46,164][fairseq.trainer][INFO] - begin training epoch 28
[2024-10-10 21:51:46,165][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 21:57:38,296][train_inner][INFO] - {"epoch": 28, "update": 27.161, "loss": "2.107", "ntokens": "237799", "nsentences": "1781.08", "wps": "99187.3", "ups": "0.42", "wpb": "237799", "bsz": "1781.1", "num_updates": "13000", "lr": "0.000203125", "gnorm": "0.773", "loss_scale": "2", "train_wall": "207", "gb_free": "40.2", "wall": "38926"}
[2024-10-10 22:00:23,221][train_inner][INFO] - {"epoch": 28, "update": 27.578, "loss": "2.089", "ntokens": "238906", "nsentences": "1726.69", "wps": "289732", "ups": "1.21", "wpb": "238906", "bsz": "1726.7", "num_updates": "13200", "lr": "0.00020625", "gnorm": "0.767", "loss_scale": "2", "train_wall": "161", "gb_free": "39.2", "wall": "39091"}
[2024-10-10 22:03:42,527][train_inner][INFO] - {"epoch": 28, "update": 27.996, "loss": "2.099", "ntokens": "238974", "nsentences": "1781.98", "wps": "239845", "ups": "1", "wpb": "238974", "bsz": "1782", "num_updates": "13400", "lr": "0.000209375", "gnorm": "0.75", "loss_scale": "2", "train_wall": "195", "gb_free": "39.1", "wall": "39290"}
[2024-10-10 22:03:51,545][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2024-10-10 22:03:51,556][train][INFO] - {"epoch": 28, "train_loss": "2.093", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157426", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "13402", "train_lr": "0.000209406", "train_gnorm": "0.759", "train_loss_scale": "2", "train_train_wall": "448", "train_gb_free": "39.7", "train_wall": "39299"}
[2024-10-10 22:03:51,753][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:03:51,769][fairseq.trainer][INFO] - begin training epoch 29
[2024-10-10 22:03:51,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:11:17,302][train_inner][INFO] - {"epoch": 29, "update": 28.413, "loss": "2.077", "ntokens": "237854", "nsentences": "1748.31", "wps": "104609", "ups": "0.44", "wpb": "237854", "bsz": "1748.3", "num_updates": "13600", "lr": "0.0002125", "gnorm": "0.736", "loss_scale": "2", "train_wall": "178", "gb_free": "40.1", "wall": "39745"}
[2024-10-10 22:14:25,545][train_inner][INFO] - {"epoch": 29, "update": 28.831, "loss": "2.082", "ntokens": "238919", "nsentences": "1773.79", "wps": "253846", "ups": "1.06", "wpb": "238919", "bsz": "1773.8", "num_updates": "13800", "lr": "0.000215625", "gnorm": "0.735", "loss_scale": "2", "train_wall": "168", "gb_free": "39.4", "wall": "39933"}
[2024-10-10 22:15:26,629][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2024-10-10 22:15:26,659][train][INFO] - {"epoch": 29, "train_loss": "2.079", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "164324", "train_ups": "0.69", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "13881", "train_lr": "0.000216891", "train_gnorm": "0.737", "train_loss_scale": "2", "train_train_wall": "393", "train_gb_free": "39.6", "train_wall": "39994"}
[2024-10-10 22:15:26,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:15:27,024][fairseq.trainer][INFO] - begin training epoch 30
[2024-10-10 22:15:27,026][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:22:24,302][train_inner][INFO] - {"epoch": 30, "update": 29.248, "loss": "2.069", "ntokens": "237730", "nsentences": "1715.73", "wps": "99312.4", "ups": "0.42", "wpb": "237730", "bsz": "1715.7", "num_updates": "14000", "lr": "0.00021875", "gnorm": "0.73", "loss_scale": "2", "train_wall": "182", "gb_free": "39.3", "wall": "40412"}
[2024-10-10 22:25:59,926][train_inner][INFO] - {"epoch": 30, "update": 29.666, "loss": "2.069", "ntokens": "238949", "nsentences": "1797.37", "wps": "221658", "ups": "0.93", "wpb": "238949", "bsz": "1797.4", "num_updates": "14200", "lr": "0.000221875", "gnorm": "0.699", "loss_scale": "2", "train_wall": "203", "gb_free": "39.6", "wall": "40627"}
[2024-10-10 22:28:23,628][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 14360 updates
[2024-10-10 22:28:23,630][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 22:28:31,441][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-10 22:28:31,457][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 30 @ 14360 updates, score None) (writing took 7.828257075510919 seconds)
[2024-10-10 22:28:31,457][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2024-10-10 22:28:31,460][train][INFO] - {"epoch": 30, "train_loss": "2.067", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145537", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "14360", "train_lr": "0.000224375", "train_gnorm": "0.707", "train_loss_scale": "4", "train_train_wall": "468", "train_gb_free": "39.6", "train_wall": "40779"}
[2024-10-10 22:28:31,569][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:28:31,605][fairseq.trainer][INFO] - begin training epoch 31
[2024-10-10 22:28:31,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:33:45,983][train_inner][INFO] - {"epoch": 31, "update": 30.084, "loss": "2.066", "ntokens": "237870", "nsentences": "1724.53", "wps": "102079", "ups": "0.43", "wpb": "237870", "bsz": "1724.5", "num_updates": "14400", "lr": "0.000225", "gnorm": "0.712", "loss_scale": "4", "train_wall": "186", "gb_free": "39.9", "wall": "41093"}
[2024-10-10 22:36:34,916][train_inner][INFO] - {"epoch": 31, "update": 30.501, "loss": "2.051", "ntokens": "238859", "nsentences": "1760.64", "wps": "282807", "ups": "1.18", "wpb": "238859", "bsz": "1760.6", "num_updates": "14600", "lr": "0.000228125", "gnorm": "0.684", "loss_scale": "4", "train_wall": "165", "gb_free": "40.1", "wall": "41262"}
[2024-10-10 22:39:52,373][train_inner][INFO] - {"epoch": 31, "update": 30.919, "loss": "2.063", "ntokens": "238891", "nsentences": "1764.35", "wps": "241980", "ups": "1.01", "wpb": "238891", "bsz": "1764.4", "num_updates": "14800", "lr": "0.00023125", "gnorm": "0.688", "loss_scale": "4", "train_wall": "193", "gb_free": "39.7", "wall": "41460"}
[2024-10-10 22:40:28,738][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2024-10-10 22:40:28,759][train][INFO] - {"epoch": 31, "train_loss": "2.058", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159238", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "14839", "train_lr": "0.000231859", "train_gnorm": "0.689", "train_loss_scale": "4", "train_train_wall": "440", "train_gb_free": "39.7", "train_wall": "41496"}
[2024-10-10 22:40:28,915][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:40:28,934][fairseq.trainer][INFO] - begin training epoch 32
[2024-10-10 22:40:28,934][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:47:45,241][train_inner][INFO] - {"epoch": 32, "update": 31.336, "loss": "2.048", "ntokens": "237765", "nsentences": "1775.36", "wps": "100564", "ups": "0.42", "wpb": "237765", "bsz": "1775.4", "num_updates": "15000", "lr": "0.000234375", "gnorm": "0.679", "loss_scale": "4", "train_wall": "180", "gb_free": "39.6", "wall": "41933"}
[2024-10-10 22:51:03,176][train_inner][INFO] - {"epoch": 32, "update": 31.754, "loss": "2.046", "ntokens": "238973", "nsentences": "1759.56", "wps": "241471", "ups": "1.01", "wpb": "238973", "bsz": "1759.6", "num_updates": "15200", "lr": "0.0002375", "gnorm": "0.662", "loss_scale": "4", "train_wall": "194", "gb_free": "39.6", "wall": "42131"}
[2024-10-10 22:52:40,702][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2024-10-10 22:52:40,735][train][INFO] - {"epoch": 32, "train_loss": "2.046", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156042", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "15318", "train_lr": "0.000239344", "train_gnorm": "0.671", "train_loss_scale": "4", "train_train_wall": "434", "train_gb_free": "39.2", "train_wall": "42228"}
[2024-10-10 22:52:40,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 22:52:40,984][fairseq.trainer][INFO] - begin training epoch 33
[2024-10-10 22:52:40,984][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 22:59:07,508][train_inner][INFO] - {"epoch": 33, "update": 32.171, "loss": "2.044", "ntokens": "237853", "nsentences": "1739.36", "wps": "98223", "ups": "0.41", "wpb": "237853", "bsz": "1739.4", "num_updates": "15400", "lr": "0.000240625", "gnorm": "0.668", "loss_scale": "4", "train_wall": "187", "gb_free": "39.7", "wall": "42615"}
[2024-10-10 23:01:55,352][train_inner][INFO] - {"epoch": 33, "update": 32.589, "loss": "2.033", "ntokens": "238896", "nsentences": "1749.54", "wps": "284677", "ups": "1.19", "wpb": "238896", "bsz": "1749.5", "num_updates": "15600", "lr": "0.00024375", "gnorm": "0.651", "loss_scale": "4", "train_wall": "163", "gb_free": "39.9", "wall": "42783"}
[2024-10-10 23:02:53,253][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-10 23:05:20,697][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2024-10-10 23:05:20,750][train][INFO] - {"epoch": 33, "train_loss": "2.036", "train_ntokens": "238450", "train_nsentences": "1755.02", "train_wps": "149970", "train_ups": "0.63", "train_wpb": "238450", "train_bsz": "1755", "train_num_updates": "15796", "train_lr": "0.000246813", "train_gnorm": "0.649", "train_loss_scale": "2", "train_train_wall": "457", "train_gb_free": "39.2", "train_wall": "42988"}
[2024-10-10 23:05:21,365][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:05:21,411][fairseq.trainer][INFO] - begin training epoch 34
[2024-10-10 23:05:21,427][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:10:23,204][train_inner][INFO] - {"epoch": 34, "update": 33.008, "loss": "2.038", "ntokens": "237806", "nsentences": "1728.86", "wps": "93659.6", "ups": "0.39", "wpb": "237806", "bsz": "1728.9", "num_updates": "15800", "lr": "0.000246875", "gnorm": "0.649", "loss_scale": "2", "train_wall": "213", "gb_free": "39.8", "wall": "43291"}
[2024-10-10 23:13:12,229][train_inner][INFO] - {"epoch": 34, "update": 33.426, "loss": "2.023", "ntokens": "238887", "nsentences": "1773.99", "wps": "282691", "ups": "1.18", "wpb": "238887", "bsz": "1774", "num_updates": "16000", "lr": "0.00025", "gnorm": "0.634", "loss_scale": "2", "train_wall": "165", "gb_free": "39.6", "wall": "43460"}
[2024-10-10 23:16:18,614][train_inner][INFO] - {"epoch": 34, "update": 33.843, "loss": "2.032", "ntokens": "238828", "nsentences": "1742.97", "wps": "256279", "ups": "1.07", "wpb": "238828", "bsz": "1743", "num_updates": "16200", "lr": "0.000253125", "gnorm": "0.631", "loss_scale": "2", "train_wall": "183", "gb_free": "39.8", "wall": "43646"}
[2024-10-10 23:17:20,005][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2024-10-10 23:17:20,030][train][INFO] - {"epoch": 34, "train_loss": "2.028", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158797", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "16275", "train_lr": "0.000254297", "train_gnorm": "0.634", "train_loss_scale": "2", "train_train_wall": "419", "train_gb_free": "39.3", "train_wall": "43707"}
[2024-10-10 23:17:20,212][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:17:20,232][fairseq.trainer][INFO] - begin training epoch 35
[2024-10-10 23:17:20,232][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:24:14,990][train_inner][INFO] - {"epoch": 35, "update": 34.261, "loss": "2.022", "ntokens": "237876", "nsentences": "1749.59", "wps": "99870.3", "ups": "0.42", "wpb": "237876", "bsz": "1749.6", "num_updates": "16400", "lr": "0.00025625", "gnorm": "0.63", "loss_scale": "2", "train_wall": "192", "gb_free": "39.6", "wall": "44122"}
[2024-10-10 23:27:20,197][train_inner][INFO] - {"epoch": 35, "update": 34.678, "loss": "2.018", "ntokens": "238893", "nsentences": "1753.63", "wps": "257985", "ups": "1.08", "wpb": "238893", "bsz": "1753.6", "num_updates": "16600", "lr": "0.000259375", "gnorm": "0.621", "loss_scale": "2", "train_wall": "181", "gb_free": "39.6", "wall": "44308"}
[2024-10-10 23:29:25,827][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2024-10-10 23:29:25,871][train][INFO] - {"epoch": 35, "train_loss": "2.02", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157360", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "16754", "train_lr": "0.000261781", "train_gnorm": "0.624", "train_loss_scale": "2", "train_train_wall": "436", "train_gb_free": "40.1", "train_wall": "44433"}
[2024-10-10 23:29:26,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:29:26,580][fairseq.trainer][INFO] - begin training epoch 36
[2024-10-10 23:29:26,580][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:35:10,556][train_inner][INFO] - {"epoch": 36, "update": 35.096, "loss": "2.021", "ntokens": "237888", "nsentences": "1748.25", "wps": "101153", "ups": "0.43", "wpb": "237888", "bsz": "1748.2", "num_updates": "16800", "lr": "0.0002625", "gnorm": "0.623", "loss_scale": "2", "train_wall": "165", "gb_free": "39.8", "wall": "44778"}
[2024-10-10 23:38:03,689][train_inner][INFO] - {"epoch": 36, "update": 35.514, "loss": "2.008", "ntokens": "238808", "nsentences": "1784.41", "wps": "275875", "ups": "1.16", "wpb": "238808", "bsz": "1784.4", "num_updates": "17000", "lr": "0.000265625", "gnorm": "0.609", "loss_scale": "2", "train_wall": "169", "gb_free": "39.6", "wall": "44951"}
[2024-10-10 23:41:10,869][train_inner][INFO] - {"epoch": 36, "update": 35.931, "loss": "2.011", "ntokens": "238955", "nsentences": "1733.78", "wps": "255326", "ups": "1.07", "wpb": "238955", "bsz": "1733.8", "num_updates": "17200", "lr": "0.00026875", "gnorm": "0.599", "loss_scale": "2", "train_wall": "183", "gb_free": "39.3", "wall": "45138"}
[2024-10-10 23:41:43,197][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2024-10-10 23:41:43,216][train][INFO] - {"epoch": 36, "train_loss": "2.01", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154904", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "17233", "train_lr": "0.000269266", "train_gnorm": "0.607", "train_loss_scale": "2", "train_train_wall": "427", "train_gb_free": "39.6", "train_wall": "45171"}
[2024-10-10 23:41:43,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:41:43,475][fairseq.trainer][INFO] - begin training epoch 37
[2024-10-10 23:41:43,475][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 23:49:04,008][train_inner][INFO] - {"epoch": 37, "update": 36.349, "loss": "1.999", "ntokens": "237839", "nsentences": "1746.41", "wps": "100538", "ups": "0.42", "wpb": "237839", "bsz": "1746.4", "num_updates": "17400", "lr": "0.000271875", "gnorm": "0.596", "loss_scale": "2", "train_wall": "198", "gb_free": "39.8", "wall": "45611"}
[2024-10-10 23:52:12,947][train_inner][INFO] - {"epoch": 37, "update": 36.766, "loss": "2.006", "ntokens": "238867", "nsentences": "1784.03", "wps": "252857", "ups": "1.06", "wpb": "238867", "bsz": "1784", "num_updates": "17600", "lr": "0.000275", "gnorm": "0.586", "loss_scale": "2", "train_wall": "185", "gb_free": "39.6", "wall": "45800"}
[2024-10-10 23:54:03,984][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2024-10-10 23:54:04,030][train][INFO] - {"epoch": 37, "train_loss": "2.003", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154180", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "17712", "train_lr": "0.00027675", "train_gnorm": "0.589", "train_loss_scale": "4", "train_train_wall": "460", "train_gb_free": "39.7", "train_wall": "45911"}
[2024-10-10 23:54:04,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 23:54:04,223][fairseq.trainer][INFO] - begin training epoch 38
[2024-10-10 23:54:04,224][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:00:12,867][train_inner][INFO] - {"epoch": 38, "update": 37.184, "loss": "2.002", "ntokens": "237858", "nsentences": "1728.52", "wps": "99126.1", "ups": "0.42", "wpb": "237858", "bsz": "1728.5", "num_updates": "17800", "lr": "0.000278125", "gnorm": "0.592", "loss_scale": "4", "train_wall": "199", "gb_free": "40.3", "wall": "46280"}
[2024-10-11 00:00:23,975][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 00:03:16,171][train_inner][INFO] - {"epoch": 38, "update": 37.603, "loss": "1.994", "ntokens": "238782", "nsentences": "1760.28", "wps": "260540", "ups": "1.09", "wpb": "238782", "bsz": "1760.3", "num_updates": "18000", "lr": "0.00028125", "gnorm": "0.575", "loss_scale": "2", "train_wall": "180", "gb_free": "39.6", "wall": "46464"}
[2024-10-11 00:05:27,442][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 00:06:39,483][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2024-10-11 00:06:39,487][train][INFO] - {"epoch": 38, "train_loss": "1.997", "train_ntokens": "238454", "train_nsentences": "1754.56", "train_wps": "150562", "train_ups": "0.63", "train_wpb": "238454", "train_bsz": "1754.6", "train_num_updates": "18189", "train_lr": "0.000284203", "train_gnorm": "0.58", "train_loss_scale": "1", "train_train_wall": "470", "train_gb_free": "40.1", "train_wall": "46667"}
[2024-10-11 00:06:39,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:06:39,597][fairseq.trainer][INFO] - begin training epoch 39
[2024-10-11 00:06:39,598][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:11:24,546][train_inner][INFO] - {"epoch": 39, "update": 38.023, "loss": "1.998", "ntokens": "237938", "nsentences": "1737.05", "wps": "97442.3", "ups": "0.41", "wpb": "237938", "bsz": "1737", "num_updates": "18200", "lr": "0.000284375", "gnorm": "0.581", "loss_scale": "1", "train_wall": "226", "gb_free": "40.1", "wall": "46952"}
[2024-10-11 00:14:06,827][train_inner][INFO] - {"epoch": 39, "update": 38.441, "loss": "1.982", "ntokens": "238924", "nsentences": "1749.36", "wps": "294465", "ups": "1.23", "wpb": "238924", "bsz": "1749.4", "num_updates": "18400", "lr": "0.0002875", "gnorm": "0.58", "loss_scale": "1", "train_wall": "159", "gb_free": "39.9", "wall": "47114"}
[2024-10-11 00:17:19,536][train_inner][INFO] - {"epoch": 39, "update": 38.858, "loss": "1.993", "ntokens": "238820", "nsentences": "1748.88", "wps": "247868", "ups": "1.04", "wpb": "238820", "bsz": "1748.9", "num_updates": "18600", "lr": "0.000290625", "gnorm": "0.568", "loss_scale": "1", "train_wall": "189", "gb_free": "39.1", "wall": "47307"}
[2024-10-11 00:18:08,701][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2024-10-11 00:18:08,724][train][INFO] - {"epoch": 39, "train_loss": "1.989", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "165718", "train_ups": "0.69", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "18668", "train_lr": "0.000291688", "train_gnorm": "0.575", "train_loss_scale": "1", "train_train_wall": "422", "train_gb_free": "40.1", "train_wall": "47356"}
[2024-10-11 00:18:09,021][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:18:09,044][fairseq.trainer][INFO] - begin training epoch 40
[2024-10-11 00:18:09,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:25:05,652][train_inner][INFO] - {"epoch": 40, "update": 39.276, "loss": "1.98", "ntokens": "237795", "nsentences": "1734.34", "wps": "102034", "ups": "0.43", "wpb": "237795", "bsz": "1734.3", "num_updates": "18800", "lr": "0.00029375", "gnorm": "0.566", "loss_scale": "1", "train_wall": "162", "gb_free": "39.7", "wall": "47773"}
[2024-10-11 00:28:13,385][train_inner][INFO] - {"epoch": 40, "update": 39.693, "loss": "1.986", "ntokens": "238902", "nsentences": "1779.84", "wps": "254521", "ups": "1.07", "wpb": "238902", "bsz": "1779.8", "num_updates": "19000", "lr": "0.000296875", "gnorm": "0.563", "loss_scale": "1", "train_wall": "184", "gb_free": "39.1", "wall": "47961"}
[2024-10-11 00:30:43,496][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 19147 updates
[2024-10-11 00:30:43,503][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 00:30:50,253][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 00:30:50,268][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 40 @ 19147 updates, score None) (writing took 6.77211042586714 seconds)
[2024-10-11 00:30:50,275][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2024-10-11 00:30:50,303][train][INFO] - {"epoch": 40, "train_loss": "1.984", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149979", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "19147", "train_lr": "0.000299172", "train_gnorm": "0.564", "train_loss_scale": "1", "train_train_wall": "445", "train_gb_free": "40.1", "train_wall": "48118"}
[2024-10-11 00:30:50,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:30:50,511][fairseq.trainer][INFO] - begin training epoch 41
[2024-10-11 00:30:50,512][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:36:25,441][train_inner][INFO] - {"epoch": 41, "update": 40.111, "loss": "1.986", "ntokens": "237795", "nsentences": "1754.85", "wps": "96655.8", "ups": "0.41", "wpb": "237795", "bsz": "1754.9", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.568", "loss_scale": "1", "train_wall": "212", "gb_free": "39.3", "wall": "48453"}
[2024-10-11 00:39:12,830][train_inner][INFO] - {"epoch": 41, "update": 40.528, "loss": "1.974", "ntokens": "238903", "nsentences": "1740.6", "wps": "285458", "ups": "1.19", "wpb": "238903", "bsz": "1740.6", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.55", "loss_scale": "1", "train_wall": "163", "gb_free": "40.1", "wall": "48620"}
[2024-10-11 00:42:30,257][train_inner][INFO] - {"epoch": 41, "update": 40.946, "loss": "1.984", "ntokens": "238943", "nsentences": "1785.77", "wps": "242066", "ups": "1.01", "wpb": "238943", "bsz": "1785.8", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.547", "loss_scale": "1", "train_wall": "194", "gb_free": "39.3", "wall": "48818"}
[2024-10-11 00:43:10,971][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2024-10-11 00:43:10,989][train][INFO] - {"epoch": 41, "train_loss": "1.978", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154208", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "19626", "train_lr": "0.000306656", "train_gnorm": "0.552", "train_loss_scale": "1", "train_train_wall": "462", "train_gb_free": "40.5", "train_wall": "48858"}
[2024-10-11 00:43:11,199][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:43:11,219][fairseq.trainer][INFO] - begin training epoch 42
[2024-10-11 00:43:11,220][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 00:50:21,668][train_inner][INFO] - {"epoch": 42, "update": 41.363, "loss": "1.97", "ntokens": "237954", "nsentences": "1723.01", "wps": "100955", "ups": "0.42", "wpb": "237954", "bsz": "1723", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.552", "loss_scale": "1", "train_wall": "209", "gb_free": "39.6", "wall": "49289"}
[2024-10-11 00:53:11,523][train_inner][INFO] - {"epoch": 42, "update": 41.781, "loss": "1.974", "ntokens": "238832", "nsentences": "1743.6", "wps": "281226", "ups": "1.18", "wpb": "238832", "bsz": "1743.6", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.555", "loss_scale": "1", "train_wall": "166", "gb_free": "39.6", "wall": "49459"}
[2024-10-11 00:54:56,799][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2024-10-11 00:54:56,837][train][INFO] - {"epoch": 42, "train_loss": "1.974", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "161817", "train_ups": "0.68", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "20105", "train_lr": "0.000314141", "train_gnorm": "0.552", "train_loss_scale": "1", "train_train_wall": "436", "train_gb_free": "39.3", "train_wall": "49564"}
[2024-10-11 00:54:57,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 00:54:57,268][fairseq.trainer][INFO] - begin training epoch 43
[2024-10-11 00:54:57,268][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:01:03,317][train_inner][INFO] - {"epoch": 43, "update": 42.198, "loss": "1.974", "ntokens": "237845", "nsentences": "1766.28", "wps": "100828", "ups": "0.42", "wpb": "237845", "bsz": "1766.3", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.545", "loss_scale": "2", "train_wall": "192", "gb_free": "39.6", "wall": "49931"}
[2024-10-11 01:04:09,000][train_inner][INFO] - {"epoch": 43, "update": 42.616, "loss": "1.974", "ntokens": "238818", "nsentences": "1794.44", "wps": "257245", "ups": "1.08", "wpb": "238818", "bsz": "1794.4", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.546", "loss_scale": "2", "train_wall": "182", "gb_free": "40.3", "wall": "50116"}
[2024-10-11 01:06:59,003][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2024-10-11 01:06:59,027][train][INFO] - {"epoch": 43, "train_loss": "1.971", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158156", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "20584", "train_lr": "0.000321625", "train_gnorm": "0.544", "train_loss_scale": "2", "train_train_wall": "438", "train_gb_free": "39.3", "train_wall": "50286"}
[2024-10-11 01:06:59,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:06:59,287][fairseq.trainer][INFO] - begin training epoch 44
[2024-10-11 01:06:59,287][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:12:07,157][train_inner][INFO] - {"epoch": 44, "update": 43.033, "loss": "1.972", "ntokens": "237853", "nsentences": "1722.24", "wps": "99489", "ups": "0.42", "wpb": "237853", "bsz": "1722.2", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.549", "loss_scale": "2", "train_wall": "199", "gb_free": "40.2", "wall": "50595"}
[2024-10-11 01:15:10,203][train_inner][INFO] - {"epoch": 44, "update": 43.451, "loss": "1.96", "ntokens": "238847", "nsentences": "1773.4", "wps": "260977", "ups": "1.09", "wpb": "238847", "bsz": "1773.4", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.534", "loss_scale": "2", "train_wall": "180", "gb_free": "39.3", "wall": "50778"}
[2024-10-11 01:18:07,935][train_inner][INFO] - {"epoch": 44, "update": 43.868, "loss": "1.97", "ntokens": "238905", "nsentences": "1741.31", "wps": "268846", "ups": "1.13", "wpb": "238906", "bsz": "1741.3", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.538", "loss_scale": "2", "train_wall": "173", "gb_free": "40.6", "wall": "50955"}
[2024-10-11 01:18:59,062][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2024-10-11 01:18:59,089][train][INFO] - {"epoch": 44, "train_loss": "1.967", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158622", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "21063", "train_lr": "0.000329109", "train_gnorm": "0.538", "train_loss_scale": "2", "train_train_wall": "435", "train_gb_free": "39.2", "train_wall": "51006"}
[2024-10-11 01:18:59,438][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:18:59,483][fairseq.trainer][INFO] - begin training epoch 45
[2024-10-11 01:18:59,483][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:25:58,135][train_inner][INFO] - {"epoch": 45, "update": 44.286, "loss": "1.961", "ntokens": "237888", "nsentences": "1771.76", "wps": "101187", "ups": "0.43", "wpb": "237888", "bsz": "1771.8", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.532", "loss_scale": "2", "train_wall": "177", "gb_free": "40.6", "wall": "51426"}
[2024-10-11 01:29:05,041][train_inner][INFO] - {"epoch": 45, "update": 44.704, "loss": "1.961", "ntokens": "238793", "nsentences": "1753.42", "wps": "255528", "ups": "1.07", "wpb": "238793", "bsz": "1753.4", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.532", "loss_scale": "2", "train_wall": "183", "gb_free": "39.8", "wall": "51612"}
[2024-10-11 01:31:18,730][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2024-10-11 01:31:18,757][train][INFO] - {"epoch": 45, "train_loss": "1.962", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154418", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "21542", "train_lr": "0.000336594", "train_gnorm": "0.531", "train_loss_scale": "2", "train_train_wall": "424", "train_gb_free": "39.7", "train_wall": "51746"}
[2024-10-11 01:31:19,153][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:31:19,181][fairseq.trainer][INFO] - begin training epoch 46
[2024-10-11 01:31:19,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:36:48,947][train_inner][INFO] - {"epoch": 46, "update": 45.121, "loss": "1.962", "ntokens": "237904", "nsentences": "1719.64", "wps": "102567", "ups": "0.43", "wpb": "237904", "bsz": "1719.6", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.531", "loss_scale": "2", "train_wall": "171", "gb_free": "39.4", "wall": "52076"}
[2024-10-11 01:39:59,968][train_inner][INFO] - {"epoch": 46, "update": 45.539, "loss": "1.951", "ntokens": "238845", "nsentences": "1745.31", "wps": "250083", "ups": "1.05", "wpb": "238845", "bsz": "1745.3", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.525", "loss_scale": "2", "train_wall": "187", "gb_free": "39.8", "wall": "52267"}
[2024-10-11 01:43:04,945][train_inner][INFO] - {"epoch": 46, "update": 45.956, "loss": "1.963", "ntokens": "238920", "nsentences": "1769.87", "wps": "258333", "ups": "1.08", "wpb": "238920", "bsz": "1769.9", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.521", "loss_scale": "2", "train_wall": "181", "gb_free": "39.8", "wall": "52452"}
[2024-10-11 01:43:24,102][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2024-10-11 01:43:24,116][train][INFO] - {"epoch": 46, "train_loss": "1.957", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157465", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "22021", "train_lr": "0.000344078", "train_gnorm": "0.525", "train_loss_scale": "2", "train_train_wall": "443", "train_gb_free": "39.3", "train_wall": "52471"}
[2024-10-11 01:43:24,619][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:43:24,662][fairseq.trainer][INFO] - begin training epoch 47
[2024-10-11 01:43:24,662][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 01:51:06,277][train_inner][INFO] - {"epoch": 47, "update": 46.374, "loss": "1.953", "ntokens": "237891", "nsentences": "1750.8", "wps": "98847.5", "ups": "0.42", "wpb": "237890", "bsz": "1750.8", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.524", "loss_scale": "2", "train_wall": "181", "gb_free": "39.3", "wall": "52934"}
[2024-10-11 01:52:34,538][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-11 01:54:18,605][train_inner][INFO] - {"epoch": 47, "update": 46.793, "loss": "1.958", "ntokens": "238939", "nsentences": "1784.77", "wps": "248476", "ups": "1.04", "wpb": "238940", "bsz": "1784.8", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.516", "loss_scale": "2", "train_wall": "189", "gb_free": "39.8", "wall": "53126"}
[2024-10-11 01:55:49,582][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2024-10-11 01:55:49,631][train][INFO] - {"epoch": 47, "train_loss": "1.955", "train_ntokens": "238449", "train_nsentences": "1753.79", "train_wps": "152890", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.8", "train_num_updates": "22499", "train_lr": "0.000351547", "train_gnorm": "0.52", "train_loss_scale": "2", "train_train_wall": "440", "train_gb_free": "39.1", "train_wall": "53217"}
[2024-10-11 01:55:50,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 01:55:50,139][fairseq.trainer][INFO] - begin training epoch 48
[2024-10-11 01:55:50,140][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:02:09,262][train_inner][INFO] - {"epoch": 48, "update": 47.211, "loss": "1.951", "ntokens": "237760", "nsentences": "1733.87", "wps": "101034", "ups": "0.42", "wpb": "237760", "bsz": "1733.9", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.519", "loss_scale": "2", "train_wall": "190", "gb_free": "39.6", "wall": "53597"}
[2024-10-11 02:05:06,108][train_inner][INFO] - {"epoch": 48, "update": 47.628, "loss": "1.949", "ntokens": "238889", "nsentences": "1758.98", "wps": "270179", "ups": "1.13", "wpb": "238889", "bsz": "1759", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.518", "loss_scale": "2", "train_wall": "173", "gb_free": "40.6", "wall": "53773"}
[2024-10-11 02:07:53,309][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2024-10-11 02:07:53,346][train][INFO] - {"epoch": 48, "train_loss": "1.952", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157826", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "22978", "train_lr": "0.000359031", "train_gnorm": "0.521", "train_loss_scale": "2", "train_train_wall": "435", "train_gb_free": "39.9", "train_wall": "53941"}
[2024-10-11 02:07:53,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:07:53,607][fairseq.trainer][INFO] - begin training epoch 49
[2024-10-11 02:07:53,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:13:05,185][train_inner][INFO] - {"epoch": 49, "update": 48.046, "loss": "1.961", "ntokens": "237831", "nsentences": "1753.06", "wps": "99288.9", "ups": "0.42", "wpb": "237832", "bsz": "1753.1", "num_updates": "23000", "lr": "0.000359375", "gnorm": "0.53", "loss_scale": "2", "train_wall": "192", "gb_free": "39.7", "wall": "54253"}
[2024-10-11 02:15:56,777][train_inner][INFO] - {"epoch": 49, "update": 48.463, "loss": "1.944", "ntokens": "238822", "nsentences": "1760.23", "wps": "278371", "ups": "1.17", "wpb": "238822", "bsz": "1760.2", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.51", "loss_scale": "2", "train_wall": "168", "gb_free": "40.1", "wall": "54424"}
[2024-10-11 02:19:06,846][train_inner][INFO] - {"epoch": 49, "update": 48.881, "loss": "1.955", "ntokens": "238923", "nsentences": "1758.82", "wps": "251413", "ups": "1.05", "wpb": "238923", "bsz": "1758.8", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.523", "loss_scale": "2", "train_wall": "186", "gb_free": "39.3", "wall": "54614"}
[2024-10-11 02:20:08,414][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2024-10-11 02:20:08,417][train][INFO] - {"epoch": 49, "train_loss": "1.951", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155383", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "23457", "train_lr": "0.000366516", "train_gnorm": "0.519", "train_loss_scale": "2", "train_train_wall": "445", "train_gb_free": "40.1", "train_wall": "54676"}
[2024-10-11 02:20:08,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:20:08,592][fairseq.trainer][INFO] - begin training epoch 50
[2024-10-11 02:20:08,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:27:08,008][train_inner][INFO] - {"epoch": 50, "update": 49.299, "loss": "1.944", "ntokens": "237830", "nsentences": "1775.07", "wps": "98858", "ups": "0.42", "wpb": "237830", "bsz": "1775.1", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.513", "loss_scale": "2", "train_wall": "211", "gb_free": "39.6", "wall": "55095"}
[2024-10-11 02:30:03,292][train_inner][INFO] - {"epoch": 50, "update": 49.716, "loss": "1.95", "ntokens": "238919", "nsentences": "1752.01", "wps": "272613", "ups": "1.14", "wpb": "238918", "bsz": "1752", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.509", "loss_scale": "2", "train_wall": "171", "gb_free": "39.1", "wall": "55271"}
[2024-10-11 02:32:24,146][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 23936 updates
[2024-10-11 02:32:24,147][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 02:32:28,366][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 02:32:28,370][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 50 @ 23936 updates, score None) (writing took 4.224069597199559 seconds)
[2024-10-11 02:32:28,370][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2024-10-11 02:32:28,372][train][INFO] - {"epoch": 50, "train_loss": "1.948", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154357", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "23936", "train_lr": "0.000374", "train_gnorm": "0.511", "train_loss_scale": "2", "train_train_wall": "459", "train_gb_free": "39.2", "train_wall": "55416"}
[2024-10-11 02:32:28,457][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:32:28,463][fairseq.trainer][INFO] - begin training epoch 51
[2024-10-11 02:32:28,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:38:06,006][train_inner][INFO] - {"epoch": 51, "update": 50.134, "loss": "1.945", "ntokens": "237743", "nsentences": "1713.01", "wps": "98504.3", "ups": "0.41", "wpb": "237743", "bsz": "1713", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.516", "loss_scale": "2", "train_wall": "217", "gb_free": "39.3", "wall": "55753"}
[2024-10-11 02:40:58,092][train_inner][INFO] - {"epoch": 51, "update": 50.551, "loss": "1.943", "ntokens": "238958", "nsentences": "1747.09", "wps": "277727", "ups": "1.16", "wpb": "238958", "bsz": "1747.1", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.508", "loss_scale": "2", "train_wall": "168", "gb_free": "39.3", "wall": "55925"}
[2024-10-11 02:41:12,545][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 02:43:53,795][train_inner][INFO] - {"epoch": 51, "update": 50.971, "loss": "1.954", "ntokens": "238894", "nsentences": "1769.29", "wps": "271936", "ups": "1.14", "wpb": "238894", "bsz": "1769.3", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.52", "loss_scale": "1", "train_wall": "172", "gb_free": "39.8", "wall": "56101"}
[2024-10-11 02:44:29,933][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2024-10-11 02:44:29,941][train][INFO] - {"epoch": 51, "train_loss": "1.946", "train_ntokens": "238447", "train_nsentences": "1753.49", "train_wps": "157960", "train_ups": "0.66", "train_wpb": "238448", "train_bsz": "1753.5", "train_num_updates": "24414", "train_lr": "0.000381469", "train_gnorm": "0.516", "train_loss_scale": "1", "train_train_wall": "455", "train_gb_free": "39.6", "train_wall": "56137"}
[2024-10-11 02:44:30,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:44:30,086][fairseq.trainer][INFO] - begin training epoch 52
[2024-10-11 02:44:30,086][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 02:51:49,298][train_inner][INFO] - {"epoch": 52, "update": 51.388, "loss": "1.936", "ntokens": "237864", "nsentences": "1723.41", "wps": "100048", "ups": "0.42", "wpb": "237864", "bsz": "1723.4", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.514", "loss_scale": "1", "train_wall": "201", "gb_free": "39.3", "wall": "56577"}
[2024-10-11 02:55:04,180][train_inner][INFO] - {"epoch": 52, "update": 51.806, "loss": "1.953", "ntokens": "239008", "nsentences": "1807.09", "wps": "245298", "ups": "1.03", "wpb": "239008", "bsz": "1807.1", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.511", "loss_scale": "1", "train_wall": "187", "gb_free": "39.6", "wall": "56772"}
[2024-10-11 02:56:31,373][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2024-10-11 02:56:31,383][train][INFO] - {"epoch": 52, "train_loss": "1.944", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158320", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "24893", "train_lr": "0.000388953", "train_gnorm": "0.513", "train_loss_scale": "1", "train_train_wall": "438", "train_gb_free": "40.2", "train_wall": "56859"}
[2024-10-11 02:56:31,511][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 02:56:31,526][fairseq.trainer][INFO] - begin training epoch 53
[2024-10-11 02:56:31,527][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:02:47,360][train_inner][INFO] - {"epoch": 53, "update": 52.223, "loss": "1.94", "ntokens": "237700", "nsentences": "1722.63", "wps": "102640", "ups": "0.43", "wpb": "237700", "bsz": "1722.6", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.52", "loss_scale": "1", "train_wall": "180", "gb_free": "40.5", "wall": "57235"}
[2024-10-11 03:05:46,306][train_inner][INFO] - {"epoch": 53, "update": 52.641, "loss": "1.94", "ntokens": "238926", "nsentences": "1750.95", "wps": "267051", "ups": "1.12", "wpb": "238926", "bsz": "1751", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.501", "loss_scale": "1", "train_wall": "175", "gb_free": "40.1", "wall": "57414"}
[2024-10-11 03:08:33,640][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2024-10-11 03:08:33,657][train][INFO] - {"epoch": 53, "train_loss": "1.943", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158137", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "25372", "train_lr": "0.000396437", "train_gnorm": "0.509", "train_loss_scale": "1", "train_train_wall": "433", "train_gb_free": "40.1", "train_wall": "57581"}
[2024-10-11 03:08:34,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:08:34,239][fairseq.trainer][INFO] - begin training epoch 54
[2024-10-11 03:08:34,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:13:48,573][train_inner][INFO] - {"epoch": 54, "update": 53.058, "loss": "1.951", "ntokens": "237732", "nsentences": "1762.05", "wps": "98591.2", "ups": "0.41", "wpb": "237732", "bsz": "1762", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.513", "loss_scale": "1", "train_wall": "203", "gb_free": "39.6", "wall": "57896"}
[2024-10-11 03:16:41,121][train_inner][INFO] - {"epoch": 54, "update": 53.476, "loss": "1.932", "ntokens": "238935", "nsentences": "1727.08", "wps": "276958", "ups": "1.16", "wpb": "238935", "bsz": "1727.1", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.501", "loss_scale": "1", "train_wall": "169", "gb_free": "39.6", "wall": "58068"}
[2024-10-11 03:19:59,696][train_inner][INFO] - {"epoch": 54, "update": 53.894, "loss": "1.949", "ntokens": "238918", "nsentences": "1787.59", "wps": "240636", "ups": "1.01", "wpb": "238918", "bsz": "1787.6", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.51", "loss_scale": "1", "train_wall": "195", "gb_free": "39.6", "wall": "58267"}
[2024-10-11 03:20:27,269][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2024-10-11 03:20:27,295][train][INFO] - {"epoch": 54, "train_loss": "1.942", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "160055", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "25851", "train_lr": "0.000403922", "train_gnorm": "0.509", "train_loss_scale": "1", "train_train_wall": "429", "train_gb_free": "39.4", "train_wall": "58295"}
[2024-10-11 03:20:27,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:20:27,576][fairseq.trainer][INFO] - begin training epoch 55
[2024-10-11 03:20:27,576][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:27:53,056][train_inner][INFO] - {"epoch": 55, "update": 54.311, "loss": "1.937", "ntokens": "237897", "nsentences": "1750.37", "wps": "100516", "ups": "0.42", "wpb": "237897", "bsz": "1750.4", "num_updates": "26000", "lr": "0.00040625", "gnorm": "0.508", "loss_scale": "1", "train_wall": "183", "gb_free": "39.2", "wall": "58740"}
[2024-10-11 03:31:31,056][train_inner][INFO] - {"epoch": 55, "update": 54.729, "loss": "1.941", "ntokens": "238786", "nsentences": "1764.68", "wps": "219081", "ups": "0.92", "wpb": "238786", "bsz": "1764.7", "num_updates": "26200", "lr": "0.000409375", "gnorm": "0.501", "loss_scale": "1", "train_wall": "214", "gb_free": "39.8", "wall": "58958"}
[2024-10-11 03:33:31,514][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2024-10-11 03:33:31,556][train][INFO] - {"epoch": 55, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145637", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "26330", "train_lr": "0.000411406", "train_gnorm": "0.503", "train_loss_scale": "2", "train_train_wall": "489", "train_gb_free": "39.3", "train_wall": "59079"}
[2024-10-11 03:33:32,203][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:33:32,248][fairseq.trainer][INFO] - begin training epoch 56
[2024-10-11 03:33:32,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:39:27,518][train_inner][INFO] - {"epoch": 56, "update": 55.146, "loss": "1.943", "ntokens": "237885", "nsentences": "1736.26", "wps": "99856.1", "ups": "0.42", "wpb": "237885", "bsz": "1736.3", "num_updates": "26400", "lr": "0.0004125", "gnorm": "0.514", "loss_scale": "2", "train_wall": "196", "gb_free": "40.1", "wall": "59435"}
[2024-10-11 03:42:06,598][train_inner][INFO] - {"epoch": 56, "update": 55.564, "loss": "1.936", "ntokens": "238834", "nsentences": "1753.06", "wps": "300278", "ups": "1.26", "wpb": "238834", "bsz": "1753.1", "num_updates": "26600", "lr": "0.000415625", "gnorm": "0.507", "loss_scale": "2", "train_wall": "156", "gb_free": "39.6", "wall": "59594"}
[2024-10-11 03:46:48,179][train_inner][INFO] - {"epoch": 56, "update": 55.981, "loss": "1.943", "ntokens": "238931", "nsentences": "1743.24", "wps": "169717", "ups": "0.71", "wpb": "238931", "bsz": "1743.2", "num_updates": "26800", "lr": "0.00041875", "gnorm": "0.512", "loss_scale": "2", "train_wall": "218", "gb_free": "39.4", "wall": "59876"}
[2024-10-11 03:47:12,188][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2024-10-11 03:47:12,223][train][INFO] - {"epoch": 56, "train_loss": "1.941", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "139183", "train_ups": "0.58", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "26809", "train_lr": "0.000418891", "train_gnorm": "0.511", "train_loss_scale": "2", "train_train_wall": "475", "train_gb_free": "39.2", "train_wall": "59900"}
[2024-10-11 03:47:12,663][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:47:12,708][fairseq.trainer][INFO] - begin training epoch 57
[2024-10-11 03:47:12,708][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 03:52:58,339][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 03:54:51,931][train_inner][INFO] - {"epoch": 57, "update": 56.401, "loss": "1.934", "ntokens": "237911", "nsentences": "1779.15", "wps": "98364.8", "ups": "0.41", "wpb": "237911", "bsz": "1779.2", "num_updates": "27000", "lr": "0.000421875", "gnorm": "0.502", "loss_scale": "1", "train_wall": "199", "gb_free": "39.4", "wall": "60359"}
[2024-10-11 03:57:56,939][train_inner][INFO] - {"epoch": 57, "update": 56.818, "loss": "1.943", "ntokens": "238805", "nsentences": "1766.56", "wps": "258162", "ups": "1.08", "wpb": "238805", "bsz": "1766.6", "num_updates": "27200", "lr": "0.000425", "gnorm": "0.507", "loss_scale": "1", "train_wall": "181", "gb_free": "40.1", "wall": "60544"}
[2024-10-11 03:59:23,591][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2024-10-11 03:59:23,604][train][INFO] - {"epoch": 57, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1754.77", "train_wps": "155841", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1754.8", "train_num_updates": "27287", "train_lr": "0.000426359", "train_gnorm": "0.508", "train_loss_scale": "1", "train_train_wall": "441", "train_gb_free": "39.2", "train_wall": "60631"}
[2024-10-11 03:59:23,762][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 03:59:23,805][fairseq.trainer][INFO] - begin training epoch 58
[2024-10-11 03:59:23,806][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:06:09,012][train_inner][INFO] - {"epoch": 58, "update": 57.236, "loss": "1.937", "ntokens": "237883", "nsentences": "1717.71", "wps": "96687.6", "ups": "0.41", "wpb": "237883", "bsz": "1717.7", "num_updates": "27400", "lr": "0.000428125", "gnorm": "0.504", "loss_scale": "1", "train_wall": "207", "gb_free": "40.3", "wall": "61036"}
[2024-10-11 04:08:57,709][train_inner][INFO] - {"epoch": 58, "update": 57.653, "loss": "1.937", "ntokens": "238835", "nsentences": "1756.45", "wps": "283169", "ups": "1.19", "wpb": "238835", "bsz": "1756.5", "num_updates": "27600", "lr": "0.00043125", "gnorm": "0.498", "loss_scale": "1", "train_wall": "164", "gb_free": "39.6", "wall": "61205"}
[2024-10-11 04:11:53,042][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2024-10-11 04:11:53,061][train][INFO] - {"epoch": 58, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152400", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "27766", "train_lr": "0.000433844", "train_gnorm": "0.498", "train_loss_scale": "1", "train_train_wall": "450", "train_gb_free": "40.2", "train_wall": "61380"}
[2024-10-11 04:11:53,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:11:53,166][fairseq.trainer][INFO] - begin training epoch 59
[2024-10-11 04:11:53,166][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:17:08,579][train_inner][INFO] - {"epoch": 59, "update": 58.071, "loss": "1.947", "ntokens": "237879", "nsentences": "1766.65", "wps": "96922.2", "ups": "0.41", "wpb": "237880", "bsz": "1766.7", "num_updates": "27800", "lr": "0.000434375", "gnorm": "0.509", "loss_scale": "1", "train_wall": "218", "gb_free": "39.6", "wall": "61696"}
[2024-10-11 04:19:55,103][train_inner][INFO] - {"epoch": 59, "update": 58.489, "loss": "1.933", "ntokens": "238916", "nsentences": "1777.04", "wps": "286960", "ups": "1.2", "wpb": "238916", "bsz": "1777", "num_updates": "28000", "lr": "0.0004375", "gnorm": "0.496", "loss_scale": "1", "train_wall": "162", "gb_free": "39.8", "wall": "61862"}
[2024-10-11 04:22:44,434][train_inner][INFO] - {"epoch": 59, "update": 58.906, "loss": "1.944", "ntokens": "238833", "nsentences": "1756.62", "wps": "282110", "ups": "1.18", "wpb": "238833", "bsz": "1756.6", "num_updates": "28200", "lr": "0.000440625", "gnorm": "0.505", "loss_scale": "1", "train_wall": "165", "gb_free": "39.6", "wall": "62032"}
[2024-10-11 04:23:37,738][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2024-10-11 04:23:37,752][train][INFO] - {"epoch": 59, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "162082", "train_ups": "0.68", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "28245", "train_lr": "0.000441328", "train_gnorm": "0.505", "train_loss_scale": "1", "train_train_wall": "433", "train_gb_free": "40.1", "train_wall": "62085"}
[2024-10-11 04:23:37,907][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:23:37,920][fairseq.trainer][INFO] - begin training epoch 60
[2024-10-11 04:23:37,921][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:30:33,719][train_inner][INFO] - {"epoch": 60, "update": 59.324, "loss": "1.93", "ntokens": "237779", "nsentences": "1731.59", "wps": "101339", "ups": "0.43", "wpb": "237779", "bsz": "1731.6", "num_updates": "28400", "lr": "0.00044375", "gnorm": "0.504", "loss_scale": "1", "train_wall": "194", "gb_free": "39.6", "wall": "62501"}
[2024-10-11 04:33:54,048][train_inner][INFO] - {"epoch": 60, "update": 59.741, "loss": "1.943", "ntokens": "238958", "nsentences": "1776.23", "wps": "238576", "ups": "1", "wpb": "238958", "bsz": "1776.2", "num_updates": "28600", "lr": "0.000446875", "gnorm": "0.504", "loss_scale": "1", "train_wall": "196", "gb_free": "39.8", "wall": "62701"}
[2024-10-11 04:35:52,517][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 28724 updates
[2024-10-11 04:35:52,523][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 04:36:00,804][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 04:36:00,836][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 60 @ 28724 updates, score None) (writing took 8.319877619855106 seconds)
[2024-10-11 04:36:00,837][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2024-10-11 04:36:00,839][train][INFO] - {"epoch": 60, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153707", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "28724", "train_lr": "0.000448812", "train_gnorm": "0.505", "train_loss_scale": "1", "train_train_wall": "455", "train_gb_free": "39.6", "train_wall": "62828"}
[2024-10-11 04:36:00,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:36:00,962][fairseq.trainer][INFO] - begin training epoch 61
[2024-10-11 04:36:00,963][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:41:39,379][train_inner][INFO] - {"epoch": 61, "update": 60.159, "loss": "1.935", "ntokens": "237872", "nsentences": "1684.65", "wps": "102239", "ups": "0.43", "wpb": "237872", "bsz": "1684.7", "num_updates": "28800", "lr": "0.00045", "gnorm": "0.508", "loss_scale": "1", "train_wall": "186", "gb_free": "39.3", "wall": "63167"}
[2024-10-11 04:44:36,993][train_inner][INFO] - {"epoch": 61, "update": 60.576, "loss": "1.934", "ntokens": "238950", "nsentences": "1740.75", "wps": "269075", "ups": "1.13", "wpb": "238950", "bsz": "1740.8", "num_updates": "29000", "lr": "0.000453125", "gnorm": "0.507", "loss_scale": "2", "train_wall": "174", "gb_free": "39.8", "wall": "63344"}
[2024-10-11 04:45:52,475][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 04:48:08,652][train_inner][INFO] - {"epoch": 61, "update": 60.996, "loss": "1.954", "ntokens": "238794", "nsentences": "1816.02", "wps": "225651", "ups": "0.94", "wpb": "238794", "bsz": "1816", "num_updates": "29200", "lr": "0.00045625", "gnorm": "0.507", "loss_scale": "1", "train_wall": "191", "gb_free": "39.9", "wall": "63556"}
[2024-10-11 04:48:09,621][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2024-10-11 04:48:09,623][train][INFO] - {"epoch": 61, "train_loss": "1.939", "train_ntokens": "238447", "train_nsentences": "1754.4", "train_wps": "156395", "train_ups": "0.66", "train_wpb": "238447", "train_bsz": "1754.4", "train_num_updates": "29202", "train_lr": "0.000456281", "train_gnorm": "0.506", "train_loss_scale": "1", "train_train_wall": "436", "train_gb_free": "40.1", "train_wall": "63557"}
[2024-10-11 04:48:09,805][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:48:09,809][fairseq.trainer][INFO] - begin training epoch 62
[2024-10-11 04:48:09,809][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 04:55:26,632][train_inner][INFO] - {"epoch": 62, "update": 61.413, "loss": "1.926", "ntokens": "237786", "nsentences": "1720.33", "wps": "108587", "ups": "0.46", "wpb": "237786", "bsz": "1720.3", "num_updates": "29400", "lr": "0.000459375", "gnorm": "0.505", "loss_scale": "1", "train_wall": "170", "gb_free": "39.7", "wall": "63994"}
[2024-10-11 04:58:46,146][train_inner][INFO] - {"epoch": 62, "update": 61.831, "loss": "1.944", "ntokens": "238905", "nsentences": "1767.37", "wps": "239494", "ups": "1", "wpb": "238905", "bsz": "1767.4", "num_updates": "29600", "lr": "0.0004625", "gnorm": "0.51", "loss_scale": "1", "train_wall": "196", "gb_free": "39.2", "wall": "64194"}
[2024-10-11 04:59:57,869][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2024-10-11 04:59:57,914][train][INFO] - {"epoch": 62, "train_loss": "1.938", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "161260", "train_ups": "0.68", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "29681", "train_lr": "0.000463766", "train_gnorm": "0.508", "train_loss_scale": "1", "train_train_wall": "434", "train_gb_free": "39.3", "train_wall": "64265"}
[2024-10-11 04:59:58,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 04:59:58,291][fairseq.trainer][INFO] - begin training epoch 63
[2024-10-11 04:59:58,292][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:06:29,019][train_inner][INFO] - {"epoch": 63, "update": 62.248, "loss": "1.938", "ntokens": "237853", "nsentences": "1743.03", "wps": "102774", "ups": "0.43", "wpb": "237853", "bsz": "1743", "num_updates": "29800", "lr": "0.000465625", "gnorm": "0.505", "loss_scale": "1", "train_wall": "176", "gb_free": "40.2", "wall": "64656"}
[2024-10-11 05:09:37,886][train_inner][INFO] - {"epoch": 63, "update": 62.666, "loss": "1.941", "ntokens": "238880", "nsentences": "1787.53", "wps": "252970", "ups": "1.06", "wpb": "238880", "bsz": "1787.5", "num_updates": "30000", "lr": "0.00046875", "gnorm": "0.511", "loss_scale": "1", "train_wall": "185", "gb_free": "39.3", "wall": "64845"}
[2024-10-11 05:12:10,703][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2024-10-11 05:12:10,724][train][INFO] - {"epoch": 63, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155863", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "30160", "train_lr": "0.00047125", "train_gnorm": "0.506", "train_loss_scale": "1", "train_train_wall": "440", "train_gb_free": "40.6", "train_wall": "64998"}
[2024-10-11 05:12:10,884][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:12:10,892][fairseq.trainer][INFO] - begin training epoch 64
[2024-10-11 05:12:10,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:17:34,287][train_inner][INFO] - {"epoch": 64, "update": 63.084, "loss": "1.944", "ntokens": "237891", "nsentences": "1736.65", "wps": "99871.6", "ups": "0.42", "wpb": "237891", "bsz": "1736.7", "num_updates": "30200", "lr": "0.000471875", "gnorm": "0.512", "loss_scale": "1", "train_wall": "197", "gb_free": "40.2", "wall": "65322"}
[2024-10-11 05:20:33,286][train_inner][INFO] - {"epoch": 64, "update": 63.501, "loss": "1.93", "ntokens": "238855", "nsentences": "1749.68", "wps": "266888", "ups": "1.12", "wpb": "238855", "bsz": "1749.7", "num_updates": "30400", "lr": "0.000475", "gnorm": "0.506", "loss_scale": "1", "train_wall": "175", "gb_free": "39.6", "wall": "65501"}
[2024-10-11 05:23:53,057][train_inner][INFO] - {"epoch": 64, "update": 63.919, "loss": "1.947", "ntokens": "238911", "nsentences": "1781.88", "wps": "239193", "ups": "1", "wpb": "238911", "bsz": "1781.9", "num_updates": "30600", "lr": "0.000478125", "gnorm": "0.511", "loss_scale": "1", "train_wall": "196", "gb_free": "39.7", "wall": "65700"}
[2024-10-11 05:24:25,184][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2024-10-11 05:24:25,208][train][INFO] - {"epoch": 64, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155507", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "30639", "train_lr": "0.000478734", "train_gnorm": "0.51", "train_loss_scale": "1", "train_train_wall": "451", "train_gb_free": "40.6", "train_wall": "65733"}
[2024-10-11 05:24:25,621][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:24:25,669][fairseq.trainer][INFO] - begin training epoch 65
[2024-10-11 05:24:25,669][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:32:09,109][train_inner][INFO] - {"epoch": 65, "update": 64.336, "loss": "1.937", "ntokens": "237859", "nsentences": "1750.89", "wps": "95901.8", "ups": "0.4", "wpb": "237859", "bsz": "1750.9", "num_updates": "30800", "lr": "0.00048125", "gnorm": "0.504", "loss_scale": "1", "train_wall": "200", "gb_free": "40.1", "wall": "66196"}
[2024-10-11 05:35:25,198][train_inner][INFO] - {"epoch": 65, "update": 64.754, "loss": "1.939", "ntokens": "238873", "nsentences": "1737.63", "wps": "243643", "ups": "1.02", "wpb": "238873", "bsz": "1737.6", "num_updates": "31000", "lr": "0.000484375", "gnorm": "0.509", "loss_scale": "1", "train_wall": "192", "gb_free": "40.6", "wall": "66393"}
[2024-10-11 05:37:28,458][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2024-10-11 05:37:28,461][train][INFO] - {"epoch": 65, "train_loss": "1.94", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145826", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "31118", "train_lr": "0.000486219", "train_gnorm": "0.507", "train_loss_scale": "1", "train_train_wall": "483", "train_gb_free": "39.3", "train_wall": "66516"}
[2024-10-11 05:37:28,575][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:37:28,586][fairseq.trainer][INFO] - begin training epoch 66
[2024-10-11 05:37:28,587][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:43:25,052][train_inner][INFO] - {"epoch": 66, "update": 65.171, "loss": "1.946", "ntokens": "237823", "nsentences": "1800.12", "wps": "99125", "ups": "0.42", "wpb": "237824", "bsz": "1800.1", "num_updates": "31200", "lr": "0.0004875", "gnorm": "0.51", "loss_scale": "2", "train_wall": "200", "gb_free": "39.6", "wall": "66872"}
[2024-10-11 05:46:25,887][train_inner][INFO] - {"epoch": 66, "update": 65.589, "loss": "1.936", "ntokens": "238833", "nsentences": "1736.87", "wps": "264157", "ups": "1.11", "wpb": "238833", "bsz": "1736.9", "num_updates": "31400", "lr": "0.000490625", "gnorm": "0.519", "loss_scale": "2", "train_wall": "177", "gb_free": "39.7", "wall": "67053"}
[2024-10-11 05:49:39,465][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2024-10-11 05:49:39,503][train][INFO] - {"epoch": 66, "train_loss": "1.942", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156240", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "31597", "train_lr": "0.000493703", "train_gnorm": "0.513", "train_loss_scale": "2", "train_train_wall": "444", "train_gb_free": "39.7", "train_wall": "67247"}
[2024-10-11 05:49:39,781][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 05:49:39,815][fairseq.trainer][INFO] - begin training epoch 67
[2024-10-11 05:49:39,815][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 05:54:24,946][train_inner][INFO] - {"epoch": 67, "update": 66.006, "loss": "1.947", "ntokens": "237880", "nsentences": "1717.6", "wps": "99312.3", "ups": "0.42", "wpb": "237880", "bsz": "1717.6", "num_updates": "31600", "lr": "0.00049375", "gnorm": "0.511", "loss_scale": "2", "train_wall": "196", "gb_free": "39.3", "wall": "67532"}
[2024-10-11 05:54:27,908][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 05:57:24,046][train_inner][INFO] - {"epoch": 67, "update": 66.426, "loss": "1.936", "ntokens": "238964", "nsentences": "1764.92", "wps": "266859", "ups": "1.12", "wpb": "238964", "bsz": "1764.9", "num_updates": "31800", "lr": "0.000496875", "gnorm": "0.508", "loss_scale": "1", "train_wall": "175", "gb_free": "39.6", "wall": "67711"}
[2024-10-11 06:00:40,223][train_inner][INFO] - {"epoch": 67, "update": 66.843, "loss": "1.947", "ntokens": "238808", "nsentences": "1761.82", "wps": "243467", "ups": "1.02", "wpb": "238808", "bsz": "1761.8", "num_updates": "32000", "lr": "0.0005", "gnorm": "0.519", "loss_scale": "1", "train_wall": "190", "gb_free": "39.7", "wall": "67908"}
[2024-10-11 06:02:03,231][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2024-10-11 06:02:03,253][train][INFO] - {"epoch": 67, "train_loss": "1.942", "train_ntokens": "238451", "train_nsentences": "1753.5", "train_wps": "153250", "train_ups": "0.64", "train_wpb": "238451", "train_bsz": "1753.5", "train_num_updates": "32075", "train_lr": "0.000499898", "train_gnorm": "0.516", "train_loss_scale": "1", "train_train_wall": "451", "train_gb_free": "39.7", "train_wall": "67991"}
[2024-10-11 06:02:03,414][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:02:03,429][fairseq.trainer][INFO] - begin training epoch 68
[2024-10-11 06:02:03,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:08:37,229][train_inner][INFO] - {"epoch": 68, "update": 67.261, "loss": "1.937", "ntokens": "237922", "nsentences": "1717.45", "wps": "99757.8", "ups": "0.42", "wpb": "237922", "bsz": "1717.5", "num_updates": "32200", "lr": "0.000499728", "gnorm": "0.512", "loss_scale": "1", "train_wall": "180", "gb_free": "39.3", "wall": "68385"}
[2024-10-11 06:11:44,747][train_inner][INFO] - {"epoch": 68, "update": 67.678, "loss": "1.94", "ntokens": "238792", "nsentences": "1768.86", "wps": "254700", "ups": "1.07", "wpb": "238792", "bsz": "1768.9", "num_updates": "32400", "lr": "0.000499457", "gnorm": "0.518", "loss_scale": "1", "train_wall": "138", "gb_free": "39.3", "wall": "68572"}
[2024-10-11 06:13:56,984][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2024-10-11 06:13:57,003][train][INFO] - {"epoch": 68, "train_loss": "1.939", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "160025", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "32554", "train_lr": "0.000499247", "train_gnorm": "0.515", "train_loss_scale": "1", "train_train_wall": "355", "train_gb_free": "39.2", "train_wall": "68704"}
[2024-10-11 06:13:57,142][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:13:57,159][fairseq.trainer][INFO] - begin training epoch 69
[2024-10-11 06:13:57,159][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:19:39,069][train_inner][INFO] - {"epoch": 69, "update": 68.096, "loss": "1.941", "ntokens": "237871", "nsentences": "1763.76", "wps": "100300", "ups": "0.42", "wpb": "237871", "bsz": "1763.8", "num_updates": "32600", "lr": "0.000499185", "gnorm": "0.513", "loss_scale": "1", "train_wall": "177", "gb_free": "40.1", "wall": "69046"}
[2024-10-11 06:22:33,332][train_inner][INFO] - {"epoch": 69, "update": 68.514, "loss": "1.934", "ntokens": "238799", "nsentences": "1774.33", "wps": "274080", "ups": "1.15", "wpb": "238799", "bsz": "1774.3", "num_updates": "32800", "lr": "0.000498913", "gnorm": "0.519", "loss_scale": "1", "train_wall": "171", "gb_free": "39.8", "wall": "69221"}
[2024-10-11 06:25:40,776][train_inner][INFO] - {"epoch": 69, "update": 68.931, "loss": "1.939", "ntokens": "238953", "nsentences": "1729.59", "wps": "254965", "ups": "1.07", "wpb": "238953", "bsz": "1729.6", "num_updates": "33000", "lr": "0.000498641", "gnorm": "0.503", "loss_scale": "1", "train_wall": "184", "gb_free": "39.8", "wall": "69408"}
[2024-10-11 06:26:24,104][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2024-10-11 06:26:24,135][train][INFO] - {"epoch": 69, "train_loss": "1.936", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152876", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "33033", "train_lr": "0.000498596", "train_gnorm": "0.511", "train_loss_scale": "1", "train_train_wall": "456", "train_gb_free": "40.1", "train_wall": "69452"}
[2024-10-11 06:26:24,272][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:26:24,280][fairseq.trainer][INFO] - begin training epoch 70
[2024-10-11 06:26:24,281][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:33:33,227][train_inner][INFO] - {"epoch": 70, "update": 69.349, "loss": "1.926", "ntokens": "237904", "nsentences": "1759.8", "wps": "100711", "ups": "0.42", "wpb": "237904", "bsz": "1759.8", "num_updates": "33200", "lr": "0.00049837", "gnorm": "0.503", "loss_scale": "1", "train_wall": "182", "gb_free": "40.1", "wall": "69881"}
[2024-10-11 06:36:38,236][train_inner][INFO] - {"epoch": 70, "update": 69.766, "loss": "1.937", "ntokens": "238921", "nsentences": "1749.29", "wps": "258288", "ups": "1.08", "wpb": "238921", "bsz": "1749.3", "num_updates": "33400", "lr": "0.000498098", "gnorm": "0.505", "loss_scale": "1", "train_wall": "174", "gb_free": "40.1", "wall": "70066"}
[2024-10-11 06:38:34,408][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 33512 updates
[2024-10-11 06:38:34,415][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 06:38:41,141][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 06:38:41,146][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 70 @ 33512 updates, score None) (writing took 6.738140613771975 seconds)
[2024-10-11 06:38:41,148][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2024-10-11 06:38:41,150][train][INFO] - {"epoch": 70, "train_loss": "1.933", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154973", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "33512", "train_lr": "0.000497946", "train_gnorm": "0.506", "train_loss_scale": "1", "train_train_wall": "412", "train_gb_free": "40.5", "train_wall": "70189"}
[2024-10-11 06:38:41,241][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:38:41,247][fairseq.trainer][INFO] - begin training epoch 71
[2024-10-11 06:38:41,247][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:44:46,448][train_inner][INFO] - {"epoch": 71, "update": 70.184, "loss": "1.93", "ntokens": "237762", "nsentences": "1727.41", "wps": "97403", "ups": "0.41", "wpb": "237762", "bsz": "1727.4", "num_updates": "33600", "lr": "0.000497826", "gnorm": "0.518", "loss_scale": "1", "train_wall": "178", "gb_free": "39.6", "wall": "70554"}
[2024-10-11 06:47:51,270][train_inner][INFO] - {"epoch": 71, "update": 70.601, "loss": "1.93", "ntokens": "238805", "nsentences": "1765.97", "wps": "258425", "ups": "1.08", "wpb": "238805", "bsz": "1766", "num_updates": "33800", "lr": "0.000497554", "gnorm": "0.515", "loss_scale": "2", "train_wall": "181", "gb_free": "39.3", "wall": "70739"}
[2024-10-11 06:50:43,657][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2024-10-11 06:50:43,676][train][INFO] - {"epoch": 71, "train_loss": "1.932", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158081", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "33991", "train_lr": "0.000497295", "train_gnorm": "0.517", "train_loss_scale": "2", "train_train_wall": "426", "train_gb_free": "39.8", "train_wall": "70911"}
[2024-10-11 06:50:43,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 06:50:43,968][fairseq.trainer][INFO] - begin training epoch 72
[2024-10-11 06:50:43,969][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 06:56:00,559][train_inner][INFO] - {"epoch": 72, "update": 71.019, "loss": "1.94", "ntokens": "237900", "nsentences": "1764.02", "wps": "97244.5", "ups": "0.41", "wpb": "237900", "bsz": "1764", "num_updates": "34000", "lr": "0.000497283", "gnorm": "0.523", "loss_scale": "2", "train_wall": "168", "gb_free": "39.9", "wall": "71228"}
[2024-10-11 06:58:53,870][train_inner][INFO] - {"epoch": 72, "update": 71.436, "loss": "1.923", "ntokens": "238856", "nsentences": "1777.79", "wps": "275647", "ups": "1.15", "wpb": "238856", "bsz": "1777.8", "num_updates": "34200", "lr": "0.000497011", "gnorm": "0.505", "loss_scale": "2", "train_wall": "148", "gb_free": "39.7", "wall": "71401"}
[2024-10-11 07:02:39,273][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 07:02:50,075][train_inner][INFO] - {"epoch": 72, "update": 71.856, "loss": "1.93", "ntokens": "238935", "nsentences": "1753.64", "wps": "202320", "ups": "0.85", "wpb": "238935", "bsz": "1753.6", "num_updates": "34400", "lr": "0.000496739", "gnorm": "0.506", "loss_scale": "1", "train_wall": "131", "gb_free": "40.6", "wall": "71637"}
[2024-10-11 07:04:06,083][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2024-10-11 07:04:06,090][train][INFO] - {"epoch": 72, "train_loss": "1.926", "train_ntokens": "238447", "train_nsentences": "1753.59", "train_wps": "142045", "train_ups": "0.6", "train_wpb": "238447", "train_bsz": "1753.6", "train_num_updates": "34469", "train_lr": "0.000496645", "train_gnorm": "0.508", "train_loss_scale": "1", "train_train_wall": "357", "train_gb_free": "39.8", "train_wall": "71713"}
[2024-10-11 07:04:06,249][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:04:06,270][fairseq.trainer][INFO] - begin training epoch 73
[2024-10-11 07:04:06,270][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:10:46,498][train_inner][INFO] - {"epoch": 73, "update": 72.273, "loss": "1.92", "ntokens": "237820", "nsentences": "1729.81", "wps": "99837.2", "ups": "0.42", "wpb": "237820", "bsz": "1729.8", "num_updates": "34600", "lr": "0.000496467", "gnorm": "0.507", "loss_scale": "1", "train_wall": "193", "gb_free": "39.4", "wall": "72114"}
[2024-10-11 07:13:42,920][train_inner][INFO] - {"epoch": 73, "update": 72.691, "loss": "1.923", "ntokens": "238949", "nsentences": "1755.36", "wps": "270895", "ups": "1.13", "wpb": "238950", "bsz": "1755.4", "num_updates": "34800", "lr": "0.000496196", "gnorm": "0.502", "loss_scale": "1", "train_wall": "172", "gb_free": "39.3", "wall": "72290"}
[2024-10-11 07:15:54,669][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2024-10-11 07:15:54,851][train][INFO] - {"epoch": 73, "train_loss": "1.924", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "161152", "train_ups": "0.68", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "34948", "train_lr": "0.000495995", "train_gnorm": "0.506", "train_loss_scale": "1", "train_train_wall": "417", "train_gb_free": "39.9", "train_wall": "72422"}
[2024-10-11 07:15:55,502][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:15:55,592][fairseq.trainer][INFO] - begin training epoch 74
[2024-10-11 07:15:55,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:21:30,526][train_inner][INFO] - {"epoch": 74, "update": 73.109, "loss": "1.926", "ntokens": "237825", "nsentences": "1744.57", "wps": "101727", "ups": "0.43", "wpb": "237826", "bsz": "1744.6", "num_updates": "35000", "lr": "0.000495924", "gnorm": "0.512", "loss_scale": "1", "train_wall": "173", "gb_free": "39.9", "wall": "72758"}
[2024-10-11 07:24:30,263][train_inner][INFO] - {"epoch": 74, "update": 73.526, "loss": "1.91", "ntokens": "238758", "nsentences": "1755.38", "wps": "265685", "ups": "1.11", "wpb": "238758", "bsz": "1755.4", "num_updates": "35200", "lr": "0.000495652", "gnorm": "0.504", "loss_scale": "1", "train_wall": "166", "gb_free": "39.3", "wall": "72938"}
[2024-10-11 07:27:52,346][train_inner][INFO] - {"epoch": 74, "update": 73.944, "loss": "1.922", "ntokens": "238955", "nsentences": "1770.79", "wps": "236514", "ups": "0.99", "wpb": "238955", "bsz": "1770.8", "num_updates": "35400", "lr": "0.00049538", "gnorm": "0.502", "loss_scale": "1", "train_wall": "146", "gb_free": "40.1", "wall": "73140"}
[2024-10-11 07:28:34,516][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2024-10-11 07:28:34,541][train][INFO] - {"epoch": 74, "train_loss": "1.916", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150351", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "35427", "train_lr": "0.000495344", "train_gnorm": "0.505", "train_loss_scale": "1", "train_train_wall": "393", "train_gb_free": "39.3", "train_wall": "73182"}
[2024-10-11 07:28:34,891][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:28:34,908][fairseq.trainer][INFO] - begin training epoch 75
[2024-10-11 07:28:34,909][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:35:51,009][train_inner][INFO] - {"epoch": 75, "update": 74.361, "loss": "1.917", "ntokens": "237786", "nsentences": "1773.99", "wps": "99357.3", "ups": "0.42", "wpb": "237786", "bsz": "1774", "num_updates": "35600", "lr": "0.000495109", "gnorm": "0.513", "loss_scale": "1", "train_wall": "200", "gb_free": "40.1", "wall": "73618"}
[2024-10-11 07:39:03,184][train_inner][INFO] - {"epoch": 75, "update": 74.779, "loss": "1.912", "ntokens": "238939", "nsentences": "1740.54", "wps": "248676", "ups": "1.04", "wpb": "238939", "bsz": "1740.5", "num_updates": "35800", "lr": "0.000494837", "gnorm": "0.497", "loss_scale": "1", "train_wall": "188", "gb_free": "40.1", "wall": "73811"}
[2024-10-11 07:40:35,596][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2024-10-11 07:40:35,639][train][INFO] - {"epoch": 75, "train_loss": "1.916", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158398", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "35906", "train_lr": "0.000494693", "train_gnorm": "0.507", "train_loss_scale": "1", "train_train_wall": "441", "train_gb_free": "39.6", "train_wall": "73903"}
[2024-10-11 07:40:36,467][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:40:36,504][fairseq.trainer][INFO] - begin training epoch 76
[2024-10-11 07:40:36,505][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:46:52,342][train_inner][INFO] - {"epoch": 76, "update": 75.196, "loss": "1.911", "ntokens": "237900", "nsentences": "1704.85", "wps": "101419", "ups": "0.43", "wpb": "237900", "bsz": "1704.9", "num_updates": "36000", "lr": "0.000494565", "gnorm": "0.515", "loss_scale": "1", "train_wall": "189", "gb_free": "39.6", "wall": "74280"}
[2024-10-11 07:49:42,016][train_inner][INFO] - {"epoch": 76, "update": 75.614, "loss": "1.901", "ntokens": "238836", "nsentences": "1723.76", "wps": "281533", "ups": "1.18", "wpb": "238836", "bsz": "1723.8", "num_updates": "36200", "lr": "0.000494293", "gnorm": "0.502", "loss_scale": "1", "train_wall": "166", "gb_free": "40.1", "wall": "74449"}
[2024-10-11 07:52:41,130][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2024-10-11 07:52:41,172][train][INFO] - {"epoch": 76, "train_loss": "1.906", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157428", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "36385", "train_lr": "0.000494042", "train_gnorm": "0.508", "train_loss_scale": "1", "train_train_wall": "439", "train_gb_free": "39.2", "train_wall": "74629"}
[2024-10-11 07:52:41,556][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 07:52:41,604][fairseq.trainer][INFO] - begin training epoch 77
[2024-10-11 07:52:41,605][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 07:57:34,966][train_inner][INFO] - {"epoch": 77, "update": 76.031, "loss": "1.915", "ntokens": "237818", "nsentences": "1807.12", "wps": "100570", "ups": "0.42", "wpb": "237818", "bsz": "1807.1", "num_updates": "36400", "lr": "0.000494022", "gnorm": "0.521", "loss_scale": "1", "train_wall": "187", "gb_free": "39.4", "wall": "74922"}
[2024-10-11 07:59:22,001][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 08:00:47,609][train_inner][INFO] - {"epoch": 77, "update": 76.451, "loss": "1.899", "ntokens": "238783", "nsentences": "1778.25", "wps": "247909", "ups": "1.04", "wpb": "238783", "bsz": "1778.2", "num_updates": "36600", "lr": "0.00049375", "gnorm": "0.51", "loss_scale": "1", "train_wall": "188", "gb_free": "39.4", "wall": "75115"}
[2024-10-11 08:04:02,980][train_inner][INFO] - {"epoch": 77, "update": 76.868, "loss": "1.909", "ntokens": "239002", "nsentences": "1774.13", "wps": "244680", "ups": "1.02", "wpb": "239002", "bsz": "1774.1", "num_updates": "36800", "lr": "0.000493478", "gnorm": "0.502", "loss_scale": "1", "train_wall": "191", "gb_free": "40.1", "wall": "75310"}
[2024-10-11 08:05:13,507][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2024-10-11 08:05:13,541][train][INFO] - {"epoch": 77, "train_loss": "1.904", "train_ntokens": "238448", "train_nsentences": "1754.38", "train_wps": "151493", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1754.4", "train_num_updates": "36863", "train_lr": "0.000493393", "train_gnorm": "0.511", "train_loss_scale": "1", "train_train_wall": "464", "train_gb_free": "39.2", "train_wall": "75381"}
[2024-10-11 08:05:13,786][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:05:13,805][fairseq.trainer][INFO] - begin training epoch 78
[2024-10-11 08:05:13,805][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:11:54,386][train_inner][INFO] - {"epoch": 78, "update": 77.286, "loss": "1.899", "ntokens": "237878", "nsentences": "1728.15", "wps": "100924", "ups": "0.42", "wpb": "237878", "bsz": "1728.2", "num_updates": "37000", "lr": "0.000493207", "gnorm": "0.521", "loss_scale": "1", "train_wall": "192", "gb_free": "40.1", "wall": "75782"}
[2024-10-11 08:14:50,151][train_inner][INFO] - {"epoch": 78, "update": 77.704, "loss": "1.898", "ntokens": "238809", "nsentences": "1761.09", "wps": "271747", "ups": "1.14", "wpb": "238809", "bsz": "1761.1", "num_updates": "37200", "lr": "0.000492935", "gnorm": "0.498", "loss_scale": "1", "train_wall": "172", "gb_free": "39.8", "wall": "75958"}
[2024-10-11 08:17:11,454][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2024-10-11 08:17:11,490][train][INFO] - {"epoch": 78, "train_loss": "1.899", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159090", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "37342", "train_lr": "0.000492742", "train_gnorm": "0.507", "train_loss_scale": "1", "train_train_wall": "433", "train_gb_free": "39.3", "train_wall": "76099"}
[2024-10-11 08:17:11,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:17:11,812][fairseq.trainer][INFO] - begin training epoch 79
[2024-10-11 08:17:11,813][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:22:59,540][train_inner][INFO] - {"epoch": 79, "update": 78.121, "loss": "1.903", "ntokens": "237894", "nsentences": "1750.06", "wps": "97222", "ups": "0.41", "wpb": "237894", "bsz": "1750.1", "num_updates": "37400", "lr": "0.000492663", "gnorm": "0.513", "loss_scale": "1", "train_wall": "187", "gb_free": "40.1", "wall": "76447"}
[2024-10-11 08:25:52,759][train_inner][INFO] - {"epoch": 79, "update": 78.539, "loss": "1.889", "ntokens": "238905", "nsentences": "1747.13", "wps": "275849", "ups": "1.15", "wpb": "238906", "bsz": "1747.1", "num_updates": "37600", "lr": "0.000492391", "gnorm": "0.496", "loss_scale": "1", "train_wall": "168", "gb_free": "39.6", "wall": "76620"}
[2024-10-11 08:29:18,102][train_inner][INFO] - {"epoch": 79, "update": 78.956, "loss": "1.903", "ntokens": "238851", "nsentences": "1759.62", "wps": "232641", "ups": "0.97", "wpb": "238850", "bsz": "1759.6", "num_updates": "37800", "lr": "0.00049212", "gnorm": "0.515", "loss_scale": "1", "train_wall": "202", "gb_free": "39.8", "wall": "76825"}
[2024-10-11 08:29:55,276][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2024-10-11 08:29:55,295][train][INFO] - {"epoch": 79, "train_loss": "1.896", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149540", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "37821", "train_lr": "0.000492091", "train_gnorm": "0.508", "train_loss_scale": "1", "train_train_wall": "454", "train_gb_free": "39.3", "train_wall": "76863"}
[2024-10-11 08:29:55,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:29:55,496][fairseq.trainer][INFO] - begin training epoch 80
[2024-10-11 08:29:55,497][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:37:19,363][train_inner][INFO] - {"epoch": 80, "update": 79.374, "loss": "1.887", "ntokens": "237850", "nsentences": "1751.2", "wps": "98845.4", "ups": "0.42", "wpb": "237850", "bsz": "1751.2", "num_updates": "38000", "lr": "0.000491848", "gnorm": "0.518", "loss_scale": "1", "train_wall": "208", "gb_free": "39.3", "wall": "77307"}
[2024-10-11 08:40:29,197][train_inner][INFO] - {"epoch": 80, "update": 79.791, "loss": "1.891", "ntokens": "238800", "nsentences": "1754.76", "wps": "251594", "ups": "1.05", "wpb": "238800", "bsz": "1754.8", "num_updates": "38200", "lr": "0.000491576", "gnorm": "0.511", "loss_scale": "1", "train_wall": "186", "gb_free": "39.3", "wall": "77497"}
[2024-10-11 08:42:07,083][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 38300 updates
[2024-10-11 08:42:07,084][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 08:42:12,415][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 08:42:12,418][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 80 @ 38300 updates, score None) (writing took 5.335142740048468 seconds)
[2024-10-11 08:42:12,424][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2024-10-11 08:42:12,429][train][INFO] - {"epoch": 80, "train_loss": "1.891", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154949", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "38300", "train_lr": "0.00049144", "train_gnorm": "0.514", "train_loss_scale": "1", "train_train_wall": "454", "train_gb_free": "39.8", "train_wall": "77600"}
[2024-10-11 08:42:12,525][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:42:12,561][fairseq.trainer][INFO] - begin training epoch 81
[2024-10-11 08:42:12,561][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 08:48:19,296][train_inner][INFO] - {"epoch": 81, "update": 80.209, "loss": "1.89", "ntokens": "237869", "nsentences": "1733.86", "wps": "101202", "ups": "0.43", "wpb": "237869", "bsz": "1733.9", "num_updates": "38400", "lr": "0.000491304", "gnorm": "0.512", "loss_scale": "1", "train_wall": "189", "gb_free": "39.6", "wall": "77967"}
[2024-10-11 08:51:37,476][train_inner][INFO] - {"epoch": 81, "update": 80.626, "loss": "1.886", "ntokens": "238993", "nsentences": "1766.15", "wps": "241197", "ups": "1.01", "wpb": "238993", "bsz": "1766.2", "num_updates": "38600", "lr": "0.000491033", "gnorm": "0.507", "loss_scale": "2", "train_wall": "194", "gb_free": "40.3", "wall": "78165"}
[2024-10-11 08:53:51,828][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 08:54:54,991][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2024-10-11 08:54:54,996][train][INFO] - {"epoch": 81, "train_loss": "1.889", "train_ntokens": "238452", "train_nsentences": "1753.32", "train_wps": "149470", "train_ups": "0.63", "train_wpb": "238452", "train_bsz": "1753.3", "train_num_updates": "38778", "train_lr": "0.000490791", "train_gnorm": "0.511", "train_loss_scale": "1", "train_train_wall": "481", "train_gb_free": "39.4", "train_wall": "78362"}
[2024-10-11 08:54:55,170][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 08:54:55,181][fairseq.trainer][INFO] - begin training epoch 82
[2024-10-11 08:54:55,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:00:04,015][train_inner][INFO] - {"epoch": 82, "update": 81.046, "loss": "1.896", "ntokens": "237823", "nsentences": "1735.88", "wps": "93902.3", "ups": "0.39", "wpb": "237823", "bsz": "1735.9", "num_updates": "38800", "lr": "0.000490761", "gnorm": "0.52", "loss_scale": "1", "train_wall": "242", "gb_free": "40.1", "wall": "78671"}
[2024-10-11 09:02:54,169][train_inner][INFO] - {"epoch": 82, "update": 81.463, "loss": "1.882", "ntokens": "238906", "nsentences": "1809.67", "wps": "280818", "ups": "1.18", "wpb": "238906", "bsz": "1809.7", "num_updates": "39000", "lr": "0.000490489", "gnorm": "0.508", "loss_scale": "1", "train_wall": "166", "gb_free": "40.1", "wall": "78842"}
[2024-10-11 09:06:28,976][train_inner][INFO] - {"epoch": 82, "update": 81.881, "loss": "1.89", "ntokens": "238842", "nsentences": "1751.2", "wps": "222383", "ups": "0.93", "wpb": "238842", "bsz": "1751.2", "num_updates": "39200", "lr": "0.000490217", "gnorm": "0.516", "loss_scale": "1", "train_wall": "211", "gb_free": "40.1", "wall": "79056"}
[2024-10-11 09:07:29,103][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2024-10-11 09:07:29,105][train][INFO] - {"epoch": 82, "train_loss": "1.886", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151460", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "39257", "train_lr": "0.00049014", "train_gnorm": "0.514", "train_loss_scale": "1", "train_train_wall": "484", "train_gb_free": "40.3", "train_wall": "79116"}
[2024-10-11 09:07:29,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:07:29,273][fairseq.trainer][INFO] - begin training epoch 83
[2024-10-11 09:07:29,275][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:14:19,966][train_inner][INFO] - {"epoch": 83, "update": 82.299, "loss": "1.879", "ntokens": "237811", "nsentences": "1737.81", "wps": "100985", "ups": "0.42", "wpb": "237811", "bsz": "1737.8", "num_updates": "39400", "lr": "0.000489946", "gnorm": "0.515", "loss_scale": "1", "train_wall": "197", "gb_free": "39.1", "wall": "79527"}
[2024-10-11 09:17:20,252][train_inner][INFO] - {"epoch": 83, "update": 82.716, "loss": "1.881", "ntokens": "238905", "nsentences": "1745.63", "wps": "265045", "ups": "1.11", "wpb": "238905", "bsz": "1745.6", "num_updates": "39600", "lr": "0.000489674", "gnorm": "0.519", "loss_scale": "1", "train_wall": "176", "gb_free": "39.4", "wall": "79708"}
[2024-10-11 09:19:46,784][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2024-10-11 09:19:46,804][train][INFO] - {"epoch": 83, "train_loss": "1.881", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154830", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "39736", "train_lr": "0.000489489", "train_gnorm": "0.518", "train_loss_scale": "1", "train_train_wall": "458", "train_gb_free": "39.3", "train_wall": "79854"}
[2024-10-11 09:19:46,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:19:46,951][fairseq.trainer][INFO] - begin training epoch 84
[2024-10-11 09:19:46,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:25:34,818][train_inner][INFO] - {"epoch": 84, "update": 83.134, "loss": "1.879", "ntokens": "237921", "nsentences": "1742.95", "wps": "96215.2", "ups": "0.4", "wpb": "237921", "bsz": "1743", "num_updates": "39800", "lr": "0.000489402", "gnorm": "0.516", "loss_scale": "1", "train_wall": "231", "gb_free": "39.2", "wall": "80202"}
[2024-10-11 09:28:40,744][train_inner][INFO] - {"epoch": 84, "update": 83.551, "loss": "1.873", "ntokens": "238902", "nsentences": "1775.3", "wps": "256994", "ups": "1.08", "wpb": "238902", "bsz": "1775.3", "num_updates": "40000", "lr": "0.00048913", "gnorm": "0.52", "loss_scale": "1", "train_wall": "182", "gb_free": "40.1", "wall": "80388"}
[2024-10-11 09:31:51,958][train_inner][INFO] - {"epoch": 84, "update": 83.969, "loss": "1.882", "ntokens": "238794", "nsentences": "1744.12", "wps": "249773", "ups": "1.05", "wpb": "238794", "bsz": "1744.1", "num_updates": "40200", "lr": "0.000488859", "gnorm": "0.52", "loss_scale": "1", "train_wall": "188", "gb_free": "40.6", "wall": "80579"}
[2024-10-11 09:32:26,308][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2024-10-11 09:32:26,315][train][INFO] - {"epoch": 84, "train_loss": "1.876", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150384", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "40215", "train_lr": "0.000488838", "train_gnorm": "0.518", "train_loss_scale": "1", "train_train_wall": "490", "train_gb_free": "40.1", "train_wall": "80614"}
[2024-10-11 09:32:26,474][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:32:26,488][fairseq.trainer][INFO] - begin training epoch 85
[2024-10-11 09:32:26,489][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:39:57,158][train_inner][INFO] - {"epoch": 85, "update": 84.386, "loss": "1.865", "ntokens": "237883", "nsentences": "1706.23", "wps": "98056.9", "ups": "0.41", "wpb": "237884", "bsz": "1706.2", "num_updates": "40400", "lr": "0.000488587", "gnorm": "0.529", "loss_scale": "1", "train_wall": "217", "gb_free": "39.3", "wall": "81065"}
[2024-10-11 09:43:26,525][train_inner][INFO] - {"epoch": 85, "update": 84.804, "loss": "1.876", "ntokens": "238837", "nsentences": "1787.36", "wps": "228159", "ups": "0.96", "wpb": "238837", "bsz": "1787.4", "num_updates": "40600", "lr": "0.000488315", "gnorm": "0.52", "loss_scale": "1", "train_wall": "205", "gb_free": "39.3", "wall": "81274"}
[2024-10-11 09:45:30,337][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2024-10-11 09:45:30,340][train][INFO] - {"epoch": 85, "train_loss": "1.872", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145683", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "40694", "train_lr": "0.000488188", "train_gnorm": "0.525", "train_loss_scale": "1", "train_train_wall": "512", "train_gb_free": "39.2", "train_wall": "81398"}
[2024-10-11 09:45:30,398][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:45:30,401][fairseq.trainer][INFO] - begin training epoch 86
[2024-10-11 09:45:30,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 09:52:19,796][train_inner][INFO] - {"epoch": 86, "update": 85.221, "loss": "1.871", "ntokens": "237849", "nsentences": "1766.1", "wps": "89205", "ups": "0.38", "wpb": "237849", "bsz": "1766.1", "num_updates": "40800", "lr": "0.000488043", "gnorm": "0.541", "loss_scale": "2", "train_wall": "237", "gb_free": "40.1", "wall": "81807"}
[2024-10-11 09:55:11,662][train_inner][INFO] - {"epoch": 86, "update": 85.639, "loss": "1.87", "ntokens": "239006", "nsentences": "1762.49", "wps": "278153", "ups": "1.16", "wpb": "239006", "bsz": "1762.5", "num_updates": "41000", "lr": "0.000487772", "gnorm": "0.52", "loss_scale": "2", "train_wall": "168", "gb_free": "39.8", "wall": "81979"}
[2024-10-11 09:57:56,867][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2024-10-11 09:57:56,907][train][INFO] - {"epoch": 86, "train_loss": "1.871", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152992", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "41173", "train_lr": "0.000487537", "train_gnorm": "0.532", "train_loss_scale": "2", "train_train_wall": "410", "train_gb_free": "39.6", "train_wall": "82144"}
[2024-10-11 09:57:57,564][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 09:57:57,632][fairseq.trainer][INFO] - begin training epoch 87
[2024-10-11 09:57:57,639][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:03:48,702][train_inner][INFO] - {"epoch": 87, "update": 86.056, "loss": "1.878", "ntokens": "237718", "nsentences": "1731.53", "wps": "91954.5", "ups": "0.39", "wpb": "237718", "bsz": "1731.5", "num_updates": "41200", "lr": "0.0004875", "gnorm": "0.544", "loss_scale": "2", "train_wall": "155", "gb_free": "39.2", "wall": "82496"}
[2024-10-11 10:06:46,953][train_inner][INFO] - {"epoch": 87, "update": 86.474, "loss": "1.857", "ntokens": "238940", "nsentences": "1770.14", "wps": "268102", "ups": "1.12", "wpb": "238940", "bsz": "1770.1", "num_updates": "41400", "lr": "0.000487228", "gnorm": "0.523", "loss_scale": "2", "train_wall": "153", "gb_free": "39.6", "wall": "82674"}
[2024-10-11 10:10:17,343][train_inner][INFO] - {"epoch": 87, "update": 86.891, "loss": "1.868", "ntokens": "238831", "nsentences": "1772.71", "wps": "227045", "ups": "0.95", "wpb": "238831", "bsz": "1772.7", "num_updates": "41600", "lr": "0.000486957", "gnorm": "0.533", "loss_scale": "2", "train_wall": "204", "gb_free": "40.1", "wall": "82885"}
[2024-10-11 10:11:02,812][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2024-10-11 10:11:02,814][train][INFO] - {"epoch": 87, "train_loss": "1.864", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145332", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "41652", "train_lr": "0.000486886", "train_gnorm": "0.534", "train_loss_scale": "2", "train_train_wall": "428", "train_gb_free": "40.1", "train_wall": "82930"}
[2024-10-11 10:11:05,223][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:11:05,394][fairseq.trainer][INFO] - begin training epoch 88
[2024-10-11 10:11:05,394][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:18:04,478][train_inner][INFO] - {"epoch": 88, "update": 87.309, "loss": "1.857", "ntokens": "237845", "nsentences": "1692", "wps": "101833", "ups": "0.43", "wpb": "237845", "bsz": "1692", "num_updates": "41800", "lr": "0.000486685", "gnorm": "0.538", "loss_scale": "2", "train_wall": "176", "gb_free": "39.3", "wall": "83352"}
[2024-10-11 10:20:50,405][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 10:21:12,680][train_inner][INFO] - {"epoch": 88, "update": 87.729, "loss": "1.866", "ntokens": "238958", "nsentences": "1792.05", "wps": "253945", "ups": "1.06", "wpb": "238958", "bsz": "1792", "num_updates": "42000", "lr": "0.000486413", "gnorm": "0.533", "loss_scale": "1", "train_wall": "184", "gb_free": "40.1", "wall": "83540"}
[2024-10-11 10:23:22,564][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2024-10-11 10:23:22,604][train][INFO] - {"epoch": 88, "train_loss": "1.862", "train_ntokens": "238453", "train_nsentences": "1754.23", "train_wps": "154072", "train_ups": "0.65", "train_wpb": "238453", "train_bsz": "1754.2", "train_num_updates": "42130", "train_lr": "0.000486236", "train_gnorm": "0.533", "train_loss_scale": "1", "train_train_wall": "444", "train_gb_free": "39.6", "train_wall": "83670"}
[2024-10-11 10:23:23,085][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:23:23,112][fairseq.trainer][INFO] - begin training epoch 89
[2024-10-11 10:23:23,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:29:18,960][train_inner][INFO] - {"epoch": 89, "update": 88.146, "loss": "1.864", "ntokens": "237812", "nsentences": "1737.88", "wps": "97810", "ups": "0.41", "wpb": "237812", "bsz": "1737.9", "num_updates": "42200", "lr": "0.000486141", "gnorm": "0.531", "loss_scale": "1", "train_wall": "200", "gb_free": "39.9", "wall": "84026"}
[2024-10-11 10:32:16,236][train_inner][INFO] - {"epoch": 89, "update": 88.564, "loss": "1.845", "ntokens": "238821", "nsentences": "1718.96", "wps": "269448", "ups": "1.13", "wpb": "238821", "bsz": "1719", "num_updates": "42400", "lr": "0.00048587", "gnorm": "0.535", "loss_scale": "1", "train_wall": "172", "gb_free": "40.1", "wall": "84204"}
[2024-10-11 10:35:19,038][train_inner][INFO] - {"epoch": 89, "update": 88.981, "loss": "1.87", "ntokens": "238937", "nsentences": "1801.72", "wps": "261432", "ups": "1.09", "wpb": "238937", "bsz": "1801.7", "num_updates": "42600", "lr": "0.000485598", "gnorm": "0.555", "loss_scale": "1", "train_wall": "177", "gb_free": "39.3", "wall": "84386"}
[2024-10-11 10:36:01,976][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2024-10-11 10:36:01,979][train][INFO] - {"epoch": 89, "train_loss": "1.857", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150410", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "42609", "train_lr": "0.000485586", "train_gnorm": "0.544", "train_loss_scale": "1", "train_train_wall": "464", "train_gb_free": "40.1", "train_wall": "84429"}
[2024-10-11 10:36:02,075][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:36:02,079][fairseq.trainer][INFO] - begin training epoch 90
[2024-10-11 10:36:02,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:43:37,669][train_inner][INFO] - {"epoch": 90, "update": 89.399, "loss": "1.852", "ntokens": "237764", "nsentences": "1800.22", "wps": "95380.2", "ups": "0.4", "wpb": "237764", "bsz": "1800.2", "num_updates": "42800", "lr": "0.000485326", "gnorm": "0.533", "loss_scale": "1", "train_wall": "234", "gb_free": "40.2", "wall": "84885"}
[2024-10-11 10:46:44,822][train_inner][INFO] - {"epoch": 90, "update": 89.816, "loss": "1.854", "ntokens": "238957", "nsentences": "1738.79", "wps": "255378", "ups": "1.07", "wpb": "238957", "bsz": "1738.8", "num_updates": "43000", "lr": "0.000485054", "gnorm": "0.535", "loss_scale": "1", "train_wall": "184", "gb_free": "39.6", "wall": "85072"}
[2024-10-11 10:47:48,173][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 43088 updates
[2024-10-11 10:47:48,174][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 10:48:00,439][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 10:48:01,205][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 90 @ 43088 updates, score None) (writing took 13.03276783414185 seconds)
[2024-10-11 10:48:01,226][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2024-10-11 10:48:01,234][train][INFO] - {"epoch": 90, "train_loss": "1.854", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158801", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "43088", "train_lr": "0.000484935", "train_gnorm": "0.541", "train_loss_scale": "1", "train_train_wall": "436", "train_gb_free": "39.3", "train_wall": "85149"}
[2024-10-11 10:48:01,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 10:48:01,771][fairseq.trainer][INFO] - begin training epoch 91
[2024-10-11 10:48:01,772][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 10:54:31,243][train_inner][INFO] - {"epoch": 91, "update": 90.234, "loss": "1.851", "ntokens": "237915", "nsentences": "1716.4", "wps": "102018", "ups": "0.43", "wpb": "237915", "bsz": "1716.4", "num_updates": "43200", "lr": "0.000484783", "gnorm": "0.556", "loss_scale": "1", "train_wall": "172", "gb_free": "41", "wall": "85539"}
[2024-10-11 10:57:36,335][train_inner][INFO] - {"epoch": 91, "update": 90.651, "loss": "1.846", "ntokens": "238823", "nsentences": "1742.65", "wps": "258075", "ups": "1.08", "wpb": "238823", "bsz": "1742.7", "num_updates": "43400", "lr": "0.000484511", "gnorm": "0.545", "loss_scale": "1", "train_wall": "181", "gb_free": "40.6", "wall": "85724"}
[2024-10-11 11:00:29,980][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2024-10-11 11:00:29,992][train][INFO] - {"epoch": 91, "train_loss": "1.85", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152543", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "43567", "train_lr": "0.000484284", "train_gnorm": "0.547", "train_loss_scale": "1", "train_train_wall": "461", "train_gb_free": "39.6", "train_wall": "85897"}
[2024-10-11 11:00:30,177][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:00:30,180][fairseq.trainer][INFO] - begin training epoch 92
[2024-10-11 11:00:30,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:05:34,969][train_inner][INFO] - {"epoch": 92, "update": 91.069, "loss": "1.854", "ntokens": "237821", "nsentences": "1760.58", "wps": "99375.9", "ups": "0.42", "wpb": "237821", "bsz": "1760.6", "num_updates": "43600", "lr": "0.000484239", "gnorm": "0.555", "loss_scale": "1", "train_wall": "211", "gb_free": "39.6", "wall": "86202"}
[2024-10-11 11:08:26,137][train_inner][INFO] - {"epoch": 92, "update": 91.486, "loss": "1.845", "ntokens": "238931", "nsentences": "1766.27", "wps": "279184", "ups": "1.17", "wpb": "238931", "bsz": "1766.3", "num_updates": "43800", "lr": "0.000483967", "gnorm": "0.554", "loss_scale": "1", "train_wall": "167", "gb_free": "40.1", "wall": "86374"}
[2024-10-11 11:11:44,420][train_inner][INFO] - {"epoch": 92, "update": 91.904, "loss": "1.848", "ntokens": "238860", "nsentences": "1732.32", "wps": "240940", "ups": "1.01", "wpb": "238860", "bsz": "1732.3", "num_updates": "44000", "lr": "0.000483696", "gnorm": "0.547", "loss_scale": "1", "train_wall": "195", "gb_free": "39.7", "wall": "86572"}
[2024-10-11 11:12:46,050][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2024-10-11 11:12:46,077][train][INFO] - {"epoch": 92, "train_loss": "1.847", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155169", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "44046", "train_lr": "0.000483633", "train_gnorm": "0.549", "train_loss_scale": "2", "train_train_wall": "463", "train_gb_free": "39.8", "train_wall": "86633"}
[2024-10-11 11:12:46,331][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:12:46,368][fairseq.trainer][INFO] - begin training epoch 93
[2024-10-11 11:12:46,368][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:17:33,467][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 11:19:29,774][train_inner][INFO] - {"epoch": 93, "update": 92.324, "loss": "1.838", "ntokens": "237794", "nsentences": "1749.14", "wps": "102200", "ups": "0.43", "wpb": "237794", "bsz": "1749.1", "num_updates": "44200", "lr": "0.000483424", "gnorm": "0.543", "loss_scale": "1", "train_wall": "194", "gb_free": "40.1", "wall": "87037"}
[2024-10-11 11:22:55,372][train_inner][INFO] - {"epoch": 93, "update": 92.741, "loss": "1.843", "ntokens": "238911", "nsentences": "1761.6", "wps": "232414", "ups": "0.97", "wpb": "238911", "bsz": "1761.6", "num_updates": "44400", "lr": "0.000483152", "gnorm": "0.562", "loss_scale": "1", "train_wall": "202", "gb_free": "39.6", "wall": "87243"}
[2024-10-11 11:25:21,138][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2024-10-11 11:25:21,142][train][INFO] - {"epoch": 93, "train_loss": "1.842", "train_ntokens": "238448", "train_nsentences": "1754.49", "train_wps": "150952", "train_ups": "0.63", "train_wpb": "238448", "train_bsz": "1754.5", "train_num_updates": "44524", "train_lr": "0.000482984", "train_gnorm": "0.555", "train_loss_scale": "1", "train_train_wall": "479", "train_gb_free": "40.5", "train_wall": "87389"}
[2024-10-11 11:25:21,247][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:25:21,261][fairseq.trainer][INFO] - begin training epoch 94
[2024-10-11 11:25:21,262][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:31:08,920][train_inner][INFO] - {"epoch": 94, "update": 93.159, "loss": "1.842", "ntokens": "237867", "nsentences": "1763.04", "wps": "96391.9", "ups": "0.41", "wpb": "237867", "bsz": "1763", "num_updates": "44600", "lr": "0.00048288", "gnorm": "0.555", "loss_scale": "1", "train_wall": "217", "gb_free": "39.4", "wall": "87736"}
[2024-10-11 11:34:02,825][train_inner][INFO] - {"epoch": 94, "update": 93.576, "loss": "1.835", "ntokens": "238890", "nsentences": "1751.72", "wps": "274744", "ups": "1.15", "wpb": "238890", "bsz": "1751.7", "num_updates": "44800", "lr": "0.000482609", "gnorm": "0.558", "loss_scale": "1", "train_wall": "162", "gb_free": "40.6", "wall": "87910"}
[2024-10-11 11:37:23,738][train_inner][INFO] - {"epoch": 94, "update": 93.994, "loss": "1.849", "ntokens": "238855", "nsentences": "1759.54", "wps": "237851", "ups": "1", "wpb": "238855", "bsz": "1759.5", "num_updates": "45000", "lr": "0.000482337", "gnorm": "0.558", "loss_scale": "1", "train_wall": "198", "gb_free": "39.4", "wall": "88111"}
[2024-10-11 11:37:30,018][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2024-10-11 11:37:30,031][train][INFO] - {"epoch": 94, "train_loss": "1.84", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156703", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "45003", "train_lr": "0.000482333", "train_gnorm": "0.558", "train_loss_scale": "1", "train_train_wall": "439", "train_gb_free": "39.7", "train_wall": "88117"}
[2024-10-11 11:37:30,241][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:37:30,259][fairseq.trainer][INFO] - begin training epoch 95
[2024-10-11 11:37:30,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:45:10,489][train_inner][INFO] - {"epoch": 95, "update": 94.411, "loss": "1.832", "ntokens": "237904", "nsentences": "1760.74", "wps": "101948", "ups": "0.43", "wpb": "237904", "bsz": "1760.7", "num_updates": "45200", "lr": "0.000482065", "gnorm": "0.543", "loss_scale": "1", "train_wall": "189", "gb_free": "40.1", "wall": "88578"}
[2024-10-11 11:48:08,777][train_inner][INFO] - {"epoch": 95, "update": 94.829, "loss": "1.843", "ntokens": "238918", "nsentences": "1791.62", "wps": "268027", "ups": "1.12", "wpb": "238918", "bsz": "1791.6", "num_updates": "45400", "lr": "0.000481793", "gnorm": "0.567", "loss_scale": "1", "train_wall": "174", "gb_free": "39.3", "wall": "88756"}
[2024-10-11 11:49:39,356][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2024-10-11 11:49:39,360][train][INFO] - {"epoch": 95, "train_loss": "1.836", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156607", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "45482", "train_lr": "0.000481682", "train_gnorm": "0.554", "train_loss_scale": "1", "train_train_wall": "446", "train_gb_free": "39.3", "train_wall": "88847"}
[2024-10-11 11:49:39,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 11:49:39,508][fairseq.trainer][INFO] - begin training epoch 96
[2024-10-11 11:49:39,509][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 11:56:17,659][train_inner][INFO] - {"epoch": 96, "update": 95.246, "loss": "1.829", "ntokens": "237768", "nsentences": "1690.6", "wps": "97271.4", "ups": "0.41", "wpb": "237768", "bsz": "1690.6", "num_updates": "45600", "lr": "0.000481522", "gnorm": "0.553", "loss_scale": "1", "train_wall": "211", "gb_free": "39.6", "wall": "89245"}
[2024-10-11 11:59:21,123][train_inner][INFO] - {"epoch": 96, "update": 95.664, "loss": "1.83", "ntokens": "238794", "nsentences": "1764.3", "wps": "260352", "ups": "1.09", "wpb": "238794", "bsz": "1764.3", "num_updates": "45800", "lr": "0.00048125", "gnorm": "0.552", "loss_scale": "1", "train_wall": "180", "gb_free": "39.5", "wall": "89429"}
[2024-10-11 12:02:10,461][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2024-10-11 12:02:10,480][train][INFO] - {"epoch": 96, "train_loss": "1.833", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152063", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "45961", "train_lr": "0.000481031", "train_gnorm": "0.554", "train_loss_scale": "1", "train_train_wall": "468", "train_gb_free": "39.8", "train_wall": "89598"}
[2024-10-11 12:02:10,642][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:02:10,653][fairseq.trainer][INFO] - begin training epoch 97
[2024-10-11 12:02:10,654][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:07:19,724][train_inner][INFO] - {"epoch": 97, "update": 96.081, "loss": "1.839", "ntokens": "237926", "nsentences": "1755.58", "wps": "99426.6", "ups": "0.42", "wpb": "237926", "bsz": "1755.6", "num_updates": "46000", "lr": "0.000480978", "gnorm": "0.565", "loss_scale": "1", "train_wall": "212", "gb_free": "39.6", "wall": "89907"}
[2024-10-11 12:10:15,585][train_inner][INFO] - {"epoch": 97, "update": 96.499, "loss": "1.821", "ntokens": "238932", "nsentences": "1739.94", "wps": "271737", "ups": "1.14", "wpb": "238932", "bsz": "1739.9", "num_updates": "46200", "lr": "0.000480707", "gnorm": "0.54", "loss_scale": "2", "train_wall": "173", "gb_free": "39.6", "wall": "90083"}
[2024-10-11 12:13:40,848][train_inner][INFO] - {"epoch": 97, "update": 96.916, "loss": "1.837", "ntokens": "238859", "nsentences": "1764.58", "wps": "232743", "ups": "0.97", "wpb": "238859", "bsz": "1764.6", "num_updates": "46400", "lr": "0.000480435", "gnorm": "0.562", "loss_scale": "2", "train_wall": "201", "gb_free": "39.7", "wall": "90288"}
[2024-10-11 12:14:06,101][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2024-10-11 12:14:06,155][train][INFO] - {"epoch": 97, "train_loss": "1.83", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159596", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "46440", "train_lr": "0.00048038", "train_gnorm": "0.557", "train_loss_scale": "2", "train_train_wall": "444", "train_gb_free": "40.1", "train_wall": "90314"}
[2024-10-11 12:14:06,447][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:14:06,491][fairseq.trainer][INFO] - begin training epoch 98
[2024-10-11 12:14:06,491][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:21:15,159][train_inner][INFO] - {"epoch": 98, "update": 97.334, "loss": "1.821", "ntokens": "237663", "nsentences": "1773.68", "wps": "104627", "ups": "0.44", "wpb": "237664", "bsz": "1773.7", "num_updates": "46600", "lr": "0.000480163", "gnorm": "0.56", "loss_scale": "2", "train_wall": "163", "gb_free": "39.8", "wall": "90743"}
[2024-10-11 12:24:36,456][train_inner][INFO] - {"epoch": 98, "update": 97.752, "loss": "1.824", "ntokens": "238984", "nsentences": "1707.62", "wps": "237447", "ups": "0.99", "wpb": "238984", "bsz": "1707.6", "num_updates": "46800", "lr": "0.000479891", "gnorm": "0.557", "loss_scale": "2", "train_wall": "196", "gb_free": "39.6", "wall": "90944"}
[2024-10-11 12:26:40,513][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2024-10-11 12:26:40,618][train][INFO] - {"epoch": 98, "train_loss": "1.824", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151390", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "46919", "train_lr": "0.00047973", "train_gnorm": "0.559", "train_loss_scale": "2", "train_train_wall": "456", "train_gb_free": "39.6", "train_wall": "91068"}
[2024-10-11 12:26:40,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:26:40,764][fairseq.trainer][INFO] - begin training epoch 99
[2024-10-11 12:26:40,765][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:32:40,300][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 12:32:41,434][train_inner][INFO] - {"epoch": 99, "update": 98.171, "loss": "1.824", "ntokens": "237892", "nsentences": "1768.09", "wps": "98105.9", "ups": "0.41", "wpb": "237892", "bsz": "1768.1", "num_updates": "47000", "lr": "0.00047962", "gnorm": "0.564", "loss_scale": "1", "train_wall": "206", "gb_free": "39.8", "wall": "91429"}
[2024-10-11 12:35:45,125][train_inner][INFO] - {"epoch": 99, "update": 98.589, "loss": "1.816", "ntokens": "238866", "nsentences": "1729.59", "wps": "260094", "ups": "1.09", "wpb": "238866", "bsz": "1729.6", "num_updates": "47200", "lr": "0.000479348", "gnorm": "0.548", "loss_scale": "1", "train_wall": "180", "gb_free": "39.6", "wall": "91613"}
[2024-10-11 12:39:08,445][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2024-10-11 12:39:08,485][train][INFO] - {"epoch": 99, "train_loss": "1.822", "train_ntokens": "238451", "train_nsentences": "1754.54", "train_wps": "152407", "train_ups": "0.64", "train_wpb": "238451", "train_bsz": "1754.5", "train_num_updates": "47397", "train_lr": "0.00047908", "train_gnorm": "0.552", "train_loss_scale": "1", "train_train_wall": "464", "train_gb_free": "40.3", "train_wall": "91816"}
[2024-10-11 12:39:08,881][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:39:08,926][fairseq.trainer][INFO] - begin training epoch 100
[2024-10-11 12:39:08,927][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:44:01,357][train_inner][INFO] - {"epoch": 100, "update": 99.006, "loss": "1.831", "ntokens": "237858", "nsentences": "1795.46", "wps": "95867", "ups": "0.4", "wpb": "237858", "bsz": "1795.5", "num_updates": "47400", "lr": "0.000479076", "gnorm": "0.558", "loss_scale": "1", "train_wall": "210", "gb_free": "39.3", "wall": "92109"}
[2024-10-11 12:46:57,662][train_inner][INFO] - {"epoch": 100, "update": 99.424, "loss": "1.81", "ntokens": "238938", "nsentences": "1737.83", "wps": "271058", "ups": "1.13", "wpb": "238938", "bsz": "1737.8", "num_updates": "47600", "lr": "0.000478804", "gnorm": "0.552", "loss_scale": "1", "train_wall": "173", "gb_free": "40.1", "wall": "92285"}
[2024-10-11 12:50:09,850][train_inner][INFO] - {"epoch": 100, "update": 99.841, "loss": "1.825", "ntokens": "238802", "nsentences": "1796.96", "wps": "248521", "ups": "1.04", "wpb": "238802", "bsz": "1797", "num_updates": "47800", "lr": "0.000478533", "gnorm": "0.566", "loss_scale": "1", "train_wall": "189", "gb_free": "39.7", "wall": "92477"}
[2024-10-11 12:51:03,752][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 47876 updates
[2024-10-11 12:51:03,753][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 12:51:12,740][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 12:51:12,772][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 100 @ 47876 updates, score None) (writing took 9.02053467463702 seconds)
[2024-10-11 12:51:12,799][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2024-10-11 12:51:12,807][train][INFO] - {"epoch": 100, "train_loss": "1.819", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157691", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "47876", "train_lr": "0.000478429", "train_gnorm": "0.561", "train_loss_scale": "1", "train_train_wall": "425", "train_gb_free": "39.8", "train_wall": "92540"}
[2024-10-11 12:51:13,037][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 12:51:13,091][fairseq.trainer][INFO] - begin training epoch 101
[2024-10-11 12:51:13,092][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 12:57:47,882][train_inner][INFO] - {"epoch": 101, "update": 100.259, "loss": "1.814", "ntokens": "237842", "nsentences": "1748.45", "wps": "103855", "ups": "0.44", "wpb": "237842", "bsz": "1748.5", "num_updates": "48000", "lr": "0.000478261", "gnorm": "0.56", "loss_scale": "1", "train_wall": "173", "gb_free": "40.1", "wall": "92935"}
[2024-10-11 13:00:58,084][train_inner][INFO] - {"epoch": 101, "update": 100.676, "loss": "1.813", "ntokens": "238940", "nsentences": "1737.14", "wps": "251270", "ups": "1.05", "wpb": "238940", "bsz": "1737.1", "num_updates": "48200", "lr": "0.000477989", "gnorm": "0.557", "loss_scale": "1", "train_wall": "186", "gb_free": "40", "wall": "93125"}
[2024-10-11 13:03:27,231][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2024-10-11 13:03:27,236][train][INFO] - {"epoch": 101, "train_loss": "1.815", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155519", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "48355", "train_lr": "0.000477779", "train_gnorm": "0.555", "train_loss_scale": "1", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "93275"}
[2024-10-11 13:03:27,347][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:03:27,360][fairseq.trainer][INFO] - begin training epoch 102
[2024-10-11 13:03:27,360][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:08:52,565][train_inner][INFO] - {"epoch": 102, "update": 101.094, "loss": "1.821", "ntokens": "237812", "nsentences": "1760.88", "wps": "100243", "ups": "0.42", "wpb": "237812", "bsz": "1760.9", "num_updates": "48400", "lr": "0.000477717", "gnorm": "0.556", "loss_scale": "1", "train_wall": "196", "gb_free": "39.3", "wall": "93600"}
[2024-10-11 13:11:56,840][train_inner][INFO] - {"epoch": 102, "update": 101.511, "loss": "1.803", "ntokens": "238946", "nsentences": "1767.48", "wps": "259347", "ups": "1.09", "wpb": "238946", "bsz": "1767.5", "num_updates": "48600", "lr": "0.000477446", "gnorm": "0.555", "loss_scale": "1", "train_wall": "180", "gb_free": "39.7", "wall": "93784"}
[2024-10-11 13:15:00,292][train_inner][INFO] - {"epoch": 102, "update": 101.929, "loss": "1.816", "ntokens": "238806", "nsentences": "1754.59", "wps": "260358", "ups": "1.09", "wpb": "238806", "bsz": "1754.6", "num_updates": "48800", "lr": "0.000477174", "gnorm": "0.557", "loss_scale": "1", "train_wall": "180", "gb_free": "40.1", "wall": "93968"}
[2024-10-11 13:15:21,285][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2024-10-11 13:15:21,298][train][INFO] - {"epoch": 102, "train_loss": "1.81", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159956", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "48834", "train_lr": "0.000477128", "train_gnorm": "0.558", "train_loss_scale": "1", "train_train_wall": "430", "train_gb_free": "39.3", "train_wall": "93989"}
[2024-10-11 13:15:21,577][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:15:21,596][fairseq.trainer][INFO] - begin training epoch 103
[2024-10-11 13:15:21,596][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:22:57,634][train_inner][INFO] - {"epoch": 103, "update": 102.347, "loss": "1.802", "ntokens": "237863", "nsentences": "1729.61", "wps": "99662.5", "ups": "0.42", "wpb": "237863", "bsz": "1729.6", "num_updates": "49000", "lr": "0.000476902", "gnorm": "0.558", "loss_scale": "1", "train_wall": "187", "gb_free": "39.3", "wall": "94445"}
[2024-10-11 13:25:03,570][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 13:26:03,629][train_inner][INFO] - {"epoch": 103, "update": 102.766, "loss": "1.812", "ntokens": "238994", "nsentences": "1755.85", "wps": "256996", "ups": "1.08", "wpb": "238994", "bsz": "1755.8", "num_updates": "49200", "lr": "0.00047663", "gnorm": "0.553", "loss_scale": "1", "train_wall": "182", "gb_free": "39.3", "wall": "94631"}
[2024-10-11 13:27:45,696][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2024-10-11 13:27:45,716][train][INFO] - {"epoch": 103, "train_loss": "1.809", "train_ntokens": "238453", "train_nsentences": "1752.53", "train_wps": "153114", "train_ups": "0.64", "train_wpb": "238453", "train_bsz": "1752.5", "train_num_updates": "49312", "train_lr": "0.000476478", "train_gnorm": "0.563", "train_loss_scale": "1", "train_train_wall": "448", "train_gb_free": "39.9", "train_wall": "94733"}
[2024-10-11 13:27:45,885][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:27:45,900][fairseq.trainer][INFO] - begin training epoch 104
[2024-10-11 13:27:45,900][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:33:57,045][train_inner][INFO] - {"epoch": 104, "update": 103.184, "loss": "1.813", "ntokens": "237785", "nsentences": "1766.51", "wps": "100457", "ups": "0.42", "wpb": "237785", "bsz": "1766.5", "num_updates": "49400", "lr": "0.000476359", "gnorm": "0.583", "loss_scale": "1", "train_wall": "185", "gb_free": "39.5", "wall": "95104"}
[2024-10-11 13:37:12,064][train_inner][INFO] - {"epoch": 104, "update": 103.601, "loss": "1.801", "ntokens": "238954", "nsentences": "1761.22", "wps": "245068", "ups": "1.03", "wpb": "238954", "bsz": "1761.2", "num_updates": "49600", "lr": "0.000476087", "gnorm": "0.56", "loss_scale": "1", "train_wall": "191", "gb_free": "40.3", "wall": "95299"}
[2024-10-11 13:40:07,973][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2024-10-11 13:40:08,028][train][INFO] - {"epoch": 104, "train_loss": "1.806", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153869", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "49791", "train_lr": "0.000475827", "train_gnorm": "0.564", "train_loss_scale": "1", "train_train_wall": "448", "train_gb_free": "39.2", "train_wall": "95475"}
[2024-10-11 13:40:08,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:40:08,264][fairseq.trainer][INFO] - begin training epoch 105
[2024-10-11 13:40:08,265][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:45:15,978][train_inner][INFO] - {"epoch": 105, "update": 104.019, "loss": "1.809", "ntokens": "237725", "nsentences": "1721.13", "wps": "98253.3", "ups": "0.41", "wpb": "237725", "bsz": "1721.1", "num_updates": "49800", "lr": "0.000475815", "gnorm": "0.562", "loss_scale": "1", "train_wall": "191", "gb_free": "39.2", "wall": "95783"}
[2024-10-11 13:48:15,753][train_inner][INFO] - {"epoch": 105, "update": 104.436, "loss": "1.795", "ntokens": "238909", "nsentences": "1731.83", "wps": "265794", "ups": "1.11", "wpb": "238909", "bsz": "1731.8", "num_updates": "50000", "lr": "0.000475543", "gnorm": "0.568", "loss_scale": "1", "train_wall": "176", "gb_free": "39.6", "wall": "95963"}
[2024-10-11 13:48:15,761][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 50000 updates
[2024-10-11 13:48:15,761][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_105_50000.pt
[2024-10-11 13:48:18,932][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_105_50000.pt
[2024-10-11 13:48:23,506][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_105_50000.pt (epoch 105 @ 50000 updates, score None) (writing took 7.745184415020049 seconds)
[2024-10-11 13:51:09,552][train_inner][INFO] - {"epoch": 105, "update": 104.854, "loss": "1.809", "ntokens": "238847", "nsentences": "1791.12", "wps": "274872", "ups": "1.15", "wpb": "238847", "bsz": "1791.1", "num_updates": "50200", "lr": "0.000475272", "gnorm": "0.56", "loss_scale": "1", "train_wall": "162", "gb_free": "39.6", "wall": "96137"}
[2024-10-11 13:52:22,352][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2024-10-11 13:52:22,379][train][INFO] - {"epoch": 105, "train_loss": "1.803", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155538", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "50270", "train_lr": "0.000475177", "train_gnorm": "0.562", "train_loss_scale": "1", "train_train_wall": "429", "train_gb_free": "39.7", "train_wall": "96210"}
[2024-10-11 13:52:22,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 13:52:22,591][fairseq.trainer][INFO] - begin training epoch 106
[2024-10-11 13:52:22,593][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 13:59:11,435][train_inner][INFO] - {"epoch": 106, "update": 105.271, "loss": "1.8", "ntokens": "237867", "nsentences": "1740.58", "wps": "98725", "ups": "0.42", "wpb": "237867", "bsz": "1740.6", "num_updates": "50400", "lr": "0.000475", "gnorm": "0.555", "loss_scale": "1", "train_wall": "208", "gb_free": "40.9", "wall": "96619"}
[2024-10-11 14:02:31,168][train_inner][INFO] - {"epoch": 106, "update": 105.689, "loss": "1.8", "ntokens": "238849", "nsentences": "1774.07", "wps": "239176", "ups": "1", "wpb": "238849", "bsz": "1774.1", "num_updates": "50600", "lr": "0.000474728", "gnorm": "0.554", "loss_scale": "1", "train_wall": "196", "gb_free": "39.8", "wall": "96819"}
[2024-10-11 14:04:58,102][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2024-10-11 14:04:58,118][train][INFO] - {"epoch": 106, "train_loss": "1.801", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151136", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "50749", "train_lr": "0.000474526", "train_gnorm": "0.562", "train_loss_scale": "1", "train_train_wall": "477", "train_gb_free": "40.1", "train_wall": "96965"}
[2024-10-11 14:04:58,230][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:04:58,247][fairseq.trainer][INFO] - begin training epoch 107
[2024-10-11 14:04:58,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:10:26,006][train_inner][INFO] - {"epoch": 107, "update": 106.106, "loss": "1.804", "ntokens": "237896", "nsentences": "1731.81", "wps": "100203", "ups": "0.42", "wpb": "237896", "bsz": "1731.8", "num_updates": "50800", "lr": "0.000474457", "gnorm": "0.574", "loss_scale": "1", "train_wall": "203", "gb_free": "39.6", "wall": "97293"}
[2024-10-11 14:13:49,526][train_inner][INFO] - {"epoch": 107, "update": 106.524, "loss": "1.792", "ntokens": "238835", "nsentences": "1791.91", "wps": "234710", "ups": "0.98", "wpb": "238835", "bsz": "1791.9", "num_updates": "51000", "lr": "0.000474185", "gnorm": "0.554", "loss_scale": "1", "train_wall": "200", "gb_free": "39.6", "wall": "97497"}
[2024-10-11 14:17:08,626][train_inner][INFO] - {"epoch": 107, "update": 106.942, "loss": "1.801", "ntokens": "238905", "nsentences": "1735.12", "wps": "239993", "ups": "1", "wpb": "238905", "bsz": "1735.1", "num_updates": "51200", "lr": "0.000473913", "gnorm": "0.562", "loss_scale": "2", "train_wall": "195", "gb_free": "39.3", "wall": "97696"}
[2024-10-11 14:17:47,997][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2024-10-11 14:17:48,015][train][INFO] - {"epoch": 107, "train_loss": "1.796", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148358", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "51228", "train_lr": "0.000473875", "train_gnorm": "0.56", "train_loss_scale": "2", "train_train_wall": "493", "train_gb_free": "39.7", "train_wall": "97735"}
[2024-10-11 14:17:48,157][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:17:48,163][fairseq.trainer][INFO] - begin training epoch 108
[2024-10-11 14:17:48,164][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:24:31,292][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2024-10-11 14:25:21,928][train_inner][INFO] - {"epoch": 108, "update": 107.361, "loss": "1.794", "ntokens": "237800", "nsentences": "1793.46", "wps": "96412.4", "ups": "0.41", "wpb": "237800", "bsz": "1793.5", "num_updates": "51400", "lr": "0.000473641", "gnorm": "0.573", "loss_scale": "1", "train_wall": "217", "gb_free": "39.4", "wall": "98189"}
[2024-10-11 14:28:50,483][train_inner][INFO] - {"epoch": 108, "update": 107.779, "loss": "1.796", "ntokens": "238917", "nsentences": "1741.28", "wps": "229128", "ups": "0.96", "wpb": "238917", "bsz": "1741.3", "num_updates": "51600", "lr": "0.00047337", "gnorm": "0.556", "loss_scale": "1", "train_wall": "204", "gb_free": "40.1", "wall": "98398"}
[2024-10-11 14:30:25,335][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2024-10-11 14:30:25,363][train][INFO] - {"epoch": 108, "train_loss": "1.795", "train_ntokens": "238447", "train_nsentences": "1754", "train_wps": "150500", "train_ups": "0.63", "train_wpb": "238447", "train_bsz": "1754", "train_num_updates": "51706", "train_lr": "0.000473226", "train_gnorm": "0.569", "train_loss_scale": "1", "train_train_wall": "475", "train_gb_free": "40.2", "train_wall": "98493"}
[2024-10-11 14:30:25,452][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:30:25,467][fairseq.trainer][INFO] - begin training epoch 109
[2024-10-11 14:30:25,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:36:39,979][train_inner][INFO] - {"epoch": 109, "update": 108.196, "loss": "1.794", "ntokens": "237783", "nsentences": "1715.57", "wps": "101295", "ups": "0.43", "wpb": "237783", "bsz": "1715.6", "num_updates": "51800", "lr": "0.000473098", "gnorm": "0.576", "loss_scale": "1", "train_wall": "169", "gb_free": "39.2", "wall": "98867"}
[2024-10-11 14:39:33,913][train_inner][INFO] - {"epoch": 109, "update": 108.614, "loss": "1.787", "ntokens": "238886", "nsentences": "1738.3", "wps": "274707", "ups": "1.15", "wpb": "238886", "bsz": "1738.3", "num_updates": "52000", "lr": "0.000472826", "gnorm": "0.549", "loss_scale": "1", "train_wall": "146", "gb_free": "40.2", "wall": "99041"}
[2024-10-11 14:42:46,590][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2024-10-11 14:42:46,622][train][INFO] - {"epoch": 109, "train_loss": "1.794", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154090", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "52185", "train_lr": "0.000472575", "train_gnorm": "0.559", "train_loss_scale": "1", "train_train_wall": "362", "train_gb_free": "40.1", "train_wall": "99234"}
[2024-10-11 14:42:46,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:42:46,933][fairseq.trainer][INFO] - begin training epoch 110
[2024-10-11 14:42:46,935][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 14:47:51,583][train_inner][INFO] - {"epoch": 110, "update": 109.031, "loss": "1.803", "ntokens": "237929", "nsentences": "1776.64", "wps": "95618.9", "ups": "0.4", "wpb": "237929", "bsz": "1776.6", "num_updates": "52200", "lr": "0.000472554", "gnorm": "0.57", "loss_scale": "1", "train_wall": "162", "gb_free": "39.3", "wall": "99539"}
[2024-10-11 14:50:42,075][train_inner][INFO] - {"epoch": 110, "update": 109.449, "loss": "1.781", "ntokens": "238905", "nsentences": "1758.38", "wps": "280269", "ups": "1.17", "wpb": "238905", "bsz": "1758.4", "num_updates": "52400", "lr": "0.000472283", "gnorm": "0.56", "loss_scale": "1", "train_wall": "167", "gb_free": "41", "wall": "99709"}
[2024-10-11 14:53:56,872][train_inner][INFO] - {"epoch": 110, "update": 109.866, "loss": "1.791", "ntokens": "238846", "nsentences": "1753.31", "wps": "245233", "ups": "1.03", "wpb": "238846", "bsz": "1753.3", "num_updates": "52600", "lr": "0.000472011", "gnorm": "0.564", "loss_scale": "1", "train_wall": "183", "gb_free": "40.1", "wall": "99904"}
[2024-10-11 14:54:42,508][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 52664 updates
[2024-10-11 14:54:42,509][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 14:54:53,481][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 14:54:53,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 110 @ 52664 updates, score None) (writing took 11.105541267432272 seconds)
[2024-10-11 14:54:53,622][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2024-10-11 14:54:53,631][train][INFO] - {"epoch": 110, "train_loss": "1.788", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157108", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "52664", "train_lr": "0.000471924", "train_gnorm": "0.564", "train_loss_scale": "1", "train_train_wall": "417", "train_gb_free": "40.1", "train_wall": "99961"}
[2024-10-11 14:54:53,781][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 14:54:53,790][fairseq.trainer][INFO] - begin training epoch 111
[2024-10-11 14:54:53,790][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:01:09,997][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 15:01:47,370][train_inner][INFO] - {"epoch": 111, "update": 110.286, "loss": "1.787", "ntokens": "237787", "nsentences": "1772.19", "wps": "101081", "ups": "0.43", "wpb": "237787", "bsz": "1772.2", "num_updates": "52800", "lr": "0.000471739", "gnorm": "0.558", "loss_scale": "0.5", "train_wall": "175", "gb_free": "39.2", "wall": "100375"}
[2024-10-11 15:04:57,013][train_inner][INFO] - {"epoch": 111, "update": 110.704, "loss": "1.785", "ntokens": "238936", "nsentences": "1729.83", "wps": "251995", "ups": "1.05", "wpb": "238936", "bsz": "1729.8", "num_updates": "53000", "lr": "0.000471467", "gnorm": "0.554", "loss_scale": "0.5", "train_wall": "186", "gb_free": "39.6", "wall": "100564"}
[2024-10-11 15:07:12,545][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2024-10-11 15:07:12,580][train][INFO] - {"epoch": 111, "train_loss": "1.788", "train_ntokens": "238454", "train_nsentences": "1753.7", "train_wps": "154250", "train_ups": "0.65", "train_wpb": "238454", "train_bsz": "1753.7", "train_num_updates": "53142", "train_lr": "0.000471274", "train_gnorm": "0.557", "train_loss_scale": "0.5", "train_train_wall": "450", "train_gb_free": "40.1", "train_wall": "100700"}
[2024-10-11 15:07:12,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:07:12,761][fairseq.trainer][INFO] - begin training epoch 112
[2024-10-11 15:07:12,762][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:12:56,674][train_inner][INFO] - {"epoch": 112, "update": 111.121, "loss": "1.792", "ntokens": "237858", "nsentences": "1749.86", "wps": "99178.8", "ups": "0.42", "wpb": "237858", "bsz": "1749.9", "num_updates": "53200", "lr": "0.000471196", "gnorm": "0.565", "loss_scale": "0.5", "train_wall": "206", "gb_free": "39.2", "wall": "101044"}
[2024-10-11 15:16:14,945][train_inner][INFO] - {"epoch": 112, "update": 111.539, "loss": "1.784", "ntokens": "238844", "nsentences": "1762.88", "wps": "240938", "ups": "1.01", "wpb": "238844", "bsz": "1762.9", "num_updates": "53400", "lr": "0.000470924", "gnorm": "0.55", "loss_scale": "0.5", "train_wall": "195", "gb_free": "39.6", "wall": "101242"}
[2024-10-11 15:19:27,085][train_inner][INFO] - {"epoch": 112, "update": 111.956, "loss": "1.786", "ntokens": "238939", "nsentences": "1728.31", "wps": "248720", "ups": "1.04", "wpb": "238939", "bsz": "1728.3", "num_updates": "53600", "lr": "0.000470652", "gnorm": "0.564", "loss_scale": "0.5", "train_wall": "188", "gb_free": "39.6", "wall": "101434"}
[2024-10-11 15:19:52,454][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2024-10-11 15:19:52,468][train][INFO] - {"epoch": 112, "train_loss": "1.785", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150309", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "53621", "train_lr": "0.000470624", "train_gnorm": "0.558", "train_loss_scale": "0.5", "train_train_wall": "481", "train_gb_free": "39.8", "train_wall": "101460"}
[2024-10-11 15:19:52,633][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:19:52,647][fairseq.trainer][INFO] - begin training epoch 113
[2024-10-11 15:19:52,649][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:27:38,066][train_inner][INFO] - {"epoch": 113, "update": 112.374, "loss": "1.78", "ntokens": "237896", "nsentences": "1809.67", "wps": "96907.1", "ups": "0.41", "wpb": "237896", "bsz": "1809.7", "num_updates": "53800", "lr": "0.00047038", "gnorm": "0.578", "loss_scale": "0.5", "train_wall": "189", "gb_free": "39.3", "wall": "101925"}
[2024-10-11 15:30:57,825][train_inner][INFO] - {"epoch": 113, "update": 112.791, "loss": "1.777", "ntokens": "238785", "nsentences": "1730.52", "wps": "239082", "ups": "1", "wpb": "238785", "bsz": "1730.5", "num_updates": "54000", "lr": "0.000470109", "gnorm": "0.568", "loss_scale": "0.5", "train_wall": "196", "gb_free": "39.3", "wall": "102125"}
[2024-10-11 15:32:42,411][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2024-10-11 15:32:42,435][train][INFO] - {"epoch": 113, "train_loss": "1.78", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148342", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "54100", "train_lr": "0.000469973", "train_gnorm": "0.571", "train_loss_scale": "0.5", "train_train_wall": "463", "train_gb_free": "40.6", "train_wall": "102230"}
[2024-10-11 15:32:42,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:32:42,740][fairseq.trainer][INFO] - begin training epoch 114
[2024-10-11 15:32:42,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:38:57,093][train_inner][INFO] - {"epoch": 114, "update": 113.209, "loss": "1.775", "ntokens": "237898", "nsentences": "1700.01", "wps": "99277.3", "ups": "0.42", "wpb": "237898", "bsz": "1700", "num_updates": "54200", "lr": "0.000469837", "gnorm": "0.566", "loss_scale": "0.5", "train_wall": "190", "gb_free": "39.6", "wall": "102604"}
[2024-10-11 15:42:22,765][train_inner][INFO] - {"epoch": 114, "update": 113.626, "loss": "1.779", "ntokens": "238833", "nsentences": "1808.15", "wps": "232253", "ups": "0.97", "wpb": "238833", "bsz": "1808.2", "num_updates": "54400", "lr": "0.000469565", "gnorm": "0.552", "loss_scale": "0.5", "train_wall": "202", "gb_free": "39.3", "wall": "102810"}
[2024-10-11 15:45:02,389][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2024-10-11 15:45:02,420][train][INFO] - {"epoch": 114, "train_loss": "1.778", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154351", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "54579", "train_lr": "0.000469322", "train_gnorm": "0.555", "train_loss_scale": "0.5", "train_train_wall": "445", "train_gb_free": "39.7", "train_wall": "102970"}
[2024-10-11 15:45:02,755][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:45:02,773][fairseq.trainer][INFO] - begin training epoch 115
[2024-10-11 15:45:02,773][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 15:50:20,932][train_inner][INFO] - {"epoch": 115, "update": 114.044, "loss": "1.786", "ntokens": "237879", "nsentences": "1741.78", "wps": "99496.9", "ups": "0.42", "wpb": "237879", "bsz": "1741.8", "num_updates": "54600", "lr": "0.000469293", "gnorm": "0.559", "loss_scale": "0.5", "train_wall": "184", "gb_free": "39.8", "wall": "103288"}
[2024-10-11 15:53:21,711][train_inner][INFO] - {"epoch": 115, "update": 114.461, "loss": "1.767", "ntokens": "238886", "nsentences": "1739.28", "wps": "264296", "ups": "1.11", "wpb": "238886", "bsz": "1739.3", "num_updates": "54800", "lr": "0.000469022", "gnorm": "0.57", "loss_scale": "1", "train_wall": "177", "gb_free": "40.2", "wall": "103469"}
[2024-10-11 15:56:42,442][train_inner][INFO] - {"epoch": 115, "update": 114.879, "loss": "1.78", "ntokens": "238853", "nsentences": "1774.41", "wps": "237990", "ups": "1", "wpb": "238853", "bsz": "1774.4", "num_updates": "55000", "lr": "0.00046875", "gnorm": "0.568", "loss_scale": "1", "train_wall": "196", "gb_free": "39.6", "wall": "103670"}
[2024-10-11 15:57:29,059][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2024-10-11 15:57:29,088][train][INFO] - {"epoch": 115, "train_loss": "1.775", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152972", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "55058", "train_lr": "0.000468671", "train_gnorm": "0.569", "train_loss_scale": "1", "train_train_wall": "448", "train_gb_free": "39.2", "train_wall": "103716"}
[2024-10-11 15:57:29,231][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 15:57:29,237][fairseq.trainer][INFO] - begin training epoch 116
[2024-10-11 15:57:29,238][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:02:56,058][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 16:04:36,256][train_inner][INFO] - {"epoch": 116, "update": 115.299, "loss": "1.772", "ntokens": "237875", "nsentences": "1712.77", "wps": "100410", "ups": "0.42", "wpb": "237875", "bsz": "1712.8", "num_updates": "55200", "lr": "0.000468478", "gnorm": "0.551", "loss_scale": "0.5", "train_wall": "166", "gb_free": "40.3", "wall": "104144"}
[2024-10-11 16:07:43,475][train_inner][INFO] - {"epoch": 116, "update": 115.716, "loss": "1.772", "ntokens": "238954", "nsentences": "1739.61", "wps": "255274", "ups": "1.07", "wpb": "238954", "bsz": "1739.6", "num_updates": "55400", "lr": "0.000468207", "gnorm": "0.568", "loss_scale": "0.5", "train_wall": "183", "gb_free": "39.3", "wall": "104331"}
[2024-10-11 16:09:58,313][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2024-10-11 16:09:58,341][train][INFO] - {"epoch": 116, "train_loss": "1.773", "train_ntokens": "238447", "train_nsentences": "1753.88", "train_wps": "152124", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1753.9", "train_num_updates": "55536", "train_lr": "0.000468022", "train_gnorm": "0.56", "train_loss_scale": "0.5", "train_train_wall": "436", "train_gb_free": "39.1", "train_wall": "104466"}
[2024-10-11 16:09:58,468][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:09:58,500][fairseq.trainer][INFO] - begin training epoch 117
[2024-10-11 16:09:58,500][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:15:47,278][train_inner][INFO] - {"epoch": 117, "update": 116.134, "loss": "1.776", "ntokens": "237644", "nsentences": "1808.06", "wps": "98242.5", "ups": "0.41", "wpb": "237644", "bsz": "1808.1", "num_updates": "55600", "lr": "0.000467935", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "214", "gb_free": "40.1", "wall": "104815"}
[2024-10-11 16:19:03,475][train_inner][INFO] - {"epoch": 117, "update": 116.551, "loss": "1.766", "ntokens": "238926", "nsentences": "1733.92", "wps": "243567", "ups": "1.02", "wpb": "238926", "bsz": "1733.9", "num_updates": "55800", "lr": "0.000467663", "gnorm": "0.56", "loss_scale": "0.5", "train_wall": "193", "gb_free": "39.6", "wall": "105011"}
[2024-10-11 16:22:16,598][train_inner][INFO] - {"epoch": 117, "update": 116.969, "loss": "1.775", "ntokens": "238956", "nsentences": "1757.87", "wps": "247471", "ups": "1.04", "wpb": "238956", "bsz": "1757.9", "num_updates": "56000", "lr": "0.000467391", "gnorm": "0.569", "loss_scale": "0.5", "train_wall": "190", "gb_free": "39.1", "wall": "105204"}
[2024-10-11 16:22:54,370][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2024-10-11 16:22:54,388][train][INFO] - {"epoch": 117, "train_loss": "1.77", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "147179", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "56015", "train_lr": "0.000467371", "train_gnorm": "0.566", "train_loss_scale": "0.5", "train_train_wall": "500", "train_gb_free": "39.7", "train_wall": "105242"}
[2024-10-11 16:22:54,520][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:22:54,524][fairseq.trainer][INFO] - begin training epoch 118
[2024-10-11 16:22:54,525][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:30:28,431][train_inner][INFO] - {"epoch": 118, "update": 117.386, "loss": "1.761", "ntokens": "237860", "nsentences": "1749.84", "wps": "96724.7", "ups": "0.41", "wpb": "237860", "bsz": "1749.8", "num_updates": "56200", "lr": "0.00046712", "gnorm": "0.56", "loss_scale": "0.5", "train_wall": "220", "gb_free": "39.6", "wall": "105696"}
[2024-10-11 16:33:35,228][train_inner][INFO] - {"epoch": 118, "update": 117.804, "loss": "1.769", "ntokens": "238881", "nsentences": "1754.21", "wps": "255771", "ups": "1.07", "wpb": "238881", "bsz": "1754.2", "num_updates": "56400", "lr": "0.000466848", "gnorm": "0.571", "loss_scale": "0.5", "train_wall": "172", "gb_free": "39.3", "wall": "105883"}
[2024-10-11 16:35:29,482][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2024-10-11 16:35:29,487][train][INFO] - {"epoch": 118, "train_loss": "1.767", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151262", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "56494", "train_lr": "0.00046672", "train_gnorm": "0.566", "train_loss_scale": "0.5", "train_train_wall": "467", "train_gb_free": "39.6", "train_wall": "105997"}
[2024-10-11 16:35:29,549][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:35:29,552][fairseq.trainer][INFO] - begin training epoch 119
[2024-10-11 16:35:29,553][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:41:34,473][train_inner][INFO] - {"epoch": 119, "update": 118.221, "loss": "1.769", "ntokens": "237761", "nsentences": "1757.97", "wps": "99225.3", "ups": "0.42", "wpb": "237761", "bsz": "1758", "num_updates": "56600", "lr": "0.000466576", "gnorm": "0.571", "loss_scale": "0.5", "train_wall": "213", "gb_free": "39.8", "wall": "106362"}
[2024-10-11 16:44:33,914][train_inner][INFO] - {"epoch": 119, "update": 118.639, "loss": "1.762", "ntokens": "238855", "nsentences": "1742.55", "wps": "266228", "ups": "1.11", "wpb": "238855", "bsz": "1742.5", "num_updates": "56800", "lr": "0.000466304", "gnorm": "0.542", "loss_scale": "0.5", "train_wall": "175", "gb_free": "40.1", "wall": "106541"}
[2024-10-11 16:47:17,856][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2024-10-11 16:47:17,906][train][INFO] - {"epoch": 119, "train_loss": "1.768", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "161233", "train_ups": "0.68", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "56973", "train_lr": "0.000466069", "train_gnorm": "0.564", "train_loss_scale": "0.5", "train_train_wall": "437", "train_gb_free": "39.6", "train_wall": "106705"}
[2024-10-11 16:47:18,070][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:47:18,097][fairseq.trainer][INFO] - begin training epoch 120
[2024-10-11 16:47:18,097][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 16:52:34,367][train_inner][INFO] - {"epoch": 120, "update": 119.056, "loss": "1.774", "ntokens": "237948", "nsentences": "1757.89", "wps": "99054.3", "ups": "0.42", "wpb": "237948", "bsz": "1757.9", "num_updates": "57000", "lr": "0.000466033", "gnorm": "0.581", "loss_scale": "0.5", "train_wall": "187", "gb_free": "39.6", "wall": "107022"}
[2024-10-11 16:55:44,391][train_inner][INFO] - {"epoch": 120, "update": 119.474, "loss": "1.759", "ntokens": "238784", "nsentences": "1781.94", "wps": "251329", "ups": "1.05", "wpb": "238784", "bsz": "1781.9", "num_updates": "57200", "lr": "0.000465761", "gnorm": "0.55", "loss_scale": "1", "train_wall": "169", "gb_free": "39.1", "wall": "107212"}
[2024-10-11 16:58:49,447][train_inner][INFO] - {"epoch": 120, "update": 119.891, "loss": "1.767", "ntokens": "238966", "nsentences": "1732.44", "wps": "258276", "ups": "1.08", "wpb": "238966", "bsz": "1732.4", "num_updates": "57400", "lr": "0.000465489", "gnorm": "0.573", "loss_scale": "1", "train_wall": "171", "gb_free": "39.6", "wall": "107397"}
[2024-10-11 16:59:50,683][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 57452 updates
[2024-10-11 16:59:50,684][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 16:59:54,654][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 16:59:54,657][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 120 @ 57452 updates, score None) (writing took 3.9743417473509908 seconds)
[2024-10-11 16:59:54,658][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2024-10-11 16:59:54,667][train][INFO] - {"epoch": 120, "train_loss": "1.763", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150931", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "57452", "train_lr": "0.000465418", "train_gnorm": "0.565", "train_loss_scale": "1", "train_train_wall": "390", "train_gb_free": "39.6", "train_wall": "107462"}
[2024-10-11 16:59:54,756][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 16:59:54,762][fairseq.trainer][INFO] - begin training epoch 121
[2024-10-11 16:59:54,762][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:06:39,736][train_inner][INFO] - {"epoch": 121, "update": 120.309, "loss": "1.759", "ntokens": "237753", "nsentences": "1748.89", "wps": "101112", "ups": "0.43", "wpb": "237753", "bsz": "1748.9", "num_updates": "57600", "lr": "0.000465217", "gnorm": "0.565", "loss_scale": "1", "train_wall": "161", "gb_free": "39.7", "wall": "107867"}
[2024-10-11 17:09:48,645][train_inner][INFO] - {"epoch": 121, "update": 120.727, "loss": "1.762", "ntokens": "238958", "nsentences": "1756.4", "wps": "253001", "ups": "1.06", "wpb": "238958", "bsz": "1756.4", "num_updates": "57800", "lr": "0.000464946", "gnorm": "0.569", "loss_scale": "1", "train_wall": "185", "gb_free": "39.6", "wall": "108056"}
[2024-10-11 17:10:45,797][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 17:11:40,433][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2024-10-11 17:11:40,466][train][INFO] - {"epoch": 121, "train_loss": "1.762", "train_ntokens": "238447", "train_nsentences": "1753.82", "train_wps": "161491", "train_ups": "0.68", "train_wpb": "238447", "train_bsz": "1753.8", "train_num_updates": "57930", "train_lr": "0.000464769", "train_gnorm": "0.565", "train_loss_scale": "0.5", "train_train_wall": "432", "train_gb_free": "39.6", "train_wall": "108168"}
[2024-10-11 17:11:40,651][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:11:40,661][fairseq.trainer][INFO] - begin training epoch 122
[2024-10-11 17:11:40,661][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:17:44,716][train_inner][INFO] - {"epoch": 122, "update": 121.146, "loss": "1.765", "ntokens": "237792", "nsentences": "1782.92", "wps": "99899.3", "ups": "0.42", "wpb": "237792", "bsz": "1782.9", "num_updates": "58000", "lr": "0.000464674", "gnorm": "0.571", "loss_scale": "0.5", "train_wall": "181", "gb_free": "40.6", "wall": "108532"}
[2024-10-11 17:20:47,958][train_inner][INFO] - {"epoch": 122, "update": 121.564, "loss": "1.753", "ntokens": "238899", "nsentences": "1749.2", "wps": "260758", "ups": "1.09", "wpb": "238899", "bsz": "1749.2", "num_updates": "58200", "lr": "0.000464402", "gnorm": "0.549", "loss_scale": "0.5", "train_wall": "156", "gb_free": "39.3", "wall": "108715"}
[2024-10-11 17:23:45,251][train_inner][INFO] - {"epoch": 122, "update": 121.981, "loss": "1.765", "ntokens": "238960", "nsentences": "1735.79", "wps": "269607", "ups": "1.13", "wpb": "238960", "bsz": "1735.8", "num_updates": "58400", "lr": "0.00046413", "gnorm": "0.558", "loss_scale": "0.5", "train_wall": "154", "gb_free": "39.6", "wall": "108893"}
[2024-10-11 17:24:19,223][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2024-10-11 17:24:19,247][train][INFO] - {"epoch": 122, "train_loss": "1.758", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150532", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "58409", "train_lr": "0.000464118", "train_gnorm": "0.558", "train_loss_scale": "0.5", "train_train_wall": "410", "train_gb_free": "39.1", "train_wall": "108927"}
[2024-10-11 17:24:20,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:24:20,128][fairseq.trainer][INFO] - begin training epoch 123
[2024-10-11 17:24:20,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:31:53,097][train_inner][INFO] - {"epoch": 123, "update": 122.399, "loss": "1.75", "ntokens": "237839", "nsentences": "1757.18", "wps": "97510.2", "ups": "0.41", "wpb": "237839", "bsz": "1757.2", "num_updates": "58600", "lr": "0.000463859", "gnorm": "0.568", "loss_scale": "0.5", "train_wall": "164", "gb_free": "39.7", "wall": "109380"}
[2024-10-11 17:35:19,481][train_inner][INFO] - {"epoch": 123, "update": 122.816, "loss": "1.761", "ntokens": "238864", "nsentences": "1775.16", "wps": "231481", "ups": "0.97", "wpb": "238864", "bsz": "1775.2", "num_updates": "58800", "lr": "0.000463587", "gnorm": "0.58", "loss_scale": "0.5", "train_wall": "158", "gb_free": "39.3", "wall": "109587"}
[2024-10-11 17:36:50,894][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2024-10-11 17:36:50,991][train][INFO] - {"epoch": 123, "train_loss": "1.755", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151940", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "58888", "train_lr": "0.000463467", "train_gnorm": "0.567", "train_loss_scale": "0.5", "train_train_wall": "366", "train_gb_free": "39.4", "train_wall": "109678"}
[2024-10-11 17:36:51,117][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:36:51,122][fairseq.trainer][INFO] - begin training epoch 124
[2024-10-11 17:36:51,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:43:26,366][train_inner][INFO] - {"epoch": 124, "update": 123.234, "loss": "1.749", "ntokens": "237868", "nsentences": "1719.12", "wps": "97713.1", "ups": "0.41", "wpb": "237868", "bsz": "1719.1", "num_updates": "59000", "lr": "0.000463315", "gnorm": "0.547", "loss_scale": "0.5", "train_wall": "164", "gb_free": "39.1", "wall": "110074"}
[2024-10-11 17:46:36,259][train_inner][INFO] - {"epoch": 124, "update": 123.651, "loss": "1.757", "ntokens": "238849", "nsentences": "1798.18", "wps": "251575", "ups": "1.05", "wpb": "238849", "bsz": "1798.2", "num_updates": "59200", "lr": "0.000463043", "gnorm": "0.556", "loss_scale": "0.5", "train_wall": "155", "gb_free": "40.1", "wall": "110264"}
[2024-10-11 17:49:22,397][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2024-10-11 17:49:22,485][train][INFO] - {"epoch": 124, "train_loss": "1.755", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151990", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "59367", "train_lr": "0.000462817", "train_gnorm": "0.563", "train_loss_scale": "0.5", "train_train_wall": "377", "train_gb_free": "39.7", "train_wall": "110430"}
[2024-10-11 17:49:22,608][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 17:49:22,619][fairseq.trainer][INFO] - begin training epoch 125
[2024-10-11 17:49:22,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 17:54:33,884][train_inner][INFO] - {"epoch": 125, "update": 124.069, "loss": "1.758", "ntokens": "237864", "nsentences": "1711.41", "wps": "99604.9", "ups": "0.42", "wpb": "237864", "bsz": "1711.4", "num_updates": "59400", "lr": "0.000462772", "gnorm": "0.583", "loss_scale": "0.5", "train_wall": "159", "gb_free": "39.8", "wall": "110741"}
[2024-10-11 17:57:38,714][train_inner][INFO] - {"epoch": 125, "update": 124.486, "loss": "1.748", "ntokens": "238811", "nsentences": "1790.21", "wps": "258422", "ups": "1.08", "wpb": "238811", "bsz": "1790.2", "num_updates": "59600", "lr": "0.0004625", "gnorm": "0.555", "loss_scale": "0.5", "train_wall": "136", "gb_free": "39.3", "wall": "110926"}
[2024-10-11 18:01:10,865][train_inner][INFO] - {"epoch": 125, "update": 124.904, "loss": "1.757", "ntokens": "238969", "nsentences": "1733.69", "wps": "225300", "ups": "0.94", "wpb": "238969", "bsz": "1733.7", "num_updates": "59800", "lr": "0.000462228", "gnorm": "0.554", "loss_scale": "0.5", "train_wall": "125", "gb_free": "40.1", "wall": "111138"}
[2024-10-11 18:02:00,771][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2024-10-11 18:02:00,859][train][INFO] - {"epoch": 125, "train_loss": "1.752", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150611", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "59846", "train_lr": "0.000462166", "train_gnorm": "0.56", "train_loss_scale": "0.5", "train_train_wall": "327", "train_gb_free": "39.3", "train_wall": "111188"}
[2024-10-11 18:02:05,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:02:05,427][fairseq.trainer][INFO] - begin training epoch 126
[2024-10-11 18:02:05,428][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:09:07,825][train_inner][INFO] - {"epoch": 126, "update": 125.322, "loss": "1.748", "ntokens": "237770", "nsentences": "1742.51", "wps": "99704.2", "ups": "0.42", "wpb": "237770", "bsz": "1742.5", "num_updates": "60000", "lr": "0.000461957", "gnorm": "0.556", "loss_scale": "1", "train_wall": "180", "gb_free": "40.1", "wall": "111615"}
[2024-10-11 18:12:23,697][train_inner][INFO] - {"epoch": 126, "update": 125.739, "loss": "1.749", "ntokens": "238943", "nsentences": "1728.59", "wps": "243990", "ups": "1.02", "wpb": "238943", "bsz": "1728.6", "num_updates": "60200", "lr": "0.000461685", "gnorm": "0.558", "loss_scale": "1", "train_wall": "191", "gb_free": "39.6", "wall": "111811"}
[2024-10-11 18:14:20,357][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2024-10-11 18:14:20,387][train][INFO] - {"epoch": 126, "train_loss": "1.75", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154452", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "60325", "train_lr": "0.000461515", "train_gnorm": "0.565", "train_loss_scale": "1", "train_train_wall": "447", "train_gb_free": "39.9", "train_wall": "111928"}
[2024-10-11 18:14:20,495][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:14:20,502][fairseq.trainer][INFO] - begin training epoch 127
[2024-10-11 18:14:20,503][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:20:11,018][train_inner][INFO] - {"epoch": 127, "update": 126.157, "loss": "1.752", "ntokens": "237871", "nsentences": "1754.95", "wps": "101804", "ups": "0.43", "wpb": "237871", "bsz": "1755", "num_updates": "60400", "lr": "0.000461413", "gnorm": "0.583", "loss_scale": "1", "train_wall": "185", "gb_free": "40.1", "wall": "112278"}
[2024-10-11 18:22:52,075][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 18:23:04,875][train_inner][INFO] - {"epoch": 127, "update": 126.576, "loss": "1.741", "ntokens": "238920", "nsentences": "1728.91", "wps": "274868", "ups": "1.15", "wpb": "238920", "bsz": "1728.9", "num_updates": "60600", "lr": "0.000461141", "gnorm": "0.567", "loss_scale": "0.5", "train_wall": "170", "gb_free": "39.8", "wall": "112452"}
[2024-10-11 18:26:03,697][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-11 18:26:18,967][train_inner][INFO] - {"epoch": 127, "update": 126.996, "loss": "1.759", "ntokens": "238819", "nsentences": "1805.09", "wps": "246113", "ups": "1.03", "wpb": "238819", "bsz": "1805.1", "num_updates": "60800", "lr": "0.00046087", "gnorm": "0.568", "loss_scale": "0.25", "train_wall": "141", "gb_free": "39.3", "wall": "112646"}
[2024-10-11 18:26:22,020][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2024-10-11 18:26:22,056][train][INFO] - {"epoch": 127, "train_loss": "1.749", "train_ntokens": "238447", "train_nsentences": "1754.35", "train_wps": "157614", "train_ups": "0.66", "train_wpb": "238447", "train_bsz": "1754.4", "train_num_updates": "60802", "train_lr": "0.000460867", "train_gnorm": "0.568", "train_loss_scale": "0.25", "train_train_wall": "384", "train_gb_free": "39.8", "train_wall": "112649"}
[2024-10-11 18:26:25,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:26:25,964][fairseq.trainer][INFO] - begin training epoch 128
[2024-10-11 18:26:25,964][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:34:21,684][train_inner][INFO] - {"epoch": 128, "update": 127.413, "loss": "1.736", "ntokens": "237909", "nsentences": "1743.68", "wps": "98573", "ups": "0.41", "wpb": "237909", "bsz": "1743.7", "num_updates": "61000", "lr": "0.000460598", "gnorm": "0.552", "loss_scale": "0.25", "train_wall": "176", "gb_free": "39.6", "wall": "113129"}
[2024-10-11 18:37:35,790][train_inner][INFO] - {"epoch": 128, "update": 127.831, "loss": "1.751", "ntokens": "238954", "nsentences": "1749.37", "wps": "246234", "ups": "1.03", "wpb": "238954", "bsz": "1749.4", "num_updates": "61200", "lr": "0.000460326", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "190", "gb_free": "40.2", "wall": "113323"}
[2024-10-11 18:38:45,935][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2024-10-11 18:38:45,959][train][INFO] - {"epoch": 128, "train_loss": "1.745", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153540", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "61281", "train_lr": "0.000460216", "train_gnorm": "0.561", "train_loss_scale": "0.25", "train_train_wall": "432", "train_gb_free": "40.1", "train_wall": "113393"}
[2024-10-11 18:38:46,194][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:38:46,201][fairseq.trainer][INFO] - begin training epoch 129
[2024-10-11 18:38:46,205][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:45:34,437][train_inner][INFO] - {"epoch": 129, "update": 128.248, "loss": "1.743", "ntokens": "237726", "nsentences": "1755.88", "wps": "99335.2", "ups": "0.42", "wpb": "237726", "bsz": "1755.9", "num_updates": "61400", "lr": "0.000460054", "gnorm": "0.574", "loss_scale": "0.25", "train_wall": "158", "gb_free": "40.1", "wall": "113802"}
[2024-10-11 18:48:36,806][train_inner][INFO] - {"epoch": 129, "update": 128.666, "loss": "1.74", "ntokens": "238912", "nsentences": "1718.63", "wps": "262026", "ups": "1.1", "wpb": "238912", "bsz": "1718.6", "num_updates": "61600", "lr": "0.000459783", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "167", "gb_free": "39.7", "wall": "113984"}
[2024-10-11 18:51:14,498][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2024-10-11 18:51:14,528][train][INFO] - {"epoch": 129, "train_loss": "1.743", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152581", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "61760", "train_lr": "0.000459565", "train_gnorm": "0.567", "train_loss_scale": "0.25", "train_train_wall": "400", "train_gb_free": "39.4", "train_wall": "114142"}
[2024-10-11 18:51:14,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 18:51:14,692][fairseq.trainer][INFO] - begin training epoch 130
[2024-10-11 18:51:14,692][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 18:56:41,251][train_inner][INFO] - {"epoch": 130, "update": 129.084, "loss": "1.747", "ntokens": "237794", "nsentences": "1775.06", "wps": "98173.2", "ups": "0.41", "wpb": "237794", "bsz": "1775.1", "num_updates": "61800", "lr": "0.000459511", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "199", "gb_free": "39.7", "wall": "114469"}
[2024-10-11 18:59:32,088][train_inner][INFO] - {"epoch": 130, "update": 129.501, "loss": "1.739", "ntokens": "238874", "nsentences": "1782.06", "wps": "279660", "ups": "1.17", "wpb": "238874", "bsz": "1782.1", "num_updates": "62000", "lr": "0.000459239", "gnorm": "0.545", "loss_scale": "0.25", "train_wall": "162", "gb_free": "40.3", "wall": "114639"}
[2024-10-11 19:02:49,337][train_inner][INFO] - {"epoch": 130, "update": 129.919, "loss": "1.746", "ntokens": "238894", "nsentences": "1759.57", "wps": "242234", "ups": "1.01", "wpb": "238894", "bsz": "1759.6", "num_updates": "62200", "lr": "0.000458967", "gnorm": "0.557", "loss_scale": "0.25", "train_wall": "193", "gb_free": "39.2", "wall": "114837"}
[2024-10-11 19:03:16,113][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 62239 updates
[2024-10-11 19:03:16,113][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 19:03:25,882][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 19:03:26,119][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 130 @ 62239 updates, score None) (writing took 10.006304799579084 seconds)
[2024-10-11 19:03:26,142][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2024-10-11 19:03:26,144][train][INFO] - {"epoch": 130, "train_loss": "1.742", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156117", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "62239", "train_lr": "0.000458914", "train_gnorm": "0.555", "train_loss_scale": "0.25", "train_train_wall": "437", "train_gb_free": "39.3", "train_wall": "114874"}
[2024-10-11 19:03:26,442][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:03:26,490][fairseq.trainer][INFO] - begin training epoch 131
[2024-10-11 19:03:26,490][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:10:47,954][train_inner][INFO] - {"epoch": 131, "update": 130.336, "loss": "1.733", "ntokens": "237878", "nsentences": "1724.21", "wps": "99403.2", "ups": "0.42", "wpb": "237878", "bsz": "1724.2", "num_updates": "62400", "lr": "0.000458696", "gnorm": "0.574", "loss_scale": "0.25", "train_wall": "175", "gb_free": "39.6", "wall": "115315"}
[2024-10-11 19:14:22,330][train_inner][INFO] - {"epoch": 131, "update": 130.754, "loss": "1.741", "ntokens": "238804", "nsentences": "1780.51", "wps": "222802", "ups": "0.93", "wpb": "238804", "bsz": "1780.5", "num_updates": "62600", "lr": "0.000458424", "gnorm": "0.564", "loss_scale": "0.25", "train_wall": "210", "gb_free": "39.6", "wall": "115530"}
[2024-10-11 19:16:16,099][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2024-10-11 19:16:16,129][train][INFO] - {"epoch": 131, "train_loss": "1.738", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148342", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "62718", "train_lr": "0.000458264", "train_gnorm": "0.564", "train_loss_scale": "0.25", "train_train_wall": "471", "train_gb_free": "39.7", "train_wall": "115644"}
[2024-10-11 19:16:16,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:16:16,645][fairseq.trainer][INFO] - begin training epoch 132
[2024-10-11 19:16:16,646][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:22:20,996][train_inner][INFO] - {"epoch": 132, "update": 131.171, "loss": "1.738", "ntokens": "237883", "nsentences": "1727.29", "wps": "99395.5", "ups": "0.42", "wpb": "237883", "bsz": "1727.3", "num_updates": "62800", "lr": "0.000458152", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "196", "gb_free": "39.4", "wall": "116008"}
[2024-10-11 19:25:24,739][train_inner][INFO] - {"epoch": 132, "update": 131.589, "loss": "1.73", "ntokens": "238974", "nsentences": "1752.04", "wps": "260142", "ups": "1.09", "wpb": "238974", "bsz": "1752", "num_updates": "63000", "lr": "0.00045788", "gnorm": "0.549", "loss_scale": "0.5", "train_wall": "180", "gb_free": "40.6", "wall": "116192"}
[2024-10-11 19:28:20,854][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2024-10-11 19:28:20,879][train][INFO] - {"epoch": 132, "train_loss": "1.735", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157597", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "63197", "train_lr": "0.000457613", "train_gnorm": "0.557", "train_loss_scale": "0.5", "train_train_wall": "436", "train_gb_free": "39.6", "train_wall": "116368"}
[2024-10-11 19:28:21,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:28:21,260][fairseq.trainer][INFO] - begin training epoch 133
[2024-10-11 19:28:21,260][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:33:23,403][train_inner][INFO] - {"epoch": 133, "update": 132.006, "loss": "1.743", "ntokens": "237753", "nsentences": "1767.87", "wps": "99342.5", "ups": "0.42", "wpb": "237753", "bsz": "1767.9", "num_updates": "63200", "lr": "0.000457609", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "189", "gb_free": "40.1", "wall": "116671"}
[2024-10-11 19:36:32,231][train_inner][INFO] - {"epoch": 133, "update": 132.424, "loss": "1.727", "ntokens": "238793", "nsentences": "1795.59", "wps": "252933", "ups": "1.06", "wpb": "238793", "bsz": "1795.6", "num_updates": "63400", "lr": "0.000457337", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "185", "gb_free": "40.6", "wall": "116860"}
[2024-10-11 19:39:47,320][train_inner][INFO] - {"epoch": 133, "update": 132.841, "loss": "1.733", "ntokens": "238920", "nsentences": "1730.67", "wps": "244942", "ups": "1.03", "wpb": "238920", "bsz": "1730.7", "num_updates": "63600", "lr": "0.000457065", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "191", "gb_free": "40.3", "wall": "117055"}
[2024-10-11 19:40:49,673][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2024-10-11 19:40:49,706][train][INFO] - {"epoch": 133, "train_loss": "1.732", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152535", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "63676", "train_lr": "0.000456962", "train_gnorm": "0.561", "train_loss_scale": "0.5", "train_train_wall": "454", "train_gb_free": "39.6", "train_wall": "117117"}
[2024-10-11 19:40:50,025][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:40:50,062][fairseq.trainer][INFO] - begin training epoch 134
[2024-10-11 19:40:50,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:47:28,928][train_inner][INFO] - {"epoch": 134, "update": 133.259, "loss": "1.729", "ntokens": "237913", "nsentences": "1734.51", "wps": "103081", "ups": "0.43", "wpb": "237913", "bsz": "1734.5", "num_updates": "63800", "lr": "0.000456793", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "176", "gb_free": "40.1", "wall": "117516"}
[2024-10-11 19:50:52,037][train_inner][INFO] - {"epoch": 134, "update": 133.676, "loss": "1.73", "ntokens": "238884", "nsentences": "1773.77", "wps": "235235", "ups": "0.98", "wpb": "238884", "bsz": "1773.8", "num_updates": "64000", "lr": "0.000456522", "gnorm": "0.553", "loss_scale": "0.5", "train_wall": "200", "gb_free": "40.1", "wall": "117719"}
[2024-10-11 19:53:11,735][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2024-10-11 19:53:11,762][train][INFO] - {"epoch": 134, "train_loss": "1.731", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153924", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "64155", "train_lr": "0.000456311", "train_gnorm": "0.561", "train_loss_scale": "0.5", "train_train_wall": "451", "train_gb_free": "40.1", "train_wall": "117859"}
[2024-10-11 19:53:12,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 19:53:12,013][fairseq.trainer][INFO] - begin training epoch 135
[2024-10-11 19:53:12,014][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 19:59:00,738][train_inner][INFO] - {"epoch": 135, "update": 134.094, "loss": "1.733", "ntokens": "237838", "nsentences": "1720.71", "wps": "97337.6", "ups": "0.41", "wpb": "237838", "bsz": "1720.7", "num_updates": "64200", "lr": "0.00045625", "gnorm": "0.583", "loss_scale": "0.5", "train_wall": "186", "gb_free": "39.8", "wall": "118208"}
[2024-10-11 20:02:02,817][train_inner][INFO] - {"epoch": 135, "update": 134.511, "loss": "1.722", "ntokens": "238851", "nsentences": "1746.5", "wps": "262383", "ups": "1.1", "wpb": "238851", "bsz": "1746.5", "num_updates": "64400", "lr": "0.000455978", "gnorm": "0.552", "loss_scale": "0.5", "train_wall": "141", "gb_free": "39.2", "wall": "118390"}
[2024-10-11 20:05:19,989][train_inner][INFO] - {"epoch": 135, "update": 134.929, "loss": "1.73", "ntokens": "238894", "nsentences": "1753.39", "wps": "242330", "ups": "1.01", "wpb": "238894", "bsz": "1753.4", "num_updates": "64600", "lr": "0.000455707", "gnorm": "0.564", "loss_scale": "0.5", "train_wall": "112", "gb_free": "39.2", "wall": "118587"}
[2024-10-11 20:05:57,897][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2024-10-11 20:05:57,923][train][INFO] - {"epoch": 135, "train_loss": "1.727", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149078", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "64634", "train_lr": "0.00045566", "train_gnorm": "0.563", "train_loss_scale": "0.5", "train_train_wall": "333", "train_gb_free": "39.3", "train_wall": "118625"}
[2024-10-11 20:05:58,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:05:58,239][fairseq.trainer][INFO] - begin training epoch 136
[2024-10-11 20:05:58,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:13:05,415][train_inner][INFO] - {"epoch": 136, "update": 135.347, "loss": "1.726", "ntokens": "237707", "nsentences": "1791.01", "wps": "102147", "ups": "0.43", "wpb": "237707", "bsz": "1791", "num_updates": "64800", "lr": "0.000455435", "gnorm": "0.556", "loss_scale": "0.5", "train_wall": "170", "gb_free": "39.7", "wall": "119053"}
[2024-10-11 20:16:00,603][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 20:16:27,257][train_inner][INFO] - {"epoch": 136, "update": 135.766, "loss": "1.73", "ntokens": "238994", "nsentences": "1763.6", "wps": "236818", "ups": "0.99", "wpb": "238994", "bsz": "1763.6", "num_updates": "65000", "lr": "0.000455163", "gnorm": "0.564", "loss_scale": "0.5", "train_wall": "198", "gb_free": "39.2", "wall": "119255"}
[2024-10-11 20:18:22,895][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2024-10-11 20:18:22,912][train][INFO] - {"epoch": 136, "train_loss": "1.728", "train_ntokens": "238447", "train_nsentences": "1754.75", "train_wps": "152997", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1754.8", "train_num_updates": "65112", "train_lr": "0.000455011", "train_gnorm": "0.568", "train_loss_scale": "0.5", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "119370"}
[2024-10-11 20:18:23,072][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:18:23,093][fairseq.trainer][INFO] - begin training epoch 137
[2024-10-11 20:18:23,094][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:24:25,971][train_inner][INFO] - {"epoch": 137, "update": 136.184, "loss": "1.727", "ntokens": "237865", "nsentences": "1745.28", "wps": "99377.9", "ups": "0.42", "wpb": "237865", "bsz": "1745.3", "num_updates": "65200", "lr": "0.000454891", "gnorm": "0.572", "loss_scale": "0.5", "train_wall": "200", "gb_free": "40.1", "wall": "119733"}
[2024-10-11 20:27:29,891][train_inner][INFO] - {"epoch": 137, "update": 136.601, "loss": "1.719", "ntokens": "238834", "nsentences": "1756.76", "wps": "259726", "ups": "1.09", "wpb": "238834", "bsz": "1756.8", "num_updates": "65400", "lr": "0.00045462", "gnorm": "0.553", "loss_scale": "0.5", "train_wall": "180", "gb_free": "40.1", "wall": "119917"}
[2024-10-11 20:30:37,508][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2024-10-11 20:30:37,533][train][INFO] - {"epoch": 137, "train_loss": "1.723", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155479", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "65591", "train_lr": "0.00045436", "train_gnorm": "0.552", "train_loss_scale": "0.5", "train_train_wall": "450", "train_gb_free": "39.8", "train_wall": "120105"}
[2024-10-11 20:30:37,672][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:30:37,683][fairseq.trainer][INFO] - begin training epoch 138
[2024-10-11 20:30:37,683][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:35:30,606][train_inner][INFO] - {"epoch": 138, "update": 137.019, "loss": "1.729", "ntokens": "237882", "nsentences": "1728.36", "wps": "98971.8", "ups": "0.42", "wpb": "237882", "bsz": "1728.4", "num_updates": "65600", "lr": "0.000454348", "gnorm": "0.559", "loss_scale": "0.5", "train_wall": "207", "gb_free": "39.3", "wall": "120398"}
[2024-10-11 20:38:28,283][train_inner][INFO] - {"epoch": 138, "update": 137.436, "loss": "1.717", "ntokens": "238888", "nsentences": "1733.01", "wps": "268916", "ups": "1.13", "wpb": "238888", "bsz": "1733", "num_updates": "65800", "lr": "0.000454076", "gnorm": "0.586", "loss_scale": "0.5", "train_wall": "172", "gb_free": "39.3", "wall": "120576"}
[2024-10-11 20:41:45,145][train_inner][INFO] - {"epoch": 138, "update": 137.854, "loss": "1.73", "ntokens": "238980", "nsentences": "1789.83", "wps": "242796", "ups": "1.02", "wpb": "238980", "bsz": "1789.8", "num_updates": "66000", "lr": "0.000453804", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "193", "gb_free": "39.6", "wall": "120773"}
[2024-10-11 20:42:52,041][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2024-10-11 20:42:52,049][train][INFO] - {"epoch": 138, "train_loss": "1.724", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155501", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "66070", "train_lr": "0.000453709", "train_gnorm": "0.57", "train_loss_scale": "0.5", "train_train_wall": "455", "train_gb_free": "39.8", "train_wall": "120839"}
[2024-10-11 20:42:52,197][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:42:52,216][fairseq.trainer][INFO] - begin training epoch 139
[2024-10-11 20:42:52,217][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 20:49:27,039][train_inner][INFO] - {"epoch": 139, "update": 138.271, "loss": "1.715", "ntokens": "237772", "nsentences": "1713.59", "wps": "102956", "ups": "0.43", "wpb": "237772", "bsz": "1713.6", "num_updates": "66200", "lr": "0.000453533", "gnorm": "0.569", "loss_scale": "0.5", "train_wall": "185", "gb_free": "40.1", "wall": "121234"}
[2024-10-11 20:52:52,699][train_inner][INFO] - {"epoch": 139, "update": 138.689, "loss": "1.72", "ntokens": "238885", "nsentences": "1766.47", "wps": "232321", "ups": "0.97", "wpb": "238886", "bsz": "1766.5", "num_updates": "66400", "lr": "0.000453261", "gnorm": "0.565", "loss_scale": "0.5", "train_wall": "202", "gb_free": "40.3", "wall": "121440"}
[2024-10-11 20:55:08,961][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2024-10-11 20:55:08,981][train][INFO] - {"epoch": 139, "train_loss": "1.72", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154992", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "66549", "train_lr": "0.000453058", "train_gnorm": "0.571", "train_loss_scale": "0.5", "train_train_wall": "454", "train_gb_free": "39.6", "train_wall": "121576"}
[2024-10-11 20:55:09,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 20:55:09,205][fairseq.trainer][INFO] - begin training epoch 140
[2024-10-11 20:55:09,205][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:00:55,581][train_inner][INFO] - {"epoch": 140, "update": 139.106, "loss": "1.726", "ntokens": "237837", "nsentences": "1791.01", "wps": "98509.4", "ups": "0.41", "wpb": "237837", "bsz": "1791", "num_updates": "66600", "lr": "0.000452989", "gnorm": "0.57", "loss_scale": "0.5", "train_wall": "189", "gb_free": "40.1", "wall": "121923"}
[2024-10-11 21:03:59,945][train_inner][INFO] - {"epoch": 140, "update": 139.524, "loss": "1.71", "ntokens": "238928", "nsentences": "1718.89", "wps": "259209", "ups": "1.08", "wpb": "238928", "bsz": "1718.9", "num_updates": "66800", "lr": "0.000452717", "gnorm": "0.561", "loss_scale": "0.5", "train_wall": "180", "gb_free": "39.4", "wall": "122107"}
[2024-10-11 21:07:24,011][train_inner][INFO] - {"epoch": 140, "update": 139.942, "loss": "1.727", "ntokens": "238841", "nsentences": "1786.99", "wps": "234088", "ups": "0.98", "wpb": "238841", "bsz": "1787", "num_updates": "67000", "lr": "0.000452446", "gnorm": "0.57", "loss_scale": "0.5", "train_wall": "201", "gb_free": "40.7", "wall": "122311"}
[2024-10-11 21:07:51,253][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 140 @ 67028 updates
[2024-10-11 21:07:51,255][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 21:08:01,670][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 21:08:01,811][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 140 @ 67028 updates, score None) (writing took 10.558011219836771 seconds)
[2024-10-11 21:08:01,812][fairseq_cli.train][INFO] - end of epoch 140 (average epoch stats below)
[2024-10-11 21:08:01,822][train][INFO] - {"epoch": 140, "train_loss": "1.718", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "147791", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "67028", "train_lr": "0.000452408", "train_gnorm": "0.566", "train_loss_scale": "1", "train_train_wall": "463", "train_gb_free": "40.1", "train_wall": "122349"}
[2024-10-11 21:08:02,026][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:08:02,080][fairseq.trainer][INFO] - begin training epoch 141
[2024-10-11 21:08:02,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:14:02,892][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 21:15:19,930][train_inner][INFO] - {"epoch": 141, "update": 140.361, "loss": "1.713", "ntokens": "237868", "nsentences": "1728.92", "wps": "99963.6", "ups": "0.42", "wpb": "237868", "bsz": "1728.9", "num_updates": "67200", "lr": "0.000452174", "gnorm": "0.582", "loss_scale": "0.5", "train_wall": "189", "gb_free": "39.8", "wall": "122787"}
[2024-10-11 21:18:36,339][train_inner][INFO] - {"epoch": 141, "update": 140.779, "loss": "1.721", "ntokens": "238868", "nsentences": "1760.91", "wps": "243246", "ups": "1.02", "wpb": "238868", "bsz": "1760.9", "num_updates": "67400", "lr": "0.000451902", "gnorm": "0.546", "loss_scale": "0.5", "train_wall": "193", "gb_free": "40.2", "wall": "122984"}
[2024-10-11 21:20:10,024][fairseq_cli.train][INFO] - end of epoch 141 (average epoch stats below)
[2024-10-11 21:20:10,036][train][INFO] - {"epoch": 141, "train_loss": "1.719", "train_ntokens": "238449", "train_nsentences": "1753.33", "train_wps": "156519", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.3", "train_num_updates": "67506", "train_lr": "0.000451758", "train_gnorm": "0.566", "train_loss_scale": "0.5", "train_train_wall": "447", "train_gb_free": "39.7", "train_wall": "123077"}
[2024-10-11 21:20:10,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:20:10,914][fairseq.trainer][INFO] - begin training epoch 142
[2024-10-11 21:20:10,915][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:25:41,182][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-11 21:26:36,660][train_inner][INFO] - {"epoch": 142, "update": 141.198, "loss": "1.716", "ntokens": "237742", "nsentences": "1738.88", "wps": "98995.6", "ups": "0.42", "wpb": "237742", "bsz": "1738.9", "num_updates": "67600", "lr": "0.00045163", "gnorm": "0.567", "loss_scale": "0.25", "train_wall": "185", "gb_free": "39.3", "wall": "123464"}
[2024-10-11 21:29:35,421][train_inner][INFO] - {"epoch": 142, "update": 141.616, "loss": "1.717", "ntokens": "238941", "nsentences": "1792.96", "wps": "267359", "ups": "1.12", "wpb": "238941", "bsz": "1793", "num_updates": "67800", "lr": "0.000451359", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "175", "gb_free": "39.6", "wall": "123643"}
[2024-10-11 21:32:25,157][fairseq_cli.train][INFO] - end of epoch 142 (average epoch stats below)
[2024-10-11 21:32:25,183][train][INFO] - {"epoch": 142, "train_loss": "1.716", "train_ntokens": "238451", "train_nsentences": "1754.9", "train_wps": "155047", "train_ups": "0.65", "train_wpb": "238451", "train_bsz": "1754.9", "train_num_updates": "67984", "train_lr": "0.000451109", "train_gnorm": "0.568", "train_loss_scale": "0.25", "train_train_wall": "435", "train_gb_free": "40.1", "train_wall": "123813"}
[2024-10-11 21:32:25,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:32:25,507][fairseq.trainer][INFO] - begin training epoch 143
[2024-10-11 21:32:25,508][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:37:31,548][train_inner][INFO] - {"epoch": 143, "update": 142.033, "loss": "1.72", "ntokens": "237888", "nsentences": "1720.8", "wps": "99929.1", "ups": "0.42", "wpb": "237888", "bsz": "1720.8", "num_updates": "68000", "lr": "0.000451087", "gnorm": "0.58", "loss_scale": "0.25", "train_wall": "187", "gb_free": "40", "wall": "124119"}
[2024-10-11 21:40:46,628][train_inner][INFO] - {"epoch": 143, "update": 142.451, "loss": "1.712", "ntokens": "238896", "nsentences": "1806.28", "wps": "244930", "ups": "1.03", "wpb": "238896", "bsz": "1806.3", "num_updates": "68200", "lr": "0.000450815", "gnorm": "0.548", "loss_scale": "0.25", "train_wall": "191", "gb_free": "40.8", "wall": "124314"}
[2024-10-11 21:43:54,958][train_inner][INFO] - {"epoch": 143, "update": 142.868, "loss": "1.714", "ntokens": "238846", "nsentences": "1730.22", "wps": "253686", "ups": "1.06", "wpb": "238846", "bsz": "1730.2", "num_updates": "68400", "lr": "0.000450543", "gnorm": "0.553", "loss_scale": "0.25", "train_wall": "184", "gb_free": "39.2", "wall": "124502"}
[2024-10-11 21:44:54,734][fairseq_cli.train][INFO] - end of epoch 143 (average epoch stats below)
[2024-10-11 21:44:54,753][train][INFO] - {"epoch": 143, "train_loss": "1.713", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152378", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "68463", "train_lr": "0.000450458", "train_gnorm": "0.556", "train_loss_scale": "0.25", "train_train_wall": "453", "train_gb_free": "40.1", "train_wall": "124562"}
[2024-10-11 21:44:54,867][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:44:54,884][fairseq.trainer][INFO] - begin training epoch 144
[2024-10-11 21:44:54,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 21:51:46,348][train_inner][INFO] - {"epoch": 144, "update": 143.286, "loss": "1.709", "ntokens": "237795", "nsentences": "1718.51", "wps": "100894", "ups": "0.42", "wpb": "237795", "bsz": "1718.5", "num_updates": "68600", "lr": "0.000450272", "gnorm": "0.574", "loss_scale": "0.25", "train_wall": "199", "gb_free": "39.7", "wall": "124974"}
[2024-10-11 21:55:09,381][train_inner][INFO] - {"epoch": 144, "update": 143.704, "loss": "1.707", "ntokens": "238912", "nsentences": "1748.91", "wps": "235356", "ups": "0.99", "wpb": "238912", "bsz": "1748.9", "num_updates": "68800", "lr": "0.00045", "gnorm": "0.552", "loss_scale": "0.25", "train_wall": "199", "gb_free": "39.7", "wall": "125177"}
[2024-10-11 21:57:15,153][fairseq_cli.train][INFO] - end of epoch 144 (average epoch stats below)
[2024-10-11 21:57:15,176][train][INFO] - {"epoch": 144, "train_loss": "1.711", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154261", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "68942", "train_lr": "0.000449807", "train_gnorm": "0.568", "train_loss_scale": "0.25", "train_train_wall": "445", "train_gb_free": "39.8", "train_wall": "125303"}
[2024-10-11 21:57:15,447][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 21:57:15,467][fairseq.trainer][INFO] - begin training epoch 145
[2024-10-11 21:57:15,468][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:03:04,064][train_inner][INFO] - {"epoch": 145, "update": 144.121, "loss": "1.715", "ntokens": "237913", "nsentences": "1762.11", "wps": "100242", "ups": "0.42", "wpb": "237913", "bsz": "1762.1", "num_updates": "69000", "lr": "0.000449728", "gnorm": "0.579", "loss_scale": "0.25", "train_wall": "167", "gb_free": "39.3", "wall": "125651"}
[2024-10-11 22:06:02,428][train_inner][INFO] - {"epoch": 145, "update": 144.539, "loss": "1.704", "ntokens": "238957", "nsentences": "1723.78", "wps": "267953", "ups": "1.12", "wpb": "238957", "bsz": "1723.8", "num_updates": "69200", "lr": "0.000449457", "gnorm": "0.564", "loss_scale": "0.25", "train_wall": "175", "gb_free": "39.9", "wall": "125830"}
[2024-10-11 22:09:15,219][train_inner][INFO] - {"epoch": 145, "update": 144.956, "loss": "1.719", "ntokens": "238815", "nsentences": "1812.58", "wps": "247757", "ups": "1.04", "wpb": "238815", "bsz": "1812.6", "num_updates": "69400", "lr": "0.000449185", "gnorm": "0.574", "loss_scale": "0.25", "train_wall": "189", "gb_free": "39.2", "wall": "126023"}
[2024-10-11 22:09:33,094][fairseq_cli.train][INFO] - end of epoch 145 (average epoch stats below)
[2024-10-11 22:09:33,107][train][INFO] - {"epoch": 145, "train_loss": "1.71", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154783", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "69421", "train_lr": "0.000449156", "train_gnorm": "0.569", "train_loss_scale": "0.25", "train_train_wall": "445", "train_gb_free": "39.8", "train_wall": "126040"}
[2024-10-11 22:09:33,244][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:09:33,264][fairseq.trainer][INFO] - begin training epoch 146
[2024-10-11 22:09:33,264][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:17:17,307][train_inner][INFO] - {"epoch": 146, "update": 145.374, "loss": "1.701", "ntokens": "237860", "nsentences": "1730.84", "wps": "98681.4", "ups": "0.41", "wpb": "237860", "bsz": "1730.8", "num_updates": "69600", "lr": "0.000448913", "gnorm": "0.556", "loss_scale": "0.5", "train_wall": "193", "gb_free": "39.9", "wall": "126505"}
[2024-10-11 22:20:27,975][train_inner][INFO] - {"epoch": 146, "update": 145.791, "loss": "1.711", "ntokens": "238927", "nsentences": "1767.52", "wps": "250633", "ups": "1.05", "wpb": "238928", "bsz": "1767.5", "num_updates": "69800", "lr": "0.000448641", "gnorm": "0.563", "loss_scale": "0.5", "train_wall": "187", "gb_free": "39.8", "wall": "126695"}
[2024-10-11 22:21:57,170][fairseq_cli.train][INFO] - end of epoch 146 (average epoch stats below)
[2024-10-11 22:21:57,200][train][INFO] - {"epoch": 146, "train_loss": "1.708", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153499", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "69900", "train_lr": "0.000448505", "train_gnorm": "0.56", "train_loss_scale": "0.5", "train_train_wall": "450", "train_gb_free": "40.1", "train_wall": "126785"}
[2024-10-11 22:21:57,595][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:21:57,652][fairseq.trainer][INFO] - begin training epoch 147
[2024-10-11 22:21:57,653][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:28:17,417][train_inner][INFO] - {"epoch": 147, "update": 146.209, "loss": "1.706", "ntokens": "237794", "nsentences": "1736.37", "wps": "101310", "ups": "0.43", "wpb": "237794", "bsz": "1736.4", "num_updates": "70000", "lr": "0.00044837", "gnorm": "0.563", "loss_scale": "0.5", "train_wall": "192", "gb_free": "39.8", "wall": "127165"}
[2024-10-11 22:31:25,452][train_inner][INFO] - {"epoch": 147, "update": 146.626, "loss": "1.709", "ntokens": "238818", "nsentences": "1794.94", "wps": "254027", "ups": "1.06", "wpb": "238818", "bsz": "1794.9", "num_updates": "70200", "lr": "0.000448098", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "184", "gb_free": "39.6", "wall": "127353"}
[2024-10-11 22:34:08,746][fairseq_cli.train][INFO] - end of epoch 147 (average epoch stats below)
[2024-10-11 22:34:08,766][train][INFO] - {"epoch": 147, "train_loss": "1.704", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156128", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "70379", "train_lr": "0.000447855", "train_gnorm": "0.561", "train_loss_scale": "0.5", "train_train_wall": "449", "train_gb_free": "40.1", "train_wall": "127516"}
[2024-10-11 22:34:09,037][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:34:09,059][fairseq.trainer][INFO] - begin training epoch 148
[2024-10-11 22:34:09,060][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:39:28,747][train_inner][INFO] - {"epoch": 148, "update": 147.044, "loss": "1.702", "ntokens": "237871", "nsentences": "1725.75", "wps": "98440.1", "ups": "0.41", "wpb": "237871", "bsz": "1725.8", "num_updates": "70400", "lr": "0.000447826", "gnorm": "0.57", "loss_scale": "0.5", "train_wall": "190", "gb_free": "39.2", "wall": "127836"}
[2024-10-11 22:42:25,073][train_inner][INFO] - {"epoch": 148, "update": 147.461, "loss": "1.696", "ntokens": "238881", "nsentences": "1743.2", "wps": "270966", "ups": "1.13", "wpb": "238881", "bsz": "1743.2", "num_updates": "70600", "lr": "0.000447554", "gnorm": "0.558", "loss_scale": "0.5", "train_wall": "128", "gb_free": "39.8", "wall": "128012"}
[2024-10-11 22:45:37,806][train_inner][INFO] - {"epoch": 148, "update": 147.879, "loss": "1.713", "ntokens": "238861", "nsentences": "1789.49", "wps": "247875", "ups": "1.04", "wpb": "238861", "bsz": "1789.5", "num_updates": "70800", "lr": "0.000447283", "gnorm": "0.565", "loss_scale": "0.5", "train_wall": "147", "gb_free": "40.1", "wall": "128205"}
[2024-10-11 22:46:33,516][fairseq_cli.train][INFO] - end of epoch 148 (average epoch stats below)
[2024-10-11 22:46:33,531][train][INFO] - {"epoch": 148, "train_loss": "1.704", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153366", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "70858", "train_lr": "0.000447204", "train_gnorm": "0.563", "train_loss_scale": "0.5", "train_train_wall": "360", "train_gb_free": "39.2", "train_wall": "128261"}
[2024-10-11 22:46:33,688][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:46:33,708][fairseq.trainer][INFO] - begin training epoch 149
[2024-10-11 22:46:33,709][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 22:53:31,782][train_inner][INFO] - {"epoch": 149, "update": 148.296, "loss": "1.698", "ntokens": "237806", "nsentences": "1750.19", "wps": "100346", "ups": "0.42", "wpb": "237806", "bsz": "1750.2", "num_updates": "71000", "lr": "0.000447011", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "188", "gb_free": "40.1", "wall": "128679"}
[2024-10-11 22:56:46,970][train_inner][INFO] - {"epoch": 149, "update": 148.714, "loss": "1.701", "ntokens": "238906", "nsentences": "1737.52", "wps": "244801", "ups": "1.02", "wpb": "238906", "bsz": "1737.5", "num_updates": "71200", "lr": "0.000446739", "gnorm": "0.561", "loss_scale": "0.5", "train_wall": "192", "gb_free": "40.1", "wall": "128874"}
[2024-10-11 22:58:45,067][fairseq_cli.train][INFO] - end of epoch 149 (average epoch stats below)
[2024-10-11 22:58:45,094][train][INFO] - {"epoch": 149, "train_loss": "1.702", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156131", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "71337", "train_lr": "0.000446553", "train_gnorm": "0.564", "train_loss_scale": "0.5", "train_train_wall": "441", "train_gb_free": "40.1", "train_wall": "128992"}
[2024-10-11 22:58:45,299][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 22:58:45,326][fairseq.trainer][INFO] - begin training epoch 150
[2024-10-11 22:58:45,326][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:04:57,720][train_inner][INFO] - {"epoch": 150, "update": 149.132, "loss": "1.705", "ntokens": "237797", "nsentences": "1756.07", "wps": "96913.1", "ups": "0.41", "wpb": "237797", "bsz": "1756.1", "num_updates": "71400", "lr": "0.000446467", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "172", "gb_free": "40.2", "wall": "129365"}
[2024-10-11 23:07:49,200][train_inner][INFO] - {"epoch": 150, "update": 149.549, "loss": "1.693", "ntokens": "238874", "nsentences": "1742.32", "wps": "278611", "ups": "1.17", "wpb": "238874", "bsz": "1742.3", "num_updates": "71600", "lr": "0.000446196", "gnorm": "0.55", "loss_scale": "0.5", "train_wall": "139", "gb_free": "39.4", "wall": "129537"}
[2024-10-11 23:10:53,026][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-11 23:10:54,871][train_inner][INFO] - {"epoch": 150, "update": 149.969, "loss": "1.705", "ntokens": "238977", "nsentences": "1760.63", "wps": "257426", "ups": "1.08", "wpb": "238977", "bsz": "1760.6", "num_updates": "71800", "lr": "0.000445924", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "168", "gb_free": "39.2", "wall": "129722"}
[2024-10-11 23:11:13,167][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 150 @ 71815 updates
[2024-10-11 23:11:13,168][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 23:11:31,716][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-11 23:11:31,736][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 150 @ 71815 updates, score None) (writing took 18.568944686092436 seconds)
[2024-10-11 23:11:31,737][fairseq_cli.train][INFO] - end of epoch 150 (average epoch stats below)
[2024-10-11 23:11:31,739][train][INFO] - {"epoch": 150, "train_loss": "1.699", "train_ntokens": "238447", "train_nsentences": "1753.6", "train_wps": "148672", "train_ups": "0.62", "train_wpb": "238447", "train_bsz": "1753.6", "train_num_updates": "71815", "train_lr": "0.000445904", "train_gnorm": "0.555", "train_loss_scale": "0.5", "train_train_wall": "381", "train_gb_free": "39.7", "train_wall": "129759"}
[2024-10-11 23:11:31,870][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:11:31,896][fairseq.trainer][INFO] - begin training epoch 151
[2024-10-11 23:11:31,897][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:18:50,519][train_inner][INFO] - {"epoch": 151, "update": 150.386, "loss": "1.697", "ntokens": "237803", "nsentences": "1755.12", "wps": "99992", "ups": "0.42", "wpb": "237802", "bsz": "1755.1", "num_updates": "72000", "lr": "0.000445652", "gnorm": "0.567", "loss_scale": "0.5", "train_wall": "181", "gb_free": "39.1", "wall": "130198"}
[2024-10-11 23:22:03,782][train_inner][INFO] - {"epoch": 151, "update": 150.804, "loss": "1.701", "ntokens": "238926", "nsentences": "1754.95", "wps": "247264", "ups": "1.03", "wpb": "238926", "bsz": "1755", "num_updates": "72200", "lr": "0.00044538", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "189", "gb_free": "40.1", "wall": "130391"}
[2024-10-11 23:23:39,653][fairseq_cli.train][INFO] - end of epoch 151 (average epoch stats below)
[2024-10-11 23:23:39,672][train][INFO] - {"epoch": 151, "train_loss": "1.7", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156907", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "72294", "train_lr": "0.000445253", "train_gnorm": "0.558", "train_loss_scale": "0.5", "train_train_wall": "447", "train_gb_free": "39.3", "train_wall": "130487"}
[2024-10-11 23:23:39,839][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:23:39,869][fairseq.trainer][INFO] - begin training epoch 152
[2024-10-11 23:23:39,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:29:57,697][train_inner][INFO] - {"epoch": 152, "update": 151.221, "loss": "1.696", "ntokens": "237867", "nsentences": "1756.63", "wps": "100385", "ups": "0.42", "wpb": "237867", "bsz": "1756.6", "num_updates": "72400", "lr": "0.000445109", "gnorm": "0.551", "loss_scale": "0.5", "train_wall": "194", "gb_free": "39.6", "wall": "130865"}
[2024-10-11 23:33:06,584][train_inner][INFO] - {"epoch": 152, "update": 151.639, "loss": "1.696", "ntokens": "238895", "nsentences": "1750.35", "wps": "252956", "ups": "1.06", "wpb": "238894", "bsz": "1750.3", "num_updates": "72600", "lr": "0.000444837", "gnorm": "0.557", "loss_scale": "0.5", "train_wall": "185", "gb_free": "40.6", "wall": "131054"}
[2024-10-11 23:34:02,233][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-11 23:35:49,029][fairseq_cli.train][INFO] - end of epoch 152 (average epoch stats below)
[2024-10-11 23:35:49,063][train][INFO] - {"epoch": 152, "train_loss": "1.697", "train_ntokens": "238449", "train_nsentences": "1752.96", "train_wps": "156269", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753", "train_num_updates": "72772", "train_lr": "0.000444603", "train_gnorm": "0.558", "train_loss_scale": "0.25", "train_train_wall": "444", "train_gb_free": "39.3", "train_wall": "131216"}
[2024-10-11 23:35:49,269][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:35:49,293][fairseq.trainer][INFO] - begin training epoch 153
[2024-10-11 23:35:49,294][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:41:11,522][train_inner][INFO] - {"epoch": 153, "update": 152.058, "loss": "1.702", "ntokens": "237793", "nsentences": "1752.33", "wps": "98072.6", "ups": "0.41", "wpb": "237793", "bsz": "1752.3", "num_updates": "72800", "lr": "0.000444565", "gnorm": "0.565", "loss_scale": "0.25", "train_wall": "188", "gb_free": "40.1", "wall": "131539"}
[2024-10-11 23:44:13,639][train_inner][INFO] - {"epoch": 153, "update": 152.476, "loss": "1.691", "ntokens": "238894", "nsentences": "1757.26", "wps": "262360", "ups": "1.1", "wpb": "238894", "bsz": "1757.3", "num_updates": "73000", "lr": "0.000444293", "gnorm": "0.568", "loss_scale": "0.25", "train_wall": "125", "gb_free": "40.1", "wall": "131721"}
[2024-10-11 23:47:21,933][train_inner][INFO] - {"epoch": 153, "update": 152.894, "loss": "1.697", "ntokens": "238837", "nsentences": "1754.61", "wps": "253697", "ups": "1.06", "wpb": "238837", "bsz": "1754.6", "num_updates": "73200", "lr": "0.000444022", "gnorm": "0.545", "loss_scale": "0.25", "train_wall": "129", "gb_free": "39.3", "wall": "131909"}
[2024-10-11 23:48:02,353][fairseq_cli.train][INFO] - end of epoch 153 (average epoch stats below)
[2024-10-11 23:48:02,374][train][INFO] - {"epoch": 153, "train_loss": "1.694", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155760", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "73251", "train_lr": "0.000443952", "train_gnorm": "0.56", "train_loss_scale": "0.25", "train_train_wall": "310", "train_gb_free": "39.7", "train_wall": "131950"}
[2024-10-11 23:48:02,600][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-11 23:48:02,635][fairseq.trainer][INFO] - begin training epoch 154
[2024-10-11 23:48:02,635][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-11 23:55:06,415][train_inner][INFO] - {"epoch": 154, "update": 153.311, "loss": "1.683", "ntokens": "237913", "nsentences": "1693.44", "wps": "102444", "ups": "0.43", "wpb": "237913", "bsz": "1693.4", "num_updates": "73400", "lr": "0.00044375", "gnorm": "0.575", "loss_scale": "0.25", "train_wall": "156", "gb_free": "39.1", "wall": "132374"}
[2024-10-11 23:58:28,301][train_inner][INFO] - {"epoch": 154, "update": 153.729, "loss": "1.698", "ntokens": "238839", "nsentences": "1804.68", "wps": "236615", "ups": "0.99", "wpb": "238839", "bsz": "1804.7", "num_updates": "73600", "lr": "0.000443478", "gnorm": "0.557", "loss_scale": "0.25", "train_wall": "198", "gb_free": "39.6", "wall": "132576"}
[2024-10-12 00:00:19,870][fairseq_cli.train][INFO] - end of epoch 154 (average epoch stats below)
[2024-10-12 00:00:19,897][train][INFO] - {"epoch": 154, "train_loss": "1.693", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154867", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "73730", "train_lr": "0.000443302", "train_gnorm": "0.561", "train_loss_scale": "0.25", "train_train_wall": "437", "train_gb_free": "39.6", "train_wall": "132687"}
[2024-10-12 00:00:20,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:00:20,132][fairseq.trainer][INFO] - begin training epoch 155
[2024-10-12 00:00:20,132][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:06:19,792][train_inner][INFO] - {"epoch": 155, "update": 154.146, "loss": "1.696", "ntokens": "237932", "nsentences": "1734.64", "wps": "100929", "ups": "0.42", "wpb": "237932", "bsz": "1734.6", "num_updates": "73800", "lr": "0.000443207", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "169", "gb_free": "39.9", "wall": "133047"}
[2024-10-12 00:09:33,372][train_inner][INFO] - {"epoch": 155, "update": 154.564, "loss": "1.692", "ntokens": "238948", "nsentences": "1769.63", "wps": "246898", "ups": "1.03", "wpb": "238948", "bsz": "1769.6", "num_updates": "74000", "lr": "0.000442935", "gnorm": "0.581", "loss_scale": "0.25", "train_wall": "186", "gb_free": "40.1", "wall": "133241"}
[2024-10-12 00:12:34,046][train_inner][INFO] - {"epoch": 155, "update": 154.981, "loss": "1.696", "ntokens": "238741", "nsentences": "1757.12", "wps": "264319", "ups": "1.11", "wpb": "238741", "bsz": "1757.1", "num_updates": "74200", "lr": "0.000442663", "gnorm": "0.57", "loss_scale": "0.25", "train_wall": "177", "gb_free": "39.6", "wall": "133421"}
[2024-10-12 00:12:50,952][fairseq_cli.train][INFO] - end of epoch 155 (average epoch stats below)
[2024-10-12 00:12:50,987][train][INFO] - {"epoch": 155, "train_loss": "1.693", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152071", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "74209", "train_lr": "0.000442651", "train_gnorm": "0.577", "train_loss_scale": "0.25", "train_train_wall": "440", "train_gb_free": "39.6", "train_wall": "133438"}
[2024-10-12 00:12:51,169][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:12:51,181][fairseq.trainer][INFO] - begin training epoch 156
[2024-10-12 00:12:51,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:20:40,424][train_inner][INFO] - {"epoch": 156, "update": 155.399, "loss": "1.686", "ntokens": "237908", "nsentences": "1761.24", "wps": "97833.8", "ups": "0.41", "wpb": "237908", "bsz": "1761.2", "num_updates": "74400", "lr": "0.000442391", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "198", "gb_free": "39.8", "wall": "133908"}
[2024-10-12 00:24:05,750][train_inner][INFO] - {"epoch": 156, "update": 155.816, "loss": "1.694", "ntokens": "238798", "nsentences": "1763.57", "wps": "232610", "ups": "0.97", "wpb": "238798", "bsz": "1763.6", "num_updates": "74600", "lr": "0.00044212", "gnorm": "0.559", "loss_scale": "0.25", "train_wall": "201", "gb_free": "40.3", "wall": "134113"}
[2024-10-12 00:25:27,675][fairseq_cli.train][INFO] - end of epoch 156 (average epoch stats below)
[2024-10-12 00:25:27,697][train][INFO] - {"epoch": 156, "train_loss": "1.69", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150940", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "74688", "train_lr": "0.000442", "train_gnorm": "0.558", "train_loss_scale": "0.25", "train_train_wall": "463", "train_gb_free": "40.1", "train_wall": "134195"}
[2024-10-12 00:25:27,828][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:25:27,841][fairseq.trainer][INFO] - begin training epoch 157
[2024-10-12 00:25:27,841][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:31:49,721][train_inner][INFO] - {"epoch": 157, "update": 156.234, "loss": "1.684", "ntokens": "237937", "nsentences": "1729.34", "wps": "102568", "ups": "0.43", "wpb": "237937", "bsz": "1729.3", "num_updates": "74800", "lr": "0.000441848", "gnorm": "0.564", "loss_scale": "0.5", "train_wall": "185", "gb_free": "41", "wall": "134577"}
[2024-10-12 00:35:11,397][train_inner][INFO] - {"epoch": 157, "update": 156.651, "loss": "1.687", "ntokens": "238959", "nsentences": "1743.72", "wps": "236984", "ups": "0.99", "wpb": "238959", "bsz": "1743.7", "num_updates": "75000", "lr": "0.000441576", "gnorm": "0.55", "loss_scale": "0.5", "train_wall": "198", "gb_free": "39.4", "wall": "134779"}
[2024-10-12 00:37:38,847][fairseq_cli.train][INFO] - end of epoch 157 (average epoch stats below)
[2024-10-12 00:37:38,886][train][INFO] - {"epoch": 157, "train_loss": "1.688", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156210", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "75167", "train_lr": "0.000441349", "train_gnorm": "0.563", "train_loss_scale": "0.5", "train_train_wall": "446", "train_gb_free": "40.1", "train_wall": "134926"}
[2024-10-12 00:37:39,119][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:37:39,122][fairseq.trainer][INFO] - begin training epoch 158
[2024-10-12 00:37:39,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:43:05,719][train_inner][INFO] - {"epoch": 158, "update": 157.069, "loss": "1.694", "ntokens": "237723", "nsentences": "1770.91", "wps": "100239", "ups": "0.42", "wpb": "237723", "bsz": "1770.9", "num_updates": "75200", "lr": "0.000441304", "gnorm": "0.574", "loss_scale": "0.5", "train_wall": "187", "gb_free": "39.3", "wall": "135253"}
[2024-10-12 00:46:01,851][train_inner][INFO] - {"epoch": 158, "update": 157.486, "loss": "1.678", "ntokens": "238861", "nsentences": "1714.63", "wps": "271240", "ups": "1.14", "wpb": "238861", "bsz": "1714.6", "num_updates": "75400", "lr": "0.000441033", "gnorm": "0.569", "loss_scale": "0.5", "train_wall": "172", "gb_free": "39.4", "wall": "135429"}
[2024-10-12 00:49:24,275][train_inner][INFO] - {"epoch": 158, "update": 157.904, "loss": "1.693", "ntokens": "238872", "nsentences": "1808.33", "wps": "236018", "ups": "0.99", "wpb": "238872", "bsz": "1808.3", "num_updates": "75600", "lr": "0.000440761", "gnorm": "0.542", "loss_scale": "0.5", "train_wall": "198", "gb_free": "39.8", "wall": "135632"}
[2024-10-12 00:50:36,555][fairseq_cli.train][INFO] - end of epoch 158 (average epoch stats below)
[2024-10-12 00:50:36,583][train][INFO] - {"epoch": 158, "train_loss": "1.685", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "146868", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "75646", "train_lr": "0.000440698", "train_gnorm": "0.555", "train_loss_scale": "0.5", "train_train_wall": "485", "train_gb_free": "39.3", "train_wall": "135704"}
[2024-10-12 00:50:36,731][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 00:50:36,747][fairseq.trainer][INFO] - begin training epoch 159
[2024-10-12 00:50:36,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 00:57:28,846][train_inner][INFO] - {"epoch": 159, "update": 158.322, "loss": "1.68", "ntokens": "237756", "nsentences": "1756.01", "wps": "98131.7", "ups": "0.41", "wpb": "237756", "bsz": "1756", "num_updates": "75800", "lr": "0.000440489", "gnorm": "0.54", "loss_scale": "0.5", "train_wall": "211", "gb_free": "40.1", "wall": "136116"}
[2024-10-12 01:00:38,823][train_inner][INFO] - {"epoch": 159, "update": 158.739, "loss": "1.683", "ntokens": "238996", "nsentences": "1743.18", "wps": "251629", "ups": "1.05", "wpb": "238996", "bsz": "1743.2", "num_updates": "76000", "lr": "0.000440217", "gnorm": "0.543", "loss_scale": "0.5", "train_wall": "163", "gb_free": "39.8", "wall": "136306"}
[2024-10-12 01:02:07,967][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-12 01:02:32,270][fairseq_cli.train][INFO] - end of epoch 159 (average epoch stats below)
[2024-10-12 01:02:32,296][train][INFO] - {"epoch": 159, "train_loss": "1.684", "train_ntokens": "238450", "train_nsentences": "1754.18", "train_wps": "159255", "train_ups": "0.67", "train_wpb": "238450", "train_bsz": "1754.2", "train_num_updates": "76124", "train_lr": "0.000440049", "train_gnorm": "0.55", "train_loss_scale": "0.25", "train_train_wall": "412", "train_gb_free": "40.1", "train_wall": "136420"}
[2024-10-12 01:02:32,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:02:32,503][fairseq.trainer][INFO] - begin training epoch 160
[2024-10-12 01:02:32,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:08:35,918][train_inner][INFO] - {"epoch": 160, "update": 159.159, "loss": "1.681", "ntokens": "237811", "nsentences": "1727.9", "wps": "99692.8", "ups": "0.42", "wpb": "237811", "bsz": "1727.9", "num_updates": "76200", "lr": "0.000439946", "gnorm": "0.579", "loss_scale": "0.25", "train_wall": "175", "gb_free": "39.2", "wall": "136783"}
[2024-10-12 01:11:53,334][train_inner][INFO] - {"epoch": 160, "update": 159.576, "loss": "1.683", "ntokens": "238930", "nsentences": "1767.12", "wps": "242070", "ups": "1.01", "wpb": "238930", "bsz": "1767.1", "num_updates": "76400", "lr": "0.000439674", "gnorm": "0.572", "loss_scale": "0.25", "train_wall": "194", "gb_free": "39.6", "wall": "136981"}
[2024-10-12 01:14:55,814][train_inner][INFO] - {"epoch": 160, "update": 159.994, "loss": "1.69", "ntokens": "238870", "nsentences": "1769.01", "wps": "261957", "ups": "1.1", "wpb": "238870", "bsz": "1769", "num_updates": "76600", "lr": "0.000439402", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "178", "gb_free": "39.6", "wall": "137163"}
[2024-10-12 01:14:57,752][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 160 @ 76603 updates
[2024-10-12 01:14:57,755][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 01:15:07,208][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 01:15:07,297][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 160 @ 76603 updates, score None) (writing took 9.544672882184386 seconds)
[2024-10-12 01:15:07,307][fairseq_cli.train][INFO] - end of epoch 160 (average epoch stats below)
[2024-10-12 01:15:07,310][train][INFO] - {"epoch": 160, "train_loss": "1.683", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151279", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "76603", "train_lr": "0.000439398", "train_gnorm": "0.573", "train_loss_scale": "0.25", "train_train_wall": "438", "train_gb_free": "39.7", "train_wall": "137175"}
[2024-10-12 01:15:07,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:15:07,483][fairseq.trainer][INFO] - begin training epoch 161
[2024-10-12 01:15:07,483][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:21:00,142][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 01:22:54,330][train_inner][INFO] - {"epoch": 161, "update": 160.413, "loss": "1.676", "ntokens": "237816", "nsentences": "1737.52", "wps": "99399.5", "ups": "0.42", "wpb": "237816", "bsz": "1737.5", "num_updates": "76800", "lr": "0.00043913", "gnorm": "0.565", "loss_scale": "0.125", "train_wall": "189", "gb_free": "39.3", "wall": "137642"}
[2024-10-12 01:26:01,193][train_inner][INFO] - {"epoch": 161, "update": 160.831, "loss": "1.682", "ntokens": "238955", "nsentences": "1756.73", "wps": "255762", "ups": "1.07", "wpb": "238955", "bsz": "1756.7", "num_updates": "77000", "lr": "0.000438859", "gnorm": "0.571", "loss_scale": "0.125", "train_wall": "183", "gb_free": "40.5", "wall": "137829"}
[2024-10-12 01:27:07,529][fairseq_cli.train][INFO] - end of epoch 161 (average epoch stats below)
[2024-10-12 01:27:07,581][train][INFO] - {"epoch": 161, "train_loss": "1.68", "train_ntokens": "238447", "train_nsentences": "1753.64", "train_wps": "158244", "train_ups": "0.66", "train_wpb": "238447", "train_bsz": "1753.6", "train_num_updates": "77081", "train_lr": "0.000438749", "train_gnorm": "0.565", "train_loss_scale": "0.125", "train_train_wall": "431", "train_gb_free": "40.1", "train_wall": "137895"}
[2024-10-12 01:27:07,916][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:27:07,952][fairseq.trainer][INFO] - begin training epoch 162
[2024-10-12 01:27:07,953][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:34:03,656][train_inner][INFO] - {"epoch": 162, "update": 161.248, "loss": "1.672", "ntokens": "237708", "nsentences": "1723.64", "wps": "98540.7", "ups": "0.41", "wpb": "237708", "bsz": "1723.6", "num_updates": "77200", "lr": "0.000438587", "gnorm": "0.551", "loss_scale": "0.125", "train_wall": "155", "gb_free": "39.3", "wall": "138311"}
[2024-10-12 01:37:06,458][train_inner][INFO] - {"epoch": 162, "update": 161.666, "loss": "1.68", "ntokens": "238989", "nsentences": "1752.2", "wps": "261518", "ups": "1.09", "wpb": "238989", "bsz": "1752.2", "num_updates": "77400", "lr": "0.000438315", "gnorm": "0.542", "loss_scale": "0.125", "train_wall": "146", "gb_free": "40.1", "wall": "138494"}
[2024-10-12 01:39:36,653][fairseq_cli.train][INFO] - end of epoch 162 (average epoch stats below)
[2024-10-12 01:39:36,676][train][INFO] - {"epoch": 162, "train_loss": "1.678", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152477", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "77560", "train_lr": "0.000438098", "train_gnorm": "0.548", "train_loss_scale": "0.125", "train_train_wall": "358", "train_gb_free": "39.4", "train_wall": "138644"}
[2024-10-12 01:39:36,802][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:39:36,822][fairseq.trainer][INFO] - begin training epoch 163
[2024-10-12 01:39:36,822][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:45:10,960][train_inner][INFO] - {"epoch": 163, "update": 162.084, "loss": "1.685", "ntokens": "237803", "nsentences": "1787.4", "wps": "98165.3", "ups": "0.41", "wpb": "237803", "bsz": "1787.4", "num_updates": "77600", "lr": "0.000438043", "gnorm": "0.575", "loss_scale": "0.125", "train_wall": "162", "gb_free": "41", "wall": "138978"}
[2024-10-12 01:48:14,481][train_inner][INFO] - {"epoch": 163, "update": 162.501, "loss": "1.672", "ntokens": "238938", "nsentences": "1754.28", "wps": "260402", "ups": "1.09", "wpb": "238938", "bsz": "1754.3", "num_updates": "77800", "lr": "0.000437772", "gnorm": "0.548", "loss_scale": "0.125", "train_wall": "180", "gb_free": "39.6", "wall": "139162"}
[2024-10-12 01:51:17,918][train_inner][INFO] - {"epoch": 163, "update": 162.919, "loss": "1.68", "ntokens": "238840", "nsentences": "1757.59", "wps": "260415", "ups": "1.09", "wpb": "238840", "bsz": "1757.6", "num_updates": "78000", "lr": "0.0004375", "gnorm": "0.558", "loss_scale": "0.125", "train_wall": "180", "gb_free": "39.7", "wall": "139345"}
[2024-10-12 01:51:56,461][fairseq_cli.train][INFO] - end of epoch 163 (average epoch stats below)
[2024-10-12 01:51:56,488][train][INFO] - {"epoch": 163, "train_loss": "1.676", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154388", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "78039", "train_lr": "0.000437447", "train_gnorm": "0.564", "train_loss_scale": "0.125", "train_train_wall": "441", "train_gb_free": "39.6", "train_wall": "139384"}
[2024-10-12 01:51:56,793][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 01:51:56,819][fairseq.trainer][INFO] - begin training epoch 164
[2024-10-12 01:51:56,820][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 01:59:15,809][train_inner][INFO] - {"epoch": 164, "update": 163.336, "loss": "1.681", "ntokens": "237869", "nsentences": "1799.5", "wps": "99550.7", "ups": "0.42", "wpb": "237869", "bsz": "1799.5", "num_updates": "78200", "lr": "0.000437228", "gnorm": "0.57", "loss_scale": "0.125", "train_wall": "196", "gb_free": "39.2", "wall": "139823"}
[2024-10-12 02:02:31,868][train_inner][INFO] - {"epoch": 164, "update": 163.754, "loss": "1.677", "ntokens": "238878", "nsentences": "1736.56", "wps": "243690", "ups": "1.02", "wpb": "238878", "bsz": "1736.6", "num_updates": "78400", "lr": "0.000436957", "gnorm": "0.562", "loss_scale": "0.125", "train_wall": "192", "gb_free": "39.3", "wall": "140019"}
[2024-10-12 02:04:09,476][fairseq_cli.train][INFO] - end of epoch 164 (average epoch stats below)
[2024-10-12 02:04:09,488][train][INFO] - {"epoch": 164, "train_loss": "1.678", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155823", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "78518", "train_lr": "0.000436796", "train_gnorm": "0.564", "train_loss_scale": "0.125", "train_train_wall": "446", "train_gb_free": "39.6", "train_wall": "140117"}
[2024-10-12 02:04:09,686][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:04:09,726][fairseq.trainer][INFO] - begin training epoch 165
[2024-10-12 02:04:09,726][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:10:22,567][train_inner][INFO] - {"epoch": 165, "update": 164.171, "loss": "1.671", "ntokens": "237861", "nsentences": "1727.25", "wps": "101068", "ups": "0.42", "wpb": "237861", "bsz": "1727.2", "num_updates": "78600", "lr": "0.000436685", "gnorm": "0.559", "loss_scale": "0.125", "train_wall": "187", "gb_free": "39.2", "wall": "140490"}
[2024-10-12 02:13:21,183][train_inner][INFO] - {"epoch": 165, "update": 164.589, "loss": "1.675", "ntokens": "238988", "nsentences": "1761.41", "wps": "267610", "ups": "1.12", "wpb": "238988", "bsz": "1761.4", "num_updates": "78800", "lr": "0.000436413", "gnorm": "0.544", "loss_scale": "0.25", "train_wall": "175", "gb_free": "39.8", "wall": "140669"}
[2024-10-12 02:16:21,820][fairseq_cli.train][INFO] - end of epoch 165 (average epoch stats below)
[2024-10-12 02:16:21,832][train][INFO] - {"epoch": 165, "train_loss": "1.674", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155964", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "78997", "train_lr": "0.000436145", "train_gnorm": "0.554", "train_loss_scale": "0.25", "train_train_wall": "441", "train_gb_free": "40.8", "train_wall": "140849"}
[2024-10-12 02:16:22,605][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:16:22,677][fairseq.trainer][INFO] - begin training epoch 166
[2024-10-12 02:16:22,677][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:21:19,772][train_inner][INFO] - {"epoch": 166, "update": 165.006, "loss": "1.677", "ntokens": "237711", "nsentences": "1737.58", "wps": "99341.3", "ups": "0.42", "wpb": "237711", "bsz": "1737.6", "num_updates": "79000", "lr": "0.000436141", "gnorm": "0.571", "loss_scale": "0.25", "train_wall": "183", "gb_free": "40.6", "wall": "141147"}
[2024-10-12 02:23:30,789][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 02:24:18,543][train_inner][INFO] - {"epoch": 166, "update": 165.426, "loss": "1.67", "ntokens": "238916", "nsentences": "1774.33", "wps": "267304", "ups": "1.12", "wpb": "238916", "bsz": "1774.3", "num_updates": "79200", "lr": "0.00043587", "gnorm": "0.563", "loss_scale": "0.125", "train_wall": "175", "gb_free": "39.6", "wall": "141326"}
[2024-10-12 02:27:53,598][train_inner][INFO] - {"epoch": 166, "update": 165.843, "loss": "1.676", "ntokens": "238842", "nsentences": "1786.84", "wps": "222128", "ups": "0.93", "wpb": "238842", "bsz": "1786.8", "num_updates": "79400", "lr": "0.000435598", "gnorm": "0.545", "loss_scale": "0.125", "train_wall": "211", "gb_free": "39.3", "wall": "141541"}
[2024-10-12 02:29:08,096][fairseq_cli.train][INFO] - end of epoch 166 (average epoch stats below)
[2024-10-12 02:29:08,133][train][INFO] - {"epoch": 166, "train_loss": "1.673", "train_ntokens": "238448", "train_nsentences": "1754.44", "train_wps": "148739", "train_ups": "0.62", "train_wpb": "238448", "train_bsz": "1754.4", "train_num_updates": "79475", "train_lr": "0.000435496", "train_gnorm": "0.558", "train_loss_scale": "0.125", "train_train_wall": "467", "train_gb_free": "39.2", "train_wall": "141616"}
[2024-10-12 02:29:08,453][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:29:08,476][fairseq.trainer][INFO] - begin training epoch 167
[2024-10-12 02:29:08,483][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:35:54,213][train_inner][INFO] - {"epoch": 167, "update": 166.261, "loss": "1.668", "ntokens": "237889", "nsentences": "1732.78", "wps": "98994.3", "ups": "0.42", "wpb": "237888", "bsz": "1732.8", "num_updates": "79600", "lr": "0.000435326", "gnorm": "0.566", "loss_scale": "0.125", "train_wall": "212", "gb_free": "39.4", "wall": "142022"}
[2024-10-12 02:38:31,249][train_inner][INFO] - {"epoch": 167, "update": 166.678, "loss": "1.671", "ntokens": "238818", "nsentences": "1715.39", "wps": "304164", "ups": "1.27", "wpb": "238818", "bsz": "1715.4", "num_updates": "79800", "lr": "0.000435054", "gnorm": "0.549", "loss_scale": "0.125", "train_wall": "153", "gb_free": "39.7", "wall": "142179"}
[2024-10-12 02:41:25,793][fairseq_cli.train][INFO] - end of epoch 167 (average epoch stats below)
[2024-10-12 02:41:25,808][train][INFO] - {"epoch": 167, "train_loss": "1.673", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154836", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "79954", "train_lr": "0.000434845", "train_gnorm": "0.556", "train_loss_scale": "0.125", "train_train_wall": "466", "train_gb_free": "39.8", "train_wall": "142353"}
[2024-10-12 02:41:25,905][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:41:25,918][fairseq.trainer][INFO] - begin training epoch 168
[2024-10-12 02:41:25,919][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 02:46:52,412][train_inner][INFO] - {"epoch": 168, "update": 167.096, "loss": "1.679", "ntokens": "237886", "nsentences": "1779.8", "wps": "94935.1", "ups": "0.4", "wpb": "237886", "bsz": "1779.8", "num_updates": "80000", "lr": "0.000434783", "gnorm": "0.562", "loss_scale": "0.125", "train_wall": "221", "gb_free": "40.1", "wall": "142680"}
[2024-10-12 02:49:54,992][train_inner][INFO] - {"epoch": 168, "update": 167.514, "loss": "1.663", "ntokens": "238827", "nsentences": "1736.18", "wps": "261628", "ups": "1.1", "wpb": "238828", "bsz": "1736.2", "num_updates": "80200", "lr": "0.000434511", "gnorm": "0.57", "loss_scale": "0.125", "train_wall": "179", "gb_free": "40", "wall": "142862"}
[2024-10-12 02:53:11,751][train_inner][INFO] - {"epoch": 168, "update": 167.931, "loss": "1.675", "ntokens": "238937", "nsentences": "1783.55", "wps": "242888", "ups": "1.02", "wpb": "238937", "bsz": "1783.5", "num_updates": "80400", "lr": "0.000434239", "gnorm": "0.559", "loss_scale": "0.125", "train_wall": "193", "gb_free": "39.6", "wall": "143059"}
[2024-10-12 02:53:43,539][fairseq_cli.train][INFO] - end of epoch 168 (average epoch stats below)
[2024-10-12 02:53:43,544][train][INFO] - {"epoch": 168, "train_loss": "1.67", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154822", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "80433", "train_lr": "0.000434194", "train_gnorm": "0.569", "train_loss_scale": "0.125", "train_train_wall": "451", "train_gb_free": "40.2", "train_wall": "143091"}
[2024-10-12 02:53:43,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 02:53:44,008][fairseq.trainer][INFO] - begin training epoch 169
[2024-10-12 02:53:44,009][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:01:18,273][train_inner][INFO] - {"epoch": 169, "update": 168.349, "loss": "1.666", "ntokens": "237859", "nsentences": "1762.52", "wps": "97780.2", "ups": "0.41", "wpb": "237859", "bsz": "1762.5", "num_updates": "80600", "lr": "0.000433967", "gnorm": "0.574", "loss_scale": "0.125", "train_wall": "194", "gb_free": "39.8", "wall": "143546"}
[2024-10-12 03:04:29,208][train_inner][INFO] - {"epoch": 169, "update": 168.766, "loss": "1.673", "ntokens": "238949", "nsentences": "1778.9", "wps": "250301", "ups": "1.05", "wpb": "238949", "bsz": "1778.9", "num_updates": "80800", "lr": "0.000433696", "gnorm": "0.563", "loss_scale": "0.125", "train_wall": "187", "gb_free": "40.3", "wall": "143737"}
[2024-10-12 03:05:55,710][fairseq_cli.train][INFO] - end of epoch 169 (average epoch stats below)
[2024-10-12 03:05:55,728][train][INFO] - {"epoch": 169, "train_loss": "1.669", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155996", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "80912", "train_lr": "0.000433543", "train_gnorm": "0.566", "train_loss_scale": "0.125", "train_train_wall": "433", "train_gb_free": "39.6", "train_wall": "143823"}
[2024-10-12 03:05:56,013][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:05:56,028][fairseq.trainer][INFO] - begin training epoch 170
[2024-10-12 03:05:56,028][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:12:14,963][train_inner][INFO] - {"epoch": 170, "update": 169.184, "loss": "1.665", "ntokens": "237769", "nsentences": "1681.66", "wps": "102102", "ups": "0.43", "wpb": "237769", "bsz": "1681.7", "num_updates": "81000", "lr": "0.000433424", "gnorm": "0.56", "loss_scale": "0.125", "train_wall": "171", "gb_free": "40.1", "wall": "144202"}
[2024-10-12 03:15:28,086][train_inner][INFO] - {"epoch": 170, "update": 169.601, "loss": "1.665", "ntokens": "238860", "nsentences": "1756.92", "wps": "247388", "ups": "1.04", "wpb": "238860", "bsz": "1756.9", "num_updates": "81200", "lr": "0.000433152", "gnorm": "0.56", "loss_scale": "0.25", "train_wall": "189", "gb_free": "39.8", "wall": "144395"}
[2024-10-12 03:18:24,365][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 170 @ 81391 updates
[2024-10-12 03:18:24,372][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 03:18:35,259][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 03:18:35,369][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 170 @ 81391 updates, score None) (writing took 11.004187662154436 seconds)
[2024-10-12 03:18:35,370][fairseq_cli.train][INFO] - end of epoch 170 (average epoch stats below)
[2024-10-12 03:18:35,396][train][INFO] - {"epoch": 170, "train_loss": "1.668", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150362", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "81391", "train_lr": "0.000432893", "train_gnorm": "0.563", "train_loss_scale": "0.25", "train_train_wall": "450", "train_gb_free": "39.1", "train_wall": "144583"}
[2024-10-12 03:18:35,567][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:18:35,614][fairseq.trainer][INFO] - begin training epoch 171
[2024-10-12 03:18:35,615][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:23:34,765][train_inner][INFO] - {"epoch": 171, "update": 170.019, "loss": "1.673", "ntokens": "237860", "nsentences": "1761.23", "wps": "97751.1", "ups": "0.41", "wpb": "237860", "bsz": "1761.2", "num_updates": "81400", "lr": "0.00043288", "gnorm": "0.573", "loss_scale": "0.25", "train_wall": "202", "gb_free": "39.6", "wall": "144882"}
[2024-10-12 03:26:34,487][train_inner][INFO] - {"epoch": 171, "update": 170.436, "loss": "1.657", "ntokens": "238964", "nsentences": "1725.17", "wps": "265941", "ups": "1.11", "wpb": "238964", "bsz": "1725.2", "num_updates": "81600", "lr": "0.000432609", "gnorm": "0.557", "loss_scale": "0.25", "train_wall": "176", "gb_free": "39.3", "wall": "145062"}
[2024-10-12 03:29:51,054][train_inner][INFO] - {"epoch": 171, "update": 170.854, "loss": "1.674", "ntokens": "238803", "nsentences": "1797.16", "wps": "242980", "ups": "1.02", "wpb": "238803", "bsz": "1797.2", "num_updates": "81800", "lr": "0.000432337", "gnorm": "0.58", "loss_scale": "0.25", "train_wall": "193", "gb_free": "39.6", "wall": "145258"}
[2024-10-12 03:31:06,481][fairseq_cli.train][INFO] - end of epoch 171 (average epoch stats below)
[2024-10-12 03:31:06,698][train][INFO] - {"epoch": 171, "train_loss": "1.665", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152028", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "81870", "train_lr": "0.000432242", "train_gnorm": "0.567", "train_loss_scale": "0.25", "train_train_wall": "472", "train_gb_free": "39.6", "train_wall": "145334"}
[2024-10-12 03:31:06,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:31:06,888][fairseq.trainer][INFO] - begin training epoch 172
[2024-10-12 03:31:06,889][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:37:58,003][train_inner][INFO] - {"epoch": 172, "update": 171.271, "loss": "1.656", "ntokens": "237868", "nsentences": "1729.43", "wps": "97698.3", "ups": "0.41", "wpb": "237868", "bsz": "1729.4", "num_updates": "82000", "lr": "0.000432065", "gnorm": "0.554", "loss_scale": "0.25", "train_wall": "209", "gb_free": "39.9", "wall": "145745"}
[2024-10-12 03:41:18,853][train_inner][INFO] - {"epoch": 172, "update": 171.689, "loss": "1.662", "ntokens": "238879", "nsentences": "1746.09", "wps": "237878", "ups": "1", "wpb": "238879", "bsz": "1746.1", "num_updates": "82200", "lr": "0.000431793", "gnorm": "0.551", "loss_scale": "0.25", "train_wall": "197", "gb_free": "40.6", "wall": "145946"}
[2024-10-12 03:43:46,286][fairseq_cli.train][INFO] - end of epoch 172 (average epoch stats below)
[2024-10-12 03:43:46,304][train][INFO] - {"epoch": 172, "train_loss": "1.662", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150364", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "82349", "train_lr": "0.000431591", "train_gnorm": "0.553", "train_loss_scale": "0.25", "train_train_wall": "473", "train_gb_free": "39.3", "train_wall": "146094"}
[2024-10-12 03:43:46,503][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:43:46,512][fairseq.trainer][INFO] - begin training epoch 173
[2024-10-12 03:43:46,512][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 03:49:31,699][train_inner][INFO] - {"epoch": 173, "update": 172.106, "loss": "1.666", "ntokens": "237872", "nsentences": "1776.82", "wps": "96531.4", "ups": "0.41", "wpb": "237872", "bsz": "1776.8", "num_updates": "82400", "lr": "0.000431522", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "204", "gb_free": "39.6", "wall": "146439"}
[2024-10-12 03:52:28,291][train_inner][INFO] - {"epoch": 173, "update": 172.524, "loss": "1.66", "ntokens": "238762", "nsentences": "1769.56", "wps": "270429", "ups": "1.13", "wpb": "238762", "bsz": "1769.6", "num_updates": "82600", "lr": "0.00043125", "gnorm": "0.542", "loss_scale": "0.25", "train_wall": "172", "gb_free": "40.3", "wall": "146616"}
[2024-10-12 03:55:35,994][train_inner][INFO] - {"epoch": 173, "update": 172.942, "loss": "1.658", "ntokens": "238958", "nsentences": "1721.33", "wps": "254619", "ups": "1.07", "wpb": "238958", "bsz": "1721.3", "num_updates": "82800", "lr": "0.000430978", "gnorm": "0.542", "loss_scale": "0.25", "train_wall": "183", "gb_free": "39.6", "wall": "146803"}
[2024-10-12 03:55:55,978][fairseq_cli.train][INFO] - end of epoch 173 (average epoch stats below)
[2024-10-12 03:55:55,999][train][INFO] - {"epoch": 173, "train_loss": "1.659", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156530", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "82828", "train_lr": "0.00043094", "train_gnorm": "0.546", "train_loss_scale": "0.25", "train_train_wall": "437", "train_gb_free": "40.8", "train_wall": "146823"}
[2024-10-12 03:55:56,234][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 03:55:56,252][fairseq.trainer][INFO] - begin training epoch 174
[2024-10-12 03:55:56,253][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:03:20,802][train_inner][INFO] - {"epoch": 174, "update": 173.359, "loss": "1.654", "ntokens": "237922", "nsentences": "1735.31", "wps": "102375", "ups": "0.43", "wpb": "237922", "bsz": "1735.3", "num_updates": "83000", "lr": "0.000430707", "gnorm": "0.559", "loss_scale": "0.25", "train_wall": "181", "gb_free": "39.3", "wall": "147268"}
[2024-10-12 04:06:56,455][train_inner][INFO] - {"epoch": 174, "update": 173.777, "loss": "1.661", "ntokens": "238875", "nsentences": "1766.84", "wps": "221550", "ups": "0.93", "wpb": "238876", "bsz": "1766.8", "num_updates": "83200", "lr": "0.000430435", "gnorm": "0.543", "loss_scale": "0.25", "train_wall": "212", "gb_free": "39.4", "wall": "147484"}
[2024-10-12 04:08:41,616][fairseq_cli.train][INFO] - end of epoch 174 (average epoch stats below)
[2024-10-12 04:08:41,632][train][INFO] - {"epoch": 174, "train_loss": "1.659", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149183", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "83307", "train_lr": "0.000430289", "train_gnorm": "0.554", "train_loss_scale": "0.5", "train_train_wall": "477", "train_gb_free": "39.7", "train_wall": "147589"}
[2024-10-12 04:08:41,901][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:08:41,920][fairseq.trainer][INFO] - begin training epoch 175
[2024-10-12 04:08:41,920][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:15:12,684][train_inner][INFO] - {"epoch": 175, "update": 174.194, "loss": "1.664", "ntokens": "237763", "nsentences": "1792.42", "wps": "95829.4", "ups": "0.4", "wpb": "237763", "bsz": "1792.4", "num_updates": "83400", "lr": "0.000430163", "gnorm": "0.562", "loss_scale": "0.5", "train_wall": "184", "gb_free": "40.5", "wall": "147980"}
[2024-10-12 04:18:16,040][train_inner][INFO] - {"epoch": 175, "update": 174.612, "loss": "1.654", "ntokens": "238985", "nsentences": "1747.49", "wps": "260697", "ups": "1.09", "wpb": "238985", "bsz": "1747.5", "num_updates": "83600", "lr": "0.000429891", "gnorm": "0.535", "loss_scale": "0.5", "train_wall": "166", "gb_free": "40.5", "wall": "148163"}
[2024-10-12 04:21:00,811][fairseq_cli.train][INFO] - end of epoch 175 (average epoch stats below)
[2024-10-12 04:21:00,832][train][INFO] - {"epoch": 175, "train_loss": "1.657", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154519", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "83786", "train_lr": "0.000429639", "train_gnorm": "0.547", "train_loss_scale": "0.5", "train_train_wall": "407", "train_gb_free": "39.7", "train_wall": "148328"}
[2024-10-12 04:21:00,994][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:21:01,005][fairseq.trainer][INFO] - begin training epoch 176
[2024-10-12 04:21:01,005][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:26:11,048][train_inner][INFO] - {"epoch": 176, "update": 175.029, "loss": "1.659", "ntokens": "237753", "nsentences": "1732.76", "wps": "100108", "ups": "0.42", "wpb": "237753", "bsz": "1732.8", "num_updates": "83800", "lr": "0.00042962", "gnorm": "0.554", "loss_scale": "0.5", "train_wall": "183", "gb_free": "40.1", "wall": "148638"}
[2024-10-12 04:29:17,356][train_inner][INFO] - {"epoch": 176, "update": 175.447, "loss": "1.654", "ntokens": "238780", "nsentences": "1783.75", "wps": "256342", "ups": "1.07", "wpb": "238780", "bsz": "1783.8", "num_updates": "84000", "lr": "0.000429348", "gnorm": "0.553", "loss_scale": "0.5", "train_wall": "182", "gb_free": "40.1", "wall": "148825"}
[2024-10-12 04:32:37,204][train_inner][INFO] - {"epoch": 176, "update": 175.864, "loss": "1.661", "ntokens": "238960", "nsentences": "1753.88", "wps": "239158", "ups": "1", "wpb": "238960", "bsz": "1753.9", "num_updates": "84200", "lr": "0.000429076", "gnorm": "0.559", "loss_scale": "0.5", "train_wall": "196", "gb_free": "40.5", "wall": "149025"}
[2024-10-12 04:33:31,038][fairseq_cli.train][INFO] - end of epoch 176 (average epoch stats below)
[2024-10-12 04:33:31,061][train][INFO] - {"epoch": 176, "train_loss": "1.657", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152246", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "84265", "train_lr": "0.000428988", "train_gnorm": "0.557", "train_loss_scale": "0.5", "train_train_wall": "453", "train_gb_free": "41", "train_wall": "149078"}
[2024-10-12 04:33:31,551][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:33:31,596][fairseq.trainer][INFO] - begin training epoch 177
[2024-10-12 04:33:31,597][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:40:31,421][train_inner][INFO] - {"epoch": 177, "update": 176.282, "loss": "1.651", "ntokens": "237756", "nsentences": "1732.07", "wps": "100275", "ups": "0.42", "wpb": "237756", "bsz": "1732.1", "num_updates": "84400", "lr": "0.000428804", "gnorm": "0.559", "loss_scale": "0.5", "train_wall": "188", "gb_free": "39.8", "wall": "149499"}
[2024-10-12 04:43:25,229][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-12 04:43:32,081][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 04:43:49,833][train_inner][INFO] - {"epoch": 177, "update": 176.704, "loss": "1.657", "ntokens": "238896", "nsentences": "1763.29", "wps": "240817", "ups": "1.01", "wpb": "238896", "bsz": "1763.3", "num_updates": "84600", "lr": "0.000428533", "gnorm": "0.562", "loss_scale": "0.125", "train_wall": "195", "gb_free": "39.7", "wall": "149697"}
[2024-10-12 04:45:55,164][fairseq_cli.train][INFO] - end of epoch 177 (average epoch stats below)
[2024-10-12 04:45:55,183][train][INFO] - {"epoch": 177, "train_loss": "1.655", "train_ntokens": "238448", "train_nsentences": "1753.8", "train_wps": "152856", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1753.8", "train_num_updates": "84742", "train_lr": "0.00042834", "train_gnorm": "0.56", "train_loss_scale": "0.125", "train_train_wall": "453", "train_gb_free": "40.1", "train_wall": "149823"}
[2024-10-12 04:45:55,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:45:55,872][fairseq.trainer][INFO] - begin training epoch 178
[2024-10-12 04:45:55,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 04:51:51,294][train_inner][INFO] - {"epoch": 178, "update": 177.121, "loss": "1.655", "ntokens": "237936", "nsentences": "1750.12", "wps": "98840.2", "ups": "0.42", "wpb": "237936", "bsz": "1750.1", "num_updates": "84800", "lr": "0.000428261", "gnorm": "0.557", "loss_scale": "0.125", "train_wall": "181", "gb_free": "39.8", "wall": "150179"}
[2024-10-12 04:54:48,292][train_inner][INFO] - {"epoch": 178, "update": 177.539, "loss": "1.649", "ntokens": "238912", "nsentences": "1743.08", "wps": "269992", "ups": "1.13", "wpb": "238912", "bsz": "1743.1", "num_updates": "85000", "lr": "0.000427989", "gnorm": "0.575", "loss_scale": "0.125", "train_wall": "149", "gb_free": "39.3", "wall": "150356"}
[2024-10-12 04:57:43,309][train_inner][INFO] - {"epoch": 178, "update": 177.956, "loss": "1.658", "ntokens": "238834", "nsentences": "1747.93", "wps": "272971", "ups": "1.14", "wpb": "238834", "bsz": "1747.9", "num_updates": "85200", "lr": "0.000427717", "gnorm": "0.575", "loss_scale": "0.125", "train_wall": "171", "gb_free": "39.3", "wall": "150531"}
[2024-10-12 04:58:22,149][fairseq_cli.train][INFO] - end of epoch 178 (average epoch stats below)
[2024-10-12 04:58:22,168][train][INFO] - {"epoch": 178, "train_loss": "1.654", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152908", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "85221", "train_lr": "0.000427689", "train_gnorm": "0.573", "train_loss_scale": "0.125", "train_train_wall": "417", "train_gb_free": "39.6", "train_wall": "150570"}
[2024-10-12 04:58:22,275][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 04:58:22,288][fairseq.trainer][INFO] - begin training epoch 179
[2024-10-12 04:58:22,289][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:05:51,912][train_inner][INFO] - {"epoch": 179, "update": 178.374, "loss": "1.649", "ntokens": "237839", "nsentences": "1773.03", "wps": "97355.6", "ups": "0.41", "wpb": "237840", "bsz": "1773", "num_updates": "85400", "lr": "0.000427446", "gnorm": "0.57", "loss_scale": "0.125", "train_wall": "216", "gb_free": "39.7", "wall": "151019"}
[2024-10-12 05:09:08,807][train_inner][INFO] - {"epoch": 179, "update": 178.791, "loss": "1.657", "ntokens": "238906", "nsentences": "1770.73", "wps": "242693", "ups": "1.02", "wpb": "238906", "bsz": "1770.7", "num_updates": "85600", "lr": "0.000427174", "gnorm": "0.543", "loss_scale": "0.125", "train_wall": "188", "gb_free": "39.7", "wall": "151216"}
[2024-10-12 05:10:30,426][fairseq_cli.train][INFO] - end of epoch 179 (average epoch stats below)
[2024-10-12 05:10:30,452][train][INFO] - {"epoch": 179, "train_loss": "1.652", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156832", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "85700", "train_lr": "0.000427038", "train_gnorm": "0.558", "train_loss_scale": "0.125", "train_train_wall": "445", "train_gb_free": "39.2", "train_wall": "151298"}
[2024-10-12 05:10:30,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:10:30,781][fairseq.trainer][INFO] - begin training epoch 180
[2024-10-12 05:10:30,786][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:16:43,934][train_inner][INFO] - {"epoch": 180, "update": 179.209, "loss": "1.65", "ntokens": "237875", "nsentences": "1732.9", "wps": "104535", "ups": "0.44", "wpb": "237875", "bsz": "1732.9", "num_updates": "85800", "lr": "0.000426902", "gnorm": "0.562", "loss_scale": "0.125", "train_wall": "168", "gb_free": "39.8", "wall": "151671"}
[2024-10-12 05:20:04,646][train_inner][INFO] - {"epoch": 180, "update": 179.626, "loss": "1.65", "ntokens": "238885", "nsentences": "1751.03", "wps": "238049", "ups": "1", "wpb": "238885", "bsz": "1751", "num_updates": "86000", "lr": "0.00042663", "gnorm": "0.553", "loss_scale": "0.125", "train_wall": "192", "gb_free": "39.6", "wall": "151872"}
[2024-10-12 05:23:04,040][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 180 @ 86179 updates
[2024-10-12 05:23:04,055][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 05:23:14,468][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 05:23:14,516][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 180 @ 86179 updates, score None) (writing took 10.475660023279488 seconds)
[2024-10-12 05:23:14,517][fairseq_cli.train][INFO] - end of epoch 180 (average epoch stats below)
[2024-10-12 05:23:14,523][train][INFO] - {"epoch": 180, "train_loss": "1.651", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149486", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "86179", "train_lr": "0.000426387", "train_gnorm": "0.562", "train_loss_scale": "0.125", "train_train_wall": "457", "train_gb_free": "39.7", "train_wall": "152062"}
[2024-10-12 05:23:14,768][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:23:14,808][fairseq.trainer][INFO] - begin training epoch 181
[2024-10-12 05:23:14,809][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:28:12,646][train_inner][INFO] - {"epoch": 181, "update": 180.044, "loss": "1.657", "ntokens": "237846", "nsentences": "1737.63", "wps": "97478.6", "ups": "0.41", "wpb": "237846", "bsz": "1737.6", "num_updates": "86200", "lr": "0.000426359", "gnorm": "0.582", "loss_scale": "0.125", "train_wall": "204", "gb_free": "39.6", "wall": "152360"}
[2024-10-12 05:31:19,175][train_inner][INFO] - {"epoch": 181, "update": 180.461, "loss": "1.64", "ntokens": "238930", "nsentences": "1732.39", "wps": "256196", "ups": "1.07", "wpb": "238930", "bsz": "1732.4", "num_updates": "86400", "lr": "0.000426087", "gnorm": "0.536", "loss_scale": "0.125", "train_wall": "183", "gb_free": "39.3", "wall": "152547"}
[2024-10-12 05:35:03,838][train_inner][INFO] - {"epoch": 181, "update": 180.879, "loss": "1.656", "ntokens": "238827", "nsentences": "1788.53", "wps": "212619", "ups": "0.89", "wpb": "238827", "bsz": "1788.5", "num_updates": "86600", "lr": "0.000425815", "gnorm": "0.554", "loss_scale": "0.125", "train_wall": "221", "gb_free": "39.8", "wall": "152771"}
[2024-10-12 05:35:46,573][fairseq_cli.train][INFO] - end of epoch 181 (average epoch stats below)
[2024-10-12 05:35:46,607][train][INFO] - {"epoch": 181, "train_loss": "1.65", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151876", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "86658", "train_lr": "0.000425736", "train_gnorm": "0.548", "train_loss_scale": "0.25", "train_train_wall": "473", "train_gb_free": "39.3", "train_wall": "152814"}
[2024-10-12 05:35:46,832][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:35:46,860][fairseq.trainer][INFO] - begin training epoch 182
[2024-10-12 05:35:46,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:42:52,240][train_inner][INFO] - {"epoch": 182, "update": 181.296, "loss": "1.65", "ntokens": "237876", "nsentences": "1755.35", "wps": "101571", "ups": "0.43", "wpb": "237876", "bsz": "1755.4", "num_updates": "86800", "lr": "0.000425543", "gnorm": "0.547", "loss_scale": "0.25", "train_wall": "187", "gb_free": "39.3", "wall": "153240"}
[2024-10-12 05:46:02,722][train_inner][INFO] - {"epoch": 182, "update": 181.714, "loss": "1.648", "ntokens": "238833", "nsentences": "1799.4", "wps": "250783", "ups": "1.05", "wpb": "238833", "bsz": "1799.4", "num_updates": "87000", "lr": "0.000425272", "gnorm": "0.57", "loss_scale": "0.25", "train_wall": "186", "gb_free": "39.7", "wall": "153430"}
[2024-10-12 05:48:01,173][fairseq_cli.train][INFO] - end of epoch 182 (average epoch stats below)
[2024-10-12 05:48:01,199][train][INFO] - {"epoch": 182, "train_loss": "1.648", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155485", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "87137", "train_lr": "0.000425086", "train_gnorm": "0.563", "train_loss_scale": "0.25", "train_train_wall": "448", "train_gb_free": "39.3", "train_wall": "153549"}
[2024-10-12 05:48:01,569][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 05:48:01,607][fairseq.trainer][INFO] - begin training epoch 183
[2024-10-12 05:48:01,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 05:53:45,586][train_inner][INFO] - {"epoch": 183, "update": 182.132, "loss": "1.645", "ntokens": "237858", "nsentences": "1696.45", "wps": "102778", "ups": "0.43", "wpb": "237858", "bsz": "1696.5", "num_updates": "87200", "lr": "0.000425", "gnorm": "0.558", "loss_scale": "0.25", "train_wall": "180", "gb_free": "39.8", "wall": "153893"}
[2024-10-12 05:56:49,766][train_inner][INFO] - {"epoch": 183, "update": 182.549, "loss": "1.645", "ntokens": "238817", "nsentences": "1766.96", "wps": "259342", "ups": "1.09", "wpb": "238817", "bsz": "1767", "num_updates": "87400", "lr": "0.000424728", "gnorm": "0.554", "loss_scale": "0.25", "train_wall": "181", "gb_free": "39.8", "wall": "154077"}
[2024-10-12 05:59:53,189][train_inner][INFO] - {"epoch": 183, "update": 182.967, "loss": "1.653", "ntokens": "238952", "nsentences": "1751.4", "wps": "260553", "ups": "1.09", "wpb": "238952", "bsz": "1751.4", "num_updates": "87600", "lr": "0.000424457", "gnorm": "0.581", "loss_scale": "0.25", "train_wall": "180", "gb_free": "40.1", "wall": "154261"}
[2024-10-12 06:00:26,342][fairseq_cli.train][INFO] - end of epoch 183 (average epoch stats below)
[2024-10-12 06:00:26,359][train][INFO] - {"epoch": 183, "train_loss": "1.647", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153283", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "87616", "train_lr": "0.000424435", "train_gnorm": "0.564", "train_loss_scale": "0.25", "train_train_wall": "455", "train_gb_free": "40.3", "train_wall": "154294"}
[2024-10-12 06:00:26,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:00:26,544][fairseq.trainer][INFO] - begin training epoch 184
[2024-10-12 06:00:26,545][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:07:59,444][train_inner][INFO] - {"epoch": 184, "update": 183.384, "loss": "1.638", "ntokens": "237868", "nsentences": "1757.18", "wps": "97840.5", "ups": "0.41", "wpb": "237868", "bsz": "1757.2", "num_updates": "87800", "lr": "0.000424185", "gnorm": "0.552", "loss_scale": "0.25", "train_wall": "209", "gb_free": "39.6", "wall": "154747"}
[2024-10-12 06:11:27,350][train_inner][INFO] - {"epoch": 184, "update": 183.802, "loss": "1.643", "ntokens": "238809", "nsentences": "1747.3", "wps": "229736", "ups": "0.96", "wpb": "238809", "bsz": "1747.3", "num_updates": "88000", "lr": "0.000423913", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "204", "gb_free": "39.3", "wall": "154955"}
[2024-10-12 06:12:40,351][fairseq_cli.train][INFO] - end of epoch 184 (average epoch stats below)
[2024-10-12 06:12:40,378][train][INFO] - {"epoch": 184, "train_loss": "1.644", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155611", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "88095", "train_lr": "0.000423784", "train_gnorm": "0.556", "train_loss_scale": "0.25", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "155028"}
[2024-10-12 06:12:40,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:12:40,593][fairseq.trainer][INFO] - begin training epoch 185
[2024-10-12 06:12:40,593][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:19:08,749][train_inner][INFO] - {"epoch": 185, "update": 184.219, "loss": "1.648", "ntokens": "237923", "nsentences": "1761.52", "wps": "103133", "ups": "0.43", "wpb": "237923", "bsz": "1761.5", "num_updates": "88200", "lr": "0.000423641", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "174", "gb_free": "39.1", "wall": "155416"}
[2024-10-12 06:19:26,208][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 06:19:41,376][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-12 06:22:17,807][train_inner][INFO] - {"epoch": 185, "update": 184.641, "loss": "1.643", "ntokens": "238878", "nsentences": "1765.24", "wps": "252712", "ups": "1.06", "wpb": "238878", "bsz": "1765.2", "num_updates": "88400", "lr": "0.00042337", "gnorm": "0.567", "loss_scale": "0.0625", "train_wall": "185", "gb_free": "39.7", "wall": "155605"}
[2024-10-12 06:25:10,493][fairseq_cli.train][INFO] - end of epoch 185 (average epoch stats below)
[2024-10-12 06:25:10,497][train][INFO] - {"epoch": 185, "train_loss": "1.644", "train_ntokens": "238448", "train_nsentences": "1754.62", "train_wps": "151631", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1754.6", "train_num_updates": "88572", "train_lr": "0.000423136", "train_gnorm": "0.569", "train_loss_scale": "0.0625", "train_train_wall": "457", "train_gb_free": "40.6", "train_wall": "155778"}
[2024-10-12 06:25:10,617][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:25:10,620][fairseq.trainer][INFO] - begin training epoch 186
[2024-10-12 06:25:10,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:30:21,159][train_inner][INFO] - {"epoch": 186, "update": 185.058, "loss": "1.648", "ntokens": "237804", "nsentences": "1740.83", "wps": "98399.5", "ups": "0.41", "wpb": "237804", "bsz": "1740.8", "num_updates": "88600", "lr": "0.000423098", "gnorm": "0.577", "loss_scale": "0.0625", "train_wall": "212", "gb_free": "40.2", "wall": "156089"}
[2024-10-12 06:33:18,865][train_inner][INFO] - {"epoch": 186, "update": 185.476, "loss": "1.635", "ntokens": "238788", "nsentences": "1760.67", "wps": "268756", "ups": "1.13", "wpb": "238788", "bsz": "1760.7", "num_updates": "88800", "lr": "0.000422826", "gnorm": "0.561", "loss_scale": "0.0625", "train_wall": "174", "gb_free": "39.9", "wall": "156266"}
[2024-10-12 06:36:34,098][train_inner][INFO] - {"epoch": 186, "update": 185.894, "loss": "1.645", "ntokens": "238994", "nsentences": "1729.4", "wps": "244851", "ups": "1.02", "wpb": "238994", "bsz": "1729.4", "num_updates": "89000", "lr": "0.000422554", "gnorm": "0.582", "loss_scale": "0.0625", "train_wall": "192", "gb_free": "39.6", "wall": "156461"}
[2024-10-12 06:37:42,683][fairseq_cli.train][INFO] - end of epoch 186 (average epoch stats below)
[2024-10-12 06:37:42,708][train][INFO] - {"epoch": 186, "train_loss": "1.642", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151843", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "89051", "train_lr": "0.000422485", "train_gnorm": "0.581", "train_loss_scale": "0.0625", "train_train_wall": "476", "train_gb_free": "40.6", "train_wall": "156530"}
[2024-10-12 06:37:42,842][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:37:42,845][fairseq.trainer][INFO] - begin training epoch 187
[2024-10-12 06:37:42,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:44:38,044][train_inner][INFO] - {"epoch": 187, "update": 186.311, "loss": "1.639", "ntokens": "237843", "nsentences": "1746.43", "wps": "98296.2", "ups": "0.41", "wpb": "237843", "bsz": "1746.4", "num_updates": "89200", "lr": "0.000422283", "gnorm": "0.573", "loss_scale": "0.0625", "train_wall": "217", "gb_free": "39.6", "wall": "156945"}
[2024-10-12 06:47:53,234][train_inner][INFO] - {"epoch": 187, "update": 186.729, "loss": "1.642", "ntokens": "238792", "nsentences": "1753.28", "wps": "244694", "ups": "1.02", "wpb": "238792", "bsz": "1753.3", "num_updates": "89400", "lr": "0.000422011", "gnorm": "0.573", "loss_scale": "0.0625", "train_wall": "191", "gb_free": "39.6", "wall": "157141"}
[2024-10-12 06:49:53,249][fairseq_cli.train][INFO] - end of epoch 187 (average epoch stats below)
[2024-10-12 06:49:53,268][train][INFO] - {"epoch": 187, "train_loss": "1.641", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156343", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "89530", "train_lr": "0.000421834", "train_gnorm": "0.566", "train_loss_scale": "0.0625", "train_train_wall": "459", "train_gb_free": "39.8", "train_wall": "157261"}
[2024-10-12 06:49:53,523][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 06:49:53,536][fairseq.trainer][INFO] - begin training epoch 188
[2024-10-12 06:49:53,537][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 06:55:56,416][train_inner][INFO] - {"epoch": 188, "update": 187.146, "loss": "1.646", "ntokens": "237927", "nsentences": "1776.02", "wps": "98484.7", "ups": "0.41", "wpb": "237927", "bsz": "1776", "num_updates": "89600", "lr": "0.000421739", "gnorm": "0.569", "loss_scale": "0.0625", "train_wall": "195", "gb_free": "39.8", "wall": "157624"}
[2024-10-12 06:58:27,520][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-12 06:59:01,451][train_inner][INFO] - {"epoch": 188, "update": 187.566, "loss": "1.632", "ntokens": "238874", "nsentences": "1753.21", "wps": "258205", "ups": "1.08", "wpb": "238874", "bsz": "1753.2", "num_updates": "89800", "lr": "0.000421467", "gnorm": "0.555", "loss_scale": "0.0312", "train_wall": "182", "gb_free": "39.6", "wall": "157809"}
[2024-10-12 07:02:22,407][train_inner][INFO] - {"epoch": 188, "update": 187.983, "loss": "1.646", "ntokens": "238890", "nsentences": "1761.88", "wps": "237774", "ups": "1", "wpb": "238890", "bsz": "1761.9", "num_updates": "90000", "lr": "0.000421196", "gnorm": "0.564", "loss_scale": "0.0312", "train_wall": "197", "gb_free": "39.3", "wall": "158010"}
[2024-10-12 07:02:30,118][fairseq_cli.train][INFO] - end of epoch 188 (average epoch stats below)
[2024-10-12 07:02:30,150][train][INFO] - {"epoch": 188, "train_loss": "1.638", "train_ntokens": "238449", "train_nsentences": "1754.41", "train_wps": "150596", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1754.4", "train_num_updates": "90008", "train_lr": "0.000421185", "train_gnorm": "0.56", "train_loss_scale": "0.0312", "train_train_wall": "464", "train_gb_free": "39.2", "train_wall": "158018"}
[2024-10-12 07:02:30,303][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:02:30,349][fairseq.trainer][INFO] - begin training epoch 189
[2024-10-12 07:02:30,350][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:10:06,250][train_inner][INFO] - {"epoch": 189, "update": 188.401, "loss": "1.628", "ntokens": "237848", "nsentences": "1705.85", "wps": "102562", "ups": "0.43", "wpb": "237848", "bsz": "1705.9", "num_updates": "90200", "lr": "0.000420924", "gnorm": "0.544", "loss_scale": "0.0312", "train_wall": "179", "gb_free": "39.8", "wall": "158474"}
[2024-10-12 07:13:22,255][train_inner][INFO] - {"epoch": 189, "update": 188.818, "loss": "1.644", "ntokens": "238864", "nsentences": "1799.54", "wps": "243747", "ups": "1.02", "wpb": "238864", "bsz": "1799.5", "num_updates": "90400", "lr": "0.000420652", "gnorm": "0.562", "loss_scale": "0.0312", "train_wall": "192", "gb_free": "39.3", "wall": "158670"}
[2024-10-12 07:14:36,737][fairseq_cli.train][INFO] - end of epoch 189 (average epoch stats below)
[2024-10-12 07:14:36,752][train][INFO] - {"epoch": 189, "train_loss": "1.638", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157196", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "90487", "train_lr": "0.000420534", "train_gnorm": "0.555", "train_loss_scale": "0.0312", "train_train_wall": "436", "train_gb_free": "39.7", "train_wall": "158744"}
[2024-10-12 07:14:36,864][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:14:36,884][fairseq.trainer][INFO] - begin training epoch 190
[2024-10-12 07:14:36,884][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:21:28,532][train_inner][INFO] - {"epoch": 190, "update": 189.236, "loss": "1.634", "ntokens": "237896", "nsentences": "1717.97", "wps": "97845.2", "ups": "0.41", "wpb": "237896", "bsz": "1718", "num_updates": "90600", "lr": "0.00042038", "gnorm": "0.591", "loss_scale": "0.0312", "train_wall": "199", "gb_free": "40", "wall": "159156"}
[2024-10-12 07:24:58,899][train_inner][INFO] - {"epoch": 190, "update": 189.653, "loss": "1.635", "ntokens": "238800", "nsentences": "1748.49", "wps": "227042", "ups": "0.95", "wpb": "238800", "bsz": "1748.5", "num_updates": "90800", "lr": "0.000420109", "gnorm": "0.573", "loss_scale": "0.0312", "train_wall": "207", "gb_free": "40.1", "wall": "159366"}
[2024-10-12 07:27:25,488][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 190 @ 90966 updates
[2024-10-12 07:27:25,490][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 07:27:34,155][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 07:27:34,642][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 190 @ 90966 updates, score None) (writing took 9.154133793897927 seconds)
[2024-10-12 07:27:34,654][fairseq_cli.train][INFO] - end of epoch 190 (average epoch stats below)
[2024-10-12 07:27:34,663][train][INFO] - {"epoch": 190, "train_loss": "1.637", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "146828", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "90966", "train_lr": "0.000419883", "train_gnorm": "0.581", "train_loss_scale": "0.0312", "train_train_wall": "475", "train_gb_free": "40.2", "train_wall": "159522"}
[2024-10-12 07:27:34,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:27:34,850][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-12 07:27:34,851][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:32:59,324][train_inner][INFO] - {"epoch": 191, "update": 190.071, "loss": "1.645", "ntokens": "237891", "nsentences": "1782.4", "wps": "99036.4", "ups": "0.42", "wpb": "237892", "bsz": "1782.4", "num_updates": "91000", "lr": "0.000419837", "gnorm": "0.578", "loss_scale": "0.0312", "train_wall": "180", "gb_free": "40.3", "wall": "159847"}
[2024-10-12 07:36:02,894][train_inner][INFO] - {"epoch": 191, "update": 190.489, "loss": "1.626", "ntokens": "238938", "nsentences": "1720.99", "wps": "260337", "ups": "1.09", "wpb": "238938", "bsz": "1721", "num_updates": "91200", "lr": "0.000419565", "gnorm": "0.543", "loss_scale": "0.0312", "train_wall": "180", "gb_free": "40.1", "wall": "160030"}
[2024-10-12 07:39:16,967][train_inner][INFO] - {"epoch": 191, "update": 190.906, "loss": "1.642", "ntokens": "238911", "nsentences": "1770.88", "wps": "246220", "ups": "1.03", "wpb": "238911", "bsz": "1770.9", "num_updates": "91400", "lr": "0.000419293", "gnorm": "0.553", "loss_scale": "0.0312", "train_wall": "190", "gb_free": "39.6", "wall": "160224"}
[2024-10-12 07:40:16,218][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-12 07:40:16,235][train][INFO] - {"epoch": 191, "train_loss": "1.635", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149984", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "91445", "train_lr": "0.000419232", "train_gnorm": "0.558", "train_loss_scale": "0.0312", "train_train_wall": "447", "train_gb_free": "39.3", "train_wall": "160284"}
[2024-10-12 07:40:16,990][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:40:17,009][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-12 07:40:17,010][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:47:25,273][train_inner][INFO] - {"epoch": 192, "update": 191.324, "loss": "1.635", "ntokens": "237730", "nsentences": "1800.66", "wps": "97376", "ups": "0.41", "wpb": "237730", "bsz": "1800.7", "num_updates": "91600", "lr": "0.000419022", "gnorm": "0.557", "loss_scale": "0.0312", "train_wall": "202", "gb_free": "40.6", "wall": "160713"}
[2024-10-12 07:50:36,146][train_inner][INFO] - {"epoch": 192, "update": 191.741, "loss": "1.627", "ntokens": "238954", "nsentences": "1716.32", "wps": "250395", "ups": "1.05", "wpb": "238954", "bsz": "1716.3", "num_updates": "91800", "lr": "0.00041875", "gnorm": "0.547", "loss_scale": "0.0312", "train_wall": "187", "gb_free": "39.6", "wall": "160904"}
[2024-10-12 07:52:30,138][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-12 07:52:30,154][train][INFO] - {"epoch": 192, "train_loss": "1.633", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155628", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "91924", "train_lr": "0.000418582", "train_gnorm": "0.553", "train_loss_scale": "0.0625", "train_train_wall": "461", "train_gb_free": "39.6", "train_wall": "161018"}
[2024-10-12 07:52:30,273][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 07:52:30,283][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-12 07:52:30,284][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 07:58:34,934][train_inner][INFO] - {"epoch": 193, "update": 192.159, "loss": "1.638", "ntokens": "237825", "nsentences": "1766.06", "wps": "99347.7", "ups": "0.42", "wpb": "237825", "bsz": "1766.1", "num_updates": "92000", "lr": "0.000418478", "gnorm": "0.558", "loss_scale": "0.0625", "train_wall": "180", "gb_free": "39.1", "wall": "161382"}
[2024-10-12 08:01:30,357][train_inner][INFO] - {"epoch": 193, "update": 192.576, "loss": "1.624", "ntokens": "238951", "nsentences": "1697.69", "wps": "272441", "ups": "1.14", "wpb": "238951", "bsz": "1697.7", "num_updates": "92200", "lr": "0.000418207", "gnorm": "0.532", "loss_scale": "0.0625", "train_wall": "170", "gb_free": "40.6", "wall": "161558"}
[2024-10-12 08:04:51,975][train_inner][INFO] - {"epoch": 193, "update": 192.994, "loss": "1.639", "ntokens": "238796", "nsentences": "1815.63", "wps": "236891", "ups": "0.99", "wpb": "238796", "bsz": "1815.6", "num_updates": "92400", "lr": "0.000417935", "gnorm": "0.568", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.6", "wall": "161759"}
[2024-10-12 08:04:54,854][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-12 08:04:54,872][train][INFO] - {"epoch": 193, "train_loss": "1.63", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153371", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "92403", "train_lr": "0.000417931", "train_gnorm": "0.549", "train_loss_scale": "0.0625", "train_train_wall": "439", "train_gb_free": "39.7", "train_wall": "161762"}
[2024-10-12 08:04:55,061][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:04:55,077][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-12 08:04:55,077][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:12:37,514][train_inner][INFO] - {"epoch": 194, "update": 193.411, "loss": "1.623", "ntokens": "237828", "nsentences": "1776.66", "wps": "102180", "ups": "0.43", "wpb": "237828", "bsz": "1776.7", "num_updates": "92600", "lr": "0.000417663", "gnorm": "0.555", "loss_scale": "0.0625", "train_wall": "184", "gb_free": "40.4", "wall": "162225"}
[2024-10-12 08:15:43,674][train_inner][INFO] - {"epoch": 194, "update": 193.829, "loss": "1.628", "ntokens": "238858", "nsentences": "1713.31", "wps": "256626", "ups": "1.07", "wpb": "238858", "bsz": "1713.3", "num_updates": "92800", "lr": "0.000417391", "gnorm": "0.573", "loss_scale": "0.0625", "train_wall": "182", "gb_free": "40.3", "wall": "162411"}
[2024-10-12 08:17:15,683][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-12 08:17:15,701][train][INFO] - {"epoch": 194, "train_loss": "1.628", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154176", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "92882", "train_lr": "0.00041728", "train_gnorm": "0.567", "train_loss_scale": "0.0625", "train_train_wall": "454", "train_gb_free": "40.6", "train_wall": "162503"}
[2024-10-12 08:17:15,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:17:15,808][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-12 08:17:15,808][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:23:39,338][train_inner][INFO] - {"epoch": 195, "update": 194.246, "loss": "1.625", "ntokens": "237920", "nsentences": "1727.21", "wps": "100038", "ups": "0.42", "wpb": "237920", "bsz": "1727.2", "num_updates": "93000", "lr": "0.00041712", "gnorm": "0.576", "loss_scale": "0.0625", "train_wall": "209", "gb_free": "40.6", "wall": "162887"}
[2024-10-12 08:26:57,265][train_inner][INFO] - {"epoch": 195, "update": 194.664, "loss": "1.629", "ntokens": "238895", "nsentences": "1771.45", "wps": "241405", "ups": "1.01", "wpb": "238895", "bsz": "1771.5", "num_updates": "93200", "lr": "0.000416848", "gnorm": "0.552", "loss_scale": "0.0625", "train_wall": "194", "gb_free": "39.3", "wall": "163085"}
[2024-10-12 08:29:31,406][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-12 08:29:31,421][train][INFO] - {"epoch": 195, "train_loss": "1.629", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155247", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "93361", "train_lr": "0.000416629", "train_gnorm": "0.569", "train_loss_scale": "0.0625", "train_train_wall": "462", "train_gb_free": "39.6", "train_wall": "163239"}
[2024-10-12 08:29:31,710][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:29:31,717][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-12 08:29:31,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:34:59,653][train_inner][INFO] - {"epoch": 196, "update": 195.081, "loss": "1.639", "ntokens": "237794", "nsentences": "1774.97", "wps": "98591.7", "ups": "0.41", "wpb": "237794", "bsz": "1775", "num_updates": "93400", "lr": "0.000416576", "gnorm": "0.595", "loss_scale": "0.0625", "train_wall": "184", "gb_free": "40.1", "wall": "163567"}
[2024-10-12 08:37:58,364][train_inner][INFO] - {"epoch": 196, "update": 195.499, "loss": "1.623", "ntokens": "238886", "nsentences": "1708.35", "wps": "267361", "ups": "1.12", "wpb": "238886", "bsz": "1708.4", "num_updates": "93600", "lr": "0.000416304", "gnorm": "0.583", "loss_scale": "0.0625", "train_wall": "175", "gb_free": "39.3", "wall": "163746"}
[2024-10-12 08:41:20,497][train_inner][INFO] - {"epoch": 196, "update": 195.916, "loss": "1.635", "ntokens": "238851", "nsentences": "1791.48", "wps": "236336", "ups": "0.99", "wpb": "238851", "bsz": "1791.5", "num_updates": "93800", "lr": "0.000416033", "gnorm": "0.554", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.8", "wall": "163948"}
[2024-10-12 08:41:50,213][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-12 08:41:50,255][train][INFO] - {"epoch": 196, "train_loss": "1.63", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154600", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "93840", "train_lr": "0.000415978", "train_gnorm": "0.572", "train_loss_scale": "0.0625", "train_train_wall": "438", "train_gb_free": "39.3", "train_wall": "163978"}
[2024-10-12 08:41:50,444][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:41:50,455][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-12 08:41:50,455][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 08:49:18,943][train_inner][INFO] - {"epoch": 197, "update": 196.334, "loss": "1.622", "ntokens": "237905", "nsentences": "1778.62", "wps": "99450.2", "ups": "0.42", "wpb": "237905", "bsz": "1778.6", "num_updates": "94000", "lr": "0.000415761", "gnorm": "0.555", "loss_scale": "0.125", "train_wall": "182", "gb_free": "39.8", "wall": "164426"}
[2024-10-12 08:52:32,319][train_inner][INFO] - {"epoch": 197, "update": 196.752, "loss": "1.631", "ntokens": "238860", "nsentences": "1776.67", "wps": "247057", "ups": "1.03", "wpb": "238860", "bsz": "1776.7", "num_updates": "94200", "lr": "0.000415489", "gnorm": "0.568", "loss_scale": "0.125", "train_wall": "189", "gb_free": "39.4", "wall": "164620"}
[2024-10-12 08:54:05,190][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-12 08:54:05,223][train][INFO] - {"epoch": 197, "train_loss": "1.626", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155406", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "94319", "train_lr": "0.000415327", "train_gnorm": "0.562", "train_loss_scale": "0.125", "train_train_wall": "433", "train_gb_free": "40.1", "train_wall": "164713"}
[2024-10-12 08:54:05,350][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 08:54:05,365][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-12 08:54:05,365][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:00:25,142][train_inner][INFO] - {"epoch": 198, "update": 197.169, "loss": "1.627", "ntokens": "237877", "nsentences": "1731.95", "wps": "100621", "ups": "0.42", "wpb": "237877", "bsz": "1732", "num_updates": "94400", "lr": "0.000415217", "gnorm": "0.567", "loss_scale": "0.125", "train_wall": "187", "gb_free": "39.6", "wall": "165093"}
[2024-10-12 09:03:19,991][train_inner][INFO] - {"epoch": 198, "update": 197.587, "loss": "1.623", "ntokens": "238904", "nsentences": "1750.78", "wps": "273285", "ups": "1.14", "wpb": "238904", "bsz": "1750.8", "num_updates": "94600", "lr": "0.000414946", "gnorm": "0.559", "loss_scale": "0.125", "train_wall": "171", "gb_free": "40.1", "wall": "165267"}
[2024-10-12 09:06:15,961][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-12 09:06:35,789][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-12 09:06:35,822][train][INFO] - {"epoch": 198, "train_loss": "1.624", "train_ntokens": "238448", "train_nsentences": "1755.3", "train_wps": "151851", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1755.3", "train_num_updates": "94797", "train_lr": "0.000414678", "train_gnorm": "0.558", "train_loss_scale": "0.0625", "train_train_wall": "461", "train_gb_free": "40.1", "train_wall": "165463"}
[2024-10-12 09:06:35,977][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:06:36,016][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-12 09:06:36,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:11:44,731][train_inner][INFO] - {"epoch": 199, "update": 198.006, "loss": "1.626", "ntokens": "237775", "nsentences": "1735.56", "wps": "94218.4", "ups": "0.4", "wpb": "237775", "bsz": "1735.6", "num_updates": "94800", "lr": "0.000414674", "gnorm": "0.554", "loss_scale": "0.0625", "train_wall": "212", "gb_free": "39.6", "wall": "165772"}
[2024-10-12 09:14:31,676][train_inner][INFO] - {"epoch": 199, "update": 198.424, "loss": "1.624", "ntokens": "238884", "nsentences": "1787.52", "wps": "286193", "ups": "1.2", "wpb": "238884", "bsz": "1787.5", "num_updates": "95000", "lr": "0.000414402", "gnorm": "0.58", "loss_scale": "0.0625", "train_wall": "158", "gb_free": "39.3", "wall": "165939"}
[2024-10-12 09:17:49,301][train_inner][INFO] - {"epoch": 199, "update": 198.841, "loss": "1.625", "ntokens": "238827", "nsentences": "1751.17", "wps": "241706", "ups": "1.01", "wpb": "238827", "bsz": "1751.2", "num_updates": "95200", "lr": "0.00041413", "gnorm": "0.611", "loss_scale": "0.0625", "train_wall": "185", "gb_free": "39.6", "wall": "166137"}
[2024-10-12 09:19:01,203][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-12 09:19:01,228][train][INFO] - {"epoch": 199, "train_loss": "1.626", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153229", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "95276", "train_lr": "0.000414027", "train_gnorm": "0.595", "train_loss_scale": "0.0625", "train_train_wall": "431", "train_gb_free": "40.1", "train_wall": "166209"}
[2024-10-12 09:19:01,331][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:19:01,337][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-12 09:19:01,338][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:25:42,172][train_inner][INFO] - {"epoch": 200, "update": 199.259, "loss": "1.62", "ntokens": "237953", "nsentences": "1707.63", "wps": "100644", "ups": "0.42", "wpb": "237953", "bsz": "1707.6", "num_updates": "95400", "lr": "0.000413859", "gnorm": "0.59", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "40.1", "wall": "166610"}
[2024-10-12 09:29:01,346][train_inner][INFO] - {"epoch": 200, "update": 199.676, "loss": "1.621", "ntokens": "238804", "nsentences": "1765.26", "wps": "239802", "ups": "1", "wpb": "238804", "bsz": "1765.3", "num_updates": "95600", "lr": "0.000413587", "gnorm": "0.578", "loss_scale": "0.0625", "train_wall": "195", "gb_free": "41", "wall": "166809"}
[2024-10-12 09:31:04,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 95755 updates
[2024-10-12 09:31:04,283][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 09:31:15,957][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 09:31:15,971][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 200 @ 95755 updates, score None) (writing took 11.695769043639302 seconds)
[2024-10-12 09:31:15,971][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-12 09:31:15,974][train][INFO] - {"epoch": 200, "train_loss": "1.624", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155452", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "95755", "train_lr": "0.000413376", "train_gnorm": "0.58", "train_loss_scale": "0.0625", "train_train_wall": "449", "train_gb_free": "40.6", "train_wall": "166943"}
[2024-10-12 09:31:16,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:31:16,209][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-12 09:31:16,209][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:36:55,179][train_inner][INFO] - {"epoch": 201, "update": 200.094, "loss": "1.629", "ntokens": "237880", "nsentences": "1759.57", "wps": "100408", "ups": "0.42", "wpb": "237880", "bsz": "1759.6", "num_updates": "95800", "lr": "0.000413315", "gnorm": "0.57", "loss_scale": "0.0625", "train_wall": "180", "gb_free": "39.6", "wall": "167283"}
[2024-10-12 09:39:48,155][train_inner][INFO] - {"epoch": 201, "update": 200.511, "loss": "1.614", "ntokens": "238919", "nsentences": "1712.46", "wps": "276257", "ups": "1.16", "wpb": "238919", "bsz": "1712.5", "num_updates": "96000", "lr": "0.000413043", "gnorm": "0.591", "loss_scale": "0.0625", "train_wall": "169", "gb_free": "39.9", "wall": "167456"}
[2024-10-12 09:43:07,197][train_inner][INFO] - {"epoch": 201, "update": 200.929, "loss": "1.629", "ntokens": "238843", "nsentences": "1797.1", "wps": "240001", "ups": "1", "wpb": "238843", "bsz": "1797.1", "num_updates": "96200", "lr": "0.000412772", "gnorm": "0.567", "loss_scale": "0.0625", "train_wall": "192", "gb_free": "40.1", "wall": "167655"}
[2024-10-12 09:43:25,581][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-10-12 09:43:25,615][train][INFO] - {"epoch": 201, "train_loss": "1.621", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156543", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "96234", "train_lr": "0.000412726", "train_gnorm": "0.576", "train_loss_scale": "0.0625", "train_train_wall": "439", "train_gb_free": "39.3", "train_wall": "167673"}
[2024-10-12 09:43:26,026][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:43:26,079][fairseq.trainer][INFO] - begin training epoch 202
[2024-10-12 09:43:26,080][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 09:51:01,741][train_inner][INFO] - {"epoch": 202, "update": 201.347, "loss": "1.617", "ntokens": "237759", "nsentences": "1732.87", "wps": "100212", "ups": "0.42", "wpb": "237759", "bsz": "1732.9", "num_updates": "96400", "lr": "0.0004125", "gnorm": "0.563", "loss_scale": "0.0625", "train_wall": "166", "gb_free": "40.3", "wall": "168129"}
[2024-10-12 09:54:23,797][train_inner][INFO] - {"epoch": 202, "update": 201.764, "loss": "1.624", "ntokens": "239007", "nsentences": "1739.49", "wps": "236620", "ups": "0.99", "wpb": "239006", "bsz": "1739.5", "num_updates": "96600", "lr": "0.000412228", "gnorm": "0.559", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.6", "wall": "168331"}
[2024-10-12 09:55:12,160][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-12 09:56:06,270][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-10-12 09:56:06,305][train][INFO] - {"epoch": 202, "train_loss": "1.624", "train_ntokens": "238450", "train_nsentences": "1754.93", "train_wps": "149837", "train_ups": "0.63", "train_wpb": "238450", "train_bsz": "1754.9", "train_num_updates": "96712", "train_lr": "0.000412076", "train_gnorm": "0.602", "train_loss_scale": "0.0312", "train_train_wall": "447", "train_gb_free": "39.3", "train_wall": "168434"}
[2024-10-12 09:56:06,585][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 09:56:06,619][fairseq.trainer][INFO] - begin training epoch 203
[2024-10-12 09:56:06,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:02:28,468][train_inner][INFO] - {"epoch": 203, "update": 202.184, "loss": "1.625", "ntokens": "237794", "nsentences": "1778.29", "wps": "98128.4", "ups": "0.41", "wpb": "237794", "bsz": "1778.3", "num_updates": "96800", "lr": "0.000411957", "gnorm": "0.658", "loss_scale": "0.0312", "train_wall": "184", "gb_free": "39.6", "wall": "168816"}
[2024-10-12 10:05:44,518][train_inner][INFO] - {"epoch": 203, "update": 202.601, "loss": "1.622", "ntokens": "238839", "nsentences": "1751.66", "wps": "243667", "ups": "1.02", "wpb": "238839", "bsz": "1751.7", "num_updates": "97000", "lr": "0.000411685", "gnorm": "0.688", "loss_scale": "0.0312", "train_wall": "192", "gb_free": "39.6", "wall": "169012"}
[2024-10-12 10:08:55,325][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-10-12 10:08:55,356][train][INFO] - {"epoch": 203, "train_loss": "1.621", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148518", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "97191", "train_lr": "0.000411425", "train_gnorm": "0.62", "train_loss_scale": "0.0312", "train_train_wall": "463", "train_gb_free": "39.8", "train_wall": "169203"}
[2024-10-12 10:08:55,612][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:08:55,636][fairseq.trainer][INFO] - begin training epoch 204
[2024-10-12 10:08:55,643][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:14:03,098][train_inner][INFO] - {"epoch": 204, "update": 203.019, "loss": "1.627", "ntokens": "237893", "nsentences": "1762.54", "wps": "95429.5", "ups": "0.4", "wpb": "237893", "bsz": "1762.5", "num_updates": "97200", "lr": "0.000411413", "gnorm": "0.578", "loss_scale": "0.0312", "train_wall": "217", "gb_free": "39.3", "wall": "169510"}
[2024-10-12 10:17:03,749][train_inner][INFO] - {"epoch": 204, "update": 203.436, "loss": "1.611", "ntokens": "238776", "nsentences": "1761.38", "wps": "264368", "ups": "1.11", "wpb": "238776", "bsz": "1761.4", "num_updates": "97400", "lr": "0.000411141", "gnorm": "0.56", "loss_scale": "0.0312", "train_wall": "177", "gb_free": "39.7", "wall": "169691"}
[2024-10-12 10:20:32,221][train_inner][INFO] - {"epoch": 204, "update": 203.854, "loss": "1.619", "ntokens": "238955", "nsentences": "1752.41", "wps": "229254", "ups": "0.96", "wpb": "238955", "bsz": "1752.4", "num_updates": "97600", "lr": "0.00041087", "gnorm": "0.573", "loss_scale": "0.0312", "train_wall": "205", "gb_free": "39.8", "wall": "169900"}
[2024-10-12 10:21:50,506][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-10-12 10:21:50,529][train][INFO] - {"epoch": 204, "train_loss": "1.616", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "147346", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "97670", "train_lr": "0.000410774", "train_gnorm": "0.569", "train_loss_scale": "0.0312", "train_train_wall": "487", "train_gb_free": "39.3", "train_wall": "169978"}
[2024-10-12 10:21:50,692][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:21:50,717][fairseq.trainer][INFO] - begin training epoch 205
[2024-10-12 10:21:50,718][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:28:40,826][train_inner][INFO] - {"epoch": 205, "update": 204.271, "loss": "1.616", "ntokens": "237914", "nsentences": "1764.91", "wps": "97387.7", "ups": "0.41", "wpb": "237914", "bsz": "1764.9", "num_updates": "97800", "lr": "0.000410598", "gnorm": "0.559", "loss_scale": "0.0312", "train_wall": "194", "gb_free": "39.3", "wall": "170388"}
[2024-10-12 10:31:49,010][train_inner][INFO] - {"epoch": 205, "update": 204.689, "loss": "1.619", "ntokens": "238826", "nsentences": "1758.96", "wps": "253834", "ups": "1.06", "wpb": "238826", "bsz": "1759", "num_updates": "98000", "lr": "0.000410326", "gnorm": "0.565", "loss_scale": "0.0312", "train_wall": "131", "gb_free": "39.3", "wall": "170576"}
[2024-10-12 10:33:55,738][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-10-12 10:33:55,756][train][INFO] - {"epoch": 205, "train_loss": "1.618", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157494", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "98149", "train_lr": "0.000410124", "train_gnorm": "0.564", "train_loss_scale": "0.0312", "train_train_wall": "366", "train_gb_free": "40.3", "train_wall": "170703"}
[2024-10-12 10:33:56,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:33:56,015][fairseq.trainer][INFO] - begin training epoch 206
[2024-10-12 10:33:56,016][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:39:53,099][train_inner][INFO] - {"epoch": 206, "update": 205.106, "loss": "1.619", "ntokens": "237882", "nsentences": "1736.05", "wps": "98282.6", "ups": "0.41", "wpb": "237882", "bsz": "1736", "num_updates": "98200", "lr": "0.000410054", "gnorm": "0.579", "loss_scale": "0.0312", "train_wall": "178", "gb_free": "39.6", "wall": "171060"}
[2024-10-12 10:42:58,866][train_inner][INFO] - {"epoch": 206, "update": 205.524, "loss": "1.608", "ntokens": "238858", "nsentences": "1766.92", "wps": "257174", "ups": "1.08", "wpb": "238858", "bsz": "1766.9", "num_updates": "98400", "lr": "0.000409783", "gnorm": "0.542", "loss_scale": "0.0312", "train_wall": "182", "gb_free": "39.3", "wall": "171246"}
[2024-10-12 10:46:27,991][train_inner][INFO] - {"epoch": 206, "update": 205.942, "loss": "1.622", "ntokens": "238894", "nsentences": "1750.75", "wps": "228477", "ups": "0.96", "wpb": "238894", "bsz": "1750.8", "num_updates": "98600", "lr": "0.000409511", "gnorm": "0.561", "loss_scale": "0.0312", "train_wall": "205", "gb_free": "39.3", "wall": "171455"}
[2024-10-12 10:47:03,268][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-10-12 10:47:03,300][train][INFO] - {"epoch": 206, "train_loss": "1.615", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145036", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "98628", "train_lr": "0.000409473", "train_gnorm": "0.556", "train_loss_scale": "0.0312", "train_train_wall": "484", "train_gb_free": "39.1", "train_wall": "171491"}
[2024-10-12 10:47:03,435][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 10:47:03,466][fairseq.trainer][INFO] - begin training epoch 207
[2024-10-12 10:47:03,467][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 10:54:47,162][train_inner][INFO] - {"epoch": 207, "update": 206.359, "loss": "1.61", "ntokens": "237835", "nsentences": "1751.16", "wps": "95292.9", "ups": "0.4", "wpb": "237835", "bsz": "1751.2", "num_updates": "98800", "lr": "0.000409239", "gnorm": "0.559", "loss_scale": "0.0625", "train_wall": "222", "gb_free": "40.2", "wall": "171955"}
[2024-10-12 10:58:12,700][train_inner][INFO] - {"epoch": 207, "update": 206.777, "loss": "1.619", "ntokens": "238898", "nsentences": "1767.56", "wps": "232472", "ups": "0.97", "wpb": "238898", "bsz": "1767.6", "num_updates": "99000", "lr": "0.000408967", "gnorm": "0.545", "loss_scale": "0.0625", "train_wall": "202", "gb_free": "39.6", "wall": "172160"}
[2024-10-12 11:00:06,324][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-10-12 11:00:06,340][train][INFO] - {"epoch": 207, "train_loss": "1.614", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "145865", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "99107", "train_lr": "0.000408822", "train_gnorm": "0.553", "train_loss_scale": "0.0625", "train_train_wall": "501", "train_gb_free": "39.7", "train_wall": "172274"}
[2024-10-12 11:00:06,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:00:06,505][fairseq.trainer][INFO] - begin training epoch 208
[2024-10-12 11:00:06,506][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:06:03,201][train_inner][INFO] - {"epoch": 208, "update": 207.194, "loss": "1.61", "ntokens": "237847", "nsentences": "1709.25", "wps": "101106", "ups": "0.43", "wpb": "237847", "bsz": "1709.2", "num_updates": "99200", "lr": "0.000408696", "gnorm": "0.548", "loss_scale": "0.0625", "train_wall": "199", "gb_free": "39.6", "wall": "172631"}
[2024-10-12 11:09:19,734][train_inner][INFO] - {"epoch": 208, "update": 207.612, "loss": "1.61", "ntokens": "238852", "nsentences": "1772.39", "wps": "243075", "ups": "1.02", "wpb": "238852", "bsz": "1772.4", "num_updates": "99400", "lr": "0.000408424", "gnorm": "0.564", "loss_scale": "0.0625", "train_wall": "193", "gb_free": "40.6", "wall": "172827"}
[2024-10-12 11:12:03,057][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-10-12 11:12:03,075][train][INFO] - {"epoch": 208, "train_loss": "1.611", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "159360", "train_ups": "0.67", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "99586", "train_lr": "0.000408171", "train_gnorm": "0.556", "train_loss_scale": "0.0625", "train_train_wall": "440", "train_gb_free": "39.3", "train_wall": "172990"}
[2024-10-12 11:12:03,357][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:12:03,393][fairseq.trainer][INFO] - begin training epoch 209
[2024-10-12 11:12:03,393][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:17:23,653][train_inner][INFO] - {"epoch": 209, "update": 208.029, "loss": "1.617", "ntokens": "237869", "nsentences": "1760.98", "wps": "98310.9", "ups": "0.41", "wpb": "237869", "bsz": "1761", "num_updates": "99600", "lr": "0.000408152", "gnorm": "0.56", "loss_scale": "0.0625", "train_wall": "182", "gb_free": "39.8", "wall": "173311"}
[2024-10-12 11:20:19,050][train_inner][INFO] - {"epoch": 209, "update": 208.447, "loss": "1.605", "ntokens": "238858", "nsentences": "1757.42", "wps": "272372", "ups": "1.14", "wpb": "238858", "bsz": "1757.4", "num_updates": "99800", "lr": "0.00040788", "gnorm": "0.58", "loss_scale": "0.0625", "train_wall": "172", "gb_free": "39.5", "wall": "173486"}
[2024-10-12 11:23:36,498][train_inner][INFO] - {"epoch": 209, "update": 208.864, "loss": "1.615", "ntokens": "238950", "nsentences": "1746.98", "wps": "242054", "ups": "1.01", "wpb": "238950", "bsz": "1747", "num_updates": "100000", "lr": "0.000407609", "gnorm": "0.611", "loss_scale": "0.0625", "train_wall": "187", "gb_free": "40.6", "wall": "173684"}
[2024-10-12 11:23:36,510][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 100000 updates
[2024-10-12 11:23:36,513][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_209_100000.pt
[2024-10-12 11:23:40,442][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_209_100000.pt
[2024-10-12 11:23:44,835][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_209_100000.pt (epoch 209 @ 100000 updates, score None) (writing took 8.325731381773949 seconds)
[2024-10-12 11:24:29,797][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-10-12 11:24:29,803][train][INFO] - {"epoch": 209, "train_loss": "1.612", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152960", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "100065", "train_lr": "0.00040752", "train_gnorm": "0.595", "train_loss_scale": "0.0625", "train_train_wall": "425", "train_gb_free": "39.9", "train_wall": "173737"}
[2024-10-12 11:24:30,102][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:24:30,116][fairseq.trainer][INFO] - begin training epoch 210
[2024-10-12 11:24:30,117][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:31:36,235][train_inner][INFO] - {"epoch": 210, "update": 209.282, "loss": "1.607", "ntokens": "237757", "nsentences": "1750.17", "wps": "99121.4", "ups": "0.42", "wpb": "237757", "bsz": "1750.2", "num_updates": "100200", "lr": "0.000407337", "gnorm": "0.584", "loss_scale": "0.0625", "train_wall": "187", "gb_free": "39.6", "wall": "174164"}
[2024-10-12 11:34:40,180][train_inner][INFO] - {"epoch": 210, "update": 209.699, "loss": "1.609", "ntokens": "238940", "nsentences": "1720.89", "wps": "259806", "ups": "1.09", "wpb": "238940", "bsz": "1720.9", "num_updates": "100400", "lr": "0.000407065", "gnorm": "0.553", "loss_scale": "0.0625", "train_wall": "181", "gb_free": "39.4", "wall": "174348"}
[2024-10-12 11:36:56,160][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 210 @ 100544 updates
[2024-10-12 11:36:56,161][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 11:37:10,049][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 11:37:10,209][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 210 @ 100544 updates, score None) (writing took 14.048596017062664 seconds)
[2024-10-12 11:37:10,210][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-10-12 11:37:10,227][train][INFO] - {"epoch": 210, "train_loss": "1.61", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150206", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "100544", "train_lr": "0.00040687", "train_gnorm": "0.563", "train_loss_scale": "0.0625", "train_train_wall": "458", "train_gb_free": "39.2", "train_wall": "174498"}
[2024-10-12 11:37:10,387][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:37:10,404][fairseq.trainer][INFO] - begin training epoch 211
[2024-10-12 11:37:10,404][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:42:55,131][train_inner][INFO] - {"epoch": 211, "update": 210.117, "loss": "1.612", "ntokens": "237828", "nsentences": "1778.37", "wps": "96103.1", "ups": "0.4", "wpb": "237828", "bsz": "1778.4", "num_updates": "100600", "lr": "0.000406793", "gnorm": "0.571", "loss_scale": "0.0625", "train_wall": "180", "gb_free": "39.3", "wall": "174843"}
[2024-10-12 11:45:53,913][train_inner][INFO] - {"epoch": 211, "update": 210.534, "loss": "1.612", "ntokens": "238925", "nsentences": "1794.08", "wps": "267300", "ups": "1.12", "wpb": "238925", "bsz": "1794.1", "num_updates": "100800", "lr": "0.000406522", "gnorm": "0.57", "loss_scale": "0.125", "train_wall": "139", "gb_free": "40.1", "wall": "175021"}
[2024-10-12 11:49:00,962][train_inner][INFO] - {"epoch": 211, "update": 210.952, "loss": "1.611", "ntokens": "238864", "nsentences": "1744.92", "wps": "255416", "ups": "1.07", "wpb": "238864", "bsz": "1744.9", "num_updates": "101000", "lr": "0.00040625", "gnorm": "0.559", "loss_scale": "0.125", "train_wall": "145", "gb_free": "39.8", "wall": "175208"}
[2024-10-12 11:49:20,083][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-10-12 11:49:20,094][train][INFO] - {"epoch": 211, "train_loss": "1.609", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156491", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "101023", "train_lr": "0.000406219", "train_gnorm": "0.574", "train_loss_scale": "0.125", "train_train_wall": "346", "train_gb_free": "40.4", "train_wall": "175227"}
[2024-10-12 11:49:20,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 11:49:20,341][fairseq.trainer][INFO] - begin training epoch 212
[2024-10-12 11:49:20,342][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 11:57:00,170][train_inner][INFO] - {"epoch": 212, "update": 211.37, "loss": "1.605", "ntokens": "237912", "nsentences": "1729.47", "wps": "99295.5", "ups": "0.42", "wpb": "237912", "bsz": "1729.5", "num_updates": "101200", "lr": "0.000405978", "gnorm": "0.58", "loss_scale": "0.125", "train_wall": "192", "gb_free": "39.6", "wall": "175688"}
[2024-10-12 12:00:11,481][train_inner][INFO] - {"epoch": 212, "update": 211.787, "loss": "1.611", "ntokens": "238802", "nsentences": "1754.17", "wps": "249658", "ups": "1.05", "wpb": "238802", "bsz": "1754.2", "num_updates": "101400", "lr": "0.000405707", "gnorm": "0.566", "loss_scale": "0.125", "train_wall": "187", "gb_free": "39.2", "wall": "175879"}
[2024-10-12 12:01:51,271][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-10-12 12:01:51,295][train][INFO] - {"epoch": 212, "train_loss": "1.609", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152050", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "101502", "train_lr": "0.000405568", "train_gnorm": "0.571", "train_loss_scale": "0.125", "train_train_wall": "461", "train_gb_free": "39.7", "train_wall": "175979"}
[2024-10-12 12:01:51,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:01:51,448][fairseq.trainer][INFO] - begin training epoch 213
[2024-10-12 12:01:51,448][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:08:19,648][train_inner][INFO] - {"epoch": 213, "update": 212.205, "loss": "1.602", "ntokens": "237868", "nsentences": "1733.97", "wps": "97454.8", "ups": "0.41", "wpb": "237868", "bsz": "1734", "num_updates": "101600", "lr": "0.000405435", "gnorm": "0.574", "loss_scale": "0.125", "train_wall": "203", "gb_free": "39.4", "wall": "176367"}
[2024-10-12 12:11:34,642][train_inner][INFO] - {"epoch": 213, "update": 212.622, "loss": "1.602", "ntokens": "238942", "nsentences": "1768.91", "wps": "245091", "ups": "1.03", "wpb": "238942", "bsz": "1768.9", "num_updates": "101800", "lr": "0.000405163", "gnorm": "0.556", "loss_scale": "0.125", "train_wall": "191", "gb_free": "40.1", "wall": "176562"}
[2024-10-12 12:14:23,314][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2024-10-12 12:14:23,351][train][INFO] - {"epoch": 213, "train_loss": "1.603", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151878", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "101981", "train_lr": "0.000404917", "train_gnorm": "0.556", "train_loss_scale": "0.125", "train_train_wall": "461", "train_gb_free": "39.6", "train_wall": "176731"}
[2024-10-12 12:14:23,603][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:14:23,625][fairseq.trainer][INFO] - begin training epoch 214
[2024-10-12 12:14:23,625][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:19:47,682][train_inner][INFO] - {"epoch": 214, "update": 213.04, "loss": "1.609", "ntokens": "237757", "nsentences": "1763.43", "wps": "96448.4", "ups": "0.41", "wpb": "237757", "bsz": "1763.4", "num_updates": "102000", "lr": "0.000404891", "gnorm": "0.552", "loss_scale": "0.125", "train_wall": "213", "gb_free": "39.7", "wall": "177055"}
[2024-10-12 12:22:37,085][train_inner][INFO] - {"epoch": 214, "update": 213.457, "loss": "1.602", "ntokens": "238863", "nsentences": "1768.89", "wps": "282027", "ups": "1.18", "wpb": "238863", "bsz": "1768.9", "num_updates": "102200", "lr": "0.00040462", "gnorm": "0.545", "loss_scale": "0.125", "train_wall": "145", "gb_free": "40.6", "wall": "177224"}
[2024-10-12 12:25:43,695][train_inner][INFO] - {"epoch": 214, "update": 213.875, "loss": "1.604", "ntokens": "238859", "nsentences": "1735.43", "wps": "256016", "ups": "1.07", "wpb": "238859", "bsz": "1735.4", "num_updates": "102400", "lr": "0.000404348", "gnorm": "0.555", "loss_scale": "0.125", "train_wall": "140", "gb_free": "39.6", "wall": "177411"}
[2024-10-12 12:26:29,034][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2024-10-12 12:26:29,057][train][INFO] - {"epoch": 214, "train_loss": "1.605", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "157392", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "102460", "train_lr": "0.000404266", "train_gnorm": "0.559", "train_loss_scale": "0.125", "train_train_wall": "369", "train_gb_free": "40.1", "train_wall": "177456"}
[2024-10-12 12:26:29,368][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:26:29,395][fairseq.trainer][INFO] - begin training epoch 215
[2024-10-12 12:26:29,396][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:33:43,817][train_inner][INFO] - {"epoch": 215, "update": 214.292, "loss": "1.605", "ntokens": "237822", "nsentences": "1755.95", "wps": "99068.6", "ups": "0.42", "wpb": "237822", "bsz": "1756", "num_updates": "102600", "lr": "0.000404076", "gnorm": "0.573", "loss_scale": "0.125", "train_wall": "169", "gb_free": "40.1", "wall": "177891"}
[2024-10-12 12:36:54,837][train_inner][INFO] - {"epoch": 215, "update": 214.71, "loss": "1.611", "ntokens": "238956", "nsentences": "1784.03", "wps": "250205", "ups": "1.05", "wpb": "238956", "bsz": "1784", "num_updates": "102800", "lr": "0.000403804", "gnorm": "0.551", "loss_scale": "0.25", "train_wall": "187", "gb_free": "39.6", "wall": "178082"}
[2024-10-12 12:38:59,418][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2024-10-12 12:38:59,437][train][INFO] - {"epoch": 215, "train_loss": "1.605", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152216", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "102939", "train_lr": "0.000403615", "train_gnorm": "0.551", "train_loss_scale": "0.25", "train_train_wall": "442", "train_gb_free": "39.2", "train_wall": "178207"}
[2024-10-12 12:38:59,725][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:38:59,737][fairseq.trainer][INFO] - begin training epoch 216
[2024-10-12 12:38:59,737][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:44:58,020][train_inner][INFO] - {"epoch": 216, "update": 215.127, "loss": "1.603", "ntokens": "237882", "nsentences": "1725.83", "wps": "98468.3", "ups": "0.41", "wpb": "237882", "bsz": "1725.8", "num_updates": "103000", "lr": "0.000403533", "gnorm": "0.572", "loss_scale": "0.25", "train_wall": "190", "gb_free": "39.4", "wall": "178565"}
[2024-10-12 12:48:16,291][train_inner][INFO] - {"epoch": 216, "update": 215.545, "loss": "1.598", "ntokens": "238820", "nsentences": "1775.81", "wps": "240917", "ups": "1.01", "wpb": "238820", "bsz": "1775.8", "num_updates": "103200", "lr": "0.000403261", "gnorm": "0.564", "loss_scale": "0.25", "train_wall": "194", "gb_free": "40.1", "wall": "178764"}
[2024-10-12 12:51:24,928][train_inner][INFO] - {"epoch": 216, "update": 215.962, "loss": "1.608", "ntokens": "238907", "nsentences": "1735.09", "wps": "253305", "ups": "1.06", "wpb": "238907", "bsz": "1735.1", "num_updates": "103400", "lr": "0.000402989", "gnorm": "0.557", "loss_scale": "0.25", "train_wall": "185", "gb_free": "40.6", "wall": "178952"}
[2024-10-12 12:51:48,636][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2024-10-12 12:51:48,658][train][INFO] - {"epoch": 216, "train_loss": "1.603", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148488", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "103418", "train_lr": "0.000402965", "train_gnorm": "0.569", "train_loss_scale": "0.25", "train_train_wall": "470", "train_gb_free": "39.3", "train_wall": "178976"}
[2024-10-12 12:51:49,002][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 12:51:49,031][fairseq.trainer][INFO] - begin training epoch 217
[2024-10-12 12:51:49,032][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 12:58:38,817][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 12:59:40,328][train_inner][INFO] - {"epoch": 217, "update": 216.382, "loss": "1.597", "ntokens": "237868", "nsentences": "1768.74", "wps": "96031.6", "ups": "0.4", "wpb": "237868", "bsz": "1768.7", "num_updates": "103600", "lr": "0.000402717", "gnorm": "0.558", "loss_scale": "0.125", "train_wall": "202", "gb_free": "40.1", "wall": "179448"}
[2024-10-12 13:02:48,042][train_inner][INFO] - {"epoch": 217, "update": 216.8, "loss": "1.607", "ntokens": "238839", "nsentences": "1754.84", "wps": "254484", "ups": "1.07", "wpb": "238839", "bsz": "1754.8", "num_updates": "103800", "lr": "0.000402446", "gnorm": "0.587", "loss_scale": "0.125", "train_wall": "184", "gb_free": "40.1", "wall": "179635"}
[2024-10-12 13:04:05,085][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2024-10-12 13:04:05,167][train][INFO] - {"epoch": 217, "train_loss": "1.604", "train_ntokens": "238452", "train_nsentences": "1752.14", "train_wps": "154762", "train_ups": "0.65", "train_wpb": "238452", "train_bsz": "1752.1", "train_num_updates": "103896", "train_lr": "0.000402315", "train_gnorm": "0.573", "train_loss_scale": "0.125", "train_train_wall": "438", "train_gb_free": "39.6", "train_wall": "179713"}
[2024-10-12 13:04:05,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:04:05,504][fairseq.trainer][INFO] - begin training epoch 218
[2024-10-12 13:04:05,504][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:10:42,060][train_inner][INFO] - {"epoch": 218, "update": 217.217, "loss": "1.598", "ntokens": "237911", "nsentences": "1701.95", "wps": "100384", "ups": "0.42", "wpb": "237911", "bsz": "1702", "num_updates": "104000", "lr": "0.000402174", "gnorm": "0.565", "loss_scale": "0.125", "train_wall": "180", "gb_free": "39.8", "wall": "180109"}
[2024-10-12 13:13:37,318][train_inner][INFO] - {"epoch": 218, "update": 217.635, "loss": "1.599", "ntokens": "238754", "nsentences": "1767.45", "wps": "272476", "ups": "1.14", "wpb": "238754", "bsz": "1767.5", "num_updates": "104200", "lr": "0.000401902", "gnorm": "0.583", "loss_scale": "0.125", "train_wall": "153", "gb_free": "40.6", "wall": "180285"}
[2024-10-12 13:16:26,061][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2024-10-12 13:16:26,104][train][INFO] - {"epoch": 218, "train_loss": "1.599", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154156", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "104375", "train_lr": "0.000401664", "train_gnorm": "0.568", "train_loss_scale": "0.125", "train_train_wall": "402", "train_gb_free": "39.7", "train_wall": "180453"}
[2024-10-12 13:16:26,312][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:16:26,321][fairseq.trainer][INFO] - begin training epoch 219
[2024-10-12 13:16:26,321][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:21:46,267][train_inner][INFO] - {"epoch": 219, "update": 218.052, "loss": "1.606", "ntokens": "237846", "nsentences": "1773.38", "wps": "97292.3", "ups": "0.41", "wpb": "237846", "bsz": "1773.4", "num_updates": "104400", "lr": "0.00040163", "gnorm": "0.565", "loss_scale": "0.125", "train_wall": "175", "gb_free": "40.1", "wall": "180774"}
[2024-10-12 13:24:58,036][train_inner][INFO] - {"epoch": 219, "update": 218.47, "loss": "1.594", "ntokens": "238928", "nsentences": "1763.44", "wps": "249195", "ups": "1.04", "wpb": "238928", "bsz": "1763.4", "num_updates": "104600", "lr": "0.000401359", "gnorm": "0.544", "loss_scale": "0.125", "train_wall": "188", "gb_free": "39.7", "wall": "180965"}
[2024-10-12 13:26:38,289][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-12 13:28:04,495][train_inner][INFO] - {"epoch": 219, "update": 218.889, "loss": "1.61", "ntokens": "238938", "nsentences": "1744.49", "wps": "256303", "ups": "1.07", "wpb": "238938", "bsz": "1744.5", "num_updates": "104800", "lr": "0.000401087", "gnorm": "0.685", "loss_scale": "0.0625", "train_wall": "183", "gb_free": "39.3", "wall": "181152"}
[2024-10-12 13:28:55,383][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2024-10-12 13:28:55,401][train][INFO] - {"epoch": 219, "train_loss": "1.603", "train_ntokens": "238448", "train_nsentences": "1753.24", "train_wps": "152118", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1753.2", "train_num_updates": "104853", "train_lr": "0.000401015", "train_gnorm": "0.607", "train_loss_scale": "0.0625", "train_train_wall": "453", "train_gb_free": "39.6", "train_wall": "181203"}
[2024-10-12 13:28:55,620][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:28:55,624][fairseq.trainer][INFO] - begin training epoch 220
[2024-10-12 13:28:55,624][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:36:07,399][train_inner][INFO] - {"epoch": 220, "update": 219.307, "loss": "1.593", "ntokens": "237751", "nsentences": "1733.15", "wps": "98469.1", "ups": "0.41", "wpb": "237751", "bsz": "1733.2", "num_updates": "105000", "lr": "0.000400815", "gnorm": "0.581", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "41", "wall": "181635"}
[2024-10-12 13:39:27,210][train_inner][INFO] - {"epoch": 220, "update": 219.724, "loss": "1.6", "ntokens": "238931", "nsentences": "1748.17", "wps": "239175", "ups": "1", "wpb": "238931", "bsz": "1748.2", "num_updates": "105200", "lr": "0.000400543", "gnorm": "0.555", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "40.1", "wall": "181835"}
[2024-10-12 13:41:50,782][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 105332 updates
[2024-10-12 13:41:50,787][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 13:41:56,788][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 13:41:56,810][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 220 @ 105332 updates, score None) (writing took 6.028133408166468 seconds)
[2024-10-12 13:41:56,811][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2024-10-12 13:41:56,820][train][INFO] - {"epoch": 220, "train_loss": "1.597", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "146171", "train_ups": "0.61", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "105332", "train_lr": "0.000400364", "train_gnorm": "0.575", "train_loss_scale": "0.0625", "train_train_wall": "489", "train_gb_free": "39.4", "train_wall": "181984"}
[2024-10-12 13:41:56,993][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:41:57,013][fairseq.trainer][INFO] - begin training epoch 221
[2024-10-12 13:41:57,013][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 13:47:44,477][train_inner][INFO] - {"epoch": 221, "update": 220.142, "loss": "1.598", "ntokens": "237904", "nsentences": "1752.89", "wps": "95687.9", "ups": "0.4", "wpb": "237904", "bsz": "1752.9", "num_updates": "105400", "lr": "0.000400272", "gnorm": "0.587", "loss_scale": "0.0625", "train_wall": "221", "gb_free": "39.7", "wall": "182332"}
[2024-10-12 13:50:59,378][train_inner][INFO] - {"epoch": 221, "update": 220.559, "loss": "1.601", "ntokens": "238822", "nsentences": "1809.82", "wps": "245086", "ups": "1.03", "wpb": "238822", "bsz": "1809.8", "num_updates": "105600", "lr": "0.0004", "gnorm": "0.561", "loss_scale": "0.0625", "train_wall": "191", "gb_free": "40.1", "wall": "182527"}
[2024-10-12 13:53:55,478][train_inner][INFO] - {"epoch": 221, "update": 220.977, "loss": "1.6", "ntokens": "238913", "nsentences": "1718.12", "wps": "271351", "ups": "1.14", "wpb": "238913", "bsz": "1718.1", "num_updates": "105800", "lr": "0.000399728", "gnorm": "0.557", "loss_scale": "0.0625", "train_wall": "172", "gb_free": "40.1", "wall": "182703"}
[2024-10-12 13:54:07,802][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2024-10-12 13:54:07,821][train][INFO] - {"epoch": 221, "train_loss": "1.599", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156254", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "105811", "train_lr": "0.000399713", "train_gnorm": "0.563", "train_loss_scale": "0.0625", "train_train_wall": "458", "train_gb_free": "40.2", "train_wall": "182715"}
[2024-10-12 13:54:08,099][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 13:54:08,125][fairseq.trainer][INFO] - begin training epoch 222
[2024-10-12 13:54:08,126][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:02:00,906][train_inner][INFO] - {"epoch": 222, "update": 221.395, "loss": "1.592", "ntokens": "237874", "nsentences": "1736.63", "wps": "98006.9", "ups": "0.41", "wpb": "237874", "bsz": "1736.6", "num_updates": "106000", "lr": "0.000399457", "gnorm": "0.559", "loss_scale": "0.0625", "train_wall": "186", "gb_free": "39.6", "wall": "183188"}
[2024-10-12 14:05:22,518][train_inner][INFO] - {"epoch": 222, "update": 221.812, "loss": "1.594", "ntokens": "238846", "nsentences": "1736.94", "wps": "236946", "ups": "0.99", "wpb": "238846", "bsz": "1736.9", "num_updates": "106200", "lr": "0.000399185", "gnorm": "0.574", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.3", "wall": "183390"}
[2024-10-12 14:06:45,355][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2024-10-12 14:06:45,382][train][INFO] - {"epoch": 222, "train_loss": "1.595", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150771", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "106290", "train_lr": "0.000399063", "train_gnorm": "0.565", "train_loss_scale": "0.0625", "train_train_wall": "453", "train_gb_free": "39.3", "train_wall": "183473"}
[2024-10-12 14:06:45,541][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:06:45,545][fairseq.trainer][INFO] - begin training epoch 223
[2024-10-12 14:06:45,545][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:12:01,597][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2024-10-12 14:13:31,598][train_inner][INFO] - {"epoch": 223, "update": 222.232, "loss": "1.598", "ntokens": "237910", "nsentences": "1808.03", "wps": "97290.8", "ups": "0.41", "wpb": "237910", "bsz": "1808", "num_updates": "106400", "lr": "0.000398913", "gnorm": "0.565", "loss_scale": "0.0312", "train_wall": "164", "gb_free": "39.8", "wall": "183879"}
[2024-10-12 14:16:57,904][train_inner][INFO] - {"epoch": 223, "update": 222.649, "loss": "1.588", "ntokens": "238896", "nsentences": "1729.1", "wps": "231603", "ups": "0.97", "wpb": "238896", "bsz": "1729.1", "num_updates": "106600", "lr": "0.000398641", "gnorm": "0.556", "loss_scale": "0.0312", "train_wall": "202", "gb_free": "39.6", "wall": "184085"}
[2024-10-12 14:19:47,732][fairseq_cli.train][INFO] - end of epoch 223 (average epoch stats below)
[2024-10-12 14:19:47,764][train][INFO] - {"epoch": 223, "train_loss": "1.593", "train_ntokens": "238448", "train_nsentences": "1753.74", "train_wps": "145682", "train_ups": "0.61", "train_wpb": "238448", "train_bsz": "1753.7", "train_num_updates": "106768", "train_lr": "0.000398413", "train_gnorm": "0.563", "train_loss_scale": "0.0312", "train_train_wall": "448", "train_gb_free": "39.3", "train_wall": "184255"}
[2024-10-12 14:19:47,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:19:47,972][fairseq.trainer][INFO] - begin training epoch 224
[2024-10-12 14:19:47,973][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:24:58,586][train_inner][INFO] - {"epoch": 224, "update": 223.067, "loss": "1.6", "ntokens": "237767", "nsentences": "1765.28", "wps": "98932.8", "ups": "0.42", "wpb": "237767", "bsz": "1765.3", "num_updates": "106800", "lr": "0.00039837", "gnorm": "0.571", "loss_scale": "0.0312", "train_wall": "209", "gb_free": "39.3", "wall": "184566"}
[2024-10-12 14:28:01,551][train_inner][INFO] - {"epoch": 224, "update": 223.484, "loss": "1.586", "ntokens": "238861", "nsentences": "1754.77", "wps": "261120", "ups": "1.09", "wpb": "238861", "bsz": "1754.8", "num_updates": "107000", "lr": "0.000398098", "gnorm": "0.549", "loss_scale": "0.0312", "train_wall": "179", "gb_free": "39.2", "wall": "184749"}
[2024-10-12 14:31:18,622][train_inner][INFO] - {"epoch": 224, "update": 223.902, "loss": "1.594", "ntokens": "238883", "nsentences": "1748.75", "wps": "242446", "ups": "1.01", "wpb": "238883", "bsz": "1748.8", "num_updates": "107200", "lr": "0.000397826", "gnorm": "0.551", "loss_scale": "0.0312", "train_wall": "193", "gb_free": "39.3", "wall": "184946"}
[2024-10-12 14:31:58,600][fairseq_cli.train][INFO] - end of epoch 224 (average epoch stats below)
[2024-10-12 14:31:58,639][train][INFO] - {"epoch": 224, "train_loss": "1.592", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156279", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "107247", "train_lr": "0.000397762", "train_gnorm": "0.555", "train_loss_scale": "0.0312", "train_train_wall": "458", "train_gb_free": "40.1", "train_wall": "184986"}
[2024-10-12 14:31:58,897][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:31:58,937][fairseq.trainer][INFO] - begin training epoch 225
[2024-10-12 14:31:58,937][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:39:23,430][train_inner][INFO] - {"epoch": 225, "update": 224.319, "loss": "1.594", "ntokens": "237950", "nsentences": "1802.1", "wps": "98166", "ups": "0.41", "wpb": "237950", "bsz": "1802.1", "num_updates": "107400", "lr": "0.000397554", "gnorm": "0.593", "loss_scale": "0.0312", "train_wall": "184", "gb_free": "39.8", "wall": "185431"}
[2024-10-12 14:42:36,656][train_inner][INFO] - {"epoch": 225, "update": 224.737, "loss": "1.589", "ntokens": "238804", "nsentences": "1727.16", "wps": "247186", "ups": "1.04", "wpb": "238804", "bsz": "1727.2", "num_updates": "107600", "lr": "0.000397283", "gnorm": "0.554", "loss_scale": "0.0312", "train_wall": "190", "gb_free": "39.3", "wall": "185624"}
[2024-10-12 14:44:34,043][fairseq_cli.train][INFO] - end of epoch 225 (average epoch stats below)
[2024-10-12 14:44:34,061][train][INFO] - {"epoch": 225, "train_loss": "1.593", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151198", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "107726", "train_lr": "0.000397111", "train_gnorm": "0.574", "train_loss_scale": "0.0312", "train_train_wall": "450", "train_gb_free": "39.2", "train_wall": "185741"}
[2024-10-12 14:44:34,254][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:44:34,276][fairseq.trainer][INFO] - begin training epoch 226
[2024-10-12 14:44:34,276][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 14:50:50,165][train_inner][INFO] - {"epoch": 226, "update": 225.154, "loss": "1.595", "ntokens": "237910", "nsentences": "1743.96", "wps": "96418.2", "ups": "0.41", "wpb": "237910", "bsz": "1744", "num_updates": "107800", "lr": "0.000397011", "gnorm": "0.599", "loss_scale": "0.0312", "train_wall": "198", "gb_free": "40.6", "wall": "186118"}
[2024-10-12 14:53:47,743][train_inner][INFO] - {"epoch": 226, "update": 225.572, "loss": "1.585", "ntokens": "238790", "nsentences": "1750.39", "wps": "268970", "ups": "1.13", "wpb": "238790", "bsz": "1750.4", "num_updates": "108000", "lr": "0.000396739", "gnorm": "0.571", "loss_scale": "0.0312", "train_wall": "173", "gb_free": "39.4", "wall": "186295"}
[2024-10-12 14:56:50,616][train_inner][INFO] - {"epoch": 226, "update": 225.99, "loss": "1.598", "ntokens": "238913", "nsentences": "1744.59", "wps": "261325", "ups": "1.09", "wpb": "238913", "bsz": "1744.6", "num_updates": "108200", "lr": "0.000396467", "gnorm": "0.565", "loss_scale": "0.0312", "train_wall": "179", "gb_free": "39.6", "wall": "186478"}
[2024-10-12 14:56:58,010][fairseq_cli.train][INFO] - end of epoch 226 (average epoch stats below)
[2024-10-12 14:56:58,042][train][INFO] - {"epoch": 226, "train_loss": "1.591", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153528", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "108205", "train_lr": "0.000396461", "train_gnorm": "0.579", "train_loss_scale": "0.0312", "train_train_wall": "443", "train_gb_free": "39.8", "train_wall": "186485"}
[2024-10-12 14:56:58,380][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 14:56:58,436][fairseq.trainer][INFO] - begin training epoch 227
[2024-10-12 14:56:58,436][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:04:47,729][train_inner][INFO] - {"epoch": 227, "update": 226.407, "loss": "1.587", "ntokens": "237920", "nsentences": "1773.23", "wps": "99738.2", "ups": "0.42", "wpb": "237920", "bsz": "1773.2", "num_updates": "108400", "lr": "0.000396196", "gnorm": "0.577", "loss_scale": "0.0625", "train_wall": "193", "gb_free": "39.3", "wall": "186955"}
[2024-10-12 15:08:09,862][train_inner][INFO] - {"epoch": 227, "update": 226.825, "loss": "1.591", "ntokens": "238807", "nsentences": "1740.89", "wps": "236294", "ups": "0.99", "wpb": "238807", "bsz": "1740.9", "num_updates": "108600", "lr": "0.000395924", "gnorm": "0.569", "loss_scale": "0.0625", "train_wall": "198", "gb_free": "39.6", "wall": "187157"}
[2024-10-12 15:09:13,784][fairseq_cli.train][INFO] - end of epoch 227 (average epoch stats below)
[2024-10-12 15:09:13,814][train][INFO] - {"epoch": 227, "train_loss": "1.591", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155237", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "108684", "train_lr": "0.00039581", "train_gnorm": "0.578", "train_loss_scale": "0.0625", "train_train_wall": "447", "train_gb_free": "39.6", "train_wall": "187221"}
[2024-10-12 15:09:14,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:09:14,139][fairseq.trainer][INFO] - begin training epoch 228
[2024-10-12 15:09:14,139][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:15:55,803][train_inner][INFO] - {"epoch": 228, "update": 227.242, "loss": "1.586", "ntokens": "237826", "nsentences": "1730.71", "wps": "102086", "ups": "0.43", "wpb": "237826", "bsz": "1730.7", "num_updates": "108800", "lr": "0.000395652", "gnorm": "0.573", "loss_scale": "0.0625", "train_wall": "171", "gb_free": "39.7", "wall": "187623"}
[2024-10-12 15:19:15,927][train_inner][INFO] - {"epoch": 228, "update": 227.66, "loss": "1.591", "ntokens": "238875", "nsentences": "1783.58", "wps": "238742", "ups": "1", "wpb": "238875", "bsz": "1783.6", "num_updates": "109000", "lr": "0.00039538", "gnorm": "0.57", "loss_scale": "0.0625", "train_wall": "197", "gb_free": "39.8", "wall": "187823"}
[2024-10-12 15:21:42,986][fairseq_cli.train][INFO] - end of epoch 228 (average epoch stats below)
[2024-10-12 15:21:42,996][train][INFO] - {"epoch": 228, "train_loss": "1.588", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152462", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "109163", "train_lr": "0.000395159", "train_gnorm": "0.56", "train_loss_scale": "0.0625", "train_train_wall": "436", "train_gb_free": "39.6", "train_wall": "187970"}
[2024-10-12 15:21:43,293][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:21:43,313][fairseq.trainer][INFO] - begin training epoch 229
[2024-10-12 15:21:43,313][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:27:10,083][train_inner][INFO] - {"epoch": 229, "update": 228.077, "loss": "1.592", "ntokens": "237875", "nsentences": "1727.4", "wps": "100340", "ups": "0.42", "wpb": "237875", "bsz": "1727.4", "num_updates": "109200", "lr": "0.000395109", "gnorm": "0.561", "loss_scale": "0.0625", "train_wall": "173", "gb_free": "39.6", "wall": "188297"}
[2024-10-12 15:30:20,469][train_inner][INFO] - {"epoch": 229, "update": 228.495, "loss": "1.588", "ntokens": "238922", "nsentences": "1808.59", "wps": "250996", "ups": "1.05", "wpb": "238922", "bsz": "1808.6", "num_updates": "109400", "lr": "0.000394837", "gnorm": "0.562", "loss_scale": "0.0625", "train_wall": "181", "gb_free": "39.8", "wall": "188488"}
[2024-10-12 15:33:32,468][train_inner][INFO] - {"epoch": 229, "update": 228.912, "loss": "1.59", "ntokens": "238834", "nsentences": "1719.2", "wps": "248793", "ups": "1.04", "wpb": "238834", "bsz": "1719.2", "num_updates": "109600", "lr": "0.000394565", "gnorm": "0.566", "loss_scale": "0.0625", "train_wall": "188", "gb_free": "39.7", "wall": "188680"}
[2024-10-12 15:34:08,025][fairseq_cli.train][INFO] - end of epoch 229 (average epoch stats below)
[2024-10-12 15:34:08,071][train][INFO] - {"epoch": 229, "train_loss": "1.588", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153298", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "109642", "train_lr": "0.000394508", "train_gnorm": "0.565", "train_loss_scale": "0.0625", "train_train_wall": "445", "train_gb_free": "39.3", "train_wall": "188715"}
[2024-10-12 15:34:08,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:34:08,308][fairseq.trainer][INFO] - begin training epoch 230
[2024-10-12 15:34:08,308][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:41:27,533][train_inner][INFO] - {"epoch": 230, "update": 229.33, "loss": "1.579", "ntokens": "237920", "nsentences": "1715.44", "wps": "100164", "ups": "0.42", "wpb": "237920", "bsz": "1715.4", "num_updates": "109800", "lr": "0.000394293", "gnorm": "0.569", "loss_scale": "0.0625", "train_wall": "191", "gb_free": "40.3", "wall": "189155"}
[2024-10-12 15:44:43,399][train_inner][INFO] - {"epoch": 230, "update": 229.747, "loss": "1.587", "ntokens": "238832", "nsentences": "1777.21", "wps": "243890", "ups": "1.02", "wpb": "238832", "bsz": "1777.2", "num_updates": "110000", "lr": "0.000394022", "gnorm": "0.575", "loss_scale": "0.0625", "train_wall": "191", "gb_free": "40.6", "wall": "189351"}
[2024-10-12 15:46:35,801][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 230 @ 110121 updates
[2024-10-12 15:46:35,807][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 15:46:45,349][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 15:46:45,361][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 230 @ 110121 updates, score None) (writing took 9.559274156577885 seconds)
[2024-10-12 15:46:45,366][fairseq_cli.train][INFO] - end of epoch 230 (average epoch stats below)
[2024-10-12 15:46:45,368][train][INFO] - {"epoch": 230, "train_loss": "1.586", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150826", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "110121", "train_lr": "0.000393857", "train_gnorm": "0.573", "train_loss_scale": "0.0625", "train_train_wall": "457", "train_gb_free": "39.6", "train_wall": "189473"}
[2024-10-12 15:46:45,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:46:45,531][fairseq.trainer][INFO] - begin training epoch 231
[2024-10-12 15:46:45,532][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 15:52:44,975][train_inner][INFO] - {"epoch": 231, "update": 230.165, "loss": "1.592", "ntokens": "237791", "nsentences": "1761.02", "wps": "98756.5", "ups": "0.42", "wpb": "237791", "bsz": "1761", "num_updates": "110200", "lr": "0.00039375", "gnorm": "0.566", "loss_scale": "0.0625", "train_wall": "202", "gb_free": "39.7", "wall": "189832"}
[2024-10-12 15:55:38,293][train_inner][INFO] - {"epoch": 231, "update": 230.582, "loss": "1.584", "ntokens": "238832", "nsentences": "1760.65", "wps": "275613", "ups": "1.15", "wpb": "238832", "bsz": "1760.7", "num_updates": "110400", "lr": "0.000393478", "gnorm": "0.571", "loss_scale": "0.125", "train_wall": "170", "gb_free": "39.2", "wall": "190006"}
[2024-10-12 15:58:47,767][train_inner][INFO] - {"epoch": 231, "update": 231.0, "loss": "1.598", "ntokens": "237928", "nsentences": "1739.38", "wps": "251174", "ups": "1.06", "wpb": "237928", "bsz": "1739.4", "num_updates": "110600", "lr": "0.000393207", "gnorm": "0.567", "loss_scale": "0.125", "train_wall": "178", "gb_free": "40.5", "wall": "190195"}
[2024-10-12 15:58:47,771][fairseq_cli.train][INFO] - end of epoch 231 (average epoch stats below)
[2024-10-12 15:58:47,772][train][INFO] - {"epoch": 231, "train_loss": "1.589", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "158108", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "110600", "train_lr": "0.000393207", "train_gnorm": "0.566", "train_loss_scale": "0.125", "train_train_wall": "440", "train_gb_free": "40.5", "train_wall": "190195"}
[2024-10-12 15:58:47,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 15:58:47,921][fairseq.trainer][INFO] - begin training epoch 232
[2024-10-12 15:58:47,922][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:06:47,840][train_inner][INFO] - {"epoch": 232, "update": 231.418, "loss": "1.574", "ntokens": "238973", "nsentences": "1721.86", "wps": "99558.2", "ups": "0.42", "wpb": "238972", "bsz": "1721.9", "num_updates": "110800", "lr": "0.000392935", "gnorm": "0.568", "loss_scale": "0.125", "train_wall": "191", "gb_free": "39.2", "wall": "190675"}
[2024-10-12 16:10:04,590][train_inner][INFO] - {"epoch": 232, "update": 231.835, "loss": "1.587", "ntokens": "238773", "nsentences": "1799.03", "wps": "242730", "ups": "1.02", "wpb": "238773", "bsz": "1799", "num_updates": "111000", "lr": "0.000392663", "gnorm": "0.559", "loss_scale": "0.125", "train_wall": "193", "gb_free": "39.6", "wall": "190872"}
[2024-10-12 16:11:14,714][fairseq_cli.train][INFO] - end of epoch 232 (average epoch stats below)
[2024-10-12 16:11:14,757][train][INFO] - {"epoch": 232, "train_loss": "1.582", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152905", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "111079", "train_lr": "0.000392556", "train_gnorm": "0.563", "train_loss_scale": "0.125", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "190942"}
[2024-10-12 16:11:15,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:11:15,074][fairseq.trainer][INFO] - begin training epoch 233
[2024-10-12 16:11:15,075][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:18:00,477][train_inner][INFO] - {"epoch": 233, "update": 232.253, "loss": "1.582", "ntokens": "237894", "nsentences": "1735.13", "wps": "99980.9", "ups": "0.42", "wpb": "237894", "bsz": "1735.1", "num_updates": "111200", "lr": "0.000392391", "gnorm": "0.548", "loss_scale": "0.125", "train_wall": "149", "gb_free": "39.9", "wall": "191348"}
[2024-10-12 16:21:11,963][train_inner][INFO] - {"epoch": 233, "update": 232.67, "loss": "1.581", "ntokens": "238841", "nsentences": "1752.28", "wps": "249474", "ups": "1.04", "wpb": "238841", "bsz": "1752.3", "num_updates": "111400", "lr": "0.00039212", "gnorm": "0.545", "loss_scale": "0.125", "train_wall": "155", "gb_free": "40.1", "wall": "191539"}
[2024-10-12 16:23:23,942][fairseq_cli.train][INFO] - end of epoch 233 (average epoch stats below)
[2024-10-12 16:23:23,972][train][INFO] - {"epoch": 233, "train_loss": "1.584", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "156631", "train_ups": "0.66", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "111558", "train_lr": "0.000391905", "train_gnorm": "0.543", "train_loss_scale": "0.125", "train_train_wall": "364", "train_gb_free": "39.6", "train_wall": "191671"}
[2024-10-12 16:23:24,217][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:23:24,240][fairseq.trainer][INFO] - begin training epoch 234
[2024-10-12 16:23:24,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:28:59,540][train_inner][INFO] - {"epoch": 234, "update": 233.088, "loss": "1.589", "ntokens": "237870", "nsentences": "1757.52", "wps": "101749", "ups": "0.43", "wpb": "237870", "bsz": "1757.5", "num_updates": "111600", "lr": "0.000391848", "gnorm": "0.558", "loss_scale": "0.125", "train_wall": "174", "gb_free": "39.1", "wall": "192007"}
[2024-10-12 16:32:12,329][train_inner][INFO] - {"epoch": 234, "update": 233.505, "loss": "1.574", "ntokens": "238897", "nsentences": "1731.92", "wps": "247840", "ups": "1.04", "wpb": "238897", "bsz": "1731.9", "num_updates": "111800", "lr": "0.000391576", "gnorm": "0.554", "loss_scale": "0.125", "train_wall": "188", "gb_free": "39.6", "wall": "192200"}
[2024-10-12 16:35:17,305][train_inner][INFO] - {"epoch": 234, "update": 233.923, "loss": "1.588", "ntokens": "238832", "nsentences": "1787.33", "wps": "258251", "ups": "1.08", "wpb": "238832", "bsz": "1787.3", "num_updates": "112000", "lr": "0.000391304", "gnorm": "0.565", "loss_scale": "0.125", "train_wall": "179", "gb_free": "40.3", "wall": "192385"}
[2024-10-12 16:35:45,411][fairseq_cli.train][INFO] - end of epoch 234 (average epoch stats below)
[2024-10-12 16:35:45,431][train][INFO] - {"epoch": 234, "train_loss": "1.582", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154046", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "112037", "train_lr": "0.000391254", "train_gnorm": "0.571", "train_loss_scale": "0.125", "train_train_wall": "440", "train_gb_free": "39.6", "train_wall": "192413"}
[2024-10-12 16:35:45,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:35:45,707][fairseq.trainer][INFO] - begin training epoch 235
[2024-10-12 16:35:45,708][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:43:14,590][train_inner][INFO] - {"epoch": 235, "update": 234.34, "loss": "1.581", "ntokens": "237802", "nsentences": "1758.8", "wps": "99649.3", "ups": "0.42", "wpb": "237802", "bsz": "1758.8", "num_updates": "112200", "lr": "0.000391033", "gnorm": "0.593", "loss_scale": "0.125", "train_wall": "188", "gb_free": "40.3", "wall": "192862"}
[2024-10-12 16:46:26,725][train_inner][INFO] - {"epoch": 235, "update": 234.758, "loss": "1.584", "ntokens": "238886", "nsentences": "1760.37", "wps": "248677", "ups": "1.04", "wpb": "238886", "bsz": "1760.4", "num_updates": "112400", "lr": "0.000390761", "gnorm": "0.563", "loss_scale": "0.125", "train_wall": "182", "gb_free": "40.3", "wall": "193054"}
[2024-10-12 16:48:30,833][fairseq_cli.train][INFO] - end of epoch 235 (average epoch stats below)
[2024-10-12 16:48:30,845][train][INFO] - {"epoch": 235, "train_loss": "1.583", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "149225", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "112516", "train_lr": "0.000390603", "train_gnorm": "0.571", "train_loss_scale": "0.25", "train_train_wall": "464", "train_gb_free": "39.8", "train_wall": "193178"}
[2024-10-12 16:48:31,016][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 16:48:31,034][fairseq.trainer][INFO] - begin training epoch 236
[2024-10-12 16:48:31,035][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 16:54:39,618][train_inner][INFO] - {"epoch": 236, "update": 235.175, "loss": "1.578", "ntokens": "237911", "nsentences": "1687.74", "wps": "96538.7", "ups": "0.41", "wpb": "237911", "bsz": "1687.7", "num_updates": "112600", "lr": "0.000390489", "gnorm": "0.576", "loss_scale": "0.25", "train_wall": "211", "gb_free": "40.1", "wall": "193547"}
[2024-10-12 16:57:47,038][train_inner][INFO] - {"epoch": 236, "update": 235.593, "loss": "1.587", "ntokens": "238946", "nsentences": "1836.32", "wps": "254996", "ups": "1.07", "wpb": "238946", "bsz": "1836.3", "num_updates": "112800", "lr": "0.000390217", "gnorm": "0.559", "loss_scale": "0.25", "train_wall": "151", "gb_free": "40.6", "wall": "193734"}
[2024-10-12 17:00:48,966][fairseq_cli.train][INFO] - end of epoch 236 (average epoch stats below)
[2024-10-12 17:00:48,977][train][INFO] - {"epoch": 236, "train_loss": "1.581", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154739", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "112995", "train_lr": "0.000389952", "train_gnorm": "0.566", "train_loss_scale": "0.25", "train_train_wall": "388", "train_gb_free": "39.3", "train_wall": "193916"}
[2024-10-12 17:00:49,186][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:00:49,202][fairseq.trainer][INFO] - begin training epoch 237
[2024-10-12 17:00:49,203][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:05:59,449][train_inner][INFO] - {"epoch": 237, "update": 236.01, "loss": "1.581", "ntokens": "237772", "nsentences": "1716.93", "wps": "96576.9", "ups": "0.41", "wpb": "237772", "bsz": "1716.9", "num_updates": "113000", "lr": "0.000389946", "gnorm": "0.566", "loss_scale": "0.25", "train_wall": "182", "gb_free": "39.8", "wall": "194227"}
[2024-10-12 17:08:42,917][train_inner][INFO] - {"epoch": 237, "update": 236.428, "loss": "1.574", "ntokens": "238893", "nsentences": "1742.49", "wps": "292296", "ups": "1.22", "wpb": "238893", "bsz": "1742.5", "num_updates": "113200", "lr": "0.000389674", "gnorm": "0.555", "loss_scale": "0.25", "train_wall": "160", "gb_free": "40.1", "wall": "194390"}
[2024-10-12 17:12:03,121][train_inner][INFO] - {"epoch": 237, "update": 236.846, "loss": "1.584", "ntokens": "238852", "nsentences": "1762.5", "wps": "238624", "ups": "1", "wpb": "238852", "bsz": "1762.5", "num_updates": "113400", "lr": "0.000389402", "gnorm": "0.562", "loss_scale": "0.25", "train_wall": "197", "gb_free": "39.8", "wall": "194591"}
[2024-10-12 17:13:36,637][fairseq_cli.train][INFO] - end of epoch 237 (average epoch stats below)
[2024-10-12 17:13:36,649][train][INFO] - {"epoch": 237, "train_loss": "1.58", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "148787", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "113474", "train_lr": "0.000389302", "train_gnorm": "0.561", "train_loss_scale": "0.25", "train_train_wall": "483", "train_gb_free": "40.1", "train_wall": "194684"}
[2024-10-12 17:13:36,793][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:13:36,812][fairseq.trainer][INFO] - begin training epoch 238
[2024-10-12 17:13:36,813][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:20:05,384][train_inner][INFO] - {"epoch": 238, "update": 237.263, "loss": "1.573", "ntokens": "237860", "nsentences": "1728.2", "wps": "98646.9", "ups": "0.41", "wpb": "237860", "bsz": "1728.2", "num_updates": "113600", "lr": "0.00038913", "gnorm": "0.551", "loss_scale": "0.25", "train_wall": "209", "gb_free": "39.6", "wall": "195073"}
[2024-10-12 17:23:18,577][train_inner][INFO] - {"epoch": 238, "update": 237.681, "loss": "1.578", "ntokens": "238826", "nsentences": "1758.3", "wps": "247252", "ups": "1.04", "wpb": "238826", "bsz": "1758.3", "num_updates": "113800", "lr": "0.000388859", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "189", "gb_free": "40.1", "wall": "195266"}
[2024-10-12 17:26:28,451][fairseq_cli.train][INFO] - end of epoch 238 (average epoch stats below)
[2024-10-12 17:26:28,490][train][INFO] - {"epoch": 238, "train_loss": "1.577", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "147983", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "113953", "train_lr": "0.000388651", "train_gnorm": "0.553", "train_loss_scale": "0.25", "train_train_wall": "493", "train_gb_free": "39.3", "train_wall": "195456"}
[2024-10-12 17:26:28,694][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:26:28,712][fairseq.trainer][INFO] - begin training epoch 239
[2024-10-12 17:26:28,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:31:50,532][train_inner][INFO] - {"epoch": 239, "update": 238.098, "loss": "1.583", "ntokens": "237915", "nsentences": "1774.6", "wps": "92944.8", "ups": "0.39", "wpb": "237915", "bsz": "1774.6", "num_updates": "114000", "lr": "0.000388587", "gnorm": "0.563", "loss_scale": "0.25", "train_wall": "240", "gb_free": "40.2", "wall": "195778"}
[2024-10-12 17:35:07,242][train_inner][INFO] - {"epoch": 239, "update": 238.516, "loss": "1.572", "ntokens": "238916", "nsentences": "1741.09", "wps": "242923", "ups": "1.02", "wpb": "238916", "bsz": "1741.1", "num_updates": "114200", "lr": "0.000388315", "gnorm": "0.554", "loss_scale": "0.25", "train_wall": "193", "gb_free": "39.9", "wall": "195975"}
[2024-10-12 17:37:42,551][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-12 17:38:38,238][train_inner][INFO] - {"epoch": 239, "update": 238.935, "loss": "1.582", "ntokens": "238823", "nsentences": "1781.14", "wps": "226381", "ups": "0.95", "wpb": "238823", "bsz": "1781.1", "num_updates": "114400", "lr": "0.000388043", "gnorm": "0.543", "loss_scale": "0.125", "train_wall": "207", "gb_free": "40.1", "wall": "196186"}
[2024-10-12 17:39:24,081][fairseq_cli.train][INFO] - end of epoch 239 (average epoch stats below)
[2024-10-12 17:39:24,109][train][INFO] - {"epoch": 239, "train_loss": "1.576", "train_ntokens": "238447", "train_nsentences": "1753.03", "train_wps": "146953", "train_ups": "0.62", "train_wpb": "238447", "train_bsz": "1753", "train_num_updates": "114431", "train_lr": "0.000388001", "train_gnorm": "0.556", "train_loss_scale": "0.125", "train_train_wall": "499", "train_gb_free": "39.6", "train_wall": "196231"}
[2024-10-12 17:39:24,391][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:39:24,401][fairseq.trainer][INFO] - begin training epoch 240
[2024-10-12 17:39:24,401][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:46:43,724][train_inner][INFO] - {"epoch": 240, "update": 239.353, "loss": "1.57", "ntokens": "237861", "nsentences": "1751.63", "wps": "97989.9", "ups": "0.41", "wpb": "237861", "bsz": "1751.6", "num_updates": "114600", "lr": "0.000387772", "gnorm": "0.596", "loss_scale": "0.125", "train_wall": "212", "gb_free": "39.4", "wall": "196671"}
[2024-10-12 17:50:24,354][train_inner][INFO] - {"epoch": 240, "update": 239.77, "loss": "1.577", "ntokens": "238867", "nsentences": "1775.76", "wps": "216545", "ups": "0.91", "wpb": "238867", "bsz": "1775.8", "num_updates": "114800", "lr": "0.0003875", "gnorm": "0.564", "loss_scale": "0.125", "train_wall": "217", "gb_free": "39.6", "wall": "196892"}
[2024-10-12 17:52:18,064][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 240 @ 114910 updates
[2024-10-12 17:52:18,065][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 17:52:22,775][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 17:52:22,779][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 240 @ 114910 updates, score None) (writing took 4.715135959908366 seconds)
[2024-10-12 17:52:22,806][fairseq_cli.train][INFO] - end of epoch 240 (average epoch stats below)
[2024-10-12 17:52:22,809][train][INFO] - {"epoch": 240, "train_loss": "1.576", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "146678", "train_ups": "0.62", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "114910", "train_lr": "0.000387351", "train_gnorm": "0.578", "train_loss_scale": "0.125", "train_train_wall": "495", "train_gb_free": "41", "train_wall": "197010"}
[2024-10-12 17:52:22,920][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 17:52:22,942][fairseq.trainer][INFO] - begin training epoch 241
[2024-10-12 17:52:22,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 17:58:26,601][train_inner][INFO] - {"epoch": 241, "update": 240.188, "loss": "1.579", "ntokens": "237897", "nsentences": "1763.01", "wps": "98663.6", "ups": "0.41", "wpb": "237897", "bsz": "1763", "num_updates": "115000", "lr": "0.000387228", "gnorm": "0.558", "loss_scale": "0.125", "train_wall": "212", "gb_free": "40.1", "wall": "197374"}
[2024-10-12 18:01:36,030][train_inner][INFO] - {"epoch": 241, "update": 240.605, "loss": "1.565", "ntokens": "238827", "nsentences": "1703.54", "wps": "252179", "ups": "1.06", "wpb": "238827", "bsz": "1703.5", "num_updates": "115200", "lr": "0.000386957", "gnorm": "0.552", "loss_scale": "0.125", "train_wall": "185", "gb_free": "39.4", "wall": "197563"}
[2024-10-12 18:04:36,634][fairseq_cli.train][INFO] - end of epoch 241 (average epoch stats below)
[2024-10-12 18:04:36,676][train][INFO] - {"epoch": 241, "train_loss": "1.575", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155638", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "115389", "train_lr": "0.0003867", "train_gnorm": "0.558", "train_loss_scale": "0.125", "train_train_wall": "461", "train_gb_free": "39.2", "train_wall": "197744"}
[2024-10-12 18:04:36,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:04:37,023][fairseq.trainer][INFO] - begin training epoch 242
[2024-10-12 18:04:37,024][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:09:46,840][train_inner][INFO] - {"epoch": 242, "update": 241.023, "loss": "1.585", "ntokens": "237871", "nsentences": "1761.88", "wps": "96931.8", "ups": "0.41", "wpb": "237871", "bsz": "1761.9", "num_updates": "115400", "lr": "0.000386685", "gnorm": "0.572", "loss_scale": "0.125", "train_wall": "197", "gb_free": "40.3", "wall": "198054"}
[2024-10-12 18:12:42,549][train_inner][INFO] - {"epoch": 242, "update": 241.441, "loss": "1.575", "ntokens": "238879", "nsentences": "1786.01", "wps": "271921", "ups": "1.14", "wpb": "238879", "bsz": "1786", "num_updates": "115600", "lr": "0.000386413", "gnorm": "0.567", "loss_scale": "0.125", "train_wall": "172", "gb_free": "39.6", "wall": "198230"}
[2024-10-12 18:16:01,449][train_inner][INFO] - {"epoch": 242, "update": 241.858, "loss": "1.572", "ntokens": "238879", "nsentences": "1727.34", "wps": "240210", "ups": "1.01", "wpb": "238879", "bsz": "1727.3", "num_updates": "115800", "lr": "0.000386141", "gnorm": "0.563", "loss_scale": "0.125", "train_wall": "195", "gb_free": "39.3", "wall": "198429"}
[2024-10-12 18:16:13,836][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-12 18:17:01,829][fairseq_cli.train][INFO] - end of epoch 242 (average epoch stats below)
[2024-10-12 18:17:01,855][train][INFO] - {"epoch": 242, "train_loss": "1.575", "train_ntokens": "238448", "train_nsentences": "1755.22", "train_wps": "152962", "train_ups": "0.64", "train_wpb": "238448", "train_bsz": "1755.2", "train_num_updates": "115867", "train_lr": "0.00038605", "train_gnorm": "0.568", "train_loss_scale": "0.0625", "train_train_wall": "447", "train_gb_free": "39.3", "train_wall": "198489"}
[2024-10-12 18:17:02,178][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:17:02,241][fairseq.trainer][INFO] - begin training epoch 243
[2024-10-12 18:17:02,242][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:23:55,109][train_inner][INFO] - {"epoch": 243, "update": 242.278, "loss": "1.565", "ntokens": "237826", "nsentences": "1714.85", "wps": "100422", "ups": "0.42", "wpb": "237826", "bsz": "1714.8", "num_updates": "116000", "lr": "0.00038587", "gnorm": "0.574", "loss_scale": "0.0625", "train_wall": "186", "gb_free": "39.6", "wall": "198902"}
[2024-10-12 18:27:15,310][train_inner][INFO] - {"epoch": 243, "update": 242.695, "loss": "1.579", "ntokens": "238802", "nsentences": "1815.98", "wps": "238578", "ups": "1", "wpb": "238802", "bsz": "1816", "num_updates": "116200", "lr": "0.000385598", "gnorm": "0.537", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "40.3", "wall": "199103"}
[2024-10-12 18:29:29,593][fairseq_cli.train][INFO] - end of epoch 243 (average epoch stats below)
[2024-10-12 18:29:29,630][train][INFO] - {"epoch": 243, "train_loss": "1.572", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152749", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "116346", "train_lr": "0.000385399", "train_gnorm": "0.55", "train_loss_scale": "0.0625", "train_train_wall": "455", "train_gb_free": "40.2", "train_wall": "199237"}
[2024-10-12 18:29:29,861][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:29:29,897][fairseq.trainer][INFO] - begin training epoch 244
[2024-10-12 18:29:29,898][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:35:18,799][train_inner][INFO] - {"epoch": 244, "update": 243.113, "loss": "1.574", "ntokens": "237969", "nsentences": "1731.45", "wps": "98444.6", "ups": "0.41", "wpb": "237969", "bsz": "1731.5", "num_updates": "116400", "lr": "0.000385326", "gnorm": "0.551", "loss_scale": "0.0625", "train_wall": "204", "gb_free": "39.4", "wall": "199586"}
[2024-10-12 18:38:08,535][train_inner][INFO] - {"epoch": 244, "update": 243.53, "loss": "1.564", "ntokens": "238922", "nsentences": "1715.07", "wps": "281542", "ups": "1.18", "wpb": "238922", "bsz": "1715.1", "num_updates": "116600", "lr": "0.000385054", "gnorm": "0.558", "loss_scale": "0.0625", "train_wall": "166", "gb_free": "39.3", "wall": "199756"}
[2024-10-12 18:41:20,351][train_inner][INFO] - {"epoch": 244, "update": 243.948, "loss": "1.581", "ntokens": "238835", "nsentences": "1775.81", "wps": "249038", "ups": "1.04", "wpb": "238835", "bsz": "1775.8", "num_updates": "116800", "lr": "0.000384783", "gnorm": "0.563", "loss_scale": "0.0625", "train_wall": "188", "gb_free": "40.1", "wall": "199948"}
[2024-10-12 18:41:47,281][fairseq_cli.train][INFO] - end of epoch 244 (average epoch stats below)
[2024-10-12 18:41:47,300][train][INFO] - {"epoch": 244, "train_loss": "1.573", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154840", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "116825", "train_lr": "0.000384749", "train_gnorm": "0.563", "train_loss_scale": "0.0625", "train_train_wall": "453", "train_gb_free": "39.6", "train_wall": "199975"}
[2024-10-12 18:41:47,519][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:41:47,533][fairseq.trainer][INFO] - begin training epoch 245
[2024-10-12 18:41:47,534][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 18:49:21,725][train_inner][INFO] - {"epoch": 245, "update": 244.365, "loss": "1.565", "ntokens": "237903", "nsentences": "1751.88", "wps": "98844.8", "ups": "0.42", "wpb": "237903", "bsz": "1751.9", "num_updates": "117000", "lr": "0.000384511", "gnorm": "0.541", "loss_scale": "0.0625", "train_wall": "171", "gb_free": "39.7", "wall": "200429"}
[2024-10-12 18:52:47,535][train_inner][INFO] - {"epoch": 245, "update": 244.783, "loss": "1.571", "ntokens": "238823", "nsentences": "1747.19", "wps": "232125", "ups": "0.97", "wpb": "238823", "bsz": "1747.2", "num_updates": "117200", "lr": "0.000384239", "gnorm": "0.574", "loss_scale": "0.0625", "train_wall": "109", "gb_free": "39.6", "wall": "200635"}
[2024-10-12 18:54:20,970][fairseq_cli.train][INFO] - end of epoch 245 (average epoch stats below)
[2024-10-12 18:54:20,992][train][INFO] - {"epoch": 245, "train_loss": "1.569", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "151547", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "117304", "train_lr": "0.000384098", "train_gnorm": "0.559", "train_loss_scale": "0.0625", "train_train_wall": "339", "train_gb_free": "39.6", "train_wall": "200728"}
[2024-10-12 18:54:21,239][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 18:54:21,269][fairseq.trainer][INFO] - begin training epoch 246
[2024-10-12 18:54:21,270][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:01:00,237][train_inner][INFO] - {"epoch": 246, "update": 245.2, "loss": "1.57", "ntokens": "237796", "nsentences": "1811.65", "wps": "96529.3", "ups": "0.41", "wpb": "237796", "bsz": "1811.7", "num_updates": "117400", "lr": "0.000383967", "gnorm": "0.574", "loss_scale": "0.0625", "train_wall": "203", "gb_free": "39.5", "wall": "201128"}
[2024-10-12 19:04:01,184][train_inner][INFO] - {"epoch": 246, "update": 245.618, "loss": "1.57", "ntokens": "238925", "nsentences": "1746.78", "wps": "264091", "ups": "1.11", "wpb": "238925", "bsz": "1746.8", "num_updates": "117600", "lr": "0.000383696", "gnorm": "0.566", "loss_scale": "0.0625", "train_wall": "168", "gb_free": "41", "wall": "201309"}
[2024-10-12 19:06:46,100][fairseq_cli.train][INFO] - end of epoch 246 (average epoch stats below)
[2024-10-12 19:06:46,140][train][INFO] - {"epoch": 246, "train_loss": "1.569", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "153284", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "117783", "train_lr": "0.000383447", "train_gnorm": "0.57", "train_loss_scale": "0.0625", "train_train_wall": "439", "train_gb_free": "39.6", "train_wall": "201474"}
[2024-10-12 19:06:46,411][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:06:46,431][fairseq.trainer][INFO] - begin training epoch 247
[2024-10-12 19:06:46,437][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:11:59,189][train_inner][INFO] - {"epoch": 247, "update": 246.035, "loss": "1.571", "ntokens": "237839", "nsentences": "1731.88", "wps": "99515", "ups": "0.42", "wpb": "237839", "bsz": "1731.9", "num_updates": "117800", "lr": "0.000383424", "gnorm": "0.57", "loss_scale": "0.0625", "train_wall": "177", "gb_free": "39.6", "wall": "201787"}
[2024-10-12 19:15:03,581][train_inner][INFO] - {"epoch": 247, "update": 246.453, "loss": "1.561", "ntokens": "238928", "nsentences": "1755.16", "wps": "259192", "ups": "1.08", "wpb": "238928", "bsz": "1755.2", "num_updates": "118000", "lr": "0.000383152", "gnorm": "0.576", "loss_scale": "0.125", "train_wall": "179", "gb_free": "39.6", "wall": "201971"}
[2024-10-12 19:18:26,745][train_inner][INFO] - {"epoch": 247, "update": 246.871, "loss": "1.568", "ntokens": "238898", "nsentences": "1759.89", "wps": "235190", "ups": "0.98", "wpb": "238898", "bsz": "1759.9", "num_updates": "118200", "lr": "0.00038288", "gnorm": "0.56", "loss_scale": "0.125", "train_wall": "199", "gb_free": "39.6", "wall": "202174"}
[2024-10-12 19:18:51,760][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2024-10-12 19:19:21,800][fairseq_cli.train][INFO] - end of epoch 247 (average epoch stats below)
[2024-10-12 19:19:21,814][train][INFO] - {"epoch": 247, "train_loss": "1.565", "train_ntokens": "238448", "train_nsentences": "1755.03", "train_wps": "150832", "train_ups": "0.63", "train_wpb": "238448", "train_bsz": "1755", "train_num_updates": "118261", "train_lr": "0.000382798", "train_gnorm": "0.57", "train_loss_scale": "0.0625", "train_train_wall": "456", "train_gb_free": "40.1", "train_wall": "202229"}
[2024-10-12 19:19:22,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:19:22,200][fairseq.trainer][INFO] - begin training epoch 248
[2024-10-12 19:19:22,201][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:26:23,954][train_inner][INFO] - {"epoch": 248, "update": 247.29, "loss": "1.566", "ntokens": "237720", "nsentences": "1770.32", "wps": "99630.7", "ups": "0.42", "wpb": "237720", "bsz": "1770.3", "num_updates": "118400", "lr": "0.000382609", "gnorm": "0.597", "loss_scale": "0.0625", "train_wall": "193", "gb_free": "39", "wall": "202651"}
[2024-10-12 19:29:40,469][train_inner][INFO] - {"epoch": 248, "update": 247.708, "loss": "1.566", "ntokens": "238922", "nsentences": "1783.67", "wps": "243172", "ups": "1.02", "wpb": "238922", "bsz": "1783.7", "num_updates": "118600", "lr": "0.000382337", "gnorm": "0.581", "loss_scale": "0.0625", "train_wall": "192", "gb_free": "39.6", "wall": "202848"}
[2024-10-12 19:31:35,685][fairseq_cli.train][INFO] - end of epoch 248 (average epoch stats below)
[2024-10-12 19:31:35,708][train][INFO] - {"epoch": 248, "train_loss": "1.566", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "155633", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "118740", "train_lr": "0.000382147", "train_gnorm": "0.582", "train_loss_scale": "0.0625", "train_train_wall": "444", "train_gb_free": "39.8", "train_wall": "202963"}
[2024-10-12 19:31:35,958][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:31:35,981][fairseq.trainer][INFO] - begin training epoch 249
[2024-10-12 19:31:35,981][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:37:26,698][train_inner][INFO] - {"epoch": 249, "update": 248.125, "loss": "1.565", "ntokens": "237897", "nsentences": "1703.96", "wps": "102054", "ups": "0.43", "wpb": "237897", "bsz": "1704", "num_updates": "118800", "lr": "0.000382065", "gnorm": "0.567", "loss_scale": "0.0625", "train_wall": "180", "gb_free": "40.6", "wall": "203314"}
[2024-10-12 19:40:33,817][train_inner][INFO] - {"epoch": 249, "update": 248.543, "loss": "1.565", "ntokens": "238804", "nsentences": "1736.65", "wps": "255283", "ups": "1.07", "wpb": "238804", "bsz": "1736.7", "num_updates": "119000", "lr": "0.000381793", "gnorm": "0.647", "loss_scale": "0.0625", "train_wall": "183", "gb_free": "40.1", "wall": "203501"}
[2024-10-12 19:43:32,213][train_inner][INFO] - {"epoch": 249, "update": 248.96, "loss": "1.57", "ntokens": "238931", "nsentences": "1759.73", "wps": "267883", "ups": "1.12", "wpb": "238931", "bsz": "1759.7", "num_updates": "119200", "lr": "0.000381522", "gnorm": "0.558", "loss_scale": "0.0625", "train_wall": "174", "gb_free": "39.8", "wall": "203680"}
[2024-10-12 19:44:14,129][fairseq_cli.train][INFO] - end of epoch 249 (average epoch stats below)
[2024-10-12 19:44:14,131][train][INFO] - {"epoch": 249, "train_loss": "1.568", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "150601", "train_ups": "0.63", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "119219", "train_lr": "0.000381496", "train_gnorm": "0.6", "train_loss_scale": "0.0625", "train_train_wall": "466", "train_gb_free": "40.3", "train_wall": "203722"}
[2024-10-12 19:44:14,246][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:44:14,250][fairseq.trainer][INFO] - begin training epoch 250
[2024-10-12 19:44:14,250][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 19:51:47,734][train_inner][INFO] - {"epoch": 250, "update": 249.378, "loss": "1.563", "ntokens": "237852", "nsentences": "1745.39", "wps": "96001.9", "ups": "0.4", "wpb": "237852", "bsz": "1745.4", "num_updates": "119400", "lr": "0.00038125", "gnorm": "0.579", "loss_scale": "0.0625", "train_wall": "223", "gb_free": "39.6", "wall": "204175"}
[2024-10-12 19:54:59,140][train_inner][INFO] - {"epoch": 250, "update": 249.795, "loss": "1.564", "ntokens": "238835", "nsentences": "1747.11", "wps": "249568", "ups": "1.04", "wpb": "238835", "bsz": "1747.1", "num_updates": "119600", "lr": "0.000380978", "gnorm": "0.571", "loss_scale": "0.0625", "train_wall": "187", "gb_free": "39.6", "wall": "204367"}
[2024-10-12 19:56:24,281][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 250 @ 119698 updates
[2024-10-12 19:56:24,287][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 19:56:35,046][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt
[2024-10-12 19:56:35,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_channel_400_0p5/ckpt/checkpoint_last.pt (epoch 250 @ 119698 updates, score None) (writing took 10.943479899317026 seconds)
[2024-10-12 19:56:35,246][fairseq_cli.train][INFO] - end of epoch 250 (average epoch stats below)
[2024-10-12 19:56:35,258][train][INFO] - {"epoch": 250, "train_loss": "1.565", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "154116", "train_ups": "0.65", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "119698", "train_lr": "0.000380845", "train_gnorm": "0.575", "train_loss_scale": "0.0625", "train_train_wall": "452", "train_gb_free": "39.6", "train_wall": "204463"}
[2024-10-12 19:56:35,402][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 19:56:35,408][fairseq.trainer][INFO] - begin training epoch 251
[2024-10-12 19:56:35,408][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:03:07,264][train_inner][INFO] - {"epoch": 251, "update": 250.213, "loss": "1.569", "ntokens": "237814", "nsentences": "1804.4", "wps": "97441.1", "ups": "0.41", "wpb": "237814", "bsz": "1804.4", "num_updates": "119800", "lr": "0.000380707", "gnorm": "0.566", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "40.1", "wall": "204855"}
[2024-10-12 20:06:17,972][train_inner][INFO] - {"epoch": 251, "update": 250.63, "loss": "1.565", "ntokens": "238915", "nsentences": "1742.78", "wps": "250580", "ups": "1.05", "wpb": "238916", "bsz": "1742.8", "num_updates": "120000", "lr": "0.000380435", "gnorm": "0.598", "loss_scale": "0.0625", "train_wall": "186", "gb_free": "39.3", "wall": "205045"}
[2024-10-12 20:09:05,578][fairseq_cli.train][INFO] - end of epoch 251 (average epoch stats below)
[2024-10-12 20:09:05,594][train][INFO] - {"epoch": 251, "train_loss": "1.563", "train_ntokens": "238449", "train_nsentences": "1753.71", "train_wps": "152223", "train_ups": "0.64", "train_wpb": "238449", "train_bsz": "1753.7", "train_num_updates": "120177", "train_lr": "0.000380194", "train_gnorm": "0.575", "train_loss_scale": "0.0625", "train_train_wall": "462", "train_gb_free": "39.6", "train_wall": "205213"}
[2024-10-12 20:09:05,718][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-12 20:09:05,722][fairseq.trainer][INFO] - begin training epoch 252
[2024-10-12 20:09:05,722][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-12 20:14:38,301][train_inner][INFO] - {"epoch": 252, "update": 251.048, "loss": "1.565", "ntokens": "237812", "nsentences": "1743.06", "wps": "95066.3", "ups": "0.4", "wpb": "237812", "bsz": "1743.1", "num_updates": "120200", "lr": "0.000380163", "gnorm": "0.566", "loss_scale": "0.0625", "train_wall": "196", "gb_free": "39.7", "wall": "205546"}
[2024-10-12 20:17:44,257][train_inner][INFO] - {"epoch": 252, "update": 251.466, "loss": "1.557", "ntokens": "238935", "nsentences": "1781.67", "wps": "257000", "ups": "1.08", "wpb": "238935", "bsz": "1781.7", "num_updates": "120400", "lr": "0.000379891", "gnorm": "0.544", "loss_scale": "0.125", "train_wall": "183", "gb_free": "39.6", "wall": "205732"}
