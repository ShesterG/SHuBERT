[2024-10-09 09:26:18,719][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:17853', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 09:26:23,435][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11475', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 09:26:25,702][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 09:26:25,709][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 09:26:25,709][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 09:26:25,709][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 09:26:25,710][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 09:26:25,710][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 09:26:26,646][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:26:27,997][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 09:26:28,008][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 09:26:28,008][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 09:26:28,008][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 09:26:28,009][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 09:26:28,015][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 09:26:28,627][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:26:33,316][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19231', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 09:26:34,083][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:14608', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 09:26:35,810][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 09:26:35,811][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 09:26:35,812][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 09:26:35,812][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 09:26:35,812][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 09:26:35,815][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 09:26:36,103][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:26:37,111][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 09:26:37,113][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 09:26:37,113][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 09:26:37,113][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 09:26:37,114][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 09:26:37,117][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 09:26:37,557][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:27:51,728][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:27:51,734][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:27:51,734][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 09:27:51,737][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 09:27:51,738][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 09:28:34,837][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1201 @ 57574 updates)
[2024-10-09 09:28:34,844][fairseq.trainer][INFO] - loading train data for epoch 1201
[2024-10-09 09:28:35,601][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:28:42,454][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:28:42,458][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 09:28:42,458][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 09:28:42,459][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 09:28:43,998][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:28:44,001][fairseq.trainer][INFO] - begin training epoch 1201
[2024-10-09 09:28:44,002][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:29:09,733][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1201 @ 57574 updates)
[2024-10-09 09:29:09,877][fairseq.trainer][INFO] - loading train data for epoch 1201
[2024-10-09 09:29:10,966][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:29:19,490][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:29:19,493][fairseq.trainer][INFO] - begin training epoch 1201
[2024-10-09 09:29:19,494][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:29:53,465][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:29:53,465][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,465][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:29:53,466][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:29:53,466][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 09:29:53,466][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 09:29:53,467][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 09:30:23,260][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 09:30:23,261][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 09:30:23,261][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 09:30:23,261][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 09:30:23,262][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 09:30:34,981][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1201 @ 57574 updates)
[2024-10-09 09:30:34,984][fairseq.trainer][INFO] - loading train data for epoch 1201
[2024-10-09 09:30:35,577][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:30:43,371][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:30:43,385][fairseq.trainer][INFO] - begin training epoch 1201
[2024-10-09 09:30:43,387][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:30:50,210][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1201 @ 57574 updates)
[2024-10-09 09:30:50,212][fairseq.trainer][INFO] - loading train data for epoch 1201
[2024-10-09 09:30:51,114][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 09:31:02,966][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:31:02,982][fairseq.trainer][INFO] - begin training epoch 1201
[2024-10-09 09:31:02,982][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:38:06,773][train_inner][INFO] - {"epoch": 1201, "update": 1200.542, "loss": "0.489", "ntokens": "259996", "nsentences": "1859.85", "wps": "59526.3", "ups": "0.23", "wpb": "259996", "bsz": "1859.8", "num_updates": "57600", "lr": "0.000465217", "gnorm": "0.396", "loss_scale": "4", "train_wall": "57", "gb_free": "40.1", "wall": "612"}
[2024-10-09 09:39:29,751][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 09:39:39,828][fairseq_cli.train][INFO] - end of epoch 1201 (average epoch stats below)
[2024-10-09 09:39:39,924][train][INFO] - {"epoch": 1201, "train_loss": "0.486", "train_ntokens": "261000", "train_nsentences": "1734.11", "train_wps": "58551.1", "train_ups": "0.22", "train_wpb": "261000", "train_bsz": "1734.1", "train_num_updates": "57621", "train_lr": "0.000465189", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "148", "train_gb_free": "39.5", "train_wall": "708"}
[2024-10-09 09:39:40,196][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:39:40,212][fairseq.trainer][INFO] - begin training epoch 1202
[2024-10-09 09:39:40,213][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:40:30,757][train_inner][INFO] - {"epoch": 1201, "update": 1200.542, "loss": "0.489", "ntokens": "259996", "nsentences": "1859.85", "wps": "128544", "ups": "0.49", "wpb": "259996", "bsz": "1859.8", "num_updates": "57600", "lr": "0.000465217", "gnorm": "0.396", "loss_scale": "4", "train_wall": "281", "gb_free": "40.1", "wall": "708"}
[2024-10-09 09:41:16,831][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 09:42:52,243][fairseq_cli.train][INFO] - end of epoch 1201 (average epoch stats below)
[2024-10-09 09:42:52,323][train][INFO] - {"epoch": 1201, "train_loss": "0.486", "train_ntokens": "261000", "train_nsentences": "1734.11", "train_wps": "62490.1", "train_ups": "0.24", "train_wpb": "261000", "train_bsz": "1734.1", "train_num_updates": "57621", "train_lr": "0.000465189", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "333", "train_gb_free": "39.5", "train_wall": "850"}
[2024-10-09 09:42:52,614][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:42:52,628][fairseq.trainer][INFO] - begin training epoch 1202
[2024-10-09 09:42:52,630][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:48:06,741][fairseq_cli.train][INFO] - end of epoch 1202 (average epoch stats below)
[2024-10-09 09:48:06,764][train][INFO] - {"epoch": 1202, "train_loss": "0.491", "train_ntokens": "260841", "train_nsentences": "1750.04", "train_wps": "24703.5", "train_ups": "0.09", "train_wpb": "260841", "train_bsz": "1750", "train_num_updates": "57669", "train_lr": "0.000465124", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "40.1", "train_wall": "1215"}
[2024-10-09 09:48:06,903][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:48:06,910][fairseq.trainer][INFO] - begin training epoch 1203
[2024-10-09 09:48:06,911][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:48:52,154][fairseq_cli.train][INFO] - end of epoch 1202 (average epoch stats below)
[2024-10-09 09:48:52,160][train][INFO] - {"epoch": 1202, "train_loss": "0.491", "train_ntokens": "260841", "train_nsentences": "1750.04", "train_wps": "34795.2", "train_ups": "0.13", "train_wpb": "260841", "train_bsz": "1750", "train_num_updates": "57669", "train_lr": "0.000465124", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "40.1", "train_wall": "1210"}
[2024-10-09 09:48:52,297][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:48:52,301][fairseq.trainer][INFO] - begin training epoch 1203
[2024-10-09 09:48:52,302][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:51:14,443][fairseq_cli.train][INFO] - end of epoch 1203 (average epoch stats below)
[2024-10-09 09:51:14,460][train][INFO] - {"epoch": 1203, "train_loss": "0.494", "train_ntokens": "260523", "train_nsentences": "1750.04", "train_wps": "66630", "train_ups": "0.26", "train_wpb": "260523", "train_bsz": "1750", "train_num_updates": "57717", "train_lr": "0.000465058", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "89", "train_gb_free": "39.7", "train_wall": "1403"}
[2024-10-09 09:51:14,645][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:51:14,661][fairseq.trainer][INFO] - begin training epoch 1204
[2024-10-09 09:51:14,662][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:52:10,596][fairseq_cli.train][INFO] - end of epoch 1203 (average epoch stats below)
[2024-10-09 09:52:10,600][train][INFO] - {"epoch": 1203, "train_loss": "0.494", "train_ntokens": "260523", "train_nsentences": "1750.04", "train_wps": "63018.4", "train_ups": "0.24", "train_wpb": "260523", "train_bsz": "1750", "train_num_updates": "57717", "train_lr": "0.000465058", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.7", "train_wall": "1408"}
[2024-10-09 09:52:10,731][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:52:10,735][fairseq.trainer][INFO] - begin training epoch 1204
[2024-10-09 09:52:10,735][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:54:36,686][fairseq_cli.train][INFO] - end of epoch 1204 (average epoch stats below)
[2024-10-09 09:54:36,707][train][INFO] - {"epoch": 1204, "train_loss": "0.489", "train_ntokens": "260708", "train_nsentences": "1750.04", "train_wps": "61878.2", "train_ups": "0.24", "train_wpb": "260708", "train_bsz": "1750", "train_num_updates": "57765", "train_lr": "0.000464993", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.8", "train_wall": "1605"}
[2024-10-09 09:54:36,785][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:54:36,788][fairseq.trainer][INFO] - begin training epoch 1205
[2024-10-09 09:54:36,788][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:55:37,480][fairseq_cli.train][INFO] - end of epoch 1204 (average epoch stats below)
[2024-10-09 09:55:37,504][train][INFO] - {"epoch": 1204, "train_loss": "0.489", "train_ntokens": "260708", "train_nsentences": "1750.04", "train_wps": "60487.1", "train_ups": "0.23", "train_wpb": "260708", "train_bsz": "1750", "train_num_updates": "57765", "train_lr": "0.000464993", "train_gnorm": "0.402", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.8", "train_wall": "1615"}
[2024-10-09 09:55:37,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:55:37,683][fairseq.trainer][INFO] - begin training epoch 1205
[2024-10-09 09:55:37,684][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:57:36,344][train_inner][INFO] - {"epoch": 1205, "update": 1204.729, "loss": "0.491", "ntokens": "260780", "nsentences": "1729.51", "wps": "44597.8", "ups": "0.17", "wpb": "260780", "bsz": "1729.5", "num_updates": "57800", "lr": "0.000464946", "gnorm": "0.385", "loss_scale": "2", "train_wall": "407", "gb_free": "39.7", "wall": "1785"}
[2024-10-09 09:58:01,188][fairseq_cli.train][INFO] - end of epoch 1205 (average epoch stats below)
[2024-10-09 09:58:01,202][train][INFO] - {"epoch": 1205, "train_loss": "0.496", "train_ntokens": "260552", "train_nsentences": "1750.04", "train_wps": "61162.1", "train_ups": "0.23", "train_wpb": "260552", "train_bsz": "1750", "train_num_updates": "57813", "train_lr": "0.000464928", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.4", "train_wall": "1809"}
[2024-10-09 09:58:01,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:58:01,374][fairseq.trainer][INFO] - begin training epoch 1206
[2024-10-09 09:58:01,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:58:47,169][train_inner][INFO] - {"epoch": 1205, "update": 1204.729, "loss": "0.491", "ntokens": "260780", "nsentences": "1729.51", "wps": "47569.9", "ups": "0.18", "wpb": "260780", "bsz": "1729.5", "num_updates": "57800", "lr": "0.000464946", "gnorm": "0.385", "loss_scale": "2", "train_wall": "314", "gb_free": "39.7", "wall": "1805"}
[2024-10-09 09:59:05,681][fairseq_cli.train][INFO] - end of epoch 1205 (average epoch stats below)
[2024-10-09 09:59:05,688][train][INFO] - {"epoch": 1205, "train_loss": "0.496", "train_ntokens": "260552", "train_nsentences": "1750.04", "train_wps": "60076.2", "train_ups": "0.23", "train_wpb": "260552", "train_bsz": "1750", "train_num_updates": "57813", "train_lr": "0.000464928", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.4", "train_wall": "1823"}
[2024-10-09 09:59:05,848][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:59:05,854][fairseq.trainer][INFO] - begin training epoch 1206
[2024-10-09 09:59:05,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:01:13,393][fairseq_cli.train][INFO] - end of epoch 1206 (average epoch stats below)
[2024-10-09 10:01:13,456][train][INFO] - {"epoch": 1206, "train_loss": "0.486", "train_ntokens": "260754", "train_nsentences": "1750.04", "train_wps": "65103.8", "train_ups": "0.25", "train_wpb": "260754", "train_bsz": "1750", "train_num_updates": "57861", "train_lr": "0.000464863", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "39.7", "train_wall": "2002"}
[2024-10-09 10:01:16,802][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:01:16,822][fairseq.trainer][INFO] - begin training epoch 1207
[2024-10-09 10:01:16,823][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:03:52,386][fairseq_cli.train][INFO] - end of epoch 1206 (average epoch stats below)
[2024-10-09 10:03:52,395][train][INFO] - {"epoch": 1206, "train_loss": "0.486", "train_ntokens": "260754", "train_nsentences": "1750.04", "train_wps": "43655.5", "train_ups": "0.17", "train_wpb": "260754", "train_bsz": "1750", "train_num_updates": "57861", "train_lr": "0.000464863", "train_gnorm": "0.367", "train_loss_scale": "2", "train_train_wall": "108", "train_gb_free": "39.7", "train_wall": "2110"}
[2024-10-09 10:03:52,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:03:52,823][fairseq.trainer][INFO] - begin training epoch 1207
[2024-10-09 10:03:52,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:06:42,800][fairseq_cli.train][INFO] - end of epoch 1207 (average epoch stats below)
[2024-10-09 10:06:42,805][train][INFO] - {"epoch": 1207, "train_loss": "0.499", "train_ntokens": "260748", "train_nsentences": "1750.04", "train_wps": "38002.2", "train_ups": "0.15", "train_wpb": "260748", "train_bsz": "1750", "train_num_updates": "57909", "train_lr": "0.000464798", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.1", "train_wall": "2331"}
[2024-10-09 10:06:43,148][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:06:43,153][fairseq.trainer][INFO] - begin training epoch 1208
[2024-10-09 10:06:43,154][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:09:06,653][fairseq_cli.train][INFO] - end of epoch 1207 (average epoch stats below)
[2024-10-09 10:09:06,670][train][INFO] - {"epoch": 1207, "train_loss": "0.499", "train_ntokens": "260748", "train_nsentences": "1750.04", "train_wps": "39825.3", "train_ups": "0.15", "train_wpb": "260748", "train_bsz": "1750", "train_num_updates": "57909", "train_lr": "0.000464798", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "90", "train_gb_free": "39.1", "train_wall": "2424"}
[2024-10-09 10:09:06,941][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:09:06,945][fairseq.trainer][INFO] - begin training epoch 1208
[2024-10-09 10:09:06,946][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:11:36,468][fairseq_cli.train][INFO] - end of epoch 1208 (average epoch stats below)
[2024-10-09 10:11:36,474][train][INFO] - {"epoch": 1208, "train_loss": "0.486", "train_ntokens": "260989", "train_nsentences": "1750.04", "train_wps": "42659", "train_ups": "0.16", "train_wpb": "260989", "train_bsz": "1750", "train_num_updates": "57957", "train_lr": "0.000464732", "train_gnorm": "0.356", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.1", "train_wall": "2625"}
[2024-10-09 10:11:36,692][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:11:36,723][fairseq.trainer][INFO] - begin training epoch 1209
[2024-10-09 10:11:36,723][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:13:15,049][fairseq_cli.train][INFO] - end of epoch 1208 (average epoch stats below)
[2024-10-09 10:13:15,052][train][INFO] - {"epoch": 1208, "train_loss": "0.486", "train_ntokens": "260989", "train_nsentences": "1750.04", "train_wps": "50436.7", "train_ups": "0.19", "train_wpb": "260989", "train_bsz": "1750", "train_num_updates": "57957", "train_lr": "0.000464732", "train_gnorm": "0.355", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "40.1", "train_wall": "2673"}
[2024-10-09 10:13:15,205][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:13:15,212][fairseq.trainer][INFO] - begin training epoch 1209
[2024-10-09 10:13:15,213][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:16:24,108][train_inner][INFO] - {"epoch": 1209, "update": 1208.896, "loss": "0.491", "ntokens": "260821", "nsentences": "1760.17", "wps": "46255.6", "ups": "0.18", "wpb": "260821", "bsz": "1760.2", "num_updates": "58000", "lr": "0.000464674", "gnorm": "0.377", "loss_scale": "2", "train_wall": "317", "gb_free": "39.8", "wall": "2912"}
[2024-10-09 10:16:25,844][fairseq_cli.train][INFO] - end of epoch 1209 (average epoch stats below)
[2024-10-09 10:16:25,847][train][INFO] - {"epoch": 1209, "train_loss": "0.489", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "43261.2", "train_ups": "0.17", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "58005", "train_lr": "0.000464667", "train_gnorm": "0.398", "train_loss_scale": "2", "train_train_wall": "90", "train_gb_free": "39.6", "train_wall": "2914"}
[2024-10-09 10:16:26,361][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:16:26,375][fairseq.trainer][INFO] - begin training epoch 1210
[2024-10-09 10:16:26,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:18:47,243][train_inner][INFO] - {"epoch": 1209, "update": 1208.896, "loss": "0.491", "ntokens": "260821", "nsentences": "1760.17", "wps": "43468.1", "ups": "0.17", "wpb": "260821", "bsz": "1760.2", "num_updates": "58000", "lr": "0.000464674", "gnorm": "0.376", "loss_scale": "2", "train_wall": "354", "gb_free": "39.8", "wall": "3005"}
[2024-10-09 10:18:48,919][fairseq_cli.train][INFO] - end of epoch 1209 (average epoch stats below)
[2024-10-09 10:18:48,922][train][INFO] - {"epoch": 1209, "train_loss": "0.489", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "37495.5", "train_ups": "0.14", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "58005", "train_lr": "0.000464667", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.6", "train_wall": "3006"}
[2024-10-09 10:18:49,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:18:49,144][fairseq.trainer][INFO] - begin training epoch 1210
[2024-10-09 10:18:49,145][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:22:18,661][fairseq_cli.train][INFO] - end of epoch 1210 (average epoch stats below)
[2024-10-09 10:22:18,672][train][INFO] - {"epoch": 1210, "train_loss": "0.492", "train_ntokens": "260582", "train_nsentences": "1750.04", "train_wps": "35451.5", "train_ups": "0.14", "train_wpb": "260582", "train_bsz": "1750", "train_num_updates": "58053", "train_lr": "0.000464602", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "39.6", "train_wall": "3267"}
[2024-10-09 10:22:19,042][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:22:19,061][fairseq.trainer][INFO] - begin training epoch 1211
[2024-10-09 10:22:19,062][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:24:24,794][fairseq_cli.train][INFO] - end of epoch 1210 (average epoch stats below)
[2024-10-09 10:24:24,812][train][INFO] - {"epoch": 1210, "train_loss": "0.492", "train_ntokens": "260582", "train_nsentences": "1750.04", "train_wps": "37238.4", "train_ups": "0.14", "train_wpb": "260582", "train_bsz": "1750", "train_num_updates": "58053", "train_lr": "0.000464602", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.6", "train_wall": "3342"}
[2024-10-09 10:24:25,207][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:24:25,215][fairseq.trainer][INFO] - begin training epoch 1211
[2024-10-09 10:24:25,215][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:27:29,661][fairseq_cli.train][INFO] - end of epoch 1211 (average epoch stats below)
[2024-10-09 10:27:29,676][train][INFO] - {"epoch": 1211, "train_loss": "0.487", "train_ntokens": "260734", "train_nsentences": "1750.04", "train_wps": "40241.6", "train_ups": "0.15", "train_wpb": "260734", "train_bsz": "1750", "train_num_updates": "58101", "train_lr": "0.000464537", "train_gnorm": "0.365", "train_loss_scale": "2", "train_train_wall": "98", "train_gb_free": "39.7", "train_wall": "3578"}
[2024-10-09 10:27:29,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:27:29,928][fairseq.trainer][INFO] - begin training epoch 1212
[2024-10-09 10:27:29,929][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:29:48,578][fairseq_cli.train][INFO] - end of epoch 1211 (average epoch stats below)
[2024-10-09 10:29:48,594][train][INFO] - {"epoch": 1211, "train_loss": "0.487", "train_ntokens": "260734", "train_nsentences": "1750.04", "train_wps": "38653.7", "train_ups": "0.15", "train_wpb": "260734", "train_bsz": "1750", "train_num_updates": "58101", "train_lr": "0.000464537", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.7", "train_wall": "3666"}
[2024-10-09 10:29:48,949][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:29:48,955][fairseq.trainer][INFO] - begin training epoch 1212
[2024-10-09 10:29:48,955][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:33:21,602][fairseq_cli.train][INFO] - end of epoch 1212 (average epoch stats below)
[2024-10-09 10:33:21,617][train][INFO] - {"epoch": 1212, "train_loss": "0.49", "train_ntokens": "260630", "train_nsentences": "1750.04", "train_wps": "35546.9", "train_ups": "0.14", "train_wpb": "260630", "train_bsz": "1750", "train_num_updates": "58149", "train_lr": "0.000464471", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.5", "train_wall": "3930"}
[2024-10-09 10:33:21,865][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:33:21,868][fairseq.trainer][INFO] - begin training epoch 1213
[2024-10-09 10:33:21,869][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:34:37,079][fairseq_cli.train][INFO] - end of epoch 1212 (average epoch stats below)
[2024-10-09 10:34:37,091][train][INFO] - {"epoch": 1212, "train_loss": "0.49", "train_ntokens": "260630", "train_nsentences": "1750.04", "train_wps": "43364", "train_ups": "0.17", "train_wpb": "260630", "train_bsz": "1750", "train_num_updates": "58149", "train_lr": "0.000464471", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "40.5", "train_wall": "3955"}
[2024-10-09 10:34:37,374][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:34:37,380][fairseq.trainer][INFO] - begin training epoch 1213
[2024-10-09 10:34:37,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:36:45,682][fairseq_cli.train][INFO] - end of epoch 1213 (average epoch stats below)
[2024-10-09 10:36:45,696][train][INFO] - {"epoch": 1213, "train_loss": "0.488", "train_ntokens": "260713", "train_nsentences": "1750.04", "train_wps": "61323.8", "train_ups": "0.24", "train_wpb": "260713", "train_bsz": "1750", "train_num_updates": "58197", "train_lr": "0.000464406", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "94", "train_gb_free": "39.7", "train_wall": "4134"}
[2024-10-09 10:36:45,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:36:45,924][fairseq.trainer][INFO] - begin training epoch 1214
[2024-10-09 10:36:45,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:38:01,617][fairseq_cli.train][INFO] - end of epoch 1213 (average epoch stats below)
[2024-10-09 10:38:01,622][train][INFO] - {"epoch": 1213, "train_loss": "0.488", "train_ntokens": "260713", "train_nsentences": "1750.04", "train_wps": "61185.7", "train_ups": "0.23", "train_wpb": "260713", "train_bsz": "1750", "train_num_updates": "58197", "train_lr": "0.000464406", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "90", "train_gb_free": "39.7", "train_wall": "4159"}
[2024-10-09 10:38:01,784][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:38:01,793][fairseq.trainer][INFO] - begin training epoch 1214
[2024-10-09 10:38:01,794][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:39:07,128][train_inner][INFO] - {"epoch": 1214, "update": 1213.062, "loss": "0.489", "ntokens": "260695", "nsentences": "1742.88", "wps": "38252.7", "ups": "0.15", "wpb": "260696", "bsz": "1742.9", "num_updates": "58200", "lr": "0.000464402", "gnorm": "0.381", "loss_scale": "2", "train_wall": "340", "gb_free": "39.1", "wall": "4275"}
[2024-10-09 10:40:07,520][fairseq_cli.train][INFO] - end of epoch 1214 (average epoch stats below)
[2024-10-09 10:40:07,536][train][INFO] - {"epoch": 1214, "train_loss": "0.487", "train_ntokens": "260603", "train_nsentences": "1750.04", "train_wps": "61979.3", "train_ups": "0.24", "train_wpb": "260603", "train_bsz": "1750", "train_num_updates": "58245", "train_lr": "0.000464341", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "40.5", "train_wall": "4336"}
[2024-10-09 10:40:08,041][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:40:08,057][fairseq.trainer][INFO] - begin training epoch 1215
[2024-10-09 10:40:08,057][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:40:28,891][train_inner][INFO] - {"epoch": 1214, "update": 1213.062, "loss": "0.489", "ntokens": "260695", "nsentences": "1742.88", "wps": "40056.4", "ups": "0.15", "wpb": "260696", "bsz": "1742.9", "num_updates": "58200", "lr": "0.000464402", "gnorm": "0.38", "loss_scale": "2", "train_wall": "299", "gb_free": "39.1", "wall": "4306"}
[2024-10-09 10:41:15,831][fairseq_cli.train][INFO] - end of epoch 1214 (average epoch stats below)
[2024-10-09 10:41:15,851][train][INFO] - {"epoch": 1214, "train_loss": "0.487", "train_ntokens": "260603", "train_nsentences": "1750.04", "train_wps": "64409.8", "train_ups": "0.25", "train_wpb": "260603", "train_bsz": "1750", "train_num_updates": "58245", "train_lr": "0.000464341", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "40.5", "train_wall": "4353"}
[2024-10-09 10:41:15,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:41:15,966][fairseq.trainer][INFO] - begin training epoch 1215
[2024-10-09 10:41:15,967][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:43:14,917][fairseq_cli.train][INFO] - end of epoch 1215 (average epoch stats below)
[2024-10-09 10:43:14,959][train][INFO] - {"epoch": 1215, "train_loss": "0.491", "train_ntokens": "260681", "train_nsentences": "1750.04", "train_wps": "66767", "train_ups": "0.26", "train_wpb": "260681", "train_bsz": "1750", "train_num_updates": "58293", "train_lr": "0.000464276", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "39.8", "train_wall": "4523"}
[2024-10-09 10:43:15,638][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:43:15,699][fairseq.trainer][INFO] - begin training epoch 1216
[2024-10-09 10:43:15,700][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:44:32,712][fairseq_cli.train][INFO] - end of epoch 1215 (average epoch stats below)
[2024-10-09 10:44:32,725][train][INFO] - {"epoch": 1215, "train_loss": "0.491", "train_ntokens": "260681", "train_nsentences": "1750.04", "train_wps": "63560.1", "train_ups": "0.24", "train_wpb": "260681", "train_bsz": "1750", "train_num_updates": "58293", "train_lr": "0.000464276", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "39.8", "train_wall": "4550"}
[2024-10-09 10:44:32,995][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:44:33,010][fairseq.trainer][INFO] - begin training epoch 1216
[2024-10-09 10:44:33,011][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:46:33,635][fairseq_cli.train][INFO] - end of epoch 1216 (average epoch stats below)
[2024-10-09 10:46:33,651][train][INFO] - {"epoch": 1216, "train_loss": "0.493", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "62946", "train_ups": "0.24", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "58341", "train_lr": "0.000464211", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "39.8", "train_wall": "4722"}
[2024-10-09 10:46:33,822][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:46:33,829][fairseq.trainer][INFO] - begin training epoch 1217
[2024-10-09 10:46:33,830][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:48:03,162][fairseq_cli.train][INFO] - end of epoch 1216 (average epoch stats below)
[2024-10-09 10:48:03,184][train][INFO] - {"epoch": 1216, "train_loss": "0.493", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "59425.9", "train_ups": "0.23", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "58341", "train_lr": "0.000464211", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.8", "train_wall": "4761"}
[2024-10-09 10:48:03,348][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:48:03,355][fairseq.trainer][INFO] - begin training epoch 1217
[2024-10-09 10:48:03,356][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:49:54,983][fairseq_cli.train][INFO] - end of epoch 1217 (average epoch stats below)
[2024-10-09 10:49:55,005][train][INFO] - {"epoch": 1217, "train_loss": "0.497", "train_ntokens": "260423", "train_nsentences": "1750.04", "train_wps": "62082", "train_ups": "0.24", "train_wpb": "260423", "train_bsz": "1750", "train_num_updates": "58389", "train_lr": "0.000464145", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "72", "train_gb_free": "39.6", "train_wall": "4923"}
[2024-10-09 10:49:55,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:49:55,129][fairseq.trainer][INFO] - begin training epoch 1218
[2024-10-09 10:49:55,130][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:51:34,911][fairseq_cli.train][INFO] - end of epoch 1217 (average epoch stats below)
[2024-10-09 10:51:34,917][train][INFO] - {"epoch": 1217, "train_loss": "0.497", "train_ntokens": "260423", "train_nsentences": "1750.04", "train_wps": "59040.6", "train_ups": "0.23", "train_wpb": "260423", "train_bsz": "1750", "train_num_updates": "58389", "train_lr": "0.000464145", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "75", "train_gb_free": "39.6", "train_wall": "4972"}
[2024-10-09 10:51:35,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:51:35,044][fairseq.trainer][INFO] - begin training epoch 1218
[2024-10-09 10:51:35,045][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:52:28,141][train_inner][INFO] - {"epoch": 1218, "update": 1217.229, "loss": "0.492", "ntokens": "260507", "nsentences": "1748.36", "wps": "65045", "ups": "0.25", "wpb": "260507", "bsz": "1748.4", "num_updates": "58400", "lr": "0.00046413", "gnorm": "0.376", "loss_scale": "2", "train_wall": "276", "gb_free": "39.6", "wall": "5076"}
[2024-10-09 10:53:11,049][fairseq_cli.train][INFO] - end of epoch 1218 (average epoch stats below)
[2024-10-09 10:53:11,052][train][INFO] - {"epoch": 1218, "train_loss": "0.493", "train_ntokens": "260537", "train_nsentences": "1750.04", "train_wps": "63790.6", "train_ups": "0.24", "train_wpb": "260537", "train_bsz": "1750", "train_num_updates": "58437", "train_lr": "0.00046408", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "39.2", "train_wall": "5119"}
[2024-10-09 10:53:11,138][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:53:11,143][fairseq.trainer][INFO] - begin training epoch 1219
[2024-10-09 10:53:11,144][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:54:10,667][train_inner][INFO] - {"epoch": 1218, "update": 1217.229, "loss": "0.492", "ntokens": "260507", "nsentences": "1748.36", "wps": "63401.6", "ups": "0.24", "wpb": "260507", "bsz": "1748.4", "num_updates": "58400", "lr": "0.00046413", "gnorm": "0.375", "loss_scale": "2", "train_wall": "263", "gb_free": "39.6", "wall": "5128"}
[2024-10-09 10:54:51,997][fairseq_cli.train][INFO] - end of epoch 1218 (average epoch stats below)
[2024-10-09 10:54:52,003][train][INFO] - {"epoch": 1218, "train_loss": "0.493", "train_ntokens": "260537", "train_nsentences": "1750.04", "train_wps": "63455.4", "train_ups": "0.24", "train_wpb": "260537", "train_bsz": "1750", "train_num_updates": "58437", "train_lr": "0.00046408", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "37", "train_gb_free": "39.2", "train_wall": "5170"}
[2024-10-09 10:54:52,116][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:54:52,123][fairseq.trainer][INFO] - begin training epoch 1219
[2024-10-09 10:54:52,123][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:56:26,467][fairseq_cli.train][INFO] - end of epoch 1219 (average epoch stats below)
[2024-10-09 10:56:26,470][train][INFO] - {"epoch": 1219, "train_loss": "0.495", "train_ntokens": "260621", "train_nsentences": "1750.04", "train_wps": "64016.3", "train_ups": "0.25", "train_wpb": "260621", "train_bsz": "1750", "train_num_updates": "58485", "train_lr": "0.000464015", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "76", "train_gb_free": "39.6", "train_wall": "5315"}
[2024-10-09 10:56:26,543][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:56:26,547][fairseq.trainer][INFO] - begin training epoch 1220
[2024-10-09 10:56:26,547][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:58:07,060][fairseq_cli.train][INFO] - end of epoch 1219 (average epoch stats below)
[2024-10-09 10:58:07,069][train][INFO] - {"epoch": 1219, "train_loss": "0.495", "train_ntokens": "260621", "train_nsentences": "1750.04", "train_wps": "64131.6", "train_ups": "0.25", "train_wpb": "260621", "train_bsz": "1750", "train_num_updates": "58485", "train_lr": "0.000464015", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.6", "train_wall": "5365"}
[2024-10-09 10:58:07,274][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:58:07,278][fairseq.trainer][INFO] - begin training epoch 1220
[2024-10-09 10:58:07,278][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 10:59:42,595][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1220 @ 58533 updates
[2024-10-09 10:59:42,596][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 10:59:46,825][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 10:59:46,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1220 @ 58533 updates, score None) (writing took 4.233407499268651 seconds)
[2024-10-09 10:59:46,829][fairseq_cli.train][INFO] - end of epoch 1220 (average epoch stats below)
[2024-10-09 10:59:46,832][train][INFO] - {"epoch": 1220, "train_loss": "0.496", "train_ntokens": "260876", "train_nsentences": "1750.04", "train_wps": "62498", "train_ups": "0.24", "train_wpb": "260876", "train_bsz": "1750", "train_num_updates": "58533", "train_lr": "0.00046395", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "63", "train_gb_free": "40.2", "train_wall": "5515"}
[2024-10-09 10:59:47,106][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 10:59:47,131][fairseq.trainer][INFO] - begin training epoch 1221
[2024-10-09 10:59:47,132][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:01:45,161][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1220 @ 58533 updates
[2024-10-09 11:01:45,168][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 11:01:49,567][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 11:01:49,570][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1220 @ 58533 updates, score None) (writing took 4.408216062933207 seconds)
[2024-10-09 11:01:49,570][fairseq_cli.train][INFO] - end of epoch 1220 (average epoch stats below)
[2024-10-09 11:01:49,573][train][INFO] - {"epoch": 1220, "train_loss": "0.496", "train_ntokens": "260876", "train_nsentences": "1750.04", "train_wps": "56278.7", "train_ups": "0.22", "train_wpb": "260876", "train_bsz": "1750", "train_num_updates": "58533", "train_lr": "0.00046395", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "40.2", "train_wall": "5587"}
[2024-10-09 11:01:49,719][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:01:49,746][fairseq.trainer][INFO] - begin training epoch 1221
[2024-10-09 11:01:49,747][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:03:33,863][fairseq_cli.train][INFO] - end of epoch 1221 (average epoch stats below)
[2024-10-09 11:03:33,876][train][INFO] - {"epoch": 1221, "train_loss": "0.492", "train_ntokens": "260770", "train_nsentences": "1750.04", "train_wps": "55131.3", "train_ups": "0.21", "train_wpb": "260770", "train_bsz": "1750", "train_num_updates": "58581", "train_lr": "0.000463885", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.3", "train_wall": "5742"}
[2024-10-09 11:03:34,072][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:03:34,076][fairseq.trainer][INFO] - begin training epoch 1222
[2024-10-09 11:03:34,077][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:05:34,426][fairseq_cli.train][INFO] - end of epoch 1221 (average epoch stats below)
[2024-10-09 11:05:34,441][train][INFO] - {"epoch": 1221, "train_loss": "0.492", "train_ntokens": "260770", "train_nsentences": "1750.04", "train_wps": "55664.2", "train_ups": "0.21", "train_wpb": "260770", "train_bsz": "1750", "train_num_updates": "58581", "train_lr": "0.000463885", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "32", "train_gb_free": "40.3", "train_wall": "5812"}
[2024-10-09 11:05:35,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:05:35,248][fairseq.trainer][INFO] - begin training epoch 1222
[2024-10-09 11:05:35,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:07:15,842][train_inner][INFO] - {"epoch": 1222, "update": 1221.396, "loss": "0.495", "ntokens": "260581", "nsentences": "1756.21", "wps": "58709.3", "ups": "0.23", "wpb": "260581", "bsz": "1756.2", "num_updates": "58600", "lr": "0.000463859", "gnorm": "0.387", "loss_scale": "2", "train_wall": "287", "gb_free": "39.3", "wall": "5964"}
[2024-10-09 11:07:36,120][fairseq_cli.train][INFO] - end of epoch 1222 (average epoch stats below)
[2024-10-09 11:07:36,122][train][INFO] - {"epoch": 1222, "train_loss": "0.5", "train_ntokens": "260668", "train_nsentences": "1750.04", "train_wps": "51650.7", "train_ups": "0.2", "train_wpb": "260668", "train_bsz": "1750", "train_num_updates": "58629", "train_lr": "0.000463819", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.6", "train_wall": "5984"}
[2024-10-09 11:07:36,365][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:07:36,372][fairseq.trainer][INFO] - begin training epoch 1223
[2024-10-09 11:07:36,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:09:16,086][train_inner][INFO] - {"epoch": 1222, "update": 1221.396, "loss": "0.495", "ntokens": "260581", "nsentences": "1756.21", "wps": "57560.5", "ups": "0.22", "wpb": "260581", "bsz": "1756.2", "num_updates": "58600", "lr": "0.000463859", "gnorm": "0.387", "loss_scale": "2", "train_wall": "264", "gb_free": "39.3", "wall": "6034"}
[2024-10-09 11:09:37,222][fairseq_cli.train][INFO] - end of epoch 1222 (average epoch stats below)
[2024-10-09 11:09:37,237][train][INFO] - {"epoch": 1222, "train_loss": "0.5", "train_ntokens": "260668", "train_nsentences": "1750.04", "train_wps": "51536.3", "train_ups": "0.2", "train_wpb": "260668", "train_bsz": "1750", "train_num_updates": "58629", "train_lr": "0.000463819", "train_gnorm": "0.403", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.6", "train_wall": "6055"}
[2024-10-09 11:09:37,383][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:09:37,403][fairseq.trainer][INFO] - begin training epoch 1223
[2024-10-09 11:09:37,404][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:11:22,196][fairseq_cli.train][INFO] - end of epoch 1223 (average epoch stats below)
[2024-10-09 11:11:22,213][train][INFO] - {"epoch": 1223, "train_loss": "0.504", "train_ntokens": "260474", "train_nsentences": "1750.04", "train_wps": "55300.7", "train_ups": "0.21", "train_wpb": "260474", "train_bsz": "1750", "train_num_updates": "58677", "train_lr": "0.000463754", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "6210"}
[2024-10-09 11:11:22,409][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:11:22,433][fairseq.trainer][INFO] - begin training epoch 1224
[2024-10-09 11:11:22,434][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:13:20,793][fairseq_cli.train][INFO] - end of epoch 1223 (average epoch stats below)
[2024-10-09 11:13:20,798][train][INFO] - {"epoch": 1223, "train_loss": "0.504", "train_ntokens": "260474", "train_nsentences": "1750.04", "train_wps": "55926", "train_ups": "0.21", "train_wpb": "260474", "train_bsz": "1750", "train_num_updates": "58677", "train_lr": "0.000463754", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.3", "train_wall": "6278"}
[2024-10-09 11:13:20,930][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:13:20,944][fairseq.trainer][INFO] - begin training epoch 1224
[2024-10-09 11:13:20,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:15:03,231][fairseq_cli.train][INFO] - end of epoch 1224 (average epoch stats below)
[2024-10-09 11:15:03,237][train][INFO] - {"epoch": 1224, "train_loss": "0.491", "train_ntokens": "260828", "train_nsentences": "1750.04", "train_wps": "56645", "train_ups": "0.22", "train_wpb": "260828", "train_bsz": "1750", "train_num_updates": "58725", "train_lr": "0.000463689", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.3", "train_wall": "6432"}
[2024-10-09 11:15:03,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:15:03,458][fairseq.trainer][INFO] - begin training epoch 1225
[2024-10-09 11:15:03,458][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:16:43,298][fairseq_cli.train][INFO] - end of epoch 1224 (average epoch stats below)
[2024-10-09 11:16:43,321][train][INFO] - {"epoch": 1224, "train_loss": "0.491", "train_ntokens": "260828", "train_nsentences": "1750.04", "train_wps": "61820.8", "train_ups": "0.24", "train_wpb": "260828", "train_bsz": "1750", "train_num_updates": "58725", "train_lr": "0.000463689", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.3", "train_wall": "6481"}
[2024-10-09 11:16:43,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:16:43,472][fairseq.trainer][INFO] - begin training epoch 1225
[2024-10-09 11:16:43,473][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:18:22,161][fairseq_cli.train][INFO] - end of epoch 1225 (average epoch stats below)
[2024-10-09 11:18:22,184][train][INFO] - {"epoch": 1225, "train_loss": "0.486", "train_ntokens": "260890", "train_nsentences": "1750.04", "train_wps": "62945.7", "train_ups": "0.24", "train_wpb": "260890", "train_bsz": "1750", "train_num_updates": "58773", "train_lr": "0.000463624", "train_gnorm": "0.344", "train_loss_scale": "2", "train_train_wall": "63", "train_gb_free": "39.6", "train_wall": "6630"}
[2024-10-09 11:18:22,472][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:18:22,488][fairseq.trainer][INFO] - begin training epoch 1226
[2024-10-09 11:18:22,489][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:20:10,663][fairseq_cli.train][INFO] - end of epoch 1225 (average epoch stats below)
[2024-10-09 11:20:10,666][train][INFO] - {"epoch": 1225, "train_loss": "0.486", "train_ntokens": "260890", "train_nsentences": "1750.04", "train_wps": "60396", "train_ups": "0.23", "train_wpb": "260890", "train_bsz": "1750", "train_num_updates": "58773", "train_lr": "0.000463624", "train_gnorm": "0.345", "train_loss_scale": "2", "train_train_wall": "72", "train_gb_free": "39.6", "train_wall": "6688"}
[2024-10-09 11:20:10,777][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:20:10,799][fairseq.trainer][INFO] - begin training epoch 1226
[2024-10-09 11:20:10,803][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:21:39,744][train_inner][INFO] - {"epoch": 1226, "update": 1225.562, "loss": "0.493", "ntokens": "260882", "nsentences": "1746.97", "wps": "60396.9", "ups": "0.23", "wpb": "260882", "bsz": "1747", "num_updates": "58800", "lr": "0.000463587", "gnorm": "0.379", "loss_scale": "2", "train_wall": "255", "gb_free": "39.9", "wall": "6828"}
[2024-10-09 11:22:02,745][fairseq_cli.train][INFO] - end of epoch 1226 (average epoch stats below)
[2024-10-09 11:22:02,762][train][INFO] - {"epoch": 1226, "train_loss": "0.489", "train_ntokens": "260788", "train_nsentences": "1750.04", "train_wps": "56752.6", "train_ups": "0.22", "train_wpb": "260788", "train_bsz": "1750", "train_num_updates": "58821", "train_lr": "0.000463558", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "72", "train_gb_free": "40.7", "train_wall": "6851"}
[2024-10-09 11:22:02,857][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:22:02,865][fairseq.trainer][INFO] - begin training epoch 1227
[2024-10-09 11:22:02,866][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:23:38,600][train_inner][INFO] - {"epoch": 1226, "update": 1225.562, "loss": "0.493", "ntokens": "260882", "nsentences": "1746.97", "wps": "60493.9", "ups": "0.23", "wpb": "260882", "bsz": "1747", "num_updates": "58800", "lr": "0.000463587", "gnorm": "0.379", "loss_scale": "2", "train_wall": "287", "gb_free": "39.9", "wall": "6896"}
[2024-10-09 11:23:55,934][fairseq_cli.train][INFO] - end of epoch 1226 (average epoch stats below)
[2024-10-09 11:23:55,951][train][INFO] - {"epoch": 1226, "train_loss": "0.489", "train_ntokens": "260788", "train_nsentences": "1750.04", "train_wps": "55568.1", "train_ups": "0.21", "train_wpb": "260788", "train_bsz": "1750", "train_num_updates": "58821", "train_lr": "0.000463558", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.7", "train_wall": "6913"}
[2024-10-09 11:23:56,205][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:23:56,210][fairseq.trainer][INFO] - begin training epoch 1227
[2024-10-09 11:23:56,210][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:25:51,973][fairseq_cli.train][INFO] - end of epoch 1227 (average epoch stats below)
[2024-10-09 11:25:51,980][train][INFO] - {"epoch": 1227, "train_loss": "0.49", "train_ntokens": "260816", "train_nsentences": "1750.04", "train_wps": "54620.3", "train_ups": "0.21", "train_wpb": "260816", "train_bsz": "1750", "train_num_updates": "58869", "train_lr": "0.000463493", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.4", "train_wall": "7080"}
[2024-10-09 11:25:52,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:25:52,062][fairseq.trainer][INFO] - begin training epoch 1228
[2024-10-09 11:25:52,063][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:27:25,549][fairseq_cli.train][INFO] - end of epoch 1227 (average epoch stats below)
[2024-10-09 11:27:25,556][train][INFO] - {"epoch": 1227, "train_loss": "0.49", "train_ntokens": "260816", "train_nsentences": "1750.04", "train_wps": "59728.2", "train_ups": "0.23", "train_wpb": "260816", "train_bsz": "1750", "train_num_updates": "58869", "train_lr": "0.000463493", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "79", "train_gb_free": "39.4", "train_wall": "7123"}
[2024-10-09 11:27:25,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:27:25,825][fairseq.trainer][INFO] - begin training epoch 1228
[2024-10-09 11:27:25,826][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:29:24,877][fairseq_cli.train][INFO] - end of epoch 1228 (average epoch stats below)
[2024-10-09 11:29:24,889][train][INFO] - {"epoch": 1228, "train_loss": "0.494", "train_ntokens": "260446", "train_nsentences": "1750.04", "train_wps": "58718.2", "train_ups": "0.23", "train_wpb": "260446", "train_bsz": "1750", "train_num_updates": "58917", "train_lr": "0.000463428", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "39.3", "train_wall": "7293"}
[2024-10-09 11:29:25,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:29:25,074][fairseq.trainer][INFO] - begin training epoch 1229
[2024-10-09 11:29:25,075][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:31:11,357][fairseq_cli.train][INFO] - end of epoch 1228 (average epoch stats below)
[2024-10-09 11:31:11,373][train][INFO] - {"epoch": 1228, "train_loss": "0.494", "train_ntokens": "260446", "train_nsentences": "1750.04", "train_wps": "55361.4", "train_ups": "0.21", "train_wpb": "260446", "train_bsz": "1750", "train_num_updates": "58917", "train_lr": "0.000463428", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "7349"}
[2024-10-09 11:31:11,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:31:11,560][fairseq.trainer][INFO] - begin training epoch 1229
[2024-10-09 11:31:11,560][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:33:00,777][fairseq_cli.train][INFO] - end of epoch 1229 (average epoch stats below)
[2024-10-09 11:33:00,784][train][INFO] - {"epoch": 1229, "train_loss": "0.486", "train_ntokens": "260182", "train_nsentences": "1750.04", "train_wps": "57847.1", "train_ups": "0.22", "train_wpb": "260182", "train_bsz": "1750", "train_num_updates": "58965", "train_lr": "0.000463363", "train_gnorm": "0.344", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "40.1", "train_wall": "7509"}
[2024-10-09 11:33:00,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:33:01,004][fairseq.trainer][INFO] - begin training epoch 1230
[2024-10-09 11:33:01,004][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:34:40,775][fairseq_cli.train][INFO] - end of epoch 1229 (average epoch stats below)
[2024-10-09 11:34:40,778][train][INFO] - {"epoch": 1229, "train_loss": "0.485", "train_ntokens": "260182", "train_nsentences": "1750.04", "train_wps": "59646.9", "train_ups": "0.23", "train_wpb": "260182", "train_bsz": "1750", "train_num_updates": "58965", "train_lr": "0.000463363", "train_gnorm": "0.344", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "7558"}
[2024-10-09 11:34:40,923][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:34:40,931][fairseq.trainer][INFO] - begin training epoch 1230
[2024-10-09 11:34:40,931][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:36:05,002][train_inner][INFO] - {"epoch": 1230, "update": 1229.729, "loss": "0.493", "ntokens": "260529", "nsentences": "1751.05", "wps": "60220.3", "ups": "0.23", "wpb": "260529", "bsz": "1751", "num_updates": "59000", "lr": "0.000463315", "gnorm": "0.364", "loss_scale": "2", "train_wall": "246", "gb_free": "39.9", "wall": "7693"}
[2024-10-09 11:36:19,541][fairseq_cli.train][INFO] - end of epoch 1230 (average epoch stats below)
[2024-10-09 11:36:19,543][train][INFO] - {"epoch": 1230, "train_loss": "0.492", "train_ntokens": "261048", "train_nsentences": "1750.04", "train_wps": "63043.5", "train_ups": "0.24", "train_wpb": "261048", "train_bsz": "1750", "train_num_updates": "59013", "train_lr": "0.000463298", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "39.9", "train_wall": "7708"}
[2024-10-09 11:36:19,690][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:36:19,695][fairseq.trainer][INFO] - begin training epoch 1231
[2024-10-09 11:36:19,696][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:37:43,428][train_inner][INFO] - {"epoch": 1230, "update": 1229.729, "loss": "0.493", "ntokens": "260529", "nsentences": "1751.05", "wps": "61677.1", "ups": "0.24", "wpb": "260529", "bsz": "1751", "num_updates": "59000", "lr": "0.000463315", "gnorm": "0.365", "loss_scale": "2", "train_wall": "248", "gb_free": "39.9", "wall": "7741"}
[2024-10-09 11:37:57,895][fairseq_cli.train][INFO] - end of epoch 1230 (average epoch stats below)
[2024-10-09 11:37:57,897][train][INFO] - {"epoch": 1230, "train_loss": "0.492", "train_ntokens": "261048", "train_nsentences": "1750.04", "train_wps": "63568.3", "train_ups": "0.24", "train_wpb": "261048", "train_bsz": "1750", "train_num_updates": "59013", "train_lr": "0.000463298", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "39.9", "train_wall": "7755"}
[2024-10-09 11:37:58,078][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:37:58,082][fairseq.trainer][INFO] - begin training epoch 1231
[2024-10-09 11:37:58,087][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:39:41,846][fairseq_cli.train][INFO] - end of epoch 1231 (average epoch stats below)
[2024-10-09 11:39:41,855][train][INFO] - {"epoch": 1231, "train_loss": "0.495", "train_ntokens": "260821", "train_nsentences": "1750.04", "train_wps": "61882.9", "train_ups": "0.24", "train_wpb": "260821", "train_bsz": "1750", "train_num_updates": "59061", "train_lr": "0.000463232", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "39.8", "train_wall": "7910"}
[2024-10-09 11:39:41,974][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:39:41,994][fairseq.trainer][INFO] - begin training epoch 1232
[2024-10-09 11:39:41,994][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:41:17,411][fairseq_cli.train][INFO] - end of epoch 1231 (average epoch stats below)
[2024-10-09 11:41:17,416][train][INFO] - {"epoch": 1231, "train_loss": "0.495", "train_ntokens": "260821", "train_nsentences": "1750.04", "train_wps": "62748.5", "train_ups": "0.24", "train_wpb": "260821", "train_bsz": "1750", "train_num_updates": "59061", "train_lr": "0.000463232", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.8", "train_wall": "7955"}
[2024-10-09 11:41:17,521][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:41:17,527][fairseq.trainer][INFO] - begin training epoch 1232
[2024-10-09 11:41:17,528][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:43:15,588][fairseq_cli.train][INFO] - end of epoch 1232 (average epoch stats below)
[2024-10-09 11:43:15,607][train][INFO] - {"epoch": 1232, "train_loss": "0.489", "train_ntokens": "260439", "train_nsentences": "1750.04", "train_wps": "58486.7", "train_ups": "0.22", "train_wpb": "260439", "train_bsz": "1750", "train_num_updates": "59109", "train_lr": "0.000463167", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.4", "train_wall": "8124"}
[2024-10-09 11:43:15,878][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:43:15,884][fairseq.trainer][INFO] - begin training epoch 1233
[2024-10-09 11:43:15,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:44:36,029][fairseq_cli.train][INFO] - end of epoch 1232 (average epoch stats below)
[2024-10-09 11:44:36,033][train][INFO] - {"epoch": 1232, "train_loss": "0.488", "train_ntokens": "260439", "train_nsentences": "1750.04", "train_wps": "62942", "train_ups": "0.24", "train_wpb": "260439", "train_bsz": "1750", "train_num_updates": "59109", "train_lr": "0.000463167", "train_gnorm": "0.359", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.4", "train_wall": "8154"}
[2024-10-09 11:44:36,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:44:36,185][fairseq.trainer][INFO] - begin training epoch 1233
[2024-10-09 11:44:36,186][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:46:26,398][fairseq_cli.train][INFO] - end of epoch 1233 (average epoch stats below)
[2024-10-09 11:46:26,437][train][INFO] - {"epoch": 1233, "train_loss": "0.484", "train_ntokens": "260783", "train_nsentences": "1750.04", "train_wps": "65599.9", "train_ups": "0.25", "train_wpb": "260782", "train_bsz": "1750", "train_num_updates": "59157", "train_lr": "0.000463102", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.3", "train_wall": "8315"}
[2024-10-09 11:46:26,816][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:46:26,828][fairseq.trainer][INFO] - begin training epoch 1234
[2024-10-09 11:46:26,829][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:47:50,459][fairseq_cli.train][INFO] - end of epoch 1233 (average epoch stats below)
[2024-10-09 11:47:50,463][train][INFO] - {"epoch": 1233, "train_loss": "0.484", "train_ntokens": "260783", "train_nsentences": "1750.04", "train_wps": "64381.4", "train_ups": "0.25", "train_wpb": "260782", "train_bsz": "1750", "train_num_updates": "59157", "train_lr": "0.000463102", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.3", "train_wall": "8348"}
[2024-10-09 11:47:50,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:47:50,593][fairseq.trainer][INFO] - begin training epoch 1234
[2024-10-09 11:47:50,594][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:49:34,355][train_inner][INFO] - {"epoch": 1234, "update": 1233.896, "loss": "0.489", "ntokens": "260783", "nsentences": "1747.8", "wps": "64443.8", "ups": "0.25", "wpb": "260783", "bsz": "1747.8", "num_updates": "59200", "lr": "0.000463043", "gnorm": "0.383", "loss_scale": "2", "train_wall": "263", "gb_free": "39.6", "wall": "8503"}
[2024-10-09 11:49:36,261][fairseq_cli.train][INFO] - end of epoch 1234 (average epoch stats below)
[2024-10-09 11:49:36,264][train][INFO] - {"epoch": 1234, "train_loss": "0.496", "train_ntokens": "260658", "train_nsentences": "1750.04", "train_wps": "65911.7", "train_ups": "0.25", "train_wpb": "260658", "train_bsz": "1750", "train_num_updates": "59205", "train_lr": "0.000463037", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "36", "train_gb_free": "39.6", "train_wall": "8505"}
[2024-10-09 11:49:36,444][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:49:36,460][fairseq.trainer][INFO] - begin training epoch 1235
[2024-10-09 11:49:36,460][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:51:00,595][train_inner][INFO] - {"epoch": 1234, "update": 1233.896, "loss": "0.489", "ntokens": "260783", "nsentences": "1747.8", "wps": "65429.2", "ups": "0.25", "wpb": "260783", "bsz": "1747.8", "num_updates": "59200", "lr": "0.000463043", "gnorm": "0.383", "loss_scale": "2", "train_wall": "270", "gb_free": "39.6", "wall": "8538"}
[2024-10-09 11:51:03,090][fairseq_cli.train][INFO] - end of epoch 1234 (average epoch stats below)
[2024-10-09 11:51:03,092][train][INFO] - {"epoch": 1234, "train_loss": "0.496", "train_ntokens": "260658", "train_nsentences": "1750.04", "train_wps": "64952.6", "train_ups": "0.25", "train_wpb": "260658", "train_bsz": "1750", "train_num_updates": "59205", "train_lr": "0.000463037", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "54", "train_gb_free": "39.6", "train_wall": "8541"}
[2024-10-09 11:51:03,250][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:51:03,265][fairseq.trainer][INFO] - begin training epoch 1235
[2024-10-09 11:51:03,266][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:53:02,321][fairseq_cli.train][INFO] - end of epoch 1235 (average epoch stats below)
[2024-10-09 11:53:02,324][train][INFO] - {"epoch": 1235, "train_loss": "0.486", "train_ntokens": "260215", "train_nsentences": "1750.04", "train_wps": "60615.5", "train_ups": "0.23", "train_wpb": "260215", "train_bsz": "1750", "train_num_updates": "59253", "train_lr": "0.000462971", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "87", "train_gb_free": "39.6", "train_wall": "8711"}
[2024-10-09 11:53:02,528][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:53:02,551][fairseq.trainer][INFO] - begin training epoch 1236
[2024-10-09 11:53:02,552][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:54:54,532][fairseq_cli.train][INFO] - end of epoch 1235 (average epoch stats below)
[2024-10-09 11:54:54,551][train][INFO] - {"epoch": 1235, "train_loss": "0.486", "train_ntokens": "260215", "train_nsentences": "1750.04", "train_wps": "53965.4", "train_ups": "0.21", "train_wpb": "260215", "train_bsz": "1750", "train_num_updates": "59253", "train_lr": "0.000462971", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.6", "train_wall": "8772"}
[2024-10-09 11:54:54,788][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:54:54,820][fairseq.trainer][INFO] - begin training epoch 1236
[2024-10-09 11:54:54,823][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:56:50,901][fairseq_cli.train][INFO] - end of epoch 1236 (average epoch stats below)
[2024-10-09 11:56:50,912][train][INFO] - {"epoch": 1236, "train_loss": "0.485", "train_ntokens": "260610", "train_nsentences": "1750.04", "train_wps": "54725.4", "train_ups": "0.21", "train_wpb": "260610", "train_bsz": "1750", "train_num_updates": "59301", "train_lr": "0.000462906", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "8939"}
[2024-10-09 11:56:51,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:56:51,203][fairseq.trainer][INFO] - begin training epoch 1237
[2024-10-09 11:56:51,204][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 11:58:47,774][fairseq_cli.train][INFO] - end of epoch 1236 (average epoch stats below)
[2024-10-09 11:58:47,803][train][INFO] - {"epoch": 1236, "train_loss": "0.485", "train_ntokens": "260610", "train_nsentences": "1750.04", "train_wps": "53632.9", "train_ups": "0.21", "train_wpb": "260610", "train_bsz": "1750", "train_num_updates": "59301", "train_lr": "0.000462906", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.7", "train_wall": "9005"}
[2024-10-09 11:58:47,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 11:58:47,978][fairseq.trainer][INFO] - begin training epoch 1237
[2024-10-09 11:58:47,978][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:00:34,941][fairseq_cli.train][INFO] - end of epoch 1237 (average epoch stats below)
[2024-10-09 12:00:34,950][train][INFO] - {"epoch": 1237, "train_loss": "0.483", "train_ntokens": "260861", "train_nsentences": "1750.04", "train_wps": "55890.3", "train_ups": "0.21", "train_wpb": "260861", "train_bsz": "1750", "train_num_updates": "59349", "train_lr": "0.000462841", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "33", "train_gb_free": "39.7", "train_wall": "9163"}
[2024-10-09 12:00:35,204][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:00:35,209][fairseq.trainer][INFO] - begin training epoch 1238
[2024-10-09 12:00:35,223][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:02:23,465][fairseq_cli.train][INFO] - end of epoch 1237 (average epoch stats below)
[2024-10-09 12:02:23,477][train][INFO] - {"epoch": 1237, "train_loss": "0.483", "train_ntokens": "260861", "train_nsentences": "1750.04", "train_wps": "58058.5", "train_ups": "0.22", "train_wpb": "260861", "train_bsz": "1750", "train_num_updates": "59349", "train_lr": "0.000462841", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "35", "train_gb_free": "39.7", "train_wall": "9221"}
[2024-10-09 12:02:23,739][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:02:23,742][fairseq.trainer][INFO] - begin training epoch 1238
[2024-10-09 12:02:23,742][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:04:23,797][fairseq_cli.train][INFO] - end of epoch 1238 (average epoch stats below)
[2024-10-09 12:04:23,812][train][INFO] - {"epoch": 1238, "train_loss": "0.491", "train_ntokens": "260848", "train_nsentences": "1750.04", "train_wps": "54713.9", "train_ups": "0.21", "train_wpb": "260848", "train_bsz": "1750", "train_num_updates": "59397", "train_lr": "0.000462776", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "40.3", "train_wall": "9392"}
[2024-10-09 12:04:24,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:04:24,040][fairseq.trainer][INFO] - begin training epoch 1239
[2024-10-09 12:04:24,041][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:06:13,871][fairseq_cli.train][INFO] - end of epoch 1238 (average epoch stats below)
[2024-10-09 12:06:13,882][train][INFO] - {"epoch": 1238, "train_loss": "0.491", "train_ntokens": "260848", "train_nsentences": "1750.04", "train_wps": "54348.2", "train_ups": "0.21", "train_wpb": "260848", "train_bsz": "1750", "train_num_updates": "59397", "train_lr": "0.000462776", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "40.3", "train_wall": "9451"}
[2024-10-09 12:06:14,066][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:06:14,071][fairseq.trainer][INFO] - begin training epoch 1239
[2024-10-09 12:06:14,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:07:18,857][train_inner][INFO] - {"epoch": 1239, "update": 1238.062, "loss": "0.487", "ntokens": "260663", "nsentences": "1753.6", "wps": "48974", "ups": "0.19", "wpb": "260663", "bsz": "1753.6", "num_updates": "59400", "lr": "0.000462772", "gnorm": "0.374", "loss_scale": "2", "train_wall": "261", "gb_free": "39.3", "wall": "9567"}
[2024-10-09 12:08:07,634][fairseq_cli.train][INFO] - end of epoch 1239 (average epoch stats below)
[2024-10-09 12:08:07,636][train][INFO] - {"epoch": 1239, "train_loss": "0.49", "train_ntokens": "260889", "train_nsentences": "1750.04", "train_wps": "55949.3", "train_ups": "0.21", "train_wpb": "260889", "train_bsz": "1750", "train_num_updates": "59445", "train_lr": "0.000462711", "train_gnorm": "0.353", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "40.5", "train_wall": "9616"}
[2024-10-09 12:08:07,780][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:08:07,796][fairseq.trainer][INFO] - begin training epoch 1240
[2024-10-09 12:08:07,797][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:09:10,028][train_inner][INFO] - {"epoch": 1239, "update": 1238.062, "loss": "0.487", "ntokens": "260663", "nsentences": "1753.6", "wps": "47853.9", "ups": "0.18", "wpb": "260663", "bsz": "1753.6", "num_updates": "59400", "lr": "0.000462772", "gnorm": "0.374", "loss_scale": "2", "train_wall": "233", "gb_free": "39.3", "wall": "9628"}
[2024-10-09 12:09:52,543][fairseq_cli.train][INFO] - end of epoch 1239 (average epoch stats below)
[2024-10-09 12:09:52,545][train][INFO] - {"epoch": 1239, "train_loss": "0.49", "train_ntokens": "260889", "train_nsentences": "1750.04", "train_wps": "57278", "train_ups": "0.22", "train_wpb": "260889", "train_bsz": "1750", "train_num_updates": "59445", "train_lr": "0.000462711", "train_gnorm": "0.356", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "40.5", "train_wall": "9670"}
[2024-10-09 12:09:52,701][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:09:52,712][fairseq.trainer][INFO] - begin training epoch 1240
[2024-10-09 12:09:52,713][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:11:43,428][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1240 @ 59493 updates
[2024-10-09 12:11:43,429][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 12:11:46,946][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 12:11:46,949][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1240 @ 59493 updates, score None) (writing took 3.5213147504255176 seconds)
[2024-10-09 12:11:46,949][fairseq_cli.train][INFO] - end of epoch 1240 (average epoch stats below)
[2024-10-09 12:11:46,952][train][INFO] - {"epoch": 1240, "train_loss": "0.482", "train_ntokens": "260413", "train_nsentences": "1750.04", "train_wps": "56995.5", "train_ups": "0.22", "train_wpb": "260413", "train_bsz": "1750", "train_num_updates": "59493", "train_lr": "0.000462645", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.6", "train_wall": "9835"}
[2024-10-09 12:11:47,032][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:11:47,045][fairseq.trainer][INFO] - begin training epoch 1241
[2024-10-09 12:11:47,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:13:21,311][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1240 @ 59493 updates
[2024-10-09 12:13:21,312][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 12:13:25,476][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 12:13:25,479][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1240 @ 59493 updates, score None) (writing took 4.168221855536103 seconds)
[2024-10-09 12:13:25,480][fairseq_cli.train][INFO] - end of epoch 1240 (average epoch stats below)
[2024-10-09 12:13:25,484][train][INFO] - {"epoch": 1240, "train_loss": "0.481", "train_ntokens": "260413", "train_nsentences": "1750.04", "train_wps": "58702.9", "train_ups": "0.23", "train_wpb": "260413", "train_bsz": "1750", "train_num_updates": "59493", "train_lr": "0.000462645", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.6", "train_wall": "9883"}
[2024-10-09 12:13:25,669][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:13:25,691][fairseq.trainer][INFO] - begin training epoch 1241
[2024-10-09 12:13:25,691][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:14:54,505][fairseq_cli.train][INFO] - end of epoch 1241 (average epoch stats below)
[2024-10-09 12:14:54,516][train][INFO] - {"epoch": 1241, "train_loss": "0.49", "train_ntokens": "260798", "train_nsentences": "1750.04", "train_wps": "66742.7", "train_ups": "0.26", "train_wpb": "260798", "train_bsz": "1750", "train_num_updates": "59541", "train_lr": "0.00046258", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.6", "train_wall": "10023"}
[2024-10-09 12:14:54,673][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:14:54,687][fairseq.trainer][INFO] - begin training epoch 1242
[2024-10-09 12:14:54,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:16:55,637][fairseq_cli.train][INFO] - end of epoch 1241 (average epoch stats below)
[2024-10-09 12:16:55,734][train][INFO] - {"epoch": 1241, "train_loss": "0.49", "train_ntokens": "260798", "train_nsentences": "1750.04", "train_wps": "59541.2", "train_ups": "0.23", "train_wpb": "260798", "train_bsz": "1750", "train_num_updates": "59541", "train_lr": "0.00046258", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.6", "train_wall": "10093"}
[2024-10-09 12:16:57,761][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:16:57,874][fairseq.trainer][INFO] - begin training epoch 1242
[2024-10-09 12:16:57,875][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:18:17,023][fairseq_cli.train][INFO] - end of epoch 1242 (average epoch stats below)
[2024-10-09 12:18:17,034][train][INFO] - {"epoch": 1242, "train_loss": "0.485", "train_ntokens": "260714", "train_nsentences": "1750.04", "train_wps": "61794.2", "train_ups": "0.24", "train_wpb": "260714", "train_bsz": "1750", "train_num_updates": "59589", "train_lr": "0.000462515", "train_gnorm": "0.359", "train_loss_scale": "2", "train_train_wall": "76", "train_gb_free": "39.7", "train_wall": "10225"}
[2024-10-09 12:18:17,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:18:17,181][fairseq.trainer][INFO] - begin training epoch 1243
[2024-10-09 12:18:17,182][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:20:42,837][fairseq_cli.train][INFO] - end of epoch 1242 (average epoch stats below)
[2024-10-09 12:20:42,860][train][INFO] - {"epoch": 1242, "train_loss": "0.485", "train_ntokens": "260714", "train_nsentences": "1750.04", "train_wps": "55102.1", "train_ups": "0.21", "train_wpb": "260714", "train_bsz": "1750", "train_num_updates": "59589", "train_lr": "0.000462515", "train_gnorm": "0.359", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.7", "train_wall": "10320"}
[2024-10-09 12:20:43,078][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:20:43,088][fairseq.trainer][INFO] - begin training epoch 1243
[2024-10-09 12:20:43,089][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:21:06,751][train_inner][INFO] - {"epoch": 1243, "update": 1242.229, "loss": "0.487", "ntokens": "260521", "nsentences": "1756.3", "wps": "62939.5", "ups": "0.24", "wpb": "260522", "bsz": "1756.3", "num_updates": "59600", "lr": "0.0004625", "gnorm": "0.373", "loss_scale": "2", "train_wall": "329", "gb_free": "39.6", "wall": "10395"}
[2024-10-09 12:21:47,101][fairseq_cli.train][INFO] - end of epoch 1243 (average epoch stats below)
[2024-10-09 12:21:47,106][train][INFO] - {"epoch": 1243, "train_loss": "0.492", "train_ntokens": "260737", "train_nsentences": "1750.04", "train_wps": "59578.2", "train_ups": "0.23", "train_wpb": "260737", "train_bsz": "1750", "train_num_updates": "59637", "train_lr": "0.00046245", "train_gnorm": "0.361", "train_loss_scale": "2", "train_train_wall": "95", "train_gb_free": "40.7", "train_wall": "10435"}
[2024-10-09 12:21:47,343][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:21:47,347][fairseq.trainer][INFO] - begin training epoch 1244
[2024-10-09 12:21:47,348][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:23:26,611][train_inner][INFO] - {"epoch": 1243, "update": 1242.229, "loss": "0.487", "ntokens": "260521", "nsentences": "1756.3", "wps": "60830.7", "ups": "0.23", "wpb": "260522", "bsz": "1756.3", "num_updates": "59600", "lr": "0.0004625", "gnorm": "0.374", "loss_scale": "2", "train_wall": "294", "gb_free": "39.6", "wall": "10484"}
[2024-10-09 12:24:00,121][fairseq_cli.train][INFO] - end of epoch 1243 (average epoch stats below)
[2024-10-09 12:24:00,124][train][INFO] - {"epoch": 1243, "train_loss": "0.492", "train_ntokens": "260737", "train_nsentences": "1750.04", "train_wps": "63445.9", "train_ups": "0.24", "train_wpb": "260737", "train_bsz": "1750", "train_num_updates": "59637", "train_lr": "0.00046245", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "40.7", "train_wall": "10518"}
[2024-10-09 12:24:00,720][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:24:00,728][fairseq.trainer][INFO] - begin training epoch 1244
[2024-10-09 12:24:00,730][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:25:20,141][fairseq_cli.train][INFO] - end of epoch 1244 (average epoch stats below)
[2024-10-09 12:25:20,151][train][INFO] - {"epoch": 1244, "train_loss": "0.491", "train_ntokens": "260798", "train_nsentences": "1750.04", "train_wps": "58759.8", "train_ups": "0.23", "train_wpb": "260798", "train_bsz": "1750", "train_num_updates": "59685", "train_lr": "0.000462385", "train_gnorm": "0.369", "train_loss_scale": "4", "train_train_wall": "69", "train_gb_free": "39.8", "train_wall": "10648"}
[2024-10-09 12:25:20,288][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:25:20,303][fairseq.trainer][INFO] - begin training epoch 1245
[2024-10-09 12:25:20,304][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:27:16,682][fairseq_cli.train][INFO] - end of epoch 1244 (average epoch stats below)
[2024-10-09 12:27:16,723][train][INFO] - {"epoch": 1244, "train_loss": "0.491", "train_ntokens": "260798", "train_nsentences": "1750.04", "train_wps": "63678", "train_ups": "0.24", "train_wpb": "260798", "train_bsz": "1750", "train_num_updates": "59685", "train_lr": "0.000462385", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "70", "train_gb_free": "39.8", "train_wall": "10714"}
[2024-10-09 12:27:17,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:27:17,618][fairseq.trainer][INFO] - begin training epoch 1245
[2024-10-09 12:27:17,619][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:28:34,811][fairseq_cli.train][INFO] - end of epoch 1245 (average epoch stats below)
[2024-10-09 12:28:34,827][train][INFO] - {"epoch": 1245, "train_loss": "0.489", "train_ntokens": "260808", "train_nsentences": "1750.04", "train_wps": "64309.2", "train_ups": "0.25", "train_wpb": "260808", "train_bsz": "1750", "train_num_updates": "59733", "train_lr": "0.000462319", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "63", "train_gb_free": "39.2", "train_wall": "10843"}
[2024-10-09 12:28:34,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:28:34,978][fairseq.trainer][INFO] - begin training epoch 1246
[2024-10-09 12:28:34,978][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:30:30,804][fairseq_cli.train][INFO] - end of epoch 1245 (average epoch stats below)
[2024-10-09 12:30:30,866][train][INFO] - {"epoch": 1245, "train_loss": "0.489", "train_ntokens": "260808", "train_nsentences": "1750.04", "train_wps": "64484.2", "train_ups": "0.25", "train_wpb": "260808", "train_bsz": "1750", "train_num_updates": "59733", "train_lr": "0.000462319", "train_gnorm": "0.383", "train_loss_scale": "4", "train_train_wall": "79", "train_gb_free": "39.2", "train_wall": "10908"}
[2024-10-09 12:30:32,787][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:30:33,066][fairseq.trainer][INFO] - begin training epoch 1246
[2024-10-09 12:30:33,067][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:31:52,758][fairseq_cli.train][INFO] - end of epoch 1246 (average epoch stats below)
[2024-10-09 12:31:52,771][train][INFO] - {"epoch": 1246, "train_loss": "0.49", "train_ntokens": "260698", "train_nsentences": "1750.04", "train_wps": "63219", "train_ups": "0.24", "train_wpb": "260698", "train_bsz": "1750", "train_num_updates": "59781", "train_lr": "0.000462254", "train_gnorm": "0.406", "train_loss_scale": "4", "train_train_wall": "66", "train_gb_free": "39.8", "train_wall": "11041"}
[2024-10-09 12:31:52,953][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:31:52,958][fairseq.trainer][INFO] - begin training epoch 1247
[2024-10-09 12:31:52,958][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:34:12,486][fairseq_cli.train][INFO] - end of epoch 1246 (average epoch stats below)
[2024-10-09 12:34:12,503][train][INFO] - {"epoch": 1246, "train_loss": "0.49", "train_ntokens": "260698", "train_nsentences": "1750.04", "train_wps": "56461.8", "train_ups": "0.22", "train_wpb": "260698", "train_bsz": "1750", "train_num_updates": "59781", "train_lr": "0.000462254", "train_gnorm": "0.405", "train_loss_scale": "4", "train_train_wall": "89", "train_gb_free": "39.8", "train_wall": "11130"}
[2024-10-09 12:34:12,733][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:34:12,740][fairseq.trainer][INFO] - begin training epoch 1247
[2024-10-09 12:34:12,741][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:34:38,427][train_inner][INFO] - {"epoch": 1247, "update": 1246.396, "loss": "0.489", "ntokens": "261038", "nsentences": "1728.57", "wps": "64321.5", "ups": "0.25", "wpb": "261038", "bsz": "1728.6", "num_updates": "59800", "lr": "0.000462228", "gnorm": "0.382", "loss_scale": "4", "train_wall": "270", "gb_free": "39.6", "wall": "11207"}
[2024-10-09 12:35:04,245][fairseq_cli.train][INFO] - end of epoch 1247 (average epoch stats below)
[2024-10-09 12:35:04,248][train][INFO] - {"epoch": 1247, "train_loss": "0.483", "train_ntokens": "261357", "train_nsentences": "1750.04", "train_wps": "65518.4", "train_ups": "0.25", "train_wpb": "261357", "train_bsz": "1750", "train_num_updates": "59829", "train_lr": "0.000462189", "train_gnorm": "0.368", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "39.8", "train_wall": "11233"}
[2024-10-09 12:35:04,358][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:35:04,366][fairseq.trainer][INFO] - begin training epoch 1248
[2024-10-09 12:35:04,367][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:36:37,889][train_inner][INFO] - {"epoch": 1247, "update": 1246.396, "loss": "0.489", "ntokens": "261038", "nsentences": "1728.57", "wps": "65981.8", "ups": "0.25", "wpb": "261038", "bsz": "1728.6", "num_updates": "59800", "lr": "0.000462228", "gnorm": "0.382", "loss_scale": "4", "train_wall": "292", "gb_free": "39.6", "wall": "11275"}
[2024-10-09 12:37:18,846][fairseq_cli.train][INFO] - end of epoch 1247 (average epoch stats below)
[2024-10-09 12:37:18,856][train][INFO] - {"epoch": 1247, "train_loss": "0.483", "train_ntokens": "261357", "train_nsentences": "1750.04", "train_wps": "67323.9", "train_ups": "0.26", "train_wpb": "261357", "train_bsz": "1750", "train_num_updates": "59829", "train_lr": "0.000462189", "train_gnorm": "0.368", "train_loss_scale": "4", "train_train_wall": "62", "train_gb_free": "39.8", "train_wall": "11316"}
[2024-10-09 12:37:19,173][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:37:19,180][fairseq.trainer][INFO] - begin training epoch 1248
[2024-10-09 12:37:19,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:37:33,876][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 12:38:12,845][fairseq_cli.train][INFO] - end of epoch 1248 (average epoch stats below)
[2024-10-09 12:38:12,848][train][INFO] - {"epoch": 1248, "train_loss": "0.486", "train_ntokens": "260933", "train_nsentences": "1751.06", "train_wps": "65026.8", "train_ups": "0.25", "train_wpb": "260933", "train_bsz": "1751.1", "train_num_updates": "59876", "train_lr": "0.000462125", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "40.1", "train_wall": "11421"}
[2024-10-09 12:38:12,932][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:38:12,936][fairseq.trainer][INFO] - begin training epoch 1249
[2024-10-09 12:38:12,936][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:39:28,029][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 12:40:30,735][fairseq_cli.train][INFO] - end of epoch 1248 (average epoch stats below)
[2024-10-09 12:40:30,748][train][INFO] - {"epoch": 1248, "train_loss": "0.486", "train_ntokens": "260933", "train_nsentences": "1751.06", "train_wps": "63914", "train_ups": "0.24", "train_wpb": "260933", "train_bsz": "1751.1", "train_num_updates": "59876", "train_lr": "0.000462125", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "40.1", "train_wall": "11508"}
[2024-10-09 12:40:30,953][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:40:30,956][fairseq.trainer][INFO] - begin training epoch 1249
[2024-10-09 12:40:30,957][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:41:26,005][fairseq_cli.train][INFO] - end of epoch 1249 (average epoch stats below)
[2024-10-09 12:41:26,008][train][INFO] - {"epoch": 1249, "train_loss": "0.487", "train_ntokens": "260392", "train_nsentences": "1750.04", "train_wps": "64707.9", "train_ups": "0.25", "train_wpb": "260392", "train_bsz": "1750", "train_num_updates": "59924", "train_lr": "0.00046206", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.8", "train_wall": "11614"}
[2024-10-09 12:41:26,171][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:41:26,174][fairseq.trainer][INFO] - begin training epoch 1250
[2024-10-09 12:41:26,175][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:43:56,122][fairseq_cli.train][INFO] - end of epoch 1249 (average epoch stats below)
[2024-10-09 12:43:56,199][train][INFO] - {"epoch": 1249, "train_loss": "0.487", "train_ntokens": "260392", "train_nsentences": "1750.04", "train_wps": "60841", "train_ups": "0.23", "train_wpb": "260392", "train_bsz": "1750", "train_num_updates": "59924", "train_lr": "0.00046206", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "99", "train_gb_free": "39.8", "train_wall": "11714"}
[2024-10-09 12:43:57,927][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:43:58,090][fairseq.trainer][INFO] - begin training epoch 1250
[2024-10-09 12:43:58,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:45:17,300][fairseq_cli.train][INFO] - end of epoch 1250 (average epoch stats below)
[2024-10-09 12:45:17,313][train][INFO] - {"epoch": 1250, "train_loss": "0.488", "train_ntokens": "260447", "train_nsentences": "1750.04", "train_wps": "54048.3", "train_ups": "0.21", "train_wpb": "260447", "train_bsz": "1750", "train_num_updates": "59972", "train_lr": "0.000461995", "train_gnorm": "0.353", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "40.1", "train_wall": "11846"}
[2024-10-09 12:45:17,508][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:45:17,525][fairseq.trainer][INFO] - begin training epoch 1251
[2024-10-09 12:45:17,539][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:47:36,655][fairseq_cli.train][INFO] - end of epoch 1250 (average epoch stats below)
[2024-10-09 12:47:36,724][train][INFO] - {"epoch": 1250, "train_loss": "0.488", "train_ntokens": "260447", "train_nsentences": "1750.04", "train_wps": "56690.2", "train_ups": "0.22", "train_wpb": "260447", "train_bsz": "1750", "train_num_updates": "59972", "train_lr": "0.000461995", "train_gnorm": "0.354", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "40.1", "train_wall": "11934"}
[2024-10-09 12:47:38,267][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:47:38,414][fairseq.trainer][INFO] - begin training epoch 1251
[2024-10-09 12:47:38,414][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:48:36,051][train_inner][INFO] - {"epoch": 1251, "update": 1250.583, "loss": "0.486", "ntokens": "260699", "nsentences": "1760.19", "wps": "62248.2", "ups": "0.24", "wpb": "260699", "bsz": "1760.2", "num_updates": "60000", "lr": "0.000461957", "gnorm": "0.374", "loss_scale": "2", "train_wall": "282", "gb_free": "40.3", "wall": "12044"}
[2024-10-09 12:49:01,554][fairseq_cli.train][INFO] - end of epoch 1251 (average epoch stats below)
[2024-10-09 12:49:01,557][train][INFO] - {"epoch": 1251, "train_loss": "0.48", "train_ntokens": "260636", "train_nsentences": "1750.04", "train_wps": "55790.8", "train_ups": "0.21", "train_wpb": "260636", "train_bsz": "1750", "train_num_updates": "60020", "train_lr": "0.000461929", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "80", "train_gb_free": "40.1", "train_wall": "12070"}
[2024-10-09 12:49:01,742][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:49:01,765][fairseq.trainer][INFO] - begin training epoch 1252
[2024-10-09 12:49:01,765][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:50:51,528][train_inner][INFO] - {"epoch": 1251, "update": 1250.583, "loss": "0.486", "ntokens": "260699", "nsentences": "1760.19", "wps": "61080", "ups": "0.23", "wpb": "260699", "bsz": "1760.2", "num_updates": "60000", "lr": "0.000461957", "gnorm": "0.375", "loss_scale": "2", "train_wall": "364", "gb_free": "40.3", "wall": "12129"}
[2024-10-09 12:51:15,176][fairseq_cli.train][INFO] - end of epoch 1251 (average epoch stats below)
[2024-10-09 12:51:15,178][train][INFO] - {"epoch": 1251, "train_loss": "0.48", "train_ntokens": "260636", "train_nsentences": "1750.04", "train_wps": "57269", "train_ups": "0.22", "train_wpb": "260636", "train_bsz": "1750", "train_num_updates": "60020", "train_lr": "0.000461929", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "40.1", "train_wall": "12153"}
[2024-10-09 12:51:16,323][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:51:16,438][fairseq.trainer][INFO] - begin training epoch 1252
[2024-10-09 12:51:16,438][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:52:41,653][fairseq_cli.train][INFO] - end of epoch 1252 (average epoch stats below)
[2024-10-09 12:52:41,665][train][INFO] - {"epoch": 1252, "train_loss": "0.483", "train_ntokens": "260864", "train_nsentences": "1750.04", "train_wps": "56888.6", "train_ups": "0.22", "train_wpb": "260864", "train_bsz": "1750", "train_num_updates": "60068", "train_lr": "0.000461864", "train_gnorm": "0.399", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.6", "train_wall": "12290"}
[2024-10-09 12:52:41,901][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:52:41,905][fairseq.trainer][INFO] - begin training epoch 1253
[2024-10-09 12:52:41,906][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:54:57,931][fairseq_cli.train][INFO] - end of epoch 1252 (average epoch stats below)
[2024-10-09 12:54:57,977][train][INFO] - {"epoch": 1252, "train_loss": "0.483", "train_ntokens": "260864", "train_nsentences": "1750.04", "train_wps": "56201.6", "train_ups": "0.22", "train_wpb": "260864", "train_bsz": "1750", "train_num_updates": "60068", "train_lr": "0.000461864", "train_gnorm": "0.397", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.6", "train_wall": "12376"}
[2024-10-09 12:54:59,422][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:54:59,598][fairseq.trainer][INFO] - begin training epoch 1253
[2024-10-09 12:54:59,599][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:56:32,859][fairseq_cli.train][INFO] - end of epoch 1253 (average epoch stats below)
[2024-10-09 12:56:32,870][train][INFO] - {"epoch": 1253, "train_loss": "0.489", "train_ntokens": "260494", "train_nsentences": "1750.04", "train_wps": "54081.7", "train_ups": "0.21", "train_wpb": "260494", "train_bsz": "1750", "train_num_updates": "60116", "train_lr": "0.000461799", "train_gnorm": "0.358", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.3", "train_wall": "12521"}
[2024-10-09 12:56:33,105][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:56:33,115][fairseq.trainer][INFO] - begin training epoch 1254
[2024-10-09 12:56:33,116][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 12:58:48,000][fairseq_cli.train][INFO] - end of epoch 1253 (average epoch stats below)
[2024-10-09 12:58:48,045][train][INFO] - {"epoch": 1253, "train_loss": "0.488", "train_ntokens": "260494", "train_nsentences": "1750.04", "train_wps": "54350", "train_ups": "0.21", "train_wpb": "260494", "train_bsz": "1750", "train_num_updates": "60116", "train_lr": "0.000461799", "train_gnorm": "0.358", "train_loss_scale": "2", "train_train_wall": "95", "train_gb_free": "39.3", "train_wall": "12606"}
[2024-10-09 12:58:49,081][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 12:58:49,144][fairseq.trainer][INFO] - begin training epoch 1254
[2024-10-09 12:58:49,152][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:00:13,857][fairseq_cli.train][INFO] - end of epoch 1254 (average epoch stats below)
[2024-10-09 13:00:13,865][train][INFO] - {"epoch": 1254, "train_loss": "0.493", "train_ntokens": "260364", "train_nsentences": "1750.04", "train_wps": "56551.7", "train_ups": "0.22", "train_wpb": "260364", "train_bsz": "1750", "train_num_updates": "60164", "train_lr": "0.000461734", "train_gnorm": "0.355", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.2", "train_wall": "12742"}
[2024-10-09 13:00:14,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:00:14,086][fairseq.trainer][INFO] - begin training epoch 1255
[2024-10-09 13:00:14,087][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:02:25,337][fairseq_cli.train][INFO] - end of epoch 1254 (average epoch stats below)
[2024-10-09 13:02:25,352][train][INFO] - {"epoch": 1254, "train_loss": "0.493", "train_ntokens": "260364", "train_nsentences": "1750.04", "train_wps": "57511.5", "train_ups": "0.22", "train_wpb": "260364", "train_bsz": "1750", "train_num_updates": "60164", "train_lr": "0.000461734", "train_gnorm": "0.354", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.2", "train_wall": "12823"}
[2024-10-09 13:02:26,057][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:02:26,135][fairseq.trainer][INFO] - begin training epoch 1255
[2024-10-09 13:02:26,135][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:03:50,138][train_inner][INFO] - {"epoch": 1255, "update": 1254.75, "loss": "0.485", "ntokens": "260692", "nsentences": "1738.86", "wps": "57039.3", "ups": "0.22", "wpb": "260692", "bsz": "1738.9", "num_updates": "60200", "lr": "0.000461685", "gnorm": "0.375", "loss_scale": "2", "train_wall": "306", "gb_free": "39.6", "wall": "12958"}
[2024-10-09 13:04:04,116][fairseq_cli.train][INFO] - end of epoch 1255 (average epoch stats below)
[2024-10-09 13:04:04,119][train][INFO] - {"epoch": 1255, "train_loss": "0.48", "train_ntokens": "260949", "train_nsentences": "1750.04", "train_wps": "54399.6", "train_ups": "0.21", "train_wpb": "260949", "train_bsz": "1750", "train_num_updates": "60212", "train_lr": "0.000461668", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.2", "train_wall": "12972"}
[2024-10-09 13:04:04,322][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:04:04,329][fairseq.trainer][INFO] - begin training epoch 1256
[2024-10-09 13:04:04,330][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:05:48,345][train_inner][INFO] - {"epoch": 1255, "update": 1254.75, "loss": "0.485", "ntokens": "260692", "nsentences": "1738.86", "wps": "58137.9", "ups": "0.22", "wpb": "260692", "bsz": "1738.9", "num_updates": "60200", "lr": "0.000461685", "gnorm": "0.374", "loss_scale": "2", "train_wall": "311", "gb_free": "39.6", "wall": "13026"}
[2024-10-09 13:06:01,242][fairseq_cli.train][INFO] - end of epoch 1255 (average epoch stats below)
[2024-10-09 13:06:01,244][train][INFO] - {"epoch": 1255, "train_loss": "0.48", "train_ntokens": "260949", "train_nsentences": "1750.04", "train_wps": "58018.2", "train_ups": "0.22", "train_wpb": "260949", "train_bsz": "1750", "train_num_updates": "60212", "train_lr": "0.000461668", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "84", "train_gb_free": "39.2", "train_wall": "13039"}
[2024-10-09 13:06:01,525][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:06:01,529][fairseq.trainer][INFO] - begin training epoch 1256
[2024-10-09 13:06:01,530][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:07:55,184][fairseq_cli.train][INFO] - end of epoch 1256 (average epoch stats below)
[2024-10-09 13:07:55,191][train][INFO] - {"epoch": 1256, "train_loss": "0.485", "train_ntokens": "260835", "train_nsentences": "1750.04", "train_wps": "54183.2", "train_ups": "0.21", "train_wpb": "260835", "train_bsz": "1750", "train_num_updates": "60260", "train_lr": "0.000461603", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.3", "train_wall": "13203"}
[2024-10-09 13:07:55,423][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:07:55,427][fairseq.trainer][INFO] - begin training epoch 1257
[2024-10-09 13:07:55,428][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:10:01,873][fairseq_cli.train][INFO] - end of epoch 1256 (average epoch stats below)
[2024-10-09 13:10:01,881][train][INFO] - {"epoch": 1256, "train_loss": "0.485", "train_ntokens": "260835", "train_nsentences": "1750.04", "train_wps": "52029.4", "train_ups": "0.2", "train_wpb": "260835", "train_bsz": "1750", "train_num_updates": "60260", "train_lr": "0.000461603", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "75", "train_gb_free": "39.3", "train_wall": "13279"}
[2024-10-09 13:10:02,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:10:02,169][fairseq.trainer][INFO] - begin training epoch 1257
[2024-10-09 13:10:02,172][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:11:52,771][fairseq_cli.train][INFO] - end of epoch 1257 (average epoch stats below)
[2024-10-09 13:11:52,775][train][INFO] - {"epoch": 1257, "train_loss": "0.487", "train_ntokens": "260997", "train_nsentences": "1750.04", "train_wps": "52731.1", "train_ups": "0.2", "train_wpb": "260997", "train_bsz": "1750", "train_num_updates": "60308", "train_lr": "0.000461538", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "40.2", "train_wall": "13441"}
[2024-10-09 13:11:53,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:11:53,003][fairseq.trainer][INFO] - begin training epoch 1258
[2024-10-09 13:11:53,003][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:14:03,151][fairseq_cli.train][INFO] - end of epoch 1257 (average epoch stats below)
[2024-10-09 13:14:03,157][train][INFO] - {"epoch": 1257, "train_loss": "0.487", "train_ntokens": "260997", "train_nsentences": "1750.04", "train_wps": "51924.1", "train_ups": "0.2", "train_wpb": "260997", "train_bsz": "1750", "train_num_updates": "60308", "train_lr": "0.000461538", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "40.2", "train_wall": "13521"}
[2024-10-09 13:14:03,340][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:14:03,375][fairseq.trainer][INFO] - begin training epoch 1258
[2024-10-09 13:14:03,376][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:15:45,664][fairseq_cli.train][INFO] - end of epoch 1258 (average epoch stats below)
[2024-10-09 13:15:45,672][train][INFO] - {"epoch": 1258, "train_loss": "0.486", "train_ntokens": "260281", "train_nsentences": "1750.04", "train_wps": "53644.7", "train_ups": "0.21", "train_wpb": "260281", "train_bsz": "1750", "train_num_updates": "60356", "train_lr": "0.000461473", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "79", "train_gb_free": "39.3", "train_wall": "13674"}
[2024-10-09 13:15:45,932][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:15:45,943][fairseq.trainer][INFO] - begin training epoch 1259
[2024-10-09 13:15:45,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:17:54,890][fairseq_cli.train][INFO] - end of epoch 1258 (average epoch stats below)
[2024-10-09 13:17:54,909][train][INFO] - {"epoch": 1258, "train_loss": "0.486", "train_ntokens": "260281", "train_nsentences": "1750.04", "train_wps": "53909.6", "train_ups": "0.21", "train_wpb": "260281", "train_bsz": "1750", "train_num_updates": "60356", "train_lr": "0.000461473", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.3", "train_wall": "13752"}
[2024-10-09 13:17:55,137][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:17:55,145][fairseq.trainer][INFO] - begin training epoch 1259
[2024-10-09 13:17:55,145][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:19:37,662][train_inner][INFO] - {"epoch": 1259, "update": 1258.917, "loss": "0.485", "ntokens": "260604", "nsentences": "1766.1", "wps": "55008", "ups": "0.21", "wpb": "260604", "bsz": "1766.1", "num_updates": "60400", "lr": "0.000461413", "gnorm": "0.367", "loss_scale": "2", "train_wall": "259", "gb_free": "39.6", "wall": "13906"}
[2024-10-09 13:19:39,045][fairseq_cli.train][INFO] - end of epoch 1259 (average epoch stats below)
[2024-10-09 13:19:39,052][train][INFO] - {"epoch": 1259, "train_loss": "0.481", "train_ntokens": "260816", "train_nsentences": "1750.04", "train_wps": "53644.6", "train_ups": "0.21", "train_wpb": "260816", "train_bsz": "1750", "train_num_updates": "60404", "train_lr": "0.000461408", "train_gnorm": "0.359", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.4", "train_wall": "13907"}
[2024-10-09 13:19:39,147][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:19:39,153][fairseq.trainer][INFO] - begin training epoch 1260
[2024-10-09 13:19:39,154][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:21:33,451][train_inner][INFO] - {"epoch": 1259, "update": 1258.917, "loss": "0.485", "ntokens": "260604", "nsentences": "1766.1", "wps": "55149.4", "ups": "0.21", "wpb": "260604", "bsz": "1766.1", "num_updates": "60400", "lr": "0.000461413", "gnorm": "0.368", "loss_scale": "2", "train_wall": "291", "gb_free": "39.6", "wall": "13971"}
[2024-10-09 13:21:35,312][fairseq_cli.train][INFO] - end of epoch 1259 (average epoch stats below)
[2024-10-09 13:21:35,314][train][INFO] - {"epoch": 1259, "train_loss": "0.481", "train_ntokens": "260816", "train_nsentences": "1750.04", "train_wps": "56801.6", "train_ups": "0.22", "train_wpb": "260816", "train_bsz": "1750", "train_num_updates": "60404", "train_lr": "0.000461408", "train_gnorm": "0.359", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.4", "train_wall": "13973"}
[2024-10-09 13:21:35,596][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:21:35,608][fairseq.trainer][INFO] - begin training epoch 1260
[2024-10-09 13:21:35,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:23:29,122][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1260 @ 60452 updates
[2024-10-09 13:23:29,123][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 13:23:32,954][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 13:23:32,956][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1260 @ 60452 updates, score None) (writing took 3.8347309790551662 seconds)
[2024-10-09 13:23:32,957][fairseq_cli.train][INFO] - end of epoch 1260 (average epoch stats below)
[2024-10-09 13:23:32,959][train][INFO] - {"epoch": 1260, "train_loss": "0.475", "train_ntokens": "260601", "train_nsentences": "1750.04", "train_wps": "53478.5", "train_ups": "0.21", "train_wpb": "260601", "train_bsz": "1750", "train_num_updates": "60452", "train_lr": "0.000461342", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.6", "train_wall": "14141"}
[2024-10-09 13:23:33,150][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:23:33,195][fairseq.trainer][INFO] - begin training epoch 1261
[2024-10-09 13:23:33,196][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:25:34,165][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1260 @ 60452 updates
[2024-10-09 13:25:34,172][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 13:25:38,265][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 13:25:38,267][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1260 @ 60452 updates, score None) (writing took 4.101831974461675 seconds)
[2024-10-09 13:25:38,267][fairseq_cli.train][INFO] - end of epoch 1260 (average epoch stats below)
[2024-10-09 13:25:38,270][train][INFO] - {"epoch": 1260, "train_loss": "0.475", "train_ntokens": "260601", "train_nsentences": "1750.04", "train_wps": "51486.8", "train_ups": "0.2", "train_wpb": "260601", "train_bsz": "1750", "train_num_updates": "60452", "train_lr": "0.000461342", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.6", "train_wall": "14216"}
[2024-10-09 13:25:38,446][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:25:38,470][fairseq.trainer][INFO] - begin training epoch 1261
[2024-10-09 13:25:38,471][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:27:22,744][fairseq_cli.train][INFO] - end of epoch 1261 (average epoch stats below)
[2024-10-09 13:27:22,751][train][INFO] - {"epoch": 1261, "train_loss": "0.488", "train_ntokens": "260854", "train_nsentences": "1750.04", "train_wps": "54489.2", "train_ups": "0.21", "train_wpb": "260854", "train_bsz": "1750", "train_num_updates": "60500", "train_lr": "0.000461277", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.6", "train_wall": "14371"}
[2024-10-09 13:27:22,883][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:27:22,906][fairseq.trainer][INFO] - begin training epoch 1262
[2024-10-09 13:27:22,906][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:29:33,640][fairseq_cli.train][INFO] - end of epoch 1261 (average epoch stats below)
[2024-10-09 13:29:33,658][train][INFO] - {"epoch": 1261, "train_loss": "0.488", "train_ntokens": "260854", "train_nsentences": "1750.04", "train_wps": "53194.1", "train_ups": "0.2", "train_wpb": "260854", "train_bsz": "1750", "train_num_updates": "60500", "train_lr": "0.000461277", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "39.6", "train_wall": "14451"}
[2024-10-09 13:29:33,883][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:29:33,893][fairseq.trainer][INFO] - begin training epoch 1262
[2024-10-09 13:29:33,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:31:20,845][fairseq_cli.train][INFO] - end of epoch 1262 (average epoch stats below)
[2024-10-09 13:31:20,857][train][INFO] - {"epoch": 1262, "train_loss": "0.484", "train_ntokens": "260572", "train_nsentences": "1750.04", "train_wps": "52530.2", "train_ups": "0.2", "train_wpb": "260572", "train_bsz": "1750", "train_num_updates": "60548", "train_lr": "0.000461212", "train_gnorm": "0.402", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.6", "train_wall": "14609"}
[2024-10-09 13:31:21,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:31:21,128][fairseq.trainer][INFO] - begin training epoch 1263
[2024-10-09 13:31:21,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:33:31,851][fairseq_cli.train][INFO] - end of epoch 1262 (average epoch stats below)
[2024-10-09 13:33:31,868][train][INFO] - {"epoch": 1262, "train_loss": "0.484", "train_ntokens": "260572", "train_nsentences": "1750.04", "train_wps": "52508.5", "train_ups": "0.2", "train_wpb": "260572", "train_bsz": "1750", "train_num_updates": "60548", "train_lr": "0.000461212", "train_gnorm": "0.402", "train_loss_scale": "2", "train_train_wall": "88", "train_gb_free": "39.6", "train_wall": "14689"}
[2024-10-09 13:33:32,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:33:32,021][fairseq.trainer][INFO] - begin training epoch 1263
[2024-10-09 13:33:32,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:34:38,098][fairseq_cli.train][INFO] - end of epoch 1263 (average epoch stats below)
[2024-10-09 13:34:38,102][train][INFO] - {"epoch": 1263, "train_loss": "0.485", "train_ntokens": "260428", "train_nsentences": "1750.04", "train_wps": "63376.6", "train_ups": "0.24", "train_wpb": "260428", "train_bsz": "1750", "train_num_updates": "60596", "train_lr": "0.000461147", "train_gnorm": "0.361", "train_loss_scale": "2", "train_train_wall": "78", "train_gb_free": "39.8", "train_wall": "14806"}
[2024-10-09 13:34:38,220][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:34:38,227][fairseq.trainer][INFO] - begin training epoch 1264
[2024-10-09 13:34:38,228][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:36:44,223][fairseq_cli.train][INFO] - end of epoch 1263 (average epoch stats below)
[2024-10-09 13:36:44,241][train][INFO] - {"epoch": 1263, "train_loss": "0.485", "train_ntokens": "260428", "train_nsentences": "1750.04", "train_wps": "64986.3", "train_ups": "0.25", "train_wpb": "260428", "train_bsz": "1750", "train_num_updates": "60596", "train_lr": "0.000461147", "train_gnorm": "0.358", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.8", "train_wall": "14882"}
[2024-10-09 13:36:44,326][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:36:44,329][fairseq.trainer][INFO] - begin training epoch 1264
[2024-10-09 13:36:44,330][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:36:57,642][train_inner][INFO] - {"epoch": 1264, "update": 1263.083, "loss": "0.483", "ntokens": "260592", "nsentences": "1756.15", "wps": "50115", "ups": "0.19", "wpb": "260592", "bsz": "1756.2", "num_updates": "60600", "lr": "0.000461141", "gnorm": "0.377", "loss_scale": "2", "train_wall": "345", "gb_free": "39.7", "wall": "14946"}
[2024-10-09 13:37:53,632][fairseq_cli.train][INFO] - end of epoch 1264 (average epoch stats below)
[2024-10-09 13:37:53,634][train][INFO] - {"epoch": 1264, "train_loss": "0.484", "train_ntokens": "260371", "train_nsentences": "1750.04", "train_wps": "63917.7", "train_ups": "0.25", "train_wpb": "260371", "train_bsz": "1750", "train_num_updates": "60644", "train_lr": "0.000461082", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "88", "train_gb_free": "39.9", "train_wall": "15002"}
[2024-10-09 13:37:53,742][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:37:53,745][fairseq.trainer][INFO] - begin training epoch 1265
[2024-10-09 13:37:53,746][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:38:57,823][train_inner][INFO] - {"epoch": 1264, "update": 1263.083, "loss": "0.483", "ntokens": "260592", "nsentences": "1756.15", "wps": "49904.7", "ups": "0.19", "wpb": "260592", "bsz": "1756.2", "num_updates": "60600", "lr": "0.000461141", "gnorm": "0.376", "loss_scale": "2", "train_wall": "370", "gb_free": "39.7", "wall": "15015"}
[2024-10-09 13:40:02,729][fairseq_cli.train][INFO] - end of epoch 1264 (average epoch stats below)
[2024-10-09 13:40:02,739][train][INFO] - {"epoch": 1264, "train_loss": "0.484", "train_ntokens": "260371", "train_nsentences": "1750.04", "train_wps": "62965", "train_ups": "0.24", "train_wpb": "260371", "train_bsz": "1750", "train_num_updates": "60644", "train_lr": "0.000461082", "train_gnorm": "0.386", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "39.9", "train_wall": "15080"}
[2024-10-09 13:40:02,824][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:40:02,827][fairseq.trainer][INFO] - begin training epoch 1265
[2024-10-09 13:40:02,828][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:41:09,045][fairseq_cli.train][INFO] - end of epoch 1265 (average epoch stats below)
[2024-10-09 13:41:09,053][train][INFO] - {"epoch": 1265, "train_loss": "0.476", "train_ntokens": "260452", "train_nsentences": "1750.04", "train_wps": "63975.1", "train_ups": "0.25", "train_wpb": "260452", "train_bsz": "1750", "train_num_updates": "60692", "train_lr": "0.000461016", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "39.7", "train_wall": "15197"}
[2024-10-09 13:41:09,251][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:41:09,254][fairseq.trainer][INFO] - begin training epoch 1266
[2024-10-09 13:41:09,255][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:43:25,531][fairseq_cli.train][INFO] - end of epoch 1265 (average epoch stats below)
[2024-10-09 13:43:25,536][train][INFO] - {"epoch": 1265, "train_loss": "0.476", "train_ntokens": "260452", "train_nsentences": "1750.04", "train_wps": "61647.2", "train_ups": "0.24", "train_wpb": "260452", "train_bsz": "1750", "train_num_updates": "60692", "train_lr": "0.000461016", "train_gnorm": "0.366", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.7", "train_wall": "15283"}
[2024-10-09 13:43:25,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:43:25,719][fairseq.trainer][INFO] - begin training epoch 1266
[2024-10-09 13:43:25,719][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:45:10,053][fairseq_cli.train][INFO] - end of epoch 1266 (average epoch stats below)
[2024-10-09 13:45:10,060][train][INFO] - {"epoch": 1266, "train_loss": "0.487", "train_ntokens": "260363", "train_nsentences": "1750.04", "train_wps": "51855.8", "train_ups": "0.2", "train_wpb": "260363", "train_bsz": "1750", "train_num_updates": "60740", "train_lr": "0.000460951", "train_gnorm": "0.419", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.3", "train_wall": "15438"}
[2024-10-09 13:45:10,160][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:45:10,170][fairseq.trainer][INFO] - begin training epoch 1267
[2024-10-09 13:45:10,170][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:47:22,341][fairseq_cli.train][INFO] - end of epoch 1266 (average epoch stats below)
[2024-10-09 13:47:22,347][train][INFO] - {"epoch": 1266, "train_loss": "0.487", "train_ntokens": "260363", "train_nsentences": "1750.04", "train_wps": "52774.5", "train_ups": "0.2", "train_wpb": "260363", "train_bsz": "1750", "train_num_updates": "60740", "train_lr": "0.000460951", "train_gnorm": "0.423", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "39.3", "train_wall": "15520"}
[2024-10-09 13:47:22,545][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:47:22,556][fairseq.trainer][INFO] - begin training epoch 1267
[2024-10-09 13:47:22,557][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:49:08,148][fairseq_cli.train][INFO] - end of epoch 1267 (average epoch stats below)
[2024-10-09 13:49:08,155][train][INFO] - {"epoch": 1267, "train_loss": "0.488", "train_ntokens": "260738", "train_nsentences": "1750.04", "train_wps": "52565.9", "train_ups": "0.2", "train_wpb": "260738", "train_bsz": "1750", "train_num_updates": "60788", "train_lr": "0.000460886", "train_gnorm": "0.353", "train_loss_scale": "2", "train_train_wall": "92", "train_gb_free": "39.8", "train_wall": "15676"}
[2024-10-09 13:49:08,409][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:49:08,412][fairseq.trainer][INFO] - begin training epoch 1268
[2024-10-09 13:49:08,413][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:51:23,390][fairseq_cli.train][INFO] - end of epoch 1267 (average epoch stats below)
[2024-10-09 13:51:23,395][train][INFO] - {"epoch": 1267, "train_loss": "0.488", "train_ntokens": "260738", "train_nsentences": "1750.04", "train_wps": "51922.1", "train_ups": "0.2", "train_wpb": "260738", "train_bsz": "1750", "train_num_updates": "60788", "train_lr": "0.000460886", "train_gnorm": "0.353", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.8", "train_wall": "15761"}
[2024-10-09 13:51:23,684][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:51:23,694][fairseq.trainer][INFO] - begin training epoch 1268
[2024-10-09 13:51:23,695][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:52:48,985][train_inner][INFO] - {"epoch": 1268, "update": 1267.25, "loss": "0.484", "ntokens": "260661", "nsentences": "1742.03", "wps": "54798.7", "ups": "0.21", "wpb": "260661", "bsz": "1742", "num_updates": "60800", "lr": "0.00046087", "gnorm": "0.381", "loss_scale": "2", "train_wall": "305", "gb_free": "39.9", "wall": "15897"}
[2024-10-09 13:53:11,689][fairseq_cli.train][INFO] - end of epoch 1268 (average epoch stats below)
[2024-10-09 13:53:11,696][train][INFO] - {"epoch": 1268, "train_loss": "0.478", "train_ntokens": "260620", "train_nsentences": "1750.04", "train_wps": "51367.9", "train_ups": "0.2", "train_wpb": "260620", "train_bsz": "1750", "train_num_updates": "60836", "train_lr": "0.000460821", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "39.3", "train_wall": "15920"}
[2024-10-09 13:53:11,868][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:53:11,871][fairseq.trainer][INFO] - begin training epoch 1269
[2024-10-09 13:53:11,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:55:04,098][train_inner][INFO] - {"epoch": 1268, "update": 1267.25, "loss": "0.484", "ntokens": "260661", "nsentences": "1742.03", "wps": "53952.5", "ups": "0.21", "wpb": "260661", "bsz": "1742", "num_updates": "60800", "lr": "0.00046087", "gnorm": "0.383", "loss_scale": "2", "train_wall": "339", "gb_free": "39.9", "wall": "15982"}
[2024-10-09 13:55:26,727][fairseq_cli.train][INFO] - end of epoch 1268 (average epoch stats below)
[2024-10-09 13:55:26,735][train][INFO] - {"epoch": 1268, "train_loss": "0.478", "train_ntokens": "260620", "train_nsentences": "1750.04", "train_wps": "51410.5", "train_ups": "0.2", "train_wpb": "260620", "train_bsz": "1750", "train_num_updates": "60836", "train_lr": "0.000460821", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.3", "train_wall": "16004"}
[2024-10-09 13:55:27,000][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:55:27,006][fairseq.trainer][INFO] - begin training epoch 1269
[2024-10-09 13:55:27,006][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:57:11,964][fairseq_cli.train][INFO] - end of epoch 1269 (average epoch stats below)
[2024-10-09 13:57:11,972][train][INFO] - {"epoch": 1269, "train_loss": "0.483", "train_ntokens": "260918", "train_nsentences": "1750.04", "train_wps": "52124.4", "train_ups": "0.2", "train_wpb": "260918", "train_bsz": "1750", "train_num_updates": "60884", "train_lr": "0.000460755", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "81", "train_gb_free": "40.2", "train_wall": "16160"}
[2024-10-09 13:57:12,193][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:57:12,209][fairseq.trainer][INFO] - begin training epoch 1270
[2024-10-09 13:57:12,209][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 13:59:15,968][fairseq_cli.train][INFO] - end of epoch 1269 (average epoch stats below)
[2024-10-09 13:59:16,091][train][INFO] - {"epoch": 1269, "train_loss": "0.483", "train_ntokens": "260918", "train_nsentences": "1750.04", "train_wps": "54607.7", "train_ups": "0.21", "train_wpb": "260918", "train_bsz": "1750", "train_num_updates": "60884", "train_lr": "0.000460755", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "73", "train_gb_free": "40.2", "train_wall": "16234"}
[2024-10-09 13:59:18,073][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 13:59:18,190][fairseq.trainer][INFO] - begin training epoch 1270
[2024-10-09 13:59:18,191][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:00:41,246][fairseq_cli.train][INFO] - end of epoch 1270 (average epoch stats below)
[2024-10-09 14:00:41,276][train][INFO] - {"epoch": 1270, "train_loss": "0.485", "train_ntokens": "260458", "train_nsentences": "1750.04", "train_wps": "59733.8", "train_ups": "0.23", "train_wpb": "260458", "train_bsz": "1750", "train_num_updates": "60932", "train_lr": "0.00046069", "train_gnorm": "0.398", "train_loss_scale": "2", "train_train_wall": "94", "train_gb_free": "39.3", "train_wall": "16370"}
[2024-10-09 14:00:41,476][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:00:41,484][fairseq.trainer][INFO] - begin training epoch 1271
[2024-10-09 14:00:41,485][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:03:04,930][fairseq_cli.train][INFO] - end of epoch 1270 (average epoch stats below)
[2024-10-09 14:03:04,953][train][INFO] - {"epoch": 1270, "train_loss": "0.485", "train_ntokens": "260458", "train_nsentences": "1750.04", "train_wps": "54627.7", "train_ups": "0.21", "train_wpb": "260458", "train_bsz": "1750", "train_num_updates": "60932", "train_lr": "0.00046069", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "89", "train_gb_free": "39.3", "train_wall": "16462"}
[2024-10-09 14:03:06,620][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:03:06,806][fairseq.trainer][INFO] - begin training epoch 1271
[2024-10-09 14:03:06,806][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:04:41,093][fairseq_cli.train][INFO] - end of epoch 1271 (average epoch stats below)
[2024-10-09 14:04:41,108][train][INFO] - {"epoch": 1271, "train_loss": "0.49", "train_ntokens": "260824", "train_nsentences": "1750.04", "train_wps": "52202", "train_ups": "0.2", "train_wpb": "260824", "train_bsz": "1750", "train_num_updates": "60980", "train_lr": "0.000460625", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.3", "train_wall": "16609"}
[2024-10-09 14:04:41,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:04:41,327][fairseq.trainer][INFO] - begin training epoch 1272
[2024-10-09 14:04:41,328][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:07:00,682][fairseq_cli.train][INFO] - end of epoch 1271 (average epoch stats below)
[2024-10-09 14:07:00,689][train][INFO] - {"epoch": 1271, "train_loss": "0.49", "train_ntokens": "260824", "train_nsentences": "1750.04", "train_wps": "53108.8", "train_ups": "0.2", "train_wpb": "260824", "train_bsz": "1750", "train_num_updates": "60980", "train_lr": "0.000460625", "train_gnorm": "0.403", "train_loss_scale": "2", "train_train_wall": "96", "train_gb_free": "39.3", "train_wall": "16698"}
[2024-10-09 14:07:00,984][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:07:01,017][fairseq.trainer][INFO] - begin training epoch 1272
[2024-10-09 14:07:01,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:08:25,443][train_inner][INFO] - {"epoch": 1272, "update": 1271.417, "loss": "0.484", "ntokens": "260549", "nsentences": "1750.47", "wps": "55646.1", "ups": "0.21", "wpb": "260549", "bsz": "1750.5", "num_updates": "61000", "lr": "0.000460598", "gnorm": "0.387", "loss_scale": "2", "train_wall": "321", "gb_free": "40.1", "wall": "16834"}
[2024-10-09 14:08:45,581][fairseq_cli.train][INFO] - end of epoch 1272 (average epoch stats below)
[2024-10-09 14:08:45,584][train][INFO] - {"epoch": 1272, "train_loss": "0.48", "train_ntokens": "260674", "train_nsentences": "1750.04", "train_wps": "51181", "train_ups": "0.2", "train_wpb": "260674", "train_bsz": "1750", "train_num_updates": "61028", "train_lr": "0.00046056", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "40.1", "train_wall": "16854"}
[2024-10-09 14:08:45,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:08:45,945][fairseq.trainer][INFO] - begin training epoch 1273
[2024-10-09 14:08:45,945][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:10:47,260][train_inner][INFO] - {"epoch": 1272, "update": 1271.417, "loss": "0.484", "ntokens": "260549", "nsentences": "1750.47", "wps": "55250.5", "ups": "0.21", "wpb": "260549", "bsz": "1750.5", "num_updates": "61000", "lr": "0.000460598", "gnorm": "0.388", "loss_scale": "2", "train_wall": "323", "gb_free": "40.1", "wall": "16925"}
[2024-10-09 14:11:05,769][fairseq_cli.train][INFO] - end of epoch 1272 (average epoch stats below)
[2024-10-09 14:11:05,775][train][INFO] - {"epoch": 1272, "train_loss": "0.48", "train_ntokens": "260674", "train_nsentences": "1750.04", "train_wps": "51054.3", "train_ups": "0.2", "train_wpb": "260674", "train_bsz": "1750", "train_num_updates": "61028", "train_lr": "0.00046056", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "62", "train_gb_free": "40.1", "train_wall": "16943"}
[2024-10-09 14:11:06,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:11:06,118][fairseq.trainer][INFO] - begin training epoch 1273
[2024-10-09 14:11:06,118][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:12:58,188][fairseq_cli.train][INFO] - end of epoch 1273 (average epoch stats below)
[2024-10-09 14:12:58,202][train][INFO] - {"epoch": 1273, "train_loss": "0.484", "train_ntokens": "260958", "train_nsentences": "1750.04", "train_wps": "49586", "train_ups": "0.19", "train_wpb": "260958", "train_bsz": "1750", "train_num_updates": "61076", "train_lr": "0.000460495", "train_gnorm": "0.412", "train_loss_scale": "2", "train_train_wall": "94", "train_gb_free": "39.6", "train_wall": "17106"}
[2024-10-09 14:12:58,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:12:58,340][fairseq.trainer][INFO] - begin training epoch 1274
[2024-10-09 14:12:58,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:15:20,383][fairseq_cli.train][INFO] - end of epoch 1273 (average epoch stats below)
[2024-10-09 14:15:20,395][train][INFO] - {"epoch": 1273, "train_loss": "0.483", "train_ntokens": "260958", "train_nsentences": "1750.04", "train_wps": "49195.3", "train_ups": "0.19", "train_wpb": "260958", "train_bsz": "1750", "train_num_updates": "61076", "train_lr": "0.000460495", "train_gnorm": "0.407", "train_loss_scale": "2", "train_train_wall": "95", "train_gb_free": "39.6", "train_wall": "17198"}
[2024-10-09 14:15:20,684][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:15:20,688][fairseq.trainer][INFO] - begin training epoch 1274
[2024-10-09 14:15:20,688][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:17:25,706][fairseq_cli.train][INFO] - end of epoch 1274 (average epoch stats below)
[2024-10-09 14:17:25,710][train][INFO] - {"epoch": 1274, "train_loss": "0.479", "train_ntokens": "260580", "train_nsentences": "1750.04", "train_wps": "46757.4", "train_ups": "0.18", "train_wpb": "260580", "train_bsz": "1750", "train_num_updates": "61124", "train_lr": "0.000460429", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "80", "train_gb_free": "39.3", "train_wall": "17374"}
[2024-10-09 14:17:25,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:17:25,823][fairseq.trainer][INFO] - begin training epoch 1275
[2024-10-09 14:17:25,824][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:19:31,817][fairseq_cli.train][INFO] - end of epoch 1274 (average epoch stats below)
[2024-10-09 14:19:31,826][train][INFO] - {"epoch": 1274, "train_loss": "0.479", "train_ntokens": "260580", "train_nsentences": "1750.04", "train_wps": "49747.9", "train_ups": "0.19", "train_wpb": "260580", "train_bsz": "1750", "train_num_updates": "61124", "train_lr": "0.000460429", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "17449"}
[2024-10-09 14:19:32,113][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:19:32,120][fairseq.trainer][INFO] - begin training epoch 1275
[2024-10-09 14:19:32,121][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:21:26,165][fairseq_cli.train][INFO] - end of epoch 1275 (average epoch stats below)
[2024-10-09 14:21:26,185][train][INFO] - {"epoch": 1275, "train_loss": "0.484", "train_ntokens": "260726", "train_nsentences": "1750.04", "train_wps": "52043.9", "train_ups": "0.2", "train_wpb": "260726", "train_bsz": "1750", "train_num_updates": "61172", "train_lr": "0.000460364", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "41.1", "train_wall": "17614"}
[2024-10-09 14:21:26,385][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:21:26,391][fairseq.trainer][INFO] - begin training epoch 1276
[2024-10-09 14:21:26,391][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:23:26,325][fairseq_cli.train][INFO] - end of epoch 1275 (average epoch stats below)
[2024-10-09 14:23:26,414][train][INFO] - {"epoch": 1275, "train_loss": "0.484", "train_ntokens": "260726", "train_nsentences": "1750.04", "train_wps": "53349.2", "train_ups": "0.2", "train_wpb": "260726", "train_bsz": "1750", "train_num_updates": "61172", "train_lr": "0.000460364", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "41.1", "train_wall": "17684"}
[2024-10-09 14:23:28,644][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:23:28,942][fairseq.trainer][INFO] - begin training epoch 1276
[2024-10-09 14:23:28,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:24:54,863][train_inner][INFO] - {"epoch": 1276, "update": 1275.583, "loss": "0.48", "ntokens": "260754", "nsentences": "1743.02", "wps": "52709", "ups": "0.2", "wpb": "260754", "bsz": "1743", "num_updates": "61200", "lr": "0.000460326", "gnorm": "0.387", "loss_scale": "2", "train_wall": "341", "gb_free": "40", "wall": "17823"}
[2024-10-09 14:25:11,017][fairseq_cli.train][INFO] - end of epoch 1276 (average epoch stats below)
[2024-10-09 14:25:11,020][train][INFO] - {"epoch": 1276, "train_loss": "0.48", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "55623.6", "train_ups": "0.21", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "61220", "train_lr": "0.000460299", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "92", "train_gb_free": "39.8", "train_wall": "17839"}
[2024-10-09 14:25:11,255][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:25:11,264][fairseq.trainer][INFO] - begin training epoch 1277
[2024-10-09 14:25:11,265][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:26:52,397][train_inner][INFO] - {"epoch": 1276, "update": 1275.583, "loss": "0.48", "ntokens": "260754", "nsentences": "1743.02", "wps": "54035.4", "ups": "0.21", "wpb": "260754", "bsz": "1743", "num_updates": "61200", "lr": "0.000460326", "gnorm": "0.385", "loss_scale": "2", "train_wall": "300", "gb_free": "40", "wall": "17890"}
[2024-10-09 14:27:12,507][fairseq_cli.train][INFO] - end of epoch 1276 (average epoch stats below)
[2024-10-09 14:27:12,510][train][INFO] - {"epoch": 1276, "train_loss": "0.48", "train_ntokens": "260540", "train_nsentences": "1750.04", "train_wps": "55313.3", "train_ups": "0.21", "train_wpb": "260540", "train_bsz": "1750", "train_num_updates": "61220", "train_lr": "0.000460299", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.8", "train_wall": "17910"}
[2024-10-09 14:27:14,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:27:14,421][fairseq.trainer][INFO] - begin training epoch 1277
[2024-10-09 14:27:14,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:28:39,088][fairseq_cli.train][INFO] - end of epoch 1277 (average epoch stats below)
[2024-10-09 14:28:39,103][train][INFO] - {"epoch": 1277, "train_loss": "0.49", "train_ntokens": "260752", "train_nsentences": "1750.04", "train_wps": "60151", "train_ups": "0.23", "train_wpb": "260752", "train_bsz": "1750", "train_num_updates": "61268", "train_lr": "0.000460234", "train_gnorm": "0.36", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "39.3", "train_wall": "18047"}
[2024-10-09 14:28:39,439][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:28:39,445][fairseq.trainer][INFO] - begin training epoch 1278
[2024-10-09 14:28:39,445][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:31:25,232][fairseq_cli.train][INFO] - end of epoch 1277 (average epoch stats below)
[2024-10-09 14:31:25,302][train][INFO] - {"epoch": 1277, "train_loss": "0.49", "train_ntokens": "260752", "train_nsentences": "1750.04", "train_wps": "49512.9", "train_ups": "0.19", "train_wpb": "260752", "train_bsz": "1750", "train_num_updates": "61268", "train_lr": "0.000460234", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "79", "train_gb_free": "39.3", "train_wall": "18163"}
[2024-10-09 14:31:26,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:31:26,882][fairseq.trainer][INFO] - begin training epoch 1278
[2024-10-09 14:31:26,882][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:33:15,562][fairseq_cli.train][INFO] - end of epoch 1278 (average epoch stats below)
[2024-10-09 14:33:15,595][train][INFO] - {"epoch": 1278, "train_loss": "0.483", "train_ntokens": "260946", "train_nsentences": "1750.04", "train_wps": "45304.1", "train_ups": "0.17", "train_wpb": "260946", "train_bsz": "1750", "train_num_updates": "61316", "train_lr": "0.000460168", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.8", "train_wall": "18324"}
[2024-10-09 14:33:15,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:33:15,784][fairseq.trainer][INFO] - begin training epoch 1279
[2024-10-09 14:33:15,785][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:36:01,010][fairseq_cli.train][INFO] - end of epoch 1278 (average epoch stats below)
[2024-10-09 14:36:01,096][train][INFO] - {"epoch": 1278, "train_loss": "0.484", "train_ntokens": "260946", "train_nsentences": "1750.04", "train_wps": "45418", "train_ups": "0.17", "train_wpb": "260946", "train_bsz": "1750", "train_num_updates": "61316", "train_lr": "0.000460168", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "103", "train_gb_free": "39.8", "train_wall": "18439"}
[2024-10-09 14:36:02,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:36:03,196][fairseq.trainer][INFO] - begin training epoch 1279
[2024-10-09 14:36:03,197][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:37:33,050][fairseq_cli.train][INFO] - end of epoch 1279 (average epoch stats below)
[2024-10-09 14:37:33,060][train][INFO] - {"epoch": 1279, "train_loss": "0.478", "train_ntokens": "260537", "train_nsentences": "1750.04", "train_wps": "48574.1", "train_ups": "0.19", "train_wpb": "260537", "train_bsz": "1750", "train_num_updates": "61364", "train_lr": "0.000460103", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "39.2", "train_wall": "18581"}
[2024-10-09 14:37:33,131][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:37:33,156][fairseq.trainer][INFO] - begin training epoch 1280
[2024-10-09 14:37:33,156][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:40:17,188][fairseq_cli.train][INFO] - end of epoch 1279 (average epoch stats below)
[2024-10-09 14:40:17,202][train][INFO] - {"epoch": 1279, "train_loss": "0.478", "train_ntokens": "260537", "train_nsentences": "1750.04", "train_wps": "48832", "train_ups": "0.19", "train_wpb": "260537", "train_bsz": "1750", "train_num_updates": "61364", "train_lr": "0.000460103", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.2", "train_wall": "18695"}
[2024-10-09 14:40:17,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:40:17,413][fairseq.trainer][INFO] - begin training epoch 1280
[2024-10-09 14:40:17,413][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:40:36,385][train_inner][INFO] - {"epoch": 1280, "update": 1279.75, "loss": "0.485", "ntokens": "260667", "nsentences": "1759.11", "wps": "55371.7", "ups": "0.21", "wpb": "260667", "bsz": "1759.1", "num_updates": "61400", "lr": "0.000460054", "gnorm": "0.378", "loss_scale": "2", "train_wall": "335", "gb_free": "39.4", "wall": "18765"}
[2024-10-09 14:40:52,560][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1280 @ 61412 updates
[2024-10-09 14:40:52,561][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 14:40:55,836][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 14:40:55,838][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1280 @ 61412 updates, score None) (writing took 3.27778032515198 seconds)
[2024-10-09 14:40:55,839][fairseq_cli.train][INFO] - end of epoch 1280 (average epoch stats below)
[2024-10-09 14:40:55,841][train][INFO] - {"epoch": 1280, "train_loss": "0.48", "train_ntokens": "260371", "train_nsentences": "1750.04", "train_wps": "61633", "train_ups": "0.24", "train_wpb": "260371", "train_bsz": "1750", "train_num_updates": "61412", "train_lr": "0.000460038", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "87", "train_gb_free": "40.1", "train_wall": "18784"}
[2024-10-09 14:40:55,893][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:40:55,908][fairseq.trainer][INFO] - begin training epoch 1281
[2024-10-09 14:40:55,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:43:14,150][train_inner][INFO] - {"epoch": 1280, "update": 1279.75, "loss": "0.485", "ntokens": "260667", "nsentences": "1759.11", "wps": "53103.1", "ups": "0.2", "wpb": "260667", "bsz": "1759.1", "num_updates": "61400", "lr": "0.000460054", "gnorm": "0.379", "loss_scale": "2", "train_wall": "301", "gb_free": "39.4", "wall": "18872"}
[2024-10-09 14:43:35,721][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1280 @ 61412 updates
[2024-10-09 14:43:35,722][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 14:43:39,919][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 14:43:39,923][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1280 @ 61412 updates, score None) (writing took 4.2022247249260545 seconds)
[2024-10-09 14:43:39,923][fairseq_cli.train][INFO] - end of epoch 1280 (average epoch stats below)
[2024-10-09 14:43:39,940][train][INFO] - {"epoch": 1280, "train_loss": "0.48", "train_ntokens": "260371", "train_nsentences": "1750.04", "train_wps": "61650.7", "train_ups": "0.24", "train_wpb": "260371", "train_bsz": "1750", "train_num_updates": "61412", "train_lr": "0.000460038", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.1", "train_wall": "18897"}
[2024-10-09 14:43:40,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:43:40,092][fairseq.trainer][INFO] - begin training epoch 1281
[2024-10-09 14:43:40,093][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:44:12,789][fairseq_cli.train][INFO] - end of epoch 1281 (average epoch stats below)
[2024-10-09 14:44:12,803][train][INFO] - {"epoch": 1281, "train_loss": "0.48", "train_ntokens": "260880", "train_nsentences": "1750.04", "train_wps": "63581.6", "train_ups": "0.24", "train_wpb": "260880", "train_bsz": "1750", "train_num_updates": "61460", "train_lr": "0.000459973", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.3", "train_wall": "18981"}
[2024-10-09 14:44:12,938][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:44:12,943][fairseq.trainer][INFO] - begin training epoch 1282
[2024-10-09 14:44:12,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:46:59,009][fairseq_cli.train][INFO] - end of epoch 1281 (average epoch stats below)
[2024-10-09 14:46:59,036][train][INFO] - {"epoch": 1281, "train_loss": "0.48", "train_ntokens": "260880", "train_nsentences": "1750.04", "train_wps": "62899.4", "train_ups": "0.24", "train_wpb": "260880", "train_bsz": "1750", "train_num_updates": "61460", "train_lr": "0.000459973", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "39.3", "train_wall": "19097"}
[2024-10-09 14:46:59,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:46:59,300][fairseq.trainer][INFO] - begin training epoch 1282
[2024-10-09 14:46:59,300][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:47:29,298][fairseq_cli.train][INFO] - end of epoch 1282 (average epoch stats below)
[2024-10-09 14:47:29,307][train][INFO] - {"epoch": 1282, "train_loss": "0.483", "train_ntokens": "260670", "train_nsentences": "1750.04", "train_wps": "63676.7", "train_ups": "0.24", "train_wpb": "260670", "train_bsz": "1750", "train_num_updates": "61508", "train_lr": "0.000459908", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "40.1", "train_wall": "19178"}
[2024-10-09 14:47:29,542][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:47:29,549][fairseq.trainer][INFO] - begin training epoch 1283
[2024-10-09 14:47:29,549][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:50:50,873][fairseq_cli.train][INFO] - end of epoch 1282 (average epoch stats below)
[2024-10-09 14:50:50,919][train][INFO] - {"epoch": 1282, "train_loss": "0.483", "train_ntokens": "260670", "train_nsentences": "1750.04", "train_wps": "53964.2", "train_ups": "0.21", "train_wpb": "260670", "train_bsz": "1750", "train_num_updates": "61508", "train_lr": "0.000459908", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "96", "train_gb_free": "40.1", "train_wall": "19328"}
[2024-10-09 14:50:51,793][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:50:51,868][fairseq.trainer][INFO] - begin training epoch 1283
[2024-10-09 14:50:51,868][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:51:31,389][fairseq_cli.train][INFO] - end of epoch 1283 (average epoch stats below)
[2024-10-09 14:51:31,400][train][INFO] - {"epoch": 1283, "train_loss": "0.486", "train_ntokens": "261151", "train_nsentences": "1750.04", "train_wps": "51781.1", "train_ups": "0.2", "train_wpb": "261151", "train_bsz": "1750", "train_num_updates": "61556", "train_lr": "0.000459842", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "19420"}
[2024-10-09 14:51:31,573][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:51:31,599][fairseq.trainer][INFO] - begin training epoch 1284
[2024-10-09 14:51:31,600][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:54:28,388][fairseq_cli.train][INFO] - end of epoch 1283 (average epoch stats below)
[2024-10-09 14:54:28,409][train][INFO] - {"epoch": 1283, "train_loss": "0.486", "train_ntokens": "261151", "train_nsentences": "1750.04", "train_wps": "57640.3", "train_ups": "0.22", "train_wpb": "261151", "train_bsz": "1750", "train_num_updates": "61556", "train_lr": "0.000459842", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "90", "train_gb_free": "39.3", "train_wall": "19546"}
[2024-10-09 14:54:28,613][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:54:28,626][fairseq.trainer][INFO] - begin training epoch 1284
[2024-10-09 14:54:28,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:54:56,139][train_inner][INFO] - {"epoch": 1284, "update": 1283.917, "loss": "0.481", "ntokens": "260807", "nsentences": "1743.66", "wps": "60670.3", "ups": "0.23", "wpb": "260807", "bsz": "1743.7", "num_updates": "61600", "lr": "0.000459783", "gnorm": "0.376", "loss_scale": "2", "train_wall": "320", "gb_free": "39.8", "wall": "19624"}
[2024-10-09 14:54:57,060][fairseq_cli.train][INFO] - end of epoch 1284 (average epoch stats below)
[2024-10-09 14:54:57,064][train][INFO] - {"epoch": 1284, "train_loss": "0.478", "train_ntokens": "260529", "train_nsentences": "1750.04", "train_wps": "60806.1", "train_ups": "0.23", "train_wpb": "260529", "train_bsz": "1750", "train_num_updates": "61604", "train_lr": "0.000459777", "train_gnorm": "0.386", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "40.5", "train_wall": "19625"}
[2024-10-09 14:54:57,243][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:54:57,261][fairseq.trainer][INFO] - begin training epoch 1285
[2024-10-09 14:54:57,261][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:58:33,035][train_inner][INFO] - {"epoch": 1284, "update": 1283.917, "loss": "0.481", "ntokens": "260807", "nsentences": "1743.66", "wps": "56766.8", "ups": "0.22", "wpb": "260807", "bsz": "1743.7", "num_updates": "61600", "lr": "0.000459783", "gnorm": "0.376", "loss_scale": "2", "train_wall": "448", "gb_free": "39.8", "wall": "19791"}
[2024-10-09 14:58:35,337][fairseq_cli.train][INFO] - end of epoch 1284 (average epoch stats below)
[2024-10-09 14:58:35,351][train][INFO] - {"epoch": 1284, "train_loss": "0.478", "train_ntokens": "260529", "train_nsentences": "1750.04", "train_wps": "50643.9", "train_ups": "0.19", "train_wpb": "260529", "train_bsz": "1750", "train_num_updates": "61604", "train_lr": "0.000459777", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "152", "train_gb_free": "40.5", "train_wall": "19793"}
[2024-10-09 14:58:35,571][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:58:35,575][fairseq.trainer][INFO] - begin training epoch 1285
[2024-10-09 14:58:35,575][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 14:58:57,533][fairseq_cli.train][INFO] - end of epoch 1285 (average epoch stats below)
[2024-10-09 14:58:57,536][train][INFO] - {"epoch": 1285, "train_loss": "0.478", "train_ntokens": "260742", "train_nsentences": "1750.04", "train_wps": "52046.9", "train_ups": "0.2", "train_wpb": "260742", "train_bsz": "1750", "train_num_updates": "61652", "train_lr": "0.000459712", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.8", "train_wall": "19866"}
[2024-10-09 14:58:57,820][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 14:58:57,844][fairseq.trainer][INFO] - begin training epoch 1286
[2024-10-09 14:58:57,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:02:36,816][fairseq_cli.train][INFO] - end of epoch 1285 (average epoch stats below)
[2024-10-09 15:02:36,823][train][INFO] - {"epoch": 1285, "train_loss": "0.478", "train_ntokens": "260742", "train_nsentences": "1750.04", "train_wps": "51832.5", "train_ups": "0.2", "train_wpb": "260742", "train_bsz": "1750", "train_num_updates": "61652", "train_lr": "0.000459712", "train_gnorm": "0.368", "train_loss_scale": "2", "train_train_wall": "116", "train_gb_free": "39.8", "train_wall": "20034"}
[2024-10-09 15:02:36,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:02:36,996][fairseq.trainer][INFO] - begin training epoch 1286
[2024-10-09 15:02:36,997][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:03:00,595][fairseq_cli.train][INFO] - end of epoch 1286 (average epoch stats below)
[2024-10-09 15:03:00,598][train][INFO] - {"epoch": 1286, "train_loss": "0.486", "train_ntokens": "260632", "train_nsentences": "1750.04", "train_wps": "51470.6", "train_ups": "0.2", "train_wpb": "260632", "train_bsz": "1750", "train_num_updates": "61700", "train_lr": "0.000459647", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "109", "train_gb_free": "40.7", "train_wall": "20109"}
[2024-10-09 15:03:00,750][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:03:00,763][fairseq.trainer][INFO] - begin training epoch 1287
[2024-10-09 15:03:00,763][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:06:54,958][fairseq_cli.train][INFO] - end of epoch 1286 (average epoch stats below)
[2024-10-09 15:06:54,965][train][INFO] - {"epoch": 1286, "train_loss": "0.486", "train_ntokens": "260632", "train_nsentences": "1750.04", "train_wps": "48463.7", "train_ups": "0.19", "train_wpb": "260632", "train_bsz": "1750", "train_num_updates": "61700", "train_lr": "0.000459647", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "147", "train_gb_free": "40.7", "train_wall": "20293"}
[2024-10-09 15:06:55,116][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:06:55,151][fairseq.trainer][INFO] - begin training epoch 1287
[2024-10-09 15:06:55,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:07:11,258][fairseq_cli.train][INFO] - end of epoch 1287 (average epoch stats below)
[2024-10-09 15:07:11,261][train][INFO] - {"epoch": 1287, "train_loss": "0.482", "train_ntokens": "260865", "train_nsentences": "1750.04", "train_wps": "49954.3", "train_ups": "0.19", "train_wpb": "260865", "train_bsz": "1750", "train_num_updates": "61748", "train_lr": "0.000459582", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "40.2", "train_wall": "20360"}
[2024-10-09 15:07:11,367][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:07:11,371][fairseq.trainer][INFO] - begin training epoch 1288
[2024-10-09 15:07:11,373][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:10:50,117][fairseq_cli.train][INFO] - end of epoch 1287 (average epoch stats below)
[2024-10-09 15:10:50,137][train][INFO] - {"epoch": 1287, "train_loss": "0.482", "train_ntokens": "260865", "train_nsentences": "1750.04", "train_wps": "53248.1", "train_ups": "0.2", "train_wpb": "260865", "train_bsz": "1750", "train_num_updates": "61748", "train_lr": "0.000459582", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "63", "train_gb_free": "40.2", "train_wall": "20528"}
[2024-10-09 15:10:50,296][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:10:50,309][fairseq.trainer][INFO] - begin training epoch 1288
[2024-10-09 15:10:50,309][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:11:10,052][fairseq_cli.train][INFO] - end of epoch 1288 (average epoch stats below)
[2024-10-09 15:11:10,054][train][INFO] - {"epoch": 1288, "train_loss": "0.483", "train_ntokens": "260675", "train_nsentences": "1750.04", "train_wps": "52398.9", "train_ups": "0.2", "train_wpb": "260675", "train_bsz": "1750", "train_num_updates": "61796", "train_lr": "0.000459516", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "96", "train_gb_free": "40.5", "train_wall": "20598"}
[2024-10-09 15:11:10,199][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:11:10,203][fairseq.trainer][INFO] - begin training epoch 1289
[2024-10-09 15:11:10,203][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:13:51,861][train_inner][INFO] - {"epoch": 1289, "update": 1288.083, "loss": "0.482", "ntokens": "260777", "nsentences": "1748.97", "wps": "45923.2", "ups": "0.18", "wpb": "260777", "bsz": "1749", "num_updates": "61800", "lr": "0.000459511", "gnorm": "0.372", "loss_scale": "2", "train_wall": "353", "gb_free": "40", "wall": "20760"}
[2024-10-09 15:14:33,800][fairseq_cli.train][INFO] - end of epoch 1288 (average epoch stats below)
[2024-10-09 15:14:33,822][train][INFO] - {"epoch": 1288, "train_loss": "0.483", "train_ntokens": "260675", "train_nsentences": "1750.04", "train_wps": "55943.6", "train_ups": "0.21", "train_wpb": "260675", "train_bsz": "1750", "train_num_updates": "61796", "train_lr": "0.000459516", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "96", "train_gb_free": "40.5", "train_wall": "20751"}
[2024-10-09 15:14:34,028][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:14:34,050][fairseq.trainer][INFO] - begin training epoch 1289
[2024-10-09 15:14:34,050][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:14:51,429][fairseq_cli.train][INFO] - end of epoch 1289 (average epoch stats below)
[2024-10-09 15:14:51,431][train][INFO] - {"epoch": 1289, "train_loss": "0.48", "train_ntokens": "260773", "train_nsentences": "1750.04", "train_wps": "56542.9", "train_ups": "0.22", "train_wpb": "260773", "train_bsz": "1750", "train_num_updates": "61844", "train_lr": "0.000459451", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.3", "train_wall": "20820"}
[2024-10-09 15:14:51,648][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:14:51,660][fairseq.trainer][INFO] - begin training epoch 1290
[2024-10-09 15:14:51,660][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:18:26,874][train_inner][INFO] - {"epoch": 1289, "update": 1288.083, "loss": "0.482", "ntokens": "260777", "nsentences": "1748.97", "wps": "43688.1", "ups": "0.17", "wpb": "260777", "bsz": "1749", "num_updates": "61800", "lr": "0.000459511", "gnorm": "0.371", "loss_scale": "2", "train_wall": "539", "gb_free": "40", "wall": "20984"}
[2024-10-09 15:19:13,954][fairseq_cli.train][INFO] - end of epoch 1289 (average epoch stats below)
[2024-10-09 15:19:13,964][train][INFO] - {"epoch": 1289, "train_loss": "0.48", "train_ntokens": "260773", "train_nsentences": "1750.04", "train_wps": "44682.9", "train_ups": "0.17", "train_wpb": "260773", "train_bsz": "1750", "train_num_updates": "61844", "train_lr": "0.000459451", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "156", "train_gb_free": "39.3", "train_wall": "21032"}
[2024-10-09 15:19:14,166][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:19:14,175][fairseq.trainer][INFO] - begin training epoch 1290
[2024-10-09 15:19:14,175][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:19:31,523][fairseq_cli.train][INFO] - end of epoch 1290 (average epoch stats below)
[2024-10-09 15:19:31,525][train][INFO] - {"epoch": 1290, "train_loss": "0.491", "train_ntokens": "260799", "train_nsentences": "1750.04", "train_wps": "44693.9", "train_ups": "0.17", "train_wpb": "260799", "train_bsz": "1750", "train_num_updates": "61892", "train_lr": "0.000459386", "train_gnorm": "0.378", "train_loss_scale": "4", "train_train_wall": "102", "train_gb_free": "39.6", "train_wall": "21100"}
[2024-10-09 15:19:31,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:19:31,959][fairseq.trainer][INFO] - begin training epoch 1291
[2024-10-09 15:19:31,959][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:25:45,571][fairseq_cli.train][INFO] - end of epoch 1290 (average epoch stats below)
[2024-10-09 15:25:45,616][train][INFO] - {"epoch": 1290, "train_loss": "0.491", "train_ntokens": "260799", "train_nsentences": "1750.04", "train_wps": "31963.3", "train_ups": "0.12", "train_wpb": "260799", "train_bsz": "1750", "train_num_updates": "61892", "train_lr": "0.000459386", "train_gnorm": "0.379", "train_loss_scale": "4", "train_train_wall": "241", "train_gb_free": "39.6", "train_wall": "21423"}
[2024-10-09 15:25:45,781][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:25:45,792][fairseq.trainer][INFO] - begin training epoch 1291
[2024-10-09 15:25:45,793][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:26:02,817][fairseq_cli.train][INFO] - end of epoch 1291 (average epoch stats below)
[2024-10-09 15:26:02,820][train][INFO] - {"epoch": 1291, "train_loss": "0.481", "train_ntokens": "260596", "train_nsentences": "1750.04", "train_wps": "31967.7", "train_ups": "0.12", "train_wpb": "260596", "train_bsz": "1750", "train_num_updates": "61940", "train_lr": "0.000459321", "train_gnorm": "0.379", "train_loss_scale": "4", "train_train_wall": "123", "train_gb_free": "40.1", "train_wall": "21491"}
[2024-10-09 15:26:03,043][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:26:03,047][fairseq.trainer][INFO] - begin training epoch 1292
[2024-10-09 15:26:03,047][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:33:02,457][fairseq_cli.train][INFO] - end of epoch 1292 (average epoch stats below)
[2024-10-09 15:33:02,507][train][INFO] - {"epoch": 1292, "train_loss": "0.473", "train_ntokens": "260725", "train_nsentences": "1750.04", "train_wps": "29820.2", "train_ups": "0.11", "train_wpb": "260725", "train_bsz": "1750", "train_num_updates": "61988", "train_lr": "0.000459255", "train_gnorm": "0.371", "train_loss_scale": "4", "train_train_wall": "119", "train_gb_free": "40.5", "train_wall": "21911"}
[2024-10-09 15:33:02,697][fairseq_cli.train][INFO] - end of epoch 1291 (average epoch stats below)
[2024-10-09 15:33:02,699][train][INFO] - {"epoch": 1291, "train_loss": "0.481", "train_ntokens": "260596", "train_nsentences": "1750.04", "train_wps": "28618.6", "train_ups": "0.11", "train_wpb": "260596", "train_bsz": "1750", "train_num_updates": "61940", "train_lr": "0.000459321", "train_gnorm": "0.38", "train_loss_scale": "4", "train_train_wall": "262", "train_gb_free": "40.1", "train_wall": "21860"}
[2024-10-09 15:33:02,840][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:33:02,854][fairseq.trainer][INFO] - begin training epoch 1293
[2024-10-09 15:33:02,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:33:03,023][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:33:03,033][fairseq.trainer][INFO] - begin training epoch 1292
[2024-10-09 15:33:03,033][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:37:04,082][train_inner][INFO] - {"epoch": 1293, "update": 1292.25, "loss": "0.481", "ntokens": "260662", "nsentences": "1747.32", "wps": "37448", "ups": "0.14", "wpb": "260662", "bsz": "1747.3", "num_updates": "62000", "lr": "0.000459239", "gnorm": "0.378", "loss_scale": "4", "train_wall": "452", "gb_free": "39.2", "wall": "22152"}
[2024-10-09 15:38:21,751][fairseq_cli.train][INFO] - end of epoch 1292 (average epoch stats below)
[2024-10-09 15:38:21,768][train][INFO] - {"epoch": 1292, "train_loss": "0.473", "train_ntokens": "260725", "train_nsentences": "1750.04", "train_wps": "39224.3", "train_ups": "0.15", "train_wpb": "260725", "train_bsz": "1750", "train_num_updates": "61988", "train_lr": "0.000459255", "train_gnorm": "0.369", "train_loss_scale": "4", "train_train_wall": "92", "train_gb_free": "40.5", "train_wall": "22179"}
[2024-10-09 15:38:22,089][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:38:22,112][fairseq.trainer][INFO] - begin training epoch 1293
[2024-10-09 15:38:22,113][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:38:23,746][fairseq_cli.train][INFO] - end of epoch 1293 (average epoch stats below)
[2024-10-09 15:38:23,749][train][INFO] - {"epoch": 1293, "train_loss": "0.482", "train_ntokens": "260682", "train_nsentences": "1750.04", "train_wps": "38951.7", "train_ups": "0.15", "train_wpb": "260682", "train_bsz": "1750", "train_num_updates": "62036", "train_lr": "0.00045919", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "145", "train_gb_free": "40.8", "train_wall": "22232"}
[2024-10-09 15:38:23,964][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:38:23,970][fairseq.trainer][INFO] - begin training epoch 1294
[2024-10-09 15:38:23,971][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:43:54,131][train_inner][INFO] - {"epoch": 1293, "update": 1292.25, "loss": "0.481", "ntokens": "260662", "nsentences": "1747.32", "wps": "34135.4", "ups": "0.13", "wpb": "260662", "bsz": "1747.3", "num_updates": "62000", "lr": "0.000459239", "gnorm": "0.377", "loss_scale": "4", "train_wall": "874", "gb_free": "39.2", "wall": "22512"}
[2024-10-09 15:45:10,127][fairseq_cli.train][INFO] - end of epoch 1293 (average epoch stats below)
[2024-10-09 15:45:10,166][train][INFO] - {"epoch": 1293, "train_loss": "0.482", "train_ntokens": "260682", "train_nsentences": "1750.04", "train_wps": "30640.5", "train_ups": "0.12", "train_wpb": "260682", "train_bsz": "1750", "train_num_updates": "62036", "train_lr": "0.00045919", "train_gnorm": "0.383", "train_loss_scale": "4", "train_train_wall": "312", "train_gb_free": "40.8", "train_wall": "22588"}
[2024-10-09 15:45:10,328][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:45:10,334][fairseq.trainer][INFO] - begin training epoch 1294
[2024-10-09 15:45:10,334][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:45:10,910][fairseq_cli.train][INFO] - end of epoch 1294 (average epoch stats below)
[2024-10-09 15:45:10,914][train][INFO] - {"epoch": 1294, "train_loss": "0.478", "train_ntokens": "260847", "train_nsentences": "1750.04", "train_wps": "30751.2", "train_ups": "0.12", "train_wpb": "260847", "train_bsz": "1750", "train_num_updates": "62084", "train_lr": "0.000459125", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "98", "train_gb_free": "39.8", "train_wall": "22639"}
[2024-10-09 15:45:11,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:45:11,053][fairseq.trainer][INFO] - begin training epoch 1295
[2024-10-09 15:45:11,056][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:51:05,611][fairseq_cli.train][INFO] - end of epoch 1295 (average epoch stats below)
[2024-10-09 15:51:05,645][train][INFO] - {"epoch": 1295, "train_loss": "0.478", "train_ntokens": "261172", "train_nsentences": "1750.04", "train_wps": "35341.5", "train_ups": "0.14", "train_wpb": "261172", "train_bsz": "1750", "train_num_updates": "62132", "train_lr": "0.00045906", "train_gnorm": "0.395", "train_loss_scale": "4", "train_train_wall": "237", "train_gb_free": "39.2", "train_wall": "22994"}
[2024-10-09 15:51:06,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:51:06,036][fairseq.trainer][INFO] - begin training epoch 1296
[2024-10-09 15:51:06,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:51:07,301][fairseq_cli.train][INFO] - end of epoch 1294 (average epoch stats below)
[2024-10-09 15:51:07,317][train][INFO] - {"epoch": 1294, "train_loss": "0.478", "train_ntokens": "260847", "train_nsentences": "1750.04", "train_wps": "35058.7", "train_ups": "0.13", "train_wpb": "260847", "train_bsz": "1750", "train_num_updates": "62084", "train_lr": "0.000459125", "train_gnorm": "0.374", "train_loss_scale": "4", "train_train_wall": "114", "train_gb_free": "39.8", "train_wall": "22945"}
[2024-10-09 15:51:07,506][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:51:07,511][fairseq.trainer][INFO] - begin training epoch 1295
[2024-10-09 15:51:07,512][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:56:25,613][fairseq_cli.train][INFO] - end of epoch 1295 (average epoch stats below)
[2024-10-09 15:56:25,640][train][INFO] - {"epoch": 1295, "train_loss": "0.478", "train_ntokens": "261172", "train_nsentences": "1750.04", "train_wps": "39383.7", "train_ups": "0.15", "train_wpb": "261172", "train_bsz": "1750", "train_num_updates": "62132", "train_lr": "0.00045906", "train_gnorm": "0.393", "train_loss_scale": "4", "train_train_wall": "144", "train_gb_free": "39.2", "train_wall": "23263"}
[2024-10-09 15:56:25,916][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:56:25,944][fairseq.trainer][INFO] - begin training epoch 1296
[2024-10-09 15:56:25,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:56:26,669][fairseq_cli.train][INFO] - end of epoch 1296 (average epoch stats below)
[2024-10-09 15:56:26,671][train][INFO] - {"epoch": 1296, "train_loss": "0.474", "train_ntokens": "260750", "train_nsentences": "1750.04", "train_wps": "38988.1", "train_ups": "0.15", "train_wpb": "260750", "train_bsz": "1750", "train_num_updates": "62180", "train_lr": "0.000458995", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "223", "train_gb_free": "39.9", "train_wall": "23315"}
[2024-10-09 15:56:26,869][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:56:26,874][fairseq.trainer][INFO] - begin training epoch 1297
[2024-10-09 15:56:26,875][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:59:08,866][train_inner][INFO] - {"epoch": 1297, "update": 1296.417, "loss": "0.48", "ntokens": "260976", "nsentences": "1757.72", "wps": "39405.3", "ups": "0.15", "wpb": "260976", "bsz": "1757.7", "num_updates": "62200", "lr": "0.000458967", "gnorm": "0.38", "loss_scale": "4", "train_wall": "698", "gb_free": "39.6", "wall": "23477"}
[2024-10-09 15:59:52,922][fairseq_cli.train][INFO] - end of epoch 1297 (average epoch stats below)
[2024-10-09 15:59:52,942][train][INFO] - {"epoch": 1297, "train_loss": "0.486", "train_ntokens": "260610", "train_nsentences": "1750.04", "train_wps": "60651.2", "train_ups": "0.23", "train_wpb": "260610", "train_bsz": "1750", "train_num_updates": "62228", "train_lr": "0.000458929", "train_gnorm": "0.374", "train_loss_scale": "4", "train_train_wall": "104", "train_gb_free": "39.7", "train_wall": "23521"}
[2024-10-09 15:59:53,161][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:59:53,180][fairseq.trainer][INFO] - begin training epoch 1298
[2024-10-09 15:59:53,181][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 15:59:55,505][fairseq_cli.train][INFO] - end of epoch 1296 (average epoch stats below)
[2024-10-09 15:59:55,526][train][INFO] - {"epoch": 1296, "train_loss": "0.474", "train_ntokens": "260750", "train_nsentences": "1750.04", "train_wps": "59634.9", "train_ups": "0.23", "train_wpb": "260750", "train_bsz": "1750", "train_num_updates": "62180", "train_lr": "0.000458995", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "132", "train_gb_free": "39.9", "train_wall": "23473"}
[2024-10-09 15:59:55,641][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 15:59:55,652][fairseq.trainer][INFO] - begin training epoch 1297
[2024-10-09 15:59:55,653][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:03:03,923][train_inner][INFO] - {"epoch": 1297, "update": 1296.417, "loss": "0.48", "ntokens": "260976", "nsentences": "1757.72", "wps": "45401.3", "ups": "0.17", "wpb": "260976", "bsz": "1757.7", "num_updates": "62200", "lr": "0.000458967", "gnorm": "0.379", "loss_scale": "4", "train_wall": "548", "gb_free": "39.6", "wall": "23661"}
[2024-10-09 16:03:45,164][fairseq_cli.train][INFO] - end of epoch 1298 (average epoch stats below)
[2024-10-09 16:03:45,185][train][INFO] - {"epoch": 1298, "train_loss": "0.476", "train_ntokens": "260635", "train_nsentences": "1750.04", "train_wps": "53873.5", "train_ups": "0.21", "train_wpb": "260636", "train_bsz": "1750", "train_num_updates": "62276", "train_lr": "0.000458864", "train_gnorm": "0.369", "train_loss_scale": "4", "train_train_wall": "85", "train_gb_free": "41", "train_wall": "23753"}
[2024-10-09 16:03:45,281][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:03:45,282][fairseq_cli.train][INFO] - end of epoch 1297 (average epoch stats below)
[2024-10-09 16:03:45,285][train][INFO] - {"epoch": 1297, "train_loss": "0.487", "train_ntokens": "260610", "train_nsentences": "1750.04", "train_wps": "54446.3", "train_ups": "0.21", "train_wpb": "260610", "train_bsz": "1750", "train_num_updates": "62228", "train_lr": "0.000458929", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "125", "train_gb_free": "39.7", "train_wall": "23703"}
[2024-10-09 16:03:45,315][fairseq.trainer][INFO] - begin training epoch 1299
[2024-10-09 16:03:45,316][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:03:45,369][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:03:45,373][fairseq.trainer][INFO] - begin training epoch 1298
[2024-10-09 16:03:45,374][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:09:50,705][fairseq_cli.train][INFO] - end of epoch 1298 (average epoch stats below)
[2024-10-09 16:09:50,714][train][INFO] - {"epoch": 1298, "train_loss": "0.476", "train_ntokens": "260635", "train_nsentences": "1750.04", "train_wps": "34235.5", "train_ups": "0.13", "train_wpb": "260636", "train_bsz": "1750", "train_num_updates": "62276", "train_lr": "0.000458864", "train_gnorm": "0.366", "train_loss_scale": "4", "train_train_wall": "102", "train_gb_free": "41", "train_wall": "24068"}
[2024-10-09 16:09:50,925][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:09:50,932][fairseq.trainer][INFO] - begin training epoch 1299
[2024-10-09 16:09:50,932][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:10:04,568][fairseq_cli.train][INFO] - end of epoch 1299 (average epoch stats below)
[2024-10-09 16:10:04,587][train][INFO] - {"epoch": 1299, "train_loss": "0.48", "train_ntokens": "260796", "train_nsentences": "1750.04", "train_wps": "32996.2", "train_ups": "0.13", "train_wpb": "260796", "train_bsz": "1750", "train_num_updates": "62324", "train_lr": "0.000458799", "train_gnorm": "0.36", "train_loss_scale": "4", "train_train_wall": "200", "train_gb_free": "40.2", "train_wall": "24133"}
[2024-10-09 16:10:04,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:10:04,924][fairseq.trainer][INFO] - begin training epoch 1300
[2024-10-09 16:10:04,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:14:17,890][fairseq_cli.train][INFO] - end of epoch 1299 (average epoch stats below)
[2024-10-09 16:14:17,905][train][INFO] - {"epoch": 1299, "train_loss": "0.48", "train_ntokens": "260796", "train_nsentences": "1750.04", "train_wps": "46852.1", "train_ups": "0.18", "train_wpb": "260796", "train_bsz": "1750", "train_num_updates": "62324", "train_lr": "0.000458799", "train_gnorm": "0.359", "train_loss_scale": "4", "train_train_wall": "157", "train_gb_free": "40.2", "train_wall": "24335"}
[2024-10-09 16:14:18,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:14:18,268][fairseq.trainer][INFO] - begin training epoch 1300
[2024-10-09 16:14:18,269][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:14:26,658][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1300 @ 62372 updates
[2024-10-09 16:14:26,659][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 16:14:30,883][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 16:14:30,886][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1300 @ 62372 updates, score None) (writing took 4.2284239418804646 seconds)
[2024-10-09 16:14:30,887][fairseq_cli.train][INFO] - end of epoch 1300 (average epoch stats below)
[2024-10-09 16:14:30,891][train][INFO] - {"epoch": 1300, "train_loss": "0.478", "train_ntokens": "260529", "train_nsentences": "1750.04", "train_wps": "46960.1", "train_ups": "0.18", "train_wpb": "260529", "train_bsz": "1750", "train_num_updates": "62372", "train_lr": "0.000458734", "train_gnorm": "0.341", "train_loss_scale": "4", "train_train_wall": "131", "train_gb_free": "40.1", "train_wall": "24399"}
[2024-10-09 16:14:30,979][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:14:30,986][fairseq.trainer][INFO] - begin training epoch 1301
[2024-10-09 16:14:30,987][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:18:23,485][train_inner][INFO] - {"epoch": 1301, "update": 1300.583, "loss": "0.479", "ntokens": "260468", "nsentences": "1750.59", "wps": "45118.5", "ups": "0.17", "wpb": "260468", "bsz": "1750.6", "num_updates": "62400", "lr": "0.000458696", "gnorm": "0.363", "loss_scale": "4", "train_wall": "606", "gb_free": "39.6", "wall": "24632"}
[2024-10-09 16:18:54,716][fairseq_cli.train][INFO] - end of epoch 1301 (average epoch stats below)
[2024-10-09 16:18:54,728][train][INFO] - {"epoch": 1301, "train_loss": "0.481", "train_ntokens": "260692", "train_nsentences": "1750.04", "train_wps": "47430.1", "train_ups": "0.18", "train_wpb": "260692", "train_bsz": "1750", "train_num_updates": "62420", "train_lr": "0.000458668", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "177", "train_gb_free": "39.8", "train_wall": "24663"}
[2024-10-09 16:18:55,024][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1300 @ 62372 updates
[2024-10-09 16:18:55,025][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 16:18:55,068][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:18:55,085][fairseq.trainer][INFO] - begin training epoch 1302
[2024-10-09 16:18:55,085][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:19:00,212][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 16:19:00,214][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1300 @ 62372 updates, score None) (writing took 5.1898851385340095 seconds)
[2024-10-09 16:19:00,215][fairseq_cli.train][INFO] - end of epoch 1300 (average epoch stats below)
[2024-10-09 16:19:00,217][train][INFO] - {"epoch": 1300, "train_loss": "0.478", "train_ntokens": "260529", "train_nsentences": "1750.04", "train_wps": "44297", "train_ups": "0.17", "train_wpb": "260529", "train_bsz": "1750", "train_num_updates": "62372", "train_lr": "0.000458734", "train_gnorm": "0.341", "train_loss_scale": "4", "train_train_wall": "158", "train_gb_free": "40.1", "train_wall": "24618"}
[2024-10-09 16:19:00,379][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:19:00,384][fairseq.trainer][INFO] - begin training epoch 1301
[2024-10-09 16:19:00,384][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:23:32,912][train_inner][INFO] - {"epoch": 1301, "update": 1300.583, "loss": "0.479", "ntokens": "260468", "nsentences": "1750.59", "wps": "42387.6", "ups": "0.16", "wpb": "260468", "bsz": "1750.6", "num_updates": "62400", "lr": "0.000458696", "gnorm": "0.362", "loss_scale": "4", "train_wall": "624", "gb_free": "39.6", "wall": "24890"}
[2024-10-09 16:24:03,941][fairseq_cli.train][INFO] - end of epoch 1302 (average epoch stats below)
[2024-10-09 16:24:03,956][train][INFO] - {"epoch": 1302, "train_loss": "0.48", "train_ntokens": "260727", "train_nsentences": "1750.04", "train_wps": "40473.3", "train_ups": "0.16", "train_wpb": "260727", "train_bsz": "1750", "train_num_updates": "62468", "train_lr": "0.000458603", "train_gnorm": "0.355", "train_loss_scale": "4", "train_train_wall": "123", "train_gb_free": "39.7", "train_wall": "24972"}
[2024-10-09 16:24:04,332][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:24:04,333][fairseq_cli.train][INFO] - end of epoch 1301 (average epoch stats below)
[2024-10-09 16:24:04,335][train][INFO] - {"epoch": 1301, "train_loss": "0.481", "train_ntokens": "260692", "train_nsentences": "1750.04", "train_wps": "41146.4", "train_ups": "0.16", "train_wpb": "260692", "train_bsz": "1750", "train_num_updates": "62420", "train_lr": "0.000458668", "train_gnorm": "0.379", "train_loss_scale": "4", "train_train_wall": "196", "train_gb_free": "39.8", "train_wall": "24922"}
[2024-10-09 16:24:04,355][fairseq.trainer][INFO] - begin training epoch 1303
[2024-10-09 16:24:04,355][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:24:04,609][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:24:04,618][fairseq.trainer][INFO] - begin training epoch 1302
[2024-10-09 16:24:04,620][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:27:52,591][fairseq_cli.train][INFO] - end of epoch 1303 (average epoch stats below)
[2024-10-09 16:27:52,601][train][INFO] - {"epoch": 1303, "train_loss": "0.479", "train_ntokens": "260999", "train_nsentences": "1750.04", "train_wps": "54793.3", "train_ups": "0.21", "train_wpb": "260999", "train_bsz": "1750", "train_num_updates": "62516", "train_lr": "0.000458538", "train_gnorm": "0.363", "train_loss_scale": "4", "train_train_wall": "88", "train_gb_free": "39.6", "train_wall": "25201"}
[2024-10-09 16:27:52,968][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:27:52,986][fairseq.trainer][INFO] - begin training epoch 1304
[2024-10-09 16:27:52,987][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:27:55,729][fairseq_cli.train][INFO] - end of epoch 1302 (average epoch stats below)
[2024-10-09 16:27:55,733][train][INFO] - {"epoch": 1302, "train_loss": "0.48", "train_ntokens": "260727", "train_nsentences": "1750.04", "train_wps": "54084.8", "train_ups": "0.21", "train_wpb": "260727", "train_bsz": "1750", "train_num_updates": "62468", "train_lr": "0.000458603", "train_gnorm": "0.354", "train_loss_scale": "4", "train_train_wall": "128", "train_gb_free": "39.7", "train_wall": "25153"}
[2024-10-09 16:27:55,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:27:55,990][fairseq.trainer][INFO] - begin training epoch 1303
[2024-10-09 16:27:55,990][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:32:29,429][fairseq_cli.train][INFO] - end of epoch 1304 (average epoch stats below)
[2024-10-09 16:32:29,443][train][INFO] - {"epoch": 1304, "train_loss": "0.489", "train_ntokens": "260471", "train_nsentences": "1750.04", "train_wps": "45162.9", "train_ups": "0.17", "train_wpb": "260471", "train_bsz": "1750", "train_num_updates": "62564", "train_lr": "0.000458473", "train_gnorm": "0.376", "train_loss_scale": "4", "train_train_wall": "77", "train_gb_free": "39.6", "train_wall": "25478"}
[2024-10-09 16:32:29,791][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:32:29,820][fairseq.trainer][INFO] - begin training epoch 1305
[2024-10-09 16:32:29,821][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:32:32,370][fairseq_cli.train][INFO] - end of epoch 1303 (average epoch stats below)
[2024-10-09 16:32:32,374][train][INFO] - {"epoch": 1303, "train_loss": "0.479", "train_ntokens": "260999", "train_nsentences": "1750.04", "train_wps": "45286.8", "train_ups": "0.17", "train_wpb": "260999", "train_bsz": "1750", "train_num_updates": "62516", "train_lr": "0.000458538", "train_gnorm": "0.364", "train_loss_scale": "4", "train_train_wall": "79", "train_gb_free": "39.6", "train_wall": "25430"}
[2024-10-09 16:32:32,689][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:32:32,693][fairseq.trainer][INFO] - begin training epoch 1304
[2024-10-09 16:32:32,697][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:37:09,250][train_inner][INFO] - {"epoch": 1305, "update": 1304.75, "loss": "0.483", "ntokens": "261007", "nsentences": "1737.73", "wps": "46370.7", "ups": "0.18", "wpb": "261007", "bsz": "1737.7", "num_updates": "62600", "lr": "0.000458424", "gnorm": "0.369", "loss_scale": "4", "train_wall": "426", "gb_free": "39.8", "wall": "25758"}
[2024-10-09 16:37:34,132][fairseq_cli.train][INFO] - end of epoch 1305 (average epoch stats below)
[2024-10-09 16:37:34,159][train][INFO] - {"epoch": 1305, "train_loss": "0.485", "train_ntokens": "260714", "train_nsentences": "1750.04", "train_wps": "41072.5", "train_ups": "0.16", "train_wpb": "260714", "train_bsz": "1750", "train_num_updates": "62612", "train_lr": "0.000458408", "train_gnorm": "0.383", "train_loss_scale": "4", "train_train_wall": "132", "train_gb_free": "39.8", "train_wall": "25782"}
[2024-10-09 16:37:34,262][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:37:34,311][fairseq.trainer][INFO] - begin training epoch 1306
[2024-10-09 16:37:34,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:37:37,769][fairseq_cli.train][INFO] - end of epoch 1304 (average epoch stats below)
[2024-10-09 16:37:37,772][train][INFO] - {"epoch": 1304, "train_loss": "0.489", "train_ntokens": "260471", "train_nsentences": "1750.04", "train_wps": "40939.3", "train_ups": "0.16", "train_wpb": "260471", "train_bsz": "1750", "train_num_updates": "62564", "train_lr": "0.000458473", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "132", "train_gb_free": "39.6", "train_wall": "25735"}
[2024-10-09 16:37:37,959][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:37:37,974][fairseq.trainer][INFO] - begin training epoch 1305
[2024-10-09 16:37:37,974][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:40:45,022][train_inner][INFO] - {"epoch": 1305, "update": 1304.75, "loss": "0.483", "ntokens": "261007", "nsentences": "1737.73", "wps": "50578.4", "ups": "0.19", "wpb": "261007", "bsz": "1737.7", "num_updates": "62600", "lr": "0.000458424", "gnorm": "0.366", "loss_scale": "4", "train_wall": "476", "gb_free": "39.8", "wall": "25923"}
[2024-10-09 16:41:10,362][fairseq_cli.train][INFO] - end of epoch 1306 (average epoch stats below)
[2024-10-09 16:41:10,365][train][INFO] - {"epoch": 1306, "train_loss": "0.488", "train_ntokens": "261025", "train_nsentences": "1750.04", "train_wps": "57951.2", "train_ups": "0.22", "train_wpb": "261025", "train_bsz": "1750", "train_num_updates": "62660", "train_lr": "0.000458342", "train_gnorm": "0.359", "train_loss_scale": "4", "train_train_wall": "91", "train_gb_free": "39.7", "train_wall": "25999"}
[2024-10-09 16:41:10,670][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:41:10,692][fairseq.trainer][INFO] - begin training epoch 1307
[2024-10-09 16:41:10,693][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:41:11,396][fairseq_cli.train][INFO] - end of epoch 1305 (average epoch stats below)
[2024-10-09 16:41:11,402][train][INFO] - {"epoch": 1305, "train_loss": "0.485", "train_ntokens": "260714", "train_nsentences": "1750.04", "train_wps": "58581.2", "train_ups": "0.22", "train_wpb": "260714", "train_bsz": "1750", "train_num_updates": "62612", "train_lr": "0.000458408", "train_gnorm": "0.378", "train_loss_scale": "4", "train_train_wall": "131", "train_gb_free": "39.8", "train_wall": "25949"}
[2024-10-09 16:41:11,604][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:41:11,616][fairseq.trainer][INFO] - begin training epoch 1306
[2024-10-09 16:41:11,617][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:46:21,195][fairseq_cli.train][INFO] - end of epoch 1306 (average epoch stats below)
[2024-10-09 16:46:21,204][train][INFO] - {"epoch": 1306, "train_loss": "0.489", "train_ntokens": "261025", "train_nsentences": "1750.04", "train_wps": "40443", "train_ups": "0.15", "train_wpb": "261025", "train_bsz": "1750", "train_num_updates": "62660", "train_lr": "0.000458342", "train_gnorm": "0.363", "train_loss_scale": "4", "train_train_wall": "119", "train_gb_free": "39.7", "train_wall": "26259"}
[2024-10-09 16:46:21,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:46:21,497][fairseq.trainer][INFO] - begin training epoch 1307
[2024-10-09 16:46:21,498][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:46:22,037][fairseq_cli.train][INFO] - end of epoch 1307 (average epoch stats below)
[2024-10-09 16:46:22,041][train][INFO] - {"epoch": 1307, "train_loss": "0.48", "train_ntokens": "260584", "train_nsentences": "1750.04", "train_wps": "40132", "train_ups": "0.15", "train_wpb": "260584", "train_bsz": "1750", "train_num_updates": "62708", "train_lr": "0.000458277", "train_gnorm": "0.36", "train_loss_scale": "4", "train_train_wall": "93", "train_gb_free": "40.8", "train_wall": "26310"}
[2024-10-09 16:46:22,248][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:46:22,254][fairseq.trainer][INFO] - begin training epoch 1308
[2024-10-09 16:46:22,254][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:50:23,899][fairseq_cli.train][INFO] - end of epoch 1308 (average epoch stats below)
[2024-10-09 16:50:23,919][train][INFO] - {"epoch": 1308, "train_loss": "0.476", "train_ntokens": "260655", "train_nsentences": "1750.04", "train_wps": "51728.4", "train_ups": "0.2", "train_wpb": "260655", "train_bsz": "1750", "train_num_updates": "62756", "train_lr": "0.000458212", "train_gnorm": "0.382", "train_loss_scale": "4", "train_train_wall": "142", "train_gb_free": "39.7", "train_wall": "26552"}
[2024-10-09 16:50:24,332][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:50:24,345][fairseq.trainer][INFO] - begin training epoch 1309
[2024-10-09 16:50:24,345][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:50:28,179][fairseq_cli.train][INFO] - end of epoch 1307 (average epoch stats below)
[2024-10-09 16:50:28,182][train][INFO] - {"epoch": 1307, "train_loss": "0.48", "train_ntokens": "260584", "train_nsentences": "1750.04", "train_wps": "50645.1", "train_ups": "0.19", "train_wpb": "260584", "train_bsz": "1750", "train_num_updates": "62708", "train_lr": "0.000458277", "train_gnorm": "0.361", "train_loss_scale": "4", "train_train_wall": "106", "train_gb_free": "40.8", "train_wall": "26506"}
[2024-10-09 16:50:28,443][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:50:28,447][fairseq.trainer][INFO] - begin training epoch 1308
[2024-10-09 16:50:28,447][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:55:34,443][fairseq_cli.train][INFO] - end of epoch 1308 (average epoch stats below)
[2024-10-09 16:55:34,491][train][INFO] - {"epoch": 1308, "train_loss": "0.476", "train_ntokens": "260655", "train_nsentences": "1750.04", "train_wps": "40850.9", "train_ups": "0.16", "train_wpb": "260655", "train_bsz": "1750", "train_num_updates": "62756", "train_lr": "0.000458212", "train_gnorm": "0.382", "train_loss_scale": "4", "train_train_wall": "115", "train_gb_free": "39.7", "train_wall": "26812"}
[2024-10-09 16:55:34,878][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:55:34,901][fairseq.trainer][INFO] - begin training epoch 1309
[2024-10-09 16:55:34,902][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 16:55:39,778][train_inner][INFO] - {"epoch": 1309, "update": 1308.917, "loss": "0.482", "ntokens": "260484", "nsentences": "1762.67", "wps": "46913.3", "ups": "0.18", "wpb": "260484", "bsz": "1762.7", "num_updates": "62800", "lr": "0.000458152", "gnorm": "0.367", "loss_scale": "4", "train_wall": "483", "gb_free": "42", "wall": "26868"}
[2024-10-09 16:55:41,157][fairseq_cli.train][INFO] - end of epoch 1309 (average epoch stats below)
[2024-10-09 16:55:41,161][train][INFO] - {"epoch": 1309, "train_loss": "0.478", "train_ntokens": "260862", "train_nsentences": "1750.04", "train_wps": "39475", "train_ups": "0.15", "train_wpb": "260862", "train_bsz": "1750", "train_num_updates": "62804", "train_lr": "0.000458147", "train_gnorm": "0.363", "train_loss_scale": "4", "train_train_wall": "134", "train_gb_free": "39.6", "train_wall": "26869"}
[2024-10-09 16:55:41,454][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 16:55:41,461][fairseq.trainer][INFO] - begin training epoch 1310
[2024-10-09 16:55:41,462][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:00:42,601][fairseq_cli.train][INFO] - end of epoch 1310 (average epoch stats below)
[2024-10-09 17:00:42,623][train][INFO] - {"epoch": 1310, "train_loss": "0.475", "train_ntokens": "260194", "train_nsentences": "1750.04", "train_wps": "41431.2", "train_ups": "0.16", "train_wpb": "260194", "train_bsz": "1750", "train_num_updates": "62852", "train_lr": "0.000458082", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "131", "train_gb_free": "39.7", "train_wall": "27171"}
[2024-10-09 17:00:42,907][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:00:42,913][fairseq.trainer][INFO] - begin training epoch 1311
[2024-10-09 17:00:42,914][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:00:43,115][train_inner][INFO] - {"epoch": 1309, "update": 1308.917, "loss": "0.482", "ntokens": "260484", "nsentences": "1762.67", "wps": "43483.8", "ups": "0.17", "wpb": "260484", "bsz": "1762.7", "num_updates": "62800", "lr": "0.000458152", "gnorm": "0.368", "loss_scale": "4", "train_wall": "569", "gb_free": "42", "wall": "27121"}
[2024-10-09 17:00:44,300][fairseq_cli.train][INFO] - end of epoch 1309 (average epoch stats below)
[2024-10-09 17:00:44,302][train][INFO] - {"epoch": 1309, "train_loss": "0.478", "train_ntokens": "260862", "train_nsentences": "1750.04", "train_wps": "40416.6", "train_ups": "0.15", "train_wpb": "260862", "train_bsz": "1750", "train_num_updates": "62804", "train_lr": "0.000458147", "train_gnorm": "0.362", "train_loss_scale": "4", "train_train_wall": "205", "train_gb_free": "39.6", "train_wall": "27122"}
[2024-10-09 17:00:44,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:00:44,597][fairseq.trainer][INFO] - begin training epoch 1310
[2024-10-09 17:00:44,598][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:05:43,891][fairseq_cli.train][INFO] - end of epoch 1310 (average epoch stats below)
[2024-10-09 17:05:43,900][train][INFO] - {"epoch": 1310, "train_loss": "0.475", "train_ntokens": "260194", "train_nsentences": "1750.04", "train_wps": "41687.6", "train_ups": "0.16", "train_wpb": "260194", "train_bsz": "1750", "train_num_updates": "62852", "train_lr": "0.000458082", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "126", "train_gb_free": "39.7", "train_wall": "27421"}
[2024-10-09 17:05:44,156][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:05:44,173][fairseq.trainer][INFO] - begin training epoch 1311
[2024-10-09 17:05:44,174][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:05:44,392][fairseq_cli.train][INFO] - end of epoch 1311 (average epoch stats below)
[2024-10-09 17:05:44,394][train][INFO] - {"epoch": 1311, "train_loss": "0.48", "train_ntokens": "260384", "train_nsentences": "1750.04", "train_wps": "41418.8", "train_ups": "0.16", "train_wpb": "260384", "train_bsz": "1750", "train_num_updates": "62900", "train_lr": "0.000458016", "train_gnorm": "0.372", "train_loss_scale": "4", "train_train_wall": "180", "train_gb_free": "39.6", "train_wall": "27473"}
[2024-10-09 17:05:44,580][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:05:44,586][fairseq.trainer][INFO] - begin training epoch 1312
[2024-10-09 17:05:44,587][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:10:05,880][fairseq_cli.train][INFO] - end of epoch 1312 (average epoch stats below)
[2024-10-09 17:10:05,885][train][INFO] - {"epoch": 1312, "train_loss": "0.486", "train_ntokens": "260829", "train_nsentences": "1750.04", "train_wps": "47879.3", "train_ups": "0.18", "train_wpb": "260829", "train_bsz": "1750", "train_num_updates": "62948", "train_lr": "0.000457951", "train_gnorm": "0.409", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "40.5", "train_wall": "27734"}
[2024-10-09 17:10:06,167][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:10:06,196][fairseq.trainer][INFO] - begin training epoch 1313
[2024-10-09 17:10:06,197][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:10:06,425][fairseq_cli.train][INFO] - end of epoch 1311 (average epoch stats below)
[2024-10-09 17:10:06,440][train][INFO] - {"epoch": 1311, "train_loss": "0.48", "train_ntokens": "260384", "train_nsentences": "1750.04", "train_wps": "47606.4", "train_ups": "0.18", "train_wpb": "260384", "train_bsz": "1750", "train_num_updates": "62900", "train_lr": "0.000458016", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "162", "train_gb_free": "39.6", "train_wall": "27684"}
[2024-10-09 17:10:06,753][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:10:06,768][fairseq.trainer][INFO] - begin training epoch 1312
[2024-10-09 17:10:06,769][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:14:07,842][fairseq_cli.train][INFO] - end of epoch 1312 (average epoch stats below)
[2024-10-09 17:14:07,868][train][INFO] - {"epoch": 1312, "train_loss": "0.486", "train_ntokens": "260829", "train_nsentences": "1750.04", "train_wps": "51859.1", "train_ups": "0.2", "train_wpb": "260829", "train_bsz": "1750", "train_num_updates": "62948", "train_lr": "0.000457951", "train_gnorm": "0.411", "train_loss_scale": "4", "train_train_wall": "77", "train_gb_free": "40.5", "train_wall": "27925"}
[2024-10-09 17:14:08,073][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:14:08,081][fairseq.trainer][INFO] - begin training epoch 1313
[2024-10-09 17:14:08,082][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:14:08,436][fairseq_cli.train][INFO] - end of epoch 1313 (average epoch stats below)
[2024-10-09 17:14:08,440][train][INFO] - {"epoch": 1313, "train_loss": "0.474", "train_ntokens": "260814", "train_nsentences": "1750.04", "train_wps": "51614.3", "train_ups": "0.2", "train_wpb": "260814", "train_bsz": "1750", "train_num_updates": "62996", "train_lr": "0.000457886", "train_gnorm": "0.376", "train_loss_scale": "4", "train_train_wall": "131", "train_gb_free": "39.3", "train_wall": "27977"}
[2024-10-09 17:14:08,573][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:14:08,577][fairseq.trainer][INFO] - begin training epoch 1314
[2024-10-09 17:14:08,577][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:16:27,737][train_inner][INFO] - {"epoch": 1314, "update": 1313.083, "loss": "0.479", "ntokens": "260658", "nsentences": "1753.27", "wps": "41774.3", "ups": "0.16", "wpb": "260658", "bsz": "1753.3", "num_updates": "63000", "lr": "0.00045788", "gnorm": "0.384", "loss_scale": "4", "train_wall": "525", "gb_free": "39.7", "wall": "28116"}
[2024-10-09 17:17:38,168][fairseq_cli.train][INFO] - end of epoch 1314 (average epoch stats below)
[2024-10-09 17:17:38,181][train][INFO] - {"epoch": 1314, "train_loss": "0.483", "train_ntokens": "261039", "train_nsentences": "1750.04", "train_wps": "59741.6", "train_ups": "0.23", "train_wpb": "261039", "train_bsz": "1750", "train_num_updates": "63044", "train_lr": "0.000457821", "train_gnorm": "0.34", "train_loss_scale": "4", "train_train_wall": "79", "train_gb_free": "40", "train_wall": "28186"}
[2024-10-09 17:17:38,320][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:17:38,340][fairseq.trainer][INFO] - begin training epoch 1315
[2024-10-09 17:17:38,341][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:17:38,466][fairseq_cli.train][INFO] - end of epoch 1313 (average epoch stats below)
[2024-10-09 17:17:38,468][train][INFO] - {"epoch": 1313, "train_loss": "0.474", "train_ntokens": "260814", "train_nsentences": "1750.04", "train_wps": "59445.6", "train_ups": "0.23", "train_wpb": "260814", "train_bsz": "1750", "train_num_updates": "62996", "train_lr": "0.000457886", "train_gnorm": "0.371", "train_loss_scale": "4", "train_train_wall": "127", "train_gb_free": "39.3", "train_wall": "28136"}
[2024-10-09 17:17:38,638][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:17:38,651][fairseq.trainer][INFO] - begin training epoch 1314
[2024-10-09 17:17:38,655][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:20:04,864][train_inner][INFO] - {"epoch": 1314, "update": 1313.083, "loss": "0.479", "ntokens": "260658", "nsentences": "1753.27", "wps": "44874.3", "ups": "0.17", "wpb": "260658", "bsz": "1753.3", "num_updates": "63000", "lr": "0.00045788", "gnorm": "0.383", "loss_scale": "4", "train_wall": "542", "gb_free": "39.7", "wall": "28282"}
[2024-10-09 17:20:59,589][fairseq_cli.train][INFO] - end of epoch 1315 (average epoch stats below)
[2024-10-09 17:20:59,604][train][INFO] - {"epoch": 1315, "train_loss": "0.477", "train_ntokens": "260880", "train_nsentences": "1750.04", "train_wps": "62172.1", "train_ups": "0.24", "train_wpb": "260880", "train_bsz": "1750", "train_num_updates": "63092", "train_lr": "0.000457755", "train_gnorm": "0.398", "train_loss_scale": "4", "train_train_wall": "116", "train_gb_free": "39.7", "train_wall": "28388"}
[2024-10-09 17:21:00,018][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:21:00,036][fairseq.trainer][INFO] - begin training epoch 1316
[2024-10-09 17:21:00,037][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:21:04,903][fairseq_cli.train][INFO] - end of epoch 1314 (average epoch stats below)
[2024-10-09 17:21:04,906][train][INFO] - {"epoch": 1314, "train_loss": "0.483", "train_ntokens": "261039", "train_nsentences": "1750.04", "train_wps": "60696.7", "train_ups": "0.23", "train_wpb": "261039", "train_bsz": "1750", "train_num_updates": "63044", "train_lr": "0.000457821", "train_gnorm": "0.343", "train_loss_scale": "4", "train_train_wall": "108", "train_gb_free": "40", "train_wall": "28342"}
[2024-10-09 17:21:05,098][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:21:05,110][fairseq.trainer][INFO] - begin training epoch 1315
[2024-10-09 17:21:05,111][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:25:05,841][fairseq_cli.train][INFO] - end of epoch 1316 (average epoch stats below)
[2024-10-09 17:25:05,853][train][INFO] - {"epoch": 1316, "train_loss": "0.482", "train_ntokens": "260648", "train_nsentences": "1750.04", "train_wps": "50808.1", "train_ups": "0.19", "train_wpb": "260648", "train_bsz": "1750", "train_num_updates": "63140", "train_lr": "0.00045769", "train_gnorm": "0.348", "train_loss_scale": "4", "train_train_wall": "73", "train_gb_free": "39.3", "train_wall": "28634"}
[2024-10-09 17:25:06,025][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:25:06,048][fairseq.trainer][INFO] - begin training epoch 1317
[2024-10-09 17:25:06,048][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 17:25:06,904][fairseq_cli.train][INFO] - end of epoch 1315 (average epoch stats below)
[2024-10-09 17:25:06,908][train][INFO] - {"epoch": 1315, "train_loss": "0.477", "train_ntokens": "260880", "train_nsentences": "1750.04", "train_wps": "51745.4", "train_ups": "0.2", "train_wpb": "260880", "train_bsz": "1750", "train_num_updates": "63092", "train_lr": "0.000457755", "train_gnorm": "0.401", "train_loss_scale": "4", "train_train_wall": "125", "train_gb_free": "39.7", "train_wall": "28584"}
[2024-10-09 17:25:06,988][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 17:25:06,991][fairseq.trainer][INFO] - begin training epoch 1316
[2024-10-09 17:25:06,991][fairseq_cli.train][INFO] - Start iterating over samples
