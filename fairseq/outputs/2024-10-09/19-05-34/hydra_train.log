[2024-10-09 19:06:12,086][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11002', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:12,216][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15313', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:12,781][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16592', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:12,966][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11989', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:13,181][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18587', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:13,442][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19308', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:15,427][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16948', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:15,654][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:15,656][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:15,656][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:15,656][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:15,656][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:15,657][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:16,930][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11404', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'gloss'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_800k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase800/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 19:06:16,953][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:16,954][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:16,957][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:16,957][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:16,957][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:16,958][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:16,956][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:16,959][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:16,966][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:16,966][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:16,967][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:16,968][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:17,472][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:17,479][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:17,479][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:17,479][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:17,479][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:17,480][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:19,368][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:19,379][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:19,379][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:19,379][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:19,380][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:19,380][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:19,770][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:19,771][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:19,772][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:19,782][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:19,783][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:19,784][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:20,851][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:22,411][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:22,964][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:24,457][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:26,555][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:27,514][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:27,635][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:27,635][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:27,635][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:27,637][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:27,637][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:30,205][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:06:33,960][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 19:06:33,962][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 19:06:33,963][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 19:06:33,963][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 19:06:33,963][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 19:06:33,964][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 19:06:51,827][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:07:08,434][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:12:56,541][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:12:56,542][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:12:56,543][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:12:56,543][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:12:56,550][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:12:56,551][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:14:35,244][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:14:35,271][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:14:46,010][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:16:39,683][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:16:39,743][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:16:39,743][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:18:51,896][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:18:51,934][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:18:51,935][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:18:51,951][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:18:51,952][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:20:08,887][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:08,890][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:20:08,891][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:20:08,900][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:20:08,901][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,603][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,604][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:20:09,604][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:20:09,604][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:20:09,604][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:20:09,605][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:20:21,067][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:20:21,068][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:20:33,618][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:20:33,620][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:20:38,042][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:20:38,222][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:20:38,231][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:20:43,335][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:20:52,462][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:19,584][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:21:19,584][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:21:19,584][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:21:19,585][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:21:22,249][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:21:22,249][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,249][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,249][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:21:22,250][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:21:22,250][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:21:22,250][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:21:22,251][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:21:39,172][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:21:39,174][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:21:44,223][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:21:53,109][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:21:53,120][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:21:53,120][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:21:58,598][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:21:58,608][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:21:58,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:22:29,236][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:22:29,238][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:22:41,205][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:23:00,329][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:23:00,334][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,334][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,334][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,334][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,335][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,335][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,335][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,335][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:23:00,335][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:23:00,335][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:23:00,335][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:23:00,336][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:23:36,706][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:23:36,743][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:23:43,846][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:24:21,590][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:24:21,612][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:24:21,612][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   4: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   5: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   6: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - rank   7: capabilities =  8.6  ; total memory = 47.529 GB ; name = NVIDIA RTX A6000                        
[2024-10-09 19:24:24,840][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 19:24:24,841][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 19:24:24,841][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 19:24:24,850][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-09 19:24:32,739][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:24:32,756][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:24:32,756][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:24:35,122][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:24:35,128][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:24:35,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:24:55,182][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:24:55,199][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:24:55,200][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:25:03,819][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 191 @ 90970 updates)
[2024-10-09 19:25:03,931][fairseq.trainer][INFO] - loading train data for epoch 191
[2024-10-09 19:25:07,409][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 840029, skipped 0 samples
[2024-10-09 19:25:54,137][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 19:25:54,143][fairseq.trainer][INFO] - begin training epoch 191
[2024-10-09 19:25:54,153][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 19:50:55,554][train_inner][INFO] - {"epoch": 191, "update": 190.063, "loss": "1.015", "ntokens": "241459", "nsentences": "1726.07", "wps": "33353.6", "ups": "0.14", "wpb": "241459", "bsz": "1726.1", "num_updates": "91000", "lr": "0.000419837", "gnorm": "0.373", "loss_scale": "0.125", "train_wall": "288", "gb_free": "40.1", "wall": "1775"}
[2024-10-09 19:50:55,849][train_inner][INFO] - {"epoch": 191, "update": 190.063, "loss": "1.015", "ntokens": "241459", "nsentences": "1726.07", "wps": "26120.7", "ups": "0.11", "wpb": "241459", "bsz": "1726.1", "num_updates": "91000", "lr": "0.000419837", "gnorm": "0.374", "loss_scale": "0.125", "train_wall": "390", "gb_free": "40.1", "wall": "1846"}
[2024-10-09 20:26:55,974][train_inner][INFO] - {"epoch": 191, "update": 190.48, "loss": "1.004", "ntokens": "239623", "nsentences": "1730.58", "wps": "22184.7", "ups": "0.09", "wpb": "239623", "bsz": "1730.6", "num_updates": "91200", "lr": "0.000419565", "gnorm": "0.275", "loss_scale": "0.125", "train_wall": "2033", "gb_free": "39.6", "wall": "3936"}
[2024-10-09 20:26:55,974][train_inner][INFO] - {"epoch": 191, "update": 190.48, "loss": "1.005", "ntokens": "239623", "nsentences": "1730.58", "wps": "22188", "ups": "0.09", "wpb": "239623", "bsz": "1730.6", "num_updates": "91200", "lr": "0.000419565", "gnorm": "0.275", "loss_scale": "0.125", "train_wall": "2032", "gb_free": "39.6", "wall": "4007"}
[2024-10-09 20:54:05,045][train_inner][INFO] - {"epoch": 191, "update": 190.898, "loss": "1.014", "ntokens": "239575", "nsentences": "1763.29", "wps": "29414.1", "ups": "0.12", "wpb": "239576", "bsz": "1763.3", "num_updates": "91400", "lr": "0.000419293", "gnorm": "0.263", "loss_scale": "0.125", "train_wall": "1430", "gb_free": "39.3", "wall": "5636"}
[2024-10-09 20:54:05,045][train_inner][INFO] - {"epoch": 191, "update": 190.898, "loss": "1.014", "ntokens": "239575", "nsentences": "1763.29", "wps": "29414", "ups": "0.12", "wpb": "239576", "bsz": "1763.3", "num_updates": "91400", "lr": "0.000419293", "gnorm": "0.264", "loss_scale": "0.125", "train_wall": "1429", "gb_free": "39.3", "wall": "5565"}
[2024-10-09 21:00:01,770][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-09 21:00:01,874][train][INFO] - {"epoch": 191, "train_loss": "1.01", "train_ntokens": "239153", "train_nsentences": "1753.71", "train_wps": "26235.9", "train_ups": "0.11", "train_wpb": "239154", "train_bsz": "1753.7", "train_num_updates": "91449", "train_lr": "0.000419227", "train_gnorm": "0.279", "train_loss_scale": "0.125", "train_train_wall": "4027", "train_gb_free": "39.8", "train_wall": "5922"}
[2024-10-09 21:00:02,051][fairseq_cli.train][INFO] - end of epoch 191 (average epoch stats below)
[2024-10-09 21:00:02,127][train][INFO] - {"epoch": 191, "train_loss": "1.01", "train_ntokens": "239153", "train_nsentences": "1753.71", "train_wps": "25889.5", "train_ups": "0.11", "train_wpb": "239154", "train_bsz": "1753.7", "train_num_updates": "91449", "train_lr": "0.000419227", "train_gnorm": "0.278", "train_loss_scale": "0.125", "train_train_wall": "4123", "train_gb_free": "39.8", "train_wall": "5993"}
[2024-10-09 21:00:02,454][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:00:02,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:00:02,492][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-09 21:00:02,492][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:00:02,493][fairseq.trainer][INFO] - begin training epoch 192
[2024-10-09 21:00:02,493][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:18:04,003][train_inner][INFO] - {"epoch": 192, "update": 191.315, "loss": "1.008", "ntokens": "238241", "nsentences": "1798.49", "wps": "33116.4", "ups": "0.14", "wpb": "238241", "bsz": "1798.5", "num_updates": "91600", "lr": "0.000419022", "gnorm": "0.28", "loss_scale": "0.125", "train_wall": "837", "gb_free": "40.1", "wall": "7075"}
[2024-10-09 21:18:04,646][train_inner][INFO] - {"epoch": 192, "update": 191.315, "loss": "1.008", "ntokens": "238241", "nsentences": "1798.49", "wps": "33101.7", "ups": "0.14", "wpb": "238241", "bsz": "1798.5", "num_updates": "91600", "lr": "0.000419022", "gnorm": "0.277", "loss_scale": "0.125", "train_wall": "844", "gb_free": "40.1", "wall": "7005"}
[2024-10-09 21:31:49,303][train_inner][INFO] - {"epoch": 192, "update": 191.733, "loss": "1.007", "ntokens": "240313", "nsentences": "1713.16", "wps": "58242.1", "ups": "0.24", "wpb": "240313", "bsz": "1713.2", "num_updates": "91800", "lr": "0.00041875", "gnorm": "0.286", "loss_scale": "0.125", "train_wall": "763", "gb_free": "39.6", "wall": "7900"}
[2024-10-09 21:31:52,587][train_inner][INFO] - {"epoch": 192, "update": 191.733, "loss": "1.009", "ntokens": "240313", "nsentences": "1713.16", "wps": "58051.4", "ups": "0.24", "wpb": "240313", "bsz": "1713.2", "num_updates": "91800", "lr": "0.00041875", "gnorm": "0.317", "loss_scale": "0.125", "train_wall": "766", "gb_free": "39.6", "wall": "7833"}
[2024-10-09 21:41:42,565][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-09 21:41:42,606][train][INFO] - {"epoch": 192, "train_loss": "1.009", "train_ntokens": "239521", "train_nsentences": "1753.71", "train_wps": "45879.4", "train_ups": "0.19", "train_wpb": "239521", "train_bsz": "1753.7", "train_num_updates": "91928", "train_lr": "0.000418576", "train_gnorm": "0.289", "train_loss_scale": "0.125", "train_train_wall": "1915", "train_gb_free": "39.6", "train_wall": "8423"}
[2024-10-09 21:41:43,065][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:41:43,104][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-09 21:41:43,106][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:41:43,138][fairseq_cli.train][INFO] - end of epoch 192 (average epoch stats below)
[2024-10-09 21:41:43,189][train][INFO] - {"epoch": 192, "train_loss": "1.009", "train_ntokens": "239521", "train_nsentences": "1753.71", "train_wps": "45873.6", "train_ups": "0.19", "train_wpb": "239521", "train_bsz": "1753.7", "train_num_updates": "91928", "train_lr": "0.000418576", "train_gnorm": "0.278", "train_loss_scale": "0.125", "train_train_wall": "1913", "train_gb_free": "39.6", "train_wall": "8494"}
[2024-10-09 21:41:43,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 21:41:43,396][fairseq.trainer][INFO] - begin training epoch 193
[2024-10-09 21:41:43,396][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 21:49:41,793][train_inner][INFO] - {"epoch": 193, "update": 192.15, "loss": "1.01", "ntokens": "238774", "nsentences": "1769.63", "wps": "44530", "ups": "0.19", "wpb": "238774", "bsz": "1769.6", "num_updates": "92000", "lr": "0.000418478", "gnorm": "0.269", "loss_scale": "0.125", "train_wall": "702", "gb_free": "39.3", "wall": "8973"}
[2024-10-09 21:49:52,684][train_inner][INFO] - {"epoch": 193, "update": 192.15, "loss": "1.01", "ntokens": "238774", "nsentences": "1769.63", "wps": "44213.9", "ups": "0.19", "wpb": "238774", "bsz": "1769.6", "num_updates": "92000", "lr": "0.000418478", "gnorm": "0.28", "loss_scale": "0.125", "train_wall": "691", "gb_free": "39.3", "wall": "8913"}
[2024-10-09 21:55:03,537][train_inner][INFO] - {"epoch": 193, "update": 192.568, "loss": "1.007", "ntokens": "239912", "nsentences": "1700.1", "wps": "149143", "ups": "0.62", "wpb": "239912", "bsz": "1700.1", "num_updates": "92200", "lr": "0.000418207", "gnorm": "0.269", "loss_scale": "0.125", "train_wall": "316", "gb_free": "40.1", "wall": "9295"}
[2024-10-09 21:55:07,823][train_inner][INFO] - {"epoch": 193, "update": 192.568, "loss": "1.007", "ntokens": "239912", "nsentences": "1700.1", "wps": "152271", "ups": "0.63", "wpb": "239912", "bsz": "1700.1", "num_updates": "92200", "lr": "0.000418207", "gnorm": "0.269", "loss_scale": "0.125", "train_wall": "309", "gb_free": "40.1", "wall": "9228"}
[2024-10-09 22:03:31,775][train_inner][INFO] - {"epoch": 193, "update": 192.985, "loss": "1.011", "ntokens": "239492", "nsentences": "1809.64", "wps": "95078.3", "ups": "0.4", "wpb": "239492", "bsz": "1809.6", "num_updates": "92400", "lr": "0.000417935", "gnorm": "0.27", "loss_scale": "0.125", "train_wall": "479", "gb_free": "39.3", "wall": "9732"}
[2024-10-09 22:03:44,488][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-09 22:03:44,591][train][INFO] - {"epoch": 193, "train_loss": "1.008", "train_ntokens": "239261", "train_nsentences": "1753.71", "train_wps": "86699.3", "train_ups": "0.36", "train_wpb": "239261", "train_bsz": "1753.7", "train_num_updates": "92407", "train_lr": "0.000417925", "train_gnorm": "0.275", "train_loss_scale": "0.125", "train_train_wall": "911", "train_gb_free": "39.7", "train_wall": "9745"}
[2024-10-09 22:03:44,961][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:03:44,979][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-09 22:03:44,991][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:04:32,142][train_inner][INFO] - {"epoch": 193, "update": 192.985, "loss": "1.011", "ntokens": "239492", "nsentences": "1809.64", "wps": "84250.2", "ups": "0.35", "wpb": "239492", "bsz": "1809.6", "num_updates": "92400", "lr": "0.000417935", "gnorm": "0.272", "loss_scale": "0.125", "train_wall": "558", "gb_free": "39.3", "wall": "9863"}
[2024-10-09 22:04:43,759][fairseq_cli.train][INFO] - end of epoch 193 (average epoch stats below)
[2024-10-09 22:04:43,768][train][INFO] - {"epoch": 193, "train_loss": "1.008", "train_ntokens": "239261", "train_nsentences": "1753.71", "train_wps": "83013.7", "train_ups": "0.35", "train_wpb": "239261", "train_bsz": "1753.7", "train_num_updates": "92407", "train_lr": "0.000417925", "train_gnorm": "0.271", "train_loss_scale": "0.125", "train_train_wall": "1003", "train_gb_free": "39.7", "train_wall": "9875"}
[2024-10-09 22:04:44,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:04:44,064][fairseq.trainer][INFO] - begin training epoch 194
[2024-10-09 22:04:44,064][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:16:47,982][train_inner][INFO] - {"epoch": 194, "update": 193.403, "loss": "1.006", "ntokens": "237836", "nsentences": "1779.42", "wps": "64645.7", "ups": "0.27", "wpb": "237836", "bsz": "1779.4", "num_updates": "92600", "lr": "0.000417663", "gnorm": "0.306", "loss_scale": "0.125", "train_wall": "377", "gb_free": "40.1", "wall": "10599"}
[2024-10-09 22:16:50,482][train_inner][INFO] - {"epoch": 194, "update": 193.403, "loss": "1.006", "ntokens": "237836", "nsentences": "1779.42", "wps": "59557", "ups": "0.25", "wpb": "237836", "bsz": "1779.4", "num_updates": "92600", "lr": "0.000417663", "gnorm": "0.296", "loss_scale": "0.125", "train_wall": "420", "gb_free": "40.1", "wall": "10531"}
[2024-10-09 22:24:06,792][train_inner][INFO] - {"epoch": 194, "update": 193.82, "loss": "1.009", "ntokens": "240367", "nsentences": "1713.64", "wps": "109574", "ups": "0.46", "wpb": "240367", "bsz": "1713.6", "num_updates": "92800", "lr": "0.000417391", "gnorm": "0.267", "loss_scale": "0.125", "train_wall": "371", "gb_free": "39.7", "wall": "11038"}
[2024-10-09 22:24:07,525][train_inner][INFO] - {"epoch": 194, "update": 193.82, "loss": "1.01", "ntokens": "240367", "nsentences": "1713.64", "wps": "110000", "ups": "0.46", "wpb": "240367", "bsz": "1713.6", "num_updates": "92800", "lr": "0.000417391", "gnorm": "0.272", "loss_scale": "0.125", "train_wall": "365", "gb_free": "39.7", "wall": "10968"}
[2024-10-09 22:26:51,625][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-09 22:26:51,667][train][INFO] - {"epoch": 194, "train_loss": "1.008", "train_ntokens": "239130", "train_nsentences": "1753.71", "train_wps": "82580.6", "train_ups": "0.35", "train_wpb": "239130", "train_bsz": "1753.7", "train_num_updates": "92886", "train_lr": "0.000417274", "train_gnorm": "0.284", "train_loss_scale": "0.125", "train_train_wall": "934", "train_gb_free": "40.1", "train_wall": "11132"}
[2024-10-09 22:26:51,855][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:26:51,864][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-09 22:26:51,864][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:27:14,989][fairseq_cli.train][INFO] - end of epoch 194 (average epoch stats below)
[2024-10-09 22:27:15,006][train][INFO] - {"epoch": 194, "train_loss": "1.008", "train_ntokens": "239130", "train_nsentences": "1753.71", "train_wps": "84769.9", "train_ups": "0.35", "train_wpb": "239130", "train_bsz": "1753.7", "train_num_updates": "92886", "train_lr": "0.000417274", "train_gnorm": "0.285", "train_loss_scale": "0.125", "train_train_wall": "920", "train_gb_free": "40.1", "train_wall": "11226"}
[2024-10-09 22:27:15,325][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:27:15,340][fairseq.trainer][INFO] - begin training epoch 195
[2024-10-09 22:27:15,340][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:36:34,060][train_inner][INFO] - {"epoch": 195, "update": 194.238, "loss": "1.006", "ntokens": "238675", "nsentences": "1728.38", "wps": "63942.7", "ups": "0.27", "wpb": "238675", "bsz": "1728.4", "num_updates": "93000", "lr": "0.00041712", "gnorm": "0.298", "loss_scale": "0.125", "train_wall": "380", "gb_free": "39.6", "wall": "11714"}
[2024-10-09 22:36:39,020][train_inner][INFO] - {"epoch": 195, "update": 194.238, "loss": "1.006", "ntokens": "238675", "nsentences": "1728.38", "wps": "63462.9", "ups": "0.27", "wpb": "238675", "bsz": "1728.4", "num_updates": "93000", "lr": "0.00041712", "gnorm": "0.279", "loss_scale": "0.125", "train_wall": "404", "gb_free": "39.6", "wall": "11790"}
[2024-10-09 22:42:22,357][train_inner][INFO] - {"epoch": 195, "update": 194.656, "loss": "1.008", "ntokens": "239164", "nsentences": "1768.03", "wps": "139325", "ups": "0.58", "wpb": "239164", "bsz": "1768", "num_updates": "93200", "lr": "0.000416848", "gnorm": "0.287", "loss_scale": "0.25", "train_wall": "338", "gb_free": "39.2", "wall": "12133"}
[2024-10-09 22:42:23,293][train_inner][INFO] - {"epoch": 195, "update": 194.656, "loss": "1.009", "ntokens": "239164", "nsentences": "1768.03", "wps": "136977", "ups": "0.57", "wpb": "239164", "bsz": "1768", "num_updates": "93200", "lr": "0.000416848", "gnorm": "0.293", "loss_scale": "0.25", "train_wall": "343", "gb_free": "39.2", "wall": "12064"}
[2024-10-09 22:47:10,250][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-09 22:47:10,271][train][INFO] - {"epoch": 195, "train_loss": "1.007", "train_ntokens": "239031", "train_nsentences": "1753.71", "train_wps": "93956.8", "train_ups": "0.39", "train_wpb": "239031", "train_bsz": "1753.7", "train_num_updates": "93365", "train_lr": "0.000416624", "train_gnorm": "0.298", "train_loss_scale": "0.25", "train_train_wall": "844", "train_gb_free": "39.1", "train_wall": "12351"}
[2024-10-09 22:47:12,123][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:47:12,158][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-09 22:47:12,158][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:47:34,175][fairseq_cli.train][INFO] - end of epoch 195 (average epoch stats below)
[2024-10-09 22:47:34,178][train][INFO] - {"epoch": 195, "train_loss": "1.007", "train_ntokens": "239031", "train_nsentences": "1753.71", "train_wps": "93913.1", "train_ups": "0.39", "train_wpb": "239031", "train_bsz": "1753.7", "train_num_updates": "93365", "train_lr": "0.000416624", "train_gnorm": "0.288", "train_loss_scale": "0.25", "train_train_wall": "866", "train_gb_free": "39.1", "train_wall": "12445"}
[2024-10-09 22:47:34,376][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 22:47:34,380][fairseq.trainer][INFO] - begin training epoch 196
[2024-10-09 22:47:34,381][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 22:55:03,548][train_inner][INFO] - {"epoch": 196, "update": 195.073, "loss": "1.008", "ntokens": "238123", "nsentences": "1785.04", "wps": "62644.2", "ups": "0.26", "wpb": "238123", "bsz": "1785", "num_updates": "93400", "lr": "0.000416576", "gnorm": "0.296", "loss_scale": "0.25", "train_wall": "342", "gb_free": "40.2", "wall": "12824"}
[2024-10-09 22:55:29,211][train_inner][INFO] - {"epoch": 196, "update": 195.073, "loss": "1.008", "ntokens": "238123", "nsentences": "1785.04", "wps": "60526.9", "ups": "0.25", "wpb": "238123", "bsz": "1785", "num_updates": "93400", "lr": "0.000416576", "gnorm": "0.295", "loss_scale": "0.25", "train_wall": "376", "gb_free": "40.2", "wall": "12920"}
[2024-10-09 23:01:07,680][train_inner][INFO] - {"epoch": 196, "update": 195.491, "loss": "1.007", "ntokens": "240746", "nsentences": "1704.86", "wps": "142261", "ups": "0.59", "wpb": "240746", "bsz": "1704.9", "num_updates": "93600", "lr": "0.000416304", "gnorm": "0.272", "loss_scale": "0.25", "train_wall": "332", "gb_free": "39.6", "wall": "13259"}
[2024-10-09 23:01:18,862][train_inner][INFO] - {"epoch": 196, "update": 195.491, "loss": "1.008", "ntokens": "240746", "nsentences": "1704.86", "wps": "128302", "ups": "0.53", "wpb": "240746", "bsz": "1704.9", "num_updates": "93600", "lr": "0.000416304", "gnorm": "0.286", "loss_scale": "0.25", "train_wall": "370", "gb_free": "39.6", "wall": "13199"}
[2024-10-09 23:08:36,923][train_inner][INFO] - {"epoch": 196, "update": 195.908, "loss": "1.011", "ntokens": "239603", "nsentences": "1790.16", "wps": "106674", "ups": "0.45", "wpb": "239603", "bsz": "1790.2", "num_updates": "93800", "lr": "0.000416033", "gnorm": "0.282", "loss_scale": "0.25", "train_wall": "436", "gb_free": "39.6", "wall": "13708"}
[2024-10-09 23:08:42,312][train_inner][INFO] - {"epoch": 196, "update": 195.908, "loss": "1.011", "ntokens": "239603", "nsentences": "1790.16", "wps": "108070", "ups": "0.45", "wpb": "239603", "bsz": "1790.2", "num_updates": "93800", "lr": "0.000416033", "gnorm": "0.272", "loss_scale": "0.25", "train_wall": "427", "gb_free": "39.6", "wall": "13643"}
[2024-10-09 23:09:36,288][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-09 23:09:36,324][train][INFO] - {"epoch": 196, "train_loss": "1.009", "train_ntokens": "239457", "train_nsentences": "1753.71", "train_wps": "85214.2", "train_ups": "0.36", "train_wpb": "239457", "train_bsz": "1753.7", "train_num_updates": "93844", "train_lr": "0.000415973", "train_gnorm": "0.28", "train_loss_scale": "0.25", "train_train_wall": "909", "train_gb_free": "39.3", "train_wall": "13697"}
[2024-10-09 23:09:36,601][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:09:36,636][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-09 23:09:36,637][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:09:41,137][fairseq_cli.train][INFO] - end of epoch 196 (average epoch stats below)
[2024-10-09 23:09:41,179][train][INFO] - {"epoch": 196, "train_loss": "1.008", "train_ntokens": "239457", "train_nsentences": "1753.71", "train_wps": "86438.2", "train_ups": "0.36", "train_wpb": "239457", "train_bsz": "1753.7", "train_num_updates": "93844", "train_lr": "0.000415973", "train_gnorm": "0.28", "train_loss_scale": "0.25", "train_train_wall": "900", "train_gb_free": "39.3", "train_wall": "13772"}
[2024-10-09 23:09:41,642][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:09:41,668][fairseq.trainer][INFO] - begin training epoch 197
[2024-10-09 23:09:41,668][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:21:14,139][train_inner][INFO] - {"epoch": 197, "update": 196.326, "loss": "1.007", "ntokens": "238520", "nsentences": "1773.98", "wps": "63451.8", "ups": "0.27", "wpb": "238520", "bsz": "1774", "num_updates": "94000", "lr": "0.000415761", "gnorm": "0.281", "loss_scale": "0.25", "train_wall": "324", "gb_free": "40.1", "wall": "14395"}
[2024-10-09 23:21:21,695][train_inner][INFO] - {"epoch": 197, "update": 196.326, "loss": "1.006", "ntokens": "238520", "nsentences": "1773.98", "wps": "62379", "ups": "0.26", "wpb": "238520", "bsz": "1774", "num_updates": "94000", "lr": "0.000415761", "gnorm": "0.288", "loss_scale": "0.25", "train_wall": "377", "gb_free": "40.1", "wall": "14473"}
[2024-10-09 23:27:07,043][train_inner][INFO] - {"epoch": 197, "update": 196.743, "loss": "1.009", "ntokens": "239673", "nsentences": "1766.21", "wps": "135847", "ups": "0.57", "wpb": "239673", "bsz": "1766.2", "num_updates": "94200", "lr": "0.000415489", "gnorm": "0.273", "loss_scale": "0.25", "train_wall": "348", "gb_free": "40.1", "wall": "14747"}
[2024-10-09 23:27:19,247][train_inner][INFO] - {"epoch": 197, "update": 196.743, "loss": "1.01", "ntokens": "239673", "nsentences": "1766.21", "wps": "134079", "ups": "0.56", "wpb": "239673", "bsz": "1766.2", "num_updates": "94200", "lr": "0.000415489", "gnorm": "0.286", "loss_scale": "0.25", "train_wall": "352", "gb_free": "40.1", "wall": "14830"}
[2024-10-09 23:31:45,653][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-09 23:31:45,679][train][INFO] - {"epoch": 197, "train_loss": "1.008", "train_ntokens": "239561", "train_nsentences": "1753.71", "train_wps": "86322.5", "train_ups": "0.36", "train_wpb": "239561", "train_bsz": "1753.7", "train_num_updates": "94323", "train_lr": "0.000415322", "train_gnorm": "0.277", "train_loss_scale": "0.25", "train_train_wall": "890", "train_gb_free": "39.6", "train_wall": "15026"}
[2024-10-09 23:31:45,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:31:45,855][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-09 23:31:45,857][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:31:54,293][fairseq_cli.train][INFO] - end of epoch 197 (average epoch stats below)
[2024-10-09 23:31:54,311][train][INFO] - {"epoch": 197, "train_loss": "1.009", "train_ntokens": "239561", "train_nsentences": "1753.71", "train_wps": "86076.3", "train_ups": "0.36", "train_wpb": "239561", "train_bsz": "1753.7", "train_num_updates": "94323", "train_lr": "0.000415322", "train_gnorm": "0.284", "train_loss_scale": "0.25", "train_train_wall": "934", "train_gb_free": "39.6", "train_wall": "15105"}
[2024-10-09 23:31:54,433][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:31:54,440][fairseq.trainer][INFO] - begin training epoch 198
[2024-10-09 23:31:54,441][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:40:38,457][train_inner][INFO] - {"epoch": 198, "update": 197.161, "loss": "1.009", "ntokens": "239194", "nsentences": "1751.65", "wps": "58961.6", "ups": "0.25", "wpb": "239194", "bsz": "1751.7", "num_updates": "94400", "lr": "0.000415217", "gnorm": "0.287", "loss_scale": "0.25", "train_wall": "452", "gb_free": "39.2", "wall": "15559"}
[2024-10-09 23:40:51,698][train_inner][INFO] - {"epoch": 198, "update": 197.161, "loss": "1.009", "ntokens": "239194", "nsentences": "1751.65", "wps": "58884.4", "ups": "0.25", "wpb": "239194", "bsz": "1751.7", "num_updates": "94400", "lr": "0.000415217", "gnorm": "0.279", "loss_scale": "0.25", "train_wall": "462", "gb_free": "39.2", "wall": "15643"}
[2024-10-09 23:46:54,482][train_inner][INFO] - {"epoch": 198, "update": 197.578, "loss": "1.005", "ntokens": "239606", "nsentences": "1745.38", "wps": "127457", "ups": "0.53", "wpb": "239606", "bsz": "1745.4", "num_updates": "94600", "lr": "0.000414946", "gnorm": "0.281", "loss_scale": "0.25", "train_wall": "334", "gb_free": "39.8", "wall": "15935"}
[2024-10-09 23:47:16,234][train_inner][INFO] - {"epoch": 198, "update": 197.578, "loss": "1.006", "ntokens": "239606", "nsentences": "1745.38", "wps": "124634", "ups": "0.52", "wpb": "239606", "bsz": "1745.4", "num_updates": "94600", "lr": "0.000414946", "gnorm": "0.283", "loss_scale": "0.25", "train_wall": "337", "gb_free": "39.8", "wall": "16027"}
[2024-10-09 23:53:33,699][train_inner][INFO] - {"epoch": 198, "update": 197.996, "loss": "1.006", "ntokens": "239511", "nsentences": "1739.68", "wps": "120023", "ups": "0.5", "wpb": "239511", "bsz": "1739.7", "num_updates": "94800", "lr": "0.000414674", "gnorm": "0.278", "loss_scale": "0.25", "train_wall": "394", "gb_free": "40.3", "wall": "16334"}
[2024-10-09 23:53:36,000][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-09 23:53:36,062][train][INFO] - {"epoch": 198, "train_loss": "1.006", "train_ntokens": "239089", "train_nsentences": "1753.71", "train_wps": "87399.3", "train_ups": "0.37", "train_wpb": "239089", "train_bsz": "1753.7", "train_num_updates": "94802", "train_lr": "0.000414671", "train_gnorm": "0.283", "train_loss_scale": "0.25", "train_train_wall": "911", "train_gb_free": "40.5", "train_wall": "16336"}
[2024-10-09 23:53:36,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:53:36,500][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-09 23:53:36,507][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 23:54:19,468][train_inner][INFO] - {"epoch": 198, "update": 197.996, "loss": "1.007", "ntokens": "239511", "nsentences": "1739.68", "wps": "113183", "ups": "0.47", "wpb": "239511", "bsz": "1739.7", "num_updates": "94800", "lr": "0.000414674", "gnorm": "0.276", "loss_scale": "0.25", "train_wall": "418", "gb_free": "40.3", "wall": "16451"}
[2024-10-09 23:54:35,671][fairseq_cli.train][INFO] - end of epoch 198 (average epoch stats below)
[2024-10-09 23:54:35,692][train][INFO] - {"epoch": 198, "train_loss": "1.007", "train_ntokens": "239089", "train_nsentences": "1753.71", "train_wps": "84123.4", "train_ups": "0.35", "train_wpb": "239089", "train_bsz": "1753.7", "train_num_updates": "94802", "train_lr": "0.000414671", "train_gnorm": "0.28", "train_loss_scale": "0.25", "train_train_wall": "965", "train_gb_free": "40.5", "train_wall": "16467"}
[2024-10-09 23:54:35,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-09 23:54:35,943][fairseq.trainer][INFO] - begin training epoch 199
[2024-10-09 23:54:35,944][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:06:12,631][train_inner][INFO] - {"epoch": 199, "update": 198.413, "loss": "1.005", "ntokens": "238635", "nsentences": "1777.72", "wps": "62889.6", "ups": "0.26", "wpb": "238635", "bsz": "1777.7", "num_updates": "95000", "lr": "0.000414402", "gnorm": "0.275", "loss_scale": "0.25", "train_wall": "342", "gb_free": "39.8", "wall": "17093"}
[2024-10-10 00:07:09,713][train_inner][INFO] - {"epoch": 199, "update": 198.413, "loss": "1.005", "ntokens": "238635", "nsentences": "1777.72", "wps": "61964.3", "ups": "0.26", "wpb": "238635", "bsz": "1777.7", "num_updates": "95000", "lr": "0.000414402", "gnorm": "0.283", "loss_scale": "0.25", "train_wall": "402", "gb_free": "39.8", "wall": "17221"}
[2024-10-10 00:10:26,721][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-10 00:12:54,945][train_inner][INFO] - {"epoch": 199, "update": 198.831, "loss": "1.005", "ntokens": "239512", "nsentences": "1751.93", "wps": "119072", "ups": "0.5", "wpb": "239512", "bsz": "1751.9", "num_updates": "95200", "lr": "0.00041413", "gnorm": "0.285", "loss_scale": "0.5", "train_wall": "383", "gb_free": "39.8", "wall": "17495"}
[2024-10-10 00:13:39,452][train_inner][INFO] - {"epoch": 199, "update": 198.833, "loss": "1.005", "ntokens": "239564", "nsentences": "1749.47", "wps": "122940", "ups": "0.51", "wpb": "239564", "bsz": "1749.5", "num_updates": "95200", "lr": "0.00041413", "gnorm": "0.285", "loss_scale": "0.25", "train_wall": "384", "gb_free": "39.3", "wall": "17611"}
[2024-10-10 00:15:00,633][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-10 00:15:00,723][train][INFO] - {"epoch": 199, "train_loss": "1.006", "train_ntokens": "239204", "train_nsentences": "1753.71", "train_wps": "89193.4", "train_ups": "0.37", "train_wpb": "239204", "train_bsz": "1753.7", "train_num_updates": "95281", "train_lr": "0.00041402", "train_gnorm": "0.277", "train_loss_scale": "0.5", "train_train_wall": "841", "train_gb_free": "39.6", "train_wall": "17621"}
[2024-10-10 00:15:01,509][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:15:01,514][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-10 00:15:01,515][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:16:07,175][fairseq_cli.train][INFO] - end of epoch 199 (average epoch stats below)
[2024-10-10 00:16:07,199][train][INFO] - {"epoch": 199, "train_loss": "1.006", "train_ntokens": "239209", "train_nsentences": "1753", "train_wps": "88534.2", "train_ups": "0.37", "train_wpb": "239209", "train_bsz": "1753", "train_num_updates": "95280", "train_lr": "0.000414022", "train_gnorm": "0.282", "train_loss_scale": "0.25", "train_train_wall": "915", "train_gb_free": "39.6", "train_wall": "17758"}
[2024-10-10 00:16:07,384][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:16:07,412][fairseq.trainer][INFO] - begin training epoch 200
[2024-10-10 00:16:07,412][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:25:34,510][train_inner][INFO] - {"epoch": 200, "update": 199.251, "loss": "1.006", "ntokens": "239331", "nsentences": "1701.9", "wps": "66941.2", "ups": "0.28", "wpb": "239331", "bsz": "1701.9", "num_updates": "95400", "lr": "0.000413859", "gnorm": "0.267", "loss_scale": "0.25", "train_wall": "381", "gb_free": "39.3", "wall": "18326"}
[2024-10-10 00:25:43,227][train_inner][INFO] - {"epoch": 200, "update": 199.248, "loss": "1.006", "ntokens": "239334", "nsentences": "1702.06", "wps": "62305.6", "ups": "0.26", "wpb": "239334", "bsz": "1702.1", "num_updates": "95400", "lr": "0.000413859", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "375", "gb_free": "39.8", "wall": "18264"}
[2024-10-10 00:31:59,652][train_inner][INFO] - {"epoch": 200, "update": 199.668, "loss": "1.006", "ntokens": "239570", "nsentences": "1777.4", "wps": "124414", "ups": "0.52", "wpb": "239570", "bsz": "1777.4", "num_updates": "95600", "lr": "0.000413587", "gnorm": "0.29", "loss_scale": "0.25", "train_wall": "379", "gb_free": "40.1", "wall": "18711"}
[2024-10-10 00:31:59,653][train_inner][INFO] - {"epoch": 200, "update": 199.666, "loss": "1.005", "ntokens": "239576", "nsentences": "1777.91", "wps": "127294", "ups": "0.53", "wpb": "239576", "bsz": "1777.9", "num_updates": "95600", "lr": "0.000413587", "gnorm": "0.278", "loss_scale": "0.5", "train_wall": "371", "gb_free": "39.6", "wall": "18640"}
[2024-10-10 00:36:24,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 95760 updates
[2024-10-10 00:36:24,332][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 00:36:36,978][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 00:36:37,411][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 200 @ 95760 updates, score None) (writing took 13.083240498788655 seconds)
[2024-10-10 00:36:37,412][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-10 00:36:37,449][train][INFO] - {"epoch": 200, "train_loss": "1.006", "train_ntokens": "239240", "train_nsentences": "1753.71", "train_wps": "88375.9", "train_ups": "0.37", "train_wpb": "239240", "train_bsz": "1753.7", "train_num_updates": "95760", "train_lr": "0.00041337", "train_gnorm": "0.277", "train_loss_scale": "0.5", "train_train_wall": "887", "train_gb_free": "40.1", "train_wall": "18918"}
[2024-10-10 00:36:37,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:36:37,626][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-10 00:36:37,627][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:38:00,038][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 200 @ 95759 updates
[2024-10-10 00:38:00,043][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 00:38:04,251][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 00:38:04,255][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 200 @ 95759 updates, score None) (writing took 4.216945969499648 seconds)
[2024-10-10 00:38:04,255][fairseq_cli.train][INFO] - end of epoch 200 (average epoch stats below)
[2024-10-10 00:38:04,259][train][INFO] - {"epoch": 200, "train_loss": "1.006", "train_ntokens": "239240", "train_nsentences": "1753.71", "train_wps": "87009.3", "train_ups": "0.36", "train_wpb": "239240", "train_bsz": "1753.7", "train_num_updates": "95759", "train_lr": "0.000413371", "train_gnorm": "0.28", "train_loss_scale": "0.25", "train_train_wall": "966", "train_gb_free": "40.1", "train_wall": "19075"}
[2024-10-10 00:38:04,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:38:04,540][fairseq.trainer][INFO] - begin training epoch 201
[2024-10-10 00:38:04,540][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:45:05,323][train_inner][INFO] - {"epoch": 201, "update": 200.084, "loss": "1.01", "ntokens": "238211", "nsentences": "1749.31", "wps": "60641", "ups": "0.25", "wpb": "238211", "bsz": "1749.3", "num_updates": "95800", "lr": "0.000413315", "gnorm": "0.281", "loss_scale": "0.5", "train_wall": "400", "gb_free": "40.2", "wall": "19426"}
[2024-10-10 00:45:18,974][train_inner][INFO] - {"epoch": 201, "update": 200.086, "loss": "1.009", "ntokens": "238127", "nsentences": "1753.93", "wps": "59586.6", "ups": "0.25", "wpb": "238127", "bsz": "1753.9", "num_updates": "95800", "lr": "0.000413315", "gnorm": "0.279", "loss_scale": "0.25", "train_wall": "459", "gb_free": "39.6", "wall": "19510"}
[2024-10-10 00:50:21,492][train_inner][INFO] - {"epoch": 201, "update": 200.501, "loss": "1.001", "ntokens": "240176", "nsentences": "1706.97", "wps": "151937", "ups": "0.63", "wpb": "240176", "bsz": "1707", "num_updates": "96000", "lr": "0.000413043", "gnorm": "0.281", "loss_scale": "0.5", "train_wall": "311", "gb_free": "39.3", "wall": "19742"}
[2024-10-10 00:50:50,190][train_inner][INFO] - {"epoch": 201, "update": 200.503, "loss": "1.001", "ntokens": "240181", "nsentences": "1704.99", "wps": "145042", "ups": "0.6", "wpb": "240181", "bsz": "1705", "num_updates": "96000", "lr": "0.000413043", "gnorm": "0.287", "loss_scale": "0.25", "train_wall": "326", "gb_free": "39.1", "wall": "19841"}
[2024-10-10 00:56:53,285][train_inner][INFO] - {"epoch": 201, "update": 200.919, "loss": "1.009", "ntokens": "239418", "nsentences": "1789.19", "wps": "122221", "ups": "0.51", "wpb": "239418", "bsz": "1789.2", "num_updates": "96200", "lr": "0.000412772", "gnorm": "0.297", "loss_scale": "0.5", "train_wall": "369", "gb_free": "39.8", "wall": "20134"}
[2024-10-10 00:57:05,706][train_inner][INFO] - {"epoch": 201, "update": 200.921, "loss": "1.009", "ntokens": "239451", "nsentences": "1797.59", "wps": "127536", "ups": "0.53", "wpb": "239452", "bsz": "1797.6", "num_updates": "96200", "lr": "0.000412772", "gnorm": "0.293", "loss_scale": "0.25", "train_wall": "369", "gb_free": "40.2", "wall": "20217"}
[2024-10-10 00:57:50,789][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-10-10 00:57:50,831][train][INFO] - {"epoch": 201, "train_loss": "1.006", "train_ntokens": "239354", "train_nsentences": "1753.71", "train_wps": "90038.7", "train_ups": "0.38", "train_wpb": "239354", "train_bsz": "1753.7", "train_num_updates": "96239", "train_lr": "0.000412719", "train_gnorm": "0.287", "train_loss_scale": "0.5", "train_train_wall": "878", "train_gb_free": "40.3", "train_wall": "20191"}
[2024-10-10 00:57:51,191][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:57:51,204][fairseq.trainer][INFO] - begin training epoch 202
[2024-10-10 00:57:51,211][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 00:58:48,474][fairseq_cli.train][INFO] - end of epoch 201 (average epoch stats below)
[2024-10-10 00:58:48,488][train][INFO] - {"epoch": 201, "train_loss": "1.006", "train_ntokens": "239354", "train_nsentences": "1753.71", "train_wps": "92147", "train_ups": "0.38", "train_wpb": "239354", "train_bsz": "1753.7", "train_num_updates": "96238", "train_lr": "0.00041272", "train_gnorm": "0.29", "train_loss_scale": "0.25", "train_train_wall": "906", "train_gb_free": "40.3", "train_wall": "20320"}
[2024-10-10 00:58:48,741][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 00:58:48,748][fairseq.trainer][INFO] - begin training epoch 202
[2024-10-10 00:58:48,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:08:22,120][train_inner][INFO] - {"epoch": 202, "update": 201.336, "loss": "1.006", "ntokens": "239254", "nsentences": "1745.32", "wps": "69466.9", "ups": "0.29", "wpb": "239254", "bsz": "1745.3", "num_updates": "96400", "lr": "0.0004125", "gnorm": "0.299", "loss_scale": "0.5", "train_wall": "345", "gb_free": "39.8", "wall": "20823"}
[2024-10-10 01:09:18,363][train_inner][INFO] - {"epoch": 202, "update": 201.338, "loss": "1.007", "ntokens": "239240", "nsentences": "1737.14", "wps": "65313.1", "ups": "0.27", "wpb": "239240", "bsz": "1737.1", "num_updates": "96400", "lr": "0.0004125", "gnorm": "0.296", "loss_scale": "0.25", "train_wall": "327", "gb_free": "40.1", "wall": "20949"}
[2024-10-10 01:14:37,503][train_inner][INFO] - {"epoch": 202, "update": 201.754, "loss": "1.008", "ntokens": "239833", "nsentences": "1741.35", "wps": "127788", "ups": "0.53", "wpb": "239833", "bsz": "1741.3", "num_updates": "96600", "lr": "0.000412228", "gnorm": "0.274", "loss_scale": "0.5", "train_wall": "370", "gb_free": "39.3", "wall": "21198"}
[2024-10-10 01:15:25,596][train_inner][INFO] - {"epoch": 202, "update": 201.756, "loss": "1.008", "ntokens": "239856", "nsentences": "1739.28", "wps": "130639", "ups": "0.54", "wpb": "239856", "bsz": "1739.3", "num_updates": "96600", "lr": "0.000412228", "gnorm": "0.277", "loss_scale": "0.25", "train_wall": "276", "gb_free": "39.6", "wall": "21317"}
[2024-10-10 01:18:12,596][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-10-10 01:18:12,754][train][INFO] - {"epoch": 202, "train_loss": "1.007", "train_ntokens": "239333", "train_nsentences": "1753.71", "train_wps": "93830.3", "train_ups": "0.39", "train_wpb": "239333", "train_bsz": "1753.7", "train_num_updates": "96718", "train_lr": "0.000412068", "train_gnorm": "0.289", "train_loss_scale": "0.5", "train_train_wall": "868", "train_gb_free": "39.2", "train_wall": "21413"}
[2024-10-10 01:18:12,984][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:18:13,009][fairseq.trainer][INFO] - begin training epoch 203
[2024-10-10 01:18:13,009][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:19:08,937][fairseq_cli.train][INFO] - end of epoch 202 (average epoch stats below)
[2024-10-10 01:19:08,947][train][INFO] - {"epoch": 202, "train_loss": "1.007", "train_ntokens": "239333", "train_nsentences": "1753.71", "train_wps": "93933.1", "train_ups": "0.39", "train_wpb": "239333", "train_bsz": "1753.7", "train_num_updates": "96717", "train_lr": "0.000412069", "train_gnorm": "0.286", "train_loss_scale": "0.25", "train_train_wall": "655", "train_gb_free": "39.2", "train_wall": "21540"}
[2024-10-10 01:19:09,091][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:19:09,107][fairseq.trainer][INFO] - begin training epoch 203
[2024-10-10 01:19:09,107][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:27:26,877][train_inner][INFO] - {"epoch": 203, "update": 202.171, "loss": "1.002", "ntokens": "238135", "nsentences": "1767.7", "wps": "61904.7", "ups": "0.26", "wpb": "238135", "bsz": "1767.7", "num_updates": "96800", "lr": "0.000411957", "gnorm": "0.285", "loss_scale": "0.5", "train_wall": "323", "gb_free": "39.2", "wall": "21967"}
[2024-10-10 01:27:39,672][train_inner][INFO] - {"epoch": 203, "update": 202.173, "loss": "1.003", "ntokens": "238069", "nsentences": "1773.64", "wps": "64866.8", "ups": "0.27", "wpb": "238069", "bsz": "1773.6", "num_updates": "96800", "lr": "0.000411957", "gnorm": "0.29", "loss_scale": "0.25", "train_wall": "293", "gb_free": "39.7", "wall": "22051"}
[2024-10-10 01:33:39,447][train_inner][INFO] - {"epoch": 203, "update": 202.589, "loss": "1.007", "ntokens": "239599", "nsentences": "1764.64", "wps": "128626", "ups": "0.54", "wpb": "239599", "bsz": "1764.6", "num_updates": "97000", "lr": "0.000411685", "gnorm": "0.287", "loss_scale": "0.5", "train_wall": "367", "gb_free": "39.3", "wall": "22340"}
[2024-10-10 01:33:52,580][train_inner][INFO] - {"epoch": 203, "update": 202.591, "loss": "1.007", "ntokens": "239658", "nsentences": "1759.37", "wps": "128545", "ups": "0.54", "wpb": "239658", "bsz": "1759.4", "num_updates": "97000", "lr": "0.000411685", "gnorm": "0.287", "loss_scale": "0.25", "train_wall": "367", "gb_free": "39.7", "wall": "22424"}
[2024-10-10 01:39:50,929][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-10-10 01:39:50,990][train][INFO] - {"epoch": 203, "train_loss": "1.006", "train_ntokens": "239229", "train_nsentences": "1753.71", "train_wps": "92262.8", "train_ups": "0.39", "train_wpb": "239229", "train_bsz": "1753.7", "train_num_updates": "97196", "train_lr": "0.000411418", "train_gnorm": "0.284", "train_loss_scale": "0.5", "train_train_wall": "859", "train_gb_free": "39.8", "train_wall": "22782"}
[2024-10-10 01:39:51,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:39:51,131][fairseq.trainer][INFO] - begin training epoch 204
[2024-10-10 01:39:51,131][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:39:54,518][fairseq_cli.train][INFO] - end of epoch 203 (average epoch stats below)
[2024-10-10 01:39:54,527][train][INFO] - {"epoch": 203, "train_loss": "1.006", "train_ntokens": "239229", "train_nsentences": "1753.71", "train_wps": "88027.2", "train_ups": "0.37", "train_wpb": "239229", "train_bsz": "1753.7", "train_num_updates": "97197", "train_lr": "0.000411417", "train_gnorm": "0.28", "train_loss_scale": "1", "train_train_wall": "851", "train_gb_free": "39.8", "train_wall": "22715"}
[2024-10-10 01:39:54,724][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 01:39:54,727][fairseq.trainer][INFO] - begin training epoch 204
[2024-10-10 01:39:54,728][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 01:46:33,649][train_inner][INFO] - {"epoch": 204, "update": 203.008, "loss": "1.008", "ntokens": "238583", "nsentences": "1761.45", "wps": "62698.6", "ups": "0.26", "wpb": "238583", "bsz": "1761.5", "num_updates": "97200", "lr": "0.000411413", "gnorm": "0.279", "loss_scale": "0.5", "train_wall": "412", "gb_free": "39.3", "wall": "23185"}
[2024-10-10 01:46:44,821][train_inner][INFO] - {"epoch": 204, "update": 203.006, "loss": "1.008", "ntokens": "238547", "nsentences": "1762.3", "wps": "60749.2", "ups": "0.25", "wpb": "238547", "bsz": "1762.3", "num_updates": "97200", "lr": "0.000411413", "gnorm": "0.273", "loss_scale": "1", "train_wall": "440", "gb_free": "39.6", "wall": "23125"}
[2024-10-10 01:48:44,646][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-10 01:52:08,303][train_inner][INFO] - {"epoch": 204, "update": 203.426, "loss": "1.003", "ntokens": "239712", "nsentences": "1756.53", "wps": "148214", "ups": "0.62", "wpb": "239712", "bsz": "1756.5", "num_updates": "97400", "lr": "0.000411141", "gnorm": "0.277", "loss_scale": "0.5", "train_wall": "318", "gb_free": "39.8", "wall": "23449"}
[2024-10-10 01:52:14,084][train_inner][INFO] - {"epoch": 204, "update": 203.426, "loss": "1.002", "ntokens": "239674", "nsentences": "1756.9", "wps": "140817", "ups": "0.59", "wpb": "239674", "bsz": "1756.9", "num_updates": "97400", "lr": "0.000411141", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "333", "gb_free": "39.8", "wall": "23525"}
[2024-10-10 01:58:43,067][train_inner][INFO] - {"epoch": 204, "update": 203.843, "loss": "1.004", "ntokens": "239444", "nsentences": "1756.54", "wps": "121327", "ups": "0.51", "wpb": "239444", "bsz": "1756.5", "num_updates": "97600", "lr": "0.00041087", "gnorm": "0.284", "loss_scale": "0.5", "train_wall": "389", "gb_free": "39.6", "wall": "23843"}
[2024-10-10 01:58:55,008][train_inner][INFO] - {"epoch": 204, "update": 203.843, "loss": "1.005", "ntokens": "239444", "nsentences": "1756.54", "wps": "119447", "ups": "0.5", "wpb": "239444", "bsz": "1756.5", "num_updates": "97600", "lr": "0.00041087", "gnorm": "0.283", "loss_scale": "0.5", "train_wall": "396", "gb_free": "39.6", "wall": "23926"}
[2024-10-10 02:00:30,757][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-10-10 02:00:30,895][train][INFO] - {"epoch": 204, "train_loss": "1.005", "train_ntokens": "239254", "train_nsentences": "1753.9", "train_wps": "92502.8", "train_ups": "0.39", "train_wpb": "239254", "train_bsz": "1753.9", "train_num_updates": "97675", "train_lr": "0.000410768", "train_gnorm": "0.282", "train_loss_scale": "0.5", "train_train_wall": "882", "train_gb_free": "39.3", "train_wall": "23951"}
[2024-10-10 02:00:31,677][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:00:31,731][fairseq.trainer][INFO] - begin training epoch 205
[2024-10-10 02:00:31,739][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:01:27,997][fairseq_cli.train][INFO] - end of epoch 204 (average epoch stats below)
[2024-10-10 02:01:28,021][train][INFO] - {"epoch": 204, "train_loss": "1.004", "train_ntokens": "239248", "train_nsentences": "1753.71", "train_wps": "88357.2", "train_ups": "0.37", "train_wpb": "239248", "train_bsz": "1753.7", "train_num_updates": "97675", "train_lr": "0.000410768", "train_gnorm": "0.28", "train_loss_scale": "0.5", "train_train_wall": "941", "train_gb_free": "39.3", "train_wall": "24079"}
[2024-10-10 02:01:28,224][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:01:28,248][fairseq.trainer][INFO] - begin training epoch 205
[2024-10-10 02:01:28,248][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:11:07,203][train_inner][INFO] - {"epoch": 205, "update": 204.261, "loss": "1.007", "ntokens": "238391", "nsentences": "1766.66", "wps": "65118.1", "ups": "0.27", "wpb": "238391", "bsz": "1766.7", "num_updates": "97800", "lr": "0.000410598", "gnorm": "0.299", "loss_scale": "0.5", "train_wall": "390", "gb_free": "39.6", "wall": "24658"}
[2024-10-10 02:11:40,939][train_inner][INFO] - {"epoch": 205, "update": 204.261, "loss": "1.007", "ntokens": "238391", "nsentences": "1766.66", "wps": "61296.1", "ups": "0.26", "wpb": "238391", "bsz": "1766.7", "num_updates": "97800", "lr": "0.000410598", "gnorm": "0.301", "loss_scale": "0.5", "train_wall": "276", "gb_free": "39.6", "wall": "24621"}
[2024-10-10 02:17:08,424][train_inner][INFO] - {"epoch": 205, "update": 204.678, "loss": "1.006", "ntokens": "239998", "nsentences": "1752.06", "wps": "132891", "ups": "0.55", "wpb": "239998", "bsz": "1752.1", "num_updates": "98000", "lr": "0.000410326", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "327", "gb_free": "39.2", "wall": "25020"}
[2024-10-10 02:17:38,077][train_inner][INFO] - {"epoch": 205, "update": 204.678, "loss": "1.005", "ntokens": "239998", "nsentences": "1752.06", "wps": "134404", "ups": "0.56", "wpb": "239998", "bsz": "1752.1", "num_updates": "98000", "lr": "0.000410326", "gnorm": "0.27", "loss_scale": "0.5", "train_wall": "280", "gb_free": "39.2", "wall": "24978"}
[2024-10-10 02:21:39,061][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-10-10 02:21:39,146][train][INFO] - {"epoch": 205, "train_loss": "1.004", "train_ntokens": "239168", "train_nsentences": "1753.71", "train_wps": "90333.8", "train_ups": "0.38", "train_wpb": "239168", "train_bsz": "1753.7", "train_num_updates": "98154", "train_lr": "0.000410117", "train_gnorm": "0.287", "train_loss_scale": "0.5", "train_train_wall": "660", "train_gb_free": "39.8", "train_wall": "25220"}
[2024-10-10 02:21:39,652][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:21:39,664][fairseq.trainer][INFO] - begin training epoch 206
[2024-10-10 02:21:39,671][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:22:03,816][fairseq_cli.train][INFO] - end of epoch 205 (average epoch stats below)
[2024-10-10 02:22:03,827][train][INFO] - {"epoch": 205, "train_loss": "1.004", "train_ntokens": "239168", "train_nsentences": "1753.71", "train_wps": "92702.4", "train_ups": "0.39", "train_wpb": "239168", "train_bsz": "1753.7", "train_num_updates": "98154", "train_lr": "0.000410117", "train_gnorm": "0.288", "train_loss_scale": "0.5", "train_train_wall": "857", "train_gb_free": "39.8", "train_wall": "25315"}
[2024-10-10 02:22:03,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:22:03,984][fairseq.trainer][INFO] - begin training epoch 206
[2024-10-10 02:22:03,985][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:29:40,737][train_inner][INFO] - {"epoch": 206, "update": 205.096, "loss": "1.003", "ntokens": "238422", "nsentences": "1743.18", "wps": "63385.6", "ups": "0.27", "wpb": "238422", "bsz": "1743.2", "num_updates": "98200", "lr": "0.000410054", "gnorm": "0.29", "loss_scale": "0.5", "train_wall": "383", "gb_free": "39.6", "wall": "25772"}
[2024-10-10 02:30:18,973][train_inner][INFO] - {"epoch": 206, "update": 205.096, "loss": "1.003", "ntokens": "238422", "nsentences": "1743.18", "wps": "62671", "ups": "0.26", "wpb": "238422", "bsz": "1743.2", "num_updates": "98200", "lr": "0.000410054", "gnorm": "0.288", "loss_scale": "0.5", "train_wall": "350", "gb_free": "39.6", "wall": "25739"}
[2024-10-10 02:35:18,154][train_inner][INFO] - {"epoch": 206, "update": 205.514, "loss": "1", "ntokens": "240289", "nsentences": "1764.95", "wps": "142442", "ups": "0.59", "wpb": "240289", "bsz": "1765", "num_updates": "98400", "lr": "0.000409783", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "332", "gb_free": "40.1", "wall": "26109"}
[2024-10-10 02:36:20,638][train_inner][INFO] - {"epoch": 206, "update": 205.514, "loss": "1.001", "ntokens": "240289", "nsentences": "1764.95", "wps": "132892", "ups": "0.55", "wpb": "240289", "bsz": "1765", "num_updates": "98400", "lr": "0.000409783", "gnorm": "0.276", "loss_scale": "0.5", "train_wall": "356", "gb_free": "40.1", "wall": "26101"}
[2024-10-10 02:41:41,808][train_inner][INFO] - {"epoch": 206, "update": 205.931, "loss": "1.009", "ntokens": "239807", "nsentences": "1749.33", "wps": "125024", "ups": "0.52", "wpb": "239807", "bsz": "1749.3", "num_updates": "98600", "lr": "0.000409511", "gnorm": "0.275", "loss_scale": "0.5", "train_wall": "379", "gb_free": "40.1", "wall": "26493"}
[2024-10-10 02:42:17,954][train_inner][INFO] - {"epoch": 206, "update": 205.931, "loss": "1.008", "ntokens": "239807", "nsentences": "1749.33", "wps": "134228", "ups": "0.56", "wpb": "239807", "bsz": "1749.3", "num_updates": "98600", "lr": "0.000409511", "gnorm": "0.278", "loss_scale": "0.5", "train_wall": "352", "gb_free": "40.1", "wall": "26458"}
[2024-10-10 02:42:41,222][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-10-10 02:42:41,280][train][INFO] - {"epoch": 206, "train_loss": "1.005", "train_ntokens": "239433", "train_nsentences": "1753.71", "train_wps": "92684.7", "train_ups": "0.39", "train_wpb": "239433", "train_bsz": "1753.7", "train_num_updates": "98633", "train_lr": "0.000409466", "train_gnorm": "0.272", "train_loss_scale": "0.5", "train_train_wall": "860", "train_gb_free": "39.7", "train_wall": "26552"}
[2024-10-10 02:42:41,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:42:41,468][fairseq.trainer][INFO] - begin training epoch 207
[2024-10-10 02:42:41,469][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:43:03,781][fairseq_cli.train][INFO] - end of epoch 206 (average epoch stats below)
[2024-10-10 02:43:03,835][train][INFO] - {"epoch": 206, "train_loss": "1.005", "train_ntokens": "239433", "train_nsentences": "1753.71", "train_wps": "89273.8", "train_ups": "0.37", "train_wpb": "239433", "train_bsz": "1753.7", "train_num_updates": "98633", "train_lr": "0.000409466", "train_gnorm": "0.276", "train_loss_scale": "0.5", "train_train_wall": "893", "train_gb_free": "39.7", "train_wall": "26504"}
[2024-10-10 02:43:04,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 02:43:04,049][fairseq.trainer][INFO] - begin training epoch 207
[2024-10-10 02:43:04,051][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 02:54:39,934][train_inner][INFO] - {"epoch": 207, "update": 206.349, "loss": "1.002", "ntokens": "238772", "nsentences": "1747.09", "wps": "64367.4", "ups": "0.27", "wpb": "238772", "bsz": "1747.1", "num_updates": "98800", "lr": "0.000409239", "gnorm": "0.266", "loss_scale": "0.5", "train_wall": "358", "gb_free": "40.1", "wall": "27200"}
[2024-10-10 02:54:48,724][train_inner][INFO] - {"epoch": 207, "update": 206.349, "loss": "1.002", "ntokens": "238772", "nsentences": "1747.09", "wps": "60686.8", "ups": "0.25", "wpb": "238772", "bsz": "1747.1", "num_updates": "98800", "lr": "0.000409239", "gnorm": "0.269", "loss_scale": "0.5", "train_wall": "414", "gb_free": "40.1", "wall": "27280"}
[2024-10-10 03:00:50,188][train_inner][INFO] - {"epoch": 207, "update": 206.766, "loss": "1.002", "ntokens": "238798", "nsentences": "1770.83", "wps": "129002", "ups": "0.54", "wpb": "238798", "bsz": "1770.8", "num_updates": "99000", "lr": "0.000408967", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "365", "gb_free": "39.3", "wall": "27571"}
[2024-10-10 03:01:04,095][train_inner][INFO] - {"epoch": 207, "update": 206.766, "loss": "1.002", "ntokens": "238798", "nsentences": "1770.83", "wps": "127236", "ups": "0.53", "wpb": "238798", "bsz": "1770.8", "num_updates": "99000", "lr": "0.000408967", "gnorm": "0.279", "loss_scale": "0.5", "train_wall": "370", "gb_free": "39.3", "wall": "27655"}
[2024-10-10 03:03:54,084][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-10-10 03:03:54,107][train][INFO] - {"epoch": 207, "train_loss": "1.003", "train_ntokens": "239252", "train_nsentences": "1753.71", "train_wps": "91662.7", "train_ups": "0.38", "train_wpb": "239252", "train_bsz": "1753.7", "train_num_updates": "99112", "train_lr": "0.000408815", "train_gnorm": "0.272", "train_loss_scale": "0.5", "train_train_wall": "858", "train_gb_free": "39.7", "train_wall": "27755"}
[2024-10-10 03:03:54,357][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:03:54,379][fairseq.trainer][INFO] - begin training epoch 208
[2024-10-10 03:03:54,380][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:04:07,811][fairseq_cli.train][INFO] - end of epoch 207 (average epoch stats below)
[2024-10-10 03:04:07,839][train][INFO] - {"epoch": 207, "train_loss": "1.003", "train_ntokens": "239252", "train_nsentences": "1753.71", "train_wps": "89079.1", "train_ups": "0.37", "train_wpb": "239252", "train_bsz": "1753.7", "train_num_updates": "99112", "train_lr": "0.000408815", "train_gnorm": "0.276", "train_loss_scale": "0.5", "train_train_wall": "906", "train_gb_free": "39.7", "train_wall": "27839"}
[2024-10-10 03:04:08,010][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:04:08,018][fairseq.trainer][INFO] - begin training epoch 208
[2024-10-10 03:04:08,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:12:59,983][train_inner][INFO] - {"epoch": 208, "update": 207.184, "loss": "1.005", "ntokens": "239384", "nsentences": "1714.62", "wps": "65607.4", "ups": "0.27", "wpb": "239384", "bsz": "1714.6", "num_updates": "99200", "lr": "0.000408696", "gnorm": "0.287", "loss_scale": "0.5", "train_wall": "339", "gb_free": "39.7", "wall": "28300"}
[2024-10-10 03:13:19,379][train_inner][INFO] - {"epoch": 208, "update": 207.184, "loss": "1.005", "ntokens": "239384", "nsentences": "1714.62", "wps": "65114.1", "ups": "0.27", "wpb": "239384", "bsz": "1714.6", "num_updates": "99200", "lr": "0.000408696", "gnorm": "0.287", "loss_scale": "0.5", "train_wall": "379", "gb_free": "39.7", "wall": "28390"}
[2024-10-10 03:18:26,109][train_inner][INFO] - {"epoch": 208, "update": 207.601, "loss": "1.003", "ntokens": "239524", "nsentences": "1769.43", "wps": "146922", "ups": "0.61", "wpb": "239524", "bsz": "1769.4", "num_updates": "99400", "lr": "0.000408424", "gnorm": "0.272", "loss_scale": "1", "train_wall": "320", "gb_free": "39.8", "wall": "28626"}
[2024-10-10 03:18:57,115][train_inner][INFO] - {"epoch": 208, "update": 207.601, "loss": "1.003", "ntokens": "239524", "nsentences": "1769.43", "wps": "141853", "ups": "0.59", "wpb": "239524", "bsz": "1769.4", "num_updates": "99400", "lr": "0.000408424", "gnorm": "0.275", "loss_scale": "1", "train_wall": "332", "gb_free": "39.8", "wall": "28728"}
[2024-10-10 03:23:47,458][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-10-10 03:23:47,493][train][INFO] - {"epoch": 208, "train_loss": "1.003", "train_ntokens": "239266", "train_nsentences": "1753.71", "train_wps": "96037.4", "train_ups": "0.4", "train_wpb": "239266", "train_bsz": "1753.7", "train_num_updates": "99591", "train_lr": "0.000408164", "train_gnorm": "0.283", "train_loss_scale": "1", "train_train_wall": "794", "train_gb_free": "39.3", "train_wall": "28948"}
[2024-10-10 03:23:47,635][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:23:47,665][fairseq.trainer][INFO] - begin training epoch 209
[2024-10-10 03:23:47,666][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:24:33,483][fairseq_cli.train][INFO] - end of epoch 208 (average epoch stats below)
[2024-10-10 03:24:33,486][train][INFO] - {"epoch": 208, "train_loss": "1.003", "train_ntokens": "239266", "train_nsentences": "1753.71", "train_wps": "93508.8", "train_ups": "0.39", "train_wpb": "239266", "train_bsz": "1753.7", "train_num_updates": "99591", "train_lr": "0.000408164", "train_gnorm": "0.284", "train_loss_scale": "1", "train_train_wall": "862", "train_gb_free": "39.3", "train_wall": "29065"}
[2024-10-10 03:24:33,613][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:24:33,625][fairseq.trainer][INFO] - begin training epoch 209
[2024-10-10 03:24:33,625][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:31:18,007][train_inner][INFO] - {"epoch": 209, "update": 208.019, "loss": "1.003", "ntokens": "238782", "nsentences": "1749.6", "wps": "64463.4", "ups": "0.27", "wpb": "238782", "bsz": "1749.6", "num_updates": "99600", "lr": "0.000408152", "gnorm": "0.291", "loss_scale": "1", "train_wall": "352", "gb_free": "41", "wall": "29469"}
[2024-10-10 03:31:24,037][train_inner][INFO] - {"epoch": 209, "update": 208.019, "loss": "1.004", "ntokens": "238782", "nsentences": "1749.6", "wps": "61390.3", "ups": "0.26", "wpb": "238782", "bsz": "1749.6", "num_updates": "99600", "lr": "0.000408152", "gnorm": "0.291", "loss_scale": "1", "train_wall": "398", "gb_free": "41", "wall": "29404"}
[2024-10-10 03:33:16,904][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-10 03:36:49,023][train_inner][INFO] - {"epoch": 209, "update": 208.438, "loss": "1.001", "ntokens": "239598", "nsentences": "1765.65", "wps": "144779", "ups": "0.6", "wpb": "239598", "bsz": "1765.7", "num_updates": "99800", "lr": "0.00040788", "gnorm": "0.274", "loss_scale": "0.5", "train_wall": "325", "gb_free": "39.6", "wall": "29800"}
[2024-10-10 03:36:55,615][train_inner][INFO] - {"epoch": 209, "update": 208.436, "loss": "1.002", "ntokens": "239665", "nsentences": "1761.77", "wps": "144577", "ups": "0.6", "wpb": "239665", "bsz": "1761.8", "num_updates": "99800", "lr": "0.00040788", "gnorm": "0.295", "loss_scale": "1", "train_wall": "326", "gb_free": "39.8", "wall": "29736"}
[2024-10-10 03:42:13,008][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-10 03:42:49,374][train_inner][INFO] - {"epoch": 209, "update": 208.854, "loss": "1.004", "ntokens": "239860", "nsentences": "1755.7", "wps": "135609", "ups": "0.57", "wpb": "239860", "bsz": "1755.7", "num_updates": "100000", "lr": "0.000407609", "gnorm": "0.275", "loss_scale": "1", "train_wall": "347", "gb_free": "39.8", "wall": "30090"}
[2024-10-10 03:42:49,403][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 100000 updates
[2024-10-10 03:42:49,405][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt
[2024-10-10 03:42:55,698][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt
[2024-10-10 03:43:02,340][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt (epoch 209 @ 100000 updates, score None) (writing took 12.937400902621448 seconds)
[2024-10-10 03:43:09,864][train_inner][INFO] - {"epoch": 209, "update": 208.858, "loss": "1.004", "ntokens": "239924", "nsentences": "1753.35", "wps": "126002", "ups": "0.53", "wpb": "239924", "bsz": "1753.3", "num_updates": "100000", "lr": "0.000407609", "gnorm": "0.278", "loss_scale": "0.25", "train_wall": "375", "gb_free": "39.6", "wall": "30181"}
[2024-10-10 03:43:09,888][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 209 @ 100000 updates
[2024-10-10 03:43:09,891][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt
[2024-10-10 03:43:14,962][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt
[2024-10-10 03:43:20,502][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_209_100000.pt (epoch 209 @ 100000 updates, score None) (writing took 10.6145680854097 seconds)
[2024-10-10 03:44:32,850][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-10-10 03:44:32,967][train][INFO] - {"epoch": 209, "train_loss": "1.003", "train_ntokens": "239325", "train_nsentences": "1753.71", "train_wps": "92051.2", "train_ups": "0.38", "train_wpb": "239325", "train_bsz": "1753.7", "train_num_updates": "100070", "train_lr": "0.000407514", "train_gnorm": "0.288", "train_loss_scale": "1", "train_train_wall": "845", "train_gb_free": "39.4", "train_wall": "30193"}
[2024-10-10 03:44:33,101][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:44:33,155][fairseq.trainer][INFO] - begin training epoch 210
[2024-10-10 03:44:33,156][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:45:01,817][fairseq_cli.train][INFO] - end of epoch 209 (average epoch stats below)
[2024-10-10 03:45:01,824][train][INFO] - {"epoch": 209, "train_loss": "1.003", "train_ntokens": "239319", "train_nsentences": "1755.11", "train_wps": "92934.8", "train_ups": "0.39", "train_wpb": "239319", "train_bsz": "1755.1", "train_num_updates": "100068", "train_lr": "0.000407516", "train_gnorm": "0.282", "train_loss_scale": "0.25", "train_train_wall": "821", "train_gb_free": "39.4", "train_wall": "30293"}
[2024-10-10 03:45:01,987][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 03:45:01,998][fairseq.trainer][INFO] - begin training epoch 210
[2024-10-10 03:45:01,999][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 03:55:37,559][train_inner][INFO] - {"epoch": 210, "update": 209.271, "loss": "1.002", "ntokens": "239084", "nsentences": "1742.78", "wps": "62248.5", "ups": "0.26", "wpb": "239084", "bsz": "1742.8", "num_updates": "100200", "lr": "0.000407337", "gnorm": "0.288", "loss_scale": "1", "train_wall": "376", "gb_free": "39", "wall": "30858"}
[2024-10-10 03:55:45,883][train_inner][INFO] - {"epoch": 210, "update": 209.276, "loss": "1.002", "ntokens": "239014", "nsentences": "1748.54", "wps": "63235", "ups": "0.26", "wpb": "239014", "bsz": "1748.5", "num_updates": "100200", "lr": "0.000407337", "gnorm": "0.293", "loss_scale": "0.25", "train_wall": "385", "gb_free": "39.6", "wall": "30937"}
[2024-10-10 03:57:30,919][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-10 04:01:16,049][train_inner][INFO] - {"epoch": 210, "update": 209.693, "loss": "1.004", "ntokens": "240068", "nsentences": "1722.35", "wps": "145430", "ups": "0.61", "wpb": "240068", "bsz": "1722.4", "num_updates": "100400", "lr": "0.000407065", "gnorm": "0.278", "loss_scale": "0.25", "train_wall": "324", "gb_free": "39.7", "wall": "31267"}
[2024-10-10 04:01:16,248][train_inner][INFO] - {"epoch": 210, "update": 209.691, "loss": "1.003", "ntokens": "240071", "nsentences": "1721.11", "wps": "141781", "ups": "0.59", "wpb": "240071", "bsz": "1721.1", "num_updates": "100400", "lr": "0.000407065", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "333", "gb_free": "39.7", "wall": "31197"}
[2024-10-10 04:05:25,935][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-10-10 04:05:25,971][train][INFO] - {"epoch": 210, "train_loss": "1.003", "train_ntokens": "239305", "train_nsentences": "1754.06", "train_wps": "91292.2", "train_ups": "0.38", "train_wpb": "239305", "train_bsz": "1754.1", "train_num_updates": "100548", "train_lr": "0.000406864", "train_gnorm": "0.277", "train_loss_scale": "0.5", "train_train_wall": "865", "train_gb_free": "39.7", "train_wall": "31446"}
[2024-10-10 04:05:26,225][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:05:26,241][fairseq.trainer][INFO] - begin training epoch 211
[2024-10-10 04:05:26,241][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:05:45,915][fairseq_cli.train][INFO] - end of epoch 210 (average epoch stats below)
[2024-10-10 04:05:45,918][train][INFO] - {"epoch": 210, "train_loss": "1.003", "train_ntokens": "239309", "train_nsentences": "1753.71", "train_wps": "92138.6", "train_ups": "0.39", "train_wpb": "239309", "train_bsz": "1753.7", "train_num_updates": "100547", "train_lr": "0.000406865", "train_gnorm": "0.284", "train_loss_scale": "0.25", "train_train_wall": "875", "train_gb_free": "39.7", "train_wall": "31537"}
[2024-10-10 04:05:46,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:05:46,061][fairseq.trainer][INFO] - begin training epoch 211
[2024-10-10 04:05:46,062][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:13:51,218][train_inner][INFO] - {"epoch": 211, "update": 210.109, "loss": "1.002", "ntokens": "238201", "nsentences": "1784.01", "wps": "63106.1", "ups": "0.26", "wpb": "238201", "bsz": "1784", "num_updates": "100600", "lr": "0.000406793", "gnorm": "0.281", "loss_scale": "0.5", "train_wall": "357", "gb_free": "40.1", "wall": "31952"}
[2024-10-10 04:14:06,276][train_inner][INFO] - {"epoch": 211, "update": 210.111, "loss": "1.002", "ntokens": "238254", "nsentences": "1779.49", "wps": "61867.3", "ups": "0.26", "wpb": "238254", "bsz": "1779.5", "num_updates": "100600", "lr": "0.000406793", "gnorm": "0.282", "loss_scale": "0.25", "train_wall": "386", "gb_free": "40.1", "wall": "32037"}
[2024-10-10 04:19:33,487][train_inner][INFO] - {"epoch": 211, "update": 210.528, "loss": "1.003", "ntokens": "239179", "nsentences": "1786.4", "wps": "146210", "ups": "0.61", "wpb": "239179", "bsz": "1786.4", "num_updates": "100800", "lr": "0.000406522", "gnorm": "0.273", "loss_scale": "0.25", "train_wall": "322", "gb_free": "39.8", "wall": "32365"}
[2024-10-10 04:19:56,694][train_inner][INFO] - {"epoch": 211, "update": 210.526, "loss": "1.002", "ntokens": "239210", "nsentences": "1784.97", "wps": "130920", "ups": "0.55", "wpb": "239210", "bsz": "1785", "num_updates": "100800", "lr": "0.000406522", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "360", "gb_free": "39.6", "wall": "32317"}
[2024-10-10 04:25:29,339][train_inner][INFO] - {"epoch": 211, "update": 210.946, "loss": "1.004", "ntokens": "240084", "nsentences": "1750.68", "wps": "134944", "ups": "0.56", "wpb": "240084", "bsz": "1750.7", "num_updates": "101000", "lr": "0.00040625", "gnorm": "0.282", "loss_scale": "0.25", "train_wall": "350", "gb_free": "39.6", "wall": "32720"}
[2024-10-10 04:25:46,726][train_inner][INFO] - {"epoch": 211, "update": 210.944, "loss": "1.005", "ntokens": "240005", "nsentences": "1755.91", "wps": "137137", "ups": "0.57", "wpb": "240005", "bsz": "1755.9", "num_updates": "101000", "lr": "0.00040625", "gnorm": "0.294", "loss_scale": "0.5", "train_wall": "344", "gb_free": "39.6", "wall": "32667"}
[2024-10-10 04:26:42,873][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-10-10 04:26:42,899][train][INFO] - {"epoch": 211, "train_loss": "1.003", "train_ntokens": "239385", "train_nsentences": "1753.71", "train_wps": "89799.8", "train_ups": "0.38", "train_wpb": "239385", "train_bsz": "1753.7", "train_num_updates": "101027", "train_lr": "0.000406213", "train_gnorm": "0.283", "train_loss_scale": "0.5", "train_train_wall": "871", "train_gb_free": "39.9", "train_wall": "32723"}
[2024-10-10 04:26:43,067][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:26:43,077][fairseq.trainer][INFO] - begin training epoch 212
[2024-10-10 04:26:43,077][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:27:02,869][fairseq_cli.train][INFO] - end of epoch 211 (average epoch stats below)
[2024-10-10 04:27:02,881][train][INFO] - {"epoch": 211, "train_loss": "1.002", "train_ntokens": "239385", "train_nsentences": "1753.71", "train_wps": "89795.6", "train_ups": "0.38", "train_wpb": "239385", "train_bsz": "1753.7", "train_num_updates": "101026", "train_lr": "0.000406215", "train_gnorm": "0.275", "train_loss_scale": "0.25", "train_train_wall": "882", "train_gb_free": "39.9", "train_wall": "32814"}
[2024-10-10 04:27:03,074][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:27:03,081][fairseq.trainer][INFO] - begin training epoch 212
[2024-10-10 04:27:03,082][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:37:25,453][train_inner][INFO] - {"epoch": 212, "update": 211.361, "loss": "1.002", "ntokens": "239007", "nsentences": "1724.2", "wps": "68413.2", "ups": "0.29", "wpb": "239007", "bsz": "1724.2", "num_updates": "101200", "lr": "0.000405978", "gnorm": "0.28", "loss_scale": "0.5", "train_wall": "352", "gb_free": "40.1", "wall": "33366"}
[2024-10-10 04:37:40,579][train_inner][INFO] - {"epoch": 212, "update": 211.363, "loss": "1.001", "ntokens": "238954", "nsentences": "1727.46", "wps": "65356.9", "ups": "0.27", "wpb": "238954", "bsz": "1727.5", "num_updates": "101200", "lr": "0.000405978", "gnorm": "0.271", "loss_scale": "0.25", "train_wall": "369", "gb_free": "40.1", "wall": "33452"}
[2024-10-10 04:43:18,030][train_inner][INFO] - {"epoch": 212, "update": 211.779, "loss": "1.002", "ntokens": "239617", "nsentences": "1757.61", "wps": "135931", "ups": "0.57", "wpb": "239617", "bsz": "1757.6", "num_updates": "101400", "lr": "0.000405707", "gnorm": "0.293", "loss_scale": "0.5", "train_wall": "346", "gb_free": "39.7", "wall": "33718"}
[2024-10-10 04:43:57,886][train_inner][INFO] - {"epoch": 212, "update": 211.781, "loss": "1.001", "ntokens": "239633", "nsentences": "1760.33", "wps": "127030", "ups": "0.53", "wpb": "239633", "bsz": "1760.3", "num_updates": "101400", "lr": "0.000405707", "gnorm": "0.276", "loss_scale": "0.25", "train_wall": "363", "gb_free": "40.6", "wall": "33829"}
[2024-10-10 04:45:59,337][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-10-10 04:45:59,616][train][INFO] - {"epoch": 212, "train_loss": "1.002", "train_ntokens": "239213", "train_nsentences": "1753.71", "train_wps": "99072.1", "train_ups": "0.41", "train_wpb": "239213", "train_bsz": "1753.7", "train_num_updates": "101506", "train_lr": "0.000405562", "train_gnorm": "0.284", "train_loss_scale": "0.5", "train_train_wall": "801", "train_gb_free": "39.2", "train_wall": "33880"}
[2024-10-10 04:46:00,913][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:46:01,034][fairseq.trainer][INFO] - begin training epoch 213
[2024-10-10 04:46:01,035][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:47:26,927][fairseq_cli.train][INFO] - end of epoch 212 (average epoch stats below)
[2024-10-10 04:47:26,937][train][INFO] - {"epoch": 212, "train_loss": "1.001", "train_ntokens": "239213", "train_nsentences": "1753.71", "train_wps": "93609.8", "train_ups": "0.39", "train_wpb": "239213", "train_bsz": "1753.7", "train_num_updates": "101505", "train_lr": "0.000405564", "train_gnorm": "0.275", "train_loss_scale": "0.25", "train_train_wall": "848", "train_gb_free": "39.2", "train_wall": "34038"}
[2024-10-10 04:47:27,097][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 04:47:27,106][fairseq.trainer][INFO] - begin training epoch 213
[2024-10-10 04:47:27,106][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 04:55:09,223][train_inner][INFO] - {"epoch": 213, "update": 212.196, "loss": "1", "ntokens": "238569", "nsentences": "1732.51", "wps": "67093.9", "ups": "0.28", "wpb": "238569", "bsz": "1732.5", "num_updates": "101600", "lr": "0.000405435", "gnorm": "0.28", "loss_scale": "0.5", "train_wall": "316", "gb_free": "40.6", "wall": "34430"}
[2024-10-10 04:55:37,365][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-10 04:57:03,270][train_inner][INFO] - {"epoch": 213, "update": 212.2, "loss": "0.998", "ntokens": "238533", "nsentences": "1725.95", "wps": "60745.8", "ups": "0.25", "wpb": "238533", "bsz": "1726", "num_updates": "101600", "lr": "0.000405435", "gnorm": "0.272", "loss_scale": "0.125", "train_wall": "406", "gb_free": "39.6", "wall": "34614"}
[2024-10-10 05:01:03,789][train_inner][INFO] - {"epoch": 213, "update": 212.614, "loss": "1.004", "ntokens": "239450", "nsentences": "1778.21", "wps": "135069", "ups": "0.56", "wpb": "239450", "bsz": "1778.2", "num_updates": "101800", "lr": "0.000405163", "gnorm": "0.303", "loss_scale": "0.5", "train_wall": "348", "gb_free": "40.1", "wall": "34784"}
[2024-10-10 05:02:45,745][train_inner][INFO] - {"epoch": 213, "update": 212.618, "loss": "1.003", "ntokens": "239546", "nsentences": "1774.48", "wps": "139897", "ups": "0.58", "wpb": "239546", "bsz": "1774.5", "num_updates": "101800", "lr": "0.000405163", "gnorm": "0.283", "loss_scale": "0.125", "train_wall": "336", "gb_free": "39.8", "wall": "34957"}
[2024-10-10 05:06:25,835][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2024-10-10 05:06:25,926][train][INFO] - {"epoch": 213, "train_loss": "1.003", "train_ntokens": "239253", "train_nsentences": "1753.71", "train_wps": "93457.3", "train_ups": "0.39", "train_wpb": "239254", "train_bsz": "1753.7", "train_num_updates": "101985", "train_lr": "0.000404912", "train_gnorm": "0.291", "train_loss_scale": "0.5", "train_train_wall": "822", "train_gb_free": "39.6", "train_wall": "35106"}
[2024-10-10 05:06:26,534][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:06:26,612][fairseq.trainer][INFO] - begin training epoch 214
[2024-10-10 05:06:26,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:07:57,773][fairseq_cli.train][INFO] - end of epoch 213 (average epoch stats below)
[2024-10-10 05:07:57,818][train][INFO] - {"epoch": 213, "train_loss": "1.001", "train_ntokens": "239247", "train_nsentences": "1752.73", "train_wps": "92910.2", "train_ups": "0.39", "train_wpb": "239247", "train_bsz": "1752.7", "train_num_updates": "101983", "train_lr": "0.000404914", "train_gnorm": "0.278", "train_loss_scale": "0.125", "train_train_wall": "841", "train_gb_free": "39.6", "train_wall": "35269"}
[2024-10-10 05:07:57,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:07:57,954][fairseq.trainer][INFO] - begin training epoch 214
[2024-10-10 05:07:57,954][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:14:32,185][train_inner][INFO] - {"epoch": 214, "update": 213.031, "loss": "1.004", "ntokens": "238687", "nsentences": "1756.16", "wps": "59054.1", "ups": "0.25", "wpb": "238687", "bsz": "1756.2", "num_updates": "102000", "lr": "0.000404891", "gnorm": "0.284", "loss_scale": "0.5", "train_wall": "408", "gb_free": "39.9", "wall": "35593"}
[2024-10-10 05:15:36,391][train_inner][INFO] - {"epoch": 214, "update": 213.035, "loss": "1.002", "ntokens": "238654", "nsentences": "1758.93", "wps": "61938.6", "ups": "0.26", "wpb": "238654", "bsz": "1758.9", "num_updates": "102000", "lr": "0.000404891", "gnorm": "0.278", "loss_scale": "0.125", "train_wall": "394", "gb_free": "39.2", "wall": "35727"}
[2024-10-10 05:19:43,735][train_inner][INFO] - {"epoch": 214, "update": 213.449, "loss": "0.998", "ntokens": "240057", "nsentences": "1761.77", "wps": "154128", "ups": "0.64", "wpb": "240058", "bsz": "1761.8", "num_updates": "102200", "lr": "0.00040462", "gnorm": "0.295", "loss_scale": "0.5", "train_wall": "296", "gb_free": "39.3", "wall": "35904"}
[2024-10-10 05:20:51,449][train_inner][INFO] - {"epoch": 214, "update": 213.453, "loss": "0.998", "ntokens": "240019", "nsentences": "1764.66", "wps": "152368", "ups": "0.63", "wpb": "240019", "bsz": "1764.7", "num_updates": "102200", "lr": "0.00040462", "gnorm": "0.29", "loss_scale": "0.125", "train_wall": "302", "gb_free": "41.5", "wall": "36043"}
[2024-10-10 05:23:36,896][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-10 05:25:40,055][train_inner][INFO] - {"epoch": 214, "update": 213.868, "loss": "1.001", "ntokens": "239471", "nsentences": "1736.87", "wps": "134426", "ups": "0.56", "wpb": "239471", "bsz": "1736.9", "num_updates": "102400", "lr": "0.000404348", "gnorm": "0.278", "loss_scale": "0.5", "train_wall": "311", "gb_free": "39.2", "wall": "36260"}
[2024-10-10 05:26:44,354][train_inner][INFO] - {"epoch": 214, "update": 213.871, "loss": "1", "ntokens": "239417", "nsentences": "1741.46", "wps": "135690", "ups": "0.57", "wpb": "239417", "bsz": "1741.5", "num_updates": "102400", "lr": "0.000404348", "gnorm": "0.269", "loss_scale": "0.125", "train_wall": "329", "gb_free": "39.6", "wall": "36395"}
[2024-10-10 05:27:32,447][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2024-10-10 05:27:32,463][train][INFO] - {"epoch": 214, "train_loss": "1.001", "train_ntokens": "239283", "train_nsentences": "1753.44", "train_wps": "90308.6", "train_ups": "0.38", "train_wpb": "239283", "train_bsz": "1753.4", "train_num_updates": "102463", "train_lr": "0.000404262", "train_gnorm": "0.283", "train_loss_scale": "0.5", "train_train_wall": "790", "train_gb_free": "39.6", "train_wall": "36373"}
[2024-10-10 05:27:32,905][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:27:32,928][fairseq.trainer][INFO] - begin training epoch 215
[2024-10-10 05:27:32,928][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:28:15,462][fairseq_cli.train][INFO] - end of epoch 214 (average epoch stats below)
[2024-10-10 05:28:15,482][train][INFO] - {"epoch": 214, "train_loss": "1", "train_ntokens": "239268", "train_nsentences": "1753.71", "train_wps": "94123.9", "train_ups": "0.39", "train_wpb": "239268", "train_bsz": "1753.7", "train_num_updates": "102462", "train_lr": "0.000404264", "train_gnorm": "0.28", "train_loss_scale": "0.125", "train_train_wall": "803", "train_gb_free": "39.6", "train_wall": "36487"}
[2024-10-10 05:28:15,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:28:15,768][fairseq.trainer][INFO] - begin training epoch 215
[2024-10-10 05:28:15,775][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:38:53,764][train_inner][INFO] - {"epoch": 215, "update": 214.286, "loss": "1.001", "ntokens": "238757", "nsentences": "1760.99", "wps": "60164.2", "ups": "0.25", "wpb": "238757", "bsz": "1761", "num_updates": "102600", "lr": "0.000404076", "gnorm": "0.273", "loss_scale": "0.5", "train_wall": "402", "gb_free": "39.3", "wall": "37054"}
[2024-10-10 05:39:03,282][train_inner][INFO] - {"epoch": 215, "update": 214.288, "loss": "1.001", "ntokens": "238799", "nsentences": "1755.29", "wps": "64638.2", "ups": "0.27", "wpb": "238799", "bsz": "1755.3", "num_updates": "102600", "lr": "0.000404076", "gnorm": "0.29", "loss_scale": "0.125", "train_wall": "357", "gb_free": "40.6", "wall": "37134"}
[2024-10-10 05:44:33,593][train_inner][INFO] - {"epoch": 215, "update": 214.704, "loss": "1.004", "ntokens": "239590", "nsentences": "1783.42", "wps": "141017", "ups": "0.59", "wpb": "239590", "bsz": "1783.4", "num_updates": "102800", "lr": "0.000403804", "gnorm": "0.271", "loss_scale": "0.5", "train_wall": "334", "gb_free": "39.3", "wall": "37394"}
[2024-10-10 05:45:09,063][train_inner][INFO] - {"epoch": 215, "update": 214.706, "loss": "1.004", "ntokens": "239547", "nsentences": "1785.76", "wps": "130984", "ups": "0.55", "wpb": "239548", "bsz": "1785.8", "num_updates": "102800", "lr": "0.000403804", "gnorm": "0.277", "loss_scale": "0.125", "train_wall": "360", "gb_free": "39.6", "wall": "37500"}
[2024-10-10 05:48:20,130][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2024-10-10 05:48:20,212][train][INFO] - {"epoch": 215, "train_loss": "1.002", "train_ntokens": "239571", "train_nsentences": "1753.71", "train_wps": "91973.5", "train_ups": "0.38", "train_wpb": "239571", "train_bsz": "1753.7", "train_num_updates": "102942", "train_lr": "0.000403611", "train_gnorm": "0.278", "train_loss_scale": "0.5", "train_train_wall": "866", "train_gb_free": "39.2", "train_wall": "37621"}
[2024-10-10 05:48:20,478][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:48:20,496][fairseq.trainer][INFO] - begin training epoch 216
[2024-10-10 05:48:20,496][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:48:34,403][fairseq_cli.train][INFO] - end of epoch 215 (average epoch stats below)
[2024-10-10 05:48:34,423][train][INFO] - {"epoch": 215, "train_loss": "1.002", "train_ntokens": "239571", "train_nsentences": "1753.71", "train_wps": "94145.2", "train_ups": "0.39", "train_wpb": "239571", "train_bsz": "1753.7", "train_num_updates": "102941", "train_lr": "0.000403613", "train_gnorm": "0.283", "train_loss_scale": "0.125", "train_train_wall": "834", "train_gb_free": "39.2", "train_wall": "37706"}
[2024-10-10 05:48:34,588][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 05:48:34,611][fairseq.trainer][INFO] - begin training epoch 216
[2024-10-10 05:48:34,612][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 05:56:57,949][train_inner][INFO] - {"epoch": 216, "update": 215.121, "loss": "1.002", "ntokens": "239339", "nsentences": "1727.03", "wps": "64309.2", "ups": "0.27", "wpb": "239339", "bsz": "1727", "num_updates": "103000", "lr": "0.000403533", "gnorm": "0.286", "loss_scale": "0.5", "train_wall": "383", "gb_free": "40.1", "wall": "38138"}
[2024-10-10 05:57:30,299][train_inner][INFO] - {"epoch": 216, "update": 215.123, "loss": "1.002", "ntokens": "239304", "nsentences": "1726.87", "wps": "64570.7", "ups": "0.27", "wpb": "239304", "bsz": "1726.9", "num_updates": "103000", "lr": "0.000403533", "gnorm": "0.29", "loss_scale": "0.125", "train_wall": "346", "gb_free": "40.1", "wall": "38241"}
[2024-10-10 06:02:57,543][train_inner][INFO] - {"epoch": 216, "update": 215.541, "loss": "0.999", "ntokens": "239536", "nsentences": "1767.45", "wps": "146401", "ups": "0.61", "wpb": "239536", "bsz": "1767.5", "num_updates": "103200", "lr": "0.000403261", "gnorm": "0.289", "loss_scale": "0.125", "train_wall": "307", "gb_free": "39.3", "wall": "38569"}
[2024-10-10 06:03:03,812][train_inner][INFO] - {"epoch": 216, "update": 215.539, "loss": "0.998", "ntokens": "239489", "nsentences": "1769.9", "wps": "130921", "ups": "0.55", "wpb": "239489", "bsz": "1769.9", "num_updates": "103200", "lr": "0.000403261", "gnorm": "0.28", "loss_scale": "0.5", "train_wall": "360", "gb_free": "39.6", "wall": "38504"}
[2024-10-10 06:08:22,101][train_inner][INFO] - {"epoch": 216, "update": 215.958, "loss": "1.003", "ntokens": "239926", "nsentences": "1743.3", "wps": "147864", "ups": "0.62", "wpb": "239926", "bsz": "1743.3", "num_updates": "103400", "lr": "0.000402989", "gnorm": "0.271", "loss_scale": "0.125", "train_wall": "288", "gb_free": "40.1", "wall": "38893"}
[2024-10-10 06:09:00,964][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2024-10-10 06:09:01,011][train][INFO] - {"epoch": 216, "train_loss": "1.001", "train_ntokens": "239234", "train_nsentences": "1753.71", "train_wps": "93427.9", "train_ups": "0.39", "train_wpb": "239234", "train_bsz": "1753.7", "train_num_updates": "103420", "train_lr": "0.000402962", "train_gnorm": "0.282", "train_loss_scale": "0.125", "train_train_wall": "769", "train_gb_free": "39.3", "train_wall": "38932"}
[2024-10-10 06:09:01,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:09:01,336][fairseq.trainer][INFO] - begin training epoch 217
[2024-10-10 06:09:01,336][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:09:05,346][train_inner][INFO] - {"epoch": 216, "update": 215.956, "loss": "1.004", "ntokens": "239977", "nsentences": "1741.14", "wps": "132759", "ups": "0.55", "wpb": "239977", "bsz": "1741.1", "num_updates": "103400", "lr": "0.000402989", "gnorm": "0.262", "loss_scale": "0.5", "train_wall": "356", "gb_free": "39.9", "wall": "38866"}
[2024-10-10 06:09:31,320][fairseq_cli.train][INFO] - end of epoch 216 (average epoch stats below)
[2024-10-10 06:09:31,341][train][INFO] - {"epoch": 216, "train_loss": "1.001", "train_ntokens": "239234", "train_nsentences": "1753.71", "train_wps": "90151.2", "train_ups": "0.38", "train_wpb": "239234", "train_bsz": "1753.7", "train_num_updates": "103421", "train_lr": "0.000402961", "train_gnorm": "0.272", "train_loss_scale": "0.5", "train_train_wall": "902", "train_gb_free": "39.3", "train_wall": "38892"}
[2024-10-10 06:09:31,582][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:09:31,608][fairseq.trainer][INFO] - begin training epoch 217
[2024-10-10 06:09:31,608][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:21:03,962][train_inner][INFO] - {"epoch": 217, "update": 216.376, "loss": "1.001", "ntokens": "238730", "nsentences": "1772.26", "wps": "62672.6", "ups": "0.26", "wpb": "238730", "bsz": "1772.3", "num_updates": "103600", "lr": "0.000402717", "gnorm": "0.273", "loss_scale": "0.125", "train_wall": "372", "gb_free": "40.1", "wall": "39655"}
[2024-10-10 06:21:26,638][train_inner][INFO] - {"epoch": 217, "update": 216.374, "loss": "1.001", "ntokens": "238659", "nsentences": "1775.06", "wps": "64390.2", "ups": "0.27", "wpb": "238659", "bsz": "1775.1", "num_updates": "103600", "lr": "0.000402717", "gnorm": "0.272", "loss_scale": "0.5", "train_wall": "383", "gb_free": "39.3", "wall": "39607"}
[2024-10-10 06:27:26,257][train_inner][INFO] - {"epoch": 217, "update": 216.791, "loss": "1", "ntokens": "239936", "nsentences": "1753.4", "wps": "133441", "ups": "0.56", "wpb": "239936", "bsz": "1753.4", "num_updates": "103800", "lr": "0.000402446", "gnorm": "0.285", "loss_scale": "0.5", "train_wall": "354", "gb_free": "40.1", "wall": "39967"}
[2024-10-10 06:27:28,570][train_inner][INFO] - {"epoch": 217, "update": 216.793, "loss": "1.001", "ntokens": "239966", "nsentences": "1752.3", "wps": "124793", "ups": "0.52", "wpb": "239966", "bsz": "1752.3", "num_updates": "103800", "lr": "0.000402446", "gnorm": "0.283", "loss_scale": "0.25", "train_wall": "379", "gb_free": "39.3", "wall": "40040"}
[2024-10-10 06:30:05,482][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2024-10-10 06:30:05,512][train][INFO] - {"epoch": 217, "train_loss": "1", "train_ntokens": "239342", "train_nsentences": "1753.71", "train_wps": "90665.6", "train_ups": "0.38", "train_wpb": "239342", "train_bsz": "1753.7", "train_num_updates": "103899", "train_lr": "0.000402311", "train_gnorm": "0.281", "train_loss_scale": "0.25", "train_train_wall": "876", "train_gb_free": "40.1", "train_wall": "40197"}
[2024-10-10 06:30:05,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:30:05,761][fairseq.trainer][INFO] - begin training epoch 218
[2024-10-10 06:30:05,762][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:30:14,925][fairseq_cli.train][INFO] - end of epoch 217 (average epoch stats below)
[2024-10-10 06:30:14,940][train][INFO] - {"epoch": 217, "train_loss": "1", "train_ntokens": "239342", "train_nsentences": "1753.71", "train_wps": "92188.3", "train_ups": "0.39", "train_wpb": "239342", "train_bsz": "1753.7", "train_num_updates": "103900", "train_lr": "0.00040231", "train_gnorm": "0.282", "train_loss_scale": "0.5", "train_train_wall": "876", "train_gb_free": "40.1", "train_wall": "40135"}
[2024-10-10 06:30:15,181][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:30:15,188][fairseq.trainer][INFO] - begin training epoch 218
[2024-10-10 06:30:15,188][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:39:24,671][train_inner][INFO] - {"epoch": 218, "update": 217.211, "loss": "0.999", "ntokens": "238761", "nsentences": "1701.46", "wps": "66687.2", "ups": "0.28", "wpb": "238761", "bsz": "1701.5", "num_updates": "104000", "lr": "0.000402174", "gnorm": "0.292", "loss_scale": "0.25", "train_wall": "332", "gb_free": "40.2", "wall": "40756"}
[2024-10-10 06:39:30,149][train_inner][INFO] - {"epoch": 218, "update": 217.209, "loss": "0.999", "ntokens": "238751", "nsentences": "1701.53", "wps": "65963.9", "ups": "0.28", "wpb": "238751", "bsz": "1701.5", "num_updates": "104000", "lr": "0.000402174", "gnorm": "0.287", "loss_scale": "0.5", "train_wall": "387", "gb_free": "39.3", "wall": "40691"}
[2024-10-10 06:45:14,246][train_inner][INFO] - {"epoch": 218, "update": 217.628, "loss": "1.001", "ntokens": "239702", "nsentences": "1767.55", "wps": "137162", "ups": "0.57", "wpb": "239702", "bsz": "1767.5", "num_updates": "104200", "lr": "0.000401902", "gnorm": "0.295", "loss_scale": "0.25", "train_wall": "343", "gb_free": "40.1", "wall": "41105"}
[2024-10-10 06:45:16,847][train_inner][INFO] - {"epoch": 218, "update": 217.626, "loss": "1", "ntokens": "239666", "nsentences": "1768.51", "wps": "138261", "ups": "0.58", "wpb": "239666", "bsz": "1768.5", "num_updates": "104200", "lr": "0.000401902", "gnorm": "0.286", "loss_scale": "0.5", "train_wall": "341", "gb_free": "40.6", "wall": "41037"}
[2024-10-10 06:49:57,978][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2024-10-10 06:49:58,056][train][INFO] - {"epoch": 218, "train_loss": "1.002", "train_ntokens": "239238", "train_nsentences": "1753.71", "train_wps": "96095.3", "train_ups": "0.4", "train_wpb": "239238", "train_bsz": "1753.7", "train_num_updates": "104378", "train_lr": "0.00040166", "train_gnorm": "0.289", "train_loss_scale": "0.25", "train_train_wall": "800", "train_gb_free": "39.7", "train_wall": "41389"}
[2024-10-10 06:49:58,509][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:49:58,568][fairseq.trainer][INFO] - begin training epoch 219
[2024-10-10 06:49:58,569][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:50:51,506][fairseq_cli.train][INFO] - end of epoch 218 (average epoch stats below)
[2024-10-10 06:50:51,543][train][INFO] - {"epoch": 218, "train_loss": "1.001", "train_ntokens": "239238", "train_nsentences": "1753.71", "train_wps": "92672", "train_ups": "0.39", "train_wpb": "239238", "train_bsz": "1753.7", "train_num_updates": "104379", "train_lr": "0.000401659", "train_gnorm": "0.284", "train_loss_scale": "1", "train_train_wall": "894", "train_gb_free": "39.7", "train_wall": "41372"}
[2024-10-10 06:50:51,696][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 06:50:51,699][fairseq.trainer][INFO] - begin training epoch 219
[2024-10-10 06:50:51,699][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 06:57:28,508][train_inner][INFO] - {"epoch": 219, "update": 218.046, "loss": "1.005", "ntokens": "238067", "nsentences": "1773.94", "wps": "64849.2", "ups": "0.27", "wpb": "238067", "bsz": "1773.9", "num_updates": "104400", "lr": "0.00040163", "gnorm": "0.282", "loss_scale": "0.25", "train_wall": "351", "gb_free": "39.6", "wall": "41840"}
[2024-10-10 06:58:09,981][train_inner][INFO] - {"epoch": 219, "update": 218.044, "loss": "1.005", "ntokens": "238113", "nsentences": "1771.71", "wps": "61599.4", "ups": "0.26", "wpb": "238113", "bsz": "1771.7", "num_updates": "104400", "lr": "0.00040163", "gnorm": "0.284", "loss_scale": "1", "train_wall": "395", "gb_free": "39.7", "wall": "41810"}
[2024-10-10 07:02:36,311][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2024-10-10 07:02:54,203][train_inner][INFO] - {"epoch": 219, "update": 218.463, "loss": "1", "ntokens": "239943", "nsentences": "1761.45", "wps": "147369", "ups": "0.61", "wpb": "239943", "bsz": "1761.5", "num_updates": "104600", "lr": "0.000401359", "gnorm": "0.273", "loss_scale": "0.25", "train_wall": "320", "gb_free": "39.9", "wall": "42165"}
[2024-10-10 07:03:41,659][train_inner][INFO] - {"epoch": 219, "update": 218.463, "loss": "0.999", "ntokens": "239991", "nsentences": "1759.47", "wps": "144718", "ups": "0.6", "wpb": "239991", "bsz": "1759.5", "num_updates": "104600", "lr": "0.000401359", "gnorm": "0.278", "loss_scale": "0.5", "train_wall": "326", "gb_free": "39.9", "wall": "42142"}
[2024-10-10 07:08:53,168][train_inner][INFO] - {"epoch": 219, "update": 218.881, "loss": "0.999", "ntokens": "239635", "nsentences": "1748.02", "wps": "133526", "ups": "0.56", "wpb": "239635", "bsz": "1748", "num_updates": "104800", "lr": "0.000401087", "gnorm": "0.278", "loss_scale": "0.25", "train_wall": "353", "gb_free": "39.9", "wall": "42524"}
[2024-10-10 07:09:52,042][train_inner][INFO] - {"epoch": 219, "update": 218.881, "loss": "0.998", "ntokens": "239635", "nsentences": "1748.02", "wps": "129404", "ups": "0.54", "wpb": "239635", "bsz": "1748", "num_updates": "104800", "lr": "0.000401087", "gnorm": "0.273", "loss_scale": "0.5", "train_wall": "362", "gb_free": "39.9", "wall": "42512"}
[2024-10-10 07:10:10,757][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2024-10-10 07:10:10,811][train][INFO] - {"epoch": 219, "train_loss": "1", "train_ntokens": "239244", "train_nsentences": "1753.71", "train_wps": "94497.3", "train_ups": "0.39", "train_wpb": "239244", "train_bsz": "1753.7", "train_num_updates": "104857", "train_lr": "0.00040101", "train_gnorm": "0.278", "train_loss_scale": "0.25", "train_train_wall": "821", "train_gb_free": "39.6", "train_wall": "42602"}
[2024-10-10 07:10:10,957][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:10:10,971][fairseq.trainer][INFO] - begin training epoch 220
[2024-10-10 07:10:10,971][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:10:55,226][fairseq_cli.train][INFO] - end of epoch 219 (average epoch stats below)
[2024-10-10 07:10:55,288][train][INFO] - {"epoch": 219, "train_loss": "1", "train_ntokens": "239248", "train_nsentences": "1753.37", "train_wps": "95005.8", "train_ups": "0.4", "train_wpb": "239248", "train_bsz": "1753.4", "train_num_updates": "104857", "train_lr": "0.00040101", "train_gnorm": "0.277", "train_loss_scale": "0.5", "train_train_wall": "815", "train_gb_free": "39.6", "train_wall": "42576"}
[2024-10-10 07:10:55,715][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:10:55,746][fairseq.trainer][INFO] - begin training epoch 220
[2024-10-10 07:10:55,748][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:21:41,600][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-10 07:22:07,537][train_inner][INFO] - {"epoch": 220, "update": 219.299, "loss": "0.999", "ntokens": "238692", "nsentences": "1731.12", "wps": "60099.2", "ups": "0.25", "wpb": "238692", "bsz": "1731.1", "num_updates": "105000", "lr": "0.000400815", "gnorm": "0.284", "loss_scale": "0.25", "train_wall": "404", "gb_free": "39.7", "wall": "43319"}
[2024-10-10 07:22:12,360][train_inner][INFO] - {"epoch": 220, "update": 219.301, "loss": "1", "ntokens": "238760", "nsentences": "1724.02", "wps": "64503.5", "ups": "0.27", "wpb": "238760", "bsz": "1724", "num_updates": "105000", "lr": "0.000400815", "gnorm": "0.286", "loss_scale": "0.25", "train_wall": "357", "gb_free": "40.9", "wall": "43253"}
[2024-10-10 07:28:05,551][train_inner][INFO] - {"epoch": 220, "update": 219.716, "loss": "1", "ntokens": "239777", "nsentences": "1753.61", "wps": "133956", "ups": "0.56", "wpb": "239777", "bsz": "1753.6", "num_updates": "105200", "lr": "0.000400543", "gnorm": "0.295", "loss_scale": "0.25", "train_wall": "352", "gb_free": "39.7", "wall": "43677"}
[2024-10-10 07:28:32,757][train_inner][INFO] - {"epoch": 220, "update": 219.718, "loss": "1", "ntokens": "239733", "nsentences": "1756.32", "wps": "126049", "ups": "0.53", "wpb": "239733", "bsz": "1756.3", "num_updates": "105200", "lr": "0.000400543", "gnorm": "0.281", "loss_scale": "0.25", "train_wall": "351", "gb_free": "39.3", "wall": "43633"}
[2024-10-10 07:31:53,879][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 105335 updates
[2024-10-10 07:31:53,931][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 07:31:57,854][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 220 @ 105336 updates
[2024-10-10 07:31:57,871][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 07:32:08,771][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt
[2024-10-10 07:32:09,090][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_gloss_400/ckpt/checkpoint_last.pt (epoch 220 @ 105336 updates, score None) (writing took 11.23548727761954 seconds)
[2024-10-10 07:32:09,090][fairseq_cli.train][INFO] - end of epoch 220 (average epoch stats below)
[2024-10-10 07:32:09,092][train][INFO] - {"epoch": 220, "train_loss": "1", "train_ntokens": "239287", "train_nsentences": "1753.71", "train_wps": "86945.7", "train_ups": "0.36", "train_wpb": "239287", "train_bsz": "1753.7", "train_num_updates": "105336", "train_lr": "0.000400359", "train_gnorm": "0.288", "train_loss_scale": "0.25", "train_train_wall": "909", "train_gb_free": "40.4", "train_wall": "43920"}
[2024-10-10 07:32:09,196][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:32:09,239][fairseq.trainer][INFO] - begin training epoch 221
[2024-10-10 07:32:09,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:38:44,546][train_inner][INFO] - {"epoch": 221, "update": 220.134, "loss": "1.001", "ntokens": "239086", "nsentences": "1745.71", "wps": "74833.1", "ups": "0.31", "wpb": "239086", "bsz": "1745.7", "num_updates": "105400", "lr": "0.000400272", "gnorm": "0.276", "loss_scale": "0.25", "train_wall": "314", "gb_free": "39.7", "wall": "44316"}
[2024-10-10 07:41:41,319][train_inner][INFO] - {"epoch": 221, "update": 220.551, "loss": "1", "ntokens": "239208", "nsentences": "1806.34", "wps": "270651", "ups": "1.13", "wpb": "239208", "bsz": "1806.3", "num_updates": "105600", "lr": "0.0004", "gnorm": "0.285", "loss_scale": "0.25", "train_wall": "173", "gb_free": "39.4", "wall": "44492"}
[2024-10-10 07:44:10,387][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2024-10-10 07:44:40,824][train_inner][INFO] - {"epoch": 221, "update": 220.971, "loss": "1.001", "ntokens": "240328", "nsentences": "1723.83", "wps": "267770", "ups": "1.11", "wpb": "240328", "bsz": "1723.8", "num_updates": "105800", "lr": "0.000399728", "gnorm": "0.286", "loss_scale": "0.25", "train_wall": "176", "gb_free": "39.3", "wall": "44672"}
[2024-10-10 07:45:13,793][fairseq_cli.train][INFO] - end of epoch 221 (average epoch stats below)
[2024-10-10 07:45:13,943][train][INFO] - {"epoch": 221, "train_loss": "1", "train_ntokens": "239416", "train_nsentences": "1752.75", "train_wps": "145840", "train_ups": "0.61", "train_wpb": "239416", "train_bsz": "1752.8", "train_num_updates": "105814", "train_lr": "0.000399709", "train_gnorm": "0.284", "train_loss_scale": "0.25", "train_train_wall": "467", "train_gb_free": "39.7", "train_wall": "44705"}
[2024-10-10 07:45:14,401][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:45:14,427][fairseq.trainer][INFO] - begin training epoch 222
[2024-10-10 07:45:14,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 07:52:38,981][train_inner][INFO] - {"epoch": 222, "update": 221.388, "loss": "1", "ntokens": "238837", "nsentences": "1733.35", "wps": "99902.2", "ups": "0.42", "wpb": "238837", "bsz": "1733.4", "num_updates": "106000", "lr": "0.000399457", "gnorm": "0.281", "loss_scale": "0.25", "train_wall": "209", "gb_free": "40.1", "wall": "45150"}
[2024-10-10 07:55:42,873][train_inner][INFO] - {"epoch": 222, "update": 221.806, "loss": "0.998", "ntokens": "239845", "nsentences": "1738.73", "wps": "260862", "ups": "1.09", "wpb": "239845", "bsz": "1738.7", "num_updates": "106200", "lr": "0.000399185", "gnorm": "0.287", "loss_scale": "0.25", "train_wall": "180", "gb_free": "39.7", "wall": "45334"}
[2024-10-10 07:57:20,661][fairseq_cli.train][INFO] - end of epoch 222 (average epoch stats below)
[2024-10-10 07:57:20,703][train][INFO] - {"epoch": 222, "train_loss": "1", "train_ntokens": "239358", "train_nsentences": "1753.71", "train_wps": "157762", "train_ups": "0.66", "train_wpb": "239358", "train_bsz": "1753.7", "train_num_updates": "106293", "train_lr": "0.000399058", "train_gnorm": "0.286", "train_loss_scale": "0.25", "train_train_wall": "451", "train_gb_free": "39.3", "train_wall": "45432"}
[2024-10-10 07:57:20,879][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 07:57:20,891][fairseq.trainer][INFO] - begin training epoch 223
[2024-10-10 07:57:20,891][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:03:33,665][train_inner][INFO] - {"epoch": 223, "update": 222.223, "loss": "1", "ntokens": "237800", "nsentences": "1805.83", "wps": "101022", "ups": "0.42", "wpb": "237800", "bsz": "1805.8", "num_updates": "106400", "lr": "0.000398913", "gnorm": "0.307", "loss_scale": "0.25", "train_wall": "187", "gb_free": "39.6", "wall": "45805"}
[2024-10-10 08:06:36,371][train_inner][INFO] - {"epoch": 223, "update": 222.641, "loss": "0.999", "ntokens": "239743", "nsentences": "1726.09", "wps": "262442", "ups": "1.09", "wpb": "239743", "bsz": "1726.1", "num_updates": "106600", "lr": "0.000398641", "gnorm": "0.281", "loss_scale": "0.25", "train_wall": "179", "gb_free": "39.6", "wall": "45987"}
[2024-10-10 08:09:25,613][fairseq_cli.train][INFO] - end of epoch 223 (average epoch stats below)
[2024-10-10 08:09:25,616][train][INFO] - {"epoch": 223, "train_loss": "1", "train_ntokens": "239041", "train_nsentences": "1753.71", "train_wps": "157952", "train_ups": "0.66", "train_wpb": "239042", "train_bsz": "1753.7", "train_num_updates": "106772", "train_lr": "0.000398408", "train_gnorm": "0.294", "train_loss_scale": "0.25", "train_train_wall": "437", "train_gb_free": "39.3", "train_wall": "46157"}
[2024-10-10 08:09:25,731][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:09:25,750][fairseq.trainer][INFO] - begin training epoch 224
[2024-10-10 08:09:25,751][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:14:37,565][train_inner][INFO] - {"epoch": 224, "update": 223.058, "loss": "1.003", "ntokens": "238521", "nsentences": "1764.17", "wps": "99138.2", "ups": "0.42", "wpb": "238521", "bsz": "1764.2", "num_updates": "106800", "lr": "0.00039837", "gnorm": "0.306", "loss_scale": "0.25", "train_wall": "202", "gb_free": "39.1", "wall": "46469"}
[2024-10-10 08:17:24,485][train_inner][INFO] - {"epoch": 224, "update": 223.476, "loss": "1", "ntokens": "239364", "nsentences": "1764.54", "wps": "286808", "ups": "1.2", "wpb": "239364", "bsz": "1764.5", "num_updates": "107000", "lr": "0.000398098", "gnorm": "0.298", "loss_scale": "0.25", "train_wall": "163", "gb_free": "40.1", "wall": "46636"}
[2024-10-10 08:20:19,567][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2024-10-10 08:20:47,203][train_inner][INFO] - {"epoch": 224, "update": 223.896, "loss": "1", "ntokens": "239886", "nsentences": "1747.83", "wps": "236676", "ups": "0.99", "wpb": "239886", "bsz": "1747.8", "num_updates": "107200", "lr": "0.000397826", "gnorm": "0.295", "loss_scale": "0.125", "train_wall": "199", "gb_free": "40.5", "wall": "46838"}
[2024-10-10 08:21:48,026][fairseq_cli.train][INFO] - end of epoch 224 (average epoch stats below)
[2024-10-10 08:21:48,059][train][INFO] - {"epoch": 224, "train_loss": "1.001", "train_ntokens": "239222", "train_nsentences": "1754.98", "train_wps": "154017", "train_ups": "0.64", "train_wpb": "239222", "train_bsz": "1755", "train_num_updates": "107250", "train_lr": "0.000397758", "train_gnorm": "0.301", "train_loss_scale": "0.125", "train_train_wall": "459", "train_gb_free": "40.1", "train_wall": "46899"}
[2024-10-10 08:21:48,261][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:21:48,265][fairseq.trainer][INFO] - begin training epoch 225
[2024-10-10 08:21:48,265][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:28:40,188][train_inner][INFO] - {"epoch": 225, "update": 224.313, "loss": "0.998", "ntokens": "237863", "nsentences": "1803.55", "wps": "100580", "ups": "0.42", "wpb": "237863", "bsz": "1803.5", "num_updates": "107400", "lr": "0.000397554", "gnorm": "0.329", "loss_scale": "0.125", "train_wall": "198", "gb_free": "39.3", "wall": "47311"}
[2024-10-10 08:31:57,496][train_inner][INFO] - {"epoch": 225, "update": 224.731, "loss": "1", "ntokens": "239780", "nsentences": "1711.66", "wps": "243059", "ups": "1.01", "wpb": "239780", "bsz": "1711.7", "num_updates": "107600", "lr": "0.000397283", "gnorm": "0.305", "loss_scale": "0.125", "train_wall": "194", "gb_free": "39.7", "wall": "47509"}
[2024-10-10 08:33:54,801][fairseq_cli.train][INFO] - end of epoch 225 (average epoch stats below)
[2024-10-10 08:33:54,832][train][INFO] - {"epoch": 225, "train_loss": "1", "train_ntokens": "239100", "train_nsentences": "1753.71", "train_wps": "157586", "train_ups": "0.66", "train_wpb": "239100", "train_bsz": "1753.7", "train_num_updates": "107729", "train_lr": "0.000397107", "train_gnorm": "0.308", "train_loss_scale": "0.125", "train_train_wall": "446", "train_gb_free": "39.2", "train_wall": "47626"}
[2024-10-10 08:33:55,048][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:33:55,068][fairseq.trainer][INFO] - begin training epoch 226
[2024-10-10 08:33:55,068][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:39:43,515][train_inner][INFO] - {"epoch": 226, "update": 225.148, "loss": "1", "ntokens": "238978", "nsentences": "1755.48", "wps": "102566", "ups": "0.43", "wpb": "238978", "bsz": "1755.5", "num_updates": "107800", "lr": "0.000397011", "gnorm": "0.288", "loss_scale": "0.125", "train_wall": "198", "gb_free": "39.7", "wall": "47975"}
[2024-10-10 08:42:21,965][train_inner][INFO] - {"epoch": 226, "update": 225.566, "loss": "0.999", "ntokens": "239671", "nsentences": "1750.89", "wps": "302537", "ups": "1.26", "wpb": "239671", "bsz": "1750.9", "num_updates": "108000", "lr": "0.000396739", "gnorm": "0.28", "loss_scale": "0.125", "train_wall": "154", "gb_free": "40.1", "wall": "48133"}
[2024-10-10 08:45:32,054][train_inner][INFO] - {"epoch": 226, "update": 225.983, "loss": "1", "ntokens": "239505", "nsentences": "1747.07", "wps": "252008", "ups": "1.05", "wpb": "239505", "bsz": "1747.1", "num_updates": "108200", "lr": "0.000396467", "gnorm": "0.283", "loss_scale": "0.125", "train_wall": "187", "gb_free": "39.2", "wall": "48323"}
[2024-10-10 08:46:00,742][fairseq_cli.train][INFO] - end of epoch 226 (average epoch stats below)
[2024-10-10 08:46:00,762][train][INFO] - {"epoch": 226, "train_loss": "0.999", "train_ntokens": "239147", "train_nsentences": "1753.71", "train_wps": "157804", "train_ups": "0.66", "train_wpb": "239146", "train_bsz": "1753.7", "train_num_updates": "108208", "train_lr": "0.000396457", "train_gnorm": "0.285", "train_loss_scale": "0.125", "train_train_wall": "453", "train_gb_free": "39.8", "train_wall": "48352"}
[2024-10-10 08:46:00,999][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:46:01,005][fairseq.trainer][INFO] - begin training epoch 227
[2024-10-10 08:46:01,007][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 08:53:22,467][train_inner][INFO] - {"epoch": 227, "update": 226.401, "loss": "0.997", "ntokens": "238724", "nsentences": "1772.25", "wps": "101498", "ups": "0.43", "wpb": "238724", "bsz": "1772.2", "num_updates": "108400", "lr": "0.000396196", "gnorm": "0.279", "loss_scale": "0.125", "train_wall": "194", "gb_free": "39.4", "wall": "48794"}
[2024-10-10 08:56:35,043][train_inner][INFO] - {"epoch": 227, "update": 226.818, "loss": "1.001", "ntokens": "239957", "nsentences": "1743.14", "wps": "249214", "ups": "1.04", "wpb": "239957", "bsz": "1743.1", "num_updates": "108600", "lr": "0.000395924", "gnorm": "0.297", "loss_scale": "0.125", "train_wall": "189", "gb_free": "40.1", "wall": "48986"}
[2024-10-10 08:58:00,670][fairseq_cli.train][INFO] - end of epoch 227 (average epoch stats below)
[2024-10-10 08:58:00,968][train][INFO] - {"epoch": 227, "train_loss": "0.999", "train_ntokens": "239379", "train_nsentences": "1753.71", "train_wps": "159213", "train_ups": "0.67", "train_wpb": "239378", "train_bsz": "1753.7", "train_num_updates": "108687", "train_lr": "0.000395806", "train_gnorm": "0.285", "train_loss_scale": "0.125", "train_train_wall": "438", "train_gb_free": "39.6", "train_wall": "49072"}
[2024-10-10 08:58:01,281][fairseq.data.iterators][INFO] - grouped total_num_itrs = 479
[2024-10-10 08:58:01,327][fairseq.trainer][INFO] - begin training epoch 228
[2024-10-10 08:58:01,328][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-10 09:04:13,061][train_inner][INFO] - {"epoch": 228, "update": 227.236, "loss": "0.997", "ntokens": "239193", "nsentences": "1721.32", "wps": "104454", "ups": "0.44", "wpb": "239193", "bsz": "1721.3", "num_updates": "108800", "lr": "0.000395652", "gnorm": "0.289", "loss_scale": "0.125", "train_wall": "183", "gb_free": "39.7", "wall": "49444"}
