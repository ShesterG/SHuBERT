[2024-10-09 01:25:46,627][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12777', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:25:57,015][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13391', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:26:02,860][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16872', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:26:03,144][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:11616', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:26:03,582][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15265', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:26:04,420][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/log.txt', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/share/data/pals/shester/sign_dinosr/fairseq/examples/dinosr', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:15735', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 16, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 15000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 100, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': True, 'max_tokens_valid': 15000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 20, 'save_interval_updates': 50000, 'keep_interval_updates': 10, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': True, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'signhubert', 'extractor_mode': layer_norm, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 3, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 32, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'discrete': True, 'codebook_size': 256, 'max_update': '${optimization.max_update}', 'channels_embed_dim': 384, 'channels_pose_embed_dim': 14, 'intermediate_dim': 1024, 'mask_strategy': 'random'}, 'task': {'_name': 'audio_pretraining', 'data': '/share/data/pals/shester/sign_dinosr_logs/dataset/train_ssl_ysl25_ase_80k_share.csv', 'labels': None, 'binarized_dataset': False, 'sample_rate': 1, 'normalize': True, 'enable_padding': False, 'max_sample_size': 1000, 'min_sample_size': 1, 'num_batch_buckets': 0, 'precompute_mask_indices': False, 'inferred_w2v_config': None, 'kmeans_label_paths': {'face': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/face/face_256.km', 'left_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/lhand/lhand_256.km', 'right_hand': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/rhand/rhand_256.km', 'body_posture': '/share/data/pals/shester/sign_dinosr_logs/km_labels/ysl25/ase80/body/body_256.km'}, 'tpu': False, 'text_compression_level': none}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': []}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2024-10-09 01:26:08,819][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:08,821][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:08,821][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:08,821][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:08,822][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:08,908][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:08,941][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:08,944][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:08,944][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:08,944][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:08,945][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:08,945][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:08,977][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:08,979][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:08,983][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:08,983][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:08,984][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:08,984][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:09,173][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:26:09,484][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:26:10,804][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:10,806][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:10,806][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:10,806][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:10,807][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:10,808][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:11,443][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:26:14,679][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:14,681][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:14,681][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:14,681][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:14,682][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:14,683][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:14,963][fairseq_cli.train][INFO] - SignHubertModel(
  (post_extract_proj): Linear(in_features=1024, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.0, inplace=False)
  (dropout_features): Dropout(p=0.0, inplace=False)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(32,), stride=(1,), padding=(16,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (layer_norm_face): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_lhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_rhand): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
  (layer_norm_body): LayerNorm((14,), eps=1e-05, elementwise_affine=True)
  (heads): ModuleList(
    (0-3): 4 x Linear(in_features=768, out_features=256, bias=True)
  )
  (face_proj): Linear(in_features=384, out_features=256, bias=True)
  (left_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (right_hand_proj): Linear(in_features=384, out_features=256, bias=True)
  (body_posture_proj): Linear(in_features=14, out_features=256, bias=True)
)
[2024-10-09 01:26:14,965][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2024-10-09 01:26:14,965][fairseq_cli.train][INFO] - model: SignHubertModel
[2024-10-09 01:26:14,965][fairseq_cli.train][INFO] - criterion: ModelCriterion
[2024-10-09 01:26:14,966][fairseq_cli.train][INFO] - num. shared model params: 88,116,284 (num. trained: 88,116,284)
[2024-10-09 01:26:14,975][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2024-10-09 01:26:16,434][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:26:18,050][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:26:24,278][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:27:09,036][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:27:09,040][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:09,047][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:27:09,048][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:27:09,048][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:27:09,049][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:27:37,774][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:27:37,787][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:27:38,479][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:27:42,329][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:27:42,329][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,329][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:27:42,330][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:27:42,330][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:27:42,331][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:27:42,332][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:27:47,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:27:47,893][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:27:47,893][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:05,485][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:28:05,486][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:28:05,486][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:28:05,487][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:28:24,704][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,706][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,707][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:28:24,707][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:28:24,707][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:28:24,711][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:28:24,712][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:28:26,482][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:28:26,495][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:28:27,894][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:28:37,316][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:28:37,333][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:28:37,334][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:28:38,256][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:28:38,258][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:28:39,068][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:28:47,434][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:28:47,452][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:28:47,453][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:28:57,992][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:28:57,994][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:29:00,999][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:29:06,794][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:29:06,794][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,794][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,794][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,794][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,795][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,795][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,815][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,815][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:06,815][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:29:06,815][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:29:06,815][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:29:06,816][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:29:16,906][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:29:16,912][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:29:16,912][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:29:21,841][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   4: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   5: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   6: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - rank   7: capabilities =  8.9  ; total memory = 47.500 GB ; name = NVIDIA RTX 6000 Ada Generation          
[2024-10-09 01:29:21,842][fairseq.utils][INFO] - ***********************CUDA enviroments for all 8 workers***********************
[2024-10-09 01:29:21,842][fairseq_cli.train][INFO] - training on 8 devices (GPUs/TPUs)
[2024-10-09 01:29:21,843][fairseq_cli.train][INFO] - max tokens per device = 15000 and max sentences per device = None
[2024-10-09 01:29:21,901][fairseq.trainer][INFO] - Preparing to load checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 01:29:32,916][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:29:32,918][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:29:33,228][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:29:39,622][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:29:39,627][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:29:39,628][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:30:15,042][fairseq.trainer][INFO] - Loaded checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1041 @ 49896 updates)
[2024-10-09 01:30:15,051][fairseq.trainer][INFO] - loading train data for epoch 1041
[2024-10-09 01:30:15,414][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 84002, skipped 0 samples
[2024-10-09 01:30:24,961][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:30:24,985][fairseq.trainer][INFO] - begin training epoch 1041
[2024-10-09 01:30:24,985][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:38:50,651][fairseq_cli.train][INFO] - end of epoch 1041 (average epoch stats below)
[2024-10-09 01:38:50,934][train][INFO] - {"epoch": 1041, "train_loss": "0.524", "train_ntokens": "260478", "train_nsentences": "1750.04", "train_wps": "49533.9", "train_ups": "0.19", "train_wpb": "260478", "train_bsz": "1750", "train_num_updates": "49944", "train_lr": "0.00047562", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "255", "train_gb_free": "39.8", "train_wall": "702"}
[2024-10-09 01:38:51,430][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:38:51,455][fairseq.trainer][INFO] - begin training epoch 1042
[2024-10-09 01:38:51,459][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:47:22,126][fairseq_cli.train][INFO] - end of epoch 1042 (average epoch stats below)
[2024-10-09 01:47:22,171][train][INFO] - {"epoch": 1042, "train_loss": "0.523", "train_ntokens": "260617", "train_nsentences": "1750.04", "train_wps": "24471.4", "train_ups": "0.09", "train_wpb": "260617", "train_bsz": "1750", "train_num_updates": "49992", "train_lr": "0.000475554", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "127", "train_gb_free": "39.7", "train_wall": "1213"}
[2024-10-09 01:47:22,289][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:47:22,298][fairseq.trainer][INFO] - begin training epoch 1043
[2024-10-09 01:47:22,299][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:50:12,861][train_inner][INFO] - {"epoch": 1043, "update": 1042.167, "loss": "0.523", "ntokens": "260299", "nsentences": "1760.85", "wps": "28851.5", "ups": "0.11", "wpb": "260299", "bsz": "1760.8", "num_updates": "50000", "lr": "0.000475543", "gnorm": "0.376", "loss_scale": "2", "train_wall": "413", "gb_free": "39.8", "wall": "1384"}
[2024-10-09 01:50:12,882][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1043 @ 50000 updates
[2024-10-09 01:50:12,883][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_1043_50000.pt
[2024-10-09 01:50:17,286][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_1043_50000.pt
[2024-10-09 01:50:26,618][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_1043_50000.pt (epoch 1043 @ 50000 updates, score None) (writing took 13.735459825955331 seconds)
[2024-10-09 01:50:47,238][fairseq_cli.train][INFO] - end of epoch 1043 (average epoch stats below)
[2024-10-09 01:50:47,241][train][INFO] - {"epoch": 1043, "train_loss": "0.525", "train_ntokens": "261085", "train_nsentences": "1750.04", "train_wps": "61111.9", "train_ups": "0.23", "train_wpb": "261085", "train_bsz": "1750", "train_num_updates": "50040", "train_lr": "0.000475489", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "52", "train_gb_free": "39.6", "train_wall": "1418"}
[2024-10-09 01:50:47,363][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:50:47,369][fairseq.trainer][INFO] - begin training epoch 1044
[2024-10-09 01:50:47,369][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:53:07,301][fairseq_cli.train][INFO] - end of epoch 1044 (average epoch stats below)
[2024-10-09 01:53:07,309][train][INFO] - {"epoch": 1044, "train_loss": "0.523", "train_ntokens": "260619", "train_nsentences": "1750.04", "train_wps": "89313.1", "train_ups": "0.34", "train_wpb": "260619", "train_bsz": "1750", "train_num_updates": "50088", "train_lr": "0.000475424", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "40.1", "train_wall": "1558"}
[2024-10-09 01:53:07,401][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:53:07,420][fairseq.trainer][INFO] - begin training epoch 1045
[2024-10-09 01:53:07,420][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:55:40,924][fairseq_cli.train][INFO] - end of epoch 1045 (average epoch stats below)
[2024-10-09 01:55:40,951][train][INFO] - {"epoch": 1045, "train_loss": "0.523", "train_ntokens": "261030", "train_nsentences": "1750.04", "train_wps": "81558.1", "train_ups": "0.31", "train_wpb": "261030", "train_bsz": "1750", "train_num_updates": "50136", "train_lr": "0.000475359", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "71", "train_gb_free": "39.4", "train_wall": "1712"}
[2024-10-09 01:55:41,202][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:55:41,215][fairseq.trainer][INFO] - begin training epoch 1046
[2024-10-09 01:55:41,216][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 01:58:35,385][fairseq_cli.train][INFO] - end of epoch 1046 (average epoch stats below)
[2024-10-09 01:58:35,389][train][INFO] - {"epoch": 1046, "train_loss": "0.532", "train_ntokens": "260571", "train_nsentences": "1750.04", "train_wps": "71702.3", "train_ups": "0.28", "train_wpb": "260571", "train_bsz": "1750", "train_num_updates": "50184", "train_lr": "0.000475293", "train_gnorm": "0.417", "train_loss_scale": "2", "train_train_wall": "74", "train_gb_free": "40.1", "train_wall": "1886"}
[2024-10-09 01:58:35,514][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 01:58:35,533][fairseq.trainer][INFO] - begin training epoch 1047
[2024-10-09 01:58:35,533][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:00:35,966][train_inner][INFO] - {"epoch": 1047, "update": 1046.333, "loss": "0.524", "ntokens": "260978", "nsentences": "1747.42", "wps": "83769", "ups": "0.32", "wpb": "260978", "bsz": "1747.4", "num_updates": "50200", "lr": "0.000475272", "gnorm": "0.389", "loss_scale": "2", "train_wall": "267", "gb_free": "39.2", "wall": "2007"}
[2024-10-09 02:00:56,068][fairseq_cli.train][INFO] - end of epoch 1047 (average epoch stats below)
[2024-10-09 02:00:56,083][train][INFO] - {"epoch": 1047, "train_loss": "0.513", "train_ntokens": "260659", "train_nsentences": "1750.04", "train_wps": "88937.2", "train_ups": "0.34", "train_wpb": "260659", "train_bsz": "1750", "train_num_updates": "50232", "train_lr": "0.000475228", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "40.1", "train_wall": "2027"}
[2024-10-09 02:00:56,206][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:00:56,222][fairseq.trainer][INFO] - begin training epoch 1048
[2024-10-09 02:00:56,223][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:03:13,995][fairseq_cli.train][INFO] - end of epoch 1048 (average epoch stats below)
[2024-10-09 02:03:14,000][train][INFO] - {"epoch": 1048, "train_loss": "0.522", "train_ntokens": "260772", "train_nsentences": "1750.04", "train_wps": "90760.1", "train_ups": "0.35", "train_wpb": "260772", "train_bsz": "1750", "train_num_updates": "50280", "train_lr": "0.000475163", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "39", "train_gb_free": "39.8", "train_wall": "2165"}
[2024-10-09 02:03:14,080][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:03:14,093][fairseq.trainer][INFO] - begin training epoch 1049
[2024-10-09 02:03:14,093][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:05:25,933][fairseq_cli.train][INFO] - end of epoch 1049 (average epoch stats below)
[2024-10-09 02:05:25,938][train][INFO] - {"epoch": 1049, "train_loss": "0.525", "train_ntokens": "260534", "train_nsentences": "1750.04", "train_wps": "94785.8", "train_ups": "0.36", "train_wpb": "260534", "train_bsz": "1750", "train_num_updates": "50328", "train_lr": "0.000475098", "train_gnorm": "0.381", "train_loss_scale": "2", "train_train_wall": "29", "train_gb_free": "40.1", "train_wall": "2297"}
[2024-10-09 02:05:26,077][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:05:26,090][fairseq.trainer][INFO] - begin training epoch 1050
[2024-10-09 02:05:26,091][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:07:51,392][fairseq_cli.train][INFO] - end of epoch 1050 (average epoch stats below)
[2024-10-09 02:07:51,395][train][INFO] - {"epoch": 1050, "train_loss": "0.529", "train_ntokens": "261021", "train_nsentences": "1750.04", "train_wps": "86136.4", "train_ups": "0.33", "train_wpb": "261021", "train_bsz": "1750", "train_num_updates": "50376", "train_lr": "0.000475033", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40.1", "train_wall": "2442"}
[2024-10-09 02:07:51,463][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:07:51,484][fairseq.trainer][INFO] - begin training epoch 1051
[2024-10-09 02:07:51,484][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:10:15,536][train_inner][INFO] - {"epoch": 1051, "update": 1050.5, "loss": "0.524", "ntokens": "260689", "nsentences": "1742.62", "wps": "89960.2", "ups": "0.35", "wpb": "260689", "bsz": "1742.6", "num_updates": "50400", "lr": "0.000475", "gnorm": "0.385", "loss_scale": "2", "train_wall": "206", "gb_free": "40.1", "wall": "2586"}
[2024-10-09 02:10:32,019][fairseq_cli.train][INFO] - end of epoch 1051 (average epoch stats below)
[2024-10-09 02:10:32,022][train][INFO] - {"epoch": 1051, "train_loss": "0.522", "train_ntokens": "260757", "train_nsentences": "1750.04", "train_wps": "77923.6", "train_ups": "0.3", "train_wpb": "260757", "train_bsz": "1750", "train_num_updates": "50424", "train_lr": "0.000474967", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.3", "train_wall": "2603"}
[2024-10-09 02:10:32,135][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:10:32,142][fairseq.trainer][INFO] - begin training epoch 1052
[2024-10-09 02:10:32,142][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:12:55,356][fairseq_cli.train][INFO] - end of epoch 1052 (average epoch stats below)
[2024-10-09 02:12:55,363][train][INFO] - {"epoch": 1052, "train_loss": "0.524", "train_ntokens": "260866", "train_nsentences": "1750.04", "train_wps": "87356.6", "train_ups": "0.33", "train_wpb": "260866", "train_bsz": "1750", "train_num_updates": "50472", "train_lr": "0.000474902", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.7", "train_wall": "2746"}
[2024-10-09 02:12:55,463][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:12:55,477][fairseq.trainer][INFO] - begin training epoch 1053
[2024-10-09 02:12:55,477][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:15:49,086][fairseq_cli.train][INFO] - end of epoch 1053 (average epoch stats below)
[2024-10-09 02:15:49,103][train][INFO] - {"epoch": 1053, "train_loss": "0.524", "train_ntokens": "260704", "train_nsentences": "1750.04", "train_wps": "72028.4", "train_ups": "0.28", "train_wpb": "260704", "train_bsz": "1750", "train_num_updates": "50520", "train_lr": "0.000474837", "train_gnorm": "0.391", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.6", "train_wall": "2920"}
[2024-10-09 02:15:49,237][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:15:49,241][fairseq.trainer][INFO] - begin training epoch 1054
[2024-10-09 02:15:49,241][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:18:17,158][fairseq_cli.train][INFO] - end of epoch 1054 (average epoch stats below)
[2024-10-09 02:18:17,164][train][INFO] - {"epoch": 1054, "train_loss": "0.523", "train_ntokens": "260603", "train_nsentences": "1750.04", "train_wps": "84486.7", "train_ups": "0.32", "train_wpb": "260603", "train_bsz": "1750", "train_num_updates": "50568", "train_lr": "0.000474772", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.8", "train_wall": "3068"}
[2024-10-09 02:18:17,305][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:18:17,323][fairseq.trainer][INFO] - begin training epoch 1055
[2024-10-09 02:18:17,323][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:20:51,256][train_inner][INFO] - {"epoch": 1055, "update": 1054.667, "loss": "0.523", "ntokens": "260647", "nsentences": "1761.38", "wps": "82001.2", "ups": "0.31", "wpb": "260647", "bsz": "1761.4", "num_updates": "50600", "lr": "0.000474728", "gnorm": "0.389", "loss_scale": "2", "train_wall": "208", "gb_free": "39.4", "wall": "3222"}
[2024-10-09 02:21:06,935][fairseq_cli.train][INFO] - end of epoch 1055 (average epoch stats below)
[2024-10-09 02:21:06,937][train][INFO] - {"epoch": 1055, "train_loss": "0.521", "train_ntokens": "260821", "train_nsentences": "1750.04", "train_wps": "73743", "train_ups": "0.28", "train_wpb": "260821", "train_bsz": "1750", "train_num_updates": "50616", "train_lr": "0.000474707", "train_gnorm": "0.39", "train_loss_scale": "2", "train_train_wall": "43", "train_gb_free": "39.4", "train_wall": "3238"}
[2024-10-09 02:21:07,096][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:21:07,100][fairseq.trainer][INFO] - begin training epoch 1056
[2024-10-09 02:21:07,100][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:23:43,289][fairseq_cli.train][INFO] - end of epoch 1056 (average epoch stats below)
[2024-10-09 02:23:43,293][train][INFO] - {"epoch": 1056, "train_loss": "0.515", "train_ntokens": "260849", "train_nsentences": "1750.04", "train_wps": "80079.9", "train_ups": "0.31", "train_wpb": "260849", "train_bsz": "1750", "train_num_updates": "50664", "train_lr": "0.000474641", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "37", "train_gb_free": "40.6", "train_wall": "3394"}
[2024-10-09 02:23:43,427][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:23:43,443][fairseq.trainer][INFO] - begin training epoch 1057
[2024-10-09 02:23:43,444][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:27:27,164][fairseq_cli.train][INFO] - end of epoch 1057 (average epoch stats below)
[2024-10-09 02:27:27,171][train][INFO] - {"epoch": 1057, "train_loss": "0.513", "train_ntokens": "260929", "train_nsentences": "1750.04", "train_wps": "55944.5", "train_ups": "0.21", "train_wpb": "260929", "train_bsz": "1750", "train_num_updates": "50712", "train_lr": "0.000474576", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.6", "train_wall": "3618"}
[2024-10-09 02:27:27,344][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:27:27,349][fairseq.trainer][INFO] - begin training epoch 1058
[2024-10-09 02:27:27,349][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:31:09,348][fairseq_cli.train][INFO] - end of epoch 1058 (average epoch stats below)
[2024-10-09 02:31:09,352][train][INFO] - {"epoch": 1058, "train_loss": "0.523", "train_ntokens": "260894", "train_nsentences": "1750.04", "train_wps": "56363.9", "train_ups": "0.22", "train_wpb": "260894", "train_bsz": "1750", "train_num_updates": "50760", "train_lr": "0.000474511", "train_gnorm": "0.41", "train_loss_scale": "2", "train_train_wall": "23", "train_gb_free": "39.2", "train_wall": "3840"}
[2024-10-09 02:31:09,486][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:31:09,497][fairseq.trainer][INFO] - begin training epoch 1059
[2024-10-09 02:31:09,497][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:33:37,472][train_inner][INFO] - {"epoch": 1059, "update": 1058.833, "loss": "0.519", "ntokens": "261062", "nsentences": "1736.85", "wps": "68144.4", "ups": "0.26", "wpb": "261062", "bsz": "1736.8", "num_updates": "50800", "lr": "0.000474457", "gnorm": "0.385", "loss_scale": "2", "train_wall": "217", "gb_free": "39.3", "wall": "3988"}
[2024-10-09 02:33:39,569][fairseq_cli.train][INFO] - end of epoch 1059 (average epoch stats below)
[2024-10-09 02:33:39,571][train][INFO] - {"epoch": 1059, "train_loss": "0.526", "train_ntokens": "260582", "train_nsentences": "1750.04", "train_wps": "83265.9", "train_ups": "0.32", "train_wpb": "260582", "train_bsz": "1750", "train_num_updates": "50808", "train_lr": "0.000474446", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "40.3", "train_wall": "3991"}
[2024-10-09 02:33:39,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:33:39,704][fairseq.trainer][INFO] - begin training epoch 1060
[2024-10-09 02:33:39,705][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:36:24,602][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1060 @ 50856 updates
[2024-10-09 02:36:24,604][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 02:36:28,300][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 02:36:28,303][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1060 @ 50856 updates, score None) (writing took 3.700542524456978 seconds)
[2024-10-09 02:36:28,304][fairseq_cli.train][INFO] - end of epoch 1060 (average epoch stats below)
[2024-10-09 02:36:28,307][train][INFO] - {"epoch": 1060, "train_loss": "0.525", "train_ntokens": "260882", "train_nsentences": "1750.04", "train_wps": "74214.4", "train_ups": "0.28", "train_wpb": "260882", "train_bsz": "1750", "train_num_updates": "50856", "train_lr": "0.00047438", "train_gnorm": "0.4", "train_loss_scale": "2", "train_train_wall": "83", "train_gb_free": "39.7", "train_wall": "4159"}
[2024-10-09 02:36:28,408][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:36:28,428][fairseq.trainer][INFO] - begin training epoch 1061
[2024-10-09 02:36:28,428][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:38:51,604][fairseq_cli.train][INFO] - end of epoch 1061 (average epoch stats below)
[2024-10-09 02:38:51,609][train][INFO] - {"epoch": 1061, "train_loss": "0.515", "train_ntokens": "260548", "train_nsentences": "1750.04", "train_wps": "87274", "train_ups": "0.33", "train_wpb": "260548", "train_bsz": "1750", "train_num_updates": "50904", "train_lr": "0.000474315", "train_gnorm": "0.411", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.6", "train_wall": "4303"}
[2024-10-09 02:38:51,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:38:51,722][fairseq.trainer][INFO] - begin training epoch 1062
[2024-10-09 02:38:51,722][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:41:03,372][fairseq_cli.train][INFO] - end of epoch 1062 (average epoch stats below)
[2024-10-09 02:41:03,379][train][INFO] - {"epoch": 1062, "train_loss": "0.519", "train_ntokens": "260466", "train_nsentences": "1750.04", "train_wps": "94883.1", "train_ups": "0.36", "train_wpb": "260466", "train_bsz": "1750", "train_num_updates": "50952", "train_lr": "0.00047425", "train_gnorm": "0.382", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "4434"}
[2024-10-09 02:41:03,548][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:41:03,552][fairseq.trainer][INFO] - begin training epoch 1063
[2024-10-09 02:41:03,552][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:43:18,936][train_inner][INFO] - {"epoch": 1063, "update": 1063.0, "loss": "0.519", "ntokens": "260522", "nsentences": "1756.33", "wps": "89610.6", "ups": "0.34", "wpb": "260522", "bsz": "1756.3", "num_updates": "51000", "lr": "0.000474185", "gnorm": "0.39", "loss_scale": "2", "train_wall": "257", "gb_free": "40.2", "wall": "4570"}
[2024-10-09 02:43:18,941][fairseq_cli.train][INFO] - end of epoch 1063 (average epoch stats below)
[2024-10-09 02:43:18,943][train][INFO] - {"epoch": 1063, "train_loss": "0.513", "train_ntokens": "260604", "train_nsentences": "1750.04", "train_wps": "92276.9", "train_ups": "0.35", "train_wpb": "260604", "train_bsz": "1750", "train_num_updates": "51000", "train_lr": "0.000474185", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "40.2", "train_wall": "4570"}
[2024-10-09 02:43:19,014][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:43:19,021][fairseq.trainer][INFO] - begin training epoch 1064
[2024-10-09 02:43:19,022][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:45:25,930][fairseq_cli.train][INFO] - end of epoch 1064 (average epoch stats below)
[2024-10-09 02:45:25,934][train][INFO] - {"epoch": 1064, "train_loss": "0.52", "train_ntokens": "261009", "train_nsentences": "1750.04", "train_wps": "98657.9", "train_ups": "0.38", "train_wpb": "261009", "train_bsz": "1750", "train_num_updates": "51048", "train_lr": "0.00047412", "train_gnorm": "0.342", "train_loss_scale": "2", "train_train_wall": "45", "train_gb_free": "39.8", "train_wall": "4697"}
[2024-10-09 02:45:26,041][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:45:26,057][fairseq.trainer][INFO] - begin training epoch 1065
[2024-10-09 02:45:26,058][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:48:03,290][fairseq_cli.train][INFO] - end of epoch 1065 (average epoch stats below)
[2024-10-09 02:48:03,302][train][INFO] - {"epoch": 1065, "train_loss": "0.529", "train_ntokens": "260504", "train_nsentences": "1750.04", "train_wps": "79460.6", "train_ups": "0.31", "train_wpb": "260504", "train_bsz": "1750", "train_num_updates": "51096", "train_lr": "0.000474054", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.6", "train_wall": "4854"}
[2024-10-09 02:48:03,493][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:48:03,497][fairseq.trainer][INFO] - begin training epoch 1066
[2024-10-09 02:48:03,498][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:51:30,284][fairseq_cli.train][INFO] - end of epoch 1066 (average epoch stats below)
[2024-10-09 02:51:30,290][train][INFO] - {"epoch": 1066, "train_loss": "0.51", "train_ntokens": "260313", "train_nsentences": "1750.04", "train_wps": "60366.5", "train_ups": "0.23", "train_wpb": "260313", "train_bsz": "1750", "train_num_updates": "51144", "train_lr": "0.000473989", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "111", "train_gb_free": "40.2", "train_wall": "5061"}
[2024-10-09 02:51:30,449][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:51:30,462][fairseq.trainer][INFO] - begin training epoch 1067
[2024-10-09 02:51:30,463][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:54:35,774][fairseq_cli.train][INFO] - end of epoch 1067 (average epoch stats below)
[2024-10-09 02:54:35,787][train][INFO] - {"epoch": 1067, "train_loss": "0.524", "train_ntokens": "261154", "train_nsentences": "1750.04", "train_wps": "67578.8", "train_ups": "0.26", "train_wpb": "261154", "train_bsz": "1750", "train_num_updates": "51192", "train_lr": "0.000473924", "train_gnorm": "0.369", "train_loss_scale": "2", "train_train_wall": "94", "train_gb_free": "39.3", "train_wall": "5247"}
[2024-10-09 02:54:36,049][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:54:36,066][fairseq.trainer][INFO] - begin training epoch 1068
[2024-10-09 02:54:36,066][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 02:57:12,805][train_inner][INFO] - {"epoch": 1068, "update": 1067.167, "loss": "0.52", "ntokens": "260777", "nsentences": "1738.58", "wps": "62546.6", "ups": "0.24", "wpb": "260777", "bsz": "1738.6", "num_updates": "51200", "lr": "0.000473913", "gnorm": "0.367", "loss_scale": "2", "train_wall": "346", "gb_free": "39.3", "wall": "5404"}
[2024-10-09 02:58:10,095][fairseq_cli.train][INFO] - end of epoch 1068 (average epoch stats below)
[2024-10-09 02:58:10,098][train][INFO] - {"epoch": 1068, "train_loss": "0.519", "train_ntokens": "260640", "train_nsentences": "1750.04", "train_wps": "58377.2", "train_ups": "0.22", "train_wpb": "260640", "train_bsz": "1750", "train_num_updates": "51240", "train_lr": "0.000473859", "train_gnorm": "0.428", "train_loss_scale": "2", "train_train_wall": "86", "train_gb_free": "39.7", "train_wall": "5461"}
[2024-10-09 02:58:10,375][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 02:58:10,387][fairseq.trainer][INFO] - begin training epoch 1069
[2024-10-09 02:58:10,387][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:01:46,224][fairseq_cli.train][INFO] - end of epoch 1069 (average epoch stats below)
[2024-10-09 03:01:46,235][train][INFO] - {"epoch": 1069, "train_loss": "0.513", "train_ntokens": "260537", "train_nsentences": "1750.04", "train_wps": "57861.2", "train_ups": "0.22", "train_wpb": "260537", "train_bsz": "1750", "train_num_updates": "51288", "train_lr": "0.000473793", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "97", "train_gb_free": "39.2", "train_wall": "5677"}
[2024-10-09 03:01:46,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:01:46,473][fairseq.trainer][INFO] - begin training epoch 1070
[2024-10-09 03:01:46,473][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:05:13,939][fairseq_cli.train][INFO] - end of epoch 1070 (average epoch stats below)
[2024-10-09 03:05:13,944][train][INFO] - {"epoch": 1070, "train_loss": "0.512", "train_ntokens": "260772", "train_nsentences": "1750.04", "train_wps": "60263.2", "train_ups": "0.23", "train_wpb": "260772", "train_bsz": "1750", "train_num_updates": "51336", "train_lr": "0.000473728", "train_gnorm": "0.405", "train_loss_scale": "2", "train_train_wall": "97", "train_gb_free": "39.6", "train_wall": "5885"}
[2024-10-09 03:05:14,149][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:05:14,186][fairseq.trainer][INFO] - begin training epoch 1071
[2024-10-09 03:05:14,187][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:08:49,814][fairseq_cli.train][INFO] - end of epoch 1071 (average epoch stats below)
[2024-10-09 03:08:49,826][train][INFO] - {"epoch": 1071, "train_loss": "0.509", "train_ntokens": "260538", "train_nsentences": "1750.04", "train_wps": "57929.6", "train_ups": "0.22", "train_wpb": "260538", "train_bsz": "1750", "train_num_updates": "51384", "train_lr": "0.000473663", "train_gnorm": "0.373", "train_loss_scale": "2", "train_train_wall": "91", "train_gb_free": "39.3", "train_wall": "6101"}
[2024-10-09 03:08:50,024][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:08:50,055][fairseq.trainer][INFO] - begin training epoch 1072
[2024-10-09 03:08:50,056][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:12:10,725][train_inner][INFO] - {"epoch": 1072, "update": 1071.333, "loss": "0.513", "ntokens": "260546", "nsentences": "1767.49", "wps": "58039", "ups": "0.22", "wpb": "260546", "bsz": "1767.5", "num_updates": "51400", "lr": "0.000473641", "gnorm": "0.391", "loss_scale": "2", "train_wall": "420", "gb_free": "41.1", "wall": "6302"}
[2024-10-09 03:12:34,187][fairseq_cli.train][INFO] - end of epoch 1072 (average epoch stats below)
[2024-10-09 03:12:34,200][train][INFO] - {"epoch": 1072, "train_loss": "0.514", "train_ntokens": "260268", "train_nsentences": "1750.04", "train_wps": "55682", "train_ups": "0.21", "train_wpb": "260268", "train_bsz": "1750", "train_num_updates": "51432", "train_lr": "0.000473598", "train_gnorm": "0.379", "train_loss_scale": "2", "train_train_wall": "102", "train_gb_free": "39.8", "train_wall": "6325"}
[2024-10-09 03:12:34,424][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:12:34,429][fairseq.trainer][INFO] - begin training epoch 1073
[2024-10-09 03:12:34,429][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:16:01,490][fairseq_cli.train][INFO] - end of epoch 1073 (average epoch stats below)
[2024-10-09 03:16:01,498][train][INFO] - {"epoch": 1073, "train_loss": "0.513", "train_ntokens": "260852", "train_nsentences": "1750.04", "train_wps": "60401.3", "train_ups": "0.23", "train_wpb": "260852", "train_bsz": "1750", "train_num_updates": "51480", "train_lr": "0.000473533", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "123", "train_gb_free": "39.7", "train_wall": "6532"}
[2024-10-09 03:16:01,754][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:16:01,773][fairseq.trainer][INFO] - begin training epoch 1074
[2024-10-09 03:16:01,774][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:19:28,384][fairseq_cli.train][INFO] - end of epoch 1074 (average epoch stats below)
[2024-10-09 03:19:28,388][train][INFO] - {"epoch": 1074, "train_loss": "0.518", "train_ntokens": "260793", "train_nsentences": "1750.04", "train_wps": "60506.6", "train_ups": "0.23", "train_wpb": "260793", "train_bsz": "1750", "train_num_updates": "51528", "train_lr": "0.000473467", "train_gnorm": "0.36", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "40.1", "train_wall": "6739"}
[2024-10-09 03:19:28,629][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:19:28,653][fairseq.trainer][INFO] - begin training epoch 1075
[2024-10-09 03:19:28,654][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:23:20,930][fairseq_cli.train][INFO] - end of epoch 1075 (average epoch stats below)
[2024-10-09 03:23:20,937][train][INFO] - {"epoch": 1075, "train_loss": "0.515", "train_ntokens": "260743", "train_nsentences": "1750.04", "train_wps": "53820.1", "train_ups": "0.21", "train_wpb": "260743", "train_bsz": "1750", "train_num_updates": "51576", "train_lr": "0.000473402", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "118", "train_gb_free": "39.7", "train_wall": "6972"}
[2024-10-09 03:23:21,155][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:23:21,166][fairseq.trainer][INFO] - begin training epoch 1076
[2024-10-09 03:23:21,167][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:26:56,869][train_inner][INFO] - {"epoch": 1076, "update": 1075.5, "loss": "0.514", "ntokens": "260820", "nsentences": "1745.91", "wps": "58868.9", "ups": "0.23", "wpb": "260820", "bsz": "1745.9", "num_updates": "51600", "lr": "0.00047337", "gnorm": "0.381", "loss_scale": "2", "train_wall": "447", "gb_free": "40.1", "wall": "7188"}
[2024-10-09 03:27:12,619][fairseq_cli.train][INFO] - end of epoch 1076 (average epoch stats below)
[2024-10-09 03:27:12,621][train][INFO] - {"epoch": 1076, "train_loss": "0.516", "train_ntokens": "260925", "train_nsentences": "1750.04", "train_wps": "54058.7", "train_ups": "0.21", "train_wpb": "260925", "train_bsz": "1750", "train_num_updates": "51624", "train_lr": "0.000473337", "train_gnorm": "0.39", "train_loss_scale": "2", "train_train_wall": "132", "train_gb_free": "39.6", "train_wall": "7204"}
[2024-10-09 03:27:12,854][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:27:12,872][fairseq.trainer][INFO] - begin training epoch 1077
[2024-10-09 03:27:12,872][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:30:19,387][fairseq_cli.train][INFO] - end of epoch 1077 (average epoch stats below)
[2024-10-09 03:30:19,391][train][INFO] - {"epoch": 1077, "train_loss": "0.514", "train_ntokens": "260503", "train_nsentences": "1750.04", "train_wps": "66950.2", "train_ups": "0.26", "train_wpb": "260503", "train_bsz": "1750", "train_num_updates": "51672", "train_lr": "0.000473272", "train_gnorm": "0.415", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.2", "train_wall": "7390"}
[2024-10-09 03:30:19,685][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:30:19,712][fairseq.trainer][INFO] - begin training epoch 1078
[2024-10-09 03:30:19,712][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:33:22,661][fairseq_cli.train][INFO] - end of epoch 1078 (average epoch stats below)
[2024-10-09 03:33:22,667][train][INFO] - {"epoch": 1078, "train_loss": "0.511", "train_ntokens": "260709", "train_nsentences": "1750.04", "train_wps": "68281.5", "train_ups": "0.26", "train_wpb": "260709", "train_bsz": "1750", "train_num_updates": "51720", "train_lr": "0.000473207", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "99", "train_gb_free": "39.4", "train_wall": "7574"}
[2024-10-09 03:33:22,948][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:33:22,952][fairseq.trainer][INFO] - begin training epoch 1079
[2024-10-09 03:33:22,952][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:36:16,217][fairseq_cli.train][INFO] - end of epoch 1079 (average epoch stats below)
[2024-10-09 03:36:16,223][train][INFO] - {"epoch": 1079, "train_loss": "0.516", "train_ntokens": "260689", "train_nsentences": "1750.04", "train_wps": "72099.6", "train_ups": "0.28", "train_wpb": "260690", "train_bsz": "1750", "train_num_updates": "51768", "train_lr": "0.000473141", "train_gnorm": "0.396", "train_loss_scale": "2", "train_train_wall": "84", "train_gb_free": "40.5", "train_wall": "7747"}
[2024-10-09 03:36:16,406][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:36:16,435][fairseq.trainer][INFO] - begin training epoch 1080
[2024-10-09 03:36:16,435][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:38:46,576][train_inner][INFO] - {"epoch": 1080, "update": 1079.667, "loss": "0.515", "ntokens": "260589", "nsentences": "1742.81", "wps": "73437", "ups": "0.28", "wpb": "260589", "bsz": "1742.8", "num_updates": "51800", "lr": "0.000473098", "gnorm": "0.392", "loss_scale": "2", "train_wall": "348", "gb_free": "39.4", "wall": "7898"}
[2024-10-09 03:39:01,344][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1080 @ 51816 updates
[2024-10-09 03:39:01,345][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 03:39:05,153][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 03:39:05,155][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1080 @ 51816 updates, score None) (writing took 3.8115500286221504 seconds)
[2024-10-09 03:39:05,156][fairseq_cli.train][INFO] - end of epoch 1080 (average epoch stats below)
[2024-10-09 03:39:05,158][train][INFO] - {"epoch": 1080, "train_loss": "0.516", "train_ntokens": "260444", "train_nsentences": "1750.04", "train_wps": "74002.2", "train_ups": "0.28", "train_wpb": "260444", "train_bsz": "1750", "train_num_updates": "51816", "train_lr": "0.000473076", "train_gnorm": "0.378", "train_loss_scale": "2", "train_train_wall": "80", "train_gb_free": "39.8", "train_wall": "7916"}
[2024-10-09 03:39:05,209][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:39:05,213][fairseq.trainer][INFO] - begin training epoch 1081
[2024-10-09 03:39:05,213][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:41:48,268][fairseq_cli.train][INFO] - end of epoch 1081 (average epoch stats below)
[2024-10-09 03:41:48,276][train][INFO] - {"epoch": 1081, "train_loss": "0.52", "train_ntokens": "260341", "train_nsentences": "1750.04", "train_wps": "76611", "train_ups": "0.29", "train_wpb": "260341", "train_bsz": "1750", "train_num_updates": "51864", "train_lr": "0.000473011", "train_gnorm": "0.414", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.2", "train_wall": "8079"}
[2024-10-09 03:41:48,464][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:41:48,477][fairseq.trainer][INFO] - begin training epoch 1082
[2024-10-09 03:41:48,478][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:44:23,172][fairseq_cli.train][INFO] - end of epoch 1082 (average epoch stats below)
[2024-10-09 03:44:23,188][train][INFO] - {"epoch": 1082, "train_loss": "0.509", "train_ntokens": "260840", "train_nsentences": "1750.04", "train_wps": "80823.6", "train_ups": "0.31", "train_wpb": "260840", "train_bsz": "1750", "train_num_updates": "51912", "train_lr": "0.000472946", "train_gnorm": "0.366", "train_loss_scale": "2", "train_train_wall": "77", "train_gb_free": "39.9", "train_wall": "8234"}
[2024-10-09 03:44:23,376][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:44:23,406][fairseq.trainer][INFO] - begin training epoch 1083
[2024-10-09 03:44:23,407][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:47:05,286][fairseq_cli.train][INFO] - end of epoch 1083 (average epoch stats below)
[2024-10-09 03:47:05,298][train][INFO] - {"epoch": 1083, "train_loss": "0.51", "train_ntokens": "260400", "train_nsentences": "1750.04", "train_wps": "77105.3", "train_ups": "0.3", "train_wpb": "260400", "train_bsz": "1750", "train_num_updates": "51960", "train_lr": "0.00047288", "train_gnorm": "0.381", "train_loss_scale": "4", "train_train_wall": "85", "train_gb_free": "39.6", "train_wall": "8396"}
[2024-10-09 03:47:05,448][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:47:05,466][fairseq.trainer][INFO] - begin training epoch 1084
[2024-10-09 03:47:05,466][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:49:26,503][train_inner][INFO] - {"epoch": 1084, "update": 1083.833, "loss": "0.513", "ntokens": "260457", "nsentences": "1755.96", "wps": "81405", "ups": "0.31", "wpb": "260457", "bsz": "1756", "num_updates": "52000", "lr": "0.000472826", "gnorm": "0.385", "loss_scale": "4", "train_wall": "295", "gb_free": "40.2", "wall": "8537"}
[2024-10-09 03:49:29,075][fairseq_cli.train][INFO] - end of epoch 1084 (average epoch stats below)
[2024-10-09 03:49:29,081][train][INFO] - {"epoch": 1084, "train_loss": "0.512", "train_ntokens": "260264", "train_nsentences": "1750.04", "train_wps": "86891.2", "train_ups": "0.33", "train_wpb": "260264", "train_bsz": "1750", "train_num_updates": "52008", "train_lr": "0.000472815", "train_gnorm": "0.381", "train_loss_scale": "4", "train_train_wall": "69", "train_gb_free": "39.8", "train_wall": "8540"}
[2024-10-09 03:49:29,218][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:49:29,230][fairseq.trainer][INFO] - begin training epoch 1085
[2024-10-09 03:49:29,231][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:52:29,441][fairseq_cli.train][INFO] - end of epoch 1085 (average epoch stats below)
[2024-10-09 03:52:29,456][train][INFO] - {"epoch": 1085, "train_loss": "0.518", "train_ntokens": "260491", "train_nsentences": "1750.04", "train_wps": "69321.3", "train_ups": "0.27", "train_wpb": "260491", "train_bsz": "1750", "train_num_updates": "52056", "train_lr": "0.00047275", "train_gnorm": "0.373", "train_loss_scale": "4", "train_train_wall": "45", "train_gb_free": "39.6", "train_wall": "8720"}
[2024-10-09 03:52:29,643][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:52:29,648][fairseq.trainer][INFO] - begin training epoch 1086
[2024-10-09 03:52:29,648][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:55:14,118][fairseq_cli.train][INFO] - end of epoch 1086 (average epoch stats below)
[2024-10-09 03:55:14,122][train][INFO] - {"epoch": 1086, "train_loss": "0.514", "train_ntokens": "260512", "train_nsentences": "1750.04", "train_wps": "75940.6", "train_ups": "0.29", "train_wpb": "260512", "train_bsz": "1750", "train_num_updates": "52104", "train_lr": "0.000472685", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "75", "train_gb_free": "40.2", "train_wall": "8885"}
[2024-10-09 03:55:14,232][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:55:14,248][fairseq.trainer][INFO] - begin training epoch 1087
[2024-10-09 03:55:14,249][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 03:58:06,222][fairseq_cli.train][INFO] - end of epoch 1087 (average epoch stats below)
[2024-10-09 03:58:06,227][train][INFO] - {"epoch": 1087, "train_loss": "0.513", "train_ntokens": "260791", "train_nsentences": "1750.04", "train_wps": "72735.9", "train_ups": "0.28", "train_wpb": "260791", "train_bsz": "1750", "train_num_updates": "52152", "train_lr": "0.00047262", "train_gnorm": "0.392", "train_loss_scale": "4", "train_train_wall": "89", "train_gb_free": "39.8", "train_wall": "9057"}
[2024-10-09 03:58:06,379][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 03:58:06,397][fairseq.trainer][INFO] - begin training epoch 1088
[2024-10-09 03:58:06,397][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:00:20,006][train_inner][INFO] - {"epoch": 1088, "update": 1088.0, "loss": "0.513", "ntokens": "260619", "nsentences": "1749.49", "wps": "79761.8", "ups": "0.31", "wpb": "260619", "bsz": "1749.5", "num_updates": "52200", "lr": "0.000472554", "gnorm": "0.372", "loss_scale": "4", "train_wall": "266", "gb_free": "39.6", "wall": "9191"}
[2024-10-09 04:00:20,017][fairseq_cli.train][INFO] - end of epoch 1088 (average epoch stats below)
[2024-10-09 04:00:20,021][train][INFO] - {"epoch": 1088, "train_loss": "0.51", "train_ntokens": "260839", "train_nsentences": "1750.04", "train_wps": "93580.8", "train_ups": "0.36", "train_wpb": "260839", "train_bsz": "1750", "train_num_updates": "52200", "train_lr": "0.000472554", "train_gnorm": "0.359", "train_loss_scale": "4", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "9191"}
[2024-10-09 04:00:20,126][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:00:20,132][fairseq.trainer][INFO] - begin training epoch 1089
[2024-10-09 04:00:20,133][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:02:25,296][fairseq_cli.train][INFO] - end of epoch 1089 (average epoch stats below)
[2024-10-09 04:02:25,299][train][INFO] - {"epoch": 1089, "train_loss": "0.509", "train_ntokens": "260823", "train_nsentences": "1750.04", "train_wps": "99936.2", "train_ups": "0.38", "train_wpb": "260823", "train_bsz": "1750", "train_num_updates": "52248", "train_lr": "0.000472489", "train_gnorm": "0.396", "train_loss_scale": "4", "train_train_wall": "49", "train_gb_free": "39.9", "train_wall": "9316"}
[2024-10-09 04:02:25,385][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:02:25,404][fairseq.trainer][INFO] - begin training epoch 1090
[2024-10-09 04:02:25,405][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:04:31,177][fairseq_cli.train][INFO] - end of epoch 1090 (average epoch stats below)
[2024-10-09 04:04:31,180][train][INFO] - {"epoch": 1090, "train_loss": "0.516", "train_ntokens": "260887", "train_nsentences": "1750.04", "train_wps": "99481.4", "train_ups": "0.38", "train_wpb": "260887", "train_bsz": "1750", "train_num_updates": "52296", "train_lr": "0.000472424", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "39.6", "train_wall": "9442"}
[2024-10-09 04:04:31,233][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:04:31,238][fairseq.trainer][INFO] - begin training epoch 1091
[2024-10-09 04:04:31,238][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:06:39,790][fairseq_cli.train][INFO] - end of epoch 1091 (average epoch stats below)
[2024-10-09 04:06:39,797][train][INFO] - {"epoch": 1091, "train_loss": "0.518", "train_ntokens": "260970", "train_nsentences": "1750.04", "train_wps": "97398.6", "train_ups": "0.37", "train_wpb": "260970", "train_bsz": "1750", "train_num_updates": "52344", "train_lr": "0.000472359", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "54", "train_gb_free": "39.8", "train_wall": "9571"}
[2024-10-09 04:06:39,857][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:06:39,860][fairseq.trainer][INFO] - begin training epoch 1092
[2024-10-09 04:06:39,861][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:09:53,602][fairseq_cli.train][INFO] - end of epoch 1092 (average epoch stats below)
[2024-10-09 04:09:53,629][train][INFO] - {"epoch": 1092, "train_loss": "0.519", "train_ntokens": "260818", "train_nsentences": "1750.04", "train_wps": "64590.3", "train_ups": "0.25", "train_wpb": "260818", "train_bsz": "1750", "train_num_updates": "52392", "train_lr": "0.000472293", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "24", "train_gb_free": "39.6", "train_wall": "9765"}
[2024-10-09 04:09:53,877][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:09:53,885][fairseq.trainer][INFO] - begin training epoch 1093
[2024-10-09 04:09:53,885][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:13:43,402][train_inner][INFO] - {"epoch": 1093, "update": 1092.167, "loss": "0.516", "ntokens": "260943", "nsentences": "1748.94", "wps": "64961.1", "ups": "0.25", "wpb": "260943", "bsz": "1748.9", "num_updates": "52400", "lr": "0.000472283", "gnorm": "0.382", "loss_scale": "4", "train_wall": "301", "gb_free": "40.3", "wall": "9994"}
[2024-10-09 04:14:31,284][fairseq_cli.train][INFO] - end of epoch 1093 (average epoch stats below)
[2024-10-09 04:14:31,288][train][INFO] - {"epoch": 1093, "train_loss": "0.514", "train_ntokens": "260900", "train_nsentences": "1750.04", "train_wps": "45103.4", "train_ups": "0.17", "train_wpb": "260900", "train_bsz": "1750", "train_num_updates": "52440", "train_lr": "0.000472228", "train_gnorm": "0.403", "train_loss_scale": "4", "train_train_wall": "164", "train_gb_free": "39.7", "train_wall": "10042"}
[2024-10-09 04:14:31,504][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:14:31,528][fairseq.trainer][INFO] - begin training epoch 1094
[2024-10-09 04:14:31,528][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:20:46,157][fairseq_cli.train][INFO] - end of epoch 1094 (average epoch stats below)
[2024-10-09 04:20:46,165][train][INFO] - {"epoch": 1094, "train_loss": "0.518", "train_ntokens": "261096", "train_nsentences": "1750.04", "train_wps": "33431.6", "train_ups": "0.13", "train_wpb": "261096", "train_bsz": "1750", "train_num_updates": "52488", "train_lr": "0.000472163", "train_gnorm": "0.368", "train_loss_scale": "4", "train_train_wall": "179", "train_gb_free": "40.1", "train_wall": "10417"}
[2024-10-09 04:20:46,575][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:20:46,610][fairseq.trainer][INFO] - begin training epoch 1095
[2024-10-09 04:20:46,611][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:26:30,637][fairseq_cli.train][INFO] - end of epoch 1095 (average epoch stats below)
[2024-10-09 04:26:30,664][train][INFO] - {"epoch": 1095, "train_loss": "0.509", "train_ntokens": "260947", "train_nsentences": "1750.04", "train_wps": "36358.9", "train_ups": "0.14", "train_wpb": "260947", "train_bsz": "1750", "train_num_updates": "52536", "train_lr": "0.000472098", "train_gnorm": "0.373", "train_loss_scale": "4", "train_train_wall": "177", "train_gb_free": "39.7", "train_wall": "10762"}
[2024-10-09 04:26:30,935][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:26:30,956][fairseq.trainer][INFO] - begin training epoch 1096
[2024-10-09 04:26:30,957][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:30:08,661][fairseq_cli.train][INFO] - end of epoch 1096 (average epoch stats below)
[2024-10-09 04:30:08,679][train][INFO] - {"epoch": 1096, "train_loss": "0.507", "train_ntokens": "260776", "train_nsentences": "1750.04", "train_wps": "57418.4", "train_ups": "0.22", "train_wpb": "260776", "train_bsz": "1750", "train_num_updates": "52584", "train_lr": "0.000472033", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "29", "train_gb_free": "39.3", "train_wall": "10980"}
[2024-10-09 04:30:08,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:30:09,008][fairseq.trainer][INFO] - begin training epoch 1097
[2024-10-09 04:30:09,009][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:33:23,300][train_inner][INFO] - {"epoch": 1097, "update": 1096.333, "loss": "0.511", "ntokens": "260991", "nsentences": "1747.19", "wps": "44244.5", "ups": "0.17", "wpb": "260991", "bsz": "1747.2", "num_updates": "52600", "lr": "0.000472011", "gnorm": "0.378", "loss_scale": "4", "train_wall": "467", "gb_free": "39.8", "wall": "11174"}
[2024-10-09 04:33:44,463][fairseq_cli.train][INFO] - end of epoch 1097 (average epoch stats below)
[2024-10-09 04:33:44,465][train][INFO] - {"epoch": 1097, "train_loss": "0.513", "train_ntokens": "260568", "train_nsentences": "1750.04", "train_wps": "57962.3", "train_ups": "0.22", "train_wpb": "260568", "train_bsz": "1750", "train_num_updates": "52632", "train_lr": "0.000471967", "train_gnorm": "0.373", "train_loss_scale": "4", "train_train_wall": "55", "train_gb_free": "40.2", "train_wall": "11195"}
[2024-10-09 04:33:44,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:33:44,783][fairseq.trainer][INFO] - begin training epoch 1098
[2024-10-09 04:33:44,784][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:37:22,408][fairseq_cli.train][INFO] - end of epoch 1098 (average epoch stats below)
[2024-10-09 04:37:22,413][train][INFO] - {"epoch": 1098, "train_loss": "0.518", "train_ntokens": "260708", "train_nsentences": "1750.04", "train_wps": "57418", "train_ups": "0.22", "train_wpb": "260708", "train_bsz": "1750", "train_num_updates": "52680", "train_lr": "0.000471902", "train_gnorm": "0.398", "train_loss_scale": "4", "train_train_wall": "114", "train_gb_free": "40", "train_wall": "11413"}
[2024-10-09 04:37:22,676][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:37:22,701][fairseq.trainer][INFO] - begin training epoch 1099
[2024-10-09 04:37:22,701][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:41:04,828][fairseq_cli.train][INFO] - end of epoch 1099 (average epoch stats below)
[2024-10-09 04:41:04,837][train][INFO] - {"epoch": 1099, "train_loss": "0.52", "train_ntokens": "260978", "train_nsentences": "1750.04", "train_wps": "56321.2", "train_ups": "0.22", "train_wpb": "260978", "train_bsz": "1750", "train_num_updates": "52728", "train_lr": "0.000471837", "train_gnorm": "0.422", "train_loss_scale": "4", "train_train_wall": "128", "train_gb_free": "39.8", "train_wall": "11636"}
[2024-10-09 04:41:05,029][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:41:05,049][fairseq.trainer][INFO] - begin training epoch 1100
[2024-10-09 04:41:05,050][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:44:37,890][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1100 @ 52776 updates
[2024-10-09 04:44:37,893][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 04:44:42,191][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 04:44:42,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1100 @ 52776 updates, score None) (writing took 4.302804132923484 seconds)
[2024-10-09 04:44:42,193][fairseq_cli.train][INFO] - end of epoch 1100 (average epoch stats below)
[2024-10-09 04:44:42,196][train][INFO] - {"epoch": 1100, "train_loss": "0.509", "train_ntokens": "260303", "train_nsentences": "1750.04", "train_wps": "57484.4", "train_ups": "0.22", "train_wpb": "260303", "train_bsz": "1750", "train_num_updates": "52776", "train_lr": "0.000471772", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "76", "train_gb_free": "39.6", "train_wall": "11853"}
[2024-10-09 04:44:42,340][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:44:42,367][fairseq.trainer][INFO] - begin training epoch 1101
[2024-10-09 04:44:42,367][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:49:11,213][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2024-10-09 04:49:12,809][train_inner][INFO] - {"epoch": 1101, "update": 1100.521, "loss": "0.516", "ntokens": "260446", "nsentences": "1751.98", "wps": "54859.6", "ups": "0.21", "wpb": "260446", "bsz": "1752", "num_updates": "52800", "lr": "0.000471739", "gnorm": "0.396", "loss_scale": "2", "train_wall": "401", "gb_free": "39.6", "wall": "12124"}
[2024-10-09 04:49:35,548][fairseq_cli.train][INFO] - end of epoch 1101 (average epoch stats below)
[2024-10-09 04:49:35,552][train][INFO] - {"epoch": 1101, "train_loss": "0.518", "train_ntokens": "261086", "train_nsentences": "1741.62", "train_wps": "41830.4", "train_ups": "0.16", "train_wpb": "261086", "train_bsz": "1741.6", "train_num_updates": "52823", "train_lr": "0.000471708", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "85", "train_gb_free": "39.6", "train_wall": "12147"}
[2024-10-09 04:49:35,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:49:35,770][fairseq.trainer][INFO] - begin training epoch 1102
[2024-10-09 04:49:35,770][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:52:01,044][fairseq_cli.train][INFO] - end of epoch 1102 (average epoch stats below)
[2024-10-09 04:52:01,064][train][INFO] - {"epoch": 1102, "train_loss": "0.511", "train_ntokens": "260488", "train_nsentences": "1750.04", "train_wps": "85933.2", "train_ups": "0.33", "train_wpb": "260488", "train_bsz": "1750", "train_num_updates": "52871", "train_lr": "0.000471643", "train_gnorm": "0.401", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40", "train_wall": "12292"}
[2024-10-09 04:52:01,259][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:52:01,283][fairseq.trainer][INFO] - begin training epoch 1103
[2024-10-09 04:52:01,283][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:54:50,729][fairseq_cli.train][INFO] - end of epoch 1103 (average epoch stats below)
[2024-10-09 04:54:50,734][train][INFO] - {"epoch": 1103, "train_loss": "0.512", "train_ntokens": "261340", "train_nsentences": "1750.04", "train_wps": "73934.8", "train_ups": "0.28", "train_wpb": "261340", "train_bsz": "1750", "train_num_updates": "52919", "train_lr": "0.000471577", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "76", "train_gb_free": "39.7", "train_wall": "12462"}
[2024-10-09 04:54:50,872][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:54:50,889][fairseq.trainer][INFO] - begin training epoch 1104
[2024-10-09 04:54:50,889][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:57:26,776][fairseq_cli.train][INFO] - end of epoch 1104 (average epoch stats below)
[2024-10-09 04:57:26,784][train][INFO] - {"epoch": 1104, "train_loss": "0.518", "train_ntokens": "261026", "train_nsentences": "1750.04", "train_wps": "80291.6", "train_ups": "0.31", "train_wpb": "261026", "train_bsz": "1750", "train_num_updates": "52967", "train_lr": "0.000471512", "train_gnorm": "0.361", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "12618"}
[2024-10-09 04:57:26,963][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:57:26,973][fairseq.trainer][INFO] - begin training epoch 1105
[2024-10-09 04:57:26,974][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 04:59:37,221][train_inner][INFO] - {"epoch": 1105, "update": 1104.688, "loss": "0.514", "ntokens": "260892", "nsentences": "1753.06", "wps": "83565.9", "ups": "0.32", "wpb": "260892", "bsz": "1753.1", "num_updates": "53000", "lr": "0.000471467", "gnorm": "0.377", "loss_scale": "2", "train_wall": "253", "gb_free": "39.6", "wall": "12748"}
[2024-10-09 04:59:49,677][fairseq_cli.train][INFO] - end of epoch 1105 (average epoch stats below)
[2024-10-09 04:59:49,679][train][INFO] - {"epoch": 1105, "train_loss": "0.511", "train_ntokens": "260609", "train_nsentences": "1750.04", "train_wps": "87543.4", "train_ups": "0.34", "train_wpb": "260609", "train_bsz": "1750", "train_num_updates": "53015", "train_lr": "0.000471447", "train_gnorm": "0.374", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "41.5", "train_wall": "12761"}
[2024-10-09 04:59:49,844][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 04:59:49,873][fairseq.trainer][INFO] - begin training epoch 1106
[2024-10-09 04:59:49,873][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:02:20,956][fairseq_cli.train][INFO] - end of epoch 1106 (average epoch stats below)
[2024-10-09 05:02:20,962][train][INFO] - {"epoch": 1106, "train_loss": "0.51", "train_ntokens": "260488", "train_nsentences": "1750.04", "train_wps": "82650.8", "train_ups": "0.32", "train_wpb": "260488", "train_bsz": "1750", "train_num_updates": "53063", "train_lr": "0.000471382", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "39.7", "train_wall": "12912"}
[2024-10-09 05:02:21,032][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:02:21,047][fairseq.trainer][INFO] - begin training epoch 1107
[2024-10-09 05:02:21,048][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:04:49,040][fairseq_cli.train][INFO] - end of epoch 1107 (average epoch stats below)
[2024-10-09 05:04:49,044][train][INFO] - {"epoch": 1107, "train_loss": "0.5", "train_ntokens": "260629", "train_nsentences": "1750.04", "train_wps": "84482.8", "train_ups": "0.32", "train_wpb": "260629", "train_bsz": "1750", "train_num_updates": "53111", "train_lr": "0.000471317", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "75", "train_gb_free": "39.3", "train_wall": "13060"}
[2024-10-09 05:04:49,141][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:04:49,163][fairseq.trainer][INFO] - begin training epoch 1108
[2024-10-09 05:04:49,163][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:07:04,222][fairseq_cli.train][INFO] - end of epoch 1108 (average epoch stats below)
[2024-10-09 05:07:04,228][train][INFO] - {"epoch": 1108, "train_loss": "0.513", "train_ntokens": "260184", "train_nsentences": "1750.04", "train_wps": "92386.1", "train_ups": "0.36", "train_wpb": "260184", "train_bsz": "1750", "train_num_updates": "53159", "train_lr": "0.000471251", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "26", "train_gb_free": "39.6", "train_wall": "13195"}
[2024-10-09 05:07:04,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:07:04,388][fairseq.trainer][INFO] - begin training epoch 1109
[2024-10-09 05:07:04,388][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:09:14,147][train_inner][INFO] - {"epoch": 1109, "update": 1108.854, "loss": "0.507", "ntokens": "260640", "nsentences": "1739.43", "wps": "90358", "ups": "0.35", "wpb": "260640", "bsz": "1739.4", "num_updates": "53200", "lr": "0.000471196", "gnorm": "0.386", "loss_scale": "2", "train_wall": "232", "gb_free": "40.1", "wall": "13325"}
[2024-10-09 05:09:19,236][fairseq_cli.train][INFO] - end of epoch 1109 (average epoch stats below)
[2024-10-09 05:09:19,239][train][INFO] - {"epoch": 1109, "train_loss": "0.504", "train_ntokens": "260672", "train_nsentences": "1750.04", "train_wps": "92678.3", "train_ups": "0.36", "train_wpb": "260672", "train_bsz": "1750", "train_num_updates": "53207", "train_lr": "0.000471186", "train_gnorm": "0.388", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.2", "train_wall": "13330"}
[2024-10-09 05:09:19,395][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:09:19,406][fairseq.trainer][INFO] - begin training epoch 1110
[2024-10-09 05:09:19,406][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:11:32,835][fairseq_cli.train][INFO] - end of epoch 1110 (average epoch stats below)
[2024-10-09 05:11:32,860][train][INFO] - {"epoch": 1110, "train_loss": "0.514", "train_ntokens": "260718", "train_nsentences": "1750.04", "train_wps": "93658.5", "train_ups": "0.36", "train_wpb": "260718", "train_bsz": "1750", "train_num_updates": "53255", "train_lr": "0.000471121", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "49", "train_gb_free": "39.7", "train_wall": "13464"}
[2024-10-09 05:11:33,045][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:11:33,055][fairseq.trainer][INFO] - begin training epoch 1111
[2024-10-09 05:11:33,055][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:13:46,570][fairseq_cli.train][INFO] - end of epoch 1111 (average epoch stats below)
[2024-10-09 05:13:46,575][train][INFO] - {"epoch": 1111, "train_loss": "0.506", "train_ntokens": "260997", "train_nsentences": "1750.04", "train_wps": "93693.3", "train_ups": "0.36", "train_wpb": "260996", "train_bsz": "1750", "train_num_updates": "53303", "train_lr": "0.000471056", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "56", "train_gb_free": "39.3", "train_wall": "13598"}
[2024-10-09 05:13:46,739][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:13:46,757][fairseq.trainer][INFO] - begin training epoch 1112
[2024-10-09 05:13:46,757][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:15:56,345][fairseq_cli.train][INFO] - end of epoch 1112 (average epoch stats below)
[2024-10-09 05:15:56,348][train][INFO] - {"epoch": 1112, "train_loss": "0.513", "train_ntokens": "260460", "train_nsentences": "1750.04", "train_wps": "96339.7", "train_ups": "0.37", "train_wpb": "260460", "train_bsz": "1750", "train_num_updates": "53351", "train_lr": "0.00047099", "train_gnorm": "0.39", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.3", "train_wall": "13727"}
[2024-10-09 05:15:56,421][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:15:56,431][fairseq.trainer][INFO] - begin training epoch 1113
[2024-10-09 05:15:56,432][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:18:02,174][fairseq_cli.train][INFO] - end of epoch 1113 (average epoch stats below)
[2024-10-09 05:18:02,178][train][INFO] - {"epoch": 1113, "train_loss": "0.513", "train_ntokens": "260987", "train_nsentences": "1750.04", "train_wps": "99561.1", "train_ups": "0.38", "train_wpb": "260987", "train_bsz": "1750", "train_num_updates": "53399", "train_lr": "0.000470925", "train_gnorm": "0.365", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.6", "train_wall": "13853"}
[2024-10-09 05:18:02,235][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:18:02,239][fairseq.trainer][INFO] - begin training epoch 1114
[2024-10-09 05:18:02,240][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:19:30,323][train_inner][INFO] - {"epoch": 1114, "update": 1113.021, "loss": "0.512", "ntokens": "260745", "nsentences": "1758.48", "wps": "84635.6", "ups": "0.32", "wpb": "260745", "bsz": "1758.5", "num_updates": "53400", "lr": "0.000470924", "gnorm": "0.385", "loss_scale": "2", "train_wall": "205", "gb_free": "40.8", "wall": "13941"}
[2024-10-09 05:20:14,129][fairseq_cli.train][INFO] - end of epoch 1114 (average epoch stats below)
[2024-10-09 05:20:14,131][train][INFO] - {"epoch": 1114, "train_loss": "0.508", "train_ntokens": "260633", "train_nsentences": "1750.04", "train_wps": "94811.4", "train_ups": "0.36", "train_wpb": "260633", "train_bsz": "1750", "train_num_updates": "53447", "train_lr": "0.00047086", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "41", "train_gb_free": "39.3", "train_wall": "13985"}
[2024-10-09 05:20:14,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:20:14,193][fairseq.trainer][INFO] - begin training epoch 1115
[2024-10-09 05:20:14,193][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:22:23,499][fairseq_cli.train][INFO] - end of epoch 1115 (average epoch stats below)
[2024-10-09 05:22:23,503][train][INFO] - {"epoch": 1115, "train_loss": "0.51", "train_ntokens": "260685", "train_nsentences": "1750.04", "train_wps": "96722.2", "train_ups": "0.37", "train_wpb": "260685", "train_bsz": "1750", "train_num_updates": "53495", "train_lr": "0.000470795", "train_gnorm": "0.377", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "39.8", "train_wall": "14114"}
[2024-10-09 05:22:23,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:22:23,641][fairseq.trainer][INFO] - begin training epoch 1116
[2024-10-09 05:22:23,641][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:24:33,140][fairseq_cli.train][INFO] - end of epoch 1116 (average epoch stats below)
[2024-10-09 05:24:33,147][train][INFO] - {"epoch": 1116, "train_loss": "0.503", "train_ntokens": "260680", "train_nsentences": "1750.04", "train_wps": "96518.1", "train_ups": "0.37", "train_wpb": "260680", "train_bsz": "1750", "train_num_updates": "53543", "train_lr": "0.00047073", "train_gnorm": "0.362", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "40.1", "train_wall": "14244"}
[2024-10-09 05:24:33,419][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:24:33,432][fairseq.trainer][INFO] - begin training epoch 1117
[2024-10-09 05:24:33,432][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:26:57,703][fairseq_cli.train][INFO] - end of epoch 1117 (average epoch stats below)
[2024-10-09 05:26:57,716][train][INFO] - {"epoch": 1117, "train_loss": "0.505", "train_ntokens": "260448", "train_nsentences": "1750.04", "train_wps": "86477.5", "train_ups": "0.33", "train_wpb": "260448", "train_bsz": "1750", "train_num_updates": "53591", "train_lr": "0.000470664", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "64", "train_gb_free": "40.2", "train_wall": "14389"}
[2024-10-09 05:26:57,838][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:26:57,845][fairseq.trainer][INFO] - begin training epoch 1118
[2024-10-09 05:26:57,845][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:28:47,988][train_inner][INFO] - {"epoch": 1118, "update": 1117.188, "loss": "0.506", "ntokens": "260640", "nsentences": "1750.12", "wps": "93476.5", "ups": "0.36", "wpb": "260640", "bsz": "1750.1", "num_updates": "53600", "lr": "0.000470652", "gnorm": "0.379", "loss_scale": "2", "train_wall": "253", "gb_free": "39.6", "wall": "14499"}
[2024-10-09 05:29:18,227][fairseq_cli.train][INFO] - end of epoch 1118 (average epoch stats below)
[2024-10-09 05:29:18,230][train][INFO] - {"epoch": 1118, "train_loss": "0.506", "train_ntokens": "260922", "train_nsentences": "1750.04", "train_wps": "89134.2", "train_ups": "0.34", "train_wpb": "260922", "train_bsz": "1750", "train_num_updates": "53639", "train_lr": "0.000470599", "train_gnorm": "0.392", "train_loss_scale": "2", "train_train_wall": "55", "train_gb_free": "39.6", "train_wall": "14529"}
[2024-10-09 05:29:18,405][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:29:18,411][fairseq.trainer][INFO] - begin training epoch 1119
[2024-10-09 05:29:18,411][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:31:47,317][fairseq_cli.train][INFO] - end of epoch 1119 (average epoch stats below)
[2024-10-09 05:31:47,323][train][INFO] - {"epoch": 1119, "train_loss": "0.504", "train_ntokens": "261111", "train_nsentences": "1750.04", "train_wps": "84065.5", "train_ups": "0.32", "train_wpb": "261111", "train_bsz": "1750", "train_num_updates": "53687", "train_lr": "0.000470534", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.3", "train_wall": "14678"}
[2024-10-09 05:31:47,445][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:31:47,455][fairseq.trainer][INFO] - begin training epoch 1120
[2024-10-09 05:31:47,455][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:34:08,461][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1120 @ 53735 updates
[2024-10-09 05:34:08,465][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 05:34:12,521][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 05:34:12,523][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1120 @ 53735 updates, score None) (writing took 4.0619603069499135 seconds)
[2024-10-09 05:34:12,523][fairseq_cli.train][INFO] - end of epoch 1120 (average epoch stats below)
[2024-10-09 05:34:12,527][train][INFO] - {"epoch": 1120, "train_loss": "0.51", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "86216.5", "train_ups": "0.33", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "53735", "train_lr": "0.000470469", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.7", "train_wall": "14823"}
[2024-10-09 05:34:12,703][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:34:12,738][fairseq.trainer][INFO] - begin training epoch 1121
[2024-10-09 05:34:12,738][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:36:27,860][fairseq_cli.train][INFO] - end of epoch 1121 (average epoch stats below)
[2024-10-09 05:36:27,870][train][INFO] - {"epoch": 1121, "train_loss": "0.51", "train_ntokens": "260655", "train_nsentences": "1750.04", "train_wps": "92445", "train_ups": "0.35", "train_wpb": "260655", "train_bsz": "1750", "train_num_updates": "53783", "train_lr": "0.000470404", "train_gnorm": "0.376", "train_loss_scale": "2", "train_train_wall": "34", "train_gb_free": "39.6", "train_wall": "14959"}
[2024-10-09 05:36:28,051][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:36:28,062][fairseq.trainer][INFO] - begin training epoch 1122
[2024-10-09 05:36:28,069][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:38:13,525][train_inner][INFO] - {"epoch": 1122, "update": 1121.354, "loss": "0.507", "ntokens": "260910", "nsentences": "1742.79", "wps": "92270.9", "ups": "0.35", "wpb": "260910", "bsz": "1742.8", "num_updates": "53800", "lr": "0.00047038", "gnorm": "0.38", "loss_scale": "2", "train_wall": "194", "gb_free": "39.7", "wall": "15064"}
[2024-10-09 05:38:42,184][fairseq_cli.train][INFO] - end of epoch 1122 (average epoch stats below)
[2024-10-09 05:38:42,195][train][INFO] - {"epoch": 1122, "train_loss": "0.504", "train_ntokens": "260848", "train_nsentences": "1750.04", "train_wps": "93219.7", "train_ups": "0.36", "train_wpb": "260848", "train_bsz": "1750", "train_num_updates": "53831", "train_lr": "0.000470338", "train_gnorm": "0.364", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.8", "train_wall": "15093"}
[2024-10-09 05:38:42,451][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:38:42,454][fairseq.trainer][INFO] - begin training epoch 1123
[2024-10-09 05:38:42,486][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:41:16,246][fairseq_cli.train][INFO] - end of epoch 1123 (average epoch stats below)
[2024-10-09 05:41:16,250][train][INFO] - {"epoch": 1123, "train_loss": "0.508", "train_ntokens": "260580", "train_nsentences": "1750.04", "train_wps": "81192.8", "train_ups": "0.31", "train_wpb": "260580", "train_bsz": "1750", "train_num_updates": "53879", "train_lr": "0.000470273", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "40.5", "train_wall": "15247"}
[2024-10-09 05:41:16,373][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:41:16,389][fairseq.trainer][INFO] - begin training epoch 1124
[2024-10-09 05:41:16,390][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:43:46,015][fairseq_cli.train][INFO] - end of epoch 1124 (average epoch stats below)
[2024-10-09 05:43:46,020][train][INFO] - {"epoch": 1124, "train_loss": "0.501", "train_ntokens": "260425", "train_nsentences": "1750.04", "train_wps": "83465.5", "train_ups": "0.32", "train_wpb": "260425", "train_bsz": "1750", "train_num_updates": "53927", "train_lr": "0.000470208", "train_gnorm": "0.383", "train_loss_scale": "2", "train_train_wall": "65", "train_gb_free": "40", "train_wall": "15397"}
[2024-10-09 05:43:46,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:43:46,182][fairseq.trainer][INFO] - begin training epoch 1125
[2024-10-09 05:43:46,183][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:46:13,044][fairseq_cli.train][INFO] - end of epoch 1125 (average epoch stats below)
[2024-10-09 05:46:13,049][train][INFO] - {"epoch": 1125, "train_loss": "0.504", "train_ntokens": "260833", "train_nsentences": "1750.04", "train_wps": "85154.9", "train_ups": "0.33", "train_wpb": "260833", "train_bsz": "1750", "train_num_updates": "53975", "train_lr": "0.000470143", "train_gnorm": "0.372", "train_loss_scale": "2", "train_train_wall": "59", "train_gb_free": "39.6", "train_wall": "15544"}
[2024-10-09 05:46:13,239][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:46:13,247][fairseq.trainer][INFO] - begin training epoch 1126
[2024-10-09 05:46:13,247][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:48:07,904][train_inner][INFO] - {"epoch": 1126, "update": 1125.521, "loss": "0.505", "ntokens": "260674", "nsentences": "1757.53", "wps": "87714.9", "ups": "0.34", "wpb": "260674", "bsz": "1757.5", "num_updates": "54000", "lr": "0.000470109", "gnorm": "0.376", "loss_scale": "2", "train_wall": "241", "gb_free": "39.8", "wall": "15659"}
[2024-10-09 05:48:25,469][fairseq_cli.train][INFO] - end of epoch 1126 (average epoch stats below)
[2024-10-09 05:48:25,487][train][INFO] - {"epoch": 1126, "train_loss": "0.508", "train_ntokens": "260316", "train_nsentences": "1750.04", "train_wps": "94360.1", "train_ups": "0.36", "train_wpb": "260316", "train_bsz": "1750", "train_num_updates": "54023", "train_lr": "0.000470077", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "40", "train_gb_free": "39.8", "train_wall": "15676"}
[2024-10-09 05:48:25,628][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:48:25,633][fairseq.trainer][INFO] - begin training epoch 1127
[2024-10-09 05:48:25,634][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:50:32,737][fairseq_cli.train][INFO] - end of epoch 1127 (average epoch stats below)
[2024-10-09 05:50:32,741][train][INFO] - {"epoch": 1127, "train_loss": "0.506", "train_ntokens": "260745", "train_nsentences": "1750.04", "train_wps": "98355.1", "train_ups": "0.38", "train_wpb": "260745", "train_bsz": "1750", "train_num_updates": "54071", "train_lr": "0.000470012", "train_gnorm": "0.407", "train_loss_scale": "2", "train_train_wall": "38", "train_gb_free": "39.2", "train_wall": "15804"}
[2024-10-09 05:50:32,878][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:50:32,896][fairseq.trainer][INFO] - begin training epoch 1128
[2024-10-09 05:50:32,896][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:52:40,564][fairseq_cli.train][INFO] - end of epoch 1128 (average epoch stats below)
[2024-10-09 05:52:40,573][train][INFO] - {"epoch": 1128, "train_loss": "0.509", "train_ntokens": "260584", "train_nsentences": "1750.04", "train_wps": "97849.9", "train_ups": "0.38", "train_wpb": "260584", "train_bsz": "1750", "train_num_updates": "54119", "train_lr": "0.000469947", "train_gnorm": "0.387", "train_loss_scale": "2", "train_train_wall": "51", "train_gb_free": "40", "train_wall": "15932"}
[2024-10-09 05:52:40,756][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:52:40,762][fairseq.trainer][INFO] - begin training epoch 1129
[2024-10-09 05:52:40,762][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:54:59,395][fairseq_cli.train][INFO] - end of epoch 1129 (average epoch stats below)
[2024-10-09 05:54:59,407][train][INFO] - {"epoch": 1129, "train_loss": "0.506", "train_ntokens": "260677", "train_nsentences": "1750.04", "train_wps": "90130", "train_ups": "0.35", "train_wpb": "260677", "train_bsz": "1750", "train_num_updates": "54167", "train_lr": "0.000469882", "train_gnorm": "0.366", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.4", "train_wall": "16070"}
[2024-10-09 05:54:59,529][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:54:59,539][fairseq.trainer][INFO] - begin training epoch 1130
[2024-10-09 05:54:59,540][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:57:02,246][train_inner][INFO] - {"epoch": 1130, "update": 1129.688, "loss": "0.508", "ntokens": "260574", "nsentences": "1752.15", "wps": "97532.2", "ups": "0.37", "wpb": "260574", "bsz": "1752.2", "num_updates": "54200", "lr": "0.000469837", "gnorm": "0.378", "loss_scale": "2", "train_wall": "187", "gb_free": "39.5", "wall": "16193"}
[2024-10-09 05:57:15,933][fairseq_cli.train][INFO] - end of epoch 1130 (average epoch stats below)
[2024-10-09 05:57:15,943][train][INFO] - {"epoch": 1130, "train_loss": "0.505", "train_ntokens": "260669", "train_nsentences": "1750.04", "train_wps": "91646.5", "train_ups": "0.35", "train_wpb": "260669", "train_bsz": "1750", "train_num_updates": "54215", "train_lr": "0.000469817", "train_gnorm": "0.363", "train_loss_scale": "2", "train_train_wall": "35", "train_gb_free": "39.6", "train_wall": "16207"}
[2024-10-09 05:57:16,084][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:57:16,089][fairseq.trainer][INFO] - begin training epoch 1131
[2024-10-09 05:57:16,089][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 05:59:34,737][fairseq_cli.train][INFO] - end of epoch 1131 (average epoch stats below)
[2024-10-09 05:59:34,749][train][INFO] - {"epoch": 1131, "train_loss": "0.497", "train_ntokens": "260713", "train_nsentences": "1750.04", "train_wps": "90158.7", "train_ups": "0.35", "train_wpb": "260713", "train_bsz": "1750", "train_num_updates": "54263", "train_lr": "0.000469751", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "16346"}
[2024-10-09 05:59:34,882][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 05:59:34,907][fairseq.trainer][INFO] - begin training epoch 1132
[2024-10-09 05:59:34,908][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:01:57,818][fairseq_cli.train][INFO] - end of epoch 1132 (average epoch stats below)
[2024-10-09 06:01:57,822][train][INFO] - {"epoch": 1132, "train_loss": "0.506", "train_ntokens": "260957", "train_nsentences": "1750.04", "train_wps": "87551.8", "train_ups": "0.34", "train_wpb": "260958", "train_bsz": "1750", "train_num_updates": "54311", "train_lr": "0.000469686", "train_gnorm": "0.38", "train_loss_scale": "2", "train_train_wall": "69", "train_gb_free": "40.1", "train_wall": "16489"}
[2024-10-09 06:01:57,993][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:01:58,013][fairseq.trainer][INFO] - begin training epoch 1133
[2024-10-09 06:01:58,014][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:04:21,725][fairseq_cli.train][INFO] - end of epoch 1133 (average epoch stats below)
[2024-10-09 06:04:21,744][train][INFO] - {"epoch": 1133, "train_loss": "0.502", "train_ntokens": "260802", "train_nsentences": "1750.04", "train_wps": "86983.1", "train_ups": "0.33", "train_wpb": "260802", "train_bsz": "1750", "train_num_updates": "54359", "train_lr": "0.000469621", "train_gnorm": "0.37", "train_loss_scale": "2", "train_train_wall": "57", "train_gb_free": "39.3", "train_wall": "16633"}
[2024-10-09 06:04:21,868][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:04:21,883][fairseq.trainer][INFO] - begin training epoch 1134
[2024-10-09 06:04:21,883][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:07:07,667][train_inner][INFO] - {"epoch": 1134, "update": 1133.854, "loss": "0.501", "ntokens": "260738", "nsentences": "1737.46", "wps": "86136.8", "ups": "0.33", "wpb": "260738", "bsz": "1737.5", "num_updates": "54400", "lr": "0.000469565", "gnorm": "0.383", "loss_scale": "2", "train_wall": "276", "gb_free": "42", "wall": "16799"}
[2024-10-09 06:07:09,588][fairseq_cli.train][INFO] - end of epoch 1134 (average epoch stats below)
[2024-10-09 06:07:09,590][train][INFO] - {"epoch": 1134, "train_loss": "0.499", "train_ntokens": "260673", "train_nsentences": "1750.04", "train_wps": "74547.9", "train_ups": "0.29", "train_wpb": "260673", "train_bsz": "1750", "train_num_updates": "54407", "train_lr": "0.000469556", "train_gnorm": "0.393", "train_loss_scale": "2", "train_train_wall": "82", "train_gb_free": "39.6", "train_wall": "16801"}
[2024-10-09 06:07:09,770][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:07:09,776][fairseq.trainer][INFO] - begin training epoch 1135
[2024-10-09 06:07:09,777][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:09:36,213][fairseq_cli.train][INFO] - end of epoch 1135 (average epoch stats below)
[2024-10-09 06:09:36,247][train][INFO] - {"epoch": 1135, "train_loss": "0.5", "train_ntokens": "260232", "train_nsentences": "1750.04", "train_wps": "85182.9", "train_ups": "0.33", "train_wpb": "260232", "train_bsz": "1750", "train_num_updates": "54455", "train_lr": "0.00046949", "train_gnorm": "0.389", "train_loss_scale": "2", "train_train_wall": "67", "train_gb_free": "40.1", "train_wall": "16947"}
[2024-10-09 06:09:36,389][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:09:36,402][fairseq.trainer][INFO] - begin training epoch 1136
[2024-10-09 06:09:36,403][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:12:09,466][fairseq_cli.train][INFO] - end of epoch 1136 (average epoch stats below)
[2024-10-09 06:12:09,469][train][INFO] - {"epoch": 1136, "train_loss": "0.51", "train_ntokens": "261220", "train_nsentences": "1750.04", "train_wps": "81834.4", "train_ups": "0.31", "train_wpb": "261220", "train_bsz": "1750", "train_num_updates": "54503", "train_lr": "0.000469425", "train_gnorm": "0.357", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "40.6", "train_wall": "17100"}
[2024-10-09 06:12:09,561][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:12:09,579][fairseq.trainer][INFO] - begin training epoch 1137
[2024-10-09 06:12:09,580][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:14:19,350][fairseq_cli.train][INFO] - end of epoch 1137 (average epoch stats below)
[2024-10-09 06:14:19,353][train][INFO] - {"epoch": 1137, "train_loss": "0.507", "train_ntokens": "260619", "train_nsentences": "1750.04", "train_wps": "96317.1", "train_ups": "0.37", "train_wpb": "260619", "train_bsz": "1750", "train_num_updates": "54551", "train_lr": "0.00046936", "train_gnorm": "0.375", "train_loss_scale": "2", "train_train_wall": "47", "train_gb_free": "39.6", "train_wall": "17230"}
[2024-10-09 06:14:19,452][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:14:19,537][fairseq.trainer][INFO] - begin training epoch 1138
[2024-10-09 06:14:19,537][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:16:30,501][fairseq_cli.train][INFO] - end of epoch 1138 (average epoch stats below)
[2024-10-09 06:16:30,504][train][INFO] - {"epoch": 1138, "train_loss": "0.505", "train_ntokens": "260661", "train_nsentences": "1750.04", "train_wps": "95403.4", "train_ups": "0.37", "train_wpb": "260661", "train_bsz": "1750", "train_num_updates": "54599", "train_lr": "0.000469295", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "60", "train_gb_free": "39.3", "train_wall": "17361"}
[2024-10-09 06:16:30,558][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:16:30,563][fairseq.trainer][INFO] - begin training epoch 1139
[2024-10-09 06:16:30,563][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:18:02,390][train_inner][INFO] - {"epoch": 1139, "update": 1138.021, "loss": "0.505", "ntokens": "260692", "nsentences": "1757.46", "wps": "79636.8", "ups": "0.31", "wpb": "260692", "bsz": "1757.5", "num_updates": "54600", "lr": "0.000469293", "gnorm": "0.381", "loss_scale": "2", "train_wall": "266", "gb_free": "39.4", "wall": "17453"}
[2024-10-09 06:18:38,052][fairseq_cli.train][INFO] - end of epoch 1139 (average epoch stats below)
[2024-10-09 06:18:38,067][train][INFO] - {"epoch": 1139, "train_loss": "0.501", "train_ntokens": "260511", "train_nsentences": "1750.04", "train_wps": "98037.8", "train_ups": "0.38", "train_wpb": "260511", "train_bsz": "1750", "train_num_updates": "54647", "train_lr": "0.00046923", "train_gnorm": "0.408", "train_loss_scale": "2", "train_train_wall": "66", "train_gb_free": "39.6", "train_wall": "17489"}
[2024-10-09 06:18:38,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:18:38,193][fairseq.trainer][INFO] - begin training epoch 1140
[2024-10-09 06:18:38,193][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:21:43,686][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1140 @ 54695 updates
[2024-10-09 06:21:43,694][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 06:21:48,970][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 06:21:48,988][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1140 @ 54695 updates, score None) (writing took 5.302779930643737 seconds)
[2024-10-09 06:21:48,989][fairseq_cli.train][INFO] - end of epoch 1140 (average epoch stats below)
[2024-10-09 06:21:48,992][train][INFO] - {"epoch": 1140, "train_loss": "0.499", "train_ntokens": "260506", "train_nsentences": "1750.04", "train_wps": "65494.8", "train_ups": "0.25", "train_wpb": "260506", "train_bsz": "1750", "train_num_updates": "54695", "train_lr": "0.000469164", "train_gnorm": "0.384", "train_loss_scale": "2", "train_train_wall": "70", "train_gb_free": "39.4", "train_wall": "17680"}
[2024-10-09 06:21:49,163][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:21:49,177][fairseq.trainer][INFO] - begin training epoch 1141
[2024-10-09 06:21:49,178][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:24:14,643][fairseq_cli.train][INFO] - end of epoch 1141 (average epoch stats below)
[2024-10-09 06:24:14,647][train][INFO] - {"epoch": 1141, "train_loss": "0.501", "train_ntokens": "260560", "train_nsentences": "1750.04", "train_wps": "85868.6", "train_ups": "0.33", "train_wpb": "260560", "train_bsz": "1750", "train_num_updates": "54743", "train_lr": "0.000469099", "train_gnorm": "0.371", "train_loss_scale": "2", "train_train_wall": "53", "train_gb_free": "39.3", "train_wall": "17826"}
[2024-10-09 06:24:14,813][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:24:14,824][fairseq.trainer][INFO] - begin training epoch 1142
[2024-10-09 06:24:14,825][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:26:39,036][fairseq_cli.train][INFO] - end of epoch 1142 (average epoch stats below)
[2024-10-09 06:26:39,051][train][INFO] - {"epoch": 1142, "train_loss": "0.506", "train_ntokens": "260673", "train_nsentences": "1750.04", "train_wps": "86649.9", "train_ups": "0.33", "train_wpb": "260673", "train_bsz": "1750", "train_num_updates": "54791", "train_lr": "0.000469034", "train_gnorm": "0.395", "train_loss_scale": "2", "train_train_wall": "68", "train_gb_free": "39.4", "train_wall": "17970"}
[2024-10-09 06:26:39,193][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:26:39,199][fairseq.trainer][INFO] - begin training epoch 1143
[2024-10-09 06:26:39,199][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:28:32,529][train_inner][INFO] - {"epoch": 1143, "update": 1142.188, "loss": "0.501", "ntokens": "260501", "nsentences": "1753.27", "wps": "82681.4", "ups": "0.32", "wpb": "260501", "bsz": "1753.3", "num_updates": "54800", "lr": "0.000469022", "gnorm": "0.388", "loss_scale": "2", "train_wall": "255", "gb_free": "40", "wall": "18083"}
[2024-10-09 06:29:05,413][fairseq_cli.train][INFO] - end of epoch 1143 (average epoch stats below)
[2024-10-09 06:29:05,417][train][INFO] - {"epoch": 1143, "train_loss": "0.501", "train_ntokens": "260605", "train_nsentences": "1750.04", "train_wps": "85467.1", "train_ups": "0.33", "train_wpb": "260605", "train_bsz": "1750", "train_num_updates": "54839", "train_lr": "0.000468969", "train_gnorm": "0.385", "train_loss_scale": "2", "train_train_wall": "61", "train_gb_free": "39.3", "train_wall": "18116"}
[2024-10-09 06:29:05,554][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:29:05,565][fairseq.trainer][INFO] - begin training epoch 1144
[2024-10-09 06:29:05,565][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:31:24,064][fairseq_cli.train][INFO] - end of epoch 1144 (average epoch stats below)
[2024-10-09 06:31:24,071][train][INFO] - {"epoch": 1144, "train_loss": "0.506", "train_ntokens": "260723", "train_nsentences": "1750.04", "train_wps": "90261.4", "train_ups": "0.35", "train_wpb": "260723", "train_bsz": "1750", "train_num_updates": "54887", "train_lr": "0.000468904", "train_gnorm": "0.4", "train_loss_scale": "4", "train_train_wall": "54", "train_gb_free": "39.3", "train_wall": "18255"}
[2024-10-09 06:31:24,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:31:24,243][fairseq.trainer][INFO] - begin training epoch 1145
[2024-10-09 06:31:24,244][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:33:47,346][fairseq_cli.train][INFO] - end of epoch 1145 (average epoch stats below)
[2024-10-09 06:33:47,353][train][INFO] - {"epoch": 1145, "train_loss": "0.498", "train_ntokens": "260502", "train_nsentences": "1750.04", "train_wps": "87271.4", "train_ups": "0.34", "train_wpb": "260502", "train_bsz": "1750", "train_num_updates": "54935", "train_lr": "0.000468838", "train_gnorm": "0.397", "train_loss_scale": "4", "train_train_wall": "61", "train_gb_free": "39.2", "train_wall": "18398"}
[2024-10-09 06:33:47,449][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:33:47,468][fairseq.trainer][INFO] - begin training epoch 1146
[2024-10-09 06:33:47,468][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:36:12,105][fairseq_cli.train][INFO] - end of epoch 1146 (average epoch stats below)
[2024-10-09 06:36:12,108][train][INFO] - {"epoch": 1146, "train_loss": "0.498", "train_ntokens": "260942", "train_nsentences": "1750.04", "train_wps": "86528.9", "train_ups": "0.33", "train_wpb": "260942", "train_bsz": "1750", "train_num_updates": "54983", "train_lr": "0.000468773", "train_gnorm": "0.381", "train_loss_scale": "4", "train_train_wall": "56", "train_gb_free": "40.5", "train_wall": "18543"}
[2024-10-09 06:36:12,222][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:36:12,234][fairseq.trainer][INFO] - begin training epoch 1147
[2024-10-09 06:36:12,235][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:38:04,206][train_inner][INFO] - {"epoch": 1147, "update": 1146.354, "loss": "0.502", "ntokens": "260889", "nsentences": "1743.07", "wps": "91277.6", "ups": "0.35", "wpb": "260889", "bsz": "1743.1", "num_updates": "55000", "lr": "0.00046875", "gnorm": "0.39", "loss_scale": "4", "train_wall": "237", "gb_free": "39.8", "wall": "18655"}
[2024-10-09 06:38:28,833][fairseq_cli.train][INFO] - end of epoch 1147 (average epoch stats below)
[2024-10-09 06:38:28,835][train][INFO] - {"epoch": 1147, "train_loss": "0.51", "train_ntokens": "260806", "train_nsentences": "1750.04", "train_wps": "91561.9", "train_ups": "0.35", "train_wpb": "260806", "train_bsz": "1750", "train_num_updates": "55031", "train_lr": "0.000468708", "train_gnorm": "0.36", "train_loss_scale": "4", "train_train_wall": "59", "train_gb_free": "39.3", "train_wall": "18680"}
[2024-10-09 06:38:28,946][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:38:28,959][fairseq.trainer][INFO] - begin training epoch 1148
[2024-10-09 06:38:28,960][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:40:47,354][fairseq_cli.train][INFO] - end of epoch 1148 (average epoch stats below)
[2024-10-09 06:40:47,357][train][INFO] - {"epoch": 1148, "train_loss": "0.501", "train_ntokens": "260658", "train_nsentences": "1750.04", "train_wps": "90324.7", "train_ups": "0.35", "train_wpb": "260658", "train_bsz": "1750", "train_num_updates": "55079", "train_lr": "0.000468643", "train_gnorm": "0.411", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "40", "train_wall": "18818"}
[2024-10-09 06:40:47,406][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:40:47,421][fairseq.trainer][INFO] - begin training epoch 1149
[2024-10-09 06:40:47,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:43:09,811][fairseq_cli.train][INFO] - end of epoch 1149 (average epoch stats below)
[2024-10-09 06:43:09,822][train][INFO] - {"epoch": 1149, "train_loss": "0.506", "train_ntokens": "261060", "train_nsentences": "1750.04", "train_wps": "87960.4", "train_ups": "0.34", "train_wpb": "261060", "train_bsz": "1750", "train_num_updates": "55127", "train_lr": "0.000468577", "train_gnorm": "0.392", "train_loss_scale": "4", "train_train_wall": "48", "train_gb_free": "39.6", "train_wall": "18961"}
[2024-10-09 06:43:09,958][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:43:09,975][fairseq.trainer][INFO] - begin training epoch 1150
[2024-10-09 06:43:09,975][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:45:34,157][fairseq_cli.train][INFO] - end of epoch 1150 (average epoch stats below)
[2024-10-09 06:45:34,162][train][INFO] - {"epoch": 1150, "train_loss": "0.505", "train_ntokens": "260701", "train_nsentences": "1750.04", "train_wps": "86698.2", "train_ups": "0.33", "train_wpb": "260701", "train_bsz": "1750", "train_num_updates": "55175", "train_lr": "0.000468512", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "49", "train_gb_free": "39.4", "train_wall": "19105"}
[2024-10-09 06:45:34,350][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:45:34,369][fairseq.trainer][INFO] - begin training epoch 1151
[2024-10-09 06:45:34,369][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:47:39,772][train_inner][INFO] - {"epoch": 1151, "update": 1150.521, "loss": "0.504", "ntokens": "260498", "nsentences": "1758.53", "wps": "90519.8", "ups": "0.35", "wpb": "260498", "bsz": "1758.5", "num_updates": "55200", "lr": "0.000468478", "gnorm": "0.384", "loss_scale": "4", "train_wall": "228", "gb_free": "40.1", "wall": "19231"}
[2024-10-09 06:47:54,703][fairseq_cli.train][INFO] - end of epoch 1151 (average epoch stats below)
[2024-10-09 06:47:54,706][train][INFO] - {"epoch": 1151, "train_loss": "0.504", "train_ntokens": "260775", "train_nsentences": "1750.04", "train_wps": "89067.3", "train_ups": "0.34", "train_wpb": "260775", "train_bsz": "1750", "train_num_updates": "55223", "train_lr": "0.000468447", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "64", "train_gb_free": "39.6", "train_wall": "19246"}
[2024-10-09 06:47:54,804][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:47:54,812][fairseq.trainer][INFO] - begin training epoch 1152
[2024-10-09 06:47:54,812][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:50:02,444][fairseq_cli.train][INFO] - end of epoch 1152 (average epoch stats below)
[2024-10-09 06:50:02,447][train][INFO] - {"epoch": 1152, "train_loss": "0.5", "train_ntokens": "260604", "train_nsentences": "1750.04", "train_wps": "97927.3", "train_ups": "0.38", "train_wpb": "260604", "train_bsz": "1750", "train_num_updates": "55271", "train_lr": "0.000468382", "train_gnorm": "0.363", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "39.7", "train_wall": "19373"}
[2024-10-09 06:50:02,557][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:50:02,573][fairseq.trainer][INFO] - begin training epoch 1153
[2024-10-09 06:50:02,574][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:52:09,528][fairseq_cli.train][INFO] - end of epoch 1153 (average epoch stats below)
[2024-10-09 06:52:09,538][train][INFO] - {"epoch": 1153, "train_loss": "0.505", "train_ntokens": "260993", "train_nsentences": "1750.04", "train_wps": "98575.4", "train_ups": "0.38", "train_wpb": "260993", "train_bsz": "1750", "train_num_updates": "55319", "train_lr": "0.000468317", "train_gnorm": "0.391", "train_loss_scale": "4", "train_train_wall": "48", "train_gb_free": "40.2", "train_wall": "19500"}
[2024-10-09 06:52:09,653][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:52:09,656][fairseq.trainer][INFO] - begin training epoch 1154
[2024-10-09 06:52:09,656][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:54:18,191][fairseq_cli.train][INFO] - end of epoch 1154 (average epoch stats below)
[2024-10-09 06:54:18,205][train][INFO] - {"epoch": 1154, "train_loss": "0.504", "train_ntokens": "260811", "train_nsentences": "1750.04", "train_wps": "97300.2", "train_ups": "0.37", "train_wpb": "260811", "train_bsz": "1750", "train_num_updates": "55367", "train_lr": "0.000468251", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "42", "train_gb_free": "39.3", "train_wall": "19629"}
[2024-10-09 06:54:18,469][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:54:18,479][fairseq.trainer][INFO] - begin training epoch 1155
[2024-10-09 06:54:18,480][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:56:27,842][train_inner][INFO] - {"epoch": 1155, "update": 1154.688, "loss": "0.503", "ntokens": "260884", "nsentences": "1743.83", "wps": "98807.9", "ups": "0.38", "wpb": "260884", "bsz": "1743.8", "num_updates": "55400", "lr": "0.000468207", "gnorm": "0.378", "loss_scale": "4", "train_wall": "202", "gb_free": "40.1", "wall": "19759"}
[2024-10-09 06:56:40,636][fairseq_cli.train][INFO] - end of epoch 1155 (average epoch stats below)
[2024-10-09 06:56:40,642][train][INFO] - {"epoch": 1155, "train_loss": "0.502", "train_ntokens": "260452", "train_nsentences": "1750.04", "train_wps": "87773.8", "train_ups": "0.34", "train_wpb": "260452", "train_bsz": "1750", "train_num_updates": "55415", "train_lr": "0.000468186", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "51", "train_gb_free": "40.1", "train_wall": "19772"}
[2024-10-09 06:56:40,772][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:56:40,783][fairseq.trainer][INFO] - begin training epoch 1156
[2024-10-09 06:56:40,783][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 06:58:58,630][fairseq_cli.train][INFO] - end of epoch 1156 (average epoch stats below)
[2024-10-09 06:58:58,646][train][INFO] - {"epoch": 1156, "train_loss": "0.505", "train_ntokens": "260701", "train_nsentences": "1750.04", "train_wps": "90677.7", "train_ups": "0.35", "train_wpb": "260701", "train_bsz": "1750", "train_num_updates": "55463", "train_lr": "0.000468121", "train_gnorm": "0.38", "train_loss_scale": "4", "train_train_wall": "52", "train_gb_free": "39.3", "train_wall": "19910"}
[2024-10-09 06:58:58,815][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 06:58:58,841][fairseq.trainer][INFO] - begin training epoch 1157
[2024-10-09 06:58:58,842][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:01:12,113][fairseq_cli.train][INFO] - end of epoch 1157 (average epoch stats below)
[2024-10-09 07:01:12,117][train][INFO] - {"epoch": 1157, "train_loss": "0.5", "train_ntokens": "260338", "train_nsentences": "1750.04", "train_wps": "93627.6", "train_ups": "0.36", "train_wpb": "260338", "train_bsz": "1750", "train_num_updates": "55511", "train_lr": "0.000468056", "train_gnorm": "0.353", "train_loss_scale": "4", "train_train_wall": "43", "train_gb_free": "40.1", "train_wall": "20043"}
[2024-10-09 07:01:12,266][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:01:12,290][fairseq.trainer][INFO] - begin training epoch 1158
[2024-10-09 07:01:12,290][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:03:32,308][fairseq_cli.train][INFO] - end of epoch 1158 (average epoch stats below)
[2024-10-09 07:03:32,325][train][INFO] - {"epoch": 1158, "train_loss": "0.499", "train_ntokens": "260415", "train_nsentences": "1750.04", "train_wps": "89160.4", "train_ups": "0.34", "train_wpb": "260415", "train_bsz": "1750", "train_num_updates": "55559", "train_lr": "0.00046799", "train_gnorm": "0.36", "train_loss_scale": "4", "train_train_wall": "36", "train_gb_free": "40.1", "train_wall": "20183"}
[2024-10-09 07:03:32,469][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:03:32,485][fairseq.trainer][INFO] - begin training epoch 1159
[2024-10-09 07:03:32,485][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:05:46,880][train_inner][INFO] - {"epoch": 1159, "update": 1158.854, "loss": "0.502", "ntokens": "260585", "nsentences": "1744.51", "wps": "93227.4", "ups": "0.36", "wpb": "260585", "bsz": "1744.5", "num_updates": "55600", "lr": "0.000467935", "gnorm": "0.362", "loss_scale": "4", "train_wall": "199", "gb_free": "40", "wall": "20318"}
[2024-10-09 07:05:49,928][fairseq_cli.train][INFO] - end of epoch 1159 (average epoch stats below)
[2024-10-09 07:05:49,930][train][INFO] - {"epoch": 1159, "train_loss": "0.501", "train_ntokens": "260544", "train_nsentences": "1750.04", "train_wps": "90886.7", "train_ups": "0.35", "train_wpb": "260544", "train_bsz": "1750", "train_num_updates": "55607", "train_lr": "0.000467925", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "39.3", "train_wall": "20321"}
[2024-10-09 07:05:50,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:05:50,160][fairseq.trainer][INFO] - begin training epoch 1160
[2024-10-09 07:05:50,161][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:08:22,875][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1160 @ 55655 updates
[2024-10-09 07:08:22,876][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 07:08:26,876][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 07:08:26,879][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1160 @ 55655 updates, score None) (writing took 4.003564953804016 seconds)
[2024-10-09 07:08:26,879][fairseq_cli.train][INFO] - end of epoch 1160 (average epoch stats below)
[2024-10-09 07:08:26,881][train][INFO] - {"epoch": 1160, "train_loss": "0.5", "train_ntokens": "260952", "train_nsentences": "1750.04", "train_wps": "79807.8", "train_ups": "0.31", "train_wpb": "260952", "train_bsz": "1750", "train_num_updates": "55655", "train_lr": "0.00046786", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "70", "train_gb_free": "39.7", "train_wall": "20478"}
[2024-10-09 07:08:27,003][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:08:27,017][fairseq.trainer][INFO] - begin training epoch 1161
[2024-10-09 07:08:27,018][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:10:45,139][fairseq_cli.train][INFO] - end of epoch 1161 (average epoch stats below)
[2024-10-09 07:10:45,151][train][INFO] - {"epoch": 1161, "train_loss": "0.502", "train_ntokens": "260397", "train_nsentences": "1750.04", "train_wps": "90401.1", "train_ups": "0.35", "train_wpb": "260397", "train_bsz": "1750", "train_num_updates": "55703", "train_lr": "0.000467795", "train_gnorm": "0.36", "train_loss_scale": "4", "train_train_wall": "45", "train_gb_free": "39.1", "train_wall": "20616"}
[2024-10-09 07:10:45,314][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:10:45,321][fairseq.trainer][INFO] - begin training epoch 1162
[2024-10-09 07:10:45,322][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:13:02,890][fairseq_cli.train][INFO] - end of epoch 1162 (average epoch stats below)
[2024-10-09 07:13:02,895][train][INFO] - {"epoch": 1162, "train_loss": "0.508", "train_ntokens": "260692", "train_nsentences": "1750.04", "train_wps": "90848.1", "train_ups": "0.35", "train_wpb": "260692", "train_bsz": "1750", "train_num_updates": "55751", "train_lr": "0.00046773", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "40.7", "train_wall": "20754"}
[2024-10-09 07:13:02,997][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:13:03,020][fairseq.trainer][INFO] - begin training epoch 1163
[2024-10-09 07:13:03,021][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:15:48,896][fairseq_cli.train][INFO] - end of epoch 1163 (average epoch stats below)
[2024-10-09 07:15:48,908][train][INFO] - {"epoch": 1163, "train_loss": "0.498", "train_ntokens": "260628", "train_nsentences": "1750.04", "train_wps": "75359.6", "train_ups": "0.29", "train_wpb": "260628", "train_bsz": "1750", "train_num_updates": "55799", "train_lr": "0.000467664", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "84", "train_gb_free": "39.1", "train_wall": "20920"}
[2024-10-09 07:15:49,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:15:49,128][fairseq.trainer][INFO] - begin training epoch 1164
[2024-10-09 07:15:49,128][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:17:30,110][train_inner][INFO] - {"epoch": 1164, "update": 1163.021, "loss": "0.502", "ntokens": "260615", "nsentences": "1758.04", "wps": "74121.6", "ups": "0.28", "wpb": "260615", "bsz": "1758", "num_updates": "55800", "lr": "0.000467663", "gnorm": "0.379", "loss_scale": "4", "train_wall": "286", "gb_free": "39.6", "wall": "21021"}
[2024-10-09 07:18:23,685][fairseq_cli.train][INFO] - end of epoch 1164 (average epoch stats below)
[2024-10-09 07:18:23,687][train][INFO] - {"epoch": 1164, "train_loss": "0.493", "train_ntokens": "260322", "train_nsentences": "1750.04", "train_wps": "80732.9", "train_ups": "0.31", "train_wpb": "260322", "train_bsz": "1750", "train_num_updates": "55847", "train_lr": "0.000467599", "train_gnorm": "0.367", "train_loss_scale": "4", "train_train_wall": "67", "train_gb_free": "39.7", "train_wall": "21075"}
[2024-10-09 07:18:23,846][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:18:23,854][fairseq.trainer][INFO] - begin training epoch 1165
[2024-10-09 07:18:23,854][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:20:48,589][fairseq_cli.train][INFO] - end of epoch 1165 (average epoch stats below)
[2024-10-09 07:20:48,592][train][INFO] - {"epoch": 1165, "train_loss": "0.502", "train_ntokens": "260281", "train_nsentences": "1750.04", "train_wps": "86220.9", "train_ups": "0.33", "train_wpb": "260281", "train_bsz": "1750", "train_num_updates": "55895", "train_lr": "0.000467534", "train_gnorm": "0.357", "train_loss_scale": "4", "train_train_wall": "64", "train_gb_free": "39.8", "train_wall": "21220"}
[2024-10-09 07:20:48,646][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:20:48,655][fairseq.trainer][INFO] - begin training epoch 1166
[2024-10-09 07:20:48,656][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:22:55,734][fairseq_cli.train][INFO] - end of epoch 1166 (average epoch stats below)
[2024-10-09 07:22:55,761][train][INFO] - {"epoch": 1166, "train_loss": "0.5", "train_ntokens": "260550", "train_nsentences": "1750.04", "train_wps": "98357.3", "train_ups": "0.38", "train_wpb": "260550", "train_bsz": "1750", "train_num_updates": "55943", "train_lr": "0.000467469", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "50", "train_gb_free": "40.2", "train_wall": "21347"}
[2024-10-09 07:22:55,862][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:22:55,869][fairseq.trainer][INFO] - begin training epoch 1167
[2024-10-09 07:22:55,870][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:25:04,786][fairseq_cli.train][INFO] - end of epoch 1167 (average epoch stats below)
[2024-10-09 07:25:04,800][train][INFO] - {"epoch": 1167, "train_loss": "0.492", "train_ntokens": "260428", "train_nsentences": "1750.04", "train_wps": "96882.5", "train_ups": "0.37", "train_wpb": "260428", "train_bsz": "1750", "train_num_updates": "55991", "train_lr": "0.000467404", "train_gnorm": "0.379", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "40.3", "train_wall": "21476"}
[2024-10-09 07:25:04,942][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:25:04,956][fairseq.trainer][INFO] - begin training epoch 1168
[2024-10-09 07:25:04,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:26:58,700][train_inner][INFO] - {"epoch": 1168, "update": 1167.188, "loss": "0.498", "ntokens": "260439", "nsentences": "1749.23", "wps": "91617", "ups": "0.35", "wpb": "260439", "bsz": "1749.2", "num_updates": "56000", "lr": "0.000467391", "gnorm": "0.37", "loss_scale": "4", "train_wall": "219", "gb_free": "39.3", "wall": "21590"}
[2024-10-09 07:27:20,360][fairseq_cli.train][INFO] - end of epoch 1168 (average epoch stats below)
[2024-10-09 07:27:20,362][train][INFO] - {"epoch": 1168, "train_loss": "0.504", "train_ntokens": "260514", "train_nsentences": "1750.04", "train_wps": "92245.7", "train_ups": "0.35", "train_wpb": "260514", "train_bsz": "1750", "train_num_updates": "56039", "train_lr": "0.000467338", "train_gnorm": "0.406", "train_loss_scale": "4", "train_train_wall": "39", "train_gb_free": "39.4", "train_wall": "21611"}
[2024-10-09 07:27:20,426][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:27:20,429][fairseq.trainer][INFO] - begin training epoch 1169
[2024-10-09 07:27:20,430][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:29:38,768][fairseq_cli.train][INFO] - end of epoch 1169 (average epoch stats below)
[2024-10-09 07:29:38,777][train][INFO] - {"epoch": 1169, "train_loss": "0.508", "train_ntokens": "260760", "train_nsentences": "1750.04", "train_wps": "90429.9", "train_ups": "0.35", "train_wpb": "260760", "train_bsz": "1750", "train_num_updates": "56087", "train_lr": "0.000467273", "train_gnorm": "0.38", "train_loss_scale": "4", "train_train_wall": "50", "train_gb_free": "39.3", "train_wall": "21750"}
[2024-10-09 07:29:38,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:29:38,989][fairseq.trainer][INFO] - begin training epoch 1170
[2024-10-09 07:29:38,990][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:31:58,801][fairseq_cli.train][INFO] - end of epoch 1170 (average epoch stats below)
[2024-10-09 07:31:58,809][train][INFO] - {"epoch": 1170, "train_loss": "0.497", "train_ntokens": "260798", "train_nsentences": "1750.04", "train_wps": "89398.7", "train_ups": "0.34", "train_wpb": "260798", "train_bsz": "1750", "train_num_updates": "56135", "train_lr": "0.000467208", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "59", "train_gb_free": "40.3", "train_wall": "21890"}
[2024-10-09 07:31:58,912][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:31:58,925][fairseq.trainer][INFO] - begin training epoch 1171
[2024-10-09 07:31:58,925][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:34:12,586][fairseq_cli.train][INFO] - end of epoch 1171 (average epoch stats below)
[2024-10-09 07:34:12,606][train][INFO] - {"epoch": 1171, "train_loss": "0.5", "train_ntokens": "260800", "train_nsentences": "1750.04", "train_wps": "93565.2", "train_ups": "0.36", "train_wpb": "260800", "train_bsz": "1750", "train_num_updates": "56183", "train_lr": "0.000467143", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "49", "train_gb_free": "39.6", "train_wall": "22024"}
[2024-10-09 07:34:12,775][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:34:12,779][fairseq.trainer][INFO] - begin training epoch 1172
[2024-10-09 07:34:12,780][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:36:12,387][train_inner][INFO] - {"epoch": 1172, "update": 1171.354, "loss": "0.501", "ntokens": "260712", "nsentences": "1756.3", "wps": "94174.3", "ups": "0.36", "wpb": "260712", "bsz": "1756.3", "num_updates": "56200", "lr": "0.00046712", "gnorm": "0.392", "loss_scale": "4", "train_wall": "215", "gb_free": "39.3", "wall": "22143"}
[2024-10-09 07:36:30,749][fairseq_cli.train][INFO] - end of epoch 1172 (average epoch stats below)
[2024-10-09 07:36:30,751][train][INFO] - {"epoch": 1172, "train_loss": "0.501", "train_ntokens": "261166", "train_nsentences": "1750.04", "train_wps": "90747", "train_ups": "0.35", "train_wpb": "261166", "train_bsz": "1750", "train_num_updates": "56231", "train_lr": "0.000467077", "train_gnorm": "0.391", "train_loss_scale": "4", "train_train_wall": "52", "train_gb_free": "40", "train_wall": "22162"}
[2024-10-09 07:36:30,951][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:36:30,956][fairseq.trainer][INFO] - begin training epoch 1173
[2024-10-09 07:36:30,956][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:38:52,072][fairseq_cli.train][INFO] - end of epoch 1173 (average epoch stats below)
[2024-10-09 07:38:52,093][train][INFO] - {"epoch": 1173, "train_loss": "0.504", "train_ntokens": "260911", "train_nsentences": "1750.04", "train_wps": "88611.7", "train_ups": "0.34", "train_wpb": "260912", "train_bsz": "1750", "train_num_updates": "56279", "train_lr": "0.000467012", "train_gnorm": "0.366", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "40.6", "train_wall": "22303"}
[2024-10-09 07:38:52,301][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:38:52,312][fairseq.trainer][INFO] - begin training epoch 1174
[2024-10-09 07:38:52,312][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:41:19,418][fairseq_cli.train][INFO] - end of epoch 1174 (average epoch stats below)
[2024-10-09 07:41:19,437][train][INFO] - {"epoch": 1174, "train_loss": "0.501", "train_ntokens": "260788", "train_nsentences": "1750.04", "train_wps": "84959.6", "train_ups": "0.33", "train_wpb": "260788", "train_bsz": "1750", "train_num_updates": "56327", "train_lr": "0.000466947", "train_gnorm": "0.386", "train_loss_scale": "4", "train_train_wall": "52", "train_gb_free": "39.7", "train_wall": "22450"}
[2024-10-09 07:41:19,634][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:41:19,639][fairseq.trainer][INFO] - begin training epoch 1175
[2024-10-09 07:41:19,639][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:43:32,101][fairseq_cli.train][INFO] - end of epoch 1175 (average epoch stats below)
[2024-10-09 07:43:32,112][train][INFO] - {"epoch": 1175, "train_loss": "0.493", "train_ntokens": "260715", "train_nsentences": "1750.04", "train_wps": "94325.6", "train_ups": "0.36", "train_wpb": "260715", "train_bsz": "1750", "train_num_updates": "56375", "train_lr": "0.000466882", "train_gnorm": "0.392", "train_loss_scale": "4", "train_train_wall": "51", "train_gb_free": "39.6", "train_wall": "22583"}
[2024-10-09 07:43:32,345][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:43:32,362][fairseq.trainer][INFO] - begin training epoch 1176
[2024-10-09 07:43:32,362][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:45:43,636][train_inner][INFO] - {"epoch": 1176, "update": 1175.521, "loss": "0.498", "ntokens": "260997", "nsentences": "1736.48", "wps": "91378.4", "ups": "0.35", "wpb": "260997", "bsz": "1736.5", "num_updates": "56400", "lr": "0.000466848", "gnorm": "0.381", "loss_scale": "4", "train_wall": "199", "gb_free": "39.3", "wall": "22715"}
[2024-10-09 07:46:01,199][fairseq_cli.train][INFO] - end of epoch 1176 (average epoch stats below)
[2024-10-09 07:46:01,201][train][INFO] - {"epoch": 1176, "train_loss": "0.495", "train_ntokens": "260546", "train_nsentences": "1750.04", "train_wps": "83886.2", "train_ups": "0.32", "train_wpb": "260546", "train_bsz": "1750", "train_num_updates": "56423", "train_lr": "0.000466817", "train_gnorm": "0.39", "train_loss_scale": "4", "train_train_wall": "56", "train_gb_free": "39.7", "train_wall": "22732"}
[2024-10-09 07:46:01,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:46:01,496][fairseq.trainer][INFO] - begin training epoch 1177
[2024-10-09 07:46:01,497][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:50:20,727][fairseq_cli.train][INFO] - end of epoch 1177 (average epoch stats below)
[2024-10-09 07:50:20,748][train][INFO] - {"epoch": 1177, "train_loss": "0.493", "train_ntokens": "260525", "train_nsentences": "1750.04", "train_wps": "48181.5", "train_ups": "0.18", "train_wpb": "260525", "train_bsz": "1750", "train_num_updates": "56471", "train_lr": "0.000466751", "train_gnorm": "0.391", "train_loss_scale": "4", "train_train_wall": "42", "train_gb_free": "39.2", "train_wall": "22992"}
[2024-10-09 07:50:20,853][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:50:20,858][fairseq.trainer][INFO] - begin training epoch 1178
[2024-10-09 07:50:20,859][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:52:42,354][fairseq_cli.train][INFO] - end of epoch 1178 (average epoch stats below)
[2024-10-09 07:52:42,358][train][INFO] - {"epoch": 1178, "train_loss": "0.504", "train_ntokens": "261332", "train_nsentences": "1750.04", "train_wps": "88583.3", "train_ups": "0.34", "train_wpb": "261332", "train_bsz": "1750", "train_num_updates": "56519", "train_lr": "0.000466686", "train_gnorm": "0.384", "train_loss_scale": "4", "train_train_wall": "54", "train_gb_free": "40", "train_wall": "23133"}
[2024-10-09 07:52:42,477][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:52:42,481][fairseq.trainer][INFO] - begin training epoch 1179
[2024-10-09 07:52:42,482][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:56:56,106][fairseq_cli.train][INFO] - end of epoch 1179 (average epoch stats below)
[2024-10-09 07:56:56,112][train][INFO] - {"epoch": 1179, "train_loss": "0.491", "train_ntokens": "260685", "train_nsentences": "1750.04", "train_wps": "49312", "train_ups": "0.19", "train_wpb": "260685", "train_bsz": "1750", "train_num_updates": "56567", "train_lr": "0.000466621", "train_gnorm": "0.378", "train_loss_scale": "4", "train_train_wall": "40", "train_gb_free": "40.1", "train_wall": "23387"}
[2024-10-09 07:56:56,201][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:56:56,205][fairseq.trainer][INFO] - begin training epoch 1180
[2024-10-09 07:56:56,205][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 07:58:49,449][train_inner][INFO] - {"epoch": 1180, "update": 1179.688, "loss": "0.498", "ntokens": "260427", "nsentences": "1765.5", "wps": "66282.6", "ups": "0.25", "wpb": "260427", "bsz": "1765.5", "num_updates": "56600", "lr": "0.000466576", "gnorm": "0.382", "loss_scale": "4", "train_wall": "183", "gb_free": "40.5", "wall": "23500"}
[2024-10-09 07:59:05,305][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1180 @ 56615 updates
[2024-10-09 07:59:05,305][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 07:59:08,730][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 07:59:08,747][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1180 @ 56615 updates, score None) (writing took 3.4422908248379827 seconds)
[2024-10-09 07:59:08,747][fairseq_cli.train][INFO] - end of epoch 1180 (average epoch stats below)
[2024-10-09 07:59:08,749][train][INFO] - {"epoch": 1180, "train_loss": "0.501", "train_ntokens": "260711", "train_nsentences": "1750.04", "train_wps": "94351.9", "train_ups": "0.36", "train_wpb": "260711", "train_bsz": "1750", "train_num_updates": "56615", "train_lr": "0.000466556", "train_gnorm": "0.362", "train_loss_scale": "4", "train_train_wall": "45", "train_gb_free": "39.8", "train_wall": "23520"}
[2024-10-09 07:59:08,806][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 07:59:08,810][fairseq.trainer][INFO] - begin training epoch 1181
[2024-10-09 07:59:08,811][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:01:17,012][fairseq_cli.train][INFO] - end of epoch 1181 (average epoch stats below)
[2024-10-09 08:01:17,029][train][INFO] - {"epoch": 1181, "train_loss": "0.499", "train_ntokens": "260361", "train_nsentences": "1750.04", "train_wps": "97426.1", "train_ups": "0.37", "train_wpb": "260362", "train_bsz": "1750", "train_num_updates": "56663", "train_lr": "0.00046649", "train_gnorm": "0.401", "train_loss_scale": "4", "train_train_wall": "44", "train_gb_free": "40.3", "train_wall": "23648"}
[2024-10-09 08:01:17,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:01:17,456][fairseq.trainer][INFO] - begin training epoch 1182
[2024-10-09 08:01:17,457][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:05:11,038][fairseq_cli.train][INFO] - end of epoch 1182 (average epoch stats below)
[2024-10-09 08:05:11,042][train][INFO] - {"epoch": 1182, "train_loss": "0.495", "train_ntokens": "260495", "train_nsentences": "1750.04", "train_wps": "53432.6", "train_ups": "0.21", "train_wpb": "260495", "train_bsz": "1750", "train_num_updates": "56711", "train_lr": "0.000466425", "train_gnorm": "0.385", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "39.1", "train_wall": "23882"}
[2024-10-09 08:05:11,190][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:05:11,232][fairseq.trainer][INFO] - begin training epoch 1183
[2024-10-09 08:05:11,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:07:29,421][fairseq_cli.train][INFO] - end of epoch 1183 (average epoch stats below)
[2024-10-09 08:07:29,424][train][INFO] - {"epoch": 1183, "train_loss": "0.493", "train_ntokens": "260953", "train_nsentences": "1750.04", "train_wps": "90518.2", "train_ups": "0.35", "train_wpb": "260953", "train_bsz": "1750", "train_num_updates": "56759", "train_lr": "0.00046636", "train_gnorm": "0.371", "train_loss_scale": "4", "train_train_wall": "36", "train_gb_free": "39.3", "train_wall": "24020"}
[2024-10-09 08:07:29,527][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:07:29,545][fairseq.trainer][INFO] - begin training epoch 1184
[2024-10-09 08:07:29,546][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:09:41,423][train_inner][INFO] - {"epoch": 1184, "update": 1183.854, "loss": "0.496", "ntokens": "260890", "nsentences": "1743.08", "wps": "80032.8", "ups": "0.31", "wpb": "260890", "bsz": "1743.1", "num_updates": "56800", "lr": "0.000466304", "gnorm": "0.383", "loss_scale": "4", "train_wall": "195", "gb_free": "39.4", "wall": "24152"}
[2024-10-09 08:09:44,611][fairseq_cli.train][INFO] - end of epoch 1184 (average epoch stats below)
[2024-10-09 08:09:44,614][train][INFO] - {"epoch": 1184, "train_loss": "0.497", "train_ntokens": "260717", "train_nsentences": "1750.04", "train_wps": "92572", "train_ups": "0.36", "train_wpb": "260717", "train_bsz": "1750", "train_num_updates": "56807", "train_lr": "0.000466295", "train_gnorm": "0.387", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "39.8", "train_wall": "24156"}
[2024-10-09 08:09:44,757][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:09:44,763][fairseq.trainer][INFO] - begin training epoch 1185
[2024-10-09 08:09:44,763][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:12:02,021][fairseq_cli.train][INFO] - end of epoch 1185 (average epoch stats below)
[2024-10-09 08:12:02,033][train][INFO] - {"epoch": 1185, "train_loss": "0.501", "train_ntokens": "260617", "train_nsentences": "1750.04", "train_wps": "91035.2", "train_ups": "0.35", "train_wpb": "260617", "train_bsz": "1750", "train_num_updates": "56855", "train_lr": "0.00046623", "train_gnorm": "0.412", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "39.3", "train_wall": "24293"}
[2024-10-09 08:12:02,216][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:12:02,229][fairseq.trainer][INFO] - begin training epoch 1186
[2024-10-09 08:12:02,229][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:14:24,594][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2024-10-09 08:14:25,361][fairseq_cli.train][INFO] - end of epoch 1186 (average epoch stats below)
[2024-10-09 08:14:25,368][train][INFO] - {"epoch": 1186, "train_loss": "0.504", "train_ntokens": "260638", "train_nsentences": "1752.79", "train_wps": "85465.9", "train_ups": "0.33", "train_wpb": "260638", "train_bsz": "1752.8", "train_num_updates": "56902", "train_lr": "0.000466166", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "61", "train_gb_free": "39.2", "train_wall": "24436"}
[2024-10-09 08:14:25,532][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:14:25,539][fairseq.trainer][INFO] - begin training epoch 1187
[2024-10-09 08:14:25,539][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:16:51,600][fairseq_cli.train][INFO] - end of epoch 1187 (average epoch stats below)
[2024-10-09 08:16:51,605][train][INFO] - {"epoch": 1187, "train_loss": "0.497", "train_ntokens": "260628", "train_nsentences": "1750.04", "train_wps": "85549.7", "train_ups": "0.33", "train_wpb": "260628", "train_bsz": "1750", "train_num_updates": "56950", "train_lr": "0.000466101", "train_gnorm": "0.363", "train_loss_scale": "4", "train_train_wall": "26", "train_gb_free": "40.1", "train_wall": "24583"}
[2024-10-09 08:16:51,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:16:51,773][fairseq.trainer][INFO] - begin training epoch 1188
[2024-10-09 08:16:51,774][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:19:13,774][fairseq_cli.train][INFO] - end of epoch 1188 (average epoch stats below)
[2024-10-09 08:19:13,782][train][INFO] - {"epoch": 1188, "train_loss": "0.499", "train_ntokens": "260676", "train_nsentences": "1750.04", "train_wps": "88009.7", "train_ups": "0.34", "train_wpb": "260676", "train_bsz": "1750", "train_num_updates": "56998", "train_lr": "0.000466035", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "40.1", "train_wall": "24725"}
[2024-10-09 08:19:13,931][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:19:13,949][fairseq.trainer][INFO] - begin training epoch 1189
[2024-10-09 08:19:13,950][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:20:59,570][train_inner][INFO] - {"epoch": 1189, "update": 1188.042, "loss": "0.5", "ntokens": "260441", "nsentences": "1749.53", "wps": "76810.9", "ups": "0.29", "wpb": "260441", "bsz": "1749.5", "num_updates": "57000", "lr": "0.000466033", "gnorm": "0.383", "loss_scale": "4", "train_wall": "205", "gb_free": "39.6", "wall": "24831"}
[2024-10-09 08:21:43,826][fairseq_cli.train][INFO] - end of epoch 1189 (average epoch stats below)
[2024-10-09 08:21:43,830][train][INFO] - {"epoch": 1189, "train_loss": "0.499", "train_ntokens": "260847", "train_nsentences": "1750.04", "train_wps": "83449.8", "train_ups": "0.32", "train_wpb": "260847", "train_bsz": "1750", "train_num_updates": "57046", "train_lr": "0.00046597", "train_gnorm": "0.413", "train_loss_scale": "4", "train_train_wall": "44", "train_gb_free": "39.6", "train_wall": "24875"}
[2024-10-09 08:21:43,984][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:21:44,007][fairseq.trainer][INFO] - begin training epoch 1190
[2024-10-09 08:21:44,008][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:23:56,292][fairseq_cli.train][INFO] - end of epoch 1190 (average epoch stats below)
[2024-10-09 08:23:56,303][train][INFO] - {"epoch": 1190, "train_loss": "0.489", "train_ntokens": "260756", "train_nsentences": "1750.04", "train_wps": "94484.8", "train_ups": "0.36", "train_wpb": "260756", "train_bsz": "1750", "train_num_updates": "57094", "train_lr": "0.000465905", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "51", "train_gb_free": "42", "train_wall": "25007"}
[2024-10-09 08:23:56,453][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:23:56,461][fairseq.trainer][INFO] - begin training epoch 1191
[2024-10-09 08:23:56,461][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:26:18,521][fairseq_cli.train][INFO] - end of epoch 1191 (average epoch stats below)
[2024-10-09 08:26:18,527][train][INFO] - {"epoch": 1191, "train_loss": "0.499", "train_ntokens": "260752", "train_nsentences": "1750.04", "train_wps": "88005.2", "train_ups": "0.34", "train_wpb": "260752", "train_bsz": "1750", "train_num_updates": "57142", "train_lr": "0.00046584", "train_gnorm": "0.372", "train_loss_scale": "4", "train_train_wall": "65", "train_gb_free": "39.8", "train_wall": "25149"}
[2024-10-09 08:26:18,586][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:26:18,602][fairseq.trainer][INFO] - begin training epoch 1192
[2024-10-09 08:26:18,602][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:28:23,896][fairseq_cli.train][INFO] - end of epoch 1192 (average epoch stats below)
[2024-10-09 08:28:23,905][train][INFO] - {"epoch": 1192, "train_loss": "0.501", "train_ntokens": "260818", "train_nsentences": "1750.04", "train_wps": "99859.2", "train_ups": "0.38", "train_wpb": "260818", "train_bsz": "1750", "train_num_updates": "57190", "train_lr": "0.000465774", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "48", "train_gb_free": "39.8", "train_wall": "25275"}
[2024-10-09 08:28:24,002][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:28:24,008][fairseq.trainer][INFO] - begin training epoch 1193
[2024-10-09 08:28:24,008][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:29:54,012][train_inner][INFO] - {"epoch": 1193, "update": 1192.208, "loss": "0.497", "ntokens": "261038", "nsentences": "1743.75", "wps": "97698.4", "ups": "0.37", "wpb": "261038", "bsz": "1743.8", "num_updates": "57200", "lr": "0.000465761", "gnorm": "0.382", "loss_scale": "4", "train_wall": "223", "gb_free": "39.7", "wall": "25365"}
[2024-10-09 08:30:36,702][fairseq_cli.train][INFO] - end of epoch 1193 (average epoch stats below)
[2024-10-09 08:30:36,704][train][INFO] - {"epoch": 1193, "train_loss": "0.496", "train_ntokens": "261072", "train_nsentences": "1750.04", "train_wps": "94367.2", "train_ups": "0.36", "train_wpb": "261072", "train_bsz": "1750", "train_num_updates": "57238", "train_lr": "0.000465709", "train_gnorm": "0.382", "train_loss_scale": "4", "train_train_wall": "58", "train_gb_free": "40.3", "train_wall": "25408"}
[2024-10-09 08:30:36,758][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:30:36,763][fairseq.trainer][INFO] - begin training epoch 1194
[2024-10-09 08:30:36,764][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:32:44,749][fairseq_cli.train][INFO] - end of epoch 1194 (average epoch stats below)
[2024-10-09 08:32:44,754][train][INFO] - {"epoch": 1194, "train_loss": "0.5", "train_ntokens": "260440", "train_nsentences": "1750.04", "train_wps": "97629.7", "train_ups": "0.37", "train_wpb": "260440", "train_bsz": "1750", "train_num_updates": "57286", "train_lr": "0.000465644", "train_gnorm": "0.383", "train_loss_scale": "4", "train_train_wall": "56", "train_gb_free": "39.6", "train_wall": "25536"}
[2024-10-09 08:32:44,943][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:32:44,959][fairseq.trainer][INFO] - begin training epoch 1195
[2024-10-09 08:32:44,960][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:34:54,431][fairseq_cli.train][INFO] - end of epoch 1195 (average epoch stats below)
[2024-10-09 08:34:54,436][train][INFO] - {"epoch": 1195, "train_loss": "0.493", "train_ntokens": "260559", "train_nsentences": "1750.04", "train_wps": "96446.2", "train_ups": "0.37", "train_wpb": "260558", "train_bsz": "1750", "train_num_updates": "57334", "train_lr": "0.000465579", "train_gnorm": "0.393", "train_loss_scale": "4", "train_train_wall": "61", "train_gb_free": "39.2", "train_wall": "25665"}
[2024-10-09 08:34:54,575][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:34:54,591][fairseq.trainer][INFO] - begin training epoch 1196
[2024-10-09 08:34:54,592][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:37:05,906][fairseq_cli.train][INFO] - end of epoch 1196 (average epoch stats below)
[2024-10-09 08:37:05,919][train][INFO] - {"epoch": 1196, "train_loss": "0.491", "train_ntokens": "260968", "train_nsentences": "1750.04", "train_wps": "95275", "train_ups": "0.37", "train_wpb": "260968", "train_bsz": "1750", "train_num_updates": "57382", "train_lr": "0.000465514", "train_gnorm": "0.375", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "39.2", "train_wall": "25797"}
[2024-10-09 08:37:06,061][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:37:06,067][fairseq.trainer][INFO] - begin training epoch 1197
[2024-10-09 08:37:06,068][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:39:02,288][train_inner][INFO] - {"epoch": 1197, "update": 1196.375, "loss": "0.494", "ntokens": "260615", "nsentences": "1755.89", "wps": "95068.1", "ups": "0.36", "wpb": "260615", "bsz": "1755.9", "num_updates": "57400", "lr": "0.000465489", "gnorm": "0.382", "loss_scale": "4", "train_wall": "252", "gb_free": "40", "wall": "25913"}
[2024-10-09 08:39:22,668][fairseq_cli.train][INFO] - end of epoch 1197 (average epoch stats below)
[2024-10-09 08:39:22,671][train][INFO] - {"epoch": 1197, "train_loss": "0.503", "train_ntokens": "260656", "train_nsentences": "1750.04", "train_wps": "91493.2", "train_ups": "0.35", "train_wpb": "260656", "train_bsz": "1750", "train_num_updates": "57430", "train_lr": "0.000465448", "train_gnorm": "0.361", "train_loss_scale": "4", "train_train_wall": "57", "train_gb_free": "40", "train_wall": "25934"}
[2024-10-09 08:39:22,810][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:39:22,814][fairseq.trainer][INFO] - begin training epoch 1198
[2024-10-09 08:39:22,815][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:41:38,460][fairseq_cli.train][INFO] - end of epoch 1198 (average epoch stats below)
[2024-10-09 08:41:38,465][train][INFO] - {"epoch": 1198, "train_loss": "0.495", "train_ntokens": "260751", "train_nsentences": "1750.04", "train_wps": "92171.9", "train_ups": "0.35", "train_wpb": "260751", "train_bsz": "1750", "train_num_updates": "57478", "train_lr": "0.000465383", "train_gnorm": "0.368", "train_loss_scale": "4", "train_train_wall": "65", "train_gb_free": "39.8", "train_wall": "26069"}
[2024-10-09 08:41:38,597][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:41:38,612][fairseq.trainer][INFO] - begin training epoch 1199
[2024-10-09 08:41:38,613][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:43:59,186][fairseq_cli.train][INFO] - end of epoch 1199 (average epoch stats below)
[2024-10-09 08:43:59,189][train][INFO] - {"epoch": 1199, "train_loss": "0.493", "train_ntokens": "260556", "train_nsentences": "1750.04", "train_wps": "88876", "train_ups": "0.34", "train_wpb": "260556", "train_bsz": "1750", "train_num_updates": "57526", "train_lr": "0.000465318", "train_gnorm": "0.373", "train_loss_scale": "4", "train_train_wall": "66", "train_gb_free": "39.7", "train_wall": "26210"}
[2024-10-09 08:43:59,290][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:43:59,345][fairseq.trainer][INFO] - begin training epoch 1200
[2024-10-09 08:43:59,346][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:46:22,039][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1200 @ 57574 updates
[2024-10-09 08:46:22,040][fairseq.trainer][INFO] - Saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 08:46:25,767][fairseq.trainer][INFO] - Finished saving checkpoint to /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt
[2024-10-09 08:46:25,770][fairseq.checkpoint_utils][INFO] - Saved checkpoint /share/data/pals/shester/sign_dinosr_logs/outputs/masking_random_400_10percent/ckpt/checkpoint_last.pt (epoch 1200 @ 57574 updates, score None) (writing took 3.7311299322173 seconds)
[2024-10-09 08:46:25,771][fairseq_cli.train][INFO] - end of epoch 1200 (average epoch stats below)
[2024-10-09 08:46:25,773][train][INFO] - {"epoch": 1200, "train_loss": "0.498", "train_ntokens": "260528", "train_nsentences": "1750.04", "train_wps": "85314", "train_ups": "0.33", "train_wpb": "260528", "train_bsz": "1750", "train_num_updates": "57574", "train_lr": "0.000465253", "train_gnorm": "0.38", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "39.7", "train_wall": "26357"}
[2024-10-09 08:46:25,848][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:46:25,878][fairseq.trainer][INFO] - begin training epoch 1201
[2024-10-09 08:46:25,878][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:48:37,224][train_inner][INFO] - {"epoch": 1201, "update": 1200.542, "loss": "0.497", "ntokens": "260543", "nsentences": "1766.49", "wps": "90634.8", "ups": "0.35", "wpb": "260543", "bsz": "1766.5", "num_updates": "57600", "lr": "0.000465217", "gnorm": "0.373", "loss_scale": "4", "train_wall": "228", "gb_free": "40.1", "wall": "26488"}
[2024-10-09 08:48:53,648][fairseq_cli.train][INFO] - end of epoch 1201 (average epoch stats below)
[2024-10-09 08:48:53,652][train][INFO] - {"epoch": 1201, "train_loss": "0.493", "train_ntokens": "261029", "train_nsentences": "1750.04", "train_wps": "84730.1", "train_ups": "0.32", "train_wpb": "261029", "train_bsz": "1750", "train_num_updates": "57622", "train_lr": "0.000465187", "train_gnorm": "0.388", "train_loss_scale": "4", "train_train_wall": "46", "train_gb_free": "39.5", "train_wall": "26505"}
[2024-10-09 08:48:53,900][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:48:53,907][fairseq.trainer][INFO] - begin training epoch 1202
[2024-10-09 08:48:53,910][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:52:03,858][fairseq_cli.train][INFO] - end of epoch 1202 (average epoch stats below)
[2024-10-09 08:52:03,866][train][INFO] - {"epoch": 1202, "train_loss": "0.49", "train_ntokens": "260882", "train_nsentences": "1750.04", "train_wps": "65834.3", "train_ups": "0.25", "train_wpb": "260882", "train_bsz": "1750", "train_num_updates": "57670", "train_lr": "0.000465122", "train_gnorm": "0.373", "train_loss_scale": "4", "train_train_wall": "67", "train_gb_free": "39.7", "train_wall": "26695"}
[2024-10-09 08:52:04,027][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:52:04,045][fairseq.trainer][INFO] - begin training epoch 1203
[2024-10-09 08:52:04,046][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:55:03,991][fairseq_cli.train][INFO] - end of epoch 1203 (average epoch stats below)
[2024-10-09 08:55:03,997][train][INFO] - {"epoch": 1203, "train_loss": "0.493", "train_ntokens": "260271", "train_nsentences": "1750.04", "train_wps": "69357.2", "train_ups": "0.27", "train_wpb": "260271", "train_bsz": "1750", "train_num_updates": "57718", "train_lr": "0.000465057", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "62", "train_gb_free": "39.7", "train_wall": "26875"}
[2024-10-09 08:55:04,050][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:55:04,070][fairseq.trainer][INFO] - begin training epoch 1204
[2024-10-09 08:55:04,071][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:57:22,101][fairseq_cli.train][INFO] - end of epoch 1204 (average epoch stats below)
[2024-10-09 08:57:22,105][train][INFO] - {"epoch": 1204, "train_loss": "0.495", "train_ntokens": "260639", "train_nsentences": "1750.04", "train_wps": "90589", "train_ups": "0.35", "train_wpb": "260639", "train_bsz": "1750", "train_num_updates": "57766", "train_lr": "0.000464992", "train_gnorm": "0.371", "train_loss_scale": "4", "train_train_wall": "47", "train_gb_free": "39.3", "train_wall": "27013"}
[2024-10-09 08:57:22,227][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:57:22,233][fairseq.trainer][INFO] - begin training epoch 1205
[2024-10-09 08:57:22,233][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 08:59:27,105][train_inner][INFO] - {"epoch": 1205, "update": 1204.708, "loss": "0.493", "ntokens": "260799", "nsentences": "1732.68", "wps": "80261.3", "ups": "0.31", "wpb": "260799", "bsz": "1732.7", "num_updates": "57800", "lr": "0.000464946", "gnorm": "0.373", "loss_scale": "4", "train_wall": "232", "gb_free": "39.6", "wall": "27138"}
[2024-10-09 08:59:41,388][fairseq_cli.train][INFO] - end of epoch 1205 (average epoch stats below)
[2024-10-09 08:59:41,390][train][INFO] - {"epoch": 1205, "train_loss": "0.494", "train_ntokens": "260661", "train_nsentences": "1750.04", "train_wps": "89831", "train_ups": "0.34", "train_wpb": "260661", "train_bsz": "1750", "train_num_updates": "57814", "train_lr": "0.000464927", "train_gnorm": "0.365", "train_loss_scale": "4", "train_train_wall": "53", "train_gb_free": "39.4", "train_wall": "27152"}
[2024-10-09 08:59:41,475][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 08:59:41,480][fairseq.trainer][INFO] - begin training epoch 1206
[2024-10-09 08:59:41,481][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:03:41,922][fairseq_cli.train][INFO] - end of epoch 1206 (average epoch stats below)
[2024-10-09 09:03:41,938][train][INFO] - {"epoch": 1206, "train_loss": "0.504", "train_ntokens": "260679", "train_nsentences": "1750.04", "train_wps": "52017.7", "train_ups": "0.2", "train_wpb": "260679", "train_bsz": "1750", "train_num_updates": "57862", "train_lr": "0.000464861", "train_gnorm": "0.393", "train_loss_scale": "4", "train_train_wall": "48", "train_gb_free": "39.2", "train_wall": "27393"}
[2024-10-09 09:03:42,059][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:03:42,076][fairseq.trainer][INFO] - begin training epoch 1207
[2024-10-09 09:03:42,076][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:06:22,205][fairseq_cli.train][INFO] - end of epoch 1207 (average epoch stats below)
[2024-10-09 09:06:22,212][train][INFO] - {"epoch": 1207, "train_loss": "0.5", "train_ntokens": "260593", "train_nsentences": "1750.04", "train_wps": "78046.5", "train_ups": "0.3", "train_wpb": "260593", "train_bsz": "1750", "train_num_updates": "57910", "train_lr": "0.000464796", "train_gnorm": "0.386", "train_loss_scale": "4", "train_train_wall": "60", "train_gb_free": "39.7", "train_wall": "27553"}
[2024-10-09 09:06:22,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:06:22,422][fairseq.trainer][INFO] - begin training epoch 1208
[2024-10-09 09:06:22,422][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:08:41,511][fairseq_cli.train][INFO] - end of epoch 1208 (average epoch stats below)
[2024-10-09 09:08:41,517][train][INFO] - {"epoch": 1208, "train_loss": "0.491", "train_ntokens": "260754", "train_nsentences": "1750.04", "train_wps": "89850.5", "train_ups": "0.34", "train_wpb": "260754", "train_bsz": "1750", "train_num_updates": "57958", "train_lr": "0.000464731", "train_gnorm": "0.377", "train_loss_scale": "4", "train_train_wall": "50", "train_gb_free": "40.6", "train_wall": "27692"}
[2024-10-09 09:08:41,657][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:08:41,661][fairseq.trainer][INFO] - begin training epoch 1209
[2024-10-09 09:08:41,661][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:11:17,077][train_inner][INFO] - {"epoch": 1209, "update": 1208.875, "loss": "0.498", "ntokens": "260850", "nsentences": "1757.22", "wps": "73483.5", "ups": "0.28", "wpb": "260850", "bsz": "1757.2", "num_updates": "58000", "lr": "0.000464674", "gnorm": "0.387", "loss_scale": "4", "train_wall": "233", "gb_free": "39.8", "wall": "27848"}
[2024-10-09 09:11:18,656][fairseq_cli.train][INFO] - end of epoch 1209 (average epoch stats below)
[2024-10-09 09:11:18,659][train][INFO] - {"epoch": 1209, "train_loss": "0.496", "train_ntokens": "260767", "train_nsentences": "1750.04", "train_wps": "79655.6", "train_ups": "0.31", "train_wpb": "260767", "train_bsz": "1750", "train_num_updates": "58006", "train_lr": "0.000464666", "train_gnorm": "0.397", "train_loss_scale": "4", "train_train_wall": "62", "train_gb_free": "40.1", "train_wall": "27850"}
[2024-10-09 09:11:18,895][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:11:18,942][fairseq.trainer][INFO] - begin training epoch 1210
[2024-10-09 09:11:18,943][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:14:05,356][fairseq_cli.train][INFO] - end of epoch 1210 (average epoch stats below)
[2024-10-09 09:14:05,370][train][INFO] - {"epoch": 1210, "train_loss": "0.482", "train_ntokens": "260469", "train_nsentences": "1750.04", "train_wps": "74997.5", "train_ups": "0.29", "train_wpb": "260469", "train_bsz": "1750", "train_num_updates": "58054", "train_lr": "0.000464601", "train_gnorm": "0.359", "train_loss_scale": "4", "train_train_wall": "50", "train_gb_free": "39.6", "train_wall": "28016"}
[2024-10-09 09:14:05,539][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:14:05,543][fairseq.trainer][INFO] - begin training epoch 1211
[2024-10-09 09:14:05,543][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:16:45,062][fairseq_cli.train][INFO] - end of epoch 1211 (average epoch stats below)
[2024-10-09 09:16:45,076][train][INFO] - {"epoch": 1211, "train_loss": "0.495", "train_ntokens": "260809", "train_nsentences": "1750.04", "train_wps": "78389.3", "train_ups": "0.3", "train_wpb": "260809", "train_bsz": "1750", "train_num_updates": "58102", "train_lr": "0.000464535", "train_gnorm": "0.374", "train_loss_scale": "4", "train_train_wall": "53", "train_gb_free": "39.7", "train_wall": "28176"}
[2024-10-09 09:16:45,232][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:16:45,238][fairseq.trainer][INFO] - begin training epoch 1212
[2024-10-09 09:16:45,238][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:19:33,753][fairseq_cli.train][INFO] - end of epoch 1212 (average epoch stats below)
[2024-10-09 09:19:33,761][train][INFO] - {"epoch": 1212, "train_loss": "0.493", "train_ntokens": "260595", "train_nsentences": "1750.04", "train_wps": "74155.1", "train_ups": "0.28", "train_wpb": "260595", "train_bsz": "1750", "train_num_updates": "58150", "train_lr": "0.00046447", "train_gnorm": "0.399", "train_loss_scale": "4", "train_train_wall": "48", "train_gb_free": "40.5", "train_wall": "28345"}
[2024-10-09 09:19:33,908][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:19:33,911][fairseq.trainer][INFO] - begin training epoch 1213
[2024-10-09 09:19:33,912][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:22:59,728][fairseq_cli.train][INFO] - end of epoch 1213 (average epoch stats below)
[2024-10-09 09:22:59,742][train][INFO] - {"epoch": 1213, "train_loss": "0.486", "train_ntokens": "260688", "train_nsentences": "1750.04", "train_wps": "60749.8", "train_ups": "0.23", "train_wpb": "260688", "train_bsz": "1750", "train_num_updates": "58198", "train_lr": "0.000464405", "train_gnorm": "0.353", "train_loss_scale": "4", "train_train_wall": "83", "train_gb_free": "39.7", "train_wall": "28551"}
[2024-10-09 09:22:59,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:22:59,941][fairseq.trainer][INFO] - begin training epoch 1214
[2024-10-09 09:22:59,942][fairseq_cli.train][INFO] - Start iterating over samples
[2024-10-09 09:24:26,397][train_inner][INFO] - {"epoch": 1214, "update": 1213.042, "loss": "0.49", "ntokens": "260529", "nsentences": "1744.05", "wps": "66014.6", "ups": "0.25", "wpb": "260529", "bsz": "1744", "num_updates": "58200", "lr": "0.000464402", "gnorm": "0.371", "loss_scale": "4", "train_wall": "245", "gb_free": "40.8", "wall": "28637"}
[2024-10-09 09:25:12,109][fairseq_cli.train][INFO] - end of epoch 1214 (average epoch stats below)
[2024-10-09 09:25:12,113][train][INFO] - {"epoch": 1214, "train_loss": "0.489", "train_ntokens": "260814", "train_nsentences": "1750.04", "train_wps": "94578.2", "train_ups": "0.36", "train_wpb": "260814", "train_bsz": "1750", "train_num_updates": "58246", "train_lr": "0.00046434", "train_gnorm": "0.37", "train_loss_scale": "4", "train_train_wall": "49", "train_gb_free": "39.6", "train_wall": "28683"}
[2024-10-09 09:25:12,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 48
[2024-10-09 09:25:12,216][fairseq.trainer][INFO] - begin training epoch 1215
[2024-10-09 09:25:12,217][fairseq_cli.train][INFO] - Start iterating over samples
